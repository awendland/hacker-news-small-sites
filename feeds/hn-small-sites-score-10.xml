<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 09 Jan 2021 01:43:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 09 Jan 2021 01:43:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Shooting photos with an IMAX projector lens]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25666217">thread link</a>) | @dmitrygr
<br/>
January 6, 2021 | https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/ | <a href="https://web.archive.org/web/*/https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>What the heck is that huge lens? That Crazy Huge Lens is an IMAX Lens. You will be surprised at the cool street portraits we got with this thing. Take a look at how Jay P rigged this with his <a href="https://bhpho.to/38bRbgL">Canon EOS R</a> camera and the amazing results.</p>
<p><iframe width="750" height="450" src="https://www.youtube.com/embed/D-ihZrP4C0A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>
<p>This is Jay P Morgan. Today on The Slanted Lens we are in Santa Monica at a skate park. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">This is a great skate park. I’ve been here before with my daughter who comes down to skate. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This time I came with this huge IMAX lens. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png" alt="" width="1072" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">This thing is a beast. It’s an IMAX lens and it was made by Iwerks. I’ve had it in a huge hard case in my storage for a long, long time. I’ve always wanted to adapt this to a camera and take portraits with it. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png" alt="" width="1071" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-768x431.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I want to do street portraits with an IMAX Lens using my Canon EOS R Camera. So here’s the process I went through to get this lens adapted, so I’ll be able to focus it and work with it.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png" alt="" width="1090" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png 1090w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-768x431.png 768w" sizes="(max-width: 1090px) 100vw, 1090px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png" alt="" width="1093" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png 1093w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-768x430.png 768w" sizes="(max-width: 1093px) 100vw, 1093px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png" alt="" width="1092" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png" alt="" width="1091" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-768x431.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png" alt="" width="1091" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-768x430.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png" alt="" width="1086" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png 1086w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-300x169.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-768x431.png 768w" sizes="(max-width: 1086px) 100vw, 1086px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png" alt="" width="1094" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png 1094w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-768x428.png 768w" sizes="(max-width: 1094px) 100vw, 1094px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png" alt="" width="1091" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-768x429.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png" alt="" width="1088" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png 1088w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-768x431.png 768w" sizes="(max-width: 1088px) 100vw, 1088px">Let’s take some pictures. The way I focus this thing is so silly. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">I have a track that I can release here and I can move my camera back and forth inside this tape I put around the lens. Then I find the point where it focuses. It’s pretty gorilla. Very, very gorilla, but it works.<img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So in this situation I don’t have a lens on the front of the camera. So if the camera is going to fire without a lens on it, you have to go to the menus and you’ve have to turn on the setting which will allow the camera to fire when there’s no lens attached. There’s no coupling here. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This is just a space between the lens and the front of the camera. I did have to turn that feature on that will allow me to shoot without a lens in order to make this work.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png" alt="" width="1070" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-768x430.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png" alt="" width="1070" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-768x429.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This lens is so interesting because it has a 180 degree angle of view. So I can get right here close and to the side and I’m in the shot. And I am in the shot when I move all the way around to the other side.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png" alt="" width="1071" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This lens has a really strange quality because my face is in focus, but the area around it is out of focus. It almost has a tilt shift kind of quality like it’s you’re focusing on one point. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">When you get somebody up front like this, it gives you a blur all the way around. It’s very cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<p>I’m learning as we go along here, it doesn’t have a flat plane of focus, but I think that’s because of the way I mounted the camera back there. It’s a little bit like a tilt shift. So I didn’t get them quite square, which is kind of cool because I get the face in focus, but the hands or the body go out of focus in the foreground. It’s just kind of cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png" alt="" width="1067" height="596" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png 1067w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-768x429.png 768w" sizes="(max-width: 1067px) 100vw, 1067px"></p>
<p>One of the reasons I love to carry a light in my bag is anytime I’m doing a street portrait or something, a continuous light is so easy to flip up really fast. It gives us a little bit of light on the face and opens up the shadows. The <a href="https://bhpho.to/32nCIvK">LitraStudio</a> is perfect for that because it’s easy. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png" alt="" width="1074" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png 1074w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-768x430.png 768w" sizes="(max-width: 1074px) 100vw, 1074px">Turn it on and it’s so powerful, it’s worth the weight. It’s not like one of the little tiny ones Litra makes. I like the bigger heavier light because it just gives me so much more power. Especially in a situation like this where you have the sun to deal with.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png" alt="" width="1072" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So there you have it. I’m going to do more of this. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png" alt="" width="1072" height="602" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">I want to adapt some other lenses to my EOS R and just try to get weird views and that kind of gritty look. This actually was way cleaner than I thought it was going to be. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">I don’t even have something blocking the light between the camera and the lens. I used just a little bit of tape in here. But it projects a great image on the sensor. It’s a little hard to focus but a lot of fun to shoot. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I hope you enjoyed this. Make sure you subscribe to the channel and ring that bell. Keep those cameras rollin’ and keep on clickin’.</p>
<p>Check out <a href="https://bhpho.to/32nCIvK">LitraStudio lights</a>:</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png" alt="" width="1073" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png 1073w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-768x429.png 768w" sizes="(max-width: 1073px) 100vw, 1073px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png" alt="" width="1072" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png" alt="" width="1071" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-768x429.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --><!-- AddThis Related Posts below via filter on the_content --><!-- AddThis Related Posts generic via filter on the_content --><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:identifier="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:title="Crazy Huge Imax Lens &#8211; Amazing Street Portraits"
    trackback:ping="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666217</guid>
            <pubDate>Thu, 07 Jan 2021 01:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A developer's perspective: the problem with screen reader testing]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25665851">thread link</a>) | @jacobtracey
<br/>
January 6, 2021 | https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/ | <a href="https://web.archive.org/web/*/https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>January 06, 2021</p></header><section itemprop="articleBody"><p>Screen readers are an essential part of using the web for people who are vision impaired, illiterate or have a learning disability.</p>
<p>Today’s screen readers traverse web pages and applications and read out user interface elements, content and allow users to navigate and interact with the web.</p>
<p>There are many screen readers available for different devices and platforms, each with differing levels of functionality, interfaces and features. The most common are JAWS, NVDA, VoiceOver and TalkBack.</p>
<p>According to the latest <a href="https://webaim.org/projects/screenreadersurvey8/">WebAIM Screen Reader User Survey</a>, when it comes to desktop screen reader usage, JAWS and NVDA are practically equal in usage, with around 40% of respondents reporting that they use one or the other.</p>
<figure>
<img src="https://jaketracey.com/webaim-graph.png" alt="Line chart of primary screen reader usage since October 2009. JAWS has steady decline from 68% to 40%. NVDA has steady incline from 3% to 41%. VoiceOver has a slow incline from 10% to 13%.">
<figcaption>Source: WebAIM</figcaption>
</figure>
<p>Based on the graph above, there’s a clear pattern over the course of the last 10 years, with NVDA usage increasing as JAWS usage drops, culminating in an inflection point in 2019 when NVDA surpassed JAWS usage for the first time.</p>
<p>As a developer regularly faced with time constraints, I have often wondered: what should be the baseline in terms of testing for screen readers, and what browser and screen reader combinations are the most important to cover in order to achieve the greatest level of WCAG compliance?</p>
<h2>An issue of time</h2>
<p>Given that almost all web applications developed in 2021 are also used on mobile and therefore require testing on both iOS and Android devices, as well as Windows and macOS for desktop users, providing adequate support for such a broad range of scenarios becomes quite difficult to manage.</p>
<p>Let’s say in a best-case scenario, a given page or feature will be tested on the following combinations:</p>
<ul>
<li>iOS / VoiceOver</li>
<li>Android / TalkBack</li>
<li>macOS / Chrome / VoiceOver</li>
<li>macOS / Safari / VoiceOver</li>
<li>macOS / Firefox / VoiceOver</li>
<li>Windows / Microsoft Edge / NVDA</li>
<li>Windows / Chrome / NVDA</li>
<li>Windows / Firefox / NVDA</li>
<li>Windows / Microsoft Edge / JAWS</li>
<li>Windows / Chrome / JAWS</li>
<li>Windows / Firefox / JAWS</li>
</ul>
<p>I should clarify that by “best-case”, I am conveniently leaving out any versions of Internet Explorer, but as frustrating as it may be, including it would add at least another 2 rounds of testing.</p>
<p>It’s also worth noting that WebAIM also recommends using Microsoft Edge with Narrator, but given its low usage, we’ll leave it out (more on this later).</p>
<p>Hypothetically, depending on the size of the functionality or page implemented, let’s say each round of testing takes one hour to complete, assuming the developer has experience with each of these browsers and screen readers.</p>
<p>In this scenario, comprehensively testing screen reader support across all these combinations adds 11 hours of development work – and that’s just to test!</p>
<h2>An issue of fragmentation</h2>
<p>Web developers will be familiar with the issues surrounding browser version fragmentation, and this problem is compounded when testing with screen readers. Contending with not only varying levels of HTML, Javascript and CSS support in the browser can be tough, and to combat this, polyfills and tools like <a href="https://caniuse.com/">caniuse.com</a> have made life a lot easier.</p>
<p>When it comes to screen reader version fragmentation, there is very little in the way of either documentation or support for developers. Fixing issues often comes down to a case of trial and error, retesting and hoping for the best.</p>
<p>A piece of information that would be incredibly useful in this area would be <em>penetration of screen reader updates</em> from the vendors. If, for instance, developers knew that there was a high adoption rate of updates among screen reader users, they could be confident that if a screen reader update resolved an issue, patches for older versions could be sunsetted. This approach has worked exceptionally well for browsers such as Chrome and Firefox.</p>
<p>Sadly, there’s not currently any way for a developer to identify the type or version of a screen reader that is being used, so implementing targeted fixes isn’t an option anyway right now.</p>
<h2>A case for dedicated accessibility testers</h2>
<p>Given the scope and time it takes to properly test across so many devices, browsers and screen readers, having dedicated accessibility testers embedded into teams can significantly increase the quality and speed with which properly accessible applications can be produced.</p>
<p>Let’s face it: developers already have a hard time keeping up with the pace of change in their own domain, let alone the level of knowledge required for comprehensive accessibility auditing.</p>
<p>That is not to say that developers should ignore accessibility completely. However, expecting someone to know about a specific bug on a particular combination of code, browser and screen reader is too much, even for the most experienced accessibility-focused developer.</p>
<h2>Why automation isn’t enough</h2>
<p>The old saying "a good programmer is a lazy programmer" comes to mind when I think about testing here. Being lazy myself (although possibly not that great of a programmer), I rely on automated tools like <a href="https://www.deque.com/axe/">axe</a> to do most of my accessibility for me. While the current range of tooling is excellent, and picks up the most obvious issues, when it comes to screen readers there’s no way around it: you need to manually test.</p>
<p>Why? Well, the current state of both browsers and screen reader support is all over the place. To highlight this, the Powermapper website has a neat <a href="https://www.powermapper.com/tests/screen-readers/aria/">list of screen reader support for WAI-ARIA attributes</a>. Not throwing shade at any one – things are continuously improving with updates to browsers and screen readers – but the point stands. Current automated testing tools are not going to catch these problems because they essentially test the validity of code, in much the same way as a code linter does.</p>
<h2>A compromise, so we can all still get stuff done</h2>
<p>Not every team has the luxury of a dedicated accessibility tester, or even a dedicated tester for that matter. Sometimes, you just need to do the best you can, with the resources that you have available.</p>
<p>"When can we stop supporting this?" has been the desperate cry of developers for years when it comes to Internet Explorer 9/10 and most recently 11, and as their usage has dropped, so has the rate of developers losing their hair trying to get their code working.</p>
<p>Which brings me back to Microsoft Edge with Narrator, as mentioned earlier. With 1% of users in that survey, and possibly 0% of users for your application or site, is it worth testing on this combination at all? More specifically, what number of users justifies support, and the testing and development overhead that comes with it?</p>
<h3>Windows - Chrome (latest version), NVDA</h3>
<p>As of December 2020, Chrome is by far the most popular browser in the world, with 65.3% of users. Later versions of Microsoft Edge utilize the same rendering engine, so there is a high likelihood that if it works in Chrome, it will work similarly in Edge.</p>
<p>Based on the WebAIM stats, it is a safe bet that NVDA will begin to increase its lead over JAWS over the next few years. Given that it is also open-source and free, I can’t help but draw a comparison to the way Firefox overtook Internet Explorer in the 2000s browser wars.</p>
<h3>macOS - Safari (latest version), VoiceOver</h3>
<p>Safari is a fair distance behind Chrome in terms of users, with 16.7% share as of writing, but it has the benefit of being the default browser in macOS. It is also free, and the support for accessibility features with VoiceOver is second to none. In addition to this, because of the similarity with its mobile counterpart, most likely any issues that are identified in the desktop version will have similar fixes.</p>
<h3>iOS - Safari (latest version), VoiceOver</h3>
<p>Safari is by far the most popular browser on iOS and all other browsers on iOS use the WebKit rendering engine. VoiceOver is the gold standard for mobile screen readers (and the only option for iOS devices), and as such it makes sense to use this combination for testing iOS accessibility.</p>
<h3>Android - Chrome (latest version), TalkBack</h3>
<p>In a similar vein to iOS, being the default browser and screen reader combination for Android makes this a simple choice, as it will cover the vast majority of users on this platform. Although manufacturers do include their own browsers and there are quite a few other options on Android, the vast majority of the time they use the inbuilt rendering engine, so the expectation in terms of accessibility should be similar, if not identical, to the Chrome experience.</p>
<p>This is by no means a catch-all solution for everyone. Each circumstance will be different, and the best course of action would be to engage your users and ask rather than trying to make the decision for them.</p>
<p>The reality is that if your site or application’s design or functionality looks bad or works poorly for a large enough number of your users because it does not support the software that they use, it can have potential ramifications to your business, through sales or reputation. Similarly, poor accessibility will have a negative impact if your users are using older versions of screen readers and browser combinations.</p>
<h2>But what about JAWS, ZoomText, System Access, <em>insert screen reader here</em>?</h2>
<p>At the risk of being slightly incendiary, I dislike the idea of paying for something that I can get for free. NVDA is a project that has brought screen readers to everybody – including those without the financial means to pay for it – so I support it. Along with the clear trajectory of its usage uptake, it is not unreasonable to expect that the majority of users will adopt it in the next 5 to 10 years.</p>
<p>At the end of the day, however, your best bet when it comes to identifying where your testing efforts should be placed is to talk to your users to find out what their needs are and what software they use. If you don’t have access to this information, the proposed testing scope above will suffice for the vast majority of your site or application’s users, and most likely will continue to do so in the years to come.</p></section></article></div>]]>
            </description>
            <link>https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665851</guid>
            <pubDate>Thu, 07 Jan 2021 01:12:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All Our Selves in One Basket – on centralization of social spaces]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25664196">thread link</a>) | @InvisibleUp
<br/>
January 6, 2021 | https://invisibleup.com/articles/31/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/31/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/31/thumb.png" alt="All Our Selves In One Basket thumbnail">
	
	
	
	<p>Published 2020-09-02</p>
	

	
<p>There's a classic old idiom, "don't put your eggs all in one basket". The reasoning goes, what if the basket breaks? What if the basket isn't big enough, or gets stolen, or was cursed by a witch or something? It's important to have redundancy, to spread the eggs across many basket so that there's no one single point of failure.</p>
<p>But if we look at society, if we look at the internet, if we look at the communities we've built ourselves around... unfortunately, I believe that's exactly what a lot of us are doing. Being able to be yourself, being able to choose how you present yourself to the world, being able to tailor your living environment to your needs and desires? That's all very, very important. But if you give the keys to your self-expression and the options for the communities you belong in to one small, largely unknown group of people, that's not good.</p>
<p>In this ludicrously in-depth article, we'll be discussing how society limits both individual and community self-expression both online and offline.</p>
<h2>Part 1: The Third Place</h2>
<p><img alt="A house, labeled '1', an office complex, labeled '2', and a '3' with a question mark" src="https://invisibleup.com/articles/31/thirdplace.png"></p>
<p>Very, very broadly speaking, a working-class person (that is, not an "owner" like a CEO, landlord, or investment banker) lives their life in three kinds of places. The first place is home. It's where you sleep, it's where you do your hobbies, it's where you have privacy and family and possibly friends if you want to invite them over. The second place is work, where you do a job to contribute to society and receive wages.</p>
<p>But clearly, we do more than that. We go to other places. Grocery stores and shops, of course, but besides that. The "third place" is where you spend your time in public, in your community. American urban sociologist Ray Oldenburg, who came up with the concept of "the third place" in his 1989 book "The Great Good Place", defines the third place as (commonly seen as) eight characteristics.</p>
<ol>
<li>There is no obligation to be here for legal, survival, political, etc. reasons. You can just <em>not show up</em>.</li>
<li>Everyone is equal. The rich, the poor, the minorities and the majorities all intermingle together in one common space.</li>
<li>Conversation and socializing is the main activity. You go here to "hang out".</li>
<li>They're accessible and accommodating for anyone who wants to visit.</li>
<li>It's a place where people regularly go, and whose regulars give the space its vibe and characteristics.</li>
<li>The physical place is not overly pretentious or imposed. It feels like <em>the community</em>, like an extension of home.</li>
<li>Generally speaking, the vibe here is more calm and friendly and playful than actively hostile and argumentative.</li>
<li>You feel like you have genuine ownership in the place, as if it's almost a communal home for you and the people you care about.</li>
</ol>
<p>That's a relatively high bar, when spelled out like that. In pandemic-era America you'd be very hard pressed to name a place like this. Offline, anyways. But this sort of pattern has shown up a lot in history, because as it turns out people <em>like</em> having a communal space to just vibe in.</p>
<h3>The Town Square</h3>
<p><img alt="The Zócalo in Mexico City" src="https://invisibleup.com/articles/31/zocalo.jpg"></p>
<p>The most obvious example in urban environments is the town square or the plaza. It's an open area in the middle of town, usually with benches and close access to shops and homes and such. Pictured is <em>La Plaza del Zócalo</em>, the main square of Mexico City. It's been a meeting spot for the people of the area since the Aztec times, an important location for numerous historical events, and significant enough to warrant its own Wikipedia page. That's really amazing for a 240 m^2 slab of concrete. What's even more amazing is that it <em>wasn't</em> always a slab of concrete. Here's a model of how it looked in 1910.</p>
<p><img alt="The Zócalo in Mexico City" src="https://invisibleup.com/articles/31/zocalo1910.jpg"></p>
<p>It was a big park area! With a bunch of trees and benches and everything. Unfortunately, the very shaky politics of 20th century Mexico left the area in major disrepair by the 1970s, and it became that. I am not from Mexico, nor do I know anyone from the region, so I can't comment on what that did to the community in Mexico City. But as an outsider, I'd consider the 1910 Zócalo much more friendly and inviting than the modern one, which is literally a flat surface with a flagpole in the middle all surrounded by a busy road.</p>
<p>Obviously that isn't the only example. These tend to be a staple of small European and Hispanic towns. Just, a place, in your neighborhood, to go and chill. Other famous examples include the Roman Forum, the Greek Agoras, the National Mall of Washington D.C, and the "quads" or "diags" of most college campuses.</p>
<h3>Shopping Malls</h3>
<p>It is incredibly worth pointing out that town squares only make sense in urban contexts, where there's a dense population of people who live, work, and shop in one general area. The appeal of town squares is that they're basically on the way to wherever you're going, so it's a really nice spot to meet up with friends or just go if you're bored.</p>
<p>Suburbia is <em>not</em> that. Or, more accurately, it is that, <em>at the scale of the car.</em> See, America's fascination of suburban sprawl has a long detailed history to it. Paraphrasing from (imo) a very good book, "Repairing the American Metropolis: Common Place Revisited" by Douglas S. Kelbaugh, the blame of sprawl can be pinned down largely on cultural reasons. First off, Americans always solved their resource and land division issues by expansion, growth, "moving out west". It was the safety valve to avoid actually thinking about difficult problems. At the time this was seen as the country's "manifest destiny", which eventually led to <a href="https://www.youtube.com/watch?v=FfoQBTPY7gk">unnervingly cheery songs on children's television happily glossing over the genocide of Native Americans like it was no big deal</a>. And, heck, if we got all this elbow room, why not make everything really, really big? Big houses, big rooms, big parcels of land. And really, really cheap too, because of the glutton of natural resources. And sure, that'll get old and worn sometime, but some of the population will leave for greener pastures anyways, so there's no need to change anything.</p>
<p>So, around the early-to-mid 20th century, when cities were getting too full of colored people who were just demanding rights too loudly, most of the rich white people just up and left. They settled suburban areas outside the cities, less densely populated, with all the backyard space you need to cook out with your neighbors. And via <a href="https://en.wikipedia.org/wiki/Redlining">redlining</a>, it was possible to dig very deeply a concrete "us vs. them" line in the dirt. The newfangled highway system just made it easier to separate the houses from the factories, to drive a wedge in the population. Also, just to drive the point home, federal, state, and local governments have subsidized services like sewer pipe connections, energy, and road building, often funded by taxes generated from the more urban, more productive areas.</p>
<p>An incredibly good example of this is to compare Flint and Burton, MI to the surrounding cities of Grand Blanc, Flushing, and Davison. I could spend a lot of time on this but I'd rather just do a visual comparison.</p>
<p><img alt="Fox Hill Glens of Grand Blanc, MI" src="https://invisibleup.com/articles/31/grandblanc.jpg">
<img alt="Section of the Flint River of Flint, MI" src="https://invisibleup.com/articles/31/flintriver.jpg"></p>
<p>It should be laughably easy to tell which one is which. (The first pic is the Fox Hill Glens of Grand Blanc, which was the first image Google gave me. The second pic is a section of the Flint River between downtown Flint and Kettering University. I took that pic during an urbex tour a few years back, because Flint was somewhat nearby and makes for <em>amazing</em> urbex pics.)</p>
<p>Where this starts to cause issues is that instead of having one core neighborhood with residential, commercial, <em>and</em> industrial areas (in a SimCity-esque model), we've split those sections into their own, largely independent areas, often harshly split on racial or class boundaries. We've got gigantic swaths of houses with maybe a corner store and a gas station, we've got giant industrial parks or office complexes, and we've got the commercial districts.</p>
<p>It's the commercial districts I really want to highlight here. If the residential areas are home, and the industrial/office parks are work, then clearly the third place is the commercial district. Now, there's two ways to approach that. </p>
<p><img alt="A strip mall" src="https://invisibleup.com/articles/31/stripmall.jpg"></p>
<p>The most common approach is to just put a bunch of boxes next to each other, surround it with a parking lot, and call it "a strip mall". Occasionally there will also be a "big box" store, like a Wal-Mart or a Target or a Best Buy or a Kohl's or a Home Depot, either attached or detached.</p>
<p>In the very worst scenarios, you're subject to drive through the <a href="https://www.strongtowns.org/journal/2017/10/30/the-stroad">"stroad", or street-road</a>, where all the shops each have their own driveway and their own parking space and it's hostile to both people <em>and</em> cars.</p>
<p>You drive here (or take the bus, if you're poor and you're fine with the once-an-hour service), you shop, you drive home. You don't really spend time here. There is literally nothing here besides concrete boxes. And also the constant issue of cars driving past you. Hope you like sprinting across five lanes of traffic moving at 40 mph!</p>
<p>Enter Austrian-born architect <a href="https://en.wikipedia.org/wiki/Victor_Gruen">Victor Gruen</a>. After fleeing to America from the Nazis, on account of being a Jewish socialist, he slowly worked up the career ladder, from draftsman to architect. And he absolutely saw the issues of suburban sprawl. In the 1950s he gave a speech where he called the suburbs "avenues of horror ... flanked by the greatest collection of vulgarity ... ever collected by mankind."</p>
<p><img alt="The Strand Arcade in Sydney CBD, Australia, opened 1892" src="https://invisibleup.com/articles/31/arcade.jpg"></p>
<p>As an alternative, he envisioned a single building, a few shops surrounded by a shared courtyard, protected from the weather. Something of an iteration of the old "arcades", like the Strand Arcade in Sydney, Australia as pictured above. The courtyard was the most substantial improvement, it was somewhere to go <em>in between</em> shopping. The arcade was just a straight hallway normally, literally just shops in a building. The shopping mall was a <em>destination</em>.</p>
<p>Victor has larger goals in mind. He expected this to be just <em>one</em> part of a new, dense, suburban community. He imagined indoor malls with housing, with schools and libraries and doctor's offices and offices, perhaps surrounded outside by high density housing …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/31/">https://invisibleup.com/articles/31/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/31/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664196</guid>
            <pubDate>Wed, 06 Jan 2021 23:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new SaaS metric for demonstrating the ROI of community]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25663937">thread link</a>) | @someproduct
<br/>
January 6, 2021 | https://orbit.love/blog/whats-your-communitys-nrg | <a href="https://web.archive.org/web/*/https://orbit.love/blog/whats-your-communitys-nrg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Many DevRel and community teams struggle to demonstrate how their activity impacts key metrics, like revenue.</p><p>We recently learned of a new SaaS metric proposed by <a href="https://openviewpartners.com/">OpenView Partners</a> that we think can help, since it can contextualize the results of community activity within a broader business situation, and help show the impact of community on business growth.</p><p>It’s called <a href="https://openviewpartners.com/blog/new-saas-metric/">Natural Rate of Growth</a> (NRG), and it’s essentially, “<em>how fast a company grows without even trying—before layering on incremental investments in sales and marketing</em>.” Here’s the equation:</p><pre><code>NRG = 100 x Annual Growth Rate x % Organic Signups X % ARR from Products</code></pre><p>In other words, <strong>if your company immediately halted paid search, banner ads, outbound efforts of the sales team, and big marketing campaigns, how much and how quickly growth increase?</strong></p><p>As it turns out, <em>many companies are asking this very question</em>, which creates the perfect opportunity for DevRel and community teams to shine by influencing NRG.</p><p>NRG exists to measure a product's ability to grow through a combination of non-paid traffic and product-centric upsells, like inviting teammates and upgrading one’s plan. <strong>These are areas community teams already influence, but most don’t have a great way to communicate the impact of their effort</strong>. We think NRG is one way to tell the story.</p><p>So how can a company drive more organic signups and ARR from products?</p><h3>Community drives NRG</h3><p>At <a href="http://orbit.love/">Orbit</a>, we think<strong> one way community delivers business value through the generation of organic signups</strong>, which has the side effect of driving ARR from products.</p><p>If you have a high gravity community with engaged and passionate users, they’ll continue engaging with each other whether or not your company is actively participating.</p><p>Just look at <a href="https://community.airtable.com/">Airtable’s community forum</a>. It sees hundreds of posts per week, with the vast majority of engagement coming from non-Airtable community members. If the Airtable team stopped replying to messages for a month, the community would continue to operate.</p><p>Search engines would continue indexing discussions that happen there, and other users would continue to find helpful community-generated content. That content would drive more usage, and lead to deeper product usage and interest in paid features, like Blocks, leading to in-product upgrades. In other words, NRG would increase.</p><p>If community drives growth, how can you increase and measure and expand your community?</p><h3>Gravity helps measure a community’s growth</h3><p>In the <a href="https://github.com/orbit-love/orbit-model">Orbit Model</a>, Gravity is the attractive force of a community that acts to retain existing members and pull in new ones, and we think it’s a key top-level metric company leadership should track.</p><p>It’s based on <a href="https://github.com/orbit-love/orbit-model#reach">reach</a> and <a href="https://github.com/orbit-love/orbit-model#love">love</a>, so an increase in gravity means two things.</p><p>First, it means the community has increased its ability to drive awareness about the community and the product it's built around (Reach). Second, it means the community has increased its level of activity, through PRs, content creation, active discussions, and more (Love).</p><p>When a community's influence and activity increase, so does its gravity.</p><h3>Gravity, NRG, and revenue</h3><p>So what about key SaaS metrics, like revenue and NRG?</p><p>Revenue is the end goal, but if community teams try to influence revenue directly, they risk alienating users with sales-centric tactics. Gravity will drop as everyone leaves the community.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/2c753578f9d8bcee8154d76bbfd88ad523c01c94-1220x470.png" alt="Text: Revenue is a natural second-order effect of high gravity. " title="Revenue &amp; Gravity"></p><p>For most communities, <strong>revenue is a natural second-order effect of high gravity</strong>. Just think of an ice cream cone. The larger the scoop on top of the cone, the more ice cream that drips down. With communities, <strong>as gravity increases, more users will end up in the adoption funnel</strong>.</p><p>That means DevRel and communities teams should focus on growing the Reach and Love of their community, leading to higher gravity, which then leads to more organic signups.</p><p>In most cases, <strong>higher gravity leads to more organic signups which leads to increased revenue.</strong></p><p>We think one effective way to demonstrate the impact of community activities, then, is by calculating NRG and showing how community and DevRel contribute.</p><p>As a result, we think DevRel leadership should consider NRG as a metric it reports on, and clearly demonstrate how community and DevRel investments move this important metric.</p></div></div>]]>
            </description>
            <link>https://orbit.love/blog/whats-your-communitys-nrg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25663937</guid>
            <pubDate>Wed, 06 Jan 2021 23:03:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Report: 60% of US companies are under financial or operational stress]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25663393">thread link</a>) | @finphil
<br/>
January 6, 2021 | https://nuadox.com/post/639600728973934592/60-percent-of-us-companies-are-under-stress | <a href="https://web.archive.org/web/*/https://nuadox.com/post/639600728973934592/60-percent-of-us-companies-are-under-stress">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="639600728973934592">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/639600728973934592/60-percent-of-us-companies-are-under-stress"><h2>Report: 60% of US companies are under financial or operational stress, 14% in distress</h2></a>
                                <figure data-orig-width="1920" data-orig-height="1242"><img src="https://64.media.tumblr.com/86199f9ec3706d2d5e0ab3e58a8dae91/c46ea7b7d30d1d77-62/s1280x1920/ff358ae657002c368b877c8458fe18f34610a19b.jpg" alt="image" data-orig-width="1920" data-orig-height="1242" width="1280" height="828"></figure><p><b>- By&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.bcg.com%2F&amp;t=MzhjZDI1YTY1NDJlNTc3NWEyOWE0Y2Y3NWNlNTViZTIwNjRiYWQ0MSxQMVFpanA2SA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639600728973934592%2F60-percent-of-us-companies-are-under-stress&amp;m=0&amp;ts=1610156618">Boston Consulting Group (BCG)</a> -</b></p><p>More than seven months into the novel coronavirus pandemic, a disturbingly large number of US companies are at risk, according to new research from Boston Consulting Group (BCG) confirming that economic distress is deeply entrenched and shows no sign of letting up.</p><p>More than 60% of US companies analyzed are under financial or operational stress as of the end of the second quarter of 2020, a 49% increase from the end of the second quarter of 2019, according to BCG analysis. And 14% are in distress—either challenged to meet their financial obligations or under operational pressure that requires significant restructuring. That represents a 43% increase over the previous year. The lack of additional government stimulus puts many of these companies at risk.</p><p>Those are among the most significant findings from the BCG TURN Radar index. The index, developed by BCG TURN, BCG’s special transformation, turnaround, and restructuring unit, tracks a company’s distress based on over 20 key performance indicators in three categories: financial, market, and qualitative. The Radar index reports on over 25,000 publicly-traded companies, with more than $100 million in revenue, across 80 countries and 20 industry sectors. There were 721 US companies tracked for distress. A company is measured against its peers, its industry, and the overall sample, and its score places it in one of three groups—either stable, stressed (underperforming in its industry or under internal or external pressure), or distressed.</p><p>The US picture is bleak, but not the worst on a global basis—in Central Europe, the Middle East, and Africa, the number of companies in distress has gone up 83%.</p><p>Overall, the BCG TURN Radar index portrays the US and global economy struggling as the pandemic maintains its grip.</p><h2><b>The US is hard-hit, and key sectors suffer, but others, boosted by pandemic demand, outperform</b></h2><p>Some US sectors have been particularly hard-hit—notably, those directly affected by the pandemic and those already challenged before the pandemic’s economic downdraft took hold.</p><p>Among the US industries suffering the most are automotive and mobility (52% stressed, 16% distressed), travel and tourism (61% stressed, 16% distressed), and retail (67% stressed, 18% distressed).</p><p>Health care providers, biopharma, the technology industry, and transportation and logistics have been the least impacted. All of these sectors have been boosted by pandemic-related demand. Health care providers and biopharma are showing significantly less stress than in the same period last year. Both have benefited from pandemic-related activity and investment. In 2019, almost 42% of biopharma companies were in distress. In 2020, that figure fell to 25%. In multiple sectors, there are big gaps between winners and losers, and research shows that large companies may achieve a stronger recovery.</p><p>“BCG TURN Radar confirms the impression created by stories of business failures and layoffs—the COVID-19 pandemic is causing deep, structural changes that are likely to be long-lasting,” says Luke Pototschnik, BCG senior partner, and head of the firm’s Transformation practice and BCG TURN in North America. “The impact may be most severe on companies that were challenged to begin with. But the good news is that there are actions companies can take—such as generating short-term cash to fund long-term investment—that can mitigate the worst of the downturn and help set them on the path to recovery.”</p><h2><b>Some subsectors stand out even in stressed industries, and the gap between winners and losers grows</b></h2><p>While the Radar index raises alarms about several major sectors of the US economy, it also finds winners even in underperforming sectors.</p><p>Many of the sectors faring worst are those that faced pre-pandemic structural challenges. “The automobile industry is struggling more than others,” says Pototschnik. “Even before the pandemic, it was dealing with significant changes such as the shift to electric vehicles, which requires investment. But in the pandemic economy, investment may be hard to come by.”</p><p>Similarly, the bankruptcy rate has been high in the already-challenged oil and gas sector, and Radar suggests that bankruptcies are likely to continue, with over 57% of the sector under stress and over 10% in distress.</p><p>Of more note is the widening gap between winners and losers in several sectors as some industries suffer while other outperform. “In most cases, outperformance is driven by pandemic-related consumer and business spending,” Pototschnik says.</p><ul><li>Most of the retail sector has moved from “stable” to “stressed,” with over 52% of restaurants in distress—but large groceries are doing well, with over 43% in stable territory.</li><li>Similarly, IT services are suffering, with over 50% in distress, but digital devices and services are thriving, with over 42% stable. The numbers reflect the sudden and massive shift from office work to remote work.</li><li>Shipping companies are performing strongly thanks to the upsurge in e-commerce, with 32% stable, while 47% of logistics companies are stressed as the result of an overall slowdown in global trade.</li></ul><p>“In several sectors, the gap between winners and losers is widening,” Pototschnik says. “Some of this may be the result of pandemic-related behavior patterns that will normalize over time. But some of these patterns, such as the shift to remote work, may be long-lasting, and some industry sectors may be permanently reshaped.”</p><h2><b>Bankruptcy rates will increase, data providers may thrive, and large companies have an advantage</b></h2><p>The Radar index does not predict future performance, and, as Pototschnik notes, “Prediction is made difficult by the complex dynamics of the pandemic. But the index, combined with our observation of certain macro trends, does suggest some outcomes.” Among BCG’s projections:</p><ul><li>Bankruptcy rates will increase, partly as a result of the robust and trustworthy bankruptcy process in the US and North America.</li><li>Bankruptcy is already underway in retail and in oil and gas. Telecom is in distress, in part due to its high investment requirements. Restructuring will come to manufacturing as supply chain networks are revisited, but instead of bankruptcy, transformation may take the form of changes in market structures.</li><li>Severe uncertainty is driving an appetite for data; industries and companies that provide data and analytics are likely to be strong performers. Technology will perform well in the long-term, even if the nature of office work is fundamentally changed. Travel and tourism will rebound once a vaccine Is developed, trusted, and distributed at scale. Sectors such as retail that have deeper business model problems apart from the pandemic are likely to lag.</li><li>Size may also be a predictor of survival. Radar shows that large companies, even in distressed industries, have more upside potential. “There are reasons why this makes sense,” Pototschnik says. “Large companies typically have healthier balance sheets. They have greater access to capital markets. They have more diversified product lines and portfolios. And they are less vulnerable than smaller companies to private-equity and activist intervention. All of these factors seem to add up to a greater margin of safety.”</li></ul><h2><b>Companies can take action to improve their odds</b></h2><p>Finally, individual companies can act to improve their odds for recovery. Separate BCG TURN research identifies the steps that leading companies take in times of crisis that lead to superior performance. Leading companies act proactively, investing in projects that generate short-term cash in order to fund long-term investments. They increase the pace of innovation, streamline the organization to maximize efficiency and capitalize on digital, and build crisis management and scenario planning capabilities to increase their resilience. “Companies that took these steps during the 2008–2009 financial crisis recovered faster and performed better than their peers,” Pototschnik says.</p><p>“The COVID-19 pandemic is a massive historic event—it is stressing companies, industries, and national and global economies to the limit,” Pototschnik says. “BCG TURN Radar indicates that that the stress is severe, and many organizations will be forced to restructure. But those that take a strategic view of restructuring and look at it as an opportunity to rethink their business stand a better chance of leading when the recovery ultimately arrives.”</p><p>–</p><p><b>Source:&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.prnewswire.com%2Fnews-releases%2Fmore-than-half-of-us-companies-are-under-financial-or-operational-stress-and-14-are-in-distress-as-pandemics-economic-impact-deepens-301201503.html&amp;t=N2ZmZDkwOWRlZTFmMjNjYjk1MjRkNGQ1ZTIwNjA4ZWI4MjMyZWNmMyxQMVFpanA2SA%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F639600728973934592%2F60-percent-of-us-companies-are-under-stress&amp;m=0&amp;ts=1610156618">Boston Consulting Group (BCG)</a></b></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/624363186289852416/new-normal-for-tech-webinar">Shaping the new normal for tech post COVID-19 (webinar)</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/covid19">covid19</a>
                                    
                                        <a href="https://nuadox.com/tagged/economy">economy</a>
                                    
                                        <a href="https://nuadox.com/tagged/usa">usa</a>
                                    
                                        <a href="https://nuadox.com/tagged/coronavirus">coronavirus</a>
                                    
                                        <a href="https://nuadox.com/tagged/pandemic">pandemic</a>
                                    
                                        <a href="https://nuadox.com/tagged/featured">featured</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/639600728973934592/60-percent-of-us-companies-are-under-stress</link>
            <guid isPermaLink="false">hacker-news-small-sites-25663393</guid>
            <pubDate>Wed, 06 Jan 2021 22:17:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Germany to order large companies to include women on executive boards]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25662984">thread link</a>) | @vinni2
<br/>
January 6, 2021 | https://www.thelocal.de/20210106/germany-to-require-large-companies-to-include-women-on-boards-cabinet | <a href="https://web.archive.org/web/*/https://www.thelocal.de/20210106/germany-to-require-large-companies-to-include-women-on-boards-cabinet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.thelocal.de/20210106/germany-to-require-large-companies-to-include-women-on-boards-cabinet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25662984</guid>
            <pubDate>Wed, 06 Jan 2021 21:43:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Experimental Semantic Code Explorer]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25662628">thread link</a>) | @paulshen
<br/>
January 6, 2021 | https://artifacts.bypaulshen.com/code-explorer/02/ | <a href="https://web.archive.org/web/*/https://artifacts.bypaulshen.com/code-explorer/02/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://artifacts.bypaulshen.com/code-explorer/02/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25662628</guid>
            <pubDate>Wed, 06 Jan 2021 21:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging Lisp (2015)]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25661701">thread link</a>) | @wooby
<br/>
January 6, 2021 | https://malisper.me/category/debugging-common-lisp/ | <a href="https://web.archive.org/web/*/https://malisper.me/category/debugging-common-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	
	<div id="content">


	<section id="primary">
		<main id="main" role="main">

		
			<!-- .page-header -->

			
				
					
<article id="post-403">
	<!-- .entry-header -->
			<p><em>This post is for all of the miscellaneous features that arent large enough to get their own individual posts. If you havent read all of them, here are the links to the previous posts on </em><em><a href="https://malisper.me/debugging-lisp-part-1-recompilation/">recompilation</a>, <a href="https://malisper.me/debugging-lisp-part-2-inspecting/">inspection</a>, <a href="https://malisper.me/debugging-lisp-part-3-redefining-classes/">class </a></em>… <a href="https://malisper.me/debugging-lisp-part-5-miscellaneous/">Read the rest </a></p><!-- .entry-content -->
				<!-- .entry-meta -->
	</article><!-- #post-## -->

				
					
<article id="post-397">
	<!-- .entry-header -->
			<div>
			<p><em>This is part four of Debugging Lisp. Here are the previous parts on <a href="https://malisper.me/debugging-lisp-part-1-recompilation/">recompilation</a>, <a href="https://malisper.me/debugging-lisp-part-2-inspecting/">inspecting</a>, and <a href="https://malisper.me/debugging-lisp-part-3-redefining-classes/">class redefinition</a>. The next post on <a href="https://malisper.me/debugging-lisp-part-5-miscellaneous/">miscellaneous debugging techniques can be found here</a>.</em></p>
<p>Many languages provide error handling as two … <a href="https://malisper.me/debugging-lisp-part-4-restarts/">Read the rest </a></p>					</div><!-- .entry-content -->
				<!-- .entry-meta -->
	</article><!-- #post-## -->

				
					
<article id="post-372">
	<!-- .entry-header -->
			<div>
			<p><em>This is part 3 of Debugging Common Lisp</em>. If you havent read either of the previous parts, you can find part 1 <a href="https://malisper.me/debugging-lisp-part-1-recompilation/">recompilation, here</a>, and part 2 <a href="https://malisper.me/debugging-lisp-part-2-inspecting/">inspecting, here</a>. <em>You can find part 4, <a href="https://malisper.me/debugging-lisp-part-4-restarts/">which is on </a></em>… <a href="https://malisper.me/debugging-lisp-part-3-redefining-classes/">Read the rest </a></p>					</div><!-- .entry-content -->
				<!-- .entry-meta -->
	</article><!-- #post-## -->

				
					
<article id="post-330">
	<!-- .entry-header -->
			<div>
			<p><em>This is part 2 of Debugging Lisp. If you haven’t read part 1 on <a href="https://malisper.me/debugging-lisp-part-1-recompilation/">dynamic recompilation, you can find it here</a>. For the next post in the series on <a href="https://malisper.me/debugging-lisp-part-3-redefining-classes/">redefining classes, click here</a>.</em></p>
<p>In this post I am … <a href="https://malisper.me/debugging-lisp-part-2-inspecting/">Read the rest </a></p>					</div><!-- .entry-content -->
				<!-- .entry-meta -->
	</article><!-- #post-## -->

				
					
<article id="post-319">
	<!-- .entry-header -->
			<p><em>This post is the start of a series on how to debug Common Lisp code, specifically with Emacs, Slime, and SBCL. If you do not understand Common Lisp, you should still be able to follow along and recognize just how </em>… <a href="https://malisper.me/debugging-lisp-part-1-recompilation/">Read the rest </a></p><!-- .entry-content -->
				<!-- .entry-meta -->
	</article><!-- #post-## -->

				
			
		
		</main><!-- #main -->
	</section><!-- #primary -->


	</div><!-- #content -->

	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://malisper.me/category/debugging-common-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25661701</guid>
            <pubDate>Wed, 06 Jan 2021 20:11:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A constructive look at the Atari 2600 BASIC cartridge]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25661077">thread link</a>) | @reaperducer
<br/>
January 6, 2021 | http://boston.conman.org/2015/06/16.1 | <a href="https://web.archive.org/web/*/http://boston.conman.org/2015/06/16.1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<!-- google_ad_section_start --> <!-- Hey, it can't hurt! -->
<h2><a name="2015-06-16" href="http://boston.conman.org/2015/06/16">Tuesday, June 16, 2015</a></h2>

<h3><a rel="bookmark" name="2015-06-16.1" href="http://boston.conman.org/2015/06/16.1">A constructive look at the Atari 2600 BASIC cartridge</a></h3>

<!-- Atari 2600 VCS, Atari 2600 BASIC, BASIC, IDE, integrated development system -->

<p>I installed <a href="http://stella.sourceforge.net/">Stella</a>
(an <a href="http://www.atariage.com/2600/">Atari 2600 VCS emulator</a>),
downloaded the <a href="http://atariage.com/software_page.html?SoftwareLabelID=15">Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> cartridge</a>
and have been playing around with it for the past few days.
If I'm going to do some <a href="http://boston.conman.org/2015/06/14.1">Stupid Twitter Trick™</a> with it,
I might as well know how it works,
right?</p>

<p>And thus,
this review.</p>

<p>Honestly,
I don't think the Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> has ever had a fair review.
It's pretty much reviled as a horrible program,
a horrible programming environment
and practically useless.
But I think that's selling it short.
Yes,
it's bad (and I'll get to that in a bit),
but in using it for the past few days,
there are some impressive features on a system where the <acronym title="Random Access Memory">RAM</acronym> can't hold a full Tweet and half the <acronym title="Central Processing Unit">CPU</acronym> time is spent 
<a href="https://www.amazon.com/exec/obidos/ASIN/026201257X/conmanlaborat-20">Racing The Beam</a>.
I'll get the bad out of the way first.</p>

<p>Input comes from the <a href="http://atariage.com/controller_page.html?ControllerID=4&amp;SystemID=2600">Atari Keypads</a>,
dual 12-button keypads.
If that weren't bad enough,
<em>I'm</em> using my keyboard as an emulated pair of Atari Keypads,
where I have to keep <a href="http://boston.conman.org/2015/06/16/AtariKeypad.jpg" type="image/jpeg">this image</a> open at all times.</p>

<p>Okay,
here's how this works.
I want to enter this line:</p>

<blockquote>
<pre>A←A+1
</pre>
</blockquote>

<p>(Ah yes!
The “left arrow” for assignment.
Mathematicians rejoice!) 
Upon startup,
the Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> cursor is white.
This is important,
because this tells you what mode you are in.
Hit a key when the cursor is white,
and you do the functions labeled in white above each key.
To get an “A,” you hit the bottom center button on the left controller
(the one with the arrow circling around it) until the cursor turns <em>blue</em>,
then you can hit the upper left key on the left controller (labeled “STATUS + A IF”).
It's a bit hard to see,
but yes, that “A” is indeed blue.</p>

<p>To get the “←” symbol 
(it's the top right button on the left controller)
you hit the bottom middle button the the left controller until the cursor cycles back to red,
then hit the upper right button on the left controller.
Then cycle the cursor back to blue to get the “A,”
then cycle to red to get the “plus” and the “1” 
(top left button on the right controller).</p>

<p>That's probably bad enough on the real thing.
On the <em>simulated Atarti 2600?</em>
Okay,
what key on my keyboard is the “cycle” key?
Then what key is the “A” key?
Here's what I have to type to get that line of code:</p>

<blockquote>
<pre>xx1xxx3x1xxx19
</pre>
</blockquote>

<p>But to be honest,
it's on par with other <a href="http://www.ganjatron.net/retrocomputing/zx81/zx81-kbd.jpg" type="image/jpeg">keyboards of the time</a> and may be a bit better,
having actual tactile feedback instead of a simple membrane.
I'm also <a href="http://boston.conman.org/2000/02/15.1">picky about keyboards</a> so I'm <em>always</em> going to bitch about the keyboard unless it's an 
<a href="http://arstechnica.com/gadgets/2013/11/why-i-use-a-20-year-old-ibm-model-m-keyboard/">IBM model M</a>.</p>

<p>And given that the Atari 2600 only has 128 <em>bytes</em> of memory,
it's expected that the programs are going to be rather short.
I at first thought that you had 64 bytes for the program,
but no—it's 64 bytes for the program, <em>variables and runtime expression evaluation!</em>
That actually surprised me.
Even worse,
running this program over and over again (spaces added for clarity):</p>

<blockquote>
<pre>1 A ← 1
2 B ← 2
3 PRINT A,B
</pre>
</blockquote>

<p><em>leaks memory!</em></p>

<p>No,
really,
that program,
if run multiple times,
will eventually exhaust all of memory.
But not all programs leak memory.
This program,
if run over and over again (more on this little program in a bit):</p>

<blockquote>
<pre>1 D ← 1
2 HOR1 ← HOR1 + D
3 IF HOR1 =  0 THEN GOTO 5
4 IF HOR1 ← 99 THEN GOTO 2
5 D ← 99 - D + 1
6 GOTO 2
</pre>
</blockquote>

<p>won't leak so much as a byte.
Go figure.</p>

<p>Worse though,
is that each variabled used in the program
(and it doesn't matter if it's a predefined variable like <code>HOR1</code> or a user defined variable like <code>A</code>)
consumes <em>three bytes</em> out of the precious 64 bytes you get for your program!
On the plus side though,
unused variables (event the builtin ones) don't use space at all
(I figured this out by watching the <acronym title="Random Access Memory">RAM</acronym> use in Stella).</p>

<p>The grahics are pretty pathetic as well.
There are two dots that can be manipulated.
The builtin variables <code>HOR1</code> and <code>VER1</code> control the horizontal and vertical position for one dot;
<code>HOR2</code> and <code>VER2</code> are used for the other dot.
The colors are fixed.
Oh,
and if the builtin variable <code>HIT</code> is 1,
the two dots are in the same position.</p>

<p>The positions are themselves limited to 0 to 99,
but that's because <em>all</em> variables are limited to the range 0 to 99.
The values wrap though—add 1 to 99 and you get 0.
Subtract 1 from 0 and you get 99.</p>

<p>Which leads us into the ugly.</p>

<p>Yes,
there are no negative values—everything is unsigned.
And the values are all limited from 0 to 99.
This stems from a unique feature of the Atari 2600 <acronym title="Central Processing Unit">CPU</acronym>,
<a href="https://en.wikipedia.org/wiki/MOS_Technology_6507">the 6507</a>
(a cheaper variation on the <a href="https://en.wikipedia.org/wiki/MOS_Technology_6502">6502</a>).
That <acronym title="Central Processing Unit">CPU</acronym> can do math in either binary <em>or</em> <a href="https://en.wikipedia.org/wiki/Binary-coded_decimal">binary-coded decimal</a>
and the Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> uses the binary-coded decimal mode, which restricts the values from 0 to 99.
So while you don't have negative numbers,
you do in a way because of the way <a href="https://en.wikipedia.org/wiki/Modular_arithmetic">the math works</a>.
99 plus 99 is 198,
but because the range is modulus 100,
the result is 98. 
Add 99 again,
and you end up with 97.  
I use this fact in the above program.
Line 5 negates <code>D</code>—it converts 99 to 1,
or 1 back to 99.
Essentially,
1 to -1 and back again,
causing the dot to slowly crawl back and forth across the screen.</p>

<p>But now we finally arrive at what's good,
or rather,
what's amazing about this program.</p>

<p>First and foremost,
it's an <acronym title="Integrated Development Environment">IDE</acronym>.</p>

<p>Seriously.</p>

<p>Dispite it being only 4,096 bytes,
there's a pretty credible,
windowed(!) integrated development environment in there.
If you look back at the <a href="http://boston.conman.org/2015/06/16/AtariKeypad.jpg" type="image/jpeg">keypad</a>,
you'll notice the first six buttons on the left controller are labeled:</p>

<ol>
<li>STATUS</li>
<li>PROGRAM</li>
<li>STACK</li>
<li>VARIABLES</li>
<li>OUTPUT</li>
<li>GRAPHICS</li>
</ol>

<p>Those are the various “windows” (and technically,
they <em>are</em> windows,
even if they don't overlap but are instead,
stacked vertically on the screen)
and the buttons there toggle the “windows” on and off.</p>

<p>The “STATUS” window 
(you can see it in the screen shot from <a href="http://boston.conman.org/2015/06/14.1">the other day</a>) 
shows memory usage (how many bytes,
called “symbols”) and how fast the program will run
(1, 2, 4, 8, 15, 30 and 60 are the speed values and they reflect how often the interpreter is run—once a second,
twice a second, on up to 60 times a second).
The “PROGRAM” window obviously contains the program
(all nine lines if you have that many—and
the <acronym title="Integrated Development Environment">IDE</acronym> automatically numbers the lines for you even though it doesn't use them or store them—more on that below).</p>

<p>The “VARIABLES” window contains a list of the variables used in the program, listed as:</p>

<blockquote>
<pre>A is 1
HOR1 is 40
B is 2
</pre>
</blockquote>

<p>“OUTPUT” is the text output window;
output of <code>PRINT</code>.  “GRAPHICS” is the laughable graphics screen.</p>

<p>Leaving the “STACK” window,
which is a misnomer actually.
It's not a true stack,
since there is no concept of “subroutine” in the Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym>.
You could think of it as “<a href="https://en.wikipedia.org/wiki/TRON_command">TRON</a>” as it actually shows you the execution of each statment that is abolutely amazing!
Imagine each line below being shown one at a time and you'll get a feeling for how this works.
We'll be following line 5 from the above program (assuming D is 1):</p>

<blockquote>
<pre>D
D←
D←99
D←99-D
D←99-1
D←98
D←98+1
D←99
</pre>
</blockquote>

<p>One more example,
to show that the Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> also follows mathematical precedence.
Here, A is 1, B is 2 and C is 3.
The line of code we're following is:</p>

<blockquote>
<pre>D←A+B*C
</pre>
</blockquote>

<p>and during execution:</p>

<blockquote>
<pre>D
D←
D←A
D←1
D←1+B
D←1+2
D←1+2*C
D←1+2*3
D←1+6
D←7
</pre>
</blockquote>

<p>Strange as it sounds,
this blew me away.
I don't think I've ever seen anything like this.
Sure,
in debuggers where you execute a line at a time.
Or in assembly language,
instruction by instruction.
But never substeps in expression evaluation.
And of course,
you can always step through the code with the “STEP” button.
I just find it amazing that all of this,
as simple as it is,
can fit in 4,096 bytes of code.</p>

<p>How it stores the code internally is interesting.
Most <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym>s I'm aware of store the line number as part of the program,
but here,
that's not done.
Take this program for example:</p>

<blockquote>
<pre>1 A ← 1
2 HOR1 ← HOR1 + 1
3 A ← A + 5
4 GOTO 2
</pre>
</blockquote>

<p>Internally in memory,
it's stored:</p>

<table>
  <caption>Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> program layout</caption>
  <thead>
    <tr><th>Byte</th><th>Symbol</th></tr>
  </thead>
  <tbody>
    <tr><td>BC</td><td>A</td></tr>
    <tr><td>E8</td><td>←</td></tr>
    <tr><td>01</td><td>1</td></tr>
    <tr><td>F1</td><td>&lt;end of line&gt;</td></tr>
    <tr><td>B2</td><td>HOR1</td></tr>
    <tr><td>E8</td><td>←</td></tr>
    <tr><td>B2</td><td>HOR1</td></tr>
    <tr><td>E3</td><td>+</td></tr>
    <tr><td>01</td><td>1</td></tr>
    <tr><td>F1</td><td>&lt;end of line&gt;</td></tr>
    <tr><td>BC</td><td>A</td></tr>
    <tr><td>E8</td><td>←</td></tr>
    <tr><td>BC</td><td>A</td></tr>
    <tr><td>E3</td><td>+</td></tr>
    <tr><td>05</td><td>5</td></tr>
    <tr><td>F1</td><td>&lt;end of line&gt;</td></tr>
    <tr><td>A6</td><td>GOTO</td></tr>
    <tr><td>02</td><td>2</td></tr>
    <tr><td>FF</td><td>&lt;end of program&gt;</td></tr>
  </tbody>
</table>

<p>Not a line number in sight,
which means <code>GOTO</code> statements do a linear scan of the program
(a typical design choice of <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> systems on 8-bit computers at the time)
but the end of each line <em>is</em> marked.
Weird,
but whatever works I guess.</p>

<p>Variables are stored after the program, sequentially:</p>

<table>
  <caption>Atari 2600 <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> variable layout</caption>
  <thead>
    <tr><th>Byte</th><th>Symbol</th></tr>
  </thead>
  <tbody>
    <tr><td>B2</td><td>HOR1</td></tr>
    <tr><td>EE</td><td>is (see below)</td></tr>
    <tr><td>02</td><td>current value</td></tr>
    <tr><td>BC</td><td>A</td></tr>
    <tr><td>EE</td><td>is</td></tr>
    <tr><td>15</td><td>current value</td></tr>
  </tbody>
</table>

<p>As best as I can tell,
the value <code>EE</code> is used when displaying the variables on the “VARIABLES” window,
and probably means “is.”  It's probably done that way to avoid a special case when displaying data—it can be treated the same when displaying the program.
I'm guessing there's not much space left what with the font data and code to support the <acronym title="Integrated Development Environment">IDE</acronym> in addition to running a
(admittedly very simple) <acronym title="Beginners All-purpose Symbolic Instruction Code">BASIC</acronym> interpreter for special casing the variables.</p>

<p>As a “proof-of-concept” it's an amzing piece of work.
As an actual product,
yes,
it <em>sucks</em>,
mostly because of the limitations of the hardware.
The ideas behind it are incredible though,
and I think it's gotten short shrifted because of the limitations,
which is sad.
There is something to learn from here.</p>

<div>

<h4>Update Wednesday, June 17<sup>th</sup>, 2015 at 1:56 AM</h4>

<p>I almost forgot—the <code>IF</code> statement is an expression!
You can do the following:</p>

<blockquote>
<pre>A ← IF B = 15 THEN 40 ELSE 99
</pre>
</blockquote>

<p>and <code>A</code> will be 40 if <code>B</code> is 15,
otherwise <code>A</code> will be 99.
There aren't many languages I've used that have allowed this.</p>

</div>



<!-- google_ad_section_end -->
</div></div>]]>
            </description>
            <link>http://boston.conman.org/2015/06/16.1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25661077</guid>
            <pubDate>Wed, 06 Jan 2021 19:14:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deleting Facebook permanently]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 215 (<a href="https://news.ycombinator.com/item?id=25659480">thread link</a>) | @joshmanders
<br/>
January 6, 2021 | https://blog.spacehey.com/entry?id=4054 | <a href="https://web.archive.org/web/*/https://blog.spacehey.com/entry?id=4054">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><span><i>I have made this initially as a bulletin but they are only 10 days in length before being removed, so reposting here for posterity.</i></span></p><p><span><i>Original bulletin:</i></span></p><div><p><span>Facebook, Inc is a garbage creepy company. I do not like their business practices at all. That's not even counting the cesspool of a user base they're cultivating on the platform.</span></p><p><span>Because of those reasons I have decided after over a decade on Facebook with ~1500 friends. I am deleting it permanently come February 1st in favor of SpaceHey becoming my new non-business social network.</span></p><p><span>I encourage you all to make a post on your feed directing your friends and family to sign up to SpaceHey and friend you here too, then delete your account after a grace period.</span></p><p><span>Lets make Facebook as scared of SpaceHey as MySpace was at the rise of Facebook.</span></p></div>
    </div></div>]]>
            </description>
            <link>https://blog.spacehey.com/entry?id=4054</link>
            <guid isPermaLink="false">hacker-news-small-sites-25659480</guid>
            <pubDate>Wed, 06 Jan 2021 16:54:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decoding the Peloton]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25658490">thread link</a>) | @_ihaque
<br/>
January 6, 2021 | https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/ | <a href="https://web.archive.org/web/*/https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><strong><span>TL</span>;<span>DR</span></strong> - I’ve decoded (most of) the protocol that the Peloton bike uses to
communicate with its head unit tablet and built a device, the PeloMon, that takes that
data during a ride, without interfering with the Peloton software, to
broadcast it over Bluetooth <span>LE</span> to whatever devices you’d like — a watch, Zwift,
Wahoo, whatever. Stick around for logic analyzer traces, hardware diagrams,
cursing at Bluetooth, and some nice&nbsp;interfaces.</p>
<p>First in a series. See the <a href="https://github.com/ihaque/pelomon">project GitHub</a>, to be updated through the&nbsp;series.</p>
<ul>
<li><a href="https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">Part I: Decoding the&nbsp;Peloton</a></li>
<li><a href="https://ihaque.org/posts/2020/12/25/pelomon-part-ib-computing-speed">Part Ib: How does the Peloton compute&nbsp;speed?</a></li>
<li><a href="https://ihaque.org/posts/2020/12/26/pelomon-part-ii-emulating-peloton">Part <span>II</span>: Emulating the&nbsp;Peloton</a></li>
<li><a href="https://ihaque.org/posts/2020/12/28/pelomon-part-iii-hardware">Part <span>III</span>: PeloMon&nbsp;Hardware</a></li>
<li><a href="https://ihaque.org/posts/2021/01/04/pelomon-part-iv-software">Part <span>IV</span>: PeloMon&nbsp;Software</a></li>
</ul>
<h2 id="table-of-contents"><a href="#table-of-contents">Table of&nbsp;Contents</a></h2>
<ul>
<li><strong><a href="#intro-to-the-pelomon-project">Intro</a></strong></li>
<li><strong><a href="#the-physical-layer-how-does-the-bike-talk-to-the-tablet">Physical Layer</a></strong> (<a href="#hardware-used">Hardware Used</a>, <a href="#mapping-the-available-signals">Mapping Signals</a>, <a href="#decoding-the-wire-protocol-with-a-logic-analyzer">Wire Protocol</a>)</li>
<li><strong><a href="#data-encoding-what-are-the-head-unit-and-bike-saying-to-each-other">Data Encoding</a></strong> (<a href="#basic-packet-structure">Packet Structure</a>, <a href="#decoding-cadence-rpm-power-and-almost-resistance">Cadence and Power</a>, <a href="#a-detour-what-happens-when-you-boot-up-the-bike">Boot Sequence</a>, <a href="#decoding-resistance-for-real-this-time">Resistance</a>)</li>
<li><strong><a href="#conclusion">Conclusion</a></strong> (<a href="#pinouts">Pinouts</a>, <a href="#protocol-description">Protocol Description</a>, <a href="#open-questions">Open Questions</a>)</li>
</ul>

<p>We have a Peloton at home. Originally, I was skeptical, but then I found
trainers I like and it’s fun to ride with friends. And really takes the edge
off all-day Zoom meetings to ride during a meeting with the camera turned&nbsp;off.</p>
<p>But, being the guy that I am, I’ve been curious about how the head unit —
which runs a lightly skinned Android — was collecting stats
from the actual bike. I was also a bit annoyed that though the Peloton software
will happily read data from an <span>HR</span> sensor, and will upload your ride data to
Strava, there was no way for it to <em>broadcast</em> data about a ride to a local
fitness appliance — which meant that although I could track the fact that I
was doing an “indoor bike” ride on my Garmin watch, the watch would see a 0
mile ride because it got no bike&nbsp;data.</p>
<p>Then a couple months ago, I came across
<a href="https://ptx2.net/posts/unbricking-a-bike-with-a-raspberry-pi/">this blog post</a>
in which someone on the Internet was able to hook up their (bricked) Flywheel
bike to Zwift using a Raspberry Pi to decode the bike sensor data and broadcast
it over Bluetooth — and I was inspired to finally give this project a shot.
What should we call a device broadcasting stats from the Peloton, monitoring it
if you will? How about&nbsp;“PeloMon”?</p>
<p>Let’s get down to&nbsp;it.</p>

<h2 id="hardware-used"><a href="#hardware-used">Hardware&nbsp;used</a></h2>
<p>Any physical layer work is going to require actual hardware!
I’ll provide links to all of the hardware involved in
the project in case you’d like to follow along. I bought from a mix of Amazon
and Adafruit; note that the Amazon links are affiliate links so if you end
up buying there I’ll get a small referral&nbsp;bonus.</p>
<table>
<tbody><tr><th>Part name</th><th>Links</th><th>Price at time of writing</th></tr>
<tr><td><span>TRRS</span> breakout board</td>
    <td><a href="https://amzn.to/3dsGuYt">Amazon</a></td>
    <td>$6.98 (qty 3)</td></tr>
<tr><td><span>USB</span> logic analyzer 24MHz 8ch</td>
    <td><a href="https://amzn.to/319svlj">Amazon</a></td>
    <td>$12.49</td></tr>
<tr><td>6” stereo headphone splitter cable</td>
    <td><a href="https://amzn.to/341FG9D">Amazon</a></td>
    <td>$4.91</td></tr>
<tr><td>3ft aux cable</td>
    <td><a href="https://amzn.to/2IzVhFi">Amazon</a></td>
    <td>$3.99</td></tr>
<tr><td>2.1mm <span>DC</span> barrel jack splitter</td>
    <td><a href="https://www.adafruit.com/product/1351">Adafruit</a></td>
    <td>$2.95</td></tr>

</tbody></table>

<h2 id="mapping-the-available-signals"><a href="#mapping-the-available-signals">Mapping the available&nbsp;signals</a></h2>
<p>There are only two cables that plug into the tablet: a barrel jack carrying
<span>DC</span> power @ 12V (coming from the power brick), and a <span>TRRS</span> connector —
think “stereo aux cable”. So the data is clearly coming in on the latter.
Since I only wanted to observe the traffic between the <span>HU</span> and the bike,
not interrupt it, I used a headphone splitter cable to split the cable from the bike with an extra jack, and connected an aux cable from that extra jack
to the breakout. Such a connection might disrupt some high-speed communications
protocols, but my guess was that a) there wasn’t going to be that much traffic
to require anything fancy, b) nothing fast would be running over 3.5mm <span>TRRS</span>, and
c) this interface would be engineered with pretty wide tolerances for stability 
in a home environment. (Spoiler alert: all of these were&nbsp;true.)</p>
<p>The first step was to identify the pinout from the jack as best
as possible. Probing the leads with a <span>DMM</span> with the bike active showed that
Ring2 was at ground (0V with respect to the power supply’s ground)
with -5.5-6V between tip or ring1 and ground. Sleeve also appears to be
at ground, but it and Ring2 may not quite be the same (more on this later).
The negative voltages with respect
to ground are a pretty strong sign that we’re going to see <span>RS</span>-232&nbsp;signaling.</p>
<h2 id="decoding-the-wire-protocol-with-a-logic-analyzer"><a href="#decoding-the-wire-protocol-with-a-logic-analyzer">Decoding the wire protocol with a logic&nbsp;analyzer</a></h2>
<p>(If you’d like to load a PulseView trace to see the data for yourself, one session
file from a test ride is located in <code>peloton_decoding/resistance-stepped-10s.sr</code>
in <a href="https://github.com/ihaque/pelomon">the PeloMon GitHub repository</a>.)</p>
<p>Normally I’d wire up the breakout and hack something together on the Arduino
I have sitting around, but it turns out that logic analyzers have gotten
<em>really really cheap</em> so I splurged on a $12.50 one and thought I’d give it
a whirl — turned out to be a great idea that made it <span>WAY</span> easier to decode
the signals. With complete abandon regarding ground isolation and the voltage
tolerances of the <span>LA</span> (is it supposed to be able to handle negative voltage?),
I hooked it up to see what I’d get. These cheapo LAs emulate a Saleae Logic
analyzer and work fine in the open-source <a href="https://sigrok.org/wiki/PulseView">PulseView</a>&nbsp;software.</p>
<p><img alt="Hooking up the LA with D0 on tip, D4 on ring1, D5 on sleeve, and GND on ring2" src="https://ihaque.org/static/img/2020/10/20201015-pinout-0tip-4ring1-5sleeve-gndring2.png">
</p><center><strong>Hooking up the <span>LA</span> with D0 on tip, D4 on ring1, D5 on sleeve, and <span>GND</span> on ring2</strong></center>
<p><img alt="D0 on tip, D2 on ring1, D4 on ring2, and GND on sleeve" src="https://ihaque.org/static/img/2020/10/20201015-pinout-0tip-2ring1-4ring2-gndsleeve.png">
</p><center><strong>D0 on tip, D2 on ring1, D4 on ring2, and <span>GND</span> on sleeve</strong></center>
<p>There’s pretty clearly serial signaling going on over these wires! One
party seems to be sending requests on Tip every 100ms, and the other
party responds about a millisecond later on Ring1. While it wasn’t obvious
from the <span>DMM</span> whether signaling <span>GND</span> should be on Ring2 or Sleeve, from the <span>LA</span>
traces, it looks like there is less glitching on the response line if Ring2 is
used as <span>GND</span> - so we’ll do that. The narrow pulses are probably single bits,
so sampling at a high rate (a few hundred kHz) lets us measure the bit
rate as&nbsp;19200bps:</p>
<p><img alt="Counting samples in the LA shows a 19.2kHz signal" src="https://ihaque.org/static/img/2020/10/20201015-pinout-19200bps.png">
</p><center><strong>Counting samples in the <span>LA</span> shows a 19.2kHz signal</strong></center>
<p>PulseView also lets you add protocol decoders to particular wires. I put a <span>UART</span>
decoder on with D0 as “<span>RX</span>” and D4 as “<span>TX</span>”, and saw data, but with a ton of
low-level serial protocol errors. UARTs invert the signal going out on the wire
with the expectation that there will be another <span>UART</span> at the other end to
re-invert. Since we don’t have that second <span>UART</span>, we have to turn the “Invert <span>RX</span>”
and “Invert <span>TX</span>” options on in PulseView, and then we see clean data! I also
experimented with other serial options (data, parity, and stop bits), but the
first guess of 8N1 turned out&nbsp;correct.</p>
<p><img alt="Without inversion enabled, we see framing errors and break conditions" src="https://ihaque.org/static/img/2020/10/20201015-missing-inversion.png">
</p><center><strong>Without inversion enabled, we see framing errors and break conditions</strong></center>
<p><img alt="Turning on the inversion in software, we see data with no serial errors!" src="https://ihaque.org/static/img/2020/10/20201015-fixed-inversion.png">
</p><center><strong>Turning on the inversion in software, we see data with no serial errors!</strong></center>
<p>Following the data streams, we see that the data stream on the
Tip wire during a ride always consists of one of three different four-byte
packets, repeated round-robin every 100ms, with the responses on Ring1 to these
requests being longer, different in length depending on the request type, and
variable in content.
It seems likely then that the Tip shows us signaling from the head unit to the
bike, and Ring1 is the bike responding to the head unit with information
about variables like current speed, resistance, or power&nbsp;output.</p>
<p><strong>Thus, we’ve worked out the physical layer protocol for the Peloton
communications: <span>RS</span>-232 at 5.5V and 19200bps 8N1 encoding, with <span>HU</span>-to-bike
communications on Tip, bike-to-<span>HU</span> on Ring1, <span>GND</span> on Ring2, and something
ground-like on&nbsp;Sleeve.</strong></p>

<p>To investigate the encoding between the head unit and the bike, I used the
logic analyzer to capture a trace of the communications during a ride. (Shoutout
to Ben Alldis and his Ministry of Sound ride series!)
The data dump and scripts are available in the GitHub repository for this project
at https://github.com/ihaque/pelomon/, in the <code>peloton_decoding</code> subdirectory.)</p>
<h2 id="basic-packet-structure"><a href="#basic-packet-structure">Basic packet&nbsp;structure</a></h2>
<p>(To follow along, run <code>peloton_decoding/decoder_plots.py</code> from the
<a href="https://github.com/ihaque/pelomon">PeloMon Github repository</a>.)</p>
<p>During a ride, about every 100ms (100.66-100.8ms) the <span>HU</span> sends a request
to the bike, and the bike responds about 300us (i.e., 0.3ms) from the end
of the <span>HU</span>’s request. The <span>HU</span> sends three different request packets round robin.
Each request type has a different response length from the&nbsp;bike:</p>
<table> 
<tbody><tr><th><span>HU</span> Request</th><th>Bike Response Length</th><th>Example Bike Response</th></tr>
<tr><td><tt>F5 41 36 F6</tt></td><td>8 bytes</td><td><tt>F1 41 03 30 30 30 C5 F6</tt></td></tr>
<tr><td><tt>F5 44 39 F6</tt></td><td>10 bytes</td><td><tt>F1 44 05 30 30 30 30 30 2A F6</tt></td></tr>
<tr><td><tt>F5 4A 3F F6</tt></td><td>9 bytes</td><td><tt>F1 4A 04 38 36 36 30 13 F6</tt></td></tr>
</tbody></table>

<p>A few things are evident from simple inspection of the&nbsp;bytes:</p>
<ul>
<li>The first byte is a header - seems to be F5 from the <span>HU</span> and F1 from the&nbsp;bike.</li>
<li>All packets end in&nbsp;F6.</li>
<li>The second byte that the <span>HU</span> sends seems to be a request type, and is mirrored in the second byte in the bike’s&nbsp;response.</li>
<li>The third byte of the bike response is the length of the full packet minus 5 — probably indicates the length of the data payload following&nbsp;it.</li>
<li>Serial packets often carry a checksum, and here the second-to-last byte from either the <span>HU</span> or the bike seems to be that: it’s the sum (modulo 256) of all the bytes preceding&nbsp;it.</li>
</ul>
<p>Thus, the packet format seems to&nbsp;be:</p>
<ul>
<li><span>HU</span>: <code>F5 [request type] [checksum] F6</code></li>
<li>Bike: <code>F1 [request type] [payload length] [response bytes 1-n] [checksum] F6</code></li>
</ul>
<p>We can now throw together a quick plot of each response byte to look for&nbsp;patterns.</p>
<p><img alt="Bytewise plot of Peloton response data for common request packets during part of a ride" src="https://ihaque.org/static/img/2020/10/20201015-peloton-bytewise.png">
</p><center><strong>Bytewise plot of Peloton response data for common request packets during part of a ride</strong></center>
<p>It appears that every byte ranges from 0x30 to 0x39 — which is exactly the
<span>ASCII</span> range for decimal digits 0 through 9. Furthermore, the earlier bytes in
each packet appear to vary more quickly than the later ones through a ride,
suggesting that the least-significant digit comes first. <strong>The Peloton bike
is encoding its responses as little-endian <span>ASCII</span> digits.</strong> It’s easy enough
to dump a plot of these values per response type now that we know the&nbsp;encoding:</p>
<p><img alt="Decoded values sent by bike to head unit during a ride" src="https://ihaque.org/static/img/2020/10/20201015-peloton-ascii.png">
</p><center><strong>Decoded values sent by bike to head unit during a ride</strong></center>
<h2 id="decoding-cadence-rpm-power-and-almost-resistance"><a href="#decoding-cadence-rpm-power-and-almost-resistance">Decoding cadence (<span>RPM</span>), power, and (almost)&nbsp;resistance</a></h2>
<p>(To follow along, run <code>peloton_decoding/decode_resistance.py</code> from the
<a href="https://github.com/ihaque/pelomon">PeloMon Github repository</a>.)</p>
<p>Glancing at these graphs it’s pretty clear that we have ride data of the Peloton
trifecta — cadence, power, and resistance — with a couple weird things thrown in
for flavor. Comparing to the Peloton ride stats, <strong>request type 0x41 seems to directly
return cadence in rpm and request type 0x44 returns 10 times power in watts (i.e.,
current power output in deciwatts)</strong>. However, while the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/</a></em></p>]]>
            </description>
            <link>https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25658490</guid>
            <pubDate>Wed, 06 Jan 2021 15:23:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I’ve Learned in 45 Years in the Software Industry]]>
            </title>
            <description>
<![CDATA[
Score 1014 | Comments 304 (<a href="https://news.ycombinator.com/item?id=25658216">thread link</a>) | @FauxDemure
<br/>
January 6, 2021 | https://www.bti360.com/what-ive-learned-in-45-years-in-the-software-industry/ | <a href="https://web.archive.org/web/*/https://www.bti360.com/what-ive-learned-in-45-years-in-the-software-industry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>BTI360 teammate Joel Goldberg recently retired after working in the software industry for over four decades. When he left he shared with our team some of the lessons he learned over his career. With his permission, we reshare his wisdom here.</h2><hr><p><a href="http://www.bti360.com/wp-content/uploads/2021/01/goldberg-early.png"><img data-attachment-id="4299" data-permalink="https://www.bti360.com/?attachment_id=4299" data-orig-file="https://www.bti360.com/wp-content/uploads/2021/01/goldberg-early.png" data-orig-size="235,341" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="goldberg-early" data-image-description="" data-medium-file="https://www.bti360.com/wp-content/uploads/2021/01/goldberg-early.png" data-large-file="https://www.bti360.com/wp-content/uploads/2021/01/goldberg-early.png" loading="lazy" src="https://www.bti360.com/wp-content/uploads/2021/01/goldberg-early.png" alt="" width="235" height="341"></a>Looking back on four decades in the software industry, I’m struck by how much has changed. I started my career with punch cards and I am ending in the era of cloud computing. Despite all this change, many principles that have helped me throughout my career haven’t changed and continue to be relevant. As I step away from the keyboard, I want to share six ideas I’ve learned from my career as a software engineer.</p><h2>1. Beware of the Curse of Knowledge</h2><p>When you know something it is almost impossible to imagine what it is like&nbsp;<em>not</em>&nbsp;to know that thing. This is the curse of knowledge, and it is the root of countless misunderstandings and inefficiencies. Smart people who are comfortable with complexity can be especially prone to it!</p><p>If you don’t guard against the curse of knowledge it has the potential to obfuscate all forms of communication, including code. The more specialized your work, the greater the risk that you will communicate in ways that are incomprehensible to the uninitiated. Fight the curse of knowledge. Work to understand your audience. Try to imagine what it would be like to learn what you are communicating for the first time.</p><h2>2. Focus on the Fundamentals</h2><p>Technology constantly changes, but some fundamental approaches to software development transcend these trends. Here are six fundamentals that will continue to be relevant for a long time.</p><ul><li><strong>Teamwork</strong>&nbsp;— Great teams build great software. Don’t take teamwork for granted.</li><li><strong>Trust&nbsp;</strong>— Teams move at the speed of trust. Be the kind of dependable person you would want to work with.</li><li><strong>Communication</strong>&nbsp;— Communicate honestly and proactively. Avoid the curse of knowledge.</li><li><strong>Seek Consensus</strong>&nbsp;— Take the time to bring your whole team along. Let discussion and disagreement bring you to the best solution.</li><li><strong>Automated Testing</strong>&nbsp;—&nbsp; Well-tested code allows your team to move fast with confidence.</li><li><strong>Clean, understandable, and navigable code and design</strong>&nbsp;— Think of the next engineer that will take over your code as your customer.&nbsp; Build code that your successor won’t have any trouble reading, maintaining, and updating.</li></ul><h2>3. Simplicity</h2><p>Fighting complexity is a never-ending cause. Solutions should be as simple as possible. Assume the next person to maintain your code won’t be as smart as you. When you can use fewer technologies, do so.</p><figure><blockquote><p><em>“A designer knows he has achieved perfection not when there is nothing left to add, but when there is nothing left to take away.”</em></p><p><cite><em>Antoine de Saint-Exupery</em></cite></p></blockquote></figure><h2>4. Seek First to Understand</h2><p>One of Stephen Covey’s seven habits is, “Seek First To Understand, Then To Be Understood.” This maxim has helped me more than any other advice to become a good listener and teammate. If you want to influence and work effectively with others, you first need to understand them. Actively listen to understand their feelings, ideas, and point of view before you begin trying to make your own thoughts known.</p><p><a href="http://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237.jpg"><img data-attachment-id="4305" data-permalink="https://www.bti360.com/what-ive-learned-in-45-years-in-the-software-industry/bti360-2019-237-2/" data-orig-file="https://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237.jpg" data-orig-size="600,388" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bti360-2019-237" data-image-description="" data-medium-file="https://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237-400x259.jpg" data-large-file="https://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237.jpg" loading="lazy" src="https://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237.jpg" alt="" width="600" height="388" srcset="https://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237.jpg 600w, https://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237-400x259.jpg 400w, https://www.bti360.com/wp-content/uploads/2021/01/bti360-2019-237-564x365.jpg 564w" sizes="(max-width: 600px) 100vw, 600px"></a></p><h2>5. Beware of Lock-In</h2><p>There will always be the next hot productivity product that will promise to revolutionize how software is built. Computer Assisted Software Engineering (CASE) tools, COTS, Enterprise Resource Planning products like Peoplesoft and SAP and, yes, even Ruby. They claim amazing reductions in cost and time if you buy into their holistic development philosophy. What is not always as obvious is the significant up-front costs or the constraints you may be committing yourself to. Lock-in used to primarily happen with vendors, but now it can happen with frameworks too. Either way, lock-in means significant cost to change. Choose wisely. New is not always better!</p><h2>6. Be Honest and Acknowledge When You Don’t Fit the Role</h2><p>At some point in your career you may find yourself in a role that isn’t a good fit. A bad fit isn’t a character flaw, but it’s a problem you shouldn’t ignore. There may be more than one solution to such a dilemma: you can evolve or the role can evolve. The key is to have the self-knowledge to recognize what is happening and get yourself out of an unhealthy spot. Being unhappy is in no-one’s best interests, and BTI360 recognizes this.</p><p>When I was at GM, you were a failure if your next move was not&nbsp;<em>up</em>—managing more people or taking on bigger, more complex projects. For many, this made for a miserable career path (see the&nbsp;<a href="https://en.wikipedia.org/wiki/Peter_principle">Peter Principle</a>). At EDS, the culture wasn’t like this. People moved in and out of management roles. There was no stigma associated with moving from roles with greater scope, like strategic planner, to roles with more narrow scope, like PM or project-level developer. I was one of the people who took advantage of this flexibility, moving from a role at the top of the technical pyramid back to being a project-level developer. I never looked back.</p><h2>Final Thoughts<img data-attachment-id="4294" data-permalink="https://www.bti360.com/?attachment_id=4294" data-orig-file="https://www.bti360.com/wp-content/uploads/2021/01/Goldberg_Joel_2_circ-230.png" data-orig-size="230,230" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Goldberg_Joel_2_circ-230" data-image-description="" data-medium-file="https://www.bti360.com/wp-content/uploads/2021/01/Goldberg_Joel_2_circ-230.png" data-large-file="https://www.bti360.com/wp-content/uploads/2021/01/Goldberg_Joel_2_circ-230.png" loading="lazy" src="https://www.bti360.com/wp-content/uploads/2021/01/Goldberg_Joel_2_circ-230.png" alt="" width="230" height="230"></h2><p>Even before I joined BTI360 I knew enough about the culture to know that it was a place that valued the kinds of principles I’ve described above. I hope each of you will take ownership of maintaining a strong engineering culture that will continue to make BTI360 a great place to build software.</p><hr><h2><em>In addition to his varied technical experience, Joel worked with a lot of interesting characters over his career, including W. Edwards Deming and Ross Perot. Next week we will share an interview where he tells more about those encounters and other interesting experiences over 4 decades in the tech industry.</em></h2><p><strong>Like What You Hear? Work Here!</strong><br> Are you a software engineer, interested in joining a software company that invests in its teammates and promotes a strong engineering culture? Then you’re in the right place! Check out our current&nbsp;<a href="https://www.bti360.com/careers/#apply-now">Career Opportunities</a>. We’re always looking for like-minded engineers to join the BTI360 family.</p></div></div>]]>
            </description>
            <link>https://www.bti360.com/what-ive-learned-in-45-years-in-the-software-industry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25658216</guid>
            <pubDate>Wed, 06 Jan 2021 14:51:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix shell pipelines have two usage patterns]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25658186">thread link</a>) | @todsacerdoti
<br/>
January 6, 2021 | https://utcc.utoronto.ca/~cks/space/blog/unix/ShellPipesTwoUsages | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/ShellPipesTwoUsages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Unix shell pipelines have two usage patterns</h2>

	<p><small>January  6, 2021</small></p>
</div><div><p>I've seen a variety of recommendations for safer shell scripting
that use Bash and set its 'pipefail' option (for example, <a href="https://vaneyckt.io/posts/safer_bash_scripts_with_set_euxo_pipefail/">this
one from 2015</a>).
This is a good recommendation in one sense, but it exposes a conflict;
this option works great for one usage pattern for pipes, and
potentially terribly for another one.</p>

<p>To understand the problem, let's start with what Bash's pipefail does.
To quote the <a href="https://www.gnu.org/savannah-checkouts/gnu/bash/manual/bash.html">Bash manual</a>:</p>

<blockquote><p>The exit status of a pipeline is the exit status of the last command
in the pipeline, unless the <code>pipefail</code> option is enabled.  If
<code>pipefail</code> is enabled, the pipelineâ€™s return status is the value of
the last (rightmost) command to exit with a non-zero status, or zero
if all commands exit successfully. [...]</p>
</blockquote>

<p>The reason to use <code>pipefail</code> is that if you don't, a command failing
unexpectedly in the middle of a pipeline won't normally be detected
by you, and won't abort your script if you used '<code>set -e</code>'. You can
go out of your way to carefully check everything with <code>$PIPESTATUS</code>,
but that's a lot of extra work.</p>

<p>Unfortunately, this is where <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/BashPipes">our old friend <code>SIGPIPE</code></a> comes into the picture. What <code>SIGPIPE</code> does
in pipelines is force processes to exit if they write to a closed
pipe. This happens if a later process in a pipeline doesn't consume
all of its input, for example if you only want to process the first
thousand lines of output of something:</p>


<blockquote><pre>generate --thing | sed 1000q | gronkulate
</pre>
</blockquote>

<p>The <code>sed</code> exits after a thousand lines and closes the pipe that
<code>generate</code> is writing to, <code>generate</code> gets <code>SIGPIPE</code> and by default
dies, and suddenly its exit status is non-zero, which means that
with <code>pipefail</code> the entire pipeline 'fails' (and with '<code>set -e</code>',
your script will normally exit).</p>

<p>(Under some circumstances, <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/ShellPipelineIndeterminate">what happens can vary from run to run due
to process scheduling</a>. It can also depend
on how much output early processes are producing compared to what later
processes are filtering; if <code>generate</code> produces 1000 lines or less,
<code>sed</code> will consume all of them.)</p>

<p>This leads to two shell pipeline usage patterns. In one usage pattern,
all processes in the pipeline consume their entire input unless
something goes wrong. Since all processes do this, no process should
ever be writing to a closed pipe and <code>SIGPIPE</code> will never happen. In
another usage pattern, at least one process will stop processing its
input early; often such processes are in the pipeline specifically to
stop at some point (as <code>sed</code> is in my example above). These pipelines
will sometimes or always generate <code>SIGPIPE</code>s and have some processes
exiting with non-zero statuses.</p>

<p>Of course, you can deal with this in an environment where you're using
<code>pipefail</code>, even with '<code>set -e</code>'. For instance, you can force one
pipeline step to always exit successfully:</p>

<blockquote><pre>(generate --thing || true) | sed 1000q | gronkulate
</pre>
</blockquote>

<p>However, you have to remember this issue and keep track of what commands
can exit early, without reading all of their input. If you miss some,
your reward is probably errors from your script. If you're lucky,
they'll be regular errors; if you're unlucky, they'll be sporadic errors
that happen when one command produces an unusually large amount of
output or another command does its work unusually soon or fast.</p>

<p>(Also, it would be nice to only ignore <code>SIGPIPE</code> based failures, not
other failures. If <code>generate</code> fails for other reasons, we'd like the
whole pipeline to be seen as having failed.)</p>

<p>My informal sense is that the 'consume everything' pipeline pattern
is far more common than the 'early exit' pipeline pattern, although
I haven't attempted to inventory my scripts. It's certainly the
natural pattern when you're filtering, transforming, and examining
all of something (for example, to count or summarize it).</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/ShellPipesTwoUsages</link>
            <guid isPermaLink="false">hacker-news-small-sites-25658186</guid>
            <pubDate>Wed, 06 Jan 2021 14:47:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Incremental learning of polynomials (and other LIP models) with IRMA]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25657402">thread link</a>) | @MrBusch
<br/>
January 6, 2021 | http://buschermoehle.org/andreas/irma.htm | <a href="https://web.archive.org/web/*/http://buschermoehle.org/andreas/irma.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://buschermoehle.org/andreas/irma.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25657402</guid>
            <pubDate>Wed, 06 Jan 2021 13:10:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating the PIN cracking scene in Terminator 2]]>
            </title>
            <description>
<![CDATA[
Score 412 | Comments 110 (<a href="https://news.ycombinator.com/item?id=25656827">thread link</a>) | @fanf2
<br/>
January 6, 2021 | https://bert.org/2021/01/04/t2-pin-cracking/ | <a href="https://web.archive.org/web/*/https://bert.org/2021/01/04/t2-pin-cracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the beginning of <a href="https://www.imdb.com/title/tt0103064/">Terminator 2: Judgement Day</a>, John Connor uses a laptop to crack the PIN of a stolen debit card.</p>



<p>I don’t think I saw Terminator 2 in the theater. I probably watched it years later on LaserDisc but the scene left quite an impression on me. I had a similar reaction to the war dialer in <a href="https://www.imdb.com/title/tt0086567/">WarGames</a> and the black box in <a href="https://www.imdb.com/title/tt0105435/">Sneakers</a>.</p>

<figure>
    <img src="https://bert.org/assets/posts/pinid/wargames.jpg" alt="War Dialer in WarGames (1983)">
    <figcaption>War Dialer in WarGames (1983)</figcaption>
</figure>

<figure>
    <img src="https://bert.org/assets/posts/pinid/sneakers.jpg" alt="Black Box in Sneakers (1992)">
    <figcaption>Black Box in Sneakers (1992)</figcaption>
</figure>

<p>Anyways, I was thinking about that scene from Terminator 2 recently which led me to googling, “What’s that laptop in Terminator 2?”</p>

<p>It’s an <a href="https://en.wikipedia.org/wiki/Atari_Portfolio">Atari Portfolio</a>, the world’s first palmtop computer. It was released in June 1989.</p>

<p><img src="https://bert.org/assets/posts/pinid/portfolio.png" alt="Atari Portfolio"></p>

<p>It had a monochrome LCD with 240x64 pixels or 40 characters x 8 lines and ran off 3 AA batteries.</p>

<p>The next thing I wondered was, “How difficult would it be to write that program?” Not a program that actually cracks PIN numbers from debit cards, I don’t think you can actually do that with a serial cable and some aluminum foil wrapped around a debit card, but a program that can simulate the output of the palmtop in that scene.</p>

<p>Let’s gather some product requirements!</p>

<p>If we watch the video again, the first thing that happens is that it displays a banner for the program.</p>

<p><img src="https://bert.org/assets/posts/pinid/pinip.jpg" alt="banner"></p>

<p>The image is clear enough that you can copy the banner easily.</p>

<div><div><pre><code>PPPPP   IIIIIII   N    N
P   PP     I      NN   N IDENTIFICATION
P   PP     I      N N  N
PPPPP      I      N  N N   PROGRAM
P          I      N   NN
P       IIIIIII   N    N

Strike a key when ready ...
</code></pre></div></div>

<p>At this point, John hits Enter and the numbers start scrolling. If we look a few frames in:</p>

<p><img src="https://bert.org/assets/posts/pinid/firstline.jpg" alt="first line"></p>

<p>We can see that the first line of numbers is:</p>

<div><div><pre><code>12345678901234567890123457890123456780
</code></pre></div></div>

<p>One might assume that this is just the digits 1 through 0 repeated four times, but upon closer look, it’s only 38 digits long. In the third set, the number 6 is omitted, and the last set, the number 9 is omitted.</p>

<p>The way the numbers decrease isn’t obvious either, but it seems like it prints about 5 lines at a certain length before decreasing the length by 1, but after the next set it decreases the length by 2 and then alternates back and forth until it identifies the 4-digit PIN code and dumps him back to a prompt.</p>

<p>Well, that seems pretty straightforward. I’ve been trying to get better at Python so here’s a script I wrote in Python 3:</p>

<div><div><pre><code><span>#!/usr/bin/env python3
</span><span>import</span> <span>time</span>
<span>import</span> <span>random</span>

<span>delay</span> <span>=</span> <span>0.025</span>

<span>print</span><span>(</span><span>"PPPPP   IIIIIII   N    N"</span><span>)</span>
<span>time</span><span>.</span><span>sleep</span><span>(</span><span>delay</span><span>)</span>
<span>print</span><span>(</span><span>"P   PP     I      NN   N IDENTIFICATION"</span><span>)</span>
<span>time</span><span>.</span><span>sleep</span><span>(</span><span>delay</span><span>)</span>
<span>print</span><span>(</span><span>"P   PP     I      N N  N"</span><span>)</span>
<span>time</span><span>.</span><span>sleep</span><span>(</span><span>delay</span><span>)</span>
<span>print</span><span>(</span><span>"PPPPP      I      N  N N   PROGRAM"</span><span>)</span>
<span>time</span><span>.</span><span>sleep</span><span>(</span><span>delay</span><span>)</span>
<span>print</span><span>(</span><span>"P          I      N   NN"</span><span>)</span>
<span>time</span><span>.</span><span>sleep</span><span>(</span><span>delay</span><span>)</span>
<span>print</span><span>(</span><span>"P       IIIIIII   N    N"</span><span>)</span>
<span>time</span><span>.</span><span>sleep</span><span>(</span><span>delay</span><span>)</span>

<span>print</span><span>(</span><span>''</span><span>)</span>
<span>input</span><span>(</span><span>"Strike a key when ready ..."</span><span>)</span>

<span>print</span><span>(</span><span>"</span><span>\n\n</span><span>12345678901234567890123457890123456780"</span><span>)</span>

<span>lines</span> <span>=</span> <span>1</span>

<span>length</span> <span>=</span> <span>38</span>
<span>decrease</span> <span>=</span> <span>1</span>
<span>while</span> <span>True</span><span>:</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>length</span><span>):</span>
        <span>print</span><span>(</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span><span>9</span><span>),</span> <span>end</span><span>=</span><span>''</span><span>)</span>
    <span>print</span><span>(</span><span>''</span><span>)</span>
    <span>time</span><span>.</span><span>sleep</span><span>(</span><span>delay</span><span>)</span>
    <span>lines</span> <span>+=</span> <span>1</span>
    <span>if</span> <span>(</span><span>lines</span> <span>==</span> <span>5</span><span>):</span>
        <span>lines</span> <span>=</span> <span>0</span>
        <span>length</span> <span>-=</span> <span>decrease</span>
        <span>if</span> <span>(</span><span>decrease</span> <span>==</span> <span>1</span><span>):</span>
            <span>decrease</span> <span>=</span> <span>2</span>
        <span>else</span><span>:</span>
            <span>decrease</span> <span>=</span> <span>1</span>
    <span>if</span> <span>(</span><span>length</span> <span>&lt;=</span> <span>4</span><span>):</span>
        <span>break</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>):</span>
    <span>print</span><span>(</span><span>"9003"</span><span>)</span>

<span>print</span><span>(</span><span>"</span><span>\n</span><span>PIN IDENTIFICATION NUMBER: 9003"</span><span>)</span>

<span>print</span><span>(</span><span>"</span><span>\n</span><span>a&gt;"</span><span>,</span> <span>end</span><span>=</span><span>''</span><span>)</span>
</code></pre></div></div>

<p>The script runs really quickly so I added a delay between lines so that you can see the same progression as in the clip. I’m sure there are other optimizations that can be made, but if I were administering this as a bad coding challenge for a tech interview, I’d pass myself.</p>

<p>Using Google Image Search, I found a site selling OEM plastic bezels for the Atari Portfolio which had this nice graphic of the front of the screen:</p>

<p><img src="https://bert.org/assets/posts/pinid/bezel.jpg" alt="screen bezel"></p>

<p>After playing around with <a href="https://github.com/nbedos/termtosvg">termtosvg</a> a bit, in particular the <a href="https://github.com/nbedos/termtosvg/blob/develop/man/termtosvg-templates.md">SVG templates</a> feature, I managed to produce this crazy SVG:</p>

<p>Despite running <a href="https://html5zombo.com/">html5zombo.com</a> for over 10 years now, I’m not sure I really appreciated what SVGs were capable of until I built this one. They can embed images? CSS? Javascript? Any site that allows users to upload arbitrary SVGs and <a href="https://github.com/bertrandom/pinid">renders them</a> now has my utmost respect.</p>

<p>While I enjoyed making my little self-contained SVG, it bugged me that my Python code could never actually run on an Atari Portfolio. The Atari Portfolio runs “DIP Operating System 2.11” (DIP DOS) which is “mostly compatible” with MS-DOS.</p>

<p>In junior high, before anybody paid me to write software professionally, I used to write BBS software, mods, and door games in my spare time in a mix of Turbo Pascal and a scripting language called PCBoard Programming Language which was similar to BASIC. Based on my minimal research, if I could write this in Turbo Pascal and compile it, it’d probably run on an Atari Portfolio.</p>

<p>I haven’t written Turbo Pascal in about 25 years, but do you ever really forget?</p>

<p>I like a fork of DOSBox called <a href="https://dosbox-x.com/">DOSBox-X</a>, so I downloaded and installed the most recent SDL2 variant for OS X. Then I found a copy of Borland Turbo Pascal 7.0, which I’ll put <a href="https://bert.org/assets/posts/pinid/tp7.zip">here</a> because it was kind of a pain to find.</p>

<p>You’ll find 4 files in that ZIP which are images of floppy disks. If you put them in a directory like <code>~/tp</code>, after you start DOSBox-X and mount a C Drive, you can mount them to the A Drive like this:</p>

<div><div><pre><code>imgmount a ~/tp/Disk01.img ~/tp/Disk02.img ~/tp/Disk03.img ~/tp/Disk04.img -floppy
</code></pre></div></div>

<p>and then switch over to the A: drive and run INSTALL:</p>



<p><img src="https://bert.org/assets/posts/pinid/install_000.png" alt="turbo pascal install"></p>

<p><img src="https://bert.org/assets/posts/pinid/install_001.png" alt="turbo pascal install"></p>

<p><img src="https://bert.org/assets/posts/pinid/install_002.png" alt="turbo pascal install"></p>

<p><img src="https://bert.org/assets/posts/pinid/install_003.png" alt="turbo pascal install"></p>

<p>At some point in the installation, you’ll have to change floppy disks, because it’s 1992.</p>

<p><img src="https://bert.org/assets/posts/pinid/install_004.png" alt="turbo pascal install"></p>

<p>You can do this by selecting <strong>Drive</strong> -&gt; <strong>A</strong> -&gt; <strong>Swap disk</strong> in DOSBox-X. It’ll go from Disk 1 to Disk 2. Then just keep doing that and pressing enter until you’ve installed all four disks.</p>

<p>After the installation is done, it’ll ask you to configure your <code>CONFIG.SYS</code> and <code>AUTOEXEC.BAT</code> because again, 1992.</p>

<p><img src="https://bert.org/assets/posts/pinid/install_005.png" alt="turbo pascal install"></p>

<p>Neither of these are strictly necessary. DOSBox-X already sets the FILES higher than the recommendation and adding it to the path only really lets you run TURBO from anywhere. When it’s done, you can run:</p>



<p><img src="https://bert.org/assets/posts/pinid/turbo_000.png" alt="turbo pascal"></p>

<p><img src="https://bert.org/assets/posts/pinid/turbo_001.png" alt="turbo pascal"></p>

<p>I’d spent so much time looking at this IDE when I was a kid that it made me a bit nostalgic. But then I started porting my Python script to Pascal and that nostalgia faded quickly. I’d like to say that I wrote the whole thing in here but at a certain point I had to switch to VSCode and then copy the file back into the DOS directory. To the people that still run <a href="http://www.columbia.edu/~em36/wpdos/">WordPerfect for DOS</a>, I get it, but I also don’t get it.</p>

<p>Here’s the script I landed on after spending a lot of time on this <a href="https://wiki.freepascal.org/Basic_Pascal_Tutorial">Pascal tutorial</a>:</p>

<div><div><pre><code>program pinid;
uses crt;

var i: byte;
var pos: byte;
var lines: byte;
var length: byte;
var decrease: byte;
var delay_amount: integer;

begin
     randomize;

     delay_amount := 25;

     clrscr;

     writeln('PPPPP   IIIIIII   N    N');
     delay(delay_amount);
     writeln('P   PP     I      NN   N IDENTIFICATION');
     delay(delay_amount);
     writeln('P   PP     I      N N  N');
     delay(delay_amount);
     writeln('PPPPP      I      N  N N   PROGRAM');
     delay(delay_amount);
     writeln('P          I      N   NN');
     delay(delay_amount);
     writeln('P       IIIIIII   N    N');
     delay(delay_amount);
     writeln('');

     write('Strike a key when ready ...');
     readln;

     writeln('');
     writeln('');
     writeln('12345678901234567890123457890123456780');

     pos := 0;
     lines := 1;

     length := 38;
     decrease := 1;

     while true do
     begin
          for i:= 1 to length do 
               write(random(9));
          writeln('');
          delay(delay_amount);
          lines := lines + 1;
          if (lines = 5) then
          begin
               lines := 0;
               length := length - decrease;
               if (decrease = 1) then
                   decrease := 2
               else
                   decrease := 1;
          end;
          if (length &lt;= 4) then
               break;
     end;

     for i:= 1 to 10 do
     begin
          writeln('9003');
          delay(delay_amount);
     end;

     writeln('');
     writeln('PIN IDENTIFICATION NUMBER: 9003');
     writeln('');

end.
</code></pre></div></div>

<p>Some quick explanations:</p>
<ul>
  <li>Pascal has type declarations. A byte can be a number from 0-255.</li>
  <li>files start with <code>program</code> and the name of the program, presumably because all modules share the same namespace but the filename is irrelevant</li>
  <li>modules are imported with the word <code>uses</code>. <code>crt</code> is a module for manipulating the screen</li>
  <li>:= is the syntax for variable assignment, so you can compare with = and differentiate between the two.</li>
  <li>If blocks are longer than one line, you have to wrap them with <code>begin</code> and <code>end</code> instead of brackets or relying upon whitespace.</li>
  <li>If you don’t run <code>randomize</code> at the beginning of your script, hilariously it always seeds random numbers with the same seed and the output is the same.</li>
  <li>WRITE writes a string, WRITELN writes a string with a newline. READLN accepts input until a newline is received.</li>
</ul>

<p>Does it work? Here’s the program running in DOSBox-X:</p>



<p>In the spirit of owning less stuff, I’ve gone through the mental exercise of what it would take to make the rest of this a reality but will not follow through on any of it:</p>

<ol>
  <li>Buy an Atari Portfolio on Ebay.</li>
  <li>Buy an <a href="http://www.best-electronics-ca.com/portfoli.htm">Atari Portfolio parallel interface and probably a new screen bezel</a> because it’s likely scratched.</li>
  <li>Find a parallel cable in my box of cables.</li>
  <li>Find a PC or laptop with a parallel port, install MS-DOS v6.22 on it.</li>
  <li>Download <a href="http://ftp.pigwa.net/stuff/mirror/www.umich.edu/%257Earchive/atari/Portfolio/Telecomm/index.html">FT.COM</a> and put it on the PC.</li>
  <li>Build the EXE in Dosbox-X and transfer it to the Atari Portfolio.</li>
  <li>Steal a debit card.</li>
  <li>Wrap part of the card in aluminum foil, buy an Atari Portfolio serial interface, run a cable to the card.</li>
  <li>Run the program.</li>
  <li>Easy money!</li>
</ol>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://bert.org/2021/01/04/t2-pin-cracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25656827</guid>
            <pubDate>Wed, 06 Jan 2021 11:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Window Functions in SQL]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25656583">thread link</a>) | @adilkhash
<br/>
January 6, 2021 | https://khashtamov.com/en/sql-window-functions/ | <a href="https://web.archive.org/web/*/https://khashtamov.com/en/sql-window-functions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    
                        <p>It is interesting that many people working with data have no clue about window functions in SQL. During the long period of time instead of using window functions I prefered coding on Python and <a href="https://khashtamov.com/en/pandas-data-analysis/">pandas</a>. Today I would like to introduce you to the concept of "window" and how it is related to data extraction from a SQL database.</p>

<p><strong>Window functions</strong> are applied to a subset/window of rows related to one another. In comparison to <code>GROUP BY</code> operation, window functions do not decrease the number of rows. Aggregate functions like <code>AVG</code>, <code>SUM</code>, <code>COUNT</code> could be used as window functions as well. Usually window functions are used to do analytical tasks. The following examples of queries will be performed on PostgreSQL database.</p>
<h2>Syntax</h2>
<pre><code>&lt;function&gt;(&lt;expression&gt;) OVER (
  &lt;window&gt;
  &lt;sorting&gt;
  &lt;window range&gt; -- optional
)</code></pre>
<p>Looks creepy 😲 We need more practice. Let's assume that we have a salary table:</p>
<figure><img src="https://khashtamov.com/uploads/redactor/salary_table_1.png" width="80%" data-image="atvi5p4igh4g"></figure>
<p><!--more-->One day your boss approaches you, he wants to know who is the highest paid employee by department. We can use the <code>MAX</code> function to select the highest salary by each department.</p>
<pre><code>SELECT
    department,
    MAX(gross_salary) as max_salary
FROM Salary
GROUP BY 1;
</code></pre>
<p>The result is:</p>

<ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-3273608550190378" data-ad-slot="9434009847"></ins>


<figure><img src="https://khashtamov.com/uploads/redactor/department_max_salary.png" width="80%" data-image="department_max_salary.png"></figure>
<p>In order to select the person with the highest salary by department we can use a subquery and <code>JOIN</code>:</p>
<pre><code>SELECT
    id,
    first_name,
    department,
    t.gross_salary
FROM Salary
JOIN (
    SELECT
        department,
        MAX(gross_salary) as gross_salary
    FROM Salary
    GROUP BY 1
) t USING(gross_salary, department);
</code></pre>
<p>The result is:</p>
<figure><img src="https://khashtamov.com/uploads/redactor/highest_paid_employees.png" width="80%" data-image="highest_paid_employees.png"></figure>
<p>But the query looks verbose and dirty, maybe we can do the same with window functions? Sure. All you need to do is to set up a window for <code>MAX</code> aggregate function: </p>
<pre><code>SELECT
    id,
    first_name,
    department,
    gross_salary,
    MAX(gross_salary) OVER (PARTITION BY department) as max_gross_salary
FROM Salary;
</code></pre>
<p>The column <code>department</code> is a window. It means that employees from the same department is a subset or window of related rows. The result of the query:</p>
<figure><img src="https://khashtamov.com/uploads/redactor/window_functions_highest_salary.png" width="80%" data-image="window_functions_highest_salary.png"></figure>
<p>As you can see we have the new column called <code>max_gross_salary</code> which shows the highest salary in each department. In order to retrieve the list of most paid employees we do the following:</p>
<pre><code>SELECT *
FROM (
         SELECT id,
                first_name,
                department,
                gross_salary,
                MAX(gross_salary) OVER (PARTITION BY department) as max_gross_salary
         FROM Salary
     ) t
WHERE max_gross_salary = gross_salary
ORDER BY id;
</code></pre>
<p>Now your boss asks you to prepare the report which shows the ratio of salaries by department and by the total wage fund because some departments have relatively low-income employees in comparison with other departments. You can solve it using subqueries:</p>
<pre><code>WITH gross_by_departments AS (
    SELECT
        department,
        SUM(gross_salary) as dep_gross_salary
    FROM Salary
    GROUP BY 1
)
SELECT
    id,
    first_name,
    department,
    gross_salary,
    ROUND(CAST(gross_salary AS numeric(9, 2)) / dep_gross_salary * 100, 2) as dep_ratio,
    ROUND(CAST(gross_salary AS numeric(9, 2)) / (SELECT SUM(gross_salary) FROM Salary) * 100, 2) as total_ratio
FROM Salary
JOIN gross_by_departments USING(department)
ORDER BY department, dep_ratio DESC
</code></pre>
<p>The result is:</p>
<figure><img src="https://khashtamov.com/uploads/redactor/subqueries_salary_ratios.png" width="80%" data-image="subqueries_salary_ratios.png"></figure>
<p>As you can see Нина earns 71.4% out of HR department, but it is only 10.7% out of total wage fund. Аркадий on the other hand has 21.4% out of total wage fund and 41% out of IT department. Can we refactor the query to make it smaller and more readable? Yes! <strong>Window functions</strong>!</p>
<pre><code>SELECT
    id,
    first_name,
    department,
    gross_salary,
    ROUND(CAST(gross_salary AS numeric(9,2)) / SUM(gross_salary) OVER (PARTITION BY department) * 100, 2) as dep_ratio,
    ROUND(CAST(gross_salary AS numeric(9,2)) / SUM(gross_salary) OVER () * 100, 2) as total_ratio
FROM Salary
ORDER BY department, dep_ratio DESC; 
</code></pre>
<p>The expression <code>OVER()</code> means that the "window" is all rows.</p>
<h2>Window functions only</h2>
<p>We used the aggregate functions <code>MAX</code> &amp; <code>SUM</code> as window functions above. But SQL standard consists of functions which cannot be used as aggregates hence no way to apply them during grouping. Here is the list of them:

</p>
<ul>
<li>first_value</li>
<li>last_value</li>
<li>lead</li>
<li>lag</li>
<li>rank</li>
<li>dense_rank</li>
<li>row_number</li>
</ul>
<p>The comprehensive list of all window functions supported in PostgreSQL you can find <a href="https://www.postgresql.org/docs/current/functions-window.html" target="_blank">here</a>.</p>
<h3>Using window functions</h3>
<p>Let's use the <code>first_value</code> function in order to solve the very first problem where we were asked to get the name of the highest paid employee by each department. The function returns the very first values according to the provided window.</p>
<pre><code>SELECT
    id,
    first_name,
    department,
    gross_salary,
    first_value(first_name) OVER (PARTITION BY department ORDER BY gross_salary DESC ) as highest_paid_employee
FROM Salary
</code></pre>
<p>We are sorting the rows in our window by salary in a descending order, it means that the very first row will be a person with the highest salary.</p>
<p>Now let's use <code>last_value</code>. It does the opposite of what <code>first_value</code> does.</p>
<pre><code>SELECT id,
       first_name,
       department,
       gross_salary,
       last_value(first_name)
       OVER (PARTITION BY department ORDER BY gross_salary DESC) AS lowest_paid_employee
FROM Salary
</code></pre>
<p>The result is:</p>
<figure><img src="https://khashtamov.com/uploads/redactor/lowest_paid_employees_last_value_window_function.png" width="80%" data-image="lowest_paid_employees_last_value_window_function.png"></figure>
<p>If you look at the table you will see that the result is wrong. Why? Because of window ranges. By default if you provide the <code>ORDER BY</code> clause the window range is all preceding rows and current row, in SQL terms it is <code>ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW</code>. It means that the <code>last_value</code> for a particular column in a particular row is a column in the same row. In order to fix this problem we need to change the range to <code>ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING</code>:</p>
<pre><code>SELECT id,
       first_name,
       department,
       gross_salary,
       last_value(first_name)
       OVER (
           PARTITION BY department
           ORDER BY gross_salary DESC
           ROWS BETWEEN
               UNBOUNDED PRECEDING
               AND UNBOUNDED FOLLOWING
           ) as lowest_paid_employee
FROM Salary
</code></pre>
<p>This is how it looks visually:</p>
<figure><span id="selection-marker-start">﻿</span><span id="selection-marker-end">﻿</span><img src="https://khashtamov.com/uploads/redactor/unbounded_preceding_current_row_unbounded_following.png" data-image="r9u3sqk8i9v7"><span id="selection-marker-start">﻿</span><span id="selection-marker-end">﻿</span></figure>
<p>The possible values:</p>
<ul>
<li>N PRECEDING, N number of rows until current row</li>
<li>CURRENT ROW</li>
<li>UNBOUNDED PRECEDING</li>
<li>UNBOUNDED FOLLOWING</li>
<li>N FOLLOWING**, N number of rows following current row</li>

</ul>
                </article></div>]]>
            </description>
            <link>https://khashtamov.com/en/sql-window-functions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25656583</guid>
            <pubDate>Wed, 06 Jan 2021 11:02:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Use Instead of Google]]>
            </title>
            <description>
<![CDATA[
Score 265 | Comments 197 (<a href="https://news.ycombinator.com/item?id=25654222">thread link</a>) | @kmclean
<br/>
January 5, 2021 | https://kiramclean.com/blog/what-i-use-now-instead-of-google/ | <a href="https://web.archive.org/web/*/https://kiramclean.com/blog/what-i-use-now-instead-of-google/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I made a goal for myself in January 2020 to stop using Google products by the end of the year. That might sound like way too generous a timeline, but Google owned pretty much all of my data at that point, so it was a fairly large project. Plus I'm a slow and steady kind of person. I know if I give myself a generous enough timeline I can accomplish even things that seem too hard for me at first.</p>
<h2>First, Why</h2>
<p>Since I got into programming about 5 years ago, I kept hearing all these bad things about Google and how horrible of a company it is from other tech people. It always seemed a bit exaggerated to me, but the evidence has been piling up over the years. Learning about <a href="https://gizmodo.com/google-is-helping-the-pentagon-build-ai-for-drones-1823464533">their involvement</a> with the US military's <a href="https://dodcio.defense.gov/Portals/0/Documents/Project%20Maven%20DSD%20Memo%2020170425.pdf">Algorithmic Warfare Cross-Functional Team (Project Maven)</a> was the last straw for me <sup id="footnote-1"><a href="https://kiramclean.com/blog/what-i-use-now-instead-of-google/#footnote-1-text">1</a></sup>, but even before I learned about that I was pretty uncomfortable with a lot of what I heard. In Google's defence they eventually did <a href="https://web.archive.org/web/20210101083904/https://www.nytimes.com/2018/06/01/technology/google-pentagon-project-maven.html">pull out of the project</a> after <a href="https://web.archive.org/web/20201231204850/https://www.nytimes.com/2018/04/04/technology/google-letter-ceo-pentagon-project.html">massive backlash by thousands of employees</a>.</p>
<p>Still, I'm pretty convinced now that their continued existence is a catastrophe not only for public safety, but also for <a href="https://www.vox.com/recode/2020/1/3/21030688/google-amazon-ai-oil-gas">the environment</a>, <a href="https://www.nytimes.com/2018/11/01/technology/google-walkout-sexual-harassment.html">gender equity</a>, <a href="https://www.telegraph.co.uk/technology/google/9739039/Googles-tax-avoidance-is-called-capitalism-says-chairman-Eric-Schmidt.html">the economy</a>, <a href="https://www.vice.com/en/article/jgexe8/google-fired-an-engineer-who-wrote-code-telling-googlers-they-had-a-right-to-organize">fair labour practices</a>, <a href="https://www.stallman.org/google.html#surveillance">privacy</a>, <a href="https://www.nature.com/articles/s41562-020-00954-0">journalism</a>, <a href="https://www.judiciary.senate.gov/download/epstein-testimony">democracy</a>, <a href="https://www.vox.com/2018/4/3/17168256/google-racism-algorithms-technology">race relations</a>, and the <a href="https://www.scientificamerican.com/article/big-tech-out-of-control-capitalism-and-the-end-of-civilization/">project of civilization itself</a>. But anyway, the point of this post isn't to motivate you to also quit Google. I'll tell you how I really feel some other time.</p>
<p>The rest of this post is about the tools and services I replaced all the Google things with. I did mostly accomplish my goal, with a few caveats which I describe in the relevant sections.</p>
<h2>Replacements</h2>
<p>Here's the short version:</p>
<ul>
<li>GMail → <a href="https://protonmail.com/signup">ProtonMail</a></li>
<li>Chrome → <a href="https://www.mozilla.org/en-US/firefox/developer/">Firefox developer edition</a></li>
<li>Google search → <a href="https://duckduckgo.com/">DuckDuckGo</a></li>
<li>Google Drive → <a href="https://www.sync.com/">Sync</a> and <a href="https://www.backblaze.com/b2/cloud-storage.html">Backblaze</a></li>
<li>Google DNS → <a href="https://blog.cloudflare.com/announcing-1111/">Cloudflare DNS</a></li>
<li>Maps → Apple maps</li>
<li>YouTube → Netflix, <a href="https://www.ted.com/">TED talks</a>, conference archives, and still a little YouTube (anonymously in a <a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/">Firefox container</a>)</li>
<li>Google Analytics → <a href="https://usefathom.com/">Fathom</a></li>
<li>Everything else (calendar, reminders, photos, docs, video chat, news feeds) → <a href="https://nextcloud.com/signup/">Nextcloud</a>, running <a href="https://kiramclean.com/blog/how-to-set-up-your-own-nextcloud-server/">on my own instance</a></li>
</ul>
<p>And here's the long version:</p>
<h3>GMail → <a href="https://protonmail.com/signup">ProtonMail</a></h3>
<p>ProtonMail has free accounts, but I pay for the lowest level that allows use of a custom domain with it (€48/year) so I don't have to change my email address ever again if I want to switch providers. It was quite a pain to change my email address all over the place, but I started in May and just did it slowly over time. I highly recommend decoupling your email address from your email provider if you're considering switching. First of all an email from a custom domain seems more, not less, serious than a gmail address to most people. But the main reason is just so you don't have to change your email address ever again if (when) you want to switch to some newer, better email provider.</p>
<p>I set up forwarding from my old GMail account to my new email address then filtered my mail for anything sent to the old address. If it was someone or some place I wanted to continue hearing from, I updated my email address with them. If not I unsubscribed. This turned out to be a wonderful opportunity to purge my newsletter and other email subscriptions. Also I'm happy to report most companies are now (finally) respecting unsubscribe requests. Two (looking at you Geektastic and Rakuten) continued to spam me after I requested they stop, so now I filter out all their mail as spam.</p>
<h3>Chrome → Firefox developer edition</h3>
<p>I primarily use <a href="https://www.mozilla.org/en-US/firefox/developer/">Firefox developer edition</a> now for my browser, including for work. The developer tools are just as good as Chrome's for the kind of work I do.</p>
<p>There are some web apps that literally or effectively only work in Chrome, which ironically perfectly illustrates the impetus for this whole undertaking. For those I use this <a href="https://github.com/Eloston/ungoogled-chromium#downloads">ungoogled Chromium</a> browser, installed via homebrew.</p>
<p>I still have Chrome installed on my computer because I need it for some work things. We use chromedriver for some integration tests and it wasn't trivially easy to trick it into using my Chromium installation instead of looking for Chrome. Replacing chromedriver is a headache, and also not my call to make at work. But it's also not really the point for me. If Google was reduced to a browser that developers can easily launch and control programmatically, I'd be satisfied. I don't use it for anything other than running automated tests at work now.</p>
<h3>Google search → <a href="https://duckduckgo.com/">DuckDuckGo</a></h3>
<p>I mostly love DuckDuckGo, but there are certain categories of searches where Google returns better results. DuckDuckGo doesn't seem to return many results from forums (like stack overflow or other stack exchange sites), which is where there the answers to a lot of my questions are, unfortunately. So I still use Google Search sometimes, but I do it in a <a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/">Firefox container</a> without being logged in to a Google account, which at least helps to avoid some of Google's incessant stalking.</p>
<p>DuckDuckGo does seem to return better results when the answer is an image, video, or regular web page, which is cool, and I suspect means it would be a perfectly fine replacement for most people. For example this blog is easier to find via DuckDuckGo than Google, which is impressive because I share a name with a small-time TV celebrity who typically dominates search results. We even look sort of similar, it's wild.</p>
<h3>Google Drive → <a href="https://www.sync.com/">Sync</a> and <a href="https://www.backblaze.com/b2/cloud-storage.html">Backblaze</a></h3>
<p>I use Sync to make my most used files available anywhere, and I've started moving a huge backlog of documents and notes I don't need to access often but don't want to throw away to Backblaze for longer term storage, just because it's cheaper. So far I just use their web UI to upload things in bulk and browse my files, but I'm looking into ways to do that more efficiently. I really need to de-clutter my digital life. I'm a major hoarder when it comes to digital files. I have scarcely deleted a document in the last 10 years, it's getting a bit ridiculous. But that's a goal for another year 🙂. For now I'm just putting all those files I don't really need to access but don't want to throw away in Backblaze to deal with later.</p>
<p>Between Sync and Backblaze I got 15GB of free storage, which is plenty for now, though as I move more and more or my scattered files over I'll have to start paying. Backblaze offers some of the cheapest object storage there is, at least.</p>
<h3>DNS → Cloudflare DNS</h3>
<p>I used to use Google's DNS servers (8.8.8.8 and 8.8.4.4), now I use <a href="https://blog.cloudflare.com/announcing-1111/">Cloudflare's</a> (1.1.1.1 and 1.0.0.1).</p>
<h3>Maps, YouTube</h3>
<p>These ones are harder to replace. I use Apple maps now most of the time, but I still use Waze (which was acquired by Google) for directions sometimes if I'm driving somewhere. For media I mostly watch Netflix, but I also watch a lot of <a href="https://www.ted.com/">TED talks</a>. I used to also watch conference videos on YouTube. Now I check conference websites for those, and a lot of them have the recordings, although they're often hosted on YouTube anyway. And I also do still use YouTube sometimes, mostly for home workout videos, but also anonymously in an isolated container.</p>
<h3>Analytics → <a href="https://usefathom.com/">Fathom</a></h3>
<p>It's been a while since I used Google Analytics, but I wanted to set up a basic hit counter for this blog and found Fathom. They provide simple privacy-focused analytics that work well enough for me. One really useful feature they have that I consider necessary now is being able to log analytics with a custom domain. Without this, visitors using ad-blockers don't get counted, which most estimates figure is now something like 40% of people, and probably more among tech-type people, like the ones most likely to find this blog.</p>
<p>I tried Cloudflare's new server-side analytics for a month, but the data didn't make as much sense (it showed the overwhelming number of visits to my homepage, even though the other analytics I had set up showed them going to one post that did well on Hacker News, which makes way more sense). Anyway, the numbers didn't seem to add up. I guess to be fair I <a href="https://twitter.com/kiraemclean/status/1340530206516387840">don't quite understand</a> how Fathom's numbers add up yet either, but their support has been helpful checking it out with me to try to help me reach some interpretation that makes sense. Fathom's dashboard is really simple, at least, which I like because it's easy to understand.</p>
<h3>Calendar, reminders, photos, docs, video chat, news feeds → <a href="https://nextcloud.com/signup/">Nextcloud</a></h3>
<p>For everything else I use Nextcloud now. I <a href="https://kiramclean.com/blog/how-to-set-up-your-own-nextcloud-server/">run my own instance</a> of it, but there are lots of providers where you can just sign up for a simple account like anything else if you're not an insufferable nerd who enjoys maintaining servers, like me.</p>
<p>This is where I have another caveat to mention. I haven't migrated all of my photos off of Google Photos yet because I have about 50,000 of them and it's just a really slow process. I estimated it would take me something like 70 hours to move them all manually, so I'm looking into better ways to do it. I'm confident I can find or maybe build something easier than manually downloading and uploading 50k files in less than 70 hours.</p>
<p>Nextcloud does the job of automatically syncing photos from my phone, though, which is all I needed to be able to delete Google Photos from my devices. I'm not sure I'll actually stick with Nextcloud for photos in the long run. The gallery is a bit lacking. It looks like <a href="https://piwigo.org/get-piwigo">Piwigo</a> might be a good alternative. Either way, I'm actually storing my photos in Backblaze, so I'll continue looking around for a different client for a bucket full of photos next year as I work on slowly culling my photos collection and migrating it to a new home.</p>
<h2>Total Cost</h2>
<p>I feel like I've won a lot by doing all this. I own my data now, so Google can't <a href="https://www.businessinsider.com/google-users-locked-out-after-years-2020-10">arbitrarily take it away from me</a>, which gives me peace of mind. I'm no longer part of their ad ecosystem, being tracked all around the internet and having my attention sold to the highest bidder. And I also feel good about "voting with my feet", so to speak. The fewer people use Google's free products, the lower their ability to sustain their unethical business model based on selling mass surveillance data.</p>
<p>But I also lost some. Specifically a few …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kiramclean.com/blog/what-i-use-now-instead-of-google/">https://kiramclean.com/blog/what-i-use-now-instead-of-google/</a></em></p>]]>
            </description>
            <link>https://kiramclean.com/blog/what-i-use-now-instead-of-google/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25654222</guid>
            <pubDate>Wed, 06 Jan 2021 02:54:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing Modern Retro Computer Terminals]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25653802">thread link</a>) | @armadillu
<br/>
January 5, 2021 | https://uri.cat/projects/modern-retro-terminal/ | <a href="https://web.archive.org/web/*/https://uri.cat/projects/modern-retro-terminal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-2357">
					<tbody><tr>
<!--					<td class="entry-aside"></td> 
-->
						<td>
							
<p>The goal for this project is to design, 3D-print and assemble the enclosures for several small desktop computers. This series was created during the covid19 pandemic, to get familiar with modern parametric 3D design tools, the limits of 3D printing and fabrication. </p>



<p>A screen size is chosen first, together with the desired components, and then an enclosure is designed around all the constrains (including FDM 3D printing limitations). </p>



<p>All of these have been designed in Autodesk Fusion360 and printed at home on an inexpensive Creality Ender 3.</p>







<h2>4:3 10″ LCD Terminal</h2>



<p>Designed around a 10″ 1024 x 768 IPS LCD. Raspberry PI 4, Ducky One SF Keyboard, black PLA.</p>















<h2>16:9 5″ LCD Terminal</h2>



<p>Designed around a 5″ 800 x 480 LCD. Raspberry Pi 3, Official Raspberry Pi keyboard, black PLA. </p>















<h2>16:9 5″ LCD Terminal v2</h2>



<p>Revised for a more modern look and a smaller footprint. It runs a Raspberry Pi 4, printed on orange PLA. Wireless USB keyboard from ali-express.</p>















<h2>UltraWide 8.8″ LCD Terminal</h2>



<p>Designed around an ultrawide 8.8″ 1920 x 480 LCD, with a rather exotic 4:1 aspect ratio. As this exceeds my 3D printer bed size, I had to figure out a way to split the design in two parts, and how to assemble them effectively. This one is powered by an Nvidia Jetson Nano 2GB, allowing it to run OpenGL natively. Ducky One2 SF keyboard. Printed on “copper” PLA.</p>















<h2>Minimal 4:3 8″ Terminal</h2>



<p>1024 x 768 8″ IPS LCD. Designed with the goal of the smallest possible footprint, leaving components out in plain sight. Raspberry pi 4, official Raspberry Pi Keyboard. Printed on neon yellow transparent PLA.</p>















<h2>Other Concepts</h2>



<p>Some rejects I produced along the way…</p>







<p>Retro TV</p>







<p> Macintosh Classic inspired design</p>



<figure><ul><li><figure><a target="_blank" href="https://uri.cat/projects/modern-retro-terminal/phone_booth_terminal_sharp_2021-jan-04_11-34-38pm-000_customizedview8576530636/"><img loading="lazy" width="640" height="360" src="https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-640x360.jpg" alt="" data-id="2512" data-full-url="https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636.jpg" data-link="https://uri.cat/projects/modern-retro-terminal/phone_booth_terminal_sharp_2021-jan-04_11-34-38pm-000_customizedview8576530636/" srcset="https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-640x360.jpg 640w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-1400x788.jpg 1400w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-312x176.jpg 312w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-768x432.jpg 768w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-1536x864.jpg 1536w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-2048x1152.jpg 2048w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-300x169.jpg 300w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-640x360@2x.jpg 1280w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-1400x788@2x.jpg 2800w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-312x176@2x.jpg 624w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-1536x864@2x.jpg 3072w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-34-38PM-000_CustomizedView8576530636-300x169@2x.jpg 600w" sizes="(max-width: 640px) 100vw, 640px"></a></figure></li><li><figure><a target="_blank" href="https://uri.cat/projects/modern-retro-terminal/phone_booth_terminal_sharp_2021-jan-04_11-35-58pm-000_customizedview48438323474/"><img loading="lazy" width="640" height="360" src="https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-640x360.jpg" alt="" data-id="2513" data-full-url="https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474.jpg" data-link="https://uri.cat/projects/modern-retro-terminal/phone_booth_terminal_sharp_2021-jan-04_11-35-58pm-000_customizedview48438323474/" srcset="https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-640x360.jpg 640w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-1400x788.jpg 1400w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-312x176.jpg 312w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-768x432.jpg 768w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-1536x864.jpg 1536w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-2048x1152.jpg 2048w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-300x169.jpg 300w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-640x360@2x.jpg 1280w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-1400x788@2x.jpg 2800w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-312x176@2x.jpg 624w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-1536x864@2x.jpg 3072w, https://uri.cat/wp-content/uploads/2021/01/phone_booth_terminal_Sharp_2021-Jan-04_11-35-58PM-000_CustomizedView48438323474-300x169@2x.jpg 600w" sizes="(max-width: 640px) 100vw, 640px"></a></figure></li></ul></figure>



<p>Faceted design test</p>







<p>Phone-booth inspired design</p>
							
									

							<!-- .entry-utility -->
						</td>
					</tr>
				</tbody></div></div>]]>
            </description>
            <link>https://uri.cat/projects/modern-retro-terminal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25653802</guid>
            <pubDate>Wed, 06 Jan 2021 01:39:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Move from Gradle to Maven]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25653455">thread link</a>) | @foxgrover
<br/>
January 5, 2021 | https://blog.astradot.com/why-we-moved-from-gradle-to-maven/ | <a href="https://web.archive.org/web/*/https://blog.astradot.com/why-we-moved-from-gradle-to-maven/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Lets get one thing out of the way, declaring dependencies like this:</p><pre><code>implementation 'org.apache.tapestry:commons:5.5.0'
</code></pre><p>is waaaaay better than declaring them like this:</p><pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.apache.tapestry&lt;/groupId&gt;
  &lt;artifactId&gt;commons&lt;/artifactId&gt;
  &lt;version&gt;5.5.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>This is where the positives for Gradle end.</p><p>First off, you cannot <em>not</em> learn Maven. The entire Java world is built using Maven conventions. Every artifact published on Maven Central has a maven <code>pom.xml</code> file. So using Gradle means you learn both Maven and Gradle.</p><p>Learning Gradle also means that you have to understand Groovy at some level, to understand how your build script is being composed. But Gradle adds it own DSL to the mix making it impossible to decipher what Groovy language constructs are being used for a particular line in a Gradle script. &nbsp;For example, one can't just define a global variable and use it in the script. Instead it has to be in an <code>ext</code> block.</p><h3 id="we-don-t-need-the-advanced-features">We don't need the advanced features</h3><p>Astradot's Java projects are small microservices. All we need from a build tool is to download dependencies, compile, jar and run a few basic tests. All the advanced, mindbending, quantum-entangling caching features that Gradle has are simply not needed.</p><p>Maven is old and robust. All editors understand it. Intellij's support for it is flawless. The XML while verbose is easily understood.</p><h3 id="there-is-an-exception-though-">There is an exception though...</h3><p>Wait, there actually <em>is</em> a place we use Gradle. That is for our Java Tracing Agent. The requirements for putting together the agent are not like your typical Java jar. Neither Maven nor Gradle could build it out of the box. Our initial thinking was to write a custom build tool for it. However, this is where we found that Gradle absolutely shines. Doing a completely custom build, where you are taking full advantage of the dynamism of having groovy as a full-fledged programming language as opposed to just a declaration format made Gradle the perfect tool for the job.</p><h3 id="that-said">That said</h3><p>For everything else, we saw no reason to choose Gradle over Maven. We do miss those single-line dependency declarations though.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.astradot.com/why-we-moved-from-gradle-to-maven/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25653455</guid>
            <pubDate>Wed, 06 Jan 2021 00:49:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's Build a Microprocessor!]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25653010">thread link</a>) | @matt_d
<br/>
January 5, 2021 | https://tiarkrompf.github.io/notes/?/lets-build-a-microprocessor/ | <a href="https://web.archive.org/web/*/https://tiarkrompf.github.io/notes/?/lets-build-a-microprocessor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tiarkrompf.github.io/notes/?/lets-build-a-microprocessor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25653010</guid>
            <pubDate>Tue, 05 Jan 2021 23:55:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Learn Prolog in 2021?]]>
            </title>
            <description>
<![CDATA[
Score 253 | Comments 157 (<a href="https://news.ycombinator.com/item?id=25652369">thread link</a>) | @triska
<br/>
January 5, 2021 | http://dstrohmaier.com/why-learn-prolog-in-2021/ | <a href="https://web.archive.org/web/*/http://dstrohmaier.com/why-learn-prolog-in-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

  <header>
    
    <p>
      <span>By David Strohmaier</span>
      <time>· Jan 5, 2021</time>
    </p>
  </header>

  

<p>Why should one learn Prolog in 2021? I should better have an answer to this question, because I will soon offer supervisions for a Prolog course. While I’m a personal admirer of this unusual programming language, students might rightfully demand a justification that goes beyond my preferences. Prolog certainly isn’t the most glamorous programming language to learn in 2021. Despite its lack of popularity, there are good reasons to learn Prolog and in the following, I’ll explore three of them.</p>

<h2 id="the-sheer-intellectual-beauty">The Sheer Intellectual Beauty</h2>

<p>Perhaps my background in philosophy helps explain my fondness for Prolog. Not only is first-order predicate logic taught to virtually all philosophy students as a tool for thought, but it also forms the foundation of Prolog’s logic-programming paradigm. Philosophers aim for a logical description of the world and Prolog goes beyond this ambition by allowing us to manipulate reality via a logical description. We solve problems by writing Horn clauses, and a Horn-clause is a logical formula that simplifies resolution. Logical formulas are the tool of problem solving. Once grasped, the idea of logically describing a problem and the having the computer solve it is almost irresistible.</p>

<p>Of course, occasionally Prolog falls short of the programming-by-description-paradigm. There are cases where Prolog mixes logic and control instead of keeping them apart.[0] Nonetheless, logic programming, the paradigm of which Prolog is the primary example, comes with its own intellectual appeal. From the perspective of intellectual aesthetics, good Prolog code is a sublime experience (<em>erhabene Erfahrung</em>).[1] Such Prolog code reveals the overwhelming power of logical description and the force of a capacity – the capacity to describe the world in logical terms and thereby solve problems – that resides in all of us.</p>

<p>In sum, Prolog code has a timeless beauty to it – a claim that I believe is more commonly associated with the S-expressions of LISP – and is therefore worth learning. I am aware that an appeal to beauty has its limits, but the aesthetic properties of a programming language should not be entirely discounted. Our sense for intellectual beauty is an important tool for creation and it needs to be trained. If one understands what makes an approach beautiful, it becomes easier to create beautiful code and to resist the lure of beauty when it distracts from practical concerns. Learning Prolog is a way to tame the power of beautiful code.</p>

<div><div><pre><code>?- beautiful(prolog).
true
</code></pre></div></div>

<h2 id="a-different-perspective-on-classical-issues">A Different Perspective on Classical Issues</h2>

<p>Recursion, list manipulations, and graph-hopping are standard topics of foundational computer science and Prolog addresses them with a twist.[2] Prolog offers a different perspective on classical issues of computer science, usually right away from the first lessons. As a result, Prolog has a relatively steep learning curve, but the different perspective can also be revelatory. One learns to describe classical problems in the format of Prolog Horn-clauses and thereby solve them, which can lead to a unique way of understanding them – especially, once one has learned to write <em>idiomatic</em> Prolog.</p>

<p>Prolog is not only beautiful, but it also reveals another aspect of the core issues of computer science to which it is applied. Occasionally, the aspect Prolog reveals is also the aspect that needs to be seen for solving a problem. Some problems call for Prolog. Having learned Prolog will allow one to address them beautifully and efficiently. To be honest, at the moment such problems are too rare to justify learning Prolog. But I don’t believe that this has to remain so. As my last argument in favour of learning Prolog, I will suggest that it has unfulfilled potential.</p>

<div><div><pre><code>?- unique_perspective(prolog).
true
</code></pre></div></div>

<h2 id="unfulfilled-potential">Unfulfilled Potential</h2>

<p>As a student of computer science, one can make a decent career by always following the hype, but to stand out one has to diverge from the well-trodden paths. Those willing to explore unpopular territory have a chance of being ahead of the crowd. In 2021, Prolog is such unpopular territory. In my field of NLP, one might instead opt to learn more about neural networks and especially the Transformer architectures such as BERT. Learning about these topics is certainly advisable for a career in NLP, but it won’t make one stand out.</p>

<p>Prolog is unpopular and, more importantly, I believe that it has not fulfilled its potential so far. The logic-programming paradigm with its separation between logic and control is powerful. Yet it does not find much use in current applications. This unpopularity despite power might deter a student from learning Prolog – perhaps logic-programming has faults which keep its from being successful – but it is also an opportunity. One can make the bet that more will come of Prolog or a language similar to it.[3] If the bet is successful, one will be ahead of the hype.</p>

<p>Such bets on unpopular options are risky. It is a high-reward bet because of the limited chances of success. That being said, I would advise making a few such bets in the course of one’s life. Even if nothing comes of them, they render life more interesting and help to show individual character. Perhaps one shouldn’t go all in on such a bet, but this consideration should justify the few hours of a Prolog course, when one gets academic credits in addition to being able to assess the unfulfilled potential of Prolog better.</p>

<div><div><pre><code>?- potential(prolog,Y), unfulfilled(Y).
true
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>Currently, Prolog does not belong to the most popular programming languages. Its logic programming paradigm makes it an outsider. Nonetheless, I’ve argued that there are good reasons to learn Prolog. The language is beautiful, it offers a different perspective on classic computer science issues, and it has unfulfilled potential. Whether you are motivated by aesthetic, academic, or career considerations, you have a reason to learn Prolog in 2021.</p>

<div><div><pre><code>learn(X) :- beautiful(X), unique_perspective(X), potential(X,Y), unfulfilled(Y).

?- learn(prolog).
true
</code></pre></div></div>

<p><em>UPDATE</em> This blog post made its way to the frontpage of Hacker News where it received a sizeable number of <a href="https://news.ycombinator.com/item?id=25652369">comments</a>. In response, I wrote a <a href="http://dstrohmaier.com/follow-up-why-learn-prolog-in-2021/">follow-up post</a>.</p>

<h3 id="footnote">Footnote</h3>

<p>[0] I’m referencing here Robert Kowalski’s formulation of Algorithm = Logic + Control.</p>

<p>[1] I hope Kantians can forgive me for treating the sublime (<em>das Erhabene</em>) as a type of beauty, neglecting Kant’s distinction.</p>

<p>[2] For an example, have a look at the quicksort implementation on <a href="https://www.metalevel.at/prolog/sorting">The Power of Prolog</a>.</p>

<p>[3] I’m not <a href="https://www.youtube.com/watch?v=kGQNeeRp4sM">the only one who has hopes for Prolog’s future</a>.</p>


  
  
  

  <tb>
      </tb>

</article></div>]]>
            </description>
            <link>http://dstrohmaier.com/why-learn-prolog-in-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25652369</guid>
            <pubDate>Tue, 05 Jan 2021 22:54:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Replaced Baremetrics and ChartMogul with Rake]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25652097">thread link</a>) | @ezekg
<br/>
January 5, 2021 | https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/ | <a href="https://web.archive.org/web/*/https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>In the early days of my business, I was a happy Baremetrics user. I was new to running a Software-as-a-Service (SaaS) business, I only had a handful of Stripe plans, and all I really wanted to know was my monthly recurring revenue (MRR). But fast-forward to 2020 and I was starting to transition into running Keygen full-time, and my needs as a solo-founder had changed quite a bit.</p>
<p>It wasn't too far into 2020 when I realized I wasn't getting the insights I needed from Baremetrics. I eventually tried switching to ChartMogul, both to see if I could get better visibility into my business, but also to save a few bucks, since I was also in the process of cutting out unneccesary costs after going full-time.</p>
<p>Instead of simply peeking MRR every single day, sometimes obsessively, I also wanted to get a better pulse on my conversion rate, and most of all, I wanted to get visibility into how long it actually takes customers to convert, and what types of customers convert. I figured, since I was already unhappy with Baremetrics and ChartMogul, I'd try my hand at calculating the metrics myself using a Rake task. I had just wrapped up the launch of a few new features, so I was looking for a change of pace anyways.</p>
<p>Scripting in Ruby is always a nice change of pace.</p>
<p>I'll walk you through the basics of using Rake to calculate some common business metrics. (Most of Keygen is a typical Ruby on Rails app, so this post will assume a Rails folder structure.)</p>
<p>Let's begin by creating a file for our Rake task,</p>
<pre><code>$ touch lib/tasks/money.rake
</code></pre>
<p>The Rake task we'll be working on makes a few assumptions, for the sake of brevity, such as assuming all subscriptions are billed monthly, as well as a lack of discounts (which I'd personally avoid anyways for B2B, but that's a blog post for another day.)</p>
<p>Feel free to adjust accordingly.</p>
<p>Next, let's add the Rake task boilerplate,</p>
<pre><code>require 'stripe'

desc 'get revenue report'
task money: :environment do
  puts 'Hello, world!'
end
</code></pre>
<p>And we can run it by using this command,</p>
<pre><code>$ rake money
&gt; Hello, world!
</code></pre>
<p>Har har. (Credit to <a href="https://twitter.com/geetfun/status/1337220581087981568">@geetfun</a> for that one.)</p>
<h2 id="retrieving-subscription-data">Retrieving subscription data</h2>
<p>So first thing's first — we'll need to get an array of all of our Stripe subscriptions. This is the main dataset that we'll be using for our calculations.</p>
<pre><code>Stripe.api_key = ENV.fetch('STRIPE_SECRET_KEY')

subscriptions =
  Stripe::Subscription.list(status: 'all', limit: 100, expand: ['data.customer'])
    # Retrieve all subscriptions, following pagination until complete.
    .auto_paging_each
    .to_a
    # Filter out deleted customers.
    .filter { |s| !s.customer.deleted? }
    # Remove duplicate subscriptions per-customer. Keep the latest.
    .sort_by { |s| [s.customer.id, -s.created] }
    .uniq { |s| s.customer.id }
</code></pre>
<p>(You may want to cache the data if you're planning on running this task a few times during development, or multiple times a day, as it can be a bit long running if you have a large number of subscriptions.)</p>
<h2 id="calculating-mrr">Calculating MRR</h2>
<p>And now for the big show! Let's calculate that ubiquitous SaaS metric: Monthly Recurring Revenue (MRR). To start, we'll get an array of our paid subscriptions,</p>
<pre><code>paid_subscriptions = subscriptions.filter { |s| s.status == 'active' }
</code></pre>
<p>(One quirk here is that we're not including subscriptions with an <code>over_due</code> status. This status is used when a subscription is still "active", but has 1 or more invoice that hasn't been paid and is overdue. We may still want to consider these users a "paid user" until their subscription is fully canceled, given they also have at least 1 paid invoice. More on invoices later, though.)</p>
<p>Next, we'll need to create an array of our monthly revenue per-user,</p>
<pre><code>revenue_per_user = paid_subscriptions.map { |s| s.plan.amount.to_f * s.quantity / 100 }
</code></pre>
<p>(If you have annual plans, you'll need to adjust <code>revenue_per_user</code> to account for that. This is also where you'd want to apply any discounts.)</p>
<p>Finally, we can sum that up to get our MRR,</p>
<pre><code>monthly_recurring_revenue = revenue_per_user.sum(0.0)
</code></pre>
<h2 id="calculating-arr">Calculating ARR</h2>
<p>Now that we have our MRR, it's super simple to calculate our Annual Run Rate (ARR),</p>
<pre><code>annual_run_rate = monthly_recurring_revenue * 12
</code></pre>
<h2 id="calculating-arpu">Calculating ARPU</h2>
<p>Our MRR calculation used our <code>revenue_per_user</code> variable, which is also useful to calculate Average Revenue Per-User (ARPU),</p>
<pre><code>average_revenue_per_user =
  revenue_per_user.sum(0.0) / revenue_per_user.size
</code></pre>
<h2 id="calculating-conversion-rate">Calculating conversion rate</h2>
<p>One of the most important metrics for my business is conversion rate. This tells me how many of the new sign ups coming in actually turn into paying customers ("new" sign ups, meaning those within the last 30 days). If I was going to optimize anything, it would be this metric right here. You can stuff more leads into the funnel, but if they aren't converting in the first place, it's all for naught.</p>
<p>Calculating our conversion rate is relatively simple,</p>
<pre><code>new_paid_subscriptions = paid_subscriptions.filter { |s| s.created &gt;= 1.month.ago.to_i }
new_subscriptions = subscriptions.filter { |s| s.created &gt;= 1.month.ago.to_i }
</code></pre>
<p>We get an array of our new paid customers and an array of all new subscriptions, for the past 30 days, then we divide the size of <code>new_paid_subscriptions</code> by the size of <code>new_subscriptions</code>,</p>
<pre><code>conversion_rate = new_paid_subscriptions.size.to_f / new_subscriptions.size * 100
</code></pre>
<p>This gives us the percentage of new sign ups that convert. (More on this later.)</p>
<h2 id="calculating-churn-rate">Calculating churn rate</h2>
<p>Another very useful metric is churn rate. This tells us how many of our customers cancel their subscription in a given time period.</p>
<p>Calculating our churn rate require a few things up front,</p>
<pre><code>canceled_subscriptions = subscriptions.filter { |s| s.status == 'canceled' }
churned_subscriptions =
  canceled_subscriptions
    # Select only recent cancelations.
    .filter { |s| s.canceled_at &gt;= 1.month.ago.to_i || s.ended_at &gt;= 1.month.ago.to_i }
    # Filter out customers who never added a payment method, i.e. an unconverted trial.
    .filter { |s| s.customer.default_source.present? }
</code></pre>
<p>Here, we get an array of all canceled subscriptions, and then filter that down into our final churned subscriptions array, containing canceled subscriptions in the past month that have a payment method added. (We could improve this by scanning for paid invoices instead of looking at whether or not the customer has a payment method, but once again, we'll dive more into invoices later.)</p>
<p>Next, we'll need to get a count of our subscribers at the start of the month,</p>
<pre><code>paid_subscriptions_count_at_period_start =
  (paid_subscriptions.size - new_paid_subscriptions.size) + churned_subscriptions.size
</code></pre>
<p>Getting that number, even though we aren't storing historical data to look back in time 30 days, actually isn't as hard as you'd think.</p>
<p>We can subtract our <code>new_paid_subscriptions</code> count from our current <code>paid_subscriptions</code> count, and then add our <code>churned_subscriptions</code> count to that (since they were paying subscribers in the previous period). That should get us the number we're looking for, given you don't do anything weird with your customer/subscription objects, e.g. delete them.</p>
<p>Finally, we can calculate our churn rate,</p>
<pre><code>churn_rate =
  churned_subscriptions.size.to_f / paid_subscriptions_count_at_period_start * 100
</code></pre>
<h2 id="calculating-ltv">Calculating LTV</h2>
<p>Another useful metric is a user's life-time value, or rather, the average of all users' life-time values, also referred to as LTV.</p>
<p>To calculate our LTV, we'll need to retrieve an array of all of our "converted" subscribers,</p>
<pre><code>converted_subscriptions =
  (paid_subscriptions + canceled_subscriptions)
    # Filter out canceled customers who never added a payment method.
    .filter { |s| s.customer.default_source.present? }
</code></pre>
<p>We may only want to pay attention to subscriptions within a certain timeframe, e.g. 1 year, but I'll leave that as-is for now, which will give us our overall LTV.</p>
<p>Next, we'll get the subscription duration, in months, of all converted subscribers,</p>
<pre><code>subscription_durations =
  converted_subscriptions
    .map { |s| ((s.ended_at || Time.now) - s.created) / 1.month }
</code></pre>
<p>Then we'll get the average subscription duration,</p>
<pre><code>average_subscription_duration =
  subscription_durations.sum(0.0) / subscription_durations.size
</code></pre>
<p>Finally, we'll multiply our ARPU by our average subscription duration,</p>
<pre><code>life_time_value =
  average_revenue_per_user * average_subscription_duration
</code></pre>
<p>The resulting number is our LTV.</p>
<h2 id="calculating-revenue-growth-rate">Calculating revenue growth rate</h2>
<p>The last metric we'll calculate is our Revenue Growth Rate. This will give us a percent change for our MRR, compared to the previous month.</p>
<p>First, we'll want to get our current MRR, which we already have from our previous calculations. Then, we'll want to get our previous month's MRR.</p>
<p>But how?</p>
<p>We'll do a few things:</p>
<ol>
<li>We'll need to take our current MRR, <code>monthly_recurring_revenue</code>.</li>
<li>Subtract our "new" revenue from it (think: <code>new_paid_subscriptions</code>).</li>
<li>Add our "lost" revenue back in (think: <code>churned_subscriptions</code>).</li>
</ol>
<p>This total should give us our MRR for the previous period, i.e. 30 days ago.</p>
<p>Where's the code? Well, I'll leave this one up to the reader.</p>
<p>But here's the gist of it,</p>
<pre><code>next_mrr = monthly_recurring_revenue
prev_mrr = (next_mrr - new_revenue) + lost_revenue
revenue_growth_rate =
  (next_mrr - prev_mrr) / prev_mrr * 100
</code></pre>
<h2 id="improving-our-dataset">Improving our dataset</h2>
<p>Our base subscription dataset is relatively simple, being an array of subscription objects, and we could actually improve it a bit to garner more insights. One way to do that would be to scan a subscription's (or customer's) invoices to determine if they've "converted" vs. simply looking at the subscription's <code>status</code> attribute.</p>
<p>You can retrieve a subscription's invoices like so,</p>
<pre><code>invoices =
  Stripe::Invoice.list(subscription: subscription.id, limit: 100)
    .auto_paging_each
    .to_a
</code></pre>
<p>But do keep in mind that this type of operation is very expensive — retreiving all invoices for all subscriptions is going to result in an N+1 query, meaning lot of Stripe API requests, and a long time spent staring at a seemingly frozen terminal. When I request invoices for a set of subscriptions, I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/">https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/</a></em></p>]]>
            </description>
            <link>https://keygen.sh/blog/how-i-replaced-baremetrics-and-chartmogul-with-rake/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25652097</guid>
            <pubDate>Tue, 05 Jan 2021 22:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kingdom: Sikkim’s merger with India]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25651871">thread link</a>) | @seventyhorses
<br/>
January 5, 2021 | https://fiftytwo.in/story/kingdom/ | <a href="https://web.archive.org/web/*/https://fiftytwo.in/story/kingdom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-2fd21b62=""><div data-v-2fd21b62=""><p>
                I
              </p> <div data-v-2fd21b62=""><p>n December 1972, Indira Gandhi, fresh from victory in the 1971 war for Bangladesh’s liberation, summoned Rameshwar Nath Kao to her office. In 1968, she had handpicked this tall Kashmiri with a formidable intellect to set up the R&amp;AW. In three years’ time, Kao had delivered the agency’s first significant success, providing critical support for the covert training of the guerrilla army Mukti Bahini in what was then East Pakistan. </p><p>“Can you do something about Sikkim?” she asked him. </p></div></div><p>Relations between the Indian state and the kingdom had reached a stalemate. India wanted to create a treaty of Permanent Association, even dangling the carrot of sponsoring Sikkim’s membership to UN organisations in return. But over the 1960s, the Chogyal had been demanding full independence with increasing vigour.&nbsp; </p><p>In the Chogyal’s backyard, the demand for merger with India had originated from the first leader of the Sikkim State Congress,
            <a href="" onclick="return!1">
              <sup id="bcb14wl0cgeu">[7]</sup>
            </a>
           Tashi Tshering, who had even gone to Delhi in 1948 to negotiate it. Patel, the man in charge of India’s integration, was keen on bringing Sikkim into the fold. Nehru chose to overrule him and sent Tshering back.
            <a href="" onclick="return!1">
              <sup id="aexroa2fiai3">[8]</sup>
            </a>
          </p><p>But Nehru’s India kept more than a watchful eye over Sikkim, much like the British had. “The Sikkimese kingdom became highly dependent on the political officers from the time that the British established direct control of Sikkim,” Saul Mullard, a researcher at  Oxford University and author of a book of Sikkimese history, explained. “Indians took over the role of political officers in Sikkim. They inherited the authority of the British and it weakened the ability of the king to set his own agenda.”</p><p>After Indira Gandhi asked him to “do something” about Sikkim, Kao concocted a plan with PN Banerjee, the joint secretary of the R&amp;AW’s eastern division and a fellow mastermind of the Bangladesh operation. He assured the prime minister that the R&amp;AW could handle Sikkim’s merger.
            <a href="" onclick="return!1">
              <sup id="q7tj6bpso0c1">[9]</sup>
            </a>
           A three-member special ops team was dispatched to Gangtok.</p><p>One of these men was GBS Sidhu, who maintained a meticulous diary of his time in Gangtok. He wrote his book at the prodding of his former boss, who had always been keen for the story of the R&amp;AW’s role in Sikkim to be made public someday. On his passing in 2002, Kao’s own notes on the operations in Sikkim and Bangladesh were handed over to the Nehru Memorial Museum and Library. These will be made public in 2027, according to his will.</p><p>To preserve its reputation as a country that respected the sovereignty of its smaller neighbours, India was keen to legitimize its takeover of Sikkim. It made common cause with the political movement started by Tashi Tshering. India would maintain that the merger was a natural consequence of the peoples’ desire for a democratic form of government. The denouement that came with the coup took more than two years of meticulous planning on the part of the Indian state. </p><p>Like its neighbours Tibet and Bhutan, Sikkim was a conservative Buddhist theocracy. The ruling elite came from two communities: the Bhutia, who migrated from Tibet in the thirteenth century, and the Lepcha, indigenous to Sikkim. The royal family of Namgyals were Bhutia who’d come from Tibet in the sixteenth century. The demographic dynamic of Sikkim started shifting in the late nineteenth century, when Jean Claude White, the first British political officer of Sikkim, began to bring in labour from Nepal to build roads and cultivate land.</p><p>There was another reason why the British encouraged Nepali immigration—to counteract Tibetan influence in Sikkim. There were close religious, cultural and political ties between the two kingdoms. White’s successors tried to undo the policy, but by the early twentieth century, the native population of Bhutia and Lepcha people was already a minority.</p><p>From the 1940s onwards, this, then, was the defining divide in Sikkim’s politics: the tension between its powerful minority and the landless and disenfranchised Nepalis, who had grown to 75 percent of the population by the 1970s. The Chogyal’s inability to provide political representation for the majority of his subjects became his Achilles heel. The R&amp;AW recognized this and surreptitiously worked to exploit it. </p><p>The Sikkim operation helped Kao cement his legacy and strengthen India’s position in relation to China. “It is a fantastic piece of work, handled in a way that it took place under the cover of democracy in process,” the former R&amp;AW officer Rana Banerji, who’s studied the Sikkim papers in the archives of the R&amp;AW’s Kolkata office, told me in a phone interview. “It showed a lot of derring-do and vision, and gave tremendous impetus to the newly-formed agency.” </p><p>Sidhu drove the operation for 26 months from February 1973 to April 1975. He was flattered to be a ‘Kaoboy’, the moniker given to the spies who were personally mentored by Kao. His book is littered with references to clandestine meetings, secured phone calls and secret memos. But Sikkim was not a regular intelligence operation. Sidhu called it a “collaborative effort” between the R&amp;AW and the political parties. “While merger was the ultimate goal, this had to be achieved in stages and through constitutional means,” he wrote. </p><p>First, Sidhu had to reassure pro-democracy leaders that India was changing its policy towards the Chogyal—it was now inclined to support their agitation with logistical and financial assistance. On the ground, the R&amp;AW worked to encourage popular support and escalate protests against the monarchy. All anti-Chogyal political parties were merged under the leadership of Kazi Lhendup Dorji’s Sikkim National Congress. The aim was to compel the Chogyal to seek India’s assistance in restoring law and order. </p><p>On 4 April 1973, the Chogyal's birthday, thousands of protestors gathered outside the palace in Gangtok. It was the culmination of weeks of planning. The protests turned violent and raged for days. On 6 April, when Indira Gandhi’s principal secretary PN Dhar and foreign secretary Kewal Singh met her to apprise her of the situation in Gangtok, they found that she was in the know and was waiting for the Chogyal’s request for help. Dhar guessed that she had already been briefed by the R&amp;AW.
            <a href="" onclick="return!1">
              <sup id="zffsew5lutcg">[10]</sup>
            </a>
          </p><p>Two days later, India took administrative control of Sikkim. It was the beginning of the end. In May 1973, a tripartite agreement was signed between the government of India, the Chogyal and the political parties representing the people of Sikkim. Elections were held in 1974, and Kazi Lhendup Dorji became the kingdom’s first chief minister. A cable from the US Consulate in Delhi noted, “Prospects for the long-term survival of the Royal House do not look good.”
            <a href="" onclick="return!1">
              <sup id="57b2r22019hx">[11]</sup>
            </a>
          </p><p>However, at the beginning of 1975, the Chogyal remained to be toppled—and in him, Gandhi unexpectedly had a worthy opponent. </p></div></div>]]>
            </description>
            <link>https://fiftytwo.in/story/kingdom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25651871</guid>
            <pubDate>Tue, 05 Jan 2021 22:09:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Fast Shall We Play? (2011)]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25650969">thread link</a>) | @hoffmannesque
<br/>
January 5, 2021 | https://thebeethovenproject.com/how-fast-shall-we-play/ | <a href="https://web.archive.org/web/*/https://thebeethovenproject.com/how-fast-shall-we-play/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img title="Metronome" alt="" src="https://thebeethovenproject.com/wp-content/uploads/2011/03/iStock_000004290281XSmall-300x198.jpg" width="300" height="198" srcset="https://thebeethovenproject.com/wp-content/uploads/2011/03/iStock_000004290281XSmall-300x198.jpg 300w, https://thebeethovenproject.com/wp-content/uploads/2011/03/iStock_000004290281XSmall.jpg 426w" sizes="(max-width: 300px) 100vw, 300px">The subject of tempi in Beethoven’s quartets is a controversial one. These pieces have throughout the years entered the subconscious of professional musicians, amateurs and audience, and the tradition, handed down by the great quartets of yesteryear, has become a norm against which all subsequent performances are judged. The recordings and performances we grew up with and the interpretive choices the artists made have become an integral part of our outlook on the masterworks. And the choice of tempo in music that so many people dearly love can arouse strong feelings: When the Kolisch Quartet performed Beethoven’s Op. 95 quartet in Paris according to the indicated metronome markings, presumably in the second quarter of the last century, a fistfight ensued.</p>
<p>Unbeknownst to many, Beethoven himself very clearly indicated what tempi he envisioned using metronome indications that for many years seem to have been forgotten or disregarded, mainly because of their controversial nature. Even today, many look at them with suspicion, or simply ignore them. For many years they were absent from the editions altogether. In the recent Henle edition they were nowhere to be found in the parts (but in the preface to the score). The completely fresh Bärenreiter edition presents them as footnotes.</p>
<p>The metronome as we know it was invented by the Dutch mechanic Dietrich Nikolaus Winkel shortly after 1800, but the construction was copied by Johann Nepomuk Mälzel who patented it. A lawsuit ensued, Winkel won, but it was too late: Mälzel’s name had already become associated with the metronome. Beethoven had already become acquainted to the gifted inventor Mälzel when he asked him to construct a hearing aid for him. When Mälzel constructed a mechanical musical instrument, the <em>Panharmonicon</em>, Beethoven agreed to compose a special piece for it: “Wellington’s Victory”. Beethoven greeted the invention of the Mälzel metronome with great enthusiasm: he had for a growing amount of time been regarding the traditional tempo indications as insufficient:</p>
<p>“I have long been thinking of abandoning these nonsensical terms <em>allegro, andante, adagio, presto,</em> and Mälzel’s metronome gives us the best opportunity to do so. I give you my word here and now that I will never use them again in any of my new compositions.” (Letter to Hofrat von Mosel, 1817)</p>
<p>Shortly after, he published a declaration jointly with Salieri starting “Mälzel’s metronome is here!”, paying tribute to the invention. He went on to publish, in instalments, metronome markings for some of his most popular works, and ended up having provided tempo indications for all nine symphonies, the first eleven string quartets, the Septet and a handful of other pieces. Interestingly he never provided tempi for the late string quartets, although there is evidence he intended to.</p>
<p>During the 19th century it seems to have been increasingly difficult to get hold of the metronome indications. They had been regarded as controversial from the outset, and with the editors resistance to publishing them and the complete change in musical aesthetics of the latter part of the Romantic era, they fell into oblivion.</p>
<p>At the beginning of the 20th century, a growing number of performers started to take notice of them again. Rudolf Kolisch (1896–1978) of Kolisch Quartet fame and a pupil of Schönberg became one of their strongest proponents and Boulez’s teacher René Leibowitz (1913–1972) became the first conductor to perform Beethoven’s symphonies according to his metronome markings. In 1942 Kolisch gave the talk “Tempo and Character in Beethoven’s music” in New York, which was subsequently published the same year, and it was to play an important part in the debate on the tempi in Beethoven’s music that seems to have been ongoing ever since.</p>
<p><strong>Myths and Truths</strong></p>
<p>A number of myths surround the metronome markings of Beethoven, and many myths need to be put to rest, but also some truths acknowledged:</p>
<p><em>1. Beethoven’s metronome was faulty.</em></p>
<p>It still exists but lacks the heavy weight at the bottom of the pendulum. Because of the lack of the static weight, evaluation of its properties is unfortunately impossible.</p>
<p><em>2. Beethoven was deaf when he wrote the indications.</em></p>
<p>The story of Beethoven’s deafness is a rather more complicated issue than popularly assumed, and hopefully a subject of a future post on this blog. His deafness was increasing during his last 25 years, but he seems to have become <em>totally</em> deaf only by the end. The Mälzel metronome is in any case a mechanical one with the “arm” clearly visible, so tempo is also visually perceived.</p>
<p><em>3. Beethoven fell out with Mälzel over his metronome.</em></p>
<p>Untrue. Beethoven and Mälzel fell out in 1814 regarding the performance rights for “Wellington’s Victory”. Beethoven filed a legal complaint that was settled in court by a compromise. They were reconciled, and Beethoven went on to pay tribute to the metronome publicly.</p>
<p><em>4. Beethoven’s secretary Schindler refuted Beethoven’s adherence to metronome markings. </em></p>
<p>True, but Beethoven’s biographer and secretary Anton Schindler’s (1795–1864) writings have since been discredited. He falsified facts and exaggerated his close relation to the composer. “[V]irtually nothing he has recorded can be relied on unless it is supported by other evidence”, <em>The Beethoven Compendium</em> (1991) states. There are a number of famous Beethoven quotes originating from Schindler that tend to crop up in texts about the composer and these need to be questioned.</p>
<p><em>5. The pieces become unplayable and/or frantic if performed according to the metronome markings.</em></p>
<p>Hard, yes, but hardly unplayable. The subject of the frantic character is of course to some extent subjective.</p>
<p>Beethoven’s music had, already in his days, a revolutionary quality: extreme contrasts, sudden accents, quick dynamic shifts. These characteristics can go surprisingly well with the furious tempo Beethoven sometimes asks for.</p>
<p><em>6. The tempo Beethoven heard in his head is not what he really wanted.</em></p>
<p>This is the hardest one. A number of composers have been reported as actually playing their music at a slightly different speed than initially asked for in their metronome markings, and the actual performance tempo often tends to get a bit slower. Certainly some composers of the late romantic era are reported to have been free with tempi, and regarded the metronome markings mostly as a recommendation or a “starting tempo”. Then again, others (Bartók for instance) are specific about tempo in the most meticulous way, also between minute changes within a movement.</p>
<p>What we do know is that Beethoven regarded the tempi in his music as something primary in regard to the desired musical expression. Often, when he had not personally attended a certain concert, tempo was the first thing he inquired about.</p>
<p>“The metronome markings [for the Missa Solemnis] will be sent to you very soon. Do wait for them. In our century, such markings are certainly necessary; moreover I have received letters from Berlin informing me that the first performance of the [ninth] Symphony met with enthusiastic applause, which I ascribe largely to the metronome markings…” (Letter to Schott, Dedember 18, 1826)</p>
<p>he writes rather humbly.&nbsp; There is furthermore not any convincing evidence for any insensitivity on his part in adhering to his own metronome markings, so we must assume that they at least give a very clear indication of his intentions. And as Kolisch writes: “what really matters is the extent of the deviation.”</p>
<p><em>7. The size of the concert venues, the instruments and the playing styles of Beethoven’s day invite for a slightly quicker pace than with modern circumstances.</em></p>
<p>This seems to me true to a certain extent. The concert halls today are generally bigger and more resonant, and the players in Beethoven’s day used little vibrato and played on gut strings that react quicker than modern ones.</p>
<p><strong>From a performer’s perspective, and a little bit of humility</strong></p>
<p>A metronome marking gives us a basic indication of the composer’s intention regarding the speed and to a certain extent character of a piece. But within the piece there are of course innumerable deviations from that speed, which is not to be seen as a straight-jacket.</p>
<p>It seems that we have come to the conclusion not to deviate too much from the intentions of Beethoven at this early stage of our exploration of the quartets. Some of them have so far seemed just right and some a little fast. After having performed some of the movements for some time attempting to follow Beethoven’s intentions regarding speed, it seems like the choice of tempo has settled after a while at a pace that feels natural. When we have sensed that a certain theme does not work musically, the metronome marking has sometimes helped us back on track. The first movement of Op. 18:6 seems very fast indeed, and when we performed it a few years ago, we settled at a slower speed, but it is going to be interesting how we feel about it when we come back to it as part of The Beethoven Project.</p>
<p>We have been asked a few times about our choice of tempo in the last movement of Op. 59:3, the famous fugue movement: Beethoven gives a break-neck speed metronome indication and we still haven’t performed it at quite his speed, but close. It seems fast to many, but it also gives an edge of the seat, furious, even shocking quality to the music. The contrast to the unusually slow preceding minuet is tremendous. It seems to me that he knew what he was doing.</p>
<p>It is early days in our learning process of these quartets, and I am sure much will happen in the course of the project. Perhaps I will write a blog post in the future completely refuting the previous text!</p>
<p>Martin Saving</p>
<p>This article was amended in December 2013 regarding the state of Beethoven’s metronome.</p>
<p>Sources (amongst others): “Integral Interpretation: Introductory Notes to Beethoven, Kolisch and the Question of the Metronome”, Thomas Y. Levin. “Tempo and Character in Beethoven’s Music”, Rudolf …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thebeethovenproject.com/how-fast-shall-we-play/">https://thebeethovenproject.com/how-fast-shall-we-play/</a></em></p>]]>
            </description>
            <link>https://thebeethovenproject.com/how-fast-shall-we-play/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25650969</guid>
            <pubDate>Tue, 05 Jan 2021 21:00:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GUIDs Are Not the Only Answer]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25650907">thread link</a>) | @ublaze
<br/>
January 5, 2021 | https://www.softwareatscale.dev/p/guids-are-not-enough | <a href="https://web.archive.org/web/*/https://www.softwareatscale.dev/p/guids-are-not-enough">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">Global Unique Identifiers</a> (GUIDs), also known as Universally Unique Identifiers (UUIDs) can be used as practically unique identifiers in systems.</p><p>GUIDs have many advantages. You can safely generate identifiers in a distributed setting, compared to a central identifier registrar. Many systems are vulnerable to <a href="https://portswigger.net/web-security/access-control/idor">Insecure Direct Object Reference</a> attacks, and even though permissions should always be checked for any access, it’s much easier to exploit these with sequential IDs compared to GUIDs (<a href="http://debarghyadas.com/writes/hacking-into-the-indian-education-system/">a high profile example</a>). Sequential IDs can leak <a href="https://news.ycombinator.com/item?id=14524061">important information</a>. Modern databases have custom <a href="https://www.postgresql.org/docs/current/datatype-uuid.html">in-built</a> UUID types which have <a href="https://stackoverflow.com/a/29882952/3399432">less storage overhead</a> and perform better than using a text type. There’s tons of <a href="https://www.clever-cloud.com/blog/engineering/2015/05/20/why-auto-increment-is-a-terrible-idea/">blogs</a> extolling the benefits of GUIDs.</p><p>But anecdotally, there’s too many cases where raw GUIDs are used as identifiers, even though they might not be the appropriate choice.</p><h2>Challenges</h2><p>By their nature, GUIDs are opaque values that don’t lend too much information about what they’re identifying. They’re also generally unergonomic due to their length and structure. It’s almost trivially obvious that GUIDs shouldn't be in URLs due to their <a href="https://wiki.c2.com/?DontPutGuidsInUrls">poor aesthetics</a>. To steal an example from <a href="https://blog.codinghorror.com/primary-keys-ids-versus-guids/">Coding Horror</a>, database queries at the REPL can become frustrating.</p><pre><code>$ select * where userid='{BAE7DF4-DDF-3RG-5TY3E3RF456AS10}'</code></pre><p>Poorly formatted log statements/errors can become harder to debug, since the identifiers don’t tell us what they’re identifying: </p><pre><code><code>error processing BAE7DF4-DDF-3RG-5TY3E3RF456AS10: nil</code></code></pre><p>This can be mitigated by having libraries that report stack traces/line numbers and help identify the exact line of code with the error, so in general, UUIDs often need context to aid debugging.</p><p>Moreover, the lack of type safety of using raw integers and raw UUIDs can cause <a href="https://rachelbythebay.com/w/2018/04/27/uid/">horrifying problems</a> and is emblematic of lack of type safety with identifiers. With poor naming in code, it’s very easy to cause problems. Consider a variation of the example from the linked blog:</p><pre><code>def get_team_and_user_ids() -&gt; List[Tuple[UUID, UUID]]:
  """Returns a tuple of (team_id, user_id) tuples"""
  ...

def ban(user_id: UUID) -&gt; None: ...

for (user, team) in get_team_and_user_ids():
    ban(user)</code></pre><p>The script might just error out since UUIDs between users and teams aren’t shared, but the consequences might have been worse with integer IDs.</p><h2>Designing your Identifiers</h2><p>Identifiers should be designed for the properties of object they’re going to be identifying. We can mix and match components based on the importance of mutability, debuggability, performance and privacy for the object. For example, identifiers for permanent or external objects like customers should be treated differently to ephemeral or internal objects like tasks/jobs.</p><p><strong>Structure identifiers with prefixes and hierarchies</strong></p><p>Often for internal objects, debuggability is key, and prefixes can help with debugging. For example, all task identifiers could have the prefix “task-”. This automatically makes context free debugging easier, and makes it easy to grep for all messages that have IDs:</p><pre><code>error processing task-2: nil</code></pre><p>Hierarchies help even more with debuggability. Let’s say that every “Job” spawns N “Tasks”. Tasks IDs might want to contain their job IDs, so that it becomes trivially simple to grep for tasks of a particular job. For example, a task ID would look like: `job-123-task-1`. This also helps in ad-hoc database queries to find relevant rows without complex JOINs. We have examples of this in real life, like area codes in phone numbers.</p><p>We can add constant prefixes/hierarchies to any existing ID type. Critics might point out that storing a prefix with a UUID is wasteful since we’d lose the benefits of database optimized UUID types. This can easily be mitigated by storing un-prefixed UUID in the database, and application code automatically prepends a prefix for client code to use, but this might add some complexity.</p><p><strong><a href="https://en.wikipedia.org/wiki/Content-addressable_storage">Content Addressability</a></strong></p><p>Sometimes, we want a zero inconsistency approach to storing objects, so it might make sense to make the identifier (or part of it) the checksum of the content that is to be stored. This guarantees that the underlying content has not been modified. Git does this with SHA1 commit hashes (<a href="https://git-scm.com/docs/hash-function-transition/">even though this is being migrated to SHA256 as of December 2020</a>). <a href="https://bazel.build/">Bazel</a> (build system) uses a Content Addressable Store for <a href="https://docs.bazel.build/versions/master/remote-caching.html">remote caching</a>.</p><p><strong>Semi sortability</strong></p><p>If you need basic sortability and don’t mind the privacy concerns, consider using a scheme like Segment’s <a href="https://github.com/segmentio/ksuid">KSUID</a>. This side-steps use of sequential IDs which will be painful to migrate away from. <a href="https://github.com/segmentio/ksuid#2-collision-free-coordination-free-dependency-free">UUID1 has some known issues</a>.</p><h2>Type Safety</h2><p>At the very least, identifiers should not be allowed to float freely as strings or integers in order to prevent a class of inconsistency bugs. SQLAlchemy, a database manipulation library in Python, lets user implement a custom <a href="https://docs.sqlalchemy.org/en/14/core/custom_types.html#sqlalchemy.types.TypeDecorator">TypeDecorator</a> (and has native support for Postgres UUIDs). Let’s reproduce an <a href="https://stackoverflow.com/a/49398042/3399432">example</a> with some tweaks:</p><pre><code>from sqlalchemy.dialects.postgresql import UUID
from flask_sqlalchemy import SQLAlchemy
import uuid
from typing import NewType

db = SQLAlchemy()

FooId = NewType("FooId", bound=UUID)

class Foo(db.Model):
    id = db.Column(FooId(as_uuid=True), primary_key=True, 
                   default=uuid.uuid4, unique=True)</code></pre><p>With a custom type “FooId” being marked as the column type, <a href="https://mypy.readthedocs.io/en/stable/">type checking</a> will prevent other ID types or raw UUID types there.</p><h2>Conclusion</h2><p>We’ve seen that there’s a fair amount of complexity involved in id management and decision making. Some high scale applications end up deploying <a href="https://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/">custom ID generation</a> services. Identifiers are an early, hard to reverse decision that affect even schemaless datastores, so they’re worth thinking about in advance, and the right decision can compound developer productivity and prevent painful infrastructure migrations down the road.</p></div></div>]]>
            </description>
            <link>https://www.softwareatscale.dev/p/guids-are-not-enough</link>
            <guid isPermaLink="false">hacker-news-small-sites-25650907</guid>
            <pubDate>Tue, 05 Jan 2021 20:56:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting root on a 4G LTE mobile hotspot]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25650686">thread link</a>) | @todsacerdoti
<br/>
January 5, 2021 | https://alex.studer.dev/2021/01/04/mw41-1 | <a href="https://web.archive.org/web/*/https://alex.studer.dev/2021/01/04/mw41-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p><i></i> January 4, 2021
	</p>
	<p>I have an <a href="https://www.alcatelmobile.com/product/mobile-broadband/mobile-wifi/linkzone-cat4-mobile-wi-fi/">Alcatel MW41</a> mobile hotspot. It works fine, but it seems to have some firmware running on it (more specifically, it’s running a web server to give you an interface to change different options), which raises two questions: 1) does it run Linux? and 2) can we get root on it?</p>

<p>Some research led me to find that it did, in fact, run Linux. Not only that, but there was a tool that would just give me root access to the hotspot, by the name of TCL-SWITCH-TOOL! <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> Apparently, this tool relied on the fact that the hotspot showed up as an external disk when you connect it to a computer. It did <em>something</em> that switched the hotspot into a debug mode, giving you a root shell.</p>

<p>The tool is Windows-only, but it’ll probably just work under <a href="https://www.winehq.org/">Wine</a>, right? I downloaded the tool, ran it, hit the “switch to debug mode” button, and….</p>

<!--more-->

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/tcl-switch.png">
		<img src="https://alex.studer.dev/assets/mw41-1/tcl-switch.png" title="“50”." alt="“50”.">
	</a>
	<figcaption><p>“50”.</p>
</figcaption>
</figure>

<p>“50”. Hmm. Closing that message gave another error:</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/tcl-switch-2.png">
		<img src="https://alex.studer.dev/assets/mw41-1/tcl-switch-2.png" title="(it didn’t work)" alt="(it didn’t work)">
	</a>
	<figcaption><p>(it didn’t work)</p>
</figcaption>
</figure>

<p>And, in the terminal I used to run the program, I saw a warning message: <code>0009:fixme:ntdll:server_ioctl_file Unsupported ioctl 4d014 (device=4 access=3 func=405 method=0)</code>. This seems to suggest that the program relies on some feature that Wine doesn’t support fully.</p>

<p>At this point, I could probably find an actual Windows computer and just use that. But that’s no fun! Can we figure out how this program works, and replicate it ourselves?</p>

<h2 id="what-does-it-even-do">What does it even do?</h2>
<p>I decided to open the program in <a href="https://ghidra-sre.org/">Ghidra</a>, a reverse engineering tool. Searching for the error message from before, “switch device error”, I found that there were multiple references to the string, and they all seemed to be part of relatively complex functions. It would definitely be possible to analyze what the program is doing this way, but is there an easier method?</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/switch-device-error.png">
		<img src="https://alex.studer.dev/assets/mw41-1/switch-device-error.png" title="As shown in the XREF list, there are four different functions that refer to this string." alt="As shown in the XREF list, there are four different functions that refer to this string.">
	</a>
	<figcaption><p>As shown in the XREF list, there are four different functions that refer to this string.</p>
</figcaption>
</figure>

<p>Well, given that the program asks for the drive letter corresponding to the hotspot, it seems reasonable to assume that it’s somehow sending some special command to the drive over that existing connection (as opposed to, say, some weird custom USB protocol). This seems to be confirmed by the presence of the string <code>\\.\PHYSICALDRIVE%c</code>, which presumably is some way to directly access the drive?</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/physical-drive.png">
		<img src="https://alex.studer.dev/assets/mw41-1/physical-drive.png" title="The mysterious `\\.\PHYSICALDRIVE%c` string." alt="The mysterious `\\.\PHYSICALDRIVE%c` string.">
	</a>
	<figcaption><p>The mysterious <code>\\.\PHYSICALDRIVE%c</code> string.</p>
</figcaption>
</figure>

<p>Let’s assume that the program somehow opens the drive and then does some magic incantation to switch the hotspot into a debug mode. No matter how complicated TCL-SWITCH-TOOL is, at the end of the day, both of those operations will eventually need to go through the Windows API, which is external to this program.</p>

<p>We can monitor those API calls by using <a href="https://wiki.winehq.org/Wine_User%27s_Guide#WINEDEBUG.3Dchannels">Wine’s debug options</a> to enable the <a href="https://wiki.winehq.org/Debug_Channels#Useful_Channels"><code>relay</code> debug channel</a>. This logs every time TCL-SWITCH-TOOL makes a function call to an external library (what Windows calls a DLL). The hope is that we’ll see the function calls to whatever Windows DLL is responsible for opening the drive and sending those commands. That should then give us a better idea of what the program is actually doing. <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>So, I ran <code>WINEDEBUG=relay wine TCL-SWITCH-TOOL.exe &amp;&gt; tcllog.log</code>, typed in the drive letter, and hit the button to switch the hotspot into debug mode. This resulted in a rather large log file. <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> I searched for the <code>PHYSICALDRIVE</code> string from before, and…nothing. Since that didn’t work, I decided to look for the drive letter I used (<code>F</code>), figuring that the tool probably had to somehow communicate the selected drive letter to Windows.</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/relay-log.png">
		<img src="https://alex.studer.dev/assets/mw41-1/relay-log.png" title="The various function calls logged by Wine." alt="The various function calls logged by Wine.">
	</a>
	<figcaption><p>The various function calls logged by Wine.</p>
</figcaption>
</figure>

<p>That actually seemed to work! In this log, each line corresponds to either a function call (labeled as <code>Call</code>) or a function returning (labeled as <code>Ret</code>). At the top, you can see that TCL-SWITCH-TOOL calls <code>CreateFileA</code>, part of <code>KERNEL32</code>, on <code>\\.\\F:</code>. <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> Then, Wine’s implementation of <code>KERNEL32</code> makes some function calls of its own and finally decides to return a value. (that’s the <code>009:Ret KERNEL32.CreateFileA()</code> line at the bottom) After that, TCL-SWITCH-TOOL decides to make another call, this time to <code>KERNEL32</code>’s <code>DeviceIoControl</code> function, which seems like what we’re looking for. And, this function call has one parameter equal to <code>4d014</code>, which matches the error message we got from Wine all the way at the beginning! <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup></p>

<p>So, what is <code>DeviceIoControl</code>? Looking at the <a href="https://docs.microsoft.com/en-us/windows/win32/api/ioapiset/nf-ioapiset-deviceiocontrol">official Microsoft documentation</a>, it seems to be a fairly generic function that does something based on the <code>dwIoControlCode</code> parameter. <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> In our case, <code>dwIoControlCode</code> is <code>0x4d014</code>, corresponding to <a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/ntddscsi/ni-ntddscsi-ioctl_scsi_pass_through_direct">IOCTL_SCSI_PASS_THROUGH_DIRECT</a>, which, according to that page, “allows an application to send almost any SCSI command to a target device.”</p>

<h2 id="finding-the-command">Finding the command</h2>
<p>By this point, it seems likely that this is the magic debug mode incantation. But what’s the actual SCSI command? Going back to Ghidra, we can pull up DeviceIoControl, and see where it’s called from. <sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup></p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/deviceiocontrol.png">
		<img src="https://alex.studer.dev/assets/mw41-1/deviceiocontrol.png" title="The reference to KERNEL32.dll’s DeviceIoControl." alt="The reference to KERNEL32.dll’s DeviceIoControl.">
	</a>
	<figcaption><p>The reference to KERNEL32.dll’s DeviceIoControl.</p>
</figcaption>
</figure>

<p>The thing that says <code>XREF</code>, on the right, tells us that this function has one reference in the entire program. (that is, it’s only used once) Double-clicking on that gives us the code that makes the DeviceIoControl call:</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/deviceiocontrol-xref.png">
		<img src="https://alex.studer.dev/assets/mw41-1/deviceiocontrol-xref.png" title="The one usage of DeviceIoControl." alt="The one usage of DeviceIoControl.">
	</a>
	<figcaption><p>The one usage of DeviceIoControl.</p>
</figcaption>
</figure>

<p>At this point, we could go through the assembly in Ghidra and determine how the various arguments to DeviceIoControl are constructed. However, there’s an easier way. We know now that the function call is at address <code>0x4031d4</code>. So, we can use <a href="https://wiki.winehq.org/Wine_Developer%27s_Guide/Debugging_Wine">Wine’s debugger</a> to set a breakpoint at that address, run the program, and then, once it hits our breakpoint, print out the various arguments. <sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup></p>

<p>So, I ran <code>winedbg --gdb TCL-SWITCH-TOOL.exe</code>, used the <code>b *0x4031d4</code> command to set the breakpoint, and tried the program again.</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/breakpoint.png">
		<img src="https://alex.studer.dev/assets/mw41-1/breakpoint.png" title="Setting (and hitting!) the breakpoint." alt="Setting (and hitting!) the breakpoint.">
	</a>
	<figcaption><p>Setting (and hitting!) the breakpoint.</p>
</figcaption>
</figure>

<p>It hit the breakpoint! Now, how do we know what the arguments are?</p>

<p>On Windows x86 systems, the <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#cdecl"><em>cdecl</em> calling convention</a> is used. <sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup> That means our arguments should have been pushed to the stack. Using GDB, we can take a look at the stack’s current contents: <sup id="fnref:10" role="doc-noteref"><a href="#fn:10">10</a></sup></p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/stack.png">
		<img src="https://alex.studer.dev/assets/mw41-1/stack.png" title="The contents of the stack." alt="The contents of the stack.">
	</a>
	<figcaption><p>The contents of the stack.</p>
</figcaption>
</figure>

<p>We can match these values to the arguments of <code>DeviceIoControl</code> (which, again, you can find <a href="https://docs.microsoft.com/en-us/windows/win32/api/ioapiset/nf-ioapiset-deviceiocontrol">on this page</a>). The <a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/ntddscsi/ni-ntddscsi-ioctl_scsi_pass_through_direct">IOCTL_SCSI_PASS_THROUGH_DIRECT page</a> tells us that it takes the command to send from the input buffer, which should correspond to <code>DeviceIoControl</code>’s third argument, <code>lpInBuffer</code>. In our case, the third argument is <code>0x32ed90</code>. The fourth argument, <code>nInBufferSize</code>, tells us how large that input buffer is, which in our case is <code>0x50</code> bytes. So, let’s look at <code>0x50</code> bytes from <code>0x32ed90</code>:</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/input-buffer.png">
		<img src="https://alex.studer.dev/assets/mw41-1/input-buffer.png" title="The contents of `lpInBuffer`." alt="The contents of `lpInBuffer`.">
	</a>
	<figcaption><p>The contents of <code>lpInBuffer</code>.</p>
</figcaption>
</figure>

<p>So is this the magic command? Well, the IOCTL page from before tells us that this should actually be a <a href="https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/ntddscsi/ns-ntddscsi-_scsi_pass_through_direct">SCSI_PASS_THROUGH_DIRECT</a> struct.</p>

<div><div><pre><code><span>typedef</span> <span>struct</span> <span>_SCSI_PASS_THROUGH_DIRECT</span> <span>{</span>
  <span>USHORT</span> <span>Length</span><span>;</span>
  <span>UCHAR</span>  <span>ScsiStatus</span><span>;</span>
  <span>UCHAR</span>  <span>PathId</span><span>;</span>
  <span>UCHAR</span>  <span>TargetId</span><span>;</span>
  <span>UCHAR</span>  <span>Lun</span><span>;</span>
  <span>UCHAR</span>  <span>CdbLength</span><span>;</span>
  <span>UCHAR</span>  <span>SenseInfoLength</span><span>;</span>
  <span>UCHAR</span>  <span>DataIn</span><span>;</span>
  <span>ULONG</span>  <span>DataTransferLength</span><span>;</span>
  <span>ULONG</span>  <span>TimeOutValue</span><span>;</span>
  <span>PVOID</span>  <span>DataBuffer</span><span>;</span>
  <span>ULONG</span>  <span>SenseInfoOffset</span><span>;</span>
  <span>UCHAR</span>  <span>Cdb</span><span>[</span><span>16</span><span>];</span>
<span>}</span> <span>SCSI_PASS_THROUGH_DIRECT</span><span>,</span> <span>*</span><span>PSCSI_PASS_THROUGH_DIRECT</span><span>;</span>
</code></pre></div></div>

<p>We can match the fields of the struct with the data we dumped out from GDB. <sup id="fnref:11" role="doc-noteref"><a href="#fn:11">11</a></sup></p>

<table>
  <thead>
    <tr>
      <th>Field</th>
      <th>Data</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Length</td>
      <td><code>0x2c	0x00</code></td>
    </tr>
    <tr>
      <td>ScsiStatus</td>
      <td><code>0x00</code></td>
    </tr>
    <tr>
      <td>PathId</td>
      <td><code>0x00</code></td>
    </tr>
    <tr>
      <td>TargetId</td>
      <td><code>0x00</code></td>
    </tr>
    <tr>
      <td>Lun</td>
      <td><code>0x00</code></td>
    </tr>
    <tr>
      <td>CdbLength</td>
      <td><code>0x0c</code></td>
    </tr>
    <tr>
      <td>SenseInfoLength</td>
      <td><code>0x1f</code></td>
    </tr>
    <tr>
      <td>DataIn</td>
      <td><code>0x01</code></td>
    </tr>
    <tr>
      <td>PADDING</td>
      <td><code>0x00	0x00	0x00</code></td>
    </tr>
    <tr>
      <td>DataTransferLength</td>
      <td><code>0xc0	0x00	0x00	0x00</code></td>
    </tr>
    <tr>
      <td>TimeOutValue</td>
      <td><code>0x64	0x00	0x00	0x00</code></td>
    </tr>
    <tr>
      <td>DataBuffer</td>
      <td><code>0x2c	0xee	0x32	0x00</code></td>
    </tr>
    <tr>
      <td>SenseInfoOffset</td>
      <td><code>0x30	0x00	0x00	0x00</code></td>
    </tr>
    <tr>
      <td>Cdb</td>
      <td><code>0x16	0xf9	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00	0x00</code></td>
    </tr>
  </tbody>
</table>

<p>Note that we have to include three bytes of padding (labeled <code>PADDING</code>) because <a href="https://docs.microsoft.com/en-us/cpp/c-language/padding-and-alignment-of-structure-members?view=msvc-160">Microsoft’s C compiler</a> has to align <code>DataTransferLength</code> to be on a four-byte boundary.</p>

<h2 id="replicating-the-command">Replicating the command</h2>
<p>Now that we’ve deciphered the struct, what is this struct telling Windows to do? Most of the fields aren’t relevant, but what’s important here is <code>Cdb</code>, which, according to the documentation, “specifies the SCSI command descriptor block to be sent to the target device.” In other words, this should be the command that switches the hotspot into debug mode! Then, after sending that command, since the <code>DataIn</code> flag is <code>0x01</code> (equivalent to <code>SCSI_IOCTL_DATA_IN</code>), Windows will read <code>0xc0</code>, or 192, bytes (the value of <code>DataTransferLength</code>) from the device. <sup id="fnref:12" role="doc-noteref"><a href="#fn:12">12</a></sup></p>

<p>Some research pointed me to the <a href="https://linux.die.net/man/8/sg_raw">sg_raw</a> command, which is how you can send arbitrary SCSI commands on Linux. <sup id="fnref:13" role="doc-noteref"><a href="#fn:13">13</a></sup> Using the value from <code>Cdb</code>, the command to use should be <code>sudo sg_raw /dev/sgX 16 f9 00 00 00 00 00 00 00 00 00 00 00 00 00 00 -v</code>, where <code>X</code> is the number corresponding to the hotspot’s disk. <sup id="fnref:14" role="doc-noteref"><a href="#fn:14">14</a></sup> I tried it, and:</p>

<figure>
	<a href="https://alex.studer.dev/assets/mw41-1/success.png">
		<img src="https://alex.studer.dev/assets/mw41-1/success.png" title="Success!" alt="Success!">
	</a>
	<figcaption><p>Success!</p>
</figcaption>
</figure>

<p>It worked! After all this, we finally have the magic command. At this point, you have full root access to the hotspot, and can do basically anything you want.</p>

<p>If you were paying close attention, you might have noticed that the first two bytes (<code>0x16 0xf9</code>) of the command match what the debug mode button says in the first place! (as can be seen at the screenshots at the beginning of the article) Despite that, this effort was still useful to figure out <em>how</em> the bytes are actually sent. It also means that you can probably figure out how to switch it into “diag mode” instead of debug mode, since that button also has its command printed on it. <sup id="fnref:15" role="doc-noteref"><a href="#fn:15">15</a></sup></p>

<p>Also, this only works because the debug protocol was fairly simple. Once we found the magic command, we could just repeat it ourselves. If the debug protocol were more complicated (for example, if the command varied based on some parameter, such as the current time), then we would need to perform a more in-depth analysis of the program.</p>

<p>One final note: you use <code>adb</code>—as in, the Android Debug Bridge—to access the shell. The hotspot doesn’t run Android, but it seems to still use <a href="https://source.android.com/devices/architecture/modular-system/adbd">adbd</a>, along with a few other components from Android. Investigating everything that’s running on the hotspot, though, is probably a subject for a future blog post.</p>



</div></div>]]>
            </description>
            <link>https://alex.studer.dev/2021/01/04/mw41-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25650686</guid>
            <pubDate>Tue, 05 Jan 2021 20:37:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatically fixing packet loss on my connection]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25650270">thread link</a>) | @robotmay
<br/>
January 5, 2021 | https://senryu.pub/afternoonrobot/articles/automatically-fixing-packet-loss-on-my-connection | <a href="https://web.archive.org/web/*/https://senryu.pub/afternoonrobot/articles/automatically-fixing-packet-loss-on-my-connection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Sometimes my internet connection starts to experience packet loss, which is a common issue for many people. Unlike most ISPs, <a href="https://www.aa.net.uk/">Andrews &amp; Arnold</a> actually provide a way to monitor packet loss statistics on your line. Physically restarting the modem is the most reliable way I've found to resolve packet loss issues.</p>

<p>Up until now I had to walk upstairs like some sort of muppet and manually toggle the modem (well, it's a <a href="https://www.draytek.co.uk/products/business/vigor-130">DrayTek Vigor 130</a> which is sort-of a modem but more a PPPoA to PPPoE converter but whatever).</p>

<p>No longer! I have solved the issue with copious complexity.</p>

<h2>Step 1: Write a Prometheus exporter for A&amp;A line stats</h2>

<p>I don't really enjoy writing Go, which a lot of exporters seem to be written in, so instead I've started writing my own small custom exporters in Ruby. This has overall made Prometheus significantly less frustrating to customise for my use-case.</p>

<p><a href="https://gitlab.com/robotmay/prometheus-aanet-exporter/-/blob/master/prometheus-aanet-exporter">https://gitlab.com/robotmay/prometheus-aanet-exporter/-/blob/master/prometheus-aanet-exporter</a></p>

<p>To use it you need to have Ruby set up, install the required gems at the top (or use the Gemfile), then move it to somewhere executable and run it using <code>systemd</code> or whatever. I'll update the instructions in the README at some point.</p>

<p>It works by fetching your personal stats data from an XML feed A&amp;A provide. If you're a customer you can fetch it from inside your control panel under the line stats graph:</p>

<p><img src="https://img.senryumedia.net/d9e630d50b97661fc026507d2f49144f.png"></p>

<h2>Step 2: Graph it in Grafana</h2>

<p>I then set up a graph showing the line stats, with an axis specifically for packet loss:</p>

<p><img title="Shiny line graph" alt="Shiny line graph" src="https://img.senryumedia.net/92c755483fb8d376a58e71c13493ea27.png"></p>

<p>This then has an alert configured which both alerts me directly when it starts firing, and also hits a <a href="https://www.home-assistant.io/">Home Assistant</a> webhook URL:</p>

<p><img title="Configure the alert based on the packet loss axis" alt="Configure the alert based on the packet loss axis" src="https://img.senryumedia.net/db01edb7169de838a53e23dba9d519d2.png"></p>

<h2>Step 3: Set up the network</h2>

<p>Houses in the UK are typically not well set up for people who like to mess around with networking. Our walls are thick and made of brick, and the copper/fibre entry point is typically somewhere really stupid. In the case of our house, this is the front upstairs bedroom, and my networking equipment is in the nice and cold kitchen area, with its stone (fire-resistant) floor, downstairs at the back of the house. When we moved in I ran <em>some</em> metres of Cat-6a cable through walls and stairwells to join the two ends.</p>

<p>I have a couple of Z-Wave plugs sat around from some previous experiments, so at first I tried just sticking the Vigor 130 on one of those in the bedroom, but unfortunately the signal doesn't penetrate that far and would require a bunch of repeaters. But then I ordered an Uninterruptible Power Supply and figured that I might as well power the Vigor 130 from that along with the rest of my equipment so that my connection stays up in power outages. The setup is now:</p>

<ol>
<li>4-way plug adapter into the UPS</li>
<li>Z-Wave plug into the 4-way</li>
<li>48v PoE injector into the Z-Wave plug. Non-PoE output into my EdgeRouter, PoE output runs to the wall socket and then up through the house</li>
<li>48v PoE to RJ45/12v 2.1mm barrel-jack splitter</li>
<li>Cat 6a cable from the adapter into the Vigor 130 network port</li>
<li>2.1mm barrel-jack with 2.5mm adapter into the Vigor's power input</li>
</ol>

<p><img title="High-tech fucking-bright-LEDs avoidance system on the front of the DrayTek" alt="High-tech fucking-bright-LEDs avoidance system on the front of the DrayTek" src="https://img.senryumedia.net/0795741f564304d4cf684bf9bff4092f.jpg"></p>

<h2>Step 4: Configuring <a href="https://www.home-assistant.io/">Home Assistant</a></h2>

<p>This is handled via an <a href="https://www.home-assistant.io/docs/automation/">automation</a>:</p>

<p><img src="https://img.senryumedia.net/355c993421d713dcafdcdf028b372a7b.png"></p>

<p>The <code>webhook</code> trigger type has to have a unique name, which requires a new notification channel in Grafana for each trigger, which is a bit of a pain but not the end of the world.</p>

<p>The next step is to come up with a process by which the modem can be restarted. I've displayed these as YAML because it's significantly more concise than screenshotting the GUI for it:</p>
<div><pre><code><span>alias</span><span>:</span> <span>ADSL Packet Loss</span>
<span>description</span><span>:</span> <span>Reset the Vigor 130 when packet loss is detected from A&amp;A</span>
<span>trigger</span><span>:</span>
  <span>-</span> <span>platform</span><span>:</span> <span>webhook</span>
    <span>webhook_id</span><span>:</span> <span>packet-loss</span>
<span>condition</span><span>:</span> <span>[]</span>
<span>action</span><span>:</span>
  <span>-</span> <span>service</span><span>:</span> <span>notify.telegram</span>
    <span>data</span><span>:</span>
      <span>message</span><span>:</span> <span>&gt;-</span>
        <span>Packet loss detected, restarting ADSL modem in 1 minute. The internet</span>
        <span>will disconnect whilst the modem restarts.</span>
  <span>-</span> <span>delay</span><span>:</span> <span>'</span><span>60'</span>
  <span>-</span> <span>repeat</span><span>:</span>
      <span>until</span><span>:</span>
        <span>-</span> <span>condition</span><span>:</span> <span>state</span>
          <span>entity_id</span><span>:</span> <span>binary_sensor.internet</span>
          <span>state</span><span>:</span> <span>'</span><span>on'</span>
      <span>sequence</span><span>:</span>
        <span>-</span> <span>type</span><span>:</span> <span>turn_off</span>
          <span>device_id</span><span>:</span> <span>012345</span>
          <span>entity_id</span><span>:</span> <span>switch.vigor_130_switch_2</span>
          <span>domain</span><span>:</span> <span>switch</span>
        <span>-</span> <span>delay</span><span>:</span> <span>'</span><span>10'</span>
        <span>-</span> <span>type</span><span>:</span> <span>turn_on</span>
          <span>device_id</span><span>:</span> <span>012345</span>
          <span>entity_id</span><span>:</span> <span>switch.vigor_130_switch_2</span>
          <span>domain</span><span>:</span> <span>switch</span>
        <span>-</span> <span>wait_template</span><span>:</span> <span>'</span><span>{{</span><span> </span><span>is_state("binary_sensor.internet",</span><span> </span><span>"on")</span><span> </span><span>}}'</span>
          <span>continue_on_timeout</span><span>:</span> <span>true</span>
          <span>timeout</span><span>:</span> <span>'</span><span>360'</span>
        <span>-</span> <span>choose</span><span>:</span>
            <span>-</span> <span>conditions</span><span>:</span>
                <span>-</span> <span>condition</span><span>:</span> <span>state</span>
                  <span>entity_id</span><span>:</span> <span>binary_sensor.internet</span>
                  <span>state</span><span>:</span> <span>'</span><span>on'</span>
              <span>sequence</span><span>:</span>
                <span>-</span> <span>service</span><span>:</span> <span>notify.telegram</span>
                  <span>data</span><span>:</span>
                    <span>message</span><span>:</span> <span>&gt;-</span>
                      <span>I have finished toggling the modem off and on and the</span>
                      <span>internet is back up.</span>
          <span>default</span><span>:</span> <span>[]</span>
  <span>-</span> <span>delay</span><span>:</span> <span>'</span><span>1800'</span>
<span>mode</span><span>:</span> <span>single</span>
</code></pre></div>
<h3>Steps</h3>

<h4>Notify</h4>

<p>Firstly, we notify users that the internet will be disconnected briefly, then pause the automation for 1 minute. I'm using Telegram for this because I find it flexible and reliable:</p>
<div><pre><code><span>-</span> <span>service</span><span>:</span> <span>notify.telegram</span>
    <span>data</span><span>:</span>
      <span>message</span><span>:</span> <span>&gt;-</span>
        <span>Packet loss detected, restarting ADSL modem in 1 minute. The internet</span>
        <span>will disconnect whilst the modem restarts.</span>
  <span>-</span> <span>delay</span><span>:</span> <span>'</span><span>60'</span>
</code></pre></div>
<p>I'd like to improve upon this by allowing the users to block the restart from happening by clicking a button in Telegram. Next iteration!</p>

<h4>Repeat the next set of instructions</h4>

<p>Next we start a repeating loop using <code>repeat</code>, which will keep trying the restart steps until the internet connection reappears. </p>

<h4>Reset loop</h4>

<p>The switch is turned off, we wait for 10 seconds, then turn it back on:</p>
<div><pre><code>        <span>-</span> <span>type</span><span>:</span> <span>turn_off</span>
          <span>device_id</span><span>:</span> <span>012345</span>
          <span>entity_id</span><span>:</span> <span>switch.vigor_130_switch_2</span>
          <span>domain</span><span>:</span> <span>switch</span>
        <span>-</span> <span>delay</span><span>:</span> <span>'</span><span>10'</span>
        <span>-</span> <span>type</span><span>:</span> <span>turn_on</span>
          <span>device_id</span><span>:</span> <span>012345</span>
          <span>entity_id</span><span>:</span> <span>switch.vigor_130_switch_2</span>
          <span>domain</span><span>:</span> <span>switch</span>
</code></pre></div>
<p>Then we wait for up to 5 minutes (360 seconds) for the internet to come back up. <code>binary_sensor.internet</code> is numerous <code>ping</code> binary sensors to different websites, where any of them responding within the last minute will cause the sensor to report as <code>on</code>.</p>
<div><pre><code>        <span>-</span> <span>wait_template</span><span>:</span> <span>'</span><span>{{</span><span> </span><span>is_state("binary_sensor.internet",</span><span> </span><span>"on")</span><span> </span><span>}}'</span>
          <span>continue_on_timeout</span><span>:</span> <span>true</span>
          <span>timeout</span><span>:</span> <span>'</span><span>360'</span>
</code></pre></div>
<p>This will time out after 5 minutes and continue to the next steps, but the sensor changing to <code>on</code> before that will exit it early. This means we allow up to 5 minutes for the connection to reappear before seeing whether we should notify the user that it's back:</p>
<div><pre><code>          <span>-</span> <span>choose</span><span>:</span>
            <span>-</span> <span>conditions</span><span>:</span>
                <span>-</span> <span>condition</span><span>:</span> <span>state</span>
                  <span>entity_id</span><span>:</span> <span>binary_sensor.internet</span>
                  <span>state</span><span>:</span> <span>'</span><span>on'</span>
              <span>sequence</span><span>:</span>
                <span>-</span> <span>service</span><span>:</span> <span>notify.telegram</span>
                  <span>data</span><span>:</span>
                    <span>message</span><span>:</span> <span>&gt;-</span>
                      <span>I have finished toggling the modem off and on and the</span>
                      <span>internet is back up.</span>
          <span>default</span><span>:</span> <span>[]</span>
</code></pre></div>
<h4>Pause for a bit</h4>

<p>In case Grafana chooses to wing multiple alerts to the webhook, we should pause at the end of this automation. This will work with the <code>single</code> mode described in the next step to effectively rate limit how often this can happen; currently 30 minutes:</p>

<h4>Super duper important</h4>

<p>You almost certainly want this running in <code>single</code> mode:</p>

<p>This will ensure only one version of this automation can run at once.</p>

<h2>Potential issues</h2>

<p>I wish Home Assistant had an option for <code>until</code> loops with a maximum retry count. I can't seem to find it in the documentation, but it might be possible with some other combination of steps.</p>

<p>I've tweaked my Grafana alert a few times to try and ensure it doesn't fire again as soon as the internet returns after the automation fires. This was a problem.</p>

<p>I almost certainly want to alter how this works when people are in the house vs an empty house. With an empty house it shouldn't really matter if we restart quickly, but with people in the house we might want to be able to override it and prevent any restarts for a certain timeframe. Some traffic inherently has high packet loss, such as (for me), downloads from Microsoft servers in the Xbox app on Windows.</p>

<h2>Fin</h2>

<p><img src="https://img.senryumedia.net/9bb3413de5c9e13d8886e5c44d7a6b3b.png"></p>

<p>It works! I could potentially drop one aspect of complexity and gather the packet loss stats directly in Home Assistant, but I already had it set up in Grafana/Prometheus so it was actually less effort this time around.</p>

<p>This will save me many minutes of effort over my lifetime, and is therefore a resounding success.</p>
</section></div>]]>
            </description>
            <link>https://senryu.pub/afternoonrobot/articles/automatically-fixing-packet-loss-on-my-connection</link>
            <guid isPermaLink="false">hacker-news-small-sites-25650270</guid>
            <pubDate>Tue, 05 Jan 2021 20:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon buys 11 Boeing 767s to expand its cargo fleet]]>
            </title>
            <description>
<![CDATA[
Score 242 | Comments 187 (<a href="https://news.ycombinator.com/item?id=25650094">thread link</a>) | @seryoiupfurds
<br/>
January 5, 2021 | https://www.cbc.ca/news/business/amazon-westjet-1.5861635 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/amazon-westjet-1.5861635">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Amazon is buying four jets from WestJet and seven&nbsp;from Delta as the e-commerce giant moves to beef up its delivery fleet at a time when passenger jets are no longer so in demand.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5861643.1609859058!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/amazon-delivery-plane.jpg"></p></div><figcaption>Amazon launched its own air cargo fleet in 2016 which has grown to consist of 80 leased jets, but Tuesday's purchase of planes from WestJet and Delta are the first ones it will own.<!-- --> <!-- -->(Luke Sharrett/Bloomberg)</figcaption></figure><p><span><p>Amazon is buying four jets from WestJet and seven&nbsp;from Delta as the e-commerce giant moves to beef up its delivery fleet at a time when passenger jets are no longer so in demand.</p>  <p>In a release, the company said the 11 jets, which are all Boeing 767-300s, are all currently set up to carry passengers but are in the process of being converted to carry only cargo. The WestJet jets will join Amazon's fleet some time this year&nbsp;and the Delta ones in 2022.</p>  <p>"Our goal is to continue delivering for customers across the U.S. in the way that they expect from Amazon, and purchasing our own aircraft is a natural next step toward that goal,"&nbsp;Sarah Rhoads, vice-president of Amazon Global Air, said in a release.</p>  <p>The 767 was a key jet for WestJet&nbsp;in its evolution as it was the airline's only wide-body jet, but the airline has recently decommissioned its entire fleet of them&nbsp;and moved to larger 787 Dreamliners for many long-haul flights.</p>  <p>"Last year our 767s were removed from service as we gauged market interest for the procurement of the 767 fleet," spokesperson Morgan Bell told CBC News in a statement. "We are pleased they found a home with Amazon."</p>  <p>The four jets represents WestJet's entire fleet of 767s.</p>  <h2>Amazon building delivery network</h2>  <p>Amazon launched its own air cargo fleet in 2016&nbsp;and, prior to Tuesday's news, the company leased&nbsp;80 planes, but the move is the first time the company has bought their own.</p>  <p>The company uses&nbsp;parcel services such as UPS and FedEx for its current deliveries, but is moving to build its own delivery network as it increasingly views itself as a competitor to those services, not a partner.</p>  <p>Amazon owns tens of thousands of its own delivery trucks, and has been experimenting with its own fleet of <a href="https://www.cbc.ca/news/technology/amazon-tests-delivery-drones-at-a-secret-site-in-canada-here-s-why-1.3015425">autonomous delivery drones</a>. But those are for the last leg of the delivery journey&nbsp;— it still relies on planes to get packages across vast distances, quickly.</p>  <p>Tuesday's news is the first purchase of jets, but also the second time in the pandemic that the company has added to its number of planes.</p>  <p>In June of 2020, the company <a href="https://www.businesswire.com/news/home/20200604005144/en/ATSG-to-Lease-Twelve-Additional-767-Freighters-to-Amazon">leased a dozen 767s from&nbsp;Air Transport Services Group, Inc.</a></p>  <p>Financial terms of the sale were not disclosed.&nbsp;</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/amazon-westjet-1.5861635</link>
            <guid isPermaLink="false">hacker-news-small-sites-25650094</guid>
            <pubDate>Tue, 05 Jan 2021 19:49:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moral Competence]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 179 (<a href="https://news.ycombinator.com/item?id=25648186">thread link</a>) | @flaque
<br/>
January 5, 2021 | https://evanjconrad.com/posts/moral-competence | <a href="https://web.archive.org/web/*/https://evanjconrad.com/posts/moral-competence">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><em>Since posting, a number of peple have pointed out that "competence" probably isn't the right word here. "Morally focused", or "morally effective" might be better. This post isn't meant to be harsh, nor is it meant to propose an absolute binary. I hope you'll read it with the kinder tone that was intended.</em></p>
<p>Last year, we pivoted our YC startup from a socially-good mental health product <a href="https://github.com/Flaque/quirk">(Quirk)</a>, towards a socially-neutral software infrastructure product <a href="https://www.roomservice.dev/">(Room Service)</a>. I couldn't have imagined myself wanting to pivot when we started; our mental health company was deeply tied to my own experience and our genuine desire to help other folks. With the clarity of a year (and a global pandemic) in between the pivot, it's easier to see some of what went wrong.</p>
<p>What we were missing, and what many social-good founders are missing, is moral competence. <strong>If you want to do good, you actually have to help people.</strong> Merely attempting to help people is not enough. That doesn't mean that <em>trying</em> to help people is bad. It's not, but moral good comes from moral competence. And that was something we lacked.</p>
<p>The morally <em>incompetent</em> want purpose; they want to be on the front-lines of the helping. But for the morally incompetent, helping people is more important than the folks being helped. They don't offer service, they seek it. The service outranks the outcome. The signature move of the morally incompetent is to be told about existing solutions that they were previously unaware of and then soldier on without any critical examination of any added value they're providing. Others working on the problem are ignored entirely or seen as a threat to their own solution. The morally incompetent are passionate about working on the problem and potentially even solving the problem, so long as they were involved in the solution. For the morally incompetent, it's important that they're helping the right people with the right problem; it would be a failure to help on an entirely different problem. All problems are stack-ranked in the morally incompetent's mind and they need to be working on the one that's most critical to them in particular, regardless of their ability to offer help. For the morally incompetent, it's of <em>critical importance</em> that they work <em>directly</em> on the problem, rather than help indirectly. For the morally incompetent, large societal issues are best solved by direct intervention, rather than large societal solutions. Working on the problem indirectly, or from an angle that is not obvious to an outside observer is a failure. For the morally incompetent, large societal problems are unsolved only because they personally haven't purposed a solution.</p>
<p>It's easy to fall into the trap of moral incompetence, we did with our company. Moral competence and incompetence often looks the same to an outside observer. The world is really good at praising people who are <em>doing</em> good things well before those things are accomplished. You get hounded for interviews, you win awards, your family and friends congratulate you. And when things <em>aren't</em> going well, when you're <em>not</em> helping people, it feels like a betrayal to tell anyone. After all, that would mean no longer helping people with your chosen problem.</p>
<p>The morally <em>competent</em> differ in intent. It's more important to cure cancer than it is to be working on curing cancer, to stop climate change than to be working on stopping climate change, to improve mental health than to be working on improving mental health. The morally competent aren't hanging around the hoop, content to be playing the game. The point isn't to be working in the field, it's to solve the problem.</p>
</article><p>If you have a question, comment, or just want to get in touch, send me an email at <code>evan at roomservice dot dev</code>.</p></div>]]>
            </description>
            <link>https://evanjconrad.com/posts/moral-competence</link>
            <guid isPermaLink="false">hacker-news-small-sites-25648186</guid>
            <pubDate>Tue, 05 Jan 2021 17:37:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Seeing the forest for the trees: A more disciplined approach for AI]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25648086">thread link</a>) | @dh00608000
<br/>
January 5, 2021 | https://david-haber.github.io/posts/ai-discipline/ | <a href="https://web.archive.org/web/*/https://david-haber.github.io/posts/ai-discipline/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

    

    
      

    

    <p>Data-driven decision-making systems in production today exhibit serious conceptual flaws. Deployed as part of high-stakes applications, they not only risk to compromise individual safety and a company’s financial performance but threaten economic and political stability at scale.</p>
<p>To achieve reliable performance of AI in the real world, we need to shift the focus from the development of <em>ML models</em> towards a more systematic discipline to create fail-safe <em>systems</em> and <em>life cycles</em>.</p>
<figure>
    <img src="https://david-haber.github.io/images/crashtest.jpg" alt="Cars go through rigorous stress testing as part of the normal development workflow. Fail-safe engineering is still underdeveloped in AI compared to more conventional technologies used in transportation, healthcare, finance, or other industries. - Photo: Mercedes-Benz"> <figcaption>
            <p>Cars go through rigorous stress testing as part of the normal development workflow. Fail-safe engineering is still underdeveloped in AI compared to more conventional technologies used in transportation, healthcare, finance, or other industries. - Photo: Mercedes-Benz</p>
        </figcaption>
</figure>

<p>While many still argue that AI’s impact has been modest, the importance to address this now becomes clear if we look at the air balls that we already managed to throw.</p>
<p>In the midst of recent wildfires in the US, one of Google’s algorithms recommended outdoor exercise to people<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, exposing their respiratory systems to harmful amounts of smoke and putting their health at severe risk. While the company might have acted in good faith (exercise is good after all!), they didn’t take into account that a wildfire event would invalidate their data and an otherwise correct recommendation. The real world is always full of surprises.</p>
<p>In 2019, the Wall Street Journal reported that a group of researchers found racial bias in a hospital algorithm which meant that black patients were less likely to receive the medical help they needed than white patients<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The reasons, it was explained, included that the algorithm would rank patients according to healthcare costs and the fact that “health-care spending for black patients was less than for white patients with similar medical conditions”. With better transparency, this issue would have been found more quickly, likely before deployment.</p>
<p>During the current pandemic, headline news claim that AI imaging systems can detect COVID-19 from chest x-rays. While this is all early work, a team at the University of Washington showed that the methodology in building those systems was terribly flawed. The models–which had been reported to have astounding accuracies in the first place–seem to have learned “spurious shortcuts” and imaging artifacts rather than medical pathology<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. As one of the consequences, physically moving the patient up in the x-ray “increased the model’s predicted odds that the patient has COVID-19”. It’s a beautiful–and alarming–illustration of the gap between news headlines, early prototypes and the complexities of operating these in hospital rooms.</p>
<p>Clinical decision-making systems recommend procedures and drug treatments to doctors and patients every day. The cost of poor decision-making often only becomes apparent when we do the math at scale. While false predictions could pose small risks at an individual level, we forget that they needlessly harm a number of human beings every day when decision-making systems are deployed and used at scale - across offices, hospitals, and countries.</p>
<p>At the same time, academic AI papers claim to outperform humans in a fascinating race to beat state-of-the-art performances. Yet, it is clear to all that our machine learning (ML) models which work well in a Jupyter notebook<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, perform less impressively in the real world. A set of metrics, ground truth and predictions is all that is needed to arrive at the “my system works well on the test set” conclusion. While there is nothing wrong with that, the problem is that–despite being neither a complete nor a sound assessment–we erroneously extrapolate that performance to complex, dynamic and real-world environments all too often.</p>
<blockquote>
<p>ML code is only a small part of the solution.
— <!-- raw HTML omitted -->Andrew Ng, Co-founder of Coursera and Adjunct Professor at Stanford University<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>The truth is that the development of <em>complete AI systems</em> is extremely challenging and the organizational effort required to drive such projects to completion is orders of magnitude higher than developing proof-of-concept or prototype <em>models</em>. Especially as the challenges of real-world AI transcend data science and code. Complete systems need to be analyzed in the context of the intended application, how they interact with and are influenced by their environment and any hardware that is used. Failure situations need to be examined through <em>failure mode and effects analyses</em><sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> and influence the design and procedures which are used during development and operation. Finally, these systems will be used by humans with different backgrounds, skills, and their own individual ways of interacting with technology. As a consequence, AI development requires great care in the design of human-computer interfaces and the consideration of human factors<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>. It is a cross-disciplinary effort that needs to involve multiple stakeholders and domain expertise to truly understand the end user we want to serve.</p>
<p>What is the result of this? Businesses around the world struggle to realize a return on their AI investments - too many projects and even entire companies are stuck in the “pilot trap”.</p>
<p>Having gone through the development of complex, physical AI systems with strict safety guarantees ourselves, we understand the challenges and the need to rethink our strategies to develop real-world AI systems. This is particularly true in the context of evolving regulatory standards which will create additional pressure for AI developers and companies in all major industries over the next few years. But it is also relevant beyond regulations - for anyone looking to realize the impact that AI has long been promising.</p>
<p>So, what does it take? We need to better understand how to design, develop and operate AI from a system’s perspective. Reasoning about systems rather than models opens the toolboxes that safety and systems engineers have been using to build robust systems for decades. We have the tools. What’s missing is our own toolbox.</p>
<blockquote>
<p>The building blocks are in place, the principles for putting these blocks together are not, and so the blocks are currently being put together in ad-hoc ways…What we’re missing is an engineering discipline with principles of analysis and design.
— <!-- raw HTML omitted -->Michael Jordan, Professor at the University of California, Berkeley<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>A more disciplined approach to AI development would not only create better products but also enable completely new applications. It would help us achieve the small failure probabilities that healthcare, transportation, finance, and other industries require.</p>
<p>Most importantly, it would help convert the AI term from an intellectual wildcard into something more fundamental, something that we can understand and reason about. Only then can we have meaningful discussions around safety, ethics, and regulations. Only then can we nudge AI projects out of the “pilot trap” and deploy them safely &amp; robustly in our complex world.</p>
<p>What does this all mean for startups and corporations? How can they establish development life cycles, create AI products and structure their organizations? What does it mean for you? Bear with us! We will present some thoughts around these questions in future articles.</p>
<p><em>Thanks to <a href="https://ruieduardo.com/" target="_blank">Rui</a>, <a href="https://twitter.com/muellerfreitag" target="_blank">Moritz</a>, <a href="https://www.linkedin.com/in/matthias-kraft-5b1229a1/" target="_blank">Matthias</a>, <a href="https://www.linkedin.com/in/mateor/" target="_blank">Mateo</a>, <a href="https://www.linkedin.com/in/annalipkina10/" target="_blank">Anna</a> and Andy for reading drafts of this article, providing feedback and discussing with me how to build better AI.</em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.sacbee.com/news/california/fires/article216227775.html" target="_blank">How bad is Sacramento’s air, exactly? Google results appear at odds with reality, some say (The Sacramento Bee, 2018)</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://www.wsj.com/articles/researchers-find-racial-bias-in-hospital-algorithm-11571941096" target="_blank">Researchers Find Racial Bias in Hospital Algorithm (The Wall Street Journal, 2019)</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.medrxiv.org/content/10.1101/2020.09.13.20193565v2.full.pdf" target="_blank">DeGrave, Alex J., Joseph D. Janizek, and Su-In Lee. “AI for radiographic COVID-19 detection selects shortcuts over signal.” medRxiv (2020).</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>A popular programming environment to run ML experiments, mostly at smaller scale. <a href="#fnref:4" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p><a href="https://www.youtube.com/watch?v=tsPuVAMaADY" target="_blank">Ng, Andrew. “Bridging AI’s Proof-of-Concept to Production Gap” (2020)</a> <a href="#fnref:5" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p><a href="https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis" target="_blank">Wikipedia article: Failure mode and effects analysis</a> <a href="#fnref:6" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>A term used by the European Union Aviation Safety Agency (EASA) to describe “anything that affects human performance”. <a href="#fnref:7" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p><a href="https://hdsr.mitpress.mit.edu/pub/wot7mkc1/release/9" target="_blank">Jordan, Michael I. “Artificial intelligence—the revolution hasn’t happened yet.” Harvard Data Science Review 1.1 (2019).</a> <a href="#fnref:8" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>


</article></div>]]>
            </description>
            <link>https://david-haber.github.io/posts/ai-discipline/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25648086</guid>
            <pubDate>Tue, 05 Jan 2021 17:31:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surveillance in the Name of Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25647919">thread link</a>) | @leoschwartz
<br/>
January 5, 2021 | https://restofworld.org/2021/trace-together-forever/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/trace-together-forever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p>Chong Kai Xiong is usually so conscious of his privacy that he refuses to use ride-hailing apps like Grab or Gojek. An IT professional who has done independent research on surveillance technologies, he says he knows how hard it is to make databases secure, and he worries about hacks and leaks.</p>



<p>But now that the novel coronavirus pandemic has made opting out of location tracking practically impossible in Singapore, he has been forced to compromise. The country’s approach to containing the virus has included the widespread use of digital check-ins via a system called <a href="https://safeentry.gov.sg/">SafeEntry</a>. Individuals must check in with their ID and phone number before they enter malls, shops, restaurants, workplaces, or schools. This information is fed back to a centralized database, which the government then uses for contact tracing.</p>



<p>Naturally, Chong isn’t happy about it. “Every time I have lunch or shop outside, I am forced to recognize the gaze of the state, surveilling my whereabouts,” he says.</p>



<p>The Singaporean government has leaned heavily on technology in its response to the pandemic. In March, the government launched its TraceTogether app, <a href="https://www.tech.gov.sg/media/technews/20201015-before-tracetogether-you-have-to-testtogether">touting it</a> as the “world’s first national digital contact-tracing effort.” The system uses Bluetooth to track people as they move and interact with one another; if two users are within two meters of each other for thirty minutes or more, it records the contact. (The government provides people without smartphones with <a href="https://token.gowhere.gov.sg/faq">tokens</a>.) The code that the app runs on was <a href="https://github.com/opentrace-community">open source</a>, so other countries can adapt it for their own uses, as Australia did to develop its own contact-tracing system.</p>



<p>The authorities claim that such technologies have <a href="https://support.tracetogether.gov.sg/hc/en-sg/articles/360052744534-How-do-TraceTogether-and-SafeEntry-work-together-Is-SafeEntry-still-required-since-there-is-TraceTogether-">greatly strengthened their contact-tracing efforts</a>. In early November, the health minister <a href="https://www.channelnewsasia.com/news/singapore/tracetogether-app-tokens-close-contacts-cases-identified-covid19-13442296">said</a> that 25,000 close contacts of confirmed Covid-19 cases had been identified through TraceTogether, of which 160 eventually tested positive. The country reported zero cases of community transmission most days in November.&nbsp;</p>



<p>Despite these successes, the imposition of more intrusive data collection technology has unnerved privacy advocates, who worry that the pandemic will be used to justify the surveillance of citizens without consideration of the long-term consequences, and without sufficient checks and balances.&nbsp;</p>



<p>Those concerns look increasingly well-founded. When Parliament reopened in January 2021, Desmond Tan, the Minister of State at the Ministry of Home Affairs, <a href="https://www.channelnewsasia.com/news/singapore/singapore-police-force-can-obtain-tracetogether-data-covid-19-13889914">said that the police would also be able to access TraceTogether data for criminal investigations</a>. The privacy statement on the TraceTogether website, which had previously stated that collected data would “only be used solely for contact tracing of persons possibly exposed to COVID-19,” was amended shortly afterwards.</p>



<p>“It’s not that, in principle, I disagree with contact tracing. It’s something that society could decide to do because there’s a trade-off with giving up privacy to ensure better health. But we didn’t make that decision democratically,” says Tan Zhi-xuan, a Singaporean who researches artificial intelligence at the Massachusetts Institute of Technology. “I think society has given up a lot in the name of efficiency and convenience.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1207755797-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1207755797-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/GettyImages-1207755797-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1207755797-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1207755797-1000x667.jpg 1000w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1207755797-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/12/GettyImages-1207755797-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="The government’s TraceTogether system uses Bluetooth to track people as they move and interact with one another.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Catherine Lai/AFP/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p>The enthusiastic adoption of data-collection technology is entirely in keeping with Singapore’s model of governance and view of itself as a high-tech “<a href="https://www.smartnation.gov.sg/">Smart Nation</a>” at the forefront of global innovation.&nbsp;</p>



<p>“Singapore is a very techno-optimistic nation,” says Monamie Bhadra Haines, an assistant professor of global science and technology studies at Nanyang Technological University. “Technology and technological solutionism is seen to be the approach that they take to solve all sorts of deeply political problems.”</p>



<p>In 2018, Singapore announced a pilot project to <a href="https://www.reuters.com/article/us-singapore-surveillance-idUSKBN1HK0RV">install facial-recognition cameras on lampposts</a>, alongside other sensors&nbsp; it claimed would be beneficial for analysing the movement of crowds or investigations in the event of a terror attack. The country is also working on <a href="https://www.tnp.sg/news/singapore/satellite-based-erp-system-start-middle-2023-lta">a satellite-based road-toll system</a> that would charge drivers based on how far they travel, though they’ve temporarily put that plan on hold.</p>



<p>In September, the government <a href="https://www.bbc.com/news/business-54266602">announced</a> that facial verification will be integrated into the existing digital identity system, which allows citizens to access government services online. A month later, the immigration authority <a href="https://www.straitstimes.com/singapore/facial-and-iris-scans-have-replaced-fingerprint-scans-as-main-mode-for-identifying">said</a> it was replacing fingerprint scans with facial and iris scans as the main mode of identity verification at the border.</p>



<p>There is rarely much public opposition to these initiatives. Singaporeans routinely report a high level of trust in the government; the country’s politics is dominated by a single powerful political party that exerts significant influence over the media. New technologies and processes are presented to the public as faits accomplis, leaving little space for public discussion.</p>



<p>“It’s also framed in this very positive way, like, ‘This will speed us through the border faster,’” says Hallam Stevens, a historian of technology at Nanyang Technological University. “There’s a kind of lack of debate about this partly because it’s going through so fast.”</p>



<p>The government maintains it is not using the TraceTogether system to actively track its citizens and that the data will only be used for Covid-19 contact tracing—although as it stated in parliament, the police will be able to request data, and some academics and activists are concerned about the underlying trade-off — convenience in exchange for privacy and power.&nbsp;</p>



<p>Singapore’s government and public agencies are exempt from the Personal Data Protection Act (PDPA), which regulates the collection and use of data in the private sector. <a href="https://www.mci.gov.sg/pressroom/news-and-stories/pressroom/2019/2/mcis-response-to-pq-on-public-agencies-exemption-from-pdpa?page=28">Other laws</a> do govern data collection in the public sector, and the government says their standards are comparable to the PDPA’s. But privacy advocates say these laws don’t sufficiently empower individual users, and that citizens have no rights to redress or accountability if they aren’t followed.</p>



<p>“The individual has no remedy for misuse of data,” says Indulekshmi Rajeswari, a privacy lawyer who practiced in Singapore before relocating to Germany.</p>



<p>Others worry that relying heavily on technology could worsen structural inequities in Singaporean society. As Tan points out, facial-recognition systems have been shown to generate different results for different ethnic groups, which could, for example, lead to racial minorities’ being subjected to extra questioning and scrutiny during immigration checks.</p>



<p>TraceTogether will soon be mandatory for all of Singapore’s residents — but it already is for the country’s population of migrant workers. <a href="https://www.straitstimes.com/singapore/over-450000-workers-to-get-contact-tracing-devices">More than 450,000 </a>have been given wearable contact-tracing tokens so that their movements and interactions can be logged even if they don’t have their phones on them while at work.</p>



<p>As Haines puts it, “If [the debate about technology is] only narrowly framed [in terms of] convenience and efficiency and speed, then what happens to problems like inequality, or power asymmetries, or any of the other kinds of deeply moral stuff that we care about?”&nbsp;</p>



<p>There are signs that Singaporeans are nervous about handing over their data. Two months after TraceTogether was launched, <a href="https://www.todayonline.com/singapore/given-low-adoption-rate-tracetogether-experts-suggest-merging-safeentry-or-other-apps">only 25% of the population</a> had voluntarily downloaded it. A local polling company, Blackbox Research, found that <a href="https://www.scmp.com/week-asia/people/article/3084903/coronavirus-why-arent-singapore-residents-using-tracetogether">45% of respondents</a> chose not to install TraceTogether because of concerns about “the government tracing their movements.” In October, the government had to <a href="https://www.tnp.sg/news/singapore/tracetogether-tokens-allegedly-modified-thick-headed-singaporeans">remind</a> people that tampering with TraceTogether tokens was illegal, after reports emerged of individuals trying to subvert or disable their tracking capabilities.</p>



<p>Chong, long used to being an outlier when it comes to apprehension over data collection in Singapore, says he has been encouraged by the recent increase in public awareness. But he’s still keeping his expectations low because he thinks the burgeoning resistance isn’t enough to put the brakes on it.</p>



<p>“Unless people start to band together and question these [Smart Nation] initiatives, I think [the government is] just going to push ahead. There are benefits to these technologies, but there needs to be some sort of debate about the trade-offs.”</p>
			<!-- Article End -->

		</div></div>]]>
            </description>
            <link>https://restofworld.org/2021/trace-together-forever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25647919</guid>
            <pubDate>Tue, 05 Jan 2021 17:22:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Year in Open-Source Neural Search: Jina AI's 2020 Year in Review]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25647022">thread link</a>) | @alexcg1
<br/>
January 5, 2021 | https://jina.ai/2020/12/28/jina-2020-year-in-review.html | <a href="https://web.archive.org/web/*/https://jina.ai/2020/12/28/jina-2020-year-in-review.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>It goes without saying that 2020 has been an unforgettable and challenging year for many. For Jina AI, 2020 has a different, more positive meaning: <strong>It is the year Jina was born and first introduced to the global open-source community</strong>.</p>

<p>In February, our founders came together with a vision of melding machine learning, search and open source, seeing the challenge and potential in <a href="https://hanxiao.io/2020/02/18/I-Quitted-Tencent-AI-and-Raised-M-to-Build-the-Next-Neural-Search-Company-in-Opensource/">building the definitive open-source neural search framework</a>.</p>

<p>From our first release in May 2020 through to December 2020, we have shipped <strong>over 100 releases</strong>, with our major release of 0.9.0 on the horizon. While Jina is still under heavy development and progressing steadily towards 1.0, weâ€™re constantly engaging with a broader audience from the open-source and machine-learning communities.</p>

<p>This engagement has been growing steadily over time:</p>

<figure>
    <img src="https://jina.ai/assets/images/blog/2020review-stars.png">
    <figcaption>Jina's Github stargazers since the first release</figcaption>
</figure>

<h3 id="milestones">Milestones</h3>

<p>As of December, <a href="https://github.com/jina-ai/jina">Jinaâ€™s Core repository</a> has <strong>over 22,000 lines of Python code</strong>. Itâ€™s an impressive feat, yet it doesnâ€™t tell the whole story. What really makes this number meaningful is how weâ€™ve worked together to achieve our product and community milestones:</p>

<figure>
    <img src="https://jina.ai/assets/images/blog/2020review-milestones.png">
    <figcaption>Jina 2020 Milestones</figcaption>
</figure>

<p>Over the past year, Jina has grown from an initial neural search structure to a powerful multi-modal and cross-modal foundation which lets businesses and developers build their own search systems and enjoy the advancement of neural-network enabled search capabilities.</p>

<h3 id="community-and-impact">Community and Impact</h3>

<p>Since day one, weâ€™ve been committed to the culture of open source software (OSS). Although Jina is maintained by a full-time engineering team, we believe <strong>community is the key to successful open-source software</strong>. We constantly seek out ways to work with other open-source projects and pull out all the stops to support our community members building their own Jina projects.</p>

<p>To date, weâ€™ve attracted close to <strong>100 contributors</strong>, and about <strong>20%</strong> of our pull requests come from our community. This is reflected in our community Slack channel, where we provide support to <strong>over 300 members</strong>.</p>

<figure>
    <img src="https://jina.ai/assets/images/blog/2020review-community-2.png">
    <figcaption>Jina Core Community Metrics</figcaption>
</figure>

<p>Weâ€™ve also integrated with other open-source projects like <a href="https://chatbotslife.com/jina-ai-with-rasa-1e81a8b869cc">Rasa</a>, <a href="">Streamlit</a>, <a href="https://medium.com/jina-ai/terraform-jina-b9217b8b4552?source=friends_link&amp;sk=d4dd21938ecb1c9d2720c44569bf590e">Terraform</a>, <a href="https://github.com/jina-ai/examples/blob/master/jupyter-notebook-integration/">Jupyter Notebook</a>, and <a href="https://hanxiao.io/2020/10/28/Mindspore-powered-Neural-Search-in-Jina/">Mindspore</a>. In September, Artur Tanona built Jinaâ€™s first community project, <a href="https://github.com/ArturTan/transformers-for-lawyers">a neural search implementation for the legal sector</a>. And in November, we kicked-off our first Early Adopter Program and began discussions with over a dozen candidates from individuals to startups to established enterprises.</p>

<h3 id="company">Company</h3>

<p>Jina AI was founded in February 2020, in the midst of a global pandemic and economic slowdown. This couldnâ€™t stop the march of the Jina team however. As one of the fastest-growing COSS startups, we have successfully closed <strong>two rounds of funding totalling over $7 million in just 6 months</strong>. This has also hit the record for early-stage COSS companies fundraising in the enterprise technology sector.</p>

<p>To date, our team has grown from three founders to a distributed team of over 20, with <strong>60% of the team focused on product development and engineering</strong>. Our team is inclusive and diverse, with members from 7+ different countries and a modern structure that fits the culture of open-source and borderless development.</p>

<p>We have initiatives in place to improve our company culture, and weâ€™re always on the lookout for <a href="http://jobs.jina.ai/">new hires</a>.</p>

<h3 id="2021">2021</h3>

<p>As we look back on our achievements, we know that 2020 is just the beginning of our journey, with the new challenges and breakthroughs of 2021 just around the corner.</p>

<p>For our product and community, our 2021 focuses will be:</p>

<ul>
  <li>Major release of 1.0 in 2021 Q1</li>
  <li>Engaging with Jinaâ€™s early adopters</li>
  <li>Improving developer (learning) experience</li>
  <li>Extending cloud support</li>
  <li>Increasing visibility in the open-source community</li>
</ul>

<p>Weâ€™ll keep building our team and we welcome those who share our belief in open source to <a href="http://jobs.jina.ai/">join our journey</a> to build the next generation of search frameworks.</p>

<h3 id="thank-you">Thank You!</h3>

<p>Last but not least, weâ€™d like to give thanks to all of our contributors, our community members, our friends at Deepset.ai, Streamlit, Philipp Vollet, our investors (GGV Capital, Yunqi Partners, and SAP.iO), and of course, our amazing team members. Thank you all for your support! Without you, Jina wouldnâ€™t be what it is today.</p>

<figure>
    <img src="https://jina.ai/assets/images/blog/2020review-heart.png">
    <figcaption>Thank you, all of our contributors!</figcaption>
</figure>


    </div></div>]]>
            </description>
            <link>https://jina.ai/2020/12/28/jina-2020-year-in-review.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25647022</guid>
            <pubDate>Tue, 05 Jan 2021 16:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PE Anatomist – Explore data structures in portable executable files]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25646284">thread link</a>) | @URfejk
<br/>
January 5, 2021 | https://rammerlabs.alidml.ru/index-eng.html | <a href="https://web.archive.org/web/*/https://rammerlabs.alidml.ru/index-eng.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://rammerlabs.alidml.ru/index-eng.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25646284</guid>
            <pubDate>Tue, 05 Jan 2021 15:11:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus (2018)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25645205">thread link</a>) | @melenaboija
<br/>
January 5, 2021 | https://www.inference.vc/untitled/ | <a href="https://web.archive.org/web/*/https://www.inference.vc/untitled/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			<article id="5cae2885ee667200171857a3">
	<p>May 24, 2018<span></span></p>
	
	<!--kg-card-begin: markdown--><p>You might have come across <a href="https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097609/">Judea Pearl's new book</a>, and a <a href="https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/">related interview</a> which was widely shared in my social bubble. In the interview, Pearl dismisses most of what we do in ML as curve fitting. While I believe that's an overstatement (conveniently ignores RL for example), it's a nice reminder that most productive debates are often triggered by controversial or outright arrogant comments. Calling machine learning alchemy was a great recent example. After reading the article, I decided to look into his famous do-calculus and the topic causal inference once <em>again</em>.</p>
<p>Again, because this happened to me semi-periodically. I first learned do-calculus in a (very unpopular but advanced) undergraduate course Bayesian networks. Since then, I have re-encountered it every 2-3 years in various contexts, but somehow it never really struck a chord. I always just thought "this stuff is difficult and/or impractical" and eventually forgot about it and moved on. I never realized how fundamental this stuff was, until now.</p>
<p>This time around, I think I fully grasped the significance of causal reasoning and I turned into a full-on believer. I know I'm late to the game but I almost think it's basic hygiene for people working with data and conditional probabilities to understand the basics of this toolkit, and I feel embarrassed for completely ignoring this throughout my career.</p>
<p>In this post I'll try to explain the basics, and convince you why you should think about this, too. If you work on deep learning, that's an even better reason to understand this. Pearl's comments may be unhelpful if interpreted as contrasting deep learning with causal inference. Rather, you should interpret it as highlighting causal inference as a huge, relatively underexplored, application of deep learning. Don't get discouraged by causal diagrams looking a lot like Bayesian networks (not a coincidence seeing they were both pioneered by Pearl) they don't compete with, they complement deep learning.</p>
<h2 id="basics">Basics</h2>
<p>First of all, causal calculus differentiates between two types of conditional distributions one might want to estimate. <strong>tldr</strong>: in ML we usually estimate only one of them, but in some applications we should actually try to or have to estimate the other one.</p>
<p>To set things up, let's say we have i.i.d. data sampled from some joint $p(x,y,z,\ldots)$. Let's assume we have lots of data and the best tools (say, deep networks) to fully estimate this joint distribution, or any property, conditional or marginal distribution thereof. In other words, let's assume $p$ is known and tractable. Say we are ultimately interested in how variable $y$ behaves given $x$. At a high level, one can ask this question in two ways:</p>
<ul>
<li>
<p>observational $p(y\vert x)$: What is the distribution of $Y$ given that I <strong>observe</strong> variable $X$ takes value $x$. This is what we usually estimate in supervised machine learning. It is a conditional distribution which can be calculated from $p(x,y,z,\ldots)$ as a ratio of two of its marginals. $p(y\vert x) = \frac{p(x,y)}{p(x)}$. We're all very familiar with this object and also know how to estimate this from data.</p>
</li>
<li>
<p>interventional $p(y\vert do(x))$: What is the distribution of $Y$ if I were to <strong>set</strong> the value of $X$ to $x$. This describes the distribution of $Y$ I would observe if I intervened in the data generating process by artificially forcing the variable $X$ to take value $x$, but otherwise simulating the rest of the variables according to the original process that generated the data. (note that the data generating procedure is NOT the same as the joint distribution $p(x,y,z,\ldots)$ and this is an important detail).</p>
</li>
</ul>
<h2 id="arenttheythesamething">Aren't they the same thing?</h2>
<p>No. $p(y\vert do(x))$ and $p(y\vert x)$ are not generally the same, and you can verify this with several simple thought experiments. Say, $Y$ is the pressure in my espresso machine's boiler which ranges roughly between $0$ and $1.1$ bar depending on how long it's been turned on. Let $X$ be the reading of the built-in barometer. Let's say we jointly observe X and Y at random times. Assuming the barometer functions properly $p(y|x)$ should be a unimodal distribution centered around $x$, with randomness due to measurement noise. However, $p(y|do(x))$ won't actually depend on the value of $x$ and is generally the same as $p(y)$, the marginal distribution of boiler pressure. This is because artificially setting my barometer to a value (say, by moving the needle) won't actually cause the pressure in the tank to go up or down.</p>
<p>In summary, $y$ and $x$ are correlated or statistically dependent and therefore seeing $x$ allows me to predict the value of $y$, but $y$ is not caused by $x$ so setting the value of $x$ won't effect the distribution of $y$. Hence, $p(y\vert x)$ and $p(y\vert do(x))$ behave very differently. This simple example is just the tip of the iceberg. The differences between interventional and observational conditionals can be a lot more nuanced and hard to characterize when there are lots of variables with complex interactions.</p>
<h2 id="whichonedoiwant">Which one do I want?</h2>
<p>Depending on the application you want to solve, you should seek to estimate one of these conditionals. If your ultimate goal is diagnosis or forecasting (i.e. observing a naturally occurring $x$ and inferring the probable values of $y$) you want the observational conditional $p(y\vert x)$. This is what we already do in supervised learning, this is what Judea Pearl called curve fitting. This is all good for a range of important applications such as classification, image segmentation, super-resolution, voice transcription, machine translation, and many more.</p>
<p>In applications where you ultimately want to control or choose $x$ based on the conditional you estimated, you should seek to estimate $p(y\vert do(x))$ instead. For example, if $x$ is a medical treatment and $y$ is the outcome, you are not merely interested in observing a naturally occurring treatment $x$ and predicting the outcome, we want to <em>proactively choose</em> the treatment $x$ given our understanding of how it effects the outcome $y$. Similar situations occur in system identification, control and online recommender systems.</p>
<h2 id="whatexactlyispyvertdox">What exactly is $p(y\vert do(x))$?</h2>
<p>This is perhaps the main concept I haven't grasped before. $p(y\vert do(x))$ is in fact a vanilla conditional distribution, but it's not computed based on $p(x,z,y,\ldots)$, but a different joint $p_{do(X=x)}(x,z,y,\ldots)$ instead. This $p_{do(X=x)}$ is the joint distribution of data which we would observe if we actually carried out the intervention in question.  $p(y\vert do(x))$ is the conditional distribution we would learn from data collected in <a href="https://en.wikipedia.org/wiki/Randomized_controlled_trial">randomized controlled trials</a> or A/B tests where the experimenter controls $x$. Note that actually carrying out the intervention or randomized trials may be impossible or at least impractical or unethical in many situations. You can't do an A/B test forcing half your subjects to smoke weed and the other half to smoke placebo to understand the effect on marijuana on their health. Even if you can't directly estimate $p(y\vert do(x))$ from randomized experiments, the object still exists. The main point of causal inference and do-calculus is:</p>
<blockquote>
<p>If I cannot measure $p(y\vert do(x))$ directly in a randomized controlled trial, can I estimate it based on data I observed outside of a controlled experiment?</p>
</blockquote>

<p>Let's start with a diagram that shows what's going on if we only care about $p(y\vert x)$, i.e. the simple supervised learning case:</p>
<p><img src="https://www.inference.vc/content/images/2018/05/Causality-0_-just-observational.png" alt=""></p>
<p>Let's say we observe 3 variables, $x, z, y$, in this order. Data is sampled i.i.d. from some observable joint distribution over 3 variables, denoted by the blue factor graph labelled 'observable joint'. If you don't know what a factor graph is, it's not important, the circles represent random variables, the little square represents a joint distribution of the variables it's connected to. We are interested in predicting $y$ from $x$, and say that $z$ is a third variable which we do not want to infer but we can also measure (I included this for completeness). The observational conditional $p(y\vert x)$ is calculated from this joint via simple conditioning. From the training data we can build a model $q(y\vert x;\theta)$ to approximate this conditional, for example using a deep net minimizing cross-entropy or whatever.</p>
<p>Now, what if we're actually interested in $p(y\vert do(x))$ rather than $p(y\vert x)$? This is what it looks like:</p>
<p><img src="https://www.inference.vc/content/images/2018/05/Causality-2_-two-distros.png" alt=""></p>
<p>So, we still have the blue observed joint and data is still sampled from this joint. However, the object we wish to estimate is on the bottom right, the red intervention conditional $p(y\vert do(x))$. This is related to the intervention joint which is denoted by the red factor graph above it. It's a joint distribution over the same domain as $p$ but it's a different distribution. If we could sample from this red distribution (e.g. actually run a randomized controlled trial where we get to pick $x$), the problem would be solved by simple supervised learning. We could generate data from the red joint, and estimate a model directly from there. However, we assume this is not possible, and all we have is data sampled from the blue joint. We have to see if we can somehow estimate the red conditional $p(y\vert do(x))$ from the blue joint.</p>
<h3 id="causalmodels">Causal models</h3>
<p>If we want to establish a connection between the blue and the red joints, <em>we must</em> introduce additional assumptions about the causal structure of the data generating mechanism. The only way we can make predictions about how our distribution changes as a consequence of an interaction is if we know how the variables are causally related. This information about causal relationships is not captured in the joint distribution alone. We have to introduce something more expressive than that. Here is how what this looks like:</p>
<p><img src="https://www.inference.vc/content/images/2018/05/Causality_-building-a-bridge--1-.png" alt=""></p>
<p>In addition to the observable joint we now also have a causal model of the world (top left) This causal model contains more detail than the joint distribution: it knows not …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.inference.vc/untitled/">https://www.inference.vc/untitled/</a></em></p>]]>
            </description>
            <link>https://www.inference.vc/untitled/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25645205</guid>
            <pubDate>Tue, 05 Jan 2021 13:21:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing User Personas]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25644758">thread link</a>) | @jrdnbwmn
<br/>
January 5, 2021 | https://learnuxd.io/posts/fixing-user-personas/ | <a href="https://web.archive.org/web/*/https://learnuxd.io/posts/fixing-user-personas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure>
    <img src="https://learnuxd.io/img/posts/user-personas/cover.svg" alt="Solving the problem with user personas">
</figure>

<p>User personas are controversial.</p>

<p>They’re built with great intentions, and then break down. People aren’t sure how to create them. They sit in drawers and hang on the wall, forgotten or ignored.</p>

<p>But personas can be very beneficial <em>if</em> they’re created and used properly.</p>

<p>Here are a few reasons why your personas may be failing, and some fixes to turn them into a useful resource.</p>

<ol id="markdown-toc">
  <li><a href="#whats-the-problem-with-personas" id="markdown-toc-whats-the-problem-with-personas">What’s the problem with personas?</a></li>
  <li><a href="#best-practices" id="markdown-toc-best-practices">Best practices</a>    <ol>
      <li><a href="#discover-from-research" id="markdown-toc-discover-from-research">Discover from research</a></li>
      <li><a href="#add-only-relevant-useful-information" id="markdown-toc-add-only-relevant-useful-information">Add only relevant, useful information</a></li>
      <li><a href="#involve-everyone-in-making-them" id="markdown-toc-involve-everyone-in-making-them">Involve everyone in making them</a></li>
      <li><a href="#include-psychographics-not-demographics" id="markdown-toc-include-psychographics-not-demographics">Include psychographics, not demographics</a></li>
      <li><a href="#limit-how-many-you-own" id="markdown-toc-limit-how-many-you-own">Limit how many you own</a></li>
      <li><a href="#use-them-properly" id="markdown-toc-use-them-properly">Use them properly</a></li>
      <li><a href="#update-them-over-time" id="markdown-toc-update-them-over-time">Update them over time</a></li>
    </ol>
  </li>
  <li><a href="#what-are-the-benefits-of-correctly-built-personas" id="markdown-toc-what-are-the-benefits-of-correctly-built-personas">What are the benefits of correctly-built personas?</a></li>
  <li><a href="#wrapping-up" id="markdown-toc-wrapping-up">Wrapping up</a></li>
</ol>

<h2 id="whats-the-problem-with-personas">What’s the problem with personas?</h2>

<p>The issue isn’t with the tool itself, it’s the fact that they have been misunderstood and misused over the years. Product teams have gotten tired of the bad experiences that come with this.</p>

<p>The main cause of the problems is that <em>design</em> personas get mixed up with <em>marketing</em> personas. Sales departments were using personas long before we were, and the two types got jumbled together.</p>

<p>But the two don’t mix<span>—</span>they serve different purposes. Marketing focuses on info that isn’t useful for designers or is downright distracting. Product people don’t just want to know the <strong>what</strong>, we want to know the <strong>why</strong>.</p>

<p>Take this example: “Jill is a Wisconsin soccer mom with three kids in an upper-middle-class income bracket who is the PTA president.” That persona might help the sales team know how to target Jill, but it doesn’t help the design team make a good product for her.</p>

<p>We need to untangle marketing persona practices from UX personas, and help product teams use them correctly.</p>

<h2 id="best-practices">Best practices</h2>

<p>Here are a few principles that will help you steer your personas in the right direction.</p>

<h3 id="discover-from-research">Discover from research</h3>

<p>Too often, personas are based on whims and guesses instead of <a href="https://learnuxd.io/posts/user-research-is-it-worth-it/" target="_blank" rel="noopener">research</a> (I’m looking at you, proto-personas).</p>

<p>Actionable, accurate, useful personas are <em>discovered</em>, not <em>created</em>. They are a result of research. They’re a data visualization. You don’t begin with personas, you gather and analyze research to see where personas emerge.</p>

<p>If we don’t have the data, we don’t make a persona. We can use something else to capture assumptions, like an <a href="https://www.playbookux.com/validate-your-assumptions-with-an-assumptions-map/" target="_blank" rel="noopener">assumption map</a>.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-personas/discover-from-research.svg" alt="Discover from research">
</figure>

<h3 id="add-only-relevant-useful-information">Add only relevant, useful information</h3>

<p>Personas should be short, digestible, and focused.</p>

<p>Every piece of information should have a purpose for being included. Only add data that directly affects the design process.</p>

<p>Lots of persona templates or examples have things like personality spectrums, favorite music, hobbies, and so on. These charts might look nice, but they’re usually unclear or irrelevant. A designer can’t get anything actionable from knowing that a persona got a 4 out of 5 on “Open to new experiences.”</p>

<p>Condense things down to avoid clutter and noise, and focus on data that matters. And remember you don’t have to rely on knowing someone’s favorite food to empathize with them (more on that later).</p>



<figure>
    <img src="https://learnuxd.io/img/posts/user-personas/only-relevant-info.svg" alt="Add only relevant, useful information">
</figure>

<h3 id="involve-everyone-in-making-them">Involve everyone in making them</h3>

<p>You may run into problems if you create your personas in a silo and then unveil them like a piece of artwork to be imposed on everybody.</p>

<p>Instead, get others involved. Everyone who is going to <em>use</em> the personas should be involved in <em>making</em> them. This builds a feeling of ownership and approval.</p>

<p>Invite teammates to sit in on research sessions. Get help brainstorming persona names. Keep the team updated on how the research is going and explain decisions. Figure out ways to get others involved until everyone is happy with the final product.</p>

<blockquote>
  <p>Personas work best when co-researched and co-created.<br>
– <a href="https://jeffgothelf.com/" target="_blank" rel="noopener">Jeff Gothelf</a></p>
</blockquote>

<figure>
    <img src="https://learnuxd.io/img/posts/user-personas/involve-everyone.svg" alt="Involve everyone in making them">
</figure>

<h3 id="include-psychographics-not-demographics">Include psychographics, not demographics</h3>

<p>Demographics are a carryover from marketing personas. In UX, what we’re really after is psychographics: <a href="https://www.nngroup.com/articles/mental-models/" target="_blank" rel="noopener">mental models</a>, motivations, pain points, attitudes, behaviors. Statistics like age, gender, ethnicity, and location do not cause thinking or behavior, so they have no bearing on the design process.</p>

<p>There is a <a href="https://medium.com/inclusive-software/describing-personas-af992e3fc527" target="_blank" rel="noopener">rising movement</a> in the UX field to completely leave out <em>all</em> demographics from personas (unless your particular product is demographic-specific).</p>



<p>Demographics cause problems. Attributes like gender, age, and race trigger our brain to think in stereotypes and assumptions. It can even lead us to favor one persona over another.</p>

<p>In the past, demographics have been used to make personas feel more relatable and help us empathize with them. But as <a href="https://indiyoung.com/" target="_blank" rel="noopener">Indi Young</a> says:</p>

<blockquote>
  <p>To actually bring a description to life, to actually develop empathy, you need the deeper, underlying reasoning behind the preferences and statements-of-fact.</p>
</blockquote>

<figure>
    <img src="https://learnuxd.io/img/posts/user-personas/psychographics-not-demographics.svg" alt="Include psychographics, not demographics">
</figure>

<h3 id="limit-how-many-you-own">Limit how many you own</h3>

<p>A product team should only have a handful of personas. Having too many takes away their ability to become memorable or useful. We can aim for a ballpark of 3 to 5.</p>

<p>Having this low number requires that we use the right <a href="https://www.nngroup.com/articles/persona-scope/">scope</a>. Remember it’s better to paint with a broad brush and meet the needs of larger groups of users than try to account for every edge case. The goal of personas is to focus on the major needs of the largest and most important users.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-personas/how-many.svg" alt="Limit how many you have">
</figure>

<h3 id="use-them-properly">Use them properly</h3>

<p>Most people aren’t well educated on what personas are or how to use them, especially if they aren’t UX designers. So our job is to <em>lead by example</em>, and <em>teach others</em>.</p>

<p>Get a core group of advocates to help lead the charge. Teach people how to write user stories with personas in mind. Put them out where people can see them. Bring them up in design meetings and keep them in the narrative of your product. You want to get them off the paper and into the minds of your team so they come up organically.</p>

<p>It’s also important to know the limits of personas and educate others on what those limits are. They’re useful, but they’re only <em>one tool</em> in your tool belt. They don’t have all the answers, and they aren’t the right approach for every decision.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-personas/use-them-properly.svg" alt="Use them properly">
</figure>

<h3 id="update-them-over-time">Update them over time</h3>

<p>Our personas should be living, breathing representations, not stagnant, stale PDFs. You don’t make it once and then lock it away forever behind a glass door.</p>

<p>This means they need to change over time and adapt to research we perform. When new data comes in, we should update our personas according to what we’ve learned.</p>

<p>Don’t forget to proactively revisit and reprocess them every once in a while. It’s an ongoing project.</p>

<figure>
    <img src="https://learnuxd.io/img/posts/user-personas/update-over-time.svg" alt="Update them over time">
</figure>

<h2 id="what-are-the-benefits-of-correctly-built-personas">What are the benefits of correctly-built personas?</h2>

<p>When you get personas right, they offer lots of benefits:</p>

<ul>
  <li>
    <p><strong>Communicate research findings clearly and succinctly</strong>, especially to others on the team who weren’t able to be part of the research process.</p>
  </li>
  <li>
    <p><strong>Give your whole team a central point of reference</strong> and a shared understanding and vocabulary about who you work for. Stay focused and avoid getting stuck in the weeds.</p>
  </li>
  <li>
    <p><strong>Help you relate to and remember your users better.</strong> Our brains are wired to empathize with <a href="https://youtu.be/XnG4c4gXaQY" target="_blank" rel="noopener">individuals, not groups</a>. So using a collective noun (like saying, “the user”) prevents us from empathizing with our userbase. We can’t wrap our heads around a big group of people, but we instantly connect with one individual. When groups of users are represented by a persona, imagining what they would do is a lot easier than pouring over cold, hard, abstract data.</p>
  </li>
  <li>
    <p><strong>Make better decisions.</strong> When people start giving their assumptions and making guesses, you can go back to your research-backed persona to point out what really matters.</p>
  </li>
  <li>
    <p><strong>Augment other types of research</strong>, like empathy maps, user scenarios, journey maps, user interviews, and <a href="https://learnuxd.io/posts/the-how-and-why-of-user-flows/" target="_blank" rel="noopener">user flows</a>.</p>
  </li>
</ul>

<h2 id="wrapping-up">Wrapping up</h2>

<p>I’m curious to hear if this helped you better understand user personas. If you still have questions or want to talk through things, I’m always happy to chat <a href="https://twitter.com/learn_uxd" target="_blank" rel="noopener">on Twitter</a>.</p>

<p>If you found this helpful, giving the Twitter thread some love is really appreciated 🙏🏻:</p>

<div>
    <div>
        <blockquote><div lang="en" dir="ltr"><p>💁🏻 User personas can be controversial and problematic. Lots of us have had bad experiences with them. </p><p>Here are a few reasons why your personas may be failing, and some fixes to turn them into a useful resource.</p><p>[thread ⤵] <a href="https://t.co/UyMweQufxG">pic.twitter.com/UyMweQufxG</a></p></div>— Learn UXD (@learn_uxd) <a href="https://twitter.com/learn_uxd/status/1346426212088950784?ref_src=twsrc%5Etfw">January 5, 2021</a></blockquote>
    </div>
</div>

<p><em>Big thanks to multiple designers in <a href="https://researchops.community/" target="_blank" rel="noopener">ResearchOps</a>, <a href="https://thedesignership.com/" target="_blank" rel="noopener">TheDesignership</a>, <a href="https://www.reddit.com/r/UXResearch/comments/k9ztdh/what_are_the_problems_with_user_personas/" target="_blank" rel="noopener">r/UXResearch</a>, and <a href="https://www.reddit.com/r/userexperience/comments/k9ztib/what_are_the_problems_with_user_personas/" target="_blank" rel="noopener">r/userexperience</a> for sharing their experiences and giving input on user persona best practices!</em></p>

</div></div>]]>
            </description>
            <link>https://learnuxd.io/posts/fixing-user-personas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25644758</guid>
            <pubDate>Tue, 05 Jan 2021 12:18:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hyperland, Intermedia, and the Web That Never Was]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25644745">thread link</a>) | @panic
<br/>
January 5, 2021 | https://www.are.na/blog/hyperland-intermedia-and-the-web-that-never-was | <a href="https://web.archive.org/web/*/https://www.are.na/blog/hyperland-intermedia-and-the-web-that-never-was">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.are.na/blog/hyperland-intermedia-and-the-web-that-never-was</link>
            <guid isPermaLink="false">hacker-news-small-sites-25644745</guid>
            <pubDate>Tue, 05 Jan 2021 12:16:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Now Habit]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25644709">thread link</a>) | @Tomte
<br/>
January 5, 2021 | https://www.2uo.de/the-now-habit/ | <a href="https://web.archive.org/web/*/https://www.2uo.de/the-now-habit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>



</header>

<p>
<em>The Now Habit</em> by Neil Fiore is a self-help book about understanding
and overcoming procrastination.
</p>

<p>
Procrastination is a mechanism to cope with the fear that is linked to the beginning
or the end of a task. Nobody is “lazy” on all fields of endeavor. You might not be able
to start the next chapter of your novel, but still do the required reading for your
college course.
</p>

<p>
A good way to start on managing procrastination is having a procrastination log where you jot down
the time, the activity, your thoughts and feelings, your excuse, your attempt of a solution
and your resulting thoughts and feelings.
</p>

<p>
The usual cycle of procrastination looks like this:
</p>

<ol>
<li>
You let the task at hand influence your happiness and self-worth.
</li>

<li>
You want to execute the task very well, so that your perfectionism is satisfied.
Thereby you increase your chance of failure by setting the bar very high.
</li>

<li>
You fear that you cannot meet the expectations you have imposed on yourself. You cannot act.
</li>

<li>
You avoid the problem by procrastinating.
</li>

<li>
Shortly before the deadline you <em>have</em> to do something. You do it, but not as well
as you could have, given the time allotted.
</li>
</ol>

<p>
The first step towards keeping procrastination at bay is to create safety. Failure must not
be the end of the world. You need to remember that many very successful people had big failures.
Your value as a person does not depend on the task.
</p>

<p>
A way to reduce the pressure you feel is to be mindful of language. Avoid “I must” and “I should”.
Try to think in terms of “I want to”, “I choose” and “I decide”.
</p>

<p>
A “should” means not being happy with a situation and deciding to do something about it.
It does not mean “I dislike the way it is and I'm going to complain”.
</p>

<p>
“I must finish” is not a helpful way of thinking. The better way is “When can I start?”.
Try to get things done at least partially, long before a deadline looms.
</p>

<p>
Partial work is an important aspect: you don't have to complete a big project in one sitting.
Bite a small, manageable chunk off and get that done. The project may be big, but it can be tackled
in smaller parts. Do a first draft. Or one test chapter. Maybe it even helps to do a first draft
sloppily on purpose and edit it afterwards.
</p>

<p>
“I must be perfect” is inhumane. You are allowed to be human. Learn from mistakes, respect boundaries.
Don't criticise yourself harshly. Have some compassion for yourself.
</p>

<p>
Take time off. Friends, Leisure time, your partner. They are important and healthy for you. Incorporate
leisure time and sports in your schedule. Don't let it be a secondary concern for “when you find the time”.
</p>

<p>
Imagine the concrete goal and the rewards. Let it pull you towards it. Don't think about the long way
till the goal, think about the way you've already behind yourself.
</p>

<p>
Don't get overwhelmed. You don't have to know the perfect starting point. You may take time to learn
and feel secure in your task. Don't bad-mouth your achievements and progress.
</p>

<p>
Plan in reverse and invent lots of smaller deadlines. Start with the externally imposed deadline.
Plan backwards what needs to be done to complete the task by that time. Plan intermediate steps
with their own, much shorter deadlines.
</p>

<p>
Channel your energy into actions to remove the threats that you fear.
</p>

<p>
Play through the worst case. What's the worst thing that can happen to you? Imagine what you could
do in such a situation. Are their alternatives? Are there maybe even upsides? How can you reduce
the probability of that worst case happening?
</p>

<p>
Sometimes people work on tasks pretty well and productively, but they never seem to finish a task.
Prolonging the almost-finished task takes up energy, as well. Just put that energy into finishing
and reap the rewards.
</p>

<p>
Excessive preparation before beginning a task is also just procrastination. Limit it and then just start.
If you really need research or other preparation, you will find out later.
</p>

<p>
Don't be discouraged by the seeming lack of progress after starting. It's often the case that the beginning
is the hardest and slowest part. The time spent in the first phase isn't lost, you've got a better
understanding of the problem and your task.
</p>

<p>
The fear that the demands of you will rise after successfully finishing the current job is irrational.
You will still have some autonomy to make an informed decision later. Don't fret about it now.  
</p>

<p>
If you feel that you need more time: are you sure that it isn't just perfectionism? Not everything
needs to be polished. Weigh the cost and benefit of working on it some more versus finishing it.
</p>

<p>
Use the “Unschedule”. The Unschedule is like a schedule, but it starts with you entering blocks
of recreational activities and leisure time. Only then do you enter your tasks, after you've worked
at least half an hour without interruption on them. This gives you a realistic overview of how much work
you can possibly tackle. Tasks are never scheduled, only recorded after the fact.
</p>

<p>
Aim for thirty minutes of uninterrupted, quality work. Take a break after that block.
</p>

<p>
Setbacks are inevitable. Look out for them. Observe yourself. What were your thoughts and feelings?
Why did you revert to your old ways? Make plans how to counter that in the future.
</p>

<p>
Drop goals that can neither be achieved nor started upon in the near future. Change your plans and
re-schedule it for a later time. Don't let that goal linger without any action towards completion.
</p>

</article></div>]]>
            </description>
            <link>https://www.2uo.de/the-now-habit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25644709</guid>
            <pubDate>Tue, 05 Jan 2021 12:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Connections and Pools]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25644656">thread link</a>) | @sudhirj
<br/>
January 5, 2021 | https://sudhir.io/understanding-connections-pools/ | <a href="https://web.archive.org/web/*/https://sudhir.io/understanding-connections-pools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <p>Connections are the hidden mechanism using which computer systems talk to each other—and they've become so fundamental that we overlook how important they are, how they work, and when they fail. We're often ignorant of them until there's a problem, which usually shows up a massive failure when our systems are doing their most amount of work. But because they're present everywhere and are so important in pretty much every system, they're worth spending a little time understanding. </p><h2 id="what-are-connections">What are connections?</h2><p>Connections are a link between two systems that allows them to exchange information as a sequence of zeroes and ones—to send and receive bytes.</p><p>Depending on where the systems are running relative to each other, a combination of underlying software and hardware will work hard to handle the physical movement of information, which <em>abstracts </em>it away. For example, if the communicating systems are two Unix processes, the <a href="https://www.usna.edu/Users/cs/wcbrown/courses/IC221/classes/L13/Class.html">IPC</a> system will handle allocating memory for the data exchanged and will handle pick-up and delivery of the bytes on both sides. If the systems are running on different computers, they will likely communicate over <a href="https://www.khanacademy.org/computing/computers-and-internet/xcae6f4a7ff015e7d:the-internet/xcae6f4a7ff015e7d:transporting-packets/a/transmission-control-protocol--tcp">TCP</a>, which will handle moving the data over a wired or wireless system between the computers. The details of how computers work together to reliably handle, transmit and receive the data is more a standardization problem, and most systems use the building blocks provided by the UDP and TCP protocols. How these connections are handled at each end is a more relevant problem for application development, which is what we'll look at now.</p><h2 id="where-do-we-use-connections">Where do we use connections?</h2><p>You're using them right now. Your browser made a connection to the web server that's hosting this blog, using which it fetched the bytes that make up the HTML, CSS, JavaScript and images that you're looking at. If you're using the HTTP/1.1 protocol, your browser made multiple connections to the server, one for each file. If you used HTTP/2, many of the files were likely served over the same connection, using <em>multiplexing</em>. In these cases your browser was the <em>client</em> and the blog server was... well, the <em>server</em>.</p><p>But the server also made connections of its own to give you this page. It used a connection to speak to a database, sending over the URL of this page inside a query and receiving the contents of the page in return. In this scenario, the application server was the <em>client</em> and the database server was the <em>server</em>. The application server might have also made connections to other third-party services, like a subscription or payment service, or a location service. </p><p>For static files, like the JS, CSS and images, there's a CDN system in between your browser and the blog server. A connection was made from your browser (client) to the CDN server (server) that's closest to you, and if the files weren't available in the cache near you there would have been another connection from the CDN server (client) to the blog server (server).</p><p>If you think carefully about all the systems you use or build, you'll see connections all over the place—but they're often hidden from view, and not understanding their invisible presence and limits will come back to bite you when (and where) you least expect it.</p><h2 id="why-is-connection-handling-important">Why is connection handling important?</h2><p>Understanding how connections are handled is important because the cost of connections is <em>asymmetric</em>—the cost is different on the client and server. In a peer to peer (P2P) system, like a torrent cloud, this is false, and connections have the same cost at both ends—but this is rarely the case. The common uses of connections have a client and a server, and the cost to the server is different from the cost to the client.</p><p>Before we look at how connections can be handled, we need to quickly review the different ways in which computers run programs and how programs do work in parallel. When you run a program, the operating system runs your code as one instance of a <em>process</em>. A <em>process</em> occupies one CPU core and some memory when it's running, and does not share its memory with any other processes. The process can start <em>threads</em>, which are like children of the process that can run concurrently<em>. Threads </em>share memory with the process that spawned them, and might allocate more memory for their use. Or the process might use an <em>event loop</em>, which is a single-processes system that keeps track of tasks it has to do and loops over all its tasks continuously and infinitely, each time doing the tasks that it can, or skipping them if they're blocked. Or the process might use internal constructs called <em>fibers, green-threads, coroutines, </em>or<em> actors—</em>each of these work a little differently and having varying costs—but they're all managed internally by the process and its threads.</p><p>Coming back to how connections are handled, let's look at database connections first—from your application server (the client in this case), you see a TCP connection paid for with a small memory buffer and one port allocation. On the server side, if you're using PostgreSQL, each connection is <a href="https://brandur.org/postgres-connections">handled</a> at the server by spawning a new process that handles all the queries being sent over that connection. This process occupies a CPU core, and about 10MB or more of memory in RAM. MySQL <a href="https://mysqlserverteam.com/mysql-connection-handling-and-scaling/">handles</a> each connection by spawning a thread inside of a process. The RAM/memory requirements are much lower in a threaded model, but it comes at the cost of context switching those threads. Redis <a href="https://redis.io/topics/clients">handles</a> each connection as an iteration in an event loop, which makes the resource costs low—but a price is paid in having to loop over every connection's queries and serving them strictly one at a time.</p><p>Consider a request to an application server. Your browser initiates a TCP connection as a client, which is cheap (small memory buffer and one port). On the server, the story is different. If the server is using Ruby on Rails, each connection is handled by one thread spawned inside a fixed number of running processes (the <a href="https://puma.io/">Puma</a> web server) or by one process (<a href="https://github.com/defunkt/unicorn">Unicorn</a>). If it's using PHP, the CGI systems start a new PHP process for each connection, and the more popular <a href="https://en.wikipedia.org/wiki/FastCGI">FastCGI</a> systems keep a few of the processes running to make handling the next connection faster. If you're using Go, one <em>goroutine </em>(a cheap and light thread-like structure, managed &amp; scheduled internally by the Go runtime) will be spawned to handle each connection. If you're using NodeJS/Deno, the incoming connections are handled in an event loop by iterating over them and responding to requests one at a time. In systems like Erlang/Elixir, each connection will be handled by an <em>actor</em>, which is another internally scheduled lightweight thread-like construct.</p><h2 id="connection-handling-architectures">Connection Handling Architectures</h2><p>The examples of how connections are handled have a few common strategies which we can identify:</p><p><strong>Processes:</strong> Each connection is handled by a separate process, either started exclusively for the connection (CGI, PostgreSQL), or maintained as part of a group of available processes (Unicorn, FastCGI).</p><p><strong>Threads:</strong> Each connection is handled by a separate thread, either spawned exclusively for the connection or held in reserve after spawning. The threads might be spread over multiple processes, but all threads are equivalent (Puma/Ruby, Tomcat/Java, MySQL).</p><p><strong>Event Loop:</strong> Each connection is an task in the event loop, and connections that have data to be read are processed by iterating over them (Node, Redis). These systems are normally single-process and single-threaded, but they may sometimes be multi-process, where each process acts as a semi-independent system with separate event loops.</p><p><strong>Coroutines / Green-Threads / Fibers / Actors:</strong> Each connection is handled by a lightweight construct whose scheduling is managed internally (Go, Erlang, Scala/Akka).</p><p>Knowing how your server is handling connections is crucial to understanding what its limits and scaling patterns are. Even basic usage or configuration requires knowledge of how the connection handling works: Redis and PostgreSQL, for example, offer different transaction &amp; locking semantics that are influenced by their respective connection handling mechanisms. Process &amp; thread based servers can crash because of resource exhaustion if their max counts are not set to a reasonable limit, and when limits are set they might be horribly under-utilized because the limits are too low. Event-loop based systems may not benefit at all from running on 64-core CPUs, unless 64 copies of them are configured to run simultaneously—which works great for web servers but not very often with databases.</p><p>Each of these ways of handling connections perform differently when used in application servers and databases, because of the distributed or centralized nature of each system. Application servers, for instance, tend to be horizontally scalable—they work correctly and in the same way whether you have 1 server or 10 or 10,000. In these cases, Moving away from the process / thread model tends to result in higher performance, because we want as much work to be done with minimal memory usage and CPU context switching. Event loops like Node work great on single core servers, but need to be clustered correctly to use multi-core severs. Coroutine / actor based systems like Go or Erlang will utilise every core of the CPU much easier because they're designed to work that way, with many thousands of goroutines or actors running simultaneously on a single machine.</p><p><em>Centralized databases</em>, on the other hand, benefit more from process / thread / event loop handling, because based on the transactional guarantees of the system we don't want multiple connections operating on the same data at the same time. The operations happening on multiple connections will have to lock during the transaction-sensitive parts of their work, or use other strategies like <a href="https://www.postgresql.org/docs/current/mvcc-intro.html">MVCC</a>, and the fewer possible connection handlers there are the better. These systems support a few connections on a single machine. On large server, PostgreSQL might manage …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sudhir.io/understanding-connections-pools/">https://sudhir.io/understanding-connections-pools/</a></em></p>]]>
            </description>
            <link>https://sudhir.io/understanding-connections-pools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25644656</guid>
            <pubDate>Tue, 05 Jan 2021 12:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Payment processor for Amazon India had leak of over 100M users]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25644187">thread link</a>) | @LordAtlas
<br/>
January 5, 2021 | https://www.businessinsider.in/tech/news/over-100-million-debit-and-credit-card-users-data-has-been-leaked-online-from-payments-processor-juspay-amazon-and-swiggy/articleshow/80096472.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/tech/news/over-100-million-debit-and-credit-card-users-data-has-been-leaked-online-from-payments-processor-juspay-amazon-and-swiggy/articleshow/80096472.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt80096472read"><div data-den="denmark"><div><ul>
 <li><strong>Information of over 100 million debit and credit card users has been leaked online from payments processor <keyword keytype="person" smid="0" usetype="2" keywordseo="Juspay" actualkeyword="Juspay">Juspay</keyword>.</strong></li>
 <li><strong>The leak includes the user’s names, contact information and information related to their debit and credit cards.</strong></li>
 <li><strong>Juspay processes payments for companies like Amazon, Swiggy, MakeMyTrip and several other companies.</strong></li>
 <li><strong>Cybersecurity researcher Rajshekhar Rajaharia who first spotted the breach has said that it could become a lot more serious if hackers figure out the encryption algorithm.</strong></li>
</ul><p>In what could be a major data breach, information of over 100 million debit and credit card users from payments processor Juspay has leaked on the dark web. Juspay processes payments for companies like Amazon, Swiggy, MakeMyTrip among others.
</p><p>
The leaked data is in the form of a data dump and has been leaked through a compromised server of Juspay. Juspay has 
<a target="_blank" href="https://juspayproducts.medium.com/your-security-is-our-first-concern-8d98c96e5f17" rel="nofollow">confirmed</a> the data leak in its official blog post, outlining the details of the breach.
</p><p>
    “It pains us to inform you that a data breach did happen on 18th August 2020. Non-sensitive masked card information, mobile numbers and email ids of a subset of our users were compromised,” the company said.
</p><p>Cybersecurity researcher Rajshekhar Rajaharia discovered the data breach. He found that the data dump was available for sale on the dark web.
</p><p>
    Speaking to Business Insider, Rajaharia noted that this data breach could be a lot more serious if the hackers figure out the encryption algorithm used to hash card numbers.
</p><p>

<strong>Here’s what was leaked in the <keyword keytype="UnKnown" smid="0" usetype="2" keywordseo="Juspay-Data-Breach" actualkeyword="Juspay data breach">Juspay data breach</keyword><br></strong>
<br>As per Juspay, the leaked information includes non-sensitive masked card information, mobile numbers and email IDs of a subset of users. The company has said that the leaked information does not include full card numbers, order information, card PIN or password.
</p><p><span>Advertisement</span></p><figure><div></div></figure><hr>
<p>The data on the dark web includes information such as the bank that has issued the card, card expiry date, the last four digits of the card, masked card number, card type and the user’s name, among other details.
</p><p>

<strong>Should you be worried?<br></strong>
<br>    Rajaharia pointed out that there could be a major risk to users if the algorithm used to hash card numbers is leaked or if the hackers figure it out on their own.
</p><p>A hash is a unique and fixed-length string that is mapped to a set of data. In this case, Juspay has hashed the 16-digit debit and credit card numbers in order to process transactions.
</p><p>
    If hackers can figure out the algorithm used to generate these hashes, they could use brute force and find out what the original card numbers are.
</p><p>
Juspay has masked only six digits out of sixteen-digit card numbers. Rajaharia says that while this is good, the safety of users rests primarily on the hashing algorithm.
</p>
<p><strong>Scammers could also exploit this data leak<br></strong>
<br>In addition to the risks mentioned above, Rajaharia also pointed out that scammers could exploit this data leak to dupe cardholders. Since the leak includes mobile numbers, they could call unsuspecting cardholders and trick them into revealing the full card numbers, PIN, CVV as well as one-time passwords.
</p><p>
Rajaharia also pointed out that since these users are paying customers, they are a lot more valuable than non-paying customers. This makes the </p><keyword keytype="UnKnown" smid="0" usetype="2" keywordseo="Juspay-data-leak" keynameseo="juspay-data-leak" actualkeyword="juspay data leak">Juspay data leak</keyword><p> a lot more lucrative for hackers and scammers.
</p><p>    
According to him, the seller he is in touch with has demanded $8,000 in Bitcoin to purchase the data.
</p>

<p><strong>SEE ALSO:<p><a href="https://www.businessinsider.in/tech/news/these-were-the-biggest-cyber-attacks-of-2020/slidelist/79941232.cms">From FireEye to Twitter to Covid-19 vaccine research ⁠— these were the biggest cyber attacks of 2020</a></p><p><a href="https://www.businessinsider.in/retail/news/hackers-are-sending-customers-fake-shipping-messages-appearing-to-come-from-amazon-and-ups-as-a-shipageddon-is-expected-during-a-hectic-shopping-season/articleshow/79816866.cms">Hackers are sending customers fake shipping messages appearing to come from Amazon and UPS as a 'shipageddon' is expected during a hectic shopping season</a></p></strong>
<br>    
</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/tech/news/over-100-million-debit-and-credit-card-users-data-has-been-leaked-online-from-payments-processor-juspay-amazon-and-swiggy/articleshow/80096472.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25644187</guid>
            <pubDate>Tue, 05 Jan 2021 10:52:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parable of Alien Chess]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 169 (<a href="https://news.ycombinator.com/item?id=25642635">thread link</a>) | @krebs_liebhaber
<br/>
January 4, 2021 | https://lukesmith.xyz/articles/chess | <a href="https://web.archive.org/web/*/https://lukesmith.xyz/articles/chess">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<a href="https://lukesmith.xyz/articles/pix/alien_pepe.jpg">
<img src="https://lukesmith.xyz/articles/pix/alien_pepe_small.gif" alt="Alien" title="Save before they delete it again.">
</a>

by <a href="https://lukesmith.xyz/index.html">Luke Smith</a>

<p>
<i>A parable on the Logical Postivist "interpretation" of scientific models.
<!-- Granted, I use the term "logical positivist" in a somewhat expanded but specific sense, -->
<!-- loosely the idea that "science is good models" or what was called in the past "instrumentalism." -->
</i>
</p>

<h2>The Parable</h2>

<p>
Suppose an alien race comes to Earth and wants to observe our games.
They are very interested in chess, despite the fact that they have eyes with properties that make it impossible to make out what actually happens on a chess board.
(The whites and blacks and squares all blur together.)
</p>

<p>
They can still learn about chess experimentally, they know they can sit two players (a so-called "white" and "black" player) down to play it, and they can tell behaviorally who at the end wins.
</p>

<p>
After extensive experimentation, they realize this: 50% of the time, the white player wins and 50% of the time, the black player wins (we'll ignore draws and any first-move advantage for the example).
</p>

<h3>The "best" model</h3>

<p>
A logical positivist alien thus creates the ultimate, long-term model of chess as an iterated game:
Chess amounts to just a drawn-out coin flip.
Half of the time white wins, half of the time black wins, just as if they were tossing a quarter.
</p>

<p>
The aliens then decide to model chess as a coin flip, as a 50-50 game with no underlying principles.
While this statistical technique might not be useful for predicting a single game, over the long run and over iterated games, <em>it is the most efficient and parsimonious possible model</em>.
</p>

<h3>"Inferior" models</h3>

<p>
Suppose, however that a "crank" scientist of the alien race posits that "God doesn't play dice" and that chess is a more complicated game, despite the fact that the aliens cannot observe it.
Suppose even he asks around and determines from humans that there are actually pieces on the board with functions, and he even devises a machine that allows his alien eyes to see the first move of the game of chess.
</p>

<p>
Seeing this move allows him to create a new theory and model of the game,
one that takes into account the first move made and he tries to generate a new set of probabilities of victory based on that move.
The model he makes, is of course highly arbitrary, stipulated and <em>ad hoc</em>.
In fact,
this model is inferior on many inevitable accounts.
For example:
</p>

<ol>
    <li>It is less predictive over iterated games than the coin flip model.</li>
    <li>It is not as parsimonious/minimal as the coin flip model.</li>
    <li>It adds new variables to the theory (pieces) that are suspect.</li>
</ol>

<h2>Which model is "right?"</h2>

<h3>Which model is closer to truth?</h3>

<p>
Since we, unlike the aliens, are not prevented by defect from observing chess, we know that the second, "inferior" theory of chess is truer.
Its theoretical categories, if apparently arbitrary in the eyes of the aliens, are getting at the actual underlying mechanics of chess.
Even if the model is less effective, it is certainly <em>righter</em>.
</p>

<h3>Which will cause fruitful scientific inquiry?</h3>

<p>
The coin flip model is a scientific dead-end.
Firstly, the coin flip model is constructed statistically, which presents the underlying mechanism to be randomness, and thus unworth of inquiry.
This isn't statistics hoisted above random variation we know to exist, instead, it's utterly blind statistics that covers over whatever principles underlie it.
</p>

<p>
Secondly and more importantly, in order to actually improve that model, it has to <em>lose</em> empirical solvency:
embracing the abstractions of pieces means introducing mess and
deviating in some way from the empircal generalization that half of all chess games are won by white and half by black.
</p>

<h3>This is not an abnormal circumstance.</h3>

<p>
The parable here, really an <em>example</em> is not abnormal.
In most affairs in science, whether that be physics or neuroscience or economics or chemistry, we are exactly like the partially-blind aliens.
</p>

<h3>"But science isn't about truth!"</h3>

<p>
Yeah, it is dude.
</p>

<p>
Even if you are pretending that science is about "models" or fitting equations and the like, again, the well-fit model is impossible to perfect, while the flawed, yet more true to reality model does have a potential over the long-term to be a superior one.
After exhaustive inquiry, an alien race might not only discover the pieces and the full set of rules behind chess, they might be able to predict what moves are good or bad and predict individual chess games.
Even on the standards of mere instrumentalism, the mindless positivistic theory is still actually inferior.
</p>

<h2>Local maxima</h2>

<img src="https://lukesmith.xyz/articles/pix/maximum.gif" alt="Local maximum">

<h3>The plot</h3>

<p>
One of the ways I visualize science and models is that each model is really like an n-dimensional optimization plot.
"Truth," or if you deny truth as metaphysics, "accuracy in data" or "well-fit equations" are upwards and the goal of science is to get further that way.
</p>

<p>
At the point you're at, you can tell which direction you can go to move upward, or, which little changes you can make to improve your model.
That is what incremental science is, after all: don't change assumptions and just fine-tune your equations.
The endless fine-tuning is sometimes thought of as "progress."
Of course I don't think that this is <em>bad</em>, but it is a very minor and scientifically less important part of science as a whole.
</p>

<p>
The reality of incremental science is that once you're at a local maximum, once you've fine-tuned your equations about as perfectly as possible,
it's over.
Everything next to you <em>looks</em> like a disimprovement.
It <em>looks</em> just like those inferior theories of alien chess that posit the existence of pieces.
From that, you might erroneously conclude that you have found the <em>global</em> maximum, which
due to the nature of the complexity of the universe and the multiplicity of
possible answers and theories, you flatly haven't.
</p>

<p>
Logical positivism is kind of theoretical lobotomy that implicitly tells scientists that they should never, ever, ever change foundational assumptions:
tweaking equations like an oblivious autist is Science®️ and everything else is "philosophy" or "metaphysics" or "pseudoscience."
This amounts to keeping each scientific field on whatever local maximum is closest, utterly unable to extricate themselves from it even when they see on the horizon abberant data.
<strong>If you want to understand the stagnation of science or any other specific field, this is where it comes from.</strong>
</p>

<h3>Purposefully "bad" science</h3>

<p>
In <i><a href="https://traffic.libsyn.com/secure/notrelated/S02E01_-_Against_Method_and_For_Pseudoscience.ogg">Against Method</a></i>, Paul Feyerabend, in what an unreflective mind might misinterpret as a "troll," says that it is important for science that people have biases, financial interests, interfering religious and political doctrines and the like in science.
Looking at the plot, you might now see why.
When we are stuck on a local maximum, every new data keeps our already-optimized model where it is no matter how low that maximum actually is.
What you need to shake it up is an external shock that totally moves our theoretical position somewhere new on the plot where we can try to optimize at another point, and then compare.
</p>

<h3>Basic assumptions</h3>

<p>
A prudent person should be able to question, "Am I even on the right track or am I playing with some model that has a fundamental flaw?"
I can guarantee you, optimizing for data and fitting math and equations is easy.
<strong>All theoretical programs are wrong because they make incorrect core assumptions.</strong>
This is very hard for the ego of scientists because it means:
</p>

<ol>
    <li>Possibly illiterate dilettantes on the internet might see and bring to attention legitimate theoretical flaws.</li>
    <li>All the years you spend in graduate school counting angels on pinheads in your respective theoretical framework is mostly a waste of time.</li>
    <li>The borders of science are borders more of a sociological club than being the border of raw rigor.</li>
    <li>Most of the scientific work is not meaningful outside of the theoretical framework that gave rise to it.</li>
</ol>

    <hr>
    




</div>]]>
            </description>
            <link>https://lukesmith.xyz/articles/chess</link>
            <guid isPermaLink="false">hacker-news-small-sites-25642635</guid>
            <pubDate>Tue, 05 Jan 2021 05:58:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blocking Pinterest may reduce your data usage]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 147 (<a href="https://news.ycombinator.com/item?id=25642392">thread link</a>) | @rukshn
<br/>
January 4, 2021 | https://ruky.me/2021/01/05/you-might-want-to-block-pinterest-to-save-your-data/ | <a href="https://web.archive.org/web/*/https://ruky.me/2021/01/05/you-might-want-to-block-pinterest-to-save-your-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><em>I guess this is the first blog post of the new year, even though I’m not someone who is keen on celebrating a new year, I sincerely hope every one would have a very bright 2021.</em></p>
<p>Most of you are enjoying unlimited internet at your homes, but sadly <a href="https://ruky.me/2020/12/28/sri-lanka-need-unlimited-internet-connections/">I’m coming from a part of the world that charges according to the data I use. </a></p>
<p>I basically pay for my <strong>home broadband </strong>data and I have monthly cap, and if I exceed that data limit I will have to buy an expensive data add-on. So data is something precious to me.</p>
<p>In the month of December, may be due to a technical error by the ISP my data add-on finished and I made a tweet criticizing them.</p>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Scammed again by <a href="https://twitter.com/SriLankaTelecom?ref_src=twsrc%5Etfw">@SriLankaTelecom</a> you should be ashamed of your practices </p><p>Bought a zoom package and data add-on today because I need zoom to work</p><p>But then suddenly by noon the internet got slower. And I checked why</p><p>My data add-on has expired but my 100% zoom data remaining</p></div>— Rukshan (@JustRuky) <a href="https://twitter.com/JustRuky/status/1344554873744855040?ref_src=twsrc%5Etfw">December 31, 2020</a></blockquote>
<p>The ISP was kind enough to reach out to me and I received an email detailing the data use of my internet connection.</p>
<p>It is a table with the websites/protocols I used, the data transmitted to that website/protocol in bytes.</p>
<p>One thing that immediately caught my eye was what’s at number 2, it was <strong>Pinterest</strong>.</p>
<p>Before I get into more detail, I want to tell you that I’m not an active Pinterest user, I don’t use their app on my mobile device. The only way I land on Pinterest is when I go to their website from Google image search results.</p>
<figure><img data-attachment-id="114" data-permalink="https://ruky.me/2021/01/05/you-might-want-to-block-pinterest-to-save-your-data/img_0074/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?fit=1194%2C276&amp;ssl=1" data-orig-size="1194,276" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_0074" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?fit=300%2C69&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?fit=1024%2C237&amp;ssl=1" loading="lazy" width="1024" height="237" src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=1024%2C237&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=1024%2C237&amp;ssl=1 1024w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=300%2C69&amp;ssl=1 300w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=768%2C178&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?w=1194&amp;ssl=1 1194w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=1024%2C237&amp;ssl=1 1024w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=300%2C69&amp;ssl=1 300w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=768%2C178&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?w=1194&amp;ssl=1 1194w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2021/01/img_0074.jpg?resize=1024%2C237&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "><figcaption>The 17 connections to Pinterest has downloaded more than 1GB of data</figcaption></figure>
<p><strong>There has been 17 connections to Pinterest and Pinterest has sent me more than 1.2GB of data.</strong></p>
<p>Even the 2000+ requests to Facebook has only downloaded roughly 300MB of data.</p>
<p>Why Pinterest is sending so much data in just 17 requests? What do they contain?</p>
<p>Maybe they are preloading or caching images for better user experience. But still 1.28GB of images is likely to have more than 1000 images.</p>
<p>Another explanation can that the ISP is trying to give me an explanation why my data vanished. But both explanations doesn’t make any sense.</p>
<p>Since data is valuable to me I will try to block requests to Pinterest, and see if that will make a difference to my data usage.</p>
<p>I’ll request another report at the end of the month to see my data usage for the month of January to compare before and after blocking Pinterest.</p>
<p>Has anyone had a similar experience in Pinterest or is it just me?</p>
<p><strong>Update</strong> : Made to the front page of HN, <a href="https://news.ycombinator.com/item?id=25642392">https://news.ycombinator.com/item?id=25642392</a><a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=25642392" target="_blank">https://news.ycombinator.com/item?id=25642392</a></p>
<p>I edited my post to answer some questions raised on HN.</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2021/01/05/you-might-want-to-block-pinterest-to-save-your-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25642392</guid>
            <pubDate>Tue, 05 Jan 2021 05:17:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I almost quit caffeine in one year]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 278 (<a href="https://news.ycombinator.com/item?id=25642182">thread link</a>) | @dhruvkar
<br/>
January 4, 2021 | https://www.wints.org/blog/2021.01.04/ | <a href="https://web.archive.org/web/*/https://www.wints.org/blog/2021.01.04/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
		<p>Splitting headache at 10am. Not a fine way to start the day.</p>
<p>For the last 10+ years, I’ve consumed 2-5 cups of coffee every day. I was hooked to coffee is an understatement. It had gotten so bad that if I didn’t get coffee by 9am, I’d get a debilitating migraine for the rest of the day. I also had restless sleep, bordering on insomnia, where I wouldn’t sleep at all for a couple nights a month.</p>
<div>
<p><img src="https://www.wints.org/img/articles/2021.01.04/coffee.jpg" alt="Coffee"></p><figcaption>Sleep killer, headache giver, kick in the butt</figcaption>
</div>
<p>In February 2020, I got the worst flu in years (don’t think it was COVID). The first three days were extra painful with withdrawal headaches.
I decided a change was in order. My last coffee was January 31st, 2020.
The rest of the process was not predetermined. I tried to follow my body needs and didn’t push to quit with a definite date in mind.</p>
<p>After I recovered from the flu, I switched to black tea for the next several months.
I felt physically sluggish and mentally slower.</p>
<p>Black tea was followed by green tea for about two months. My sleep dramatically improved, however still felt lethargic. After green tea, I still didn’t feel ready to stop all together.</p>
<div>
<p><img src="https://www.wints.org/img/articles/2021.01.04/tea.jpg" alt="Jasmine Pearl Tea"></p><figcaption>Savior, kinda</figcaption>
</div>
<p>Enter <u><a href="https://amzn.to/3pwj3Cc">jasmine pearl tea</a></u>. It’s rolled up into a ball and each ball has 1-3 tea leaves. I started using three tea balls for my morning tea. Over the course of three months, I’m down to <i>one tea ball every other day</i>. It’s been a useful tool for measuring caffeine intake. Final quitting day is February 1st, 2021.</p>
<p>The few things I’ve learned along the way:</p>
<h5 id="a-dont-plan-for-every-eventuality">A. Don’t plan for every eventuality</h5>
<p>It was tempting to outline every possible aspect of this challenge – what to drink, when to drink it, how often, when to decrease dosage, what to do in case of a backslide etc. I consciously avoided this for two reasons. One, making a full blown plan feels so satisfying that the actual challenge doesn’t feel compelling anymore, leading me to underperform or give up. And two, I might give up if I backslide so badly that my plan doesn’t account for it. That’s pretty demoralizing.</p>
<h5 id="b-celebrate-positive-consequences">B. Celebrate positive consequences</h5>
<p>I still have headaches if I miss my “caffeine window”. But they are far less painful and much more manageable. That’s a win! I sleep so much better now too.</p>
<h5 id="c-take-your-time">C. Take your time</h5>
<p>It took 10 years to get to this level of caffeine dependence. Spending one year to unwind this addiction is relatively fast! I felt a lot slower mentally in the first 6 months and still do as I continue to reduce my caffeine. I expect that once I no longer depend on caffeine, my body will pick up the slack.</p>
<p>All in all, This has been another step in discipline and a healthier me.</p>

	</div>
  </div></div>]]>
            </description>
            <link>https://www.wints.org/blog/2021.01.04/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25642182</guid>
            <pubDate>Tue, 05 Jan 2021 04:40:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principle of Maximum Entropy]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25641459">thread link</a>) | @keyboardman
<br/>
January 4, 2021 | https://leimao.github.io/blog/Maximum-Entropy/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Maximum-Entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>The principle of maximum entropy states that the probability distribution which best represents the current state of knowledge is the one with largest entropy, in the context of precisely stated prior data (such as a proposition that expresses testable information). These prior data serves as the constrains to the probability distribution.</p>



<p>Given the second law of thermodynamics (principle of increase of entropy), isolated systems spontaneously evolve towards thermodynamic equilibrium, the state with maximum entropy, maximum entropy distributions become the most natural distributions under certain constrains. In this blog post, I would like to discuss entropy maximization and a couple of maximum entropy distributions.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="gaussian-integral">Gaussian Integral</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi} \\
\end{align}\]

</p><p>I will skip the proof here, since the proof from <a href="https://en.wikipedia.org/wiki/Gaussian_integral">Wikipedia</a> is not that difficult to understand.</p>

<h4 id="useful-integrals">Useful Integrals</h4><p>

\[\begin{align}
\int_{-\infty}^{\infty} x e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} e^{-x^2} d(-x^2) \\
&amp;= -\frac{1}{2} e^{-x^2} \big\rvert_{-\infty}^{\infty}\\
&amp;= 0 \\
\end{align}\]

\[\begin{align}
\int_{-\infty}^{\infty} x^2 e^{-x^2} dx &amp;= -\frac{1}{2} \int_{-\infty}^{\infty} x d (e^{-x^2}) \\
&amp;= -\frac{1}{2} \Big( x e^{-x^2} \big\rvert_{-\infty}^{\infty} - \int_{-\infty}^{\infty} e^{-x^2} dx \Big) \\
&amp;= -\frac{1}{2} \Big( 0 - \sqrt{\pi} \Big) \\
&amp;= \frac{\sqrt{\pi}}{2} \\
\end{align}\]

</p><p>Notice that here we used integral by parts.</p>

<h3 id="entropy-maximization">Entropy Maximization</h3>

<h4 id="discrete-probability-distribution">Discrete Probability Distribution</h4>

<p>Suppose $P$ is a discrete probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) \\
\end{align}\]

</p><p>We further have some constrains on $P$:</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\sum_{x \in X}^{} P(x) = 1$</li>
  <li>$\sum_{x \in X}^{} P(x) r_i(x) = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>The first two constrains are trivial given $P$ is a probability distribution. The third constrain is optional and it indicates a constrain on the entire system. Notice that there could be more than one constrain if $m &gt; 1$.</p>



<p>We would like to maximize the entropy.</p><p>

\[\max_{P} H(P) = \max_{P} \Big( - \sum_{x \in X}^{} P(x) \log P(x) \Big)\]

</p><p>Letâ€™s try to solve this optimization problem. We would use Lagrange multiplier for the constrains.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \sum_{x \in X}^{} P(x) \log P(x) + \lambda_0 \Big(\sum_{x \in X}^{} P(x) - 1 \Big) + \sum_{i=1}^{m} \lambda_i \sum_{x \in X}^{} \Big(P(x) r_i(x) - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\sum_{x \in X}^{} P(x) = 1$,</p><p>

\[\begin{align}
\sum_{x \in X}^{} P(x) &amp;= \sum_{x \in X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= e^{\lambda_0 - 1} \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)}\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
\end{align}\]

</p><h4 id="continuous-probability-distribution">Continuous Probability Distribution</h4>

<p>Similarly, suppose $P$ is a continuous probability distribution. The entropy is defined as</p><p>

\[\begin{align}
H(P) &amp;= - \int_{X}^{} P(x) \log P(x) dx \\
\end{align}\]

</p><p>With the following constrains</p>

<ul>
  <li>$P(x) \geq 0$</li>
  <li>$\int_{X}^{} P(x) dx = 1$</li>
  <li>$\int_{X}^{} P(x) r_i(x) dx = \alpha_i$ for $1 \leq i \leq m$</li>
</ul>

<p>Similarly, to maximize the entropy, we maximize the Lagrangian for the continuous case.</p><p>

\[\begin{align}
L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \int_{X}^{} P(x) \log P(x) dx + \lambda_0 \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
\end{align}\]

</p><p>We take the derivative of $L(P, \lambda_0, \lambda_1, \cdots, \lambda_m)$ with respect to $P(x)$ and the derivative should be $0$. We will also use the <a href="https://en.wikipedia.org/wiki/Calculus_of_variations">calculus of variations</a> to compute the derivative, which is slightly more complicated. Without going into all the details, we have the following derivatives.</p><p>

\[\begin{align}
\frac{\partial}{\partial P(x)} L(P, \lambda_0, \lambda_1, \cdots, \lambda_m) &amp;= - \frac{\partial}{\partial P(x)} \int_{X}^{} P(x) \log P(x)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \int_{X}^{} \frac{\partial}{\partial P(x)} \big( P(x) \log P(x) \big)  dx + \lambda_0 \frac{\partial}{\partial P(x)} \Big(\int_{X}^{} P(x)  dx - 1 \Big) + \sum_{i=1}^{m} \lambda_i \frac{\partial}{\partial P(x)} \Big( \int_{X}^{} P(x) r_i(x)  dx - \alpha_i \Big) \\
&amp;= - \log P(x) - 1 + \lambda_0 + \sum_{i=1}^{m} \lambda_i r_i(x) \\
&amp;= 0 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[\begin{align}
P(x) &amp;= e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } \\
&amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{e^{1 - \lambda_0}} \\
\end{align}\]

</p><p>Because $\int_{X}^{} P(x) dx = 1$,</p><p>

\[\begin{align}
\int_{X}^{} P(x) dx &amp;= \int_{X}^{} e^{\big(\sum_{i=1}^{m} \lambda_i r_i(x)\big) + \lambda_0 - 1 } dx \\
&amp;= e^{\lambda_0 - 1} \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx \\
&amp;= 1 \\
\end{align}\]

</p><p>Therefore,</p><p>

\[e^{1 - \lambda_0} = \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx\]

</p><p>With this, we could rewrite $P(x)$ as</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
\end{align}\]

</p><h3 id="maximum-entropy-distribution-examples">Maximum Entropy Distribution Examples</h3>

<h4 id="roll-dice">Roll Dice</h4>

<p>A conventional dice has 6 faces. $X = \{ 1, 2, 3, 4, 5, 6 \}$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So, the maximum entropy probability distribution of getting each face of the dice is</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \sum_{x \in X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} } \\
&amp;= \frac{ e^{0} }{ \sum_{x \in X}^{} e^{0} } \\
&amp;= \frac{ 1 }{ 6 } \\
\end{align}\]

</p><h4 id="uniform-distribution">Uniform Distribution</h4>

<p>The only constrain we put on a distribution is $X = [a, b]$. Because we donâ€™t have additional constrains, therefore</p><p>

\[\lambda_1 = \lambda_2 = \cdots = \lambda_m = 0\]

</p><p>So the maximum entropy probability distribution is actually uniform distribution.</p><p>

\[\begin{align}
P(x) &amp;= \frac{ e^{\sum_{i=1}^{m} \lambda_i r_i(x)} }{ \int_{X}^{} e^{\sum_{i=1}^{m} \lambda_i r_i(x)} dx } \\
&amp;= \frac{ e^{0} }{ \int_{a}^{b} e^{0} dx } \\
&amp;= \frac{ 1 }{ b - a } \\
\end{align}\]

</p><h4 id="gaussian-distribution">Gaussian Distribution</h4>

<p>We could also derive Gaussian Distribution using entropy maximization. The constrains for the maximum entropy distribution are</p>

<ul>
  <li>$X = (-\infty, \infty)$</li>
  <li>$\mathbb{E}[X] = \int_{-\infty}^{\infty} x P(x) dx = \mu$</li>
  <li>$\mathbb{V}[X] = \mathbb{E}[X^2] - \mathbb{E}[X]^2 = \mathbb{E}[X^2] - \mu^2 = \int_{-\infty}^{\infty} x^2 P(x) dx - \mu^2 = \sigma^2$</li>
</ul>

<p>which translates to</p>

<ul>
  <li>$m = 2$</li>
  <li>$r_1(x) = x$, $\alpha_1 = \mu$</li>
  <li>$r_2(x) = x^2$, $\alpha_2 = \sigma^2$</li>
</ul><p>

\[\begin{align}
P(x) &amp;= e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} \\
\end{align}\]

</p><p>Because</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= 1 \\
\end{align}\]

</p><p>We have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} e^{\lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2} dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \big( \lambda_0 - 1 + \lambda_1 x + \lambda_2 x^2 \big) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \Big[ \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2^2} \Big] \bigg) dx  \\
&amp;= \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2} \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( \lambda_2 \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
\end{align}\]

</p><p>Here we assume $\lambda_2 &lt; 0$, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( -(-\lambda_2) \big(x + \frac{\lambda_1}{2\lambda_2}\big)^2 \bigg) dx  \\
&amp;= \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) dx  \\
&amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)^2 \bigg) d \Big( \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big) \Big)  \\
\end{align}\]

</p><p>To make it more clear, we set</p><p>

\[y = \sqrt{ -\lambda_2 }\big(x + \frac{\lambda_1}{2\lambda_2}\big)\]

</p><p>So using Gaussian integral, we further have</p><p>

\[\begin{align}
\int_{-\infty}^{\infty} P(x) dx &amp;= \frac{1}{\sqrt{ -\lambda_2 }} \exp \bigg( - \frac{\lambda_1^2 - 4 \lambda_0 \lambda_2 + 4 \lambda_2}{4\lambda_2}  \bigg) \int_{-\infty}^{\infty} \exp \bigg( - …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Maximum-Entropy/">https://leimao.github.io/blog/Maximum-Entropy/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Maximum-Entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25641459</guid>
            <pubDate>Tue, 05 Jan 2021 02:51:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Telegram publishes users' locations online]]>
            </title>
            <description>
<![CDATA[
Score 485 | Comments 223 (<a href="https://news.ycombinator.com/item?id=25641399">thread link</a>) | @Nullslash
<br/>
January 4, 2021 | https://blog.ahmed.nyc/2021/01/if-you-use-this-feature-on-telegram.html | <a href="https://web.archive.org/web/*/https://blog.ahmed.nyc/2021/01/if-you-use-this-feature-on-telegram.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-2299938338217590975" itemprop="description articleBody">
<p><span data-preserver-spaces="true">A few years ago, while using the Line app, I noticed a feature called "People nearby." The feature lets you connect with other Line users within the same area. The feature would give you the exact distance from you to the other users. If someone spoofs their latitude, longitude, they can triangulate a user and find their location. I reported an issue in the&nbsp;</span><a href="https://line.me/en/" target="_blank"><span data-preserver-spaces="true">Line app</span></a><span data-preserver-spaces="true">, and They paid me $1000 for it. They fixed it by adding a random number to the user's destination. You can find my name&nbsp;</span><a href="https://bugbounty.linecorp.com/en/halloffame/2017/" target="_blank"><span data-preserver-spaces="true">here</span></a><span data-preserver-spaces="true">.&nbsp;</span></p><p>A few days ago, I installed Telegram, and I noticed that they have the same feature. I tried to see if I can unmask other users' locations, and I found they have the same issue I discovered in the Line app a few years ago. I reported the problem to Telegram security, and they said it's not an issue.&nbsp;<strong>If you enable the feature of making yourself visible on the map, you're publishing your home address online. </strong><span>Lot of users don't know this when they enable that feature. This is what they said when I emailed them:</span>&nbsp;</p><blockquote><p>From:<span>	</span>security@telegram.org</p><p>To: me</p><p>Hello,</p><p>Thanks for reaching us out. Users in the People Nearby section</p><p>intentionally share their location, and this feature is disabled by</p><p>default. It's expected that determining the exact location is possible</p><p>under certain conditions.</p><p>Unfortunately, this case is not covered by our bug bounty program.</p></blockquote><p><span data-preserver-spaces="true">Disclosure timeline:&nbsp;</span></p><ul><li><span data-preserver-spaces="true">Contacted Telegram on December 22nd with full details of how to exploit the information.</span></li></ul><ul><li><span data-preserver-spaces="true">They responded on December 23rd; they asked me to create a video of the PoC 🙄</span></li></ul><ul><li><span data-preserver-spaces="true">I made a video on the same day and sent it to them.</span></li></ul><ul><li><span data-preserver-spaces="true">They responded after 14 days, saying their bug bounty program does not cover the issue.</span></li></ul><p><span>So, here is how it works in detail:<br></span><span>Open Telegram, and go to people near me, there is an option to see how far people are from your location.</span></p><p><span id="docs-internal-guid-53f1000f-7fff-b4b2-905d-ee47865be904"><span><span><img height="351" src="https://lh3.googleusercontent.com/JbKyjueKloPEbmeyE9ZbcVkATBhRNlY4hjl8NZZOhHn4lgt56UnjR3HjAVP2Z5MNSAAe0jzL3rKNjfLI3QCueXXe6inocEKB5RwX9b6A3kIydvA74fjzmfZlEjkH0bNrfQUYR80I" width="268"></span></span></span></p><div><p>After you click on it, it will show a list of people near you like the following:</p></div><p><span id="docs-internal-guid-684e7a7b-7fff-37c6-a5fc-5d6693280cf8"><span><span><img height="478" src="https://lh4.googleusercontent.com/umUhHMfl3qKMXVgyIdX3pXnKuronNR29XQgzc_WoX0imTtVPTvEWBLhK5x-WZvu3vz-KEInZy5lZGIOLdSO0DUP33G3Iv-758309YimhtEMxU1xM63QKoGeTJq473VIGLT0N78Yh" width="276"></span></span></span></p><p>If you notice, Telegram is telling me how far each person is far from me. An adversary can spoof their location for three points and use them to draw three triangulation circles. To spoof a GPS location, the adversary can do one of the following options:</p><div><div><p>1-Use hardware GPS spoofer (Very hard to get, and the FCC will fine you hard if you use such a device)<br>2-Use root to spoof to GPS (Medium)<br>3-Just walk around the area, collect the GPS latitude and longitude of yourself, and how far the target person is from you (Super easy)</p></div><p><span data-preserver-spaces="true">For the sake of the demonstration, I will go with option number two. There is an app in the play store called&nbsp;</span><a href="https://play.google.com/store/apps/details?id=com.lexa.fakegps" target="_blank"><span data-preserver-spaces="true">GPS spoof</span></a><span data-preserver-spaces="true">; download it and install it. For some reason, the app doesn't work with Android 11; I used Android 7 instead. After it, collect 3 locations of a user for unmasking.</span></p><p><span data-preserver-spaces="true"><p>4-Spoof the location near the user within a 7 miles radius limit. That's the limit Telegram has in place. The targeted user lives in Bay Ridge, so I spoofed the address to the Bay Ridge area. Then collect how far that person is from that point. Repeat three times like the following:</p><p><span id="docs-internal-guid-39370a7c-7fff-d4b2-7c98-923492b72907"><p dir="ltr"><span><span><img height="281" src="https://lh6.googleusercontent.com/jpBnx1GgSBqLo7XCheaHJMsFff8977ZW3T-T853_rrvi-Ela1dS1BLXNExYOaO-I3ROdEByW6v1woZG7MfxC2O2a5z6ArOPApDVI8YUFo1MYntYsVhdgFZ_XBd2L71ULH2BCT5PL" width="159"></span></span><span><span><img height="281" src="https://lh6.googleusercontent.com/YZPfdHypa3L3B9ZDucwylK3bwBmRnhswS2oHdKuJjMu8DjvKZNxNEmRzehFtk0WdM_QOz3WkLhljISpwhCjF5SMLbUXi0srUGrGTL7BmiWp-A3MBt3DNfLlbtpGtHVSg1DsKaPRB" width="163"></span></span><span><span><img height="284" src="https://lh4.googleusercontent.com/2pazuJRtclJd6-PKGIY5YJp7TH_B-JDQWE5OSz0zfhQyANYIQocBoqqNStCp-i7zscV2ckkX2IRfFQ_7-VjXa13GHkWIwioMj9unPiLe8LBxmVOI1rHe_vM4WRtUWVuzOFvXG-0T" width="162"></span></span></p><p dir="ltr"><span><span><img height="283" src="https://lh4.googleusercontent.com/s6VyofBRsNeMj1Wa9eL3KCEQq01d9R9F6iGoxWiIcDmH_UbjU4yA0cxyy10uzCkZJjUGiUzjWHIya1OkHhDFoCezB1H5BmozDmY62ueuAMFxCbdVGkrFJPCLK4aDx-k0CEAEUNiG" width="159"></span></span><span><span><img height="285" src="https://lh3.googleusercontent.com/JyNBgZBtw3UzT37VSfK6Ma-gO8pk4lKqzV5e3md9O4GYVayN8CwQ0Om_RRAr7btAiCL6mmixCjHws4Ba7jiIJpYvTurhqp2r9cUufZCiQwTm3cMDX_unnbFEehZO-Jhnhf6oAONM" width="162"></span></span><span><span><img height="285" src="https://lh6.googleusercontent.com/ECWiWe3T86oAkn25lmYcHmkdf74i_PPiwGJpddtv9k6IoW9lstqwbZu6yvPjbyUWjwV3DWG0XngaPrwAYYZL7Yjp5A9wCMZ3AMvjREuDy7XCPXBCJJIPBx6oZsw2J3NXlhPqGiXS" width="161"></span></span></p><p dir="ltr"><span><span><img height="288" src="https://lh3.googleusercontent.com/bbnj35dH1xShYmEAcVqxKaUm4VWLKQVqoitSekn6qWGsEnqcyaBLvG4ieI1Kc-guB-Gov0fQ3ziSlpTS-BKSgA7B9cCh153b7qNV8TBduNYWUlhX027R3w7IiitLbm3l5k3GHJQo=w163-h288" width="163"></span></span><span><span><img height="278" src="https://lh6.googleusercontent.com/qyXn90Ir58knd4dwSjf9j1qi_lx2jvY0RgYoOMgrVeSnTbD5QrTBKAf7ZiGb3wwjUYLiqDcZJRonYPr9GV3ekTTIh9r8Vve3mhy7TqSMMQyl9dJBq0sU5hllZ6U4Ay0i1mgg2u-r=w157-h278" width="157"></span></span><span><span><img height="280" src="https://lh6.googleusercontent.com/fbADLbmhYgNppqnXeWjEnR0U8sNP4IgLNhmKsDmGuNAUICttr0Hg1WUAdkxRWsK3p9AcUkSnlHfMtAUpr0E4LrqQd3UKcpHehl6cXbdbmMAcsUwsH-WRXGeX_U81AZ2JBlLje5vS=w158-h280" width="158"></span></span></p><div><p>5-Open Google Earth Pro, search for latitude, the longitude of the spoofed locations, and use the ruler to draw a circle with the target user destination from each location. Here is the result:</p></div><p dir="ltr"><span id="docs-internal-guid-95b4c21c-7fff-a99e-599a-63c2737e7191"><span><span><img height="377" src="https://lh4.googleusercontent.com/nLdF4cxdiW-GN4fXpfwiSy87aGQuqk4MPLu_aSjvOl2I7mj_ElfnI4CN_6iJCsJhrJhQs8u6E2imNeQrpPql9PzRQG760TpJqKt4uJwnXwkwUIjSPKAFgQH8o5sLW62b-Yf42znN" width="594"></span></span></span></p><p><span>The intersection of the three circles is the location of the user. To verify this, I added one of the users and asked them if they live near the point.</span></p><p dir="ltr"><span><span id="docs-internal-guid-267fb593-7fff-119e-00ae-01c6045c0efb"><span><span><img height="569" src="https://lh3.googleusercontent.com/l53s1fb3kWCRiZk5MbG0Y9MOEJqzDuSpew4lATjxGd8o4jDEMPZvpdtphQCEwUWQTsyGcZ6tNt1C3RkMAqTR6yXZ7ddGzp7zbprAyFkPwnP1WenVcpWRP8sX9tU5Zyz98kr9KIGD" width="276"></span></span></span></span></p><p dir="ltr">I was able to get that user's exact home address.</p><p><span data-preserver-spaces="true">Telegram told me it's not an issue. If you use this feature, please make sure to disable it. Unless you want your location to be accessible by everyone.&nbsp;</span></p><p><span data-preserver-spaces="true">Unfortunately, Telegram poor application security can be reflected with the number of scammers they have within that feature. Telegram allows users to create local groups within a geographical area. Many scammers spoof their location and try to sell fake bitcoin investments, hacking tools, SSNs that are used for unemployment fraud, and so on. The amount of illegal activities I saw there make the&nbsp;</span><a href="https://en.wikipedia.org/wiki/Silk_Road_(marketplace)" target="_blank"><span data-preserver-spaces="true">Silkroad&nbsp;</span></a><span data-preserver-spaces="true">look like amateurs ran it.&nbsp;<br></span></p></span></p></span></p></div>

</div></div>]]>
            </description>
            <link>https://blog.ahmed.nyc/2021/01/if-you-use-this-feature-on-telegram.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25641399</guid>
            <pubDate>Tue, 05 Jan 2021 02:41:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hthsm: A hierarchical finite state machine framework for keeping C apps tidy]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25641307">thread link</a>) | @raykamp
<br/>
January 4, 2021 | https://www.thehumbletransistor.com/blog-feed/spaghetti-and-the-hsm | <a href="https://web.archive.org/web/*/https://www.thehumbletransistor.com/blog-feed/spaghetti-and-the-hsm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="canvas">

      
  
  



    

    

    

    <section id="page" role="main" data-content-field="main-content">
      <!-- CATEGORY NAV -->
      
      <div>



<article id="article-5e1e2a87dc0b4d66eae5c910" data-item-id="5e1e2a87dc0b4d66eae5c910">

  <!--SPECIAL CONTENT-->

  


  <!--POST HEADER-->

  <header>
		
    <p><span><time datetime="2020-01-22">January 22, 2020</time></span>
    </p>
  </header>

  <!--POST BODY-->


  <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1579035326116" id="item-5e1e2a87dc0b4d66eae5c910"><div><div><div data-block-type="2" id="block-860892b2641ca978144b"><p><strong>If you’ve worked on a Bluetooth LE firmware application, you might be familiar with the “well this got complicated fast” epiphany. </strong> In this post, I’m recommending something of a <strong>silver bullet: A</strong> <strong>tried-and-true method to keep BLE firmware structured, serviceable, and maintainable</strong>. If you’re dealing with an unruly firmware project, treat yourself to some relief and check out what this can do for your project.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1579902767344_16174"><div><h2><strong>The Foe</strong></h2><p><strong>Bluetooth Low Energy firmware</strong> applications have their <strong>inherent complexities</strong>. They’re structured as <strong>event-driven systems. </strong>That basically mean they react to “events” that can occur at any time.  That’s physical event sources like button presses, battery alerts, and sensors inputs, but also to incoming Bluetooth communications from an App. In our experience, even top-tier chip vendors like Nordic Semiconductors provide subpar guidance on how to best orchestrate this system of events and reactions. An unsuspecting developer may feel they’re using a lean approach, linking event sources in code to their corresponding reactions in a piecemeal fashion. The complexity of this patch network soon grows exponentially and starts feeling like a firmware savant is required just to make sense of it all.   As the project grows, the <strong>event-reaction mappings grow in quantity </strong>and<strong> </strong>likely require being dynamically re-mapped in different modes of operation. If left untreated, the affliction can get the best of you, spreading faster than you add features. If you’re anything like us, there’s an inevitable face-the-music moment where this event-driven <strong>spaghetti code </strong>can no longer be tolerated. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1579741448937_7867"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e191c4fca124e6013953696/1579742390701-YYBH18QMSF84Y1BWUU50/ke17ZwdGBToddI8pDm48kFHnJVcEmoz8agNXTGj5VGRZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEZGQ3XMIedd2ezgsx2J8MAPwBjlgiuPbJzq7D4yAXgHFtO8nJtk629tZGIWiyY3XQ/spaghetti.gif" data-image="https://images.squarespace-cdn.com/content/v1/5e191c4fca124e6013953696/1579742390701-YYBH18QMSF84Y1BWUU50/ke17ZwdGBToddI8pDm48kFHnJVcEmoz8agNXTGj5VGRZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVEZGQ3XMIedd2ezgsx2J8MAPwBjlgiuPbJzq7D4yAXgHFtO8nJtk629tZGIWiyY3XQ/spaghetti.gif" data-image-dimensions="400x225" data-image-focal-point="0.5,0.5" alt="spaghetti.gif" data-load="false" data-image-id="5e28f4b078c38064efb1cabc" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1579741448937_9543"><div><p>This isn’t the glutinous spaghetti that you bite with your teeth. It’s the kind that<em> </em>compiles into bytes and bites to deal with. If you’re not aware of spaghetti code and its nauseating effects, then let’s briefly recap.  “Spaghetti code” is a slang term for code with convoluted structure, so much that it’s difficult to debug and and maintain it.</p><p><strong>What problems are caused by event-driven spaghetti code?</strong></p><ol data-rte-list="default"><li><p><strong>Bugs: the worst kind of bugs.</strong> It’s the ugly should-have-been-avoidable bugs that crop up and continue to crop up when you lose a handle on the structure of your application.</p></li><li><p><strong>Code duplication.</strong> The completely unnecessary there-must-be-a-better-way kind of duplication. When the system for handling events is poorly structured, developers struggle to repurpose code across similar events and states of operation. For example, a “battery charging” and “charge complete” state should be able to elegantly share a lot of charging-related functionality. </p></li><li><p> <strong>Loneliness</strong>, also known as staffing problems due to your unmaintainable codebase.<strong> </strong> No one likes to work alone, so restructure your application in a way that your coworkers and future coworkers cherish. </p></li></ol></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1579801278944_6416"><div><h2><strong>Fret Not</strong></h2><p>I want to recommend a system that’s worked for me — two steps for developers like us to immunize against the spaghetti affliction right from the start. </p><p><strong>Overview of the Steps to Avoid Spaghetti Code:</strong></p><ol data-rte-list="default"><li><p>Use an atomic <strong>event queue</strong>. Rather than reacting to events all over your different interrupt execution contexts, an event queue allows you to consolidate those portions of your code into one place. It’s your conduit for “deferring” the handling of events from many contexts (like interrupts) into one main context. It additionally solves the issue of thread/interrupt safety, by avoiding concurrent access of shared resources across different contexts..  For example, you don’t want a SPI peripheral used in two contexts that can interrupt one another. Instead, both contexts can queue events for the main function to perform the SPI operations sequentially. </p></li><li><p>Use a <strong>hierarchical state machine (HSM)</strong>, and a framework to implement one. An HSM is the  knockout punch for our spaghetti foe. It provides an intuitive and <a href="https://en.wikipedia.org/wiki/Deterministic_finite_automaton">deterministic</a> scheme to define how events should be handled throughout various modes of operation. HSMs are “hierarchical” in the sense that each state can be configured to inherit behaviors from a “superstate”, a more general state that encapsulates it and potentially other states. The hierarchical aspect of HSMs make them far more practical for real-world firmware applications than a textbook flat state machine. A “battery charging” and “charging complete” state could both inherit and share a bulk of their code from an “charger attached” state. </p></li></ol></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1579801278944_14942"><div><h2><strong>Immunization Step 1 of 2: <br>Take a queue from your vendor</strong></h2><p><strong>An event queue is the essence of event-driven architecture</strong>. If you’re already using one and understand their merit, you may want to jump ahead to the next part.</p><p>Firmware events generally arrive in the context of an interrupt, either hardware or software driven. In the case of some dead-simple events, you might get away handling them right there in the interrupt; But, generally that’s bad practice. There’s a common <strong>embedded development commandment</strong>:</p><p><strong><em> “Thou shalt not dilly dally within an interrupt service routine”</em></strong></p><p>And lest we forget its companion rule:</p><p><strong><em>“Respect thine interrupt/thread safety”</em></strong></p><p>Immunization step #1 is using the atomic queue to <span>defer event processing to one location in your main context</span>. That keeps us complaint with the embedded commandments, and sets the groundwork for the step #2.</p></div></div><div data-aspect-ratio="54.93333333333334" data-block-type="5" id="block-yui_3_17_2_1_1579946663094_24662"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e191c4fca124e6013953696/1580328156869-49F7JTF2BWSZ6Z7JCLYT/ke17ZwdGBToddI8pDm48kHixWE7WBapMBa7NHDyEzBgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcUpg26EGkUvVo2UL1i7KXk5MNf1V_Wr3Sl6GBRjMIRCjqGMUAV3BVAv4KdlqM0YlR/Drake%27s+Deferred+Execution.png" data-image="https://images.squarespace-cdn.com/content/v1/5e191c4fca124e6013953696/1580328156869-49F7JTF2BWSZ6Z7JCLYT/ke17ZwdGBToddI8pDm48kHixWE7WBapMBa7NHDyEzBgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcUpg26EGkUvVo2UL1i7KXk5MNf1V_Wr3Sl6GBRjMIRCjqGMUAV3BVAv4KdlqM0YlR/Drake%27s+Deferred+Execution.png" data-image-dimensions="1257x690" data-image-focal-point="0.5,0.5" alt="Drake's Deferred Execution.png" data-load="false" data-image-id="5e31e4dca9b7c85037ad088f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5e191c4fca124e6013953696/1580328156869-49F7JTF2BWSZ6Z7JCLYT/ke17ZwdGBToddI8pDm48kHixWE7WBapMBa7NHDyEzBgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcUpg26EGkUvVo2UL1i7KXk5MNf1V_Wr3Sl6GBRjMIRCjqGMUAV3BVAv4KdlqM0YlR/Drake%27s+Deferred+Execution.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1579946663094_24944"><div><p>An event-queue paradigm has been around for a while. Many developers would be hard-pressed to develop complex applications without it. You use the queue to take all your events and  funnel them into a single context where they’re processed one at a time. Right off the bat, that gains you cozy-warm assurances of thread/interrupt safety because event handling isn’t strewn across all sorts of overlapping execution contexts.</p><p>Courteous silicon vendors usually provide developers with some form of an atomic queue. <strong>Nordic </strong>provides <strong>nRF52</strong> developers with <a href="https://infocenter.nordicsemi.com/topic/sdk_nrf5_v16.0.0/lib_scheduler.html?cp=7_1_3_39">their “app scheduler”</a><em>. </em><strong>Texas Instruments</strong><em> </em>provides <strong>CC2640</strong> developers with <a href="http://dev.ti.com/tirex/content/simplelink_cc2640r2_sdk_2_40_00_32/docs/blestack/ble_user_guide/html/ble-stack-tirtos/queues.html">their queue module</a> accompanying their TI-RTOS. For our intents and purposes, both of these modules are just different packagings of a functionally-equivalent queue. </p><p>Here’s a snippet of generic example code to drive the concept home:</p></div></div><div data-block-type="44" id="block-yui_3_17_2_1_1579734449814_4508"><div><pre><code>// eventHandler is always executed in the "main" context
void eventHandler(Event event){
    switch(event){
        case TIMER_FIRED:
            perform_periodic_task();
            start_timer();
            break;
        case BUTTON_PRESS:
            react_to_button_press();
            break;
        case BUTTON_RELEASE:
            react_to_button_release();
            break;
        default:
            break;
    }
}

// Interupt handlers
void timerFired_interrupt(void){
    // Add event to the event queue
    // deferring its handling to the main context
    queue_push(TIMER_FIRED);
}

void buttonPress_interrupt(void){
    queue_push(BUTTON_PRESS);
}

void buttonRelease_interrupt(void){
    queue_push(BUTTON_RELEASE);
}

int main(void){
    // Initialize and configure button interrupt
    initialize_buttons();
    initialize_timer();
    start_timer();

    // Main loop    
    for (;;)
    {
        // idle() stays in a low-power state until there's an event
        idle(); 
        while( !queue_empty() ){
            Event event = queue_dequeue();
            eventHandler(event);
        }
    }
}</code></pre>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1579946663094_7468"><div><h2><strong>Immunization Step 2 of 2: <br>Stately Behavior</strong></h2><p>At this point, all of your event processing has been deferred and consolidated into a main context, like the above example’s “eventHandler()” function.  However, the events still need to be handled in a systematic manner. Unlike the example in Step #1, most firmware projects will include many more events whose handling changes over time. This step recommends using a hierarchical state machine to cleanly implement event handling that adapts throughout different modes/states of operation. </p><p>If you’re developing a product, like say a low-power wearable, then your device surely has states. Most states are clear-cut and easy to define. I’m talking On, Off, low-power shipping mode, connected, disconnected, etc. At its basis, a state machine is used to encapsulate  event-handling behavior for each of these different states of operation.</p><p>Furthermore, you may find commonality or “hierarchy” among those states — that’s states that include other states.  HSMs are “hierarchical” in the sense that states inherit behavior from the states that contain them (superstates). This hierarchy allows your code to stay clear and concise, sharing event-handling subroutines between similar states. </p><p><strong>Example of states &amp; hierarchy for a Bluetooth LE device</strong></p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1579991861465_10353"><p><img src="https://static1.squarespace.com/static/5e191c4fca124e6013953696/t/5e2cc20d86eb9b2324c9bda4/1579991565772/stateExample.png" alt="Hierarchical State Example"></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1579952812491_90864"><div><p>Between the state machine’s consolidation/encapsulation of state behaviors and the hierarchical aspect’s management of complex shared state behaviors, we now have our knockout punch against spaghetti code.</p><p>If you find this section to be daunting, then skip ahead to the good stuff at the bottom: A link to our open-source HSM implementation called HTHSM. HTHSM’s Github documentation provides a <a href="https://github.com/TheHumbleTransistor/HTHSM">practical example for implementing an HSM</a>. </p><p>If you want to learn more, I recommend looking into Miro Samek. He’s a guru of all event-driven firmware things and articulately presents his case for state machines in his “<a href="https://barrgroup.com/embedded-systems/how-to/state-machines-event-driven-systems">State Machines for Event-Driven Systems</a>”. Like us, he champions the HSM, boasting its practicality in “<a href="https://barrgroup.com/embedded-systems/how-to/introduction-hierarchical-state-machines">Introduction to Hierarchical State Machines</a>”. </p><p>All implementations of state machines are not at all equal, however. If you’re ready to implement a worthwhile state machine, below are my battle-tested recommendations. </p><p><strong> If you’re implementing your own HSM, here’s what I …</strong></p></div></div></div></div></div></div></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thehumbletransistor.com/blog-feed/spaghetti-and-the-hsm">https://www.thehumbletransistor.com/blog-feed/spaghetti-and-the-hsm</a></em></p>]]>
            </description>
            <link>https://www.thehumbletransistor.com/blog-feed/spaghetti-and-the-hsm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25641307</guid>
            <pubDate>Tue, 05 Jan 2021 02:28:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Load testing is hard and the tools are not great]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25641234">thread link</a>) | @ntietz
<br/>
January 4, 2021 | https://ntietz.com/tech-blog/load-testing-is-hard-but-why/ | <a href="https://web.archive.org/web/*/https://ntietz.com/tech-blog/load-testing-is-hard-but-why/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    

    <p><strong>Monday, January  4, 2021</strong></p>

    <p>If you're building an application that needs to scale—and we all tell ourselves that we are—then at some point you have to figure out if it <em>does</em> or not. This is where load testing comes in: if you want to see whether or not your application can handle scale, just <em>generate</em> scale and see if it can handle it! It sounds straightforward enough.</p>
<p>Then you try to actually generate load. This is straightforward if your application is dead simple, because you can use something like <a href="https://en.wikipedia.org/wiki/Apache_JMeter">Apache JMeter</a> to generate repeated requests. If you can do this, I envy you: every system I've worked on is more complicated and requires a more intricate testing plan.</p>
<p>Your application gets slightly more complicated, so you then turn to tools like <a href="https://en.wikipedia.org/wiki/Gatling_(software)">Gatling</a>. These let you simulate virtual users going through scenarios, which is a lot more helpful than just <a href="https://en.wikipedia.org/wiki/Siege_(software)">besieging</a>&nbsp;one or a handful of URLs. Even this isn't sufficient if you're writing an application that uses both WebSockets <em>and</em> HTTP calls, over a long-lived session, and requires certain actions repeated on a timer. Unless I severely missed something in the documentation, I cannot see a way to, say, setup a heartbeat that runs ever 30 seconds, do certain actions upon response to a WebSocket message, and also do some other HTTP actions, all with the same HTTP session. I haven't found a way to do that in <em>any</em> load testing tool (which is why I wrote my own at work, which I hope to open source if I can make the time to clean it up and separate out proprietary bits).</p>
<p>But let's suppose you <em>do</em> have a tool that works, out of the box, like Gatling or Locust, and it fits your needs. Great! Now let's write that test. In my experience, this is the hardest bit yet, because you have to first figure out what realistic load looks like — welcome to a day or three of dredging through logs and taking notes while you peer at the network tools in your browser as you click around in your web application. And then after you know what realistic load looks like, you get to write what boils down to a subset of your application to pretend to be a user, hit the API, and do the things your user would do.</p>
<p>And we're not done yet! This is fine, we have our load test written and it's realistic. But this is a moving target, because updates keep going out. So now you have the maintenance problem, too: as your application changes, how do you keep your load test up to date? There isn't great tooling to do this, there is little out there to help you. You have to make this part of your process and hope you don't miss things. This is not a satisfying answer, and that's why this is also one of the hardest parts of load testing an application.</p>
<p>We'll just skip the whole "running it" part, because honestly, if you've gotten this far through a load test, then running it shouldn't be the hardest part.</p>

<p>So basically, here's where we are:</p>
<ul>
<li>Most load testing tools support simplistic workloads, and even the complex ones don't let you do everything that's realistically needed to simulate <em>real</em> usage of a web application.</li>
<li>Writing the test with a simulation of real usage is the hardest part, even if the tools do support what you need.</li>
<li>Maintaining the test is the second hardest part, and the tooling here does not help you in the slightest.</li>
</ul>
<p>Let's look at these in detail and see how much complexity we can pare away.</p>
<h2 id="simulating-users-do-we-have-to">Simulating users. Do we have to?</h2>
<p>I'm a "yes" here, although it might depend on your application. And for these purposes, we're talking about the user <em>of a service</em>; if you have a monolith, this is your users as a whole, but if you have microservices the "user" might be another one of your services! For the applications I've worked on, I have had minor success with targeted tests of specific endpoints. But these end up requiring such complicated setup that you aren't better off than you were with the load test itself! And while it may yield some results and improvements, it doesn't get to everything (you may have endpoints that interact) and you don't get a realistic workload.</p>
<p>"When do you <em>not</em> need to simulate users?" is probably a better question. Seems to me like this is when you <em>know</em> that your endpoints are all independent in performance, you don't have any stateful requests, and the ordering of requests does not impact performance. These are big things to assume and it's hard to have confidence in them without testing their independence, at which point, we're back to writing that whole dang test.</p>
<p>The best you can do here is probably at the API and system design time, not at your test time. If you design a simpler API, you're going to have far less surface area to test. If you design a system with more certainly independent pieces (distinct databases per service, for example) then it's easier to test them in isolation than in a monolith. Doing this also lets you use a tool that is simpler, so you get two wins!</p>
<h2 id="writing-the-tests-is-hard-so-is-maintenance">Writing the tests is <em>hard.</em> So is maintenance.</h2>
<p>Creating a load test is hard because you have to do a few things: you have to understand what the flow through <em>usage</em> of your API is, and you have to write a simulation of that usage. Understanding that flow means understanding other systems than the one under test and since your system is presumably not the focus of their documentation, there is not going to be a super clear diagram of when and how it's called; this often looks like sifting logs until you figure out what the representative usage is. And then writing that simulation is certainly not trivial, because you need to manage the state for a large number of actors representing users of your API!</p>
<p>Oh, and you get to write integration tests for this now, too.</p>
<p>There's some research out there on how to make some of these tasks easier. You can figure out what you need for the initial test, and detect regressions (missing new workloads) from automated analysis of the logs, for example. But as far as I can tell, there is no software on GitHub, let alone a product I can buy, that's going to do that for me. So it doesn't seem like it has much of any traction in industry. It would be a big project to implement it on your own, which might be why it has languished (or is done at big companies, and is not spoken of).</p>

<p>There's a lot of complexity in load tests, and there is not a lot of tooling to help you with it. So maybe the answer is: write fewer of these types of tests, and don't expect them to give you all the answers to how your system performs.</p>
<p>You have a few options for getting a great picture of how your system performs:</p>
<ul>
<li><strong>Good old analysis.</strong> Sit down with a notebook, a pen, an understanding of your systems as a whole, and an afternoon to spare, and you can figure out with some napkin math what the general parameters and bounds of scaling on your system are. When you find the bottleneck, or you have some unknowns (how many transactions per second <em>can</em> our database support? how many do we generate?) then you can go test those specifically!</li>
<li><strong>Feature rollouts.</strong> If you can roll out features slowly across your users, then you don't necessarily have to do any load testing at all! You can measure performance experimentally and see if it's good enough. Good? Roll forward. Bad? Roll back.</li>
<li><strong>Traffic replay.</strong> This doesn't help at all with new features (see feature rollouts ten words ago for that) but it does help with understanding your system breaking points for existing features without as much development. You can take the traffic you saw before and replay it (multiple times over, even, by combining multiple different periods' traffic) and see how the system performs! (Side note: I would <em>love</em> tooling to help with this, and with amplifying traffic when doing this, so if anyone has a recommendation... hit me up.)</li>
</ul>
<hr>
<p>If you have some silver bullet I've missed, or a fantastic research paper in this area you'd recommend reading, or a story of terrible times with scaling that you want to share with me, please email them to <a href="mailto:me@ntietz.com">me@ntietz.com</a>.</p>

  </article>
</div></div>]]>
            </description>
            <link>https://ntietz.com/tech-blog/load-testing-is-hard-but-why/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25641234</guid>
            <pubDate>Tue, 05 Jan 2021 02:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Analysis of Privacy on the App Store]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25640548">thread link</a>) | @wallflower
<br/>
January 4, 2021 | https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html | <a href="https://web.archive.org/web/*/https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><article>
  
  <div><p>In iOS 14.3, Apple added their new <a href="https://developer.apple.com/app-store/app-privacy-details/">app privacy details</a> to App Store listings. App privacy details, which are sometimes compared to the nutritional labels on foodstuff, are details about the data an app collects and the purposes and use of such data. What can we learn by analysing this data?</p>

<p>From the 14<sup>th</sup> of December 2020, all new apps and app updates have to provide information on the data the app collects. This is used to power the app privacy details labelling. On Twitter, videos scrolling through the privacy listing for Facebook circulated immediately after the 14.3 release.</p>

<p>This system is somewhat flawed, because app developers can, at least in theory, lie about the data they collect. Some apps that profess to collect no data, actually turn out to collect a bunch if you read their privacy policy. However, the punishment for being caught lying, removal from the App Store, is a strong deterrent and it’s safe to assume most developers will have been truthful in their accounts.</p>

<p>An interesting side-effect of this, is that Apple has now made available the same data that can be found in terse and hard to parse privacy policies as simple and structured data that can be parsed and analysed. In this post I will do just that i.e. collect and analyse the privacy details for thousands of the most popular apps on the App Store.</p>

<h2 id="collecting-the-data">Collecting the Data</h2>

<p>If you just want to read the juicy details feel free to skip to the <a href="#analysis">analysis</a>.</p>

<p>Apple makes the privacy labelling data available for each app on the App Store via an API used by the App Store apps. By reverse engineering the App Store apps I’ve figured out how to make the API divulge this data on a per app basis.</p>

<p>This only gets me the privacy data for a single app, but I want to analyse popular apps. A good source of popular apps are the charts the App Store provides on a per app category basis. An example of this is “Top Free” apps in “Education”. These listings contain up to 200 apps per category and price point(i.e. free or paid).</p>

<p>On the UK store, which is the store I’ve used for all this analysis, there are 24 categories. Each of which have top charts with up to 200 paid and 200 free apps. This means the theoretical total number of apps is 9600. However, because some apps occupy chart positions in multiple categories and because the charts also contain app bundles the actual number is lower.</p>

<p>The full list of categories is:</p>

<table>
  <thead>
    <tr>
      <th><strong>Category</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Book</td>
    </tr>
    <tr>
      <td>Business</td>
    </tr>
    <tr>
      <td>Developer Tools</td>
    </tr>
    <tr>
      <td>Education</td>
    </tr>
    <tr>
      <td>Entertainment</td>
    </tr>
    <tr>
      <td>Finance</td>
    </tr>
    <tr>
      <td>Food &amp; Drink</td>
    </tr>
    <tr>
      <td>Graphics &amp; Design</td>
    </tr>
    <tr>
      <td>Health &amp; Fitness</td>
    </tr>
    <tr>
      <td>Lifestyle</td>
    </tr>
    <tr>
      <td>Magazines &amp; Newspapers</td>
    </tr>
    <tr>
      <td>Medical</td>
    </tr>
    <tr>
      <td>Music</td>
    </tr>
    <tr>
      <td>Navigation</td>
    </tr>
    <tr>
      <td>News</td>
    </tr>
    <tr>
      <td>Photo &amp; Video</td>
    </tr>
    <tr>
      <td>Productivity</td>
    </tr>
    <tr>
      <td>Reference</td>
    </tr>
    <tr>
      <td>Shopping</td>
    </tr>
    <tr>
      <td>Social Networking</td>
    </tr>
    <tr>
      <td>Sports</td>
    </tr>
    <tr>
      <td>Travel</td>
    </tr>
    <tr>
      <td>Utilities</td>
    </tr>
    <tr>
      <td>Weather</td>
    </tr>
  </tbody>
</table>

<h2 id="structure-of-the-data">Structure of the Data</h2>

<p>If you don’t care about the exact details and structure of the data feel free to skip to the <a href="#analysis">analysis</a>.</p>

<p>The structure of the data returned by the App Store API is</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>&lt;number&gt;</span><span>,</span><span>
  </span><span>"type"</span><span>:</span><span> </span><span>"apps"</span><span>,</span><span>
  </span><span>"href"</span><span>:</span><span> </span><span>&lt;href&gt;</span><span>,</span><span>
  </span><span>"attributes"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"privacyDetails"</span><span>:</span><span> </span><span>&lt;privacy-details&gt;</span><span>
  </span><span>}</span><span>
</span><span>}</span></code></pre></figure>

<p>The <code>&lt;privacy-details&gt;</code> section of this document is the important bit. It’s an array where each item has the following structure.</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"privacyType"</span><span>:</span><span> </span><span>&lt;human-readable-description&gt;</span><span>,</span><span>
  </span><span>"identifier"</span><span>:</span><span> </span><span>&lt;string-identifier&gt;</span><span>,</span><span>
  </span><span>"description"</span><span>:</span><span> </span><span>&lt;human-readable-description&gt;</span><span>,</span><span>
  </span><span>"dataCategories"</span><span>:</span><span> </span><span>&lt;data-categories&gt;</span><span>,</span><span>
  </span><span>"purposes"</span><span>:</span><span> </span><span>&lt;data-purposes&gt;</span><span>
</span><span>}</span></code></pre></figure>

<p>The <code>&lt;string-identifier&gt;</code> is one of</p>

<table>
  <thead>
    <tr>
      <th><strong>Identifier</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DATA_LINKED_TO_YOU</td>
    </tr>
    <tr>
      <td>DATA_NOT_COLLECTED</td>
    </tr>
    <tr>
      <td>DATA_NOT_LINKED_TO_YOU</td>
    </tr>
    <tr>
      <td>DATA_USED_TO_TRACK_YOU</td>
    </tr>
  </tbody>
</table>

<p><code>DATA_NOT_COLLECTED</code> is used as a marker in which case <code>dataCategories</code> and <code>purposes</code> are both empty and this is the only element in the <code>privacyDetails</code> array.</p>

<p><code>DATA_USED_TO_TRACK_YOU</code> contains details on data used to track you across websites and apps owned by other companies, Apple’s description is <em>The following data may be used to track you across apps and websites owned by other companies:</em>. For this entry <code>purposes</code> will be empty and <code>dataCategories</code> contain the different data types that are tracked across apps and websites owned by other companies.</p>

<p><code>DATA_LINKED_TO_YOU</code> and <code>DATA_NOT_LINKED_TO_YOU</code> both contain data types with purposes specific granularity. This means that <code>dataCategories</code> will be empty and the different data types are in <code>purposes</code>. Apple’s description for <code>DATA_LINKED_TO_YOU</code> and <code>DATA_NOT_LINKED_TO_YOU</code> are <em>The following data, which may be collected and linked to your identity, may be used for the following purposes:</em> and <em>The following data, which may be collected but is not linked to your identity, may be used for the following purposes:</em> respectively.</p>

<p><code>&lt;data-purposes&gt;</code> is an array of purposes with the following structure:</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"purpose"</span><span>:</span><span> </span><span>&lt;human-readable-purpose&gt;</span><span>,</span><span>
  </span><span>"identifier"</span><span>:</span><span> </span><span>&lt;purpose-identifier&gt;</span><span>,</span><span>
  </span><span>"dataCategories"</span><span>:</span><span> </span><span>&lt;data-categories&gt;</span><span>,</span><span>
</span><span>}</span></code></pre></figure>

<p>The different values for <code>&lt;purpose-identifier&gt;</code> are:</p>

<table>
  <thead>
    <tr>
      <th><strong>Purpose</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ANALYTICS</td>
    </tr>
    <tr>
      <td>APP_FUNCTIONALITY</td>
    </tr>
    <tr>
      <td>DEVELOPERS_ADVERTISING</td>
    </tr>
    <tr>
      <td>OTHER_PURPOSES</td>
    </tr>
    <tr>
      <td>PRODUCT_PERSONALIZATION</td>
    </tr>
    <tr>
      <td>THIRD_PARTY_ADVERTISING</td>
    </tr>
  </tbody>
</table>

<p>These are described by Apple in their <a href="https://developer.apple.com/app-store/app-privacy-details/#data-type-usage">documentation</a>, but I’ve added them here for completeness.</p>

<table>
  <thead>
    <tr>
      <th>Purpose</th>
      <th>Definition</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Third-Party Advertising</td>
      <td>Such as displaying third-party ads in your app, or sharing data with entities who display third-party ads</td>
    </tr>
    <tr>
      <td>Developer’s Advertising or Marketing</td>
      <td>Such as displaying first-party ads in your app, sending  marketing communications directly to your users, or sharing data with  entities who will display your ads</td>
    </tr>
    <tr>
      <td>Analytics</td>
      <td>Using data to evaluate user behavior, including to  understand the effectiveness of existing product features, plan new  features, or measure audience size or characteristics</td>
    </tr>
    <tr>
      <td>Product Personalization</td>
      <td>Customizing what the user sees, such as a list of recommended products, posts, or suggestions</td>
    </tr>
    <tr>
      <td>App Functionality</td>
      <td>Such as to authenticate the user, enable features,  prevent fraud, implement security measures, ensure server up-time,  minimize app crashes, improve scalability and performance, or perform  customer support</td>
    </tr>
    <tr>
      <td>Other Purposes</td>
      <td>Any other purposes not listed</td>
    </tr>
  </tbody>
</table>

<p>Lastly <code>&lt;data-categories&gt;</code> is an array of objects with the following structure:</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"dataCategory"</span><span>:</span><span> </span><span>&lt;human-readable-purpose&gt;</span><span>,</span><span>
  </span><span>"identifier"</span><span>:</span><span> </span><span>&lt;data-category-identifier&gt;</span><span>,</span><span>
  </span><span>"dataTypes"</span><span>:</span><span> </span><span>[</span><span>&lt;human-readable-data-type&gt;</span><span>],</span><span>
</span><span>}</span></code></pre></figure>

<p>The full list of data types and the categories they belong to is:</p>

<figure><pre><code data-lang="json"><span>{</span><span>
  </span><span>"IDENTIFIERS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"User ID"</span><span>,</span><span>
    </span><span>"Device ID"</span><span>
  </span><span>],</span><span>
  </span><span>"USAGE_DATA"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Other Usage Data"</span><span>,</span><span>
    </span><span>"Advertising Data"</span><span>,</span><span>
    </span><span>"Product Interaction"</span><span>
  </span><span>],</span><span>
  </span><span>"DIAGNOSTICS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Performance Data"</span><span>,</span><span>
    </span><span>"Other Diagnostic Data"</span><span>,</span><span>
    </span><span>"Crash Data"</span><span>
  </span><span>],</span><span>
  </span><span>"CONTACT_INFO"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Name"</span><span>,</span><span>
    </span><span>"Other User Contact Info"</span><span>,</span><span>
    </span><span>"Phone Number"</span><span>,</span><span>
    </span><span>"Email Address"</span><span>,</span><span>
    </span><span>"Physical Address"</span><span>
  </span><span>],</span><span>
  </span><span>"PURCHASES"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Purchase History"</span><span>
  </span><span>],</span><span>
  </span><span>"LOCATION"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Coarse Location"</span><span>,</span><span>
    </span><span>"Precise Location"</span><span>
  </span><span>],</span><span>
  </span><span>"USER_CONTENT"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Other User Content"</span><span>,</span><span>
    </span><span>"Photos or Videos"</span><span>,</span><span>
    </span><span>"Audio Data"</span><span>,</span><span>
    </span><span>"Emails or Text Messages"</span><span>,</span><span>
    </span><span>"Customer Support"</span><span>,</span><span>
    </span><span>"Gameplay Content"</span><span>
  </span><span>],</span><span>
  </span><span>"CONTACTS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Contacts"</span><span>
  </span><span>],</span><span>
  </span><span>"OTHER"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Other Data Types"</span><span>
  </span><span>],</span><span>
  </span><span>"BROWSING_HISTORY"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Browsing History"</span><span>
  </span><span>],</span><span>
  </span><span>"SEARCH_HISTORY"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Search History"</span><span>
  </span><span>],</span><span>
  </span><span>"HEALTH_AND_FITNESS"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Health"</span><span>,</span><span>
    </span><span>"Fitness"</span><span>
  </span><span>],</span><span>
  </span><span>"FINANCIAL_INFO"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Credit Info"</span><span>,</span><span>
    </span><span>"Payment Info"</span><span>,</span><span>
    </span><span>"Other Financial Info"</span><span>
  </span><span>],</span><span>
  </span><span>"SENSITIVE_INFO"</span><span>:</span><span> </span><span>[</span><span>
    </span><span>"Sensitive Info"</span><span>
  </span><span>]</span><span>
</span><span>}</span></code></pre></figure>

<p>Let’s do some analysis of this data</p>

<h2 id="analysis">Analysis</h2>

<p><strong>Last Updated:</strong> 7<sup>th</sup> of January 2020. Added data for Games, which was previously missing and extended analysis of all apps to larger data set.</p>

<p>The data set I’ve collected contains 9477 combinations of apps and a position in a given category chart. In total there are 9435 unique apps in this data set.</p>

<p>Most charts contain 200 or nearly 200 apps, however <strong>Graphics &amp; Design(Paid)</strong>, <strong>Developer Tools(Paid)</strong>, and <strong>Magazines &amp; Newspapers(Paid)</strong> all have fewer than 90 apps so I’m dropping them from further analysis.</p>

<p>Because the privacy details have only been required for new apps and updates since mid December, not all apps contain information about privacy details. After removing those apps 3370 apps remain in the data set. Breaking this down by chart, several charts have less than 25 apps so I am dropping them from further analysis too. This leaves 3233 apps in the data set.</p>

<p>In total the following charts have been dropped:</p>

<ul>
  <li>Education(Paid)</li>
  <li>Navigation(Paid)</li>
  <li>Sports(Paid)</li>
  <li>Business(Paid)</li>
  <li>Food &amp; Drink(Paid)</li>
  <li>Shopping(Paid)</li>
  <li>Medical(Paid)</li>
  <li>Magazines &amp; Newspapers(Paid)</li>
</ul>

<p>For the analysis there are a few different data points that are interesting:</p>

<ul>
  <li>Apps that collect data this is linked to the user and how many such data types they collect.<sup>*</sup></li>
  <li>Apps that collect no data.</li>
  <li>Third Party tracking, i.e. tracking users across apps and websites owned by other companies and how many(max 32) such data types they collect.</li>
</ul>

<p>* Data that is linked to the user for the purpose of supporting app functionality, that is the <code>APP_FUNCTIONALITY</code> purpose, is legitimate and will be exclude from the following analysis. This leaves 160 data types spread across 5 purposes.</p>

<p>I am excluding data that is collected but not linked to the user, in part to keep down the length of the analysis and in part because it’s the least interesting. I’ll probably do a follow up post on it later.</p>

<p>The questions I’ll be looking at for this analysis are:</p>

<ol>
  <li><a href="#free-vs-paid">Do free apps collect more data?</a></li>
  <li><a href="#worst-charts">Which are the worst charts?</a></li>
  <li><a href="#worst-apps">Which apps in the whole data set are the worst?</a></li>
  <li><a href="#oxymorons">Which apps lie subtly about the nature of data they collect?</a></li>
</ol>

<p>But first let’s have a quick look at the data set.</p>

<p><em>Note: The images in this post can be clicked to show larger versions</em></p>

<p><a href="https://hugotunius.se/img/app-privacy/data-collected-histogram-plot.svg"><img src="https://hugotunius.se/img/app-privacy/data-collected-histogram-plot.svg?1610051683" alt="Histogram plot of data types collected. The apps that collect zero such data types dominate"></a></p>

<p>As we can see here, most apps collect no data outside of that which supports the app’s functionality. To get a better view of the apps that do collect data, let’s remove the majority of apps that don’t.</p>

<p><a href="https://hugotunius.se/img/app-privacy/data-collected-histogram-non-zero-plot.svg"><img src="https://hugotunius.se/img/app-privacy/data-collected-histogram-non-zero-plot.svg?1610051683" alt="Histogram plot of data types collected with zero values removed."></a></p>

<p>Still the amount of data collected is fairly low, but there’s a curious set of outliers somewhere around 120 data types collected. All of those outliers have something in common, see if you can figure it out before I reveal the answer later in the post.</p>

<p>How about third party tracking?</p>

<p><a href="https://hugotunius.se/img/app-privacy/ttp-histogram-plot.svg"><img src="https://hugotunius.se/img/app-privacy/ttp-histogram-plot.svg?1610051683" alt="Histogram plot of third party tracking data types collected. The apps that collect zero such data types dominate"></a></p>

<p>Again most apps don’t collect any data types …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html">https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html</a></em></p>]]>
            </description>
            <link>https://hugotunius.se/2021/01/03/an-analysis-of-privacy-on-the-app-store.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25640548</guid>
            <pubDate>Tue, 05 Jan 2021 00:56:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vons, Pavilions to Replace Drivers with Independent Contractors]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25640294">thread link</a>) | @danso
<br/>
January 4, 2021 | https://knock-la.com/vons-fires-delivery-drivers-prop-22-e899ee24ffd0 | <a href="https://web.archive.org/web/*/https://knock-la.com/vons-fires-delivery-drivers-prop-22-e899ee24ffd0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="19f8">News</h2><h2 id="a67f">California begins to see the devastating effects of Proposition 22.</h2><div><div><div><p><a href="https://medium.com/@mydickerson?source=post_page-----e899ee24ffd0--------------------------------" rel="noopener"><img alt="Mike Dickerson" src="https://miro.medium.com/fit/c/96/96/1*53IHqPFrt1okeXEPGL9a2Q.jpeg" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/9806/1*LzqfF7ZQEYRE_TnBHrdVpQ.jpeg" width="4903" height="2712" srcset="https://miro.medium.com/max/552/1*LzqfF7ZQEYRE_TnBHrdVpQ.jpeg 276w, https://miro.medium.com/max/1104/1*LzqfF7ZQEYRE_TnBHrdVpQ.jpeg 552w, https://miro.medium.com/max/1280/1*LzqfF7ZQEYRE_TnBHrdVpQ.jpeg 640w, https://miro.medium.com/max/1400/1*LzqfF7ZQEYRE_TnBHrdVpQ.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*LzqfF7ZQEYRE_TnBHrdVpQ.jpeg?q=20"></p></div></div></div><figcaption>(Source: <a href="https://commons.wikimedia.org/wiki/File:Aves_en_Vons.JPG" rel="noopener">AdriÃ¡n CerÃ³n</a>, <a href="https://creativecommons.org/licenses/by-sa/4.0" rel="noopener">CC BY-SA 4.0</a>, via Wikimedia Commons)</figcaption></figure><p id="fcd4">When Dylanâ€™s grocery delivery arrived a few days before New Years, it came with some bad news. The delivery driver who brought his groceries from Vons mentioned that drivers across the state are getting fired by Vons, Pavilions, and other California stores owned by Albertsons Companies in late February. Stores will instead turn to a third-party delivery service using independent contractors.</p><p id="d033">â€œI was disturbed and disappointed that Vons would eliminate these jobs. I felt like they were the only remaining company that treated delivery drivers ethically but no longer,â€� said Dylan.</p><p id="1f42">After publication, an Albertsons representative sent the following statement: â€œWe will transition that portion of our eCommerce operations to third-party logistics providers.â€� She added â€œWhile we know that this move will help us create a more efficient operation, it wasnâ€™t a decision we made lightly or without a great deal of consideration.â€�</p><p id="10d5">Drivers under the Albertsons Companies umbrella are employees, while Ralphs delivery is operated by Instacart and Target uses Shipt, a similar app. At Bay Area stores, drivers are unionized, and will not be affected by the layoffs. For southern California shoppers, this move leaves them without a grocery delivery option that treats drivers as employees.</p><p id="baaa">Unions are vowing to fight the change, says Jim Araby, Director of Strategic Campaigns at UCFW5. â€œThe only drivers that kept their jobs were the unionized drivers in the Bay Area. All the other drivers in California were laid off because they were non-union. We represent those drivers and they will keep their job.â€�</p><p id="4b12">These layoffs are unsurprising after the passage of Proposition 22, which gutted worker protections while making it easier for companies to shift financial burdens onto newly-designated â€œindependent contractors.â€� In a <a rel="noopener" href="https://knock-la.com/the-case-for-voting-no-on-ca-prop-22-a64d25b2828d">piece for KNOCK</a> last year, Keith F. Eberl predicted this exact outcome in the opening paragraph:</p><blockquote><p id="95b6">â€œContrary to the companiesâ€™ deceptive ad campaign and intimidating messages to their workers, Prop 22 does not preserve driver flexibility or save drivers from politicians. What Prop 22 does do is change current law so the companies can shift their costs to the driver and diminish or remove driversâ€™ rights, protections, and benefits. Prop 22 will also block driversâ€™ ability to organize so they canâ€™t collectively bargain a contract. In addition, this proposition will block local governments from writing or enforcing protections for drivers.â€�</p></blockquote><p id="a03f">The only surprise is the speed at which Albertsons reversed course on its commitments to workers. This move comes after nearly a year of celebrating grocery store workers for feeding communities. <a href="https://www.vons.com/steps-we-are-taking-at-your-grocery-store.html" rel="noopener">Earlier this year</a>, Albertsons Companies President &amp; CEO Vivek Sankaran said the company was â€œtaking care of our team.â€� Albertsons Companies â€œare workingâ€¦ to ensure that every member of our team who faces a crisis can have peace of mind that we will help them get through it.â€�</p><p id="c5d5">Albertsons was happy to reap public goodwill during the pandemic. But once Prop 22 gave the company the option of replacing workers with lower-paid contractors, they jumped at the opportunity. Employees received notice during the holidays that their employment would end one month into the new year.</p><p id="66cc">Early in the pandemic, union members demanded hazard pay, additional medical leave, and employee protections during the pandemic. In March, Safeway and Northern California grocery workers <a href="https://www.sfchronicle.com/business/article/Coronavirus-Safeway-reaches-new-agreement-for-15150811.php" rel="noopener">reached an agreement</a> providing these additional benefits.</p><p id="452b">Labor and management were able to cooperate in April, requesting that grocery workers be designated as first responders. In an April j<a href="https://www.albertsonscompanies.com/helping-you-through-covid-19/albertsons-companies-ucfw-launch-joint-effort.html" rel="noopener">oint statement</a>, Sankaran and United Food and Commercial Workers International Union (UFCW) President Marc Perrone wrote:</p><blockquote><p id="c86a">â€œThis joint action is an example of how all Americans must work together to protect everyone working on the frontlines. This includesâ€¦ associates at our nationâ€™s grocery stores who are providing communities with the essential food and supplies needed to weather this public health crisis.â€�</p></blockquote><p id="0a33">Negotiations in October <a href="https://www.ocregister.com/2020/10/08/grocery-warehouse-workers-truck-drivers-give-notice-of-potential-strike/" rel="noopener">turned contentious</a>, as members of the Teamsters issued a notice of potential strike due to rising healthcare costs. Lou Villavazo, who chairs the bargaining effort, told the <a href="https://www.ocregister.com/2020/10/08/grocery-warehouse-workers-truck-drivers-give-notice-of-potential-strike/" rel="noopener">Orange County Register</a> that â€œemployers have been bargaining in bad faith. Weâ€™ve had over 18 bargaining sessions with them and we provided our economic proposal â€¦ but no response.â€�</p><p id="e2db">Organized labor made the difference for drivers in the Bay Area, who will remain as employees for now. But without the power of a union, southern California drivers lack an organizational structure through which to fight back.</p><p id="b343">Many, myself included, turned to Vons and Albertsons stores for their groceries, knowing that drivers were employed with benefits. Unionized drivers offered a clear alternative to the <a href="https://www.bloomberg.com/news/articles/2020-12-24/no-holiday-cheer-for-gig-workers-hunting-your-last-minute-gifts" rel="noopener">hellscape of gig-economy apps</a> like Instacart.</p><p id="a579">In a <a href="https://www.albertsonscompanies.com/newsroom/appreciation-pay-for-front-line-associates.html" rel="noopener">March 2020 statement</a>, Sankaran said â€œthese times are unprecedented in the grocery industryâ€¦ [a] simple â€˜thank youâ€™ doesnâ€™t seem like quite enough.â€� He was right. Delivery drivers deserve healthcare, job protections, and fair wages. Workers won those fights this year because they fought as a union. With DoorDash taking over in February, that united front will be gone.</p><p id="26c2">You can contact Albertsons Companies and let them know what you think of this move:</p><p id="2910">Vons Retail Store/Corporate Phone Number: 877â€“723â€“3929</p><p id="2f7e">Albertsons Retail Store/Corporate Phone Number: 877â€“723â€“3929</p><p id="2b59"><em>EDITORâ€™S NOTE: After publication, Albertsonâ€™s responded to KNOCKâ€™s request for comment. This piece has since been edited to clarify that union drivers will not be laid off and that workers facing layoffs in Southern California are non-union, as well as to include statements from both Albertsons and UCFW5. The scheduled date of the layoffs was also corrected.</em></p></div></div></section></div>]]>
            </description>
            <link>https://knock-la.com/vons-fires-delivery-drivers-prop-22-e899ee24ffd0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25640294</guid>
            <pubDate>Tue, 05 Jan 2021 00:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Google Traffic Has Fallen to Zero]]>
            </title>
            <description>
<![CDATA[
Score 485 | Comments 397 (<a href="https://news.ycombinator.com/item?id=25640217">thread link</a>) | @josephjrobison
<br/>
January 4, 2021 | https://www.goodcheapandfast.com/2020 | <a href="https://web.archive.org/web/*/https://www.goodcheapandfast.com/2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          
            
              
                
                  
                
              
            
          

          <main>
            
              <section data-content-field="main-content">
                <div data-type="page" data-updated-on="1608230832114" id="page-5fd3a159f92762251f1c6eca"><div><div><div data-block-type="2" id="block-016a72dee6b3751c6cf2"><p><h3>Google's December 2020 Core Algorithm Update drove this website's traffic to new highs last week, then it fell to zero.</h3></p></div><div data-block-type="5" id="block-yui_3_17_2_1_1607704925648_14759"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607705105493-A75SVPI65VJDT5XKLWXI/ke17ZwdGBToddI8pDm48kEYoQxTi5oKpiEba6WUyZp4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds6qln6HpuaNqwonEk3tr1DAktcgtHSS7CyIBz9i8uwd7zs2yPjc1ECvpa5Zm_kMqw/Eo9bZOCWMAARRGD.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607705105493-A75SVPI65VJDT5XKLWXI/ke17ZwdGBToddI8pDm48kEYoQxTi5oKpiEba6WUyZp4UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds6qln6HpuaNqwonEk3tr1DAktcgtHSS7CyIBz9i8uwd7zs2yPjc1ECvpa5Zm_kMqw/Eo9bZOCWMAARRGD.jpeg" data-image-dimensions="1536x549" data-image-focal-point="0.5,0.5" alt="Eo9bZOCWMAARRGD.jpeg" data-load="false" data-image-id="5fd3a211c4a2b267e28574c8" data-type="image" src="https://www.goodcheapandfast.com/Eo9bZOCWMAARRGD.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1607704925648_15047"><div><p>This website stopped receiving referrals from Google last night. It's a total wipeout after two years of building a business that's also my full-time focus and my family's sole source of income. I'm heartbroken and confused.</p><h2><strong>The Cruelest Year</strong></h2><p>2020 has been awful, and despite this new challenge that I face, I still count myself blessed. A friend of mine has lived in a veritable shoebox for a decade, pumping every hour and cent he had into building two of the most beloved bars in New York City. He filed for bankruptcy last month. Another friend attended a family reunion in February; it was the last time that she'd see several of her relatives (who died from COVID-19 in the weeks that followed).</p><p>Again, no matter what happens to this site, I really do feel fortunate and blessed.</p><h2><strong>The Risk of Relying on Big Tech</strong></h2><p>As much as I've tried to diversify <em>Good, Cheap and Fast</em>'<em>s</em> revenue and traffic, I haven’t escaped the gravitational pull of Amazon and Google. This poses major risks and I advise caution to anyone considering a similar business model.</p><p>In April of this year, Amazon <a href="https://searchengineland.com/amazon-affiliate-commission-rates-cut-332966">reduced the affiliate commissions</a> that it pays to online publishers. My revenue fell by 41% as a result. It was a crushing blow that I attempted to mitigate by joining other affiliate programs, but they didn't pan out. The median conversion rate of the 70 other websites that I linked to was a meager 0.8%, which is approximately 1/10 of the conversion rate on Amazon.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1607784280213_34634"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Best Buy is a great company. Nevertheless, my visitors are 6,500% more likely to make a purchase from Amazon.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1607784280213_34922"><div><p>Then, <a href="https://www.mariehaynes.com/may-2020-core-google-update/">Google's May 2020 algorithm update</a> cut my traffic by around 70%.</p><p>I didn't publish much on this website between March and April because I was focused on <a href="https://www.linkedin.com/posts/johndefeo_for-anyone-looking-for-coronavirus-newsupdates-activity-6644299863842447360-xaYA/">learning about COVID-19</a> with the goal of keeping my family safe. It's reasonable to assume that this hiatus may have resulted in this site being on the wrong side of Google's algorithm, so from May until now, I've worked seven days a week on improving this site -- around 1,200 hours in total.</p><p>My Google traffic gradually recovered, reached new highs, then it went terminal.</p><h2><strong>Doing the Right Thing</strong></h2></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1607784280213_18633"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607784443523-YRG92MPU12H93L80Q7PT/ke17ZwdGBToddI8pDm48kJeCjys4TeC3DGU_a1akXtdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyUUXYGPH9DHj5celJrvHX8W6t_uE79Pi8unyS9KZtA3CYWXOatDWau0S9eSkX7oGw/Screen+Shot+2020-12-12+at+9.47.00+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607784443523-YRG92MPU12H93L80Q7PT/ke17ZwdGBToddI8pDm48kJeCjys4TeC3DGU_a1akXtdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyUUXYGPH9DHj5celJrvHX8W6t_uE79Pi8unyS9KZtA3CYWXOatDWau0S9eSkX7oGw/Screen+Shot+2020-12-12+at+9.47.00+AM.png" data-image-dimensions="659x872" data-image-focal-point="0.5,0.5" alt="This website is committed to privacy; it was one of the first 100 companies to endorse the  Contract for the Web ." data-load="false" data-image-id="5fd4d7fb164d0f203c51bdf9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607784443523-YRG92MPU12H93L80Q7PT/ke17ZwdGBToddI8pDm48kJeCjys4TeC3DGU_a1akXtdZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyUUXYGPH9DHj5celJrvHX8W6t_uE79Pi8unyS9KZtA3CYWXOatDWau0S9eSkX7oGw/Screen+Shot+2020-12-12+at+9.47.00+AM.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>This website is committed to privacy; it was one of the first 100 companies to endorse the <a href="https://contractfortheweb.org/">Contract for the Web</a>.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1607784280213_18921"><p>Since I launched this site in Oct. 2018, it has never contained ads, trackers nor slideshows. I don't collect any personally identifiable information. I don't allow guest posts or third-party content. I'm completely transparent about how this website makes money as well as the methods and limitations of my product selection methodology. Every affiliate link on this site is properly disclosed and wrapped in a "rel sponsored" tag. I take the time to read scientific and medical research as it relates to the topics that I cover, and when I find a product that is potentially harmful (like weighted eye masks), I share my findings with every major publisher who has written positive things about that product. I use my expertise to <a href="https://www.linkedin.com/posts/johndefeo_if-you-support-a-charity-via-amazonsmile-activity-6737737229449379840-vc6I/">support charity</a> and <a href="https://www.linkedin.com/posts/johndefeo_to-my-friends-in-journalism-be-cautious-activity-6733095426775404544-FbxR/">to teach colleagues about scams</a>. All of these factors have built trust in my brand. I know this because the percentage of my visitors who go forth to make a purchase has climbed steadily for two years.</p></div><div data-block-type="5" id="block-yui_3_17_2_1_1607784280213_68769"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607785322376-GN0139MP1XEGAGBNW4VL/ke17ZwdGBToddI8pDm48kFqYFZLDQ5urJwi9gnzSGHJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIERTuUcWuFWTMfMjVW38Nggz8HmC14XFJR0_lAEGtGZ8/Screen+Shot+2020-12-12+at+10.01.20+AM.png" data-image="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607785322376-GN0139MP1XEGAGBNW4VL/ke17ZwdGBToddI8pDm48kFqYFZLDQ5urJwi9gnzSGHJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIERTuUcWuFWTMfMjVW38Nggz8HmC14XFJR0_lAEGtGZ8/Screen+Shot+2020-12-12+at+10.01.20+AM.png" data-image-dimensions="849x518" data-image-focal-point="0.5,0.5" alt="My traffic and revenue are subject to forces outside my control, however, this stat measures the factors in my control." data-load="false" data-image-id="5fd4db6ae5ac582896f9dcc2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607785322376-GN0139MP1XEGAGBNW4VL/ke17ZwdGBToddI8pDm48kFqYFZLDQ5urJwi9gnzSGHJZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIERTuUcWuFWTMfMjVW38Nggz8HmC14XFJR0_lAEGtGZ8/Screen+Shot+2020-12-12+at+10.01.20+AM.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>My traffic and revenue are subject to forces outside my control, however, this stat measures the factors in my control.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1607784280213_69057"><div><p>But, as much as I'd like this website to be a destination, it will never be one.&nbsp;</p><p><em>Good, Cheap and Fast</em> was profiled by big name websites like <a href="https://www.fastcompany.com/90274504/hate-browsing-amazon-this-is-the-ultimate-no-frills-shopping-site">Fast Company</a> and <a href="https://twitter.com/kottke/status/1067547920617086976">Kottke</a>. These media mentions drove hundreds of thousands of visits. Nevertheless, if someone who was referred to this website two years ago is looking for a cheap portable generator today, he or she is much more likely to Google "cheap portable generator" than to come to my homepage.</p><p>It's understandable. Alas, without search visibility, this site in invisible.</p><h2><strong>Can a Domain Be Cursed?</strong></h2><p>I did my due diligence before I registered goodcheapandfast.com. It had no backlink history and it had only existed previously as a parked domain in 2013. There are no obvious skeletons in this domain's closet, yet strange things have been afoot, almost since day one.</p><p>For example, Bing didn't even index this website's homepage a month after <em>Good, Cheap and Fast</em> was linked to from websites like Esquire and Slate. I contacted bingwb@microsoft.com with my concerns and received this response:</p><blockquote><p>Good day and thank you for your patience while we investigated the issue.</p><p>Firstly, I am happy to provide you information that our product review group succeeded in removing the block of the site. After submitting your site to be reviewed the team has decided to lift the  block. Please allow up to 2-3 weeks for your site to be crawled indexed and serving again.&nbsp;&nbsp;</p><p>I am unable to provide you the specifics of the block as our product review team does not share details of the block.</p></blockquote><p>The mystery didn't end there. Two years later, this website has received fewer than 100 total referrals from Bing. That's not normal and neither is this: Since 2019, pages on this website started dropping in-and-out of Google's results. An article that ranked #1 would disappear entirely, then reappear, then disappear, then reappear. These were like mini strokes. Sometimes the traffic bounced back in full; other times it gradually faded away.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1607704925648_28921"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607705806377-HKE2K8E19Z6N7L9RDYFI/ke17ZwdGBToddI8pDm48kBBWv4dEpfcKRhEc-mPgvhhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIH_TPfyAj5DK2q4KS84c9dntObHZV9V2os84uj8Aa0M0KMshLAGzx4R3EDFOm1kBS/Google-Indexing-Bugs.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607705806377-HKE2K8E19Z6N7L9RDYFI/ke17ZwdGBToddI8pDm48kBBWv4dEpfcKRhEc-mPgvhhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIH_TPfyAj5DK2q4KS84c9dntObHZV9V2os84uj8Aa0M0KMshLAGzx4R3EDFOm1kBS/Google-Indexing-Bugs.jpg" data-image-dimensions="750x229" data-image-focal-point="0.5,0.5" alt="I have a hard time describing the frustration and confusion that I’ve felt watching my fate swing like a pendulum." data-load="false" data-image-id="5fd3a4ce872d8f1a0acde79a" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1607705806377-HKE2K8E19Z6N7L9RDYFI/ke17ZwdGBToddI8pDm48kBBWv4dEpfcKRhEc-mPgvhhZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIH_TPfyAj5DK2q4KS84c9dntObHZV9V2os84uj8Aa0M0KMshLAGzx4R3EDFOm1kBS/Google-Indexing-Bugs.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>I have a hard time describing the frustration and confusion that I’ve felt watching my fate swing like a pendulum.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1607704925648_29209"><div><p>I've managed dozens of websites over the last 17 years -- most recently as the head of content strategy and search engine optimization for one of the largest publishing companies in the U.S. -- and I've never seen anything like this before.</p><h2><strong>The Lunatic Fringe</strong></h2><p>I’m not too proud to ask for help, especially when my livelihood depends on it, so I swallowed any professional embarrassment and shared my plight with Google spokespersons and online marketing professionals. The best that I've gotten in return was a <a href="https://twitter.com/dannysullivan/status/1327323523828703232">superficial acknowledgement</a> that resulted in a dead end.</p><p>I get it. My situation is weird and it's not easily explainable. But, the ramifications are very real and they threaten my financial (and mental) well being.</p><blockquote><p>(The closest analogue that I've had to this experience was dealing with the State of NJ Treasury, trying to recover unclaimed property that was purchased by Anthony DeFeo, in the custody of John Anthony DeFeo for the benefit of John William Anthony DeFeo. It dragged on for two years.)</p></blockquote><p>There's an old proverb, "Who knows what is good and what is bad." </p><p>Maybe my own plight, which admittedly doesn't even register as a drop in the sea of 2020 misery, is part of something good that has yet to reveal itself. </p><p>I'm doing the best that I can to stay positive, but it isn't easy.</p><p>———</p><p><strong>Update, 12/15</strong> - My traffic has settled into a 90% loss. I at least feel better (in a sad way) that I have been heard and explicitly told <a href="https://twitter.com/dannysullivan/status/1338949972507590656">that there is no recourse</a>.</p><p><strong>Postscript</strong> - If you’ve made it this far and you’re feeling magnanimous, I humbly ask that you share <a href="https://www.gofundme.com/f/trying-to-raise-much-as-possible-fight-my-cancer">my friend Chris May’s online fundraiser</a>. Chris was laid off earlier this year, then diagnosed with Stage 4 colon cancer. He is 45 years old.</p></div></div></div></div><div><div><div><div><div data-block-json="{&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;collectionId&quot;:&quot;5c9fa5b8971a1874e4775783&quot;,&quot;design&quot;:&quot;list&quot;,&quot;headerText&quot;:&quot;Featured&quot;,&quot;textSize&quot;:&quot;medium&quot;,&quot;pageSize&quot;:10,&quot;imageAspectRatio&quot;:&quot;1&quot;,&quot;columnWidth&quot;:270,&quot;gutter&quot;:60,&quot;listImageSize&quot;:10,&quot;listImageAlignment&quot;:&quot;left&quot;,&quot;slidesPerRow&quot;:3,&quot;textAlignment&quot;:&quot;left&quot;,&quot;showTitle&quot;:true,&quot;showThumbnail&quot;:true,&quot;showExcerpt&quot;:true,&quot;showReadMoreLink&quot;:false,&quot;showPrice&quot;:true,&quot;productQuickViewEnabled&quot;:false,&quot;showPastOrUpcomingEvents&quot;:&quot;upcoming&quot;,&quot;metadataPosition&quot;:&quot;below-content&quot;,&quot;primaryMetadata&quot;:&quot;none&quot;,&quot;secondaryMetadata&quot;:&quot;none&quot;,&quot;filter&quot;:{&quot;categoryIds&quot;:null},&quot;autoCrop&quot;:true,&quot;lightbox&quot;:true,&quot;mixedContent&quot;:true,&quot;blockId&quot;:&quot;a748e58d2531d057b519&quot;}" data-block-type="55" id="block-yui_3_17_2_1_1607704925648_36997"><div>



<div>

  <div>

    

    <div>

      

        <div data-click-through-url="https://www.goodcheapandfast.com/about">

          
            <!-- Thumbnail -->
            

  
  <div>
    <a href="https://www.goodcheapandfast.com/about" data-title="John DeFeo, Founder of Good, Cheap and Fast" data-description="<p class=&quot;&quot; style=&quot;white-space:pre-wrap;&quot;>&quot;Good, cheap and fast -- pick two,&quot; is one of my favorite sayings. It's usually true, however, I built this website to help you find top-rated, inexpensive products within minutes. Here's the catch: It's a slow process behind the scenes.</p><p class=&quot;&quot; style=&quot;white-space:pre-wrap;&quot;>Since 2018, I've spent thousands of hours scouring the web for above-average products that sell for below-average prices. Along the way, I've learned how to spot counterfeit goods, disingenuous sellers, fake reviews (and real reviews that aren't particularly helpful).</p><p class=&quot;&quot; style=&quot;white-space:pre-wrap;&quot;><em>Good, Cheap and Fast</em> has no ads, no slideshows and no tracking pixels. I value your time and your privacy and I hope that others will do the same.</p><p class=&quot;&quot; style=&quot;white-space:pre-wrap;&quot;>In the recent past, I was head of insights for the company that published <em>AnandTech</em>, <em>Laptop Mag</em>, <em>Tom's Guide</em> and <em>Tom's Hardware</em> (as well as educational sites like <em>Space.com</em> and <em>Live Science</em>). I worked with product reviewers, lab testers and journalists each day for six years.</p><p class=&quot;&quot; style=&quot;white-space:pre-wrap;&quot;>Before that, I was director of business intelligence for <em>The Street</em> (a financial media company) and a strategist at publications like <em>Car &amp;amp; Driver</em>, <em>Elle</em>, <em>Popular Photography</em> and <em>Woman's Day</em>. I also co-founded <em>Debonair</em>, a men's fashion and lifestyle publication. I’m a graduate of New York University’s Tisch School of the Arts and I live in Brooklyn, New York.</p><p class=&quot;&quot; style=&quot;white-space:pre-wrap;&quot;>You can contact me via <a href=&quot;mailto:john@goodcheapandfast.com&quot; target=&quot;&quot;><strong>e-mail</strong></a> or find me on <a href=&quot;https://www.linkedin.com/in/johndefeo/&quot; target=&quot;&quot;><strong>LinkedIn</strong></a>, <a href=&quot;https://www.crunchbase.com/person/john-defeo-10a7&quot; target=&quot;&quot;><strong>Crunchbase</strong></a> and <a href=&quot;https://twitter.com/johndefeo&quot; target=&quot;&quot;><strong>Twitter</strong></a>.</p>">
      <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1601559434612-IKX5K2REA2KKRY4S6S57/ke17ZwdGBToddI8pDm48kPJXHKy2-mnvrsdpGQjlhod7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmihaE5rlzFBImxTetd_yW5btdZx37rH5fuWDtePBPDaHF5LxdCVHkNEqSYPsUQCdT/John-W-DeFeo-Headshot.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1601559434612-IKX5K2REA2KKRY4S6S57/ke17ZwdGBToddI8pDm48kPJXHKy2-mnvrsdpGQjlhod7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmihaE5rlzFBImxTetd_yW5btdZx37rH5fuWDtePBPDaHF5LxdCVHkNEqSYPsUQCdT/John-W-DeFeo-Headshot.jpg" data-image-dimensions="1000x1000" data-image-focal-point="0.5,0.5" alt="John DeFeo, Founder of Good, Cheap and Fast" data-load="false" src="https://images.squarespace-cdn.com/content/v1/5bbe4cb0d745625c9d104763/1601559434612-IKX5K2REA2KKRY4S6S57/ke17ZwdGBToddI8pDm48kPJXHKy2-mnvrsdpGQjlhod7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmihaE5rlzFBImxTetd_yW5btdZx37rH5fuWDtePBPDaHF5LxdCVHkNEqSYPsUQCdT/John-W-DeFeo-Headshot.jpg">

    

    

        

        

      </p>
    </a>

    <!-- Products: Quick View -->
    

  </div>
  



          

          <div data-animation-role="content">

            <!-- Metadata (Above Title) -->
            

            
              <!-- Title -->
              
            

            <!-- Metadata (Below Title) -->
            

            
              
            

            
              

              
              <!--- Gallery: Caption Description -->
                <div><p>"Good, cheap and fast -- pick two," is one of my favorite sayings. It's usually true, however, I built this website to help you find top-rated, inexpensive products within minutes. Here's the catch: It's a slow process behind the scenes.</p><p>Since 2018, I've spent thousands of hours scouring the web for above-average products that sell for below-average prices. Along the way, I've learned how to spot counterfeit goods, disingenuous sellers, fake reviews (and real reviews that aren't particularly helpful).</p><p><em>Good, Cheap and Fast</em> has no ads, no slideshows and no tracking pixels. I value your time and your privacy and I hope that others will do the same.</p><p>In the recent past, I was head of insights for the company that published <em>AnandTech</em>, <em>Laptop Mag</em>, <em>Tom's Guide</em> and <em>Tom's Hardware</em> (as well as educational sites like <em>Space.com</em> and <em>Live Science</em>). I worked with product reviewers, lab testers and journalists …</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.goodcheapandfast.com/2020">https://www.goodcheapandfast.com/2020</a></em></p>]]>
            </description>
            <link>https://www.goodcheapandfast.com/2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25640217</guid>
            <pubDate>Tue, 05 Jan 2021 00:17:19 GMT</pubDate>
        </item>
    </channel>
</rss>
