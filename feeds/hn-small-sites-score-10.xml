<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 26 Nov 2020 08:27:23 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 26 Nov 2020 08:27:23 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2Ôªø<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>Ôªø could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it‚Äôs injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world‚Äôs single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>üì© Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>üéô <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>üì≤ Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to OOMKill Alerting in Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25192733">thread link</a>) | @draganm
<br/>
November 23, 2020 | https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters | <a href="https://web.archive.org/web/*/https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <span>Monday 23 Nov 2020, 18:30</span> <h2>Intro</h2> <p>RAM is most likely the scarcest resource that is first exhausted on your servers. If you‚Äôre serious about running software under Linux/Unix, you‚Äôre certainly aware of what an OOMKill is.</p> <p>Short refresher: when a program requests a new memory page from the kernel two things can happen.</p> <ul><li>There is a free memory page: The kernel page assigns the page to the process and everything is great.</li> <li>The system is Out Of Memory (OOM): The kernel chooses a process based on its ‚Äòbadness‚Äô (mainly by how much ram it uses). It sends a SIGKILL to the process. This forces the receiving process to exit with exit code <code>137</code>. All the memory pages belonging to that process are free and now the kernel can fulfill the memory request.</li></ul> <p>Lately, I had a task to add alerting to a sizeable Kubernetes cluster. The cluster has ~100 active Deployments with autoscaling of nodes up to ~50 nodes at peak times. The cluster is well maintained and has a robust autoscaling strategy. All deployments have resource limits defined. Sometimes, some of the deployed pods would breach the memory limits. In those cases, it would be nice to find out when that happens and investigate the cause of it.</p> <p>Prometheus and Alertmanager were already deployed. So I‚Äôve thought that alerting on OOMKills will be as easy. I just had to find the right metric(s) indicating that OOMKill has happened and write an alerting rule for it. Given the length of this post, you could imagine how wrong I was!</p> <h2>First Attempt</h2> <p>A brief Google search has led me to the <a href="https://github.com/kubernetes/kube-state-metrics/blob/master/docs/pod-metrics.md" rel="nofollow">kube pod state metric</a>. It turns out it has a metric called <code>kube_pod_container_status_last_terminated_reason</code>. The value of the metric is <code>1</code> when a container in a pod has terminated with an error. Based on the exit code, the <code>reason</code> label will be set to <code>OOMKilled</code> if the exit code was <code>137</code>. That sounded promising! So I‚Äôve created an alert for that.</p> <p>As usual, things are rarely straightforward. As soon as the container restarts, the value of this metric will be <code>1</code>. For alerting purposes, one has to combine it with another metric that will change when a pod restarts. <code>kube_pod_container_status_restarts_total</code> does that. Combine the two - and Bingo! It Worked!</p> <h2>‚ÄúInvisible‚Äù OOMKills</h2> <p>For a brief moment, I‚Äôve thought that I was done. I was about to declare victory over OOMKills in production! But then a puzzle came my way: One of our software developers has come forward. He claimed that one of his pods was running out of memory and he couldn‚Äôt see any alerts for it.</p> <p>At first, I wasn‚Äôt inclined to believe that his diagnosis of running out of memory was correct. Mainly because his Pod didn‚Äôt even restart! But then I looked at the graph of the memory use of the Pod. It did show the usual pattern: Memory usage would grow, reach its peak at the memory limit, and then suddenly drop.</p> <p>I‚Äôve asked the developer for the gory details of the implementation. It turned out that the init process in the container would start a child process and wait for the result of it. If the child process would exit with an error, it would return an error to the requester and not terminate (because - why should it?).</p> <p>That is when it dawned to me - my alerting is effective only if container exits. This is usually the case when the init process of the container is OOMKilled. But there is no guarantee this will happen if a child of the init is OOMKilled. In the case where the container‚Äôs init tries to handle OOMKill by itself, my alerting is not triggering!</p> <h2>Trying the Existing Solutions</h2> <p>Given that OOMKills are as old as Unix, I thought: surely someone will have a solution for this already.</p> <p>I‚Äôve ensued onto a frantic search for some kind of metric exporter for this. I just needed the number of OOMKill events in a pod, or at least in a Docker container. Here is what I‚Äôve found:</p> <h3>cAdvisor</h3> <p>My first stop was cAdvisor itself. It turns out that cAdvisor is <a href="https://github.com/google/cadvisor/issues/1837" rel="nofollow">getting the OOMKill events, but not exporting them as a Prometheus metric and no one really seems to care.</a> So that was a dead-end.</p> <h3>kubernetes-oomkill-exporter</h3> <p>My second stop was <a href="https://github.com/sapcc/kubernetes-oomkill-exporter" rel="nofollow">kubernetes-oomkill-exporter</a>. A very promising-sounding project with two huge disadvantages:</p> <ul><li>There is really no documentation for it, literally anywhere.</li> <li>It does not work.</li></ul> <p>I‚Äôve tried the latest version of <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.3.0/images/sha256-b80875b903635f0336ea0b122b332e086da51ec5cd797de5d682dd14c3910b9f?context=explore" rel="nofollow">the Docker image</a>, but once started it crashes and burns with:</p> <pre><code>standard_init_linux.go:211: exec user process caused "no such file or directory"</code></pre> <p>Going <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.2.0/images/sha256-5e1b57f4ac0b57406ef067da3e83f743d70ff89aa1db717d41af2c699dc12f3a?context=explore" rel="nofollow">back one minor version</a> one gets the following output:</p> <pre><code>F1120 22:04:21.571246       1 main.go:73] Could not create log watcher
I1120 22:04:21.572066       1 main.go:64] Starting prometheus metrics</code></pre> <p>As it seems no one has committed any code to in over a year. It has a low number of stars (14). All that meant that I was back to square one.</p> <h2>Rolling my Own: <code>missing-container-metrics</code></h2> <p>Having a hard time finding an existing solution meant only one thing: I will have to write my own.</p> <p>A cursory look at <a href="https://docs.docker.com/engine/reference/commandline/events/" rel="nofollow">Docker‚Äôs events</a> delivered everything I needed. There is an event called <code>oom</code>. Docker emits this event every time the OOMKiller process gets active in the container. Now I was only missing a piece of code that will listen to those events and export them as Prometheus metrics.</p> <p>This is how <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> was born. What it does is to connect to a local Docker instance (via <code>/var/run/docker.sock</code>). It lists all existing containers as a starting point. And then it listens to Docker events. Using those events, it keeps track of the currently running containers. It also gathers the basic stats of each container it knows about:</p> <ul><li>Number of restarts</li> <li>Last exit code</li> <li>Number of OOMKills</li></ul> <p>By design, it is not Kubernetes specific. This means it can be used with a plain Docker. But it also has a couple of very convenient Kubernetes specific features.</p> <p>Whenever it finds a container label for the pod name or namespace, it adds them as a label to the exported metrics. Also, label naming is compatible with <code>kube-state-metrics</code>.</p> <p>This keeps things simple for metric joins in PromQL.</p> <h2>Running it in the Cluster</h2> <p>In a Kubernetes cluster, <code>missing-container-metrics</code> needs to run on every node. The simplest way to achieve this is to use a daemon-set. The source code comes with an example <a href="https://github.com/draganm/missing-container-metrics#kubernetes" rel="nofollow">daemon set</a> deployment.</p> <h2>An Interesting Find Using <code>missing-container-metrics</code></h2> <p>The most interesting issue I‚Äôve found was where I‚Äôve least expected it: Fluentd!</p> <p>Fluentd log forwarder for node/pod/kubelet logs to the log aggregator. When the volume of logs was very high, Fluentd is OOMKilled.</p> <p>Looking at the details of how Fluentd works, it becomes clear what is going on.</p> <p>Fluentd has one main process (that ends up being init process in the container). This main process forks a worker process that forwards the logs. When the worker process dies for some reason (for example OOMKill), the main process starts a new one. This leads to an endless loop of spawn/OOMKill.</p> <p>The fact that Fluentd is the log forwarder is very unfortunate. OOMKill loop would stop the log forwarding, so you could not ‚Äòsee‚Äô what is going on by inspecting the logs.</p> <h2>Epilogue</h2> <p>If you want to make sure that your Kubernetes cluster is healthy, it is essential to alert on OOMKills. This enables you to know when processes hit their memory limits. Be it because of memory leaks or wrongly configured memory limits.</p> <p>It turns out that monitoring for OOMKills in Kubernetes is not as an easy task as one might think. Using <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> makes it much easier though.</p> <p>So go ahead, deploy <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> to your cluster. You might be surprised how many of OOMKills you have not been noticing.</p> <p>I hope that it will be useful to you, and will save you the time that I‚Äôve spent searching for the solution.</p></article></div>]]>
            </description>
            <link>https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192733</guid>
            <pubDate>Mon, 23 Nov 2020 22:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A list with 200+ companies sponsoring tech newsletters and websites]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25189975">thread link</a>) | @thikari
<br/>
November 23, 2020 | https://sponsorgap.com/companies-buying-ads-and-sponsorships | <a href="https://web.archive.org/web/*/https://sponsorgap.com/companies-buying-ads-and-sponsorships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Sponsorgap makes it easy to get a sponsor for your product. <br> </p></div></div>]]>
            </description>
            <link>https://sponsorgap.com/companies-buying-ads-and-sponsorships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189975</guid>
            <pubDate>Mon, 23 Nov 2020 18:36:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Synthetic-Aperture Radar Imaging]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25189860">thread link</a>) | @parsecs
<br/>
November 23, 2020 | https://hforsten.com/synthetic-aperture-radar-imaging.html | <a href="https://web.archive.org/web/*/https://hforsten.com/synthetic-aperture-radar-imaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                
<p>Few years ago I did some <a href="https://hforsten.com/homemade-synthetic-aperture-radar.html">simple synthetic-aperture radar (SAR) imaging
experiments</a> with the second version of my homemade
FMCW radar. Since then I made a much improved <a href="https://hforsten.com/third-version-of-homemade-6-ghz-fmcw-radar.html">third version of the
radar</a> but didn't do any SAR measurements due to the
amount of effort it would have required. I did have plans to do some SAR
experiments afterwards but it took until now to have enough time and
motivation.</p>
<p>Synthetic aperture radar (SAR) imaging is a way to synthesize very large antenna
array by moving single antenna on a known path. If there are no moving targets
in the scene then one radar taking many measurements along a path gives the same
result as one ridiculously large radar that is as long as the movement path.</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xsar_imaging.png.pagespeed.ic.MP13OL2L7B.png" width="40%/"></p><p>SAR imaging of a single target. As the radar
    moves the measured distance follows a parabola.</p>
</div>

<p>If we move on a straight path while radar pointing 90 degrees from the direction
of the path measures a distance to the single target, we will find that the
measured distance follows a parabola. This follows directly from the Pythagorean
theorem. The SAR imaging problem is finding out the target position from the
measured distance data. Of course in a real scene we have multiple targets and
the solution isn't as simple as looking where the closest approach is as could
be done in the picture above.</p>

<p>There are few different algorithms for solving this problem, but the one I'm
going to use is called Omega-k algorithm. It is a fast imaging algorithm
utilizing FFT which also makes it efficient to calculate on GPU. The derivation
mostly follows <a href="https://ieeexplore.ieee.org/document/7878107">a paper by Guo and
Dong</a>.</p>
<p>The radar I have is a frequency modulated constant wave (FMCW) radar. It
transmits a short frequency sweep. The transmitted waveform can be modeled as: </p>
<p>$$ s_t(\tau) = \exp(j 2 \pi f_c \tau + \pi \gamma \tau^2),\quad -T_s/2 &lt; \tau &lt; T_s/2 $$</p>
<p>, where <span>\(j&nbsp;= \sqrt{-1}\)</span>, <span>\(f_c =\)</span> RF carrier frequency, <span>\(\tau =\)</span> time variable,
<span>\(\gamma = B/T_s =\)</span> sweep bandwidth / sweep length <span>\(=\)</span> sweep rate.</p>
<p>The transmitted wave reflects off a target at some distance and is received after
time <span>\(t_d\)</span>. Ignoring the amplitude, the received wave is a time-delayed copy
of the transmitted signal: <span>\(s_r(\tau) = s_t(\tau - t_d)\)</span>. Signals from multiple
targets are summed.</p>
<p>The receiver mixes the received signal with the transmitted signal. This mixing
is called dechirping and it removes the high frequency RF component. The result
is a low frequency signal, usually some few kHz to MHz and is easy to digitize
with low-cost ADC. With the complex signals we take complex conjugate of the
transmitted signal to get the low-pass product and the resulting mixing product is:</p>
<p>$$ s_{\text{IF}}(\tau) = s_t(\tau - t_d) s_t^*(\tau) = \exp(-j 2 \pi f_c t_d
- j 2 \pi \gamma t_d \tau + j \pi \gamma \tau^2) $$</p>
<p>During SAR measurement the radar repeats this measurement while moving on
a straight path with a constant speed. The position of the radar on the path is:
<span>\(x = v \tau + x_n\)</span>, where <span>\(v\)</span> is speed of the radar platform and <span>\(x_n
= v n T_p\)</span>. <span>\(n\)</span> is the index for measurements and <span>\(T_p\)</span> is the transmit
repetition interval.</p>
<p>If the radar target is at position <span>\((x_0, y_0)\)</span> the distance to the target can
be written as:</p>
<p>$$ R(x) = \sqrt{y_0^2 + (x_0 - x)^2}&nbsp;$$</p>
<p>We set the y-coordinate of the path to be 0 and x position is limited to <span>\(-L/2
&lt; x &lt; L/2\)</span>, where <span>\(L\)</span> is length of the path.</p>
<p>Since electromagnetic waves travel at the speed of light and radar signal needs
to travel to the target and back to the radar, we get expression
for received signal time delay <span>\(t_d = 2R(x)/c\)</span>, where <span>\(c\)</span> is the speed of light.</p>
<p>The recorded signal can be written as:</p>
<p>$$ s_{\text{IF}}(\tau, x) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) R(x)\right)
\exp\left(j \frac{4 \pi \gamma^2}{c^2} R^2(x)\right) $$</p>
<p>The last term in the above expression is called residual video phase term and
it's an undesirable by-product from dechirping operation. It should be removed
before further processing by multiplying by <span>\(\exp(-j \frac{4 \pi \gamma^2}{c^2}
R^2(x))\)</span>.  However this form is inconvenient because it depends on <span>\(R(x)\)</span>. Using
the fact that <span>\(R(x) = c t_d / 2\)</span> and that <span>\(t_d\)</span> can be expressed in terms of
frequency of the IF signal: <span>\(f = -2 \gamma R(x) / c = -\gamma t_d \Rightarrow
t_d = -\frac{f}{\gamma}\)</span> we can write the correction term as <span>\(\exp(-j \pi f^2
/ \gamma)\)</span>. This form can be applied easily to the Fourier transformed signal.</p>
<p>With RVP term removed the signal is:</p>
<p>$$ s(\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + \gamma \tau) \sqrt{y_0^2 + (x_n - x_0 + v \tau)^2}\right) $$</p>
<p>Ideally we would like to have the signal in form <span>\(\exp(-j 2 \pi f_y y_0)\exp(-j
2\pi f_x x_0)\)</span>, then we could apply two dimensional inverse Fourier transform to
get a delta function centered at <span>\((x_0, y_0)\)</span> focusing the image. Currently the
signal <span>\(s(\tau, x_n)\)</span> is not in this form and inverse Fourier transform doesn't
give anything interesting. We need to find some processing steps to apply to the
signal to get it to the required form so that inverse Fourier transform can be
applied. The reason to look specifically for this kind of form is that FFT can
be performed very efficiently.</p>
<p>As a first step, note that <span>\(\gamma\)</span> has units of Hz/s and <span>\(\tau\)</span> has units of s.
The product <span>\(\gamma \tau\)</span> has units of Hz so it's a frequency. This product is actually
instantenous modulation frequency of the sweep. We do substitution <span>\(\gamma
\tau \rightarrow f_\tau\)</span> to get rid of the time variable. <span>\(\tau\)</span> range was <span>\(-T/2
\ldots T/2\)</span> and the new range for <span>\(f_\tau\)</span> is <span>\(-B/2 \ldots B/2\)</span>.</p>
<p>$$ S(f_\tau, x_n) = \exp\left(-j \frac{4 \pi}{c} (f_c + f_\tau) \sqrt{y_0^2 + (x_n - x_0 + \frac{v f_\tau}{\gamma} )^2}\right) $$</p>
<p>Also instead of using frequency the math is cleaner and the implementation of
the algorithm is easier when using wavenumbers instead. We define range
wavenumber <span>\(K_r = K_{rc} + \Delta K_r\)</span>. <span>\(K_{rc} = \frac{4\pi f_c}{c}\)</span>, <span>\(\Delta
K_r = \frac{4\pi f_\tau}{c} = -\frac{2\pi B}{c} \ldots \frac{2\pi B}{c}\)</span>.</p>
<p>$$ S(K_r, x_n) = \exp\left(-j K_r \sqrt{y_0^2 + (x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} )^2}\right) $$</p>
<p>Next step is to do Fourier transform in azimuth direction (direction of the
movement) to move also the <span>\(x_n\)</span> variable to frequency domain.</p>
<p>$$ S(K_r, K_x) = \int_{-\infty}^\infty S(K_r, x_n) \exp(-j K_x x_n)\, dx_n  = \int_{-\infty}^\infty \exp(j\Phi(x_n))\, dx_n $$</p>
<p><span>\(K_x = 2\pi f_x\)</span> is wavenumber in the azimuth direction. This integral doesn't have
exact solution, but there is a method to calculate quite accurate approximation
using a method called principle of stationary phase (PSOP). Phase of the
function being integrated can be written as:</p>
<p>$$ \Phi(x_n) = -K_r \sqrt{y_0^2 + \left(x_n - x_0 + \frac{v c \Delta K_r}{4 \pi \gamma} \right)^2} - K_x x_n $$</p>
<p>If we plot the phase <span>\(\Phi(x_n)\)</span> for some realistic values we get a plot that
looks something like below:</p>
<div id="centered">
    <p><img src="https://hforsten.com/img/fmcw3-sar/xphi_plot.png.pagespeed.ic.0z1VF8YpRH.png" width="40%/"></p><p>Phase and real part of the function being
    integrated.</p>
</div>

<p>There is one point where derivative of the phase is zero (stationary point) and
the function varies slowly, but away from that point the function is highly
oscillatory. As we integrate the function the oscillations far away from the
stationary point cancel out and mainly the area around the stationary point
contributes to the result of the integral.</p>
<p>We can expand the function around the stationary point <span>\(\frac{d}{dx_n}\Phi(x_n) \rvert_{x_n=x_n^\star} = 0\)</span>, as
<span>\(\Phi(x_n) = \Phi(x_n^\star) + 0 + \frac{1}{2}\Phi^{''}(x_n - x_n^\star)^2\)</span>.</p>
<p>Plugging the Taylor expansion in to the integral we get:</p>
<p>$$ \begin{aligned}S(K_r, K_x) &amp;\approx \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)(x_n-x_n^\star)^2\right)\, d x_n \\
&amp;= \exp(j\Phi(x_n^\star)) \int_{-\infty}^\infty \exp\left(j\frac{1}{2}\Phi^{''}(x_n^\star)s^2\right)\, d s \\
&amp;= \exp(j\Phi(x_n^\star)) \sqrt{\frac{2\pi j}{\Phi^{''}(x_n^\star)}} \end{aligned}
$$</p>
<p>Since <span>\(\Phi(x_n)\)</span> is purely real function, if <span>\(\mu\)</span> is sign of the
<span>\(\Phi(x_n^\star)\)</span>, then the square root term can be written as
<span>\(\sqrt{\frac{2\pi}{|\Phi^{''}(x_n^\star)|}} exp(j\pi \mu/4)\)</span>. The second
derivative contributes amplitude term and constant phase term, neither of them
which is important for focusing image which mainly depends on aligning the
phases. We have ignored the amplitude since beginning and it ends up being slowly
varying function so we will just approximate it away.</p>
<p>The stationary point of the function <span>\(\frac{d}{dx_n}\Phi(x_n)
\rvert_{x_n=x_n^\star} = 0\)</span> can be solved to be:</p>
<p>$$ x_n^\star = x_0 - \frac{K_x y_0}{\sqrt{K_r^2 - K_x^2}} - \frac{c \Delta K_r
v}{4\pi\gamma} $$</p>
<p>Plugging in the stationary point to the <span>\(S(K_r, K_x)\)</span> equation above we get the
solution of the integral:</p>
<p>$$ S(K_r, K_x) \approx \exp\left(j(-y_0 \sqrt{K_r^2 - K_x^2} - K_x x_0 + \frac{c \Delta K_r K_x
v}{4\pi\gamma})\right) $$</p>
<p>The last term is phase offset caused by the movement of the radar during the
sweep. It can be removed by multiplying with exponential in the opposite phase.</p>
<p><span>\(x_0\)</span> term is already in the correct form as it is multiplied only by <span>\(K_x\)</span>, but
<span>\(y_0\)</span> term depends on both <span>\(K_r\)</span> and <span>\(K_x\)</span>. <span>\(K_r, K_x\)</span> dependence can be fixed
by making a substitution <span>\(\sqrt{K_r^2 - K_x^2} \rightarrow K_y\)</span>. This step is
called Stolt interpolation as it is implemented by interpolating the data to
a new grid.</p>
<p>After the Stolt interpolation the signal is in form:</p>
<p>$$ S(K_y, K_x) = \exp(j(-K_y y_0 - K_x x_0)) $$</p>
<p>Taking 2D inverse Fourier transform gives the focused image with delta function
centered at <span>\((x_0, y_0)\)</span>.</p>

<p>The Omega-k algorithm is mainly large FFTs and interpolation. Both can be
implemented well on GPU which requires large parallelism from the program. Well
written GPU implementation should be several times faster than CPU
implementation. For convenience I'll implement the algorithm using Tensorflow
library. Although it's ‚Ä¶</p></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hforsten.com/synthetic-aperture-radar-imaging.html">https://hforsten.com/synthetic-aperture-radar-imaging.html</a></em></p>]]>
            </description>
            <link>https://hforsten.com/synthetic-aperture-radar-imaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189860</guid>
            <pubDate>Mon, 23 Nov 2020 18:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Exclusive Wi-Fi Router Contains Backdoor to Control Devices]]>
            </title>
            <description>
<![CDATA[
Score 281 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25189673">thread link</a>) | @wikus
<br/>
November 23, 2020 | https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/ | <a href="https://web.archive.org/web/*/https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1238">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h4>A Walmart-exclusive Wi-Fi router, and others sold on Amazon &amp; eBay contain hidden backdoors to control devices <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">reports CyberNews</a>.</h4>
<ul>
<li>Researchers discovered that many low cost, Chinese-made Wi-Fi routers contain a hidden backdoor which is being actively exploited to create botnet attacks.</li>
</ul>
<p>CyberNews researchers discovered suspicious backdoors in a Chinese made router sold under the name ‚ÄòJetstream‚Äô. This router is part of Walmart‚Äôs new line of affordable Wi-Fi routers.</p>
<blockquote><p>This backdoor would allow an attacker the ability to remotely control not only the routers, but also any devices connected to that network.</p></blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg" alt="" width="800" height="532" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-300x199.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-768x511.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-272x182.jpg 272w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232.jpg 1280w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>The researchers contacted Walmart to get a statement, and a Walmart spokesperson had this to say:</p>
<blockquote><p>‚ÄúThank you for bringing this to our attention. We are looking into the issue to learn more. The item in question is currently out of stock and we do not have plans to replenish it.‚Äù</p></blockquote>
<p>CyberNews researchers also discovered that ‚ÄòWavlink‚Äô branded routers, often sold on Amazon or eBay, <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">contain similar backdoors</a>.</p>
<p>Worryingly, they also discovered that these <strong>backdoors are being actively exploited</strong>, and there have been attempts to add the routers to a botnet with malware that allows them to be used in large scale DDoS attacks, which have <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">in the past taken down major websites</a> such as Reddit, Netflix, CNN, GitHub, Twitter, AirBnb and more.</p>
<h4><strong>Read more of the <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">full report on CyberNews</a>.</strong></h4>
<p><strong><a href="https://james-clee.com/2020/04/18/multiple-wavlink-vulnerabilities/" target="_blank" rel="noopener noreferrer">James Clee‚Äôs Report</a> on ‚ÄòWavlink‚Äô routers‚Äô backdoors.<br>
</strong></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189673</guid>
            <pubDate>Mon, 23 Nov 2020 18:10:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selling to unicorns from my parents basement]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25188716">thread link</a>) | @timjones
<br/>
November 23, 2020 | https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents | <a href="https://web.archive.org/web/*/https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>‚öîÔ∏è David selling to Goliath</h2><p><strong>Me</strong> - a <a href="https://www.themvpsprint.com/about">bootstrapped solopreneur</a> with a laptop and a dream.</p><p><strong>Them</strong> - a billion dollar unicorn with 10,000+ employees.</p><h4><strong>Will I really be able to sell into their corporate web of bureaucracy?</strong></h4><h2>üí∏ From idea to revenue</h2><p><em><a href="https://www.themvpsprint.com/about">I‚Äôm a solo, bootstrapped founder</a></em> building a SaaS startup in public.</p><p>Over the last 4 weeks, I‚Äôve <a href="https://mvpsprint.substack.com/p/choose-a-problem">chosen a problem to solve</a>, <a href="https://mvpsprint.substack.com/p/step-2-even-unicorns-walk-before-they-run">picked a niche</a>, <a href="https://www.themvpsprint.com/p/step-3-seeking-validation">validated my problem</a>, and <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">created a top-of-the-funnel distribution strategy</a>.</p><p>This week I create a strategy for selling <a href="https://www.hellohailey.io/">HelloHailey</a> into companies of all sizes - from small startups to billion dollar unicorns.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png&quot;,&quot;height&quot;:2774,&quot;width&quot;:971,&quot;resizeWidth&quot;:368,&quot;bytes&quot;:277261,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I‚Äôm sharing all my product decisions, metrics, successes, and failures in public.</p><p><strong>Next Monday, I‚Äôll (finally) describe the product I‚Äôm building.</strong> Want to read it in your inbox?</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Get my real-time case study&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Get my real-time case study</span></a></p><h2>üöÄ Land and expand</h2><p>The traditional SaaS sales process follows a <strong>top-down approach</strong>. A sales rep targets a high-level decision maker for a high-priced deal.</p><p>After a long sales process, a company slowly integrates a piece of software. <strong>The command comes from high in the org chart and makes its way down.</strong></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png&quot;,&quot;height&quot;:1190,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:303429,&quot;alt&quot;:&quot;Top-down sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="Top-down sales strategy"></a><figcaption>A top-down sales approach targets the top of the org chart.</figcaption></figure></div><h3><strong>But I‚Äôll be selling bottom-up</strong> </h3><p><strong>I‚Äôll scale the corporate walls via product managers (PMs) and engineering managers (EMs)</strong>. </p><p>I‚Äôll look unintimidating - a low price product that eats up a small chunk of a budget these team leads control.</p><p><strong>Then I‚Äôll spread through the company like wildfire </strong>via growth mechanisms built into the product.</p><p>One team will adopt me.</p><p>Then two.</p><p>Then the entire department. </p><p>Then the entire company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png&quot;,&quot;height&quot;:2128,&quot;width&quot;:1456,&quot;resizeWidth&quot;:546,&quot;bytes&quot;:348487,&quot;alt&quot;:&quot;\&quot;Land and Expand\&quot; sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="&quot;Land and Expand&quot; sales strategy"></a><figcaption>A ‚ÄúLand and Expand‚Äù strategy starts at the bottom of the org chart; then expands via growth mechanisms built into the product.</figcaption></figure></div><p>I know what you‚Äôre thinking - <em>all this sounds great on paper. But how are you so confident it will work?</em></p><p><strong>I‚Äôm not </strong>üò≥</p><p><strong>Honestly, I don‚Äôt even know if I‚Äôll be able to ‚Äúland‚Äù, much less expand</strong>.</p><h3>It‚Äôs time to test out my landing gear</h3><p>‚Ä¶so I don‚Äôt build a product that crashes and burns on the runway.</p><p><strong>In <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">last week‚Äôs article</a>, I outlined my top-of-the-funnel strategy</strong> - how to get PM and EM eyeballs on <a href="https://www.hellohailey.io/">HelloHailey</a>.</p><p><strong>This week I‚Äôm focusing on the bottom of the funnel</strong> - converting those eyeballs into paid users.</p><p><strong>Here‚Äôs what that funnel looks like for a PM or EM:</strong></p><ol><li><p><strong>Discover</strong> through top-of-the-funnel distribution channels.</p></li><li><p><strong>Try for free</strong> with their team.</p></li><li><p><strong>Get value - </strong>signaled by high engagement and retention.</p></li><li><p><strong>Convert to paid tier</strong> - to unlock premium features or exceed maximum number of seats (users) in free tier.</p></li><li><p><strong>Expand </strong>- add more seats within their company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png&quot;,&quot;height&quot;:1760,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308211,&quot;alt&quot;:&quot;HelloHailey user acquisition funnel&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="HelloHailey user acquisition funnel"></a><figcaption>HelloHailey user acquisition funnel</figcaption></figure></div></li></ol><h4><strong>My go-to-market strategy fails if I can‚Äôt convert free users into paid users.</strong></h4><p>But I know very little about B2B purchasing processes for low-ticket ($25-$50 / month) SaaS products:</p><ol><li><p><em>Will users have to fight tooth and nail for approval?</em></p></li><li><p><em>Who has a company credit card?</em></p></li><li><p><em>What budget will the money come from?</em></p></li></ol><p>To avoid this suc-SaaS story turning into a dis-SaaS-ter (üôÑ sorry, couldn‚Äôt resist), <strong>I‚Äôm going to invest a few days now into understanding what the purchasing process will look like.</strong></p><h2>üí∞ How low-ticket SaaS products get purchased</h2><p>I probed into my network of EMs and PMs for answers. </p><p><em>Big shoutout to all those who helped me! </em>üôè</p><p>It turns out that my fears of a long chain of approvals with stringent criteria were unfounded.</p><h3><strong>The approval and purchase process is just two steps:</strong></h3><h4>1. Ask a manager</h4><p>Approval is loose and informal. PMs and EMs briefly mention it to their managers over email or their regular check-in.</p><p>Managers won‚Äôt require much justification for approval. Why? Its an immaterial amount of money and they trust their employees‚Äô judgment.</p><h4>2. Find a credit card</h4><p>With very few exceptions, PMs and EMs (at the levels I‚Äôm targeting) don‚Äôt have company credit cards. So how do they pay after getting approval?</p><h5>Pay with personal credit card</h5><p>This is a common practice for team meals, social events, and one-off software purchases. A senior team member will pay with a personal card and file an expense report.</p><p>But people are more hesitant to pay for a <em><strong>recurring</strong></em> team subscription with a personal card.</p><h5>Find a company credit card</h5><p>This varies from company to company, but the most common places people go are:</p><ol><li><p><strong>Finance</strong> (manages budgets)</p></li><li><p><strong>IT</strong> (manages access to company subscriptions)</p></li><li><p><strong>Lowest person above them in the org chart with a company card</strong> (usually a Director or VP, depending on company size)</p></li></ol><h2>üòÅ Why my strategy will work</h2><h5>‚úÖ  Loose approval process</h5><p>I mentioned this before, but it‚Äôs worth restating. <strong>This means that the PM or EM using <a href="https://www.hellohailey.io/">HelloHailey</a> is the primary decision maker.</strong></p><p>No bureaucracy. No long, complex sales cycles.</p><p><strong>I just need to build a great product.</strong></p><h5>‚úÖ  Fits into an existing budget</h5><p>It‚Äôs my hypothesis that teams will pay for HelloHailey using their team ‚Äúsocial‚Äù budgets. These budgets cover expenses like meals, games, or team events.</p><h5>‚úÖ  Takes a small percentage of that budget</h5><p>Team social budgets range from $10-$100 / person / month, with a median somewhere in the middle.</p><p>With a price of $2-$3 / person / month, HelloHailey would eat up only 5% of that budget on average.</p><h5>‚úÖ  Social budgets have been underutilized with sudden shift to remote work</h5><p>Half the people I talked to haven‚Äôt used their social budgets at all since being forced into remote work.</p><p>Most of the other half has used it sparingly for virtual team events.</p><h2>üò¢ Why it might not work</h2><p>Until companies <em>actually</em> start paying me, my strategy will be full of uncertainty.</p><p>Here are some ways it might fail:</p><h5>üí©  Doesn‚Äôt fit into an existing budget</h5><p>Maybe companies don‚Äôt think it‚Äôs appropriate to pull from team social budgets for this kind of purchase.</p><p>If it doesn‚Äôt fit nicely into <em>any</em> existing category, it‚Äôll be much harder for companies to buy it.</p><h5>üí©  Hard to budget for a product with expanding price</h5><p><a href="https://www.hellohailey.io/">HelloHailey</a> will get more expensive as more users and teams are added within a company. </p><h5>üí©  <strong>What happens when a product purchased with Team A‚Äôs social budget adds users from Team B and gets more expensive? </strong></h5><p>I don‚Äôt know ü§∑‚Äç‚ôÇÔ∏è (<em>Do you? <a href="https://twitter.com/AnotherTimJones">Share your wisdom and help me out</a> </em>üôÇ ).</p><p>But I‚Äôm not the first person to face this problem. There are precedents in place and I‚Äôm confident I‚Äôll figure it out.</p><h5>üí©  Approval process is more difficult than expected</h5><p>The people I interviewed could be outliers. Maybe a typical manager requires more convincing to approve this kind of purchase.</p><h2>What about expanding?</h2><p>I now feel confident about landing. <strong>So how will I expand?</strong></p><p>I have some ideas for how I can build growth mechanisms into a product like this.</p><p>But if I‚Äôm being honest, I‚Äôm not sure yet ü§∑‚Äç‚ôÇÔ∏è. And I‚Äôm OK with that.</p><p><strong>With a successful ‚Äúland‚Äù strategy, and low to moderate expansion revenue, I can build a great business.</strong></p><p>Intra-company virality would be a must if I wanted to become a VC-backed rocket ship.</p><p><strong>But that‚Äôs not my goal.</strong></p><p><strong>I want to build a small, profitable company that solves a problem I‚Äôm passionate about.</strong></p><p>I can sell to unicorns. But I don‚Äôt want to <em>become</em> one.</p><h2>What did I get wrong?</h2><p>I learned a lot this week, but I‚Äôve never done this before. </p><p><strong>Do you have SaaS sales experience?</strong></p><p>Don‚Äôt pull your punches! Help me out on my Twitter thread:</p><p>Don‚Äôt have any tips for me? <strong>Maybe you could help me out with a like or a retweet.</strong></p><p><strong>As a solopreneur with no funding or income, I‚Äôll take all the help I can get üòÅ</strong></p><h2>ü§î Reducing uncertainty one week at a time</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/cac3da08-e921-4064-b421-eebf46ef563b_920x248.png&quot;,&quot;height&quot;:248,&quot;width&quot;:920,&quot;resizeWidth&quot;:490,&quot;bytes&quot;:29061,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png&quot;,&quot;height&quot;:184,&quot;width&quot;:478,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I‚Äôm finally feeling confident about my go-to-market strategy. Now it‚Äôs time to define the product I‚Äôll be going to market with‚Ä¶</p><p><strong>Over the next two weeks, I‚Äôll define my product vision and finalize requirements for an MVP (minimum viable product).</strong></p><p><strong>Curious to find out what I‚Äôll be building?</strong> </p><p>I‚Äôll tell you next Monday:</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Send me next week's update&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Send me next week's update</span></a></p><p><em>I‚Äôll be documenting my startup journey from idea to paying users over the coming weeks and months. I‚Äôd love to have you along for the ride.</em></p><p><em>Icons made by&nbsp;<a href="https://www.freepik.com/">Freepik</a>,&nbsp;<a href="https://www.flaticon.com/authors/icongeek26">Icongeek26</a>, and&nbsp;<a href="https://www.flaticon.com/authors/pixel-perfect">Pixel perfect</a>&nbsp;from&nbsp;<a href="https://www.flaticon.com/">Flaticon</a></em></p></div></div>]]>
            </description>
            <link>https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188716</guid>
            <pubDate>Mon, 23 Nov 2020 16:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Small Games]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25188542">thread link</a>) | @polm23
<br/>
November 23, 2020 | https://lorenzo.itch.io/on-small-games | <a href="https://web.archive.org/web/*/https://lorenzo.itch.io/on-small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>I wanted to write a Small Games Manifesto for the Manifesto Jam, but I&nbsp;was too tired, so I collected&nbsp;other people's thoughts about small games instead.</em></p>

<p><em>See also: <a href="http://ebeth.itch.io/small-games-manifesto" target="_blank">Small Games Manifesto</a> by Ebeth.</em><br></p>

<p><em>Looking for some small games to play? Check out my <a href="https://itch.io/c/6160/small-is-beautiful" target="_blank">Small is Beautiful</a> and&nbsp;<a href="https://itch.io/c/232207/bitsy-faves-pt2-20192020" target="_blank">Bitsy Faves</a>&nbsp;collections.</em></p>

<p><em>Follow me on Twitter <a href="https://twitter.com/LorenzoPilia" target="_blank" rel="nofollow noopener">@LorenzoPilia</a></em></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</p>

<p>Make short and intense games:<br>think haiku, not epic.<br>Think poetry, not prose.<br><strong>‚Äî Auriea Harvey &amp; Micha√´l Samyn: Realtime Art Manifesto</strong><br><a href="http://tale-of-tales.com/tales/RAM.html" rel="nofollow noopener">http://tale-of-tales.com/tales/RAM.html</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>things i will never do in this lifetime:&nbsp;<br>play a game for a few straight hours<br>play a game with more than a few hours worth of content<br><strong>‚Äî @moshboy</strong><br><a href="https://twitter.com/moshboy/status/607408540496465922" rel="nofollow noopener">https://twitter.com/moshboy/status/607408540496465922</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Hell, you'd be surprised at how many people buy games with a moderate length and never finish them. On PC over 50 percent of the people who bought the latest Wolfenstein, a game you can beat in under 15 hours, never earned the achievement for finishing the story. Only 31 percent of Dishonored players on the PC beat the game. People think game length is mandatory, but even shorter games aren't finished by the majority of players.
<br><strong>‚Äî Ben Kuchera: To hell with longer games, tell me how SHORT your game is</strong><br><a href="https://www.polygon.com/2014/10/14/6974791/short-games-review" rel="nofollow noopener">https://www.polygon.com/2014/10/14/6974791/short-games-review</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Especially if you're starting out, try to do small projects and don't worry too much about polishing them, don't worry about shipping the perfect game, embrace the messiness of getting into games for the first time, embrace not knowing what you're doing exactly yet. (...) If you just put your heart into it in that way, and embrace the messiness of small games, people will really connect with that.<br><strong>‚Äî Nina Freeman: Keynote at A MAZE. / Johannesburg 2017<br></strong><a href="https://twitter.com/AMazeFest/status/908032352953217038" rel="nofollow noopener">https://twitter.com/AMazeFest/status/908032352953217038</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Duration doesn't need to be a burden. It can be a tool to wield.<br><strong>‚Äî Thomas McMullan: Inside and the rise of short games</strong><br><a href="http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games" rel="nofollow noopener">http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small-scale works are often derided for feeling embryonic or unfinished, throwaway motifs or fledgling ideas that the artist failed to integrate into a sufficiently ambitious whole. Game designer Jake Elliott, who drew the title of his Ruins from Schumann‚Äôs appraisal of Chopin‚Äôs preludes, defended their proportion in an interview: ‚ÄúMaybe [Chopin] felt like they were complete objects, but there wasn‚Äôt a vocabulary for talking about pieces of music that were short at the time. Their length is what drew me ‚Ä¶ there is a lot that‚Äôs unspoken.‚Äù Having conventionally privileged length, magnitude, and formal unity, games too have left critics bereft of a clear rubric for evaluating intentionally abbreviated, serialized, even disorderly exercises in interactive design.<br><strong>‚Äî Peter Lido: Undertale, one year later</strong><br><a href="https://killscreen.com/articles/undertale-one-year-later/" rel="nofollow noopener">https://killscreen.com/articles/undertale-one-year-later/</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>The final idea that we brought over as gamers, the final idea that we had to let go of, was that a longer game makes a better game. We felt that the sense of completion and catharsis that you get when you watch our ending was so critical to the experience, that we decided that we had to help as many people as possible to complete Monument Valley. And that was more important than making the game longer or more difficult.<br><strong>‚Äî Ken Wong: Games Without Gamers (#DICE2014 Europe)</strong><br><a href="http://youtu.be/YdSClYHDow0?t=13m37s" rel="nofollow noopener">https://youtu.be/YdSClYHDow0?t=13m37s</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>I value games being short, it makes them easier to fit into life, they get to the point sooner, it's possible to play them more times, trying out different possibilities, there's a clearer connection between decisions and outcome.<br><strong>‚Äî Michael Brough: imbroglio notes 6 - meditation</strong><br><a href="http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1" rel="nofollow noopener">http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small games must be protected from their own defenders!! They must be defended against a rhetoric of convenience, as if fitting helpfully into the meagre free time allotted us by rentiers was something to be proud of rather than something to grind against - they must be defended against the meagre virtues of "minimalism", parsimony, elegance, the values of those with enough cultural cachet that they can afford to speak softly, and which hold the same relation to an actual human economy of wants and needs as does a millionaire who doesn't tip.<br><strong>‚Äî thecathamites: Small Game Manifesto (part of&nbsp;Buttertown, 10 manifestos for groups of no people)</strong><br><a href="https://thecatamites.itch.io/buttertown">https://thecatamites.itch.io/buttertown</a></p>


</div></div>]]>
            </description>
            <link>https://lorenzo.itch.io/on-small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188542</guid>
            <pubDate>Mon, 23 Nov 2020 16:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Firecracker on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25187965">thread link</a>) | @sairamkunala
<br/>
November 23, 2020 | https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="abstract">Abstract</h2><p>Traditionally services were deployed on bare metal and in the last decades we have seen the rise of virtualisation (running additional operating systems in a operating system process) and lately containerisation (running an operating system process in a separate security context from the rest of processes on the same host). Virtualisation and containerisation offers different levels of isolation by moving some operating system functionality to the guest systems.</p><p>The following chart illustrates that pretty well:</p><p><img src="https://dev.l1x.be/img/isolation.png" alt="OS functionality location"></p><p>Source: <a href="https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf">https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf</a></p><p>In this article, I perform a deep dive into Firecracker and how it can be used for deploying services on Raspberry Pi (4B).</p><h2 id="getting-started">Getting started</h2><p>There are few paths to take here. First I am going to try the easy one, using Ubuntu. Later on we can investigate the use of Alpine Linux which is much more lightweight than Ubuntu, ideal for devices like RPI.</p><h3 id="installing-the-image-on-a-microsd-card">Installing the image on a microSD card</h3><p>We need a 64 bit Ubuntu image and a microsd card. For the imaging I use <a href="https://www.balena.io/etcher/">Balena Etcher</a> that makes the imaging process super easy.</p><p>Getting the pre-installed image:</p><div><pre><code data-lang="bash">wget https://cdimage.ubuntu.com/releases/20.04/release/<span>\
</span><span></span>ubuntu-20.04.1-preinstalled-server-arm64+raspi.img.xz
</code></pre></div><p>Preinstalled means that we get a fully working operating system and there is no need for additional installation steps after booting up. With Balena Etcher it is super easy to write the compressed image file to the sd card and boot the system up once ready. SSHD starts up after the installation and we can log in via ssh if we know the IP address that the DHCP server issues to our device (assuming DHCP server is present in our LAN).</p><p>There are few mildly annoying things with Ubuntu (snaps, unattended-upgrades) that I usually remove. I also prefer to use Chrony over the systemd equivalent. Ansible repo for these is available here: <a href="https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml">https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml</a></p><h3 id="installing-firecracker-jailer-and-firectl">Installing Firecracker, Jailer and Firectl</h3><ul><li>Firecracker: The main component, it is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs.</li><li>Jailer: For starting Firecracker in production mode, applies a cgroup/namespace isolation barrier and then drops privileges. There</li><li>Firectl: A command line utility for convenience</li></ul><h4 id="getting-firecracker-and-jailer">Getting Firecracker and Jailer</h4><p>For the first two it is possible to download the release binaries from Github.</p><div><pre><code data-lang="bash"><span>version</span><span>=</span><span>'v0.23.0'</span>

wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/firecracker-<span>${</span><span>version</span><span>}</span>-aarch64
wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/jailer-<span>${</span><span>version</span><span>}</span>-aarch64

mv firecracker-<span>${</span><span>version</span><span>}</span>-aarch64 firecracker
mv jailer-<span>${</span><span>version</span><span>}</span>-aarch64 jailer

chmod +x firecracker jailer

./firecracker --help
./jailer --help
</code></pre></div><h4 id="firectl">Firectl</h4><p>Firectl is a bit trickier to install because there is no release binary and it requires Golang 1.14 to compile. We can do these in two steps.</p><div><pre><code data-lang="bash">wget https://golang.org/dl/go1.14.12.linux-arm64.tar.gz
tar xzvf go1.14.12.linux-arm64.tar.gz
</code></pre></div><p>After getting go we can get the source of firectl and compile it:</p><div><pre><code data-lang="bash">git clone https://github.com/firecracker-microvm/firectl.git
<span>cd</span> firectl/
 ~/go/bin/go build -x
</code></pre></div><p>Testing Firectl:</p><p>We have all the tools we need for running our first microVM the only thing is missing: something to run.</p><h3 id="downloading-our-first-image">Downloading our first image</h3><p>For a microVM there are two things necessary to have:</p><ul><li>an uncompressed linux kernel (vmlinux)</li><li>a filesystem</li></ul><p>Later on we are going to investigate how we could create our own version of these, but for now we are going to use images from</p><div><pre><code data-lang="bash">wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/kernel/vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/fsfiles/xenial.rootfs.ext4
</code></pre></div><h3 id="configuring-network">Configuring network</h3><p>For the microVM to function properly we need a networking device. For this scenario we are going to use tap and create a device:</p><div><pre><code data-lang="bash">sudo ip tuntap add dev tap0 mode tap
sudo ip addr add 172.16.0.1/24 dev tap0
sudo ip link <span>set</span> tap0 up
ip addr show dev tap0
</code></pre></div><p>If we want to give access to our VM we have to enable IP forwarding:</p><div><pre><code data-lang="bash"><span>DEVICE_NAME</span><span>=</span>eth0
sudo sh -c <span>"echo 1 &gt; /proc/sys/net/ipv4/ip_forward"</span>
sudo iptables -t nat -A POSTROUTING -o <span>$DEVICE_NAME</span> -j MASQUERADE
sudo iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i tap0 -o <span>$DEVICE_NAME</span> -j ACCEPT
</code></pre></div><h3 id="running-our-first-microvm">Running our first microVM</h3><p>This is how we can start up our first microVM. I usually start it in screen so I can open a new session easily because it will use the standard input and output for the newly started of console (unless you redirect it).</p><p>This is for debug mode, starting with sudo:</p><div><pre><code data-lang="bash">sudo ./firectl/firectl <span>\
</span><span></span>--firecracker-binary<span>=</span>./firecracker <span>\
</span><span></span>--kernel<span>=</span>vmlinux.bin <span>\
</span><span></span>--tap-device<span>=</span>tap0/aa:fc:00:00:00:01 <span>\
</span><span></span>--kernel-opts<span>=</span><span>\
</span><span></span><span>"console=ttyS0 reboot=k panic=1 pci=off \
</span><span>ip=172.16.0.42::172.16.0.1:255.255.255.0::eth0:off"</span> <span>\
</span><span></span>--root-drive<span>=</span>./xenial.rootfs.ext4
</code></pre></div><p>If everything went well you can see something like this:</p><pre><code>Ubuntu 18.04.2 LTS fadfdd4af58a ttyS0

fadfdd4af58a login:
</code></pre><p>User and password is root:root.</p><h3 id="testing-networking">Testing networking</h3><p>For this we need to have a bit bigger image.</p><div><pre><code data-lang="bash">dd <span>if</span><span>=</span>/dev/zero <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>800</span> &gt;&gt; xenial.rootfs.ext4
resize2fs -f xenial.rootfs.ext4
</code></pre></div><p>After starting up the usual way and logging in we need to fix few things:</p><p>Adding some working nameserver:</p><div><pre><code data-lang="bash"><span>echo</span> <span>'nameserver 1.1.1.1'</span> &gt;  /etc/resolv.conf
</code></pre></div><p>Now trying to update:</p><div><pre><code data-lang="bash">root@fadfdd4af58a:~# apt update
Get:1 http://ports.ubuntu.com/ubuntu-ports bionic InRelease <span>[</span><span>242</span> kB<span>]</span>
Get:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease <span>[</span>88.7 kB<span>]</span>
Hit:3 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease
Hit:4 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease
Get:5 http://ports.ubuntu.com/ubuntu-ports bionic/universe arm64 Packages <span>[</span>11.0 MB<span>]</span>
Get:6 http://ports.ubuntu.com/ubuntu-ports bionic/multiverse arm64 Packages <span>[</span><span>153</span> kB<span>]</span>
Get:7 http://ports.ubuntu.com/ubuntu-ports bionic/main arm64 Packages <span>[</span><span>1285</span> kB<span>]</span>
Get:8 http://ports.ubuntu.com/ubuntu-ports bionic/restricted arm64 Packages <span>[</span><span>572</span> B<span>]</span>
Get:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/universe arm64 Packages <span>[</span><span>1865</span> kB<span>]</span>
Get:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/restricted arm64 Packages <span>[</span><span>2262</span> B<span>]</span>
Get:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 Packages <span>[</span><span>1431</span> kB<span>]</span>
Get:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/multiverse arm64 Packages <span>[</span><span>5758</span> B<span>]</span>
Fetched 16.1 MB in 6s <span>(</span><span>2543</span> kB/s<span>)</span>
Reading package lists... Error!
E: flAbsPath on /var/lib/dpkg/status failed - realpath <span>(</span>2: No such file or directory<span>)</span>
E: Could not open file  - open <span>(</span>2: No such file or directory<span>)</span>
E: Problem opening
E: The package lists or status file could not be parsed or opened.
</code></pre></div><p>Fixing the apt issues:</p><div><pre><code data-lang="bash">mkdir -p /var/lib/dpkg/<span>{</span>info,alternatives<span>}</span>
touch /var/lib/dpkg/status
apt install apt-utils -y
</code></pre></div><p>Enjoy!</p><p>Next time we can go through how to compile a new kernel and have a different rootfs (potentially using Alpine).</p></div></div>]]>
            </description>
            <link>https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187965</guid>
            <pubDate>Mon, 23 Nov 2020 15:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Somfy blinds automated via MQTT and Home Assistant]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25187945">thread link</a>) | @ggambetta
<br/>
November 23, 2020 | https://mwitkow.me/posts/2020-11-08_somfy/ | <a href="https://web.archive.org/web/*/https://mwitkow.me/posts/2020-11-08_somfy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post I‚Äôll show you how to use a Raspberry Pi and some soldering skills to automate old Somfy blinds via the MQTT protocol exposed to Home Assistant and Google Home.</p><p>We‚Äôve moved to a new apartment and one of its features are external blinds (a.k.a. covers) that are controlled through a dedicated remote of the Somfy brand. However, just like with a TV, finding the remote is often tricky, so I decided to try and automate the external blind movements through Home Assistant and further voice commands of Google Home.</p><p>The system in place is a Somfy‚Äôs Telis 4 RTS Pure remote, with two remotes, each being able to program 5 channels (4 individual ones and combined). The system uses a legacy, proprietary radio protocol called <a href="https://service.somfy.com/downloads/nam_v4/rts_pocket_guide_dec_2017.pdf">RTS</a>, which only Somfy and Telis use.</p><p>Somfy offers a RTS bridge called <a href="https://www.somfysystems.com/en-us/products/1811403/mylink">Somfy MyLink</a> for a wooping ~300CHF, which is a little steep for something that is not necessary and just scratching an itch. Also, there‚Äôs not much fun in that.</p><p>Turns out, <a href="https://github.com/Nickduino/">Nickduino</a> had a similar itch to scratch. Using 3-4 CHF-worth of hardware components, it is quite easy to build a software radio that will immitate a Somfy Telis remote and control the blinds.</p><p>There‚Äôs an bare-bones <a href="https://github.com/Nickduino/Somfy_Remote/blob/master/Somfy_Remote.ino">Somfy Remote Arduino sketch</a> that shows how the protocol works. I originally wanted make the blind controller as small as possible and base it on an <a href="https://en.wikipedia.org/wiki/ESP32">ESP32</a>, taking that sketch and controlling it via <a href="https://github.com/256dpi/arduino-mqtt">arduino-mqtt</a>.</p><p>Turns out there is a full MQTT/web interface script <a href="https://github.com/Nickduino/Pi-Somfy">Nickduino/Pi-Somfy</a> that also only goes into the details of how to solder things, and connect things onto a Raspberry Pi. Laziness won the day, especially as I wanted to use my spare Pi for something anyway.</p><h2 id="the-hardware">The hardware</h2><p>Usually for 433MHz signals you could easily use a ready-made module such us <a href="https://www.berrybase.ch/raspberry-pi-co/raspberry-pi/module-sensoren/433mhz-sender-empf-228-nger-superregeneration-modul-fs1000a-xy-fst-xy-mk-5v">this 2CHF sender-receiver pair</a>. However, in order for Somfy to make their RTS even more proprietary than it already was, it is not using the typical <code>433.93MHz</code> frequency but <code>433.42MHz</code> ü§¶‚Äç‚ôÇÔ∏è. This means one will need to do some soldering.</p><p>The PiSomfy <a href="https://github.com/Nickduino/Pi-Somfy#2-hardware">hardware guide</a> is excellent in telling you what you need. I got:</p><ul><li><a href="https://www.ebay.com/itm/5x-433Mhz-RF-transmitter-and-receiver-kit-Module-Arduino-ARM-WL-MCU-Raspberry-Fc-/254607185239?hash=item3b47c55557">5 ready <code>433.93MHz</code> sender circuits</a></li><li><a href="https://www.ebay.com/itm/10pcs-433-42m-433-42mhz-r433-f433-saw-resonator-crystals-to-39-/331637441887?hash=item4d3721c55f">10 pieces of the <code>433.42MHz</code> oscilator</a> - because my soldering is terrible</li><li><a href="https://www.ebay.com/itm/40PCS-20cm-2-54MM-FF-FM-MM-Dupont-wire-jumper-cables-male-to-female-For-Arduino/312724733910?hash=item48cfd8bfd6:g:05sAAOSwlbZdSZ6E">male-male jumper cables</a> - to avoid soldering üòâ</li><li>(already had it) a solid copper cable to use as an antenna</li></ul><p>After 4 weeks, all the eBay items were in place, and I could start soldering. Turns out de-soldering things off is much harder than soldering things on. I managed to peel away the original oscillator with by applying leverage underneath it using a swiss army knife and heating its connectors one by one. Soldering the new one was quite easy in comparison.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/soldering.jpg" alt="It&amp;rsquo;s not pretty but it worked." width="600"><figcaption><p>It‚Äôs not pretty but it worked.</p></figcaption></figure><p>I then took a 17cm piece of solid copper cable, and wrapped it into a small coil. Turns out soldering a think 1mm cable to a tiny connector was the trickiest bit, but with the right amount of patience, things will stick eventually.</p><p>Eventually, the fully connected sender fits nicely into a Raspberry Pi enclosure after connecting everything to the GPIO 4 pin:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/final_side_by_side.jpg" alt="All fits nicely into a standard Pi enclosure. The remote we&amp;rsquo;ll be replacing are on the left." width="700"><figcaption><p>All fits nicely into a standard Pi enclosure. The remote we‚Äôll be replacing are on the left.</p></figcaption></figure><h2 id="programming">Programming</h2><p>Installing Pi-Somfy is super easy, just follow <a href="https://github.com/Nickduino/Pi-Somfy#3-software">these steps</a>. It assume you install it under the default <code>pi</code> user in <code>/home/pi</code>, and comes with a handy <code>systemctl</code> service for auto-starting the system.</p><p>By default it will come up on port <code>:80</code> of your Pi. Programming the blinds takes a little bit of time. The procedure is as follows:</p><ul><li>Set the right channel (individual blind, or all) on the remote you‚Äôre programming from.</li><li>Measure the time in seconds it takes for each blind to come fully down.</li><li>Click <em>Add new</em> to put in the name (this will be your MQTT name by the way) and add in the time.</li><li>Using a pen, press the ‚Äúhole‚Äù on the other side of the remote. This sends the signal to the blind to accept programming a new remote.</li><li>Press <em>Save</em> and follow the instructions. The blind should ‚Äúwiggle‚Äù once programmed.</li></ul><p><strong>Note</strong>: The system relies on time to figure out where the blind is percentage-wise. It can often get things wrong (e.g. if you stopped it mid-through), or on the all-channel if blinds have different lengths (e.g. balcony). But in practice it works remarkably well.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/pi_remote.png" alt="Fully programmed blinds." width="700"><figcaption><p>Fully programmed blinds.</p></figcaption></figure><p><a href="https://en.wikipedia.org/wiki/MQTT">MQTT</a> is a standard protocol for message brokers, and finds a lot of use in home IoT. For most use cases, it has a simple publish-subscribe mechanic based on topics.</p><h2 id="installing-mosquitto">Installing Mosquitto</h2><p>Home Assistant has an embedded MQTT broker, but it is <em>highly advised</em> to use an external one, such as Mosquitto. You should install it on the same machine that runs Home Assistant, as it will act as a hub for other MQTT-connected services. To do that on Ubuntu:</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get install mosquitto mosquitto-clients
</code></pre></div><p>Now let‚Äôs set up a password file in <code>/etc/mosquitto/passwd</code> with a user for <code>homeassistant</code> and <code>pisomfy</code>.</p><pre><code>sudo mosquitto_passwd -c /etc/mosquitto/passwd homeassistant
Password: YourHomeAssistantPassword
sudo mosquitto_passwd -c /etc/mosquitto/passwd pisomfy
Password: YourPiSomfyPassword
</code></pre><p>Then, enforce use of passwords in mosquitto by editing <code>/etc/mosquitto/conf.d/default.conf</code> and changing it to:</p><pre><code>allow_anonymous false
password_file /etc/mosquitto/passwd
</code></pre><p>For debugging purposes, open a separate tab on the same machine and subscribe to all messages under the <code>home-assistant/#</code> topic via:</p><pre><code>mosquitto_sub -u homeassistant -P YourHomeAssistantPassword -p 1883 -h 127.0.0.1 -v -t "home-assistant/#"
</code></pre><p>This will come in handy to check things are working.</p><h2 id="configuring-home-assistant">Configuring Home Assistant</h2><p>Update your <code>/etc/homeassistant/configuration.yaml</code> to add:</p><div><pre><code data-lang="yaml"><span>mqtt</span><span>:</span><span>
</span><span>  </span><span>broker</span><span>:</span><span> </span><span>127.0.0.1</span><span>
</span><span>  </span><span>username</span><span>:</span><span> </span><span>homeassistant</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"YourHomeAssistantPassword"</span><span>
</span><span>  </span><span>discovery</span><span>:</span><span> </span><span>true</span><span>
</span></code></pre></div><p>Restart Home Assistant</p><pre><code>sudo systemctl restart homeassistant
</code></pre><h3 id="configure-pisomfy">Configure PiSomfy</h3><p>On your Pi machine, open <code>/home/pi/operateShutters.conf</code> and edit the `[MQTT] section to look as follows</p><div><pre><code data-lang="ini"><span>[MQTT]</span>
<span># Location (IP Address of DNS Name) of the MQTT Server</span>
<span>MQTT_Server</span> <span>=</span> <span>myHAmachine # or hostname of your home assistant machine</span>
<span># Port of the MQTT Server</span>
<span>MQTT_Port</span> <span>=</span> <span>1883</span>
<span># Username for the MQTT Server</span>
<span>MQTT_User</span> <span>=</span> <span>pisomfy</span>
<span># Password of the MQTT Server</span>
<span>MQTT_Password</span> <span>=</span> <span>YourPiSomfyPassword</span>
<span># Enable auto discovery</span>
<span>EnableDiscovery</span> <span>=</span> <span>true</span>
</code></pre></div><p>And restart the service:</p><pre><code>sudo systemctl restart shutters.conf`
</code></pre><p>At this point the tab with the subscriptions should be full of messages. These are auto-discovery messages over MQTT for each of the programmed covers. This will cause Home Assistant to automatically add the entities.</p><p>They should show up with the same names as in PiSomfy.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/home_assistant_entities.png" alt="Home Assistant Entities auto discovered via MQTT." width="800"><figcaption><p>Home Assistant Entities auto discovered via MQTT.</p></figcaption></figure><p>Adding them to a dashboard is relatively trivial, for example:</p><div><pre><code data-lang="yaml"><span>type</span><span>:</span><span> </span><span>entities</span><span>
</span><span></span><span>entities</span><span>:</span><span>
</span><span>  </span>- <span>entity</span><span>:</span><span> </span><span>cover.lr_all</span><span>
</span><span>    </span><span>name</span><span>:</span><span> </span><span>Living Room Covers</span><span>
</span></code></pre></div><p>In order to simplify things, I wanted to only expose the <code>_all</code> blinds (a.k.a. covers) to Google Home/Assistant. For that I added an explicit section in the <code>/etc/homeassistant/configuration.yaml</code> section of <code>google_assistant</code>:</p><div><pre><code data-lang="yaml"><span>google_assistant</span><span>:</span><span>
</span><span>  </span><span># ...</span><span>
</span><span>  </span><span>exposed_domains</span><span>:</span><span>
</span><span>    </span>- <span>fan</span><span>
</span><span>  </span><span>entity_config</span><span>:</span><span>
</span><span>    </span><span>cover.br_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Bedroom Covers"</span><span>
</span><span>    </span><span>cover.lr_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Living Room Covers"</span><span>
</span></code></pre></div><p>After restarting Home Assistant, and uttering the magical <em>Ok Google, Sync All Devices</em>, the covers will show up in your Home App:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/google_home.jpg" alt="Looks like a blind, acts as a blind." width="300"><figcaption><p>Looks like a blind, acts as a blind.</p></figcaption></figure><p>This means you can controll it using keywords:</p><ul><li><em>Ok Google, close Bedroom covers</em></li><li><em>Ok Google, open Bedroom covers</em></li><li><em>Ok Google, set Bedroom covers to 50%</em></li></ul><p>The killer feature is setting this up as a routine to open/close the blind as you wake up, go to sleep.</p><p>Happy hacking :)</p></div></div>]]>
            </description>
            <link>https://mwitkow.me/posts/2020-11-08_somfy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187945</guid>
            <pubDate>Mon, 23 Nov 2020 15:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django refactoring game ‚Äì can you fix all the Models anti-patterns?]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25187507">thread link</a>) | @rikatee
<br/>
November 23, 2020 | https://django.doctor/challenge | <a href="https://web.archive.org/web/*/https://django.doctor/challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://django.doctor/challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187507</guid>
            <pubDate>Mon, 23 Nov 2020 15:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tech Stack of a One-Man SaaS]]>
            </title>
            <description>
<![CDATA[
Score 432 | Comments 235 (<a href="https://news.ycombinator.com/item?id=25186342">thread link</a>) | @amzans
<br/>
November 23, 2020 | https://panelbear.com/blog/tech-stack/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Being an engineer at heart, each time I see a company write about their tech stack, I brew a fresh cup of coffee, sit back and enjoy reading the newfound little treat.</p><p>There‚Äôs just something fascinating about getting to know what‚Äôs under the hood of other people‚Äôs businesses. It‚Äôs like gossip, but about software.</p><p>A couple of months ago I started working on <a href="https://panelbear.com/blog/why-panelbear/" target="_blank" rel="noopener">yet another private analytics service</a>, a project which has gone through numerous iterations, and I feel lucky that 400+ websites have already integrated with it, even though it's still in the early stages.</p><p>That‚Äôs why, in the same spirit as Jake Lazaroff‚Äôs <a href="https://jake.nyc/words/tools-and-services-i-use-to-run-my-saas/" target="_blank" rel="noopener">Tools and Services I Use to Run My SaaS</a>, I thought it‚Äôs now my turn to do a short write up of the technologies I‚Äôm using to run this new service.</p><h2>Languages</h2><p>Over the years I have added many programming languages to my toolbelt, but for solo projects I have converged to two in particular that strike a good balance of productivity and reliability.</p><ul><li><p><a href="https://python.org/" target="_blank" rel="noopener">Python</a>: Most of the backend code is in Python. Which has enabled me to ship features incredibly fast. Additionally, I use <a href="http://mypy-lang.org/" target="_blank" rel="noopener">mypy</a> for optional type hints, which helps keep the codebase manageable.</p></li><li><p><a href="https://www.typescriptlang.org/" target="_blank" rel="noopener">Typescript</a>: I used to avoid working on the frontend as much as I could. That is until I discovered Typescript about 4 years ago. It just makes the whole experience a lot better, and I now use it for all my projects together with React.</p></li></ul><h2>Frameworks and libraries</h2><p>This list could have been huge, as I stand on the shoulders of giants who have published the vast amount of open-source code which I rely on. But I'd like to highlight only a handful due to their major role in the stack:</p><ul><li><a href="https://www.djangoproject.com/" target="_blank" rel="noopener">Django</a>: It's like a superpower for solo developers. The longer you work in this industry, the more you appreciate not having to reinvent the wheel for the 100th time. A monolithic framework can get you <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366" target="_blank" rel="noopener">really</a>, <a href="https://github.com/getsentry/sentry" target="_blank" rel="noopener">really</a> <a href="https://djangostars.com/blog/10-popular-sites-made-on-django/" target="_blank" rel="noopener">far</a>. To me, it's about predictable software that's fast in every way that matters. In case you're interested, I talk more about this topic on <a href="https://panelbear.com/blog/boring-tech/" target="_blank" rel="noopener">Choose Boring Technology</a>.</li><li><a href="https://reactjs.org/" target="_blank" rel="noopener">React</a>: The web app for the dashboards is built using React + Webpack. After using Angular for a long time, I switched to React because it's just a pluggable view layer that doesn't get in the way. I use the fantastic <a href="https://github.com/Frojd/django-react-templatetags" target="_blank" rel="noopener">django-react-templatetags</a> to embed the React components in my Django templates.</li><li><a href="https://nextjs.org/" target="_blank" rel="noopener">NextJS</a>: I use it for the landing pages, documentation and the blog which you are currently reading. It enables me to re-use various React components, and still reap the performance and SEO benefits of a statically generated site.</li><li><a href="https://docs.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: I use it for any kind of background/scheduled tasks. It does have a learning curve for more advanced use-cases, but it's quite reliable once you understand how it works, and more importantly when it fails.</li><li><a href="https://getbootstrap.com/" target="_blank" rel="noopener">Bootstrap 4</a>: I built a custom theme on top of Bootstrap. It has saved me a lot of time, and there's lots of documentation around it. That's why I picked it.</li></ul><h2>Databases</h2><p>I originally stored all data in a single SQLite database, doing backups meant making a copy of this file to an object storage like S3. At the time, it was more than enough for the small sites I tested Panelbear with. But as I added more features and websites, I needed more specialized software to support those features:</p><ul><li><a href="https://clickhouse.tech/" target="_blank" rel="noopener">Clickhouse</a>: I believe this is one of those technologies that over time will become ubiquitous. It's honestly a fantastic piece of software that enabled me to build features that initially seemed impossible on low-cost hardware. I do intend to write a future blog post on some lessons learned from running Clickhouse on Kubernetes. So stay tuned!</li><li><a href="https://www.postgresql.org/" target="_blank" rel="noopener">PostgreSQL</a>: My go-to relational database. Sane defaults, battle-tested, and deeply integrated with Django. For Panelbear, I use it for all application data that is not analytics related. For the analytics data, I instead wrote a simple interface for querying Clickhouse within Django.</li><li><a href="https://redis.io/" target="_blank" rel="noopener">Redis</a>: I use it for many things: caching, rate-limiting, as a task queue, and as a key/value store with TTL for various features. Rock-solid, and great documentation.</li></ul><h2>Deployment</h2><p>I treat my infrastructure as <a href="https://joachim8675309.medium.com/devops-concepts-pets-vs-cattle-2380b5aab313" target="_blank" rel="noopener">cattle instead of pets</a>, things like servers and clusters are meant to come and go. So if one server gets "sick", I just replace it with another one. That means everything is described as code in a git repo, and I do not change things by SSH'ing into the servers. You can think of it like a template to clone my entire infrastructure with one command into any AWS region/environment.</p><p>This also helps me in case of disaster recovery. I just run a few commands, and some minutes later my stack has been re-created. This was particularly useful when I moved from DigitalOcean, to Linode, and recently to AWS. Everything is described in code, so it's easy to keep track of what components I own, even years later (all companies have some AWS IAM policy or VPC subnet lurking around which was created via clicky-clicky on the UI, and now everyone depends on it).</p><ul><li><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>: I manage most of my cloud infrastructure with Terraform. Things like EKS clusters, S3 buckets, roles, and RDS instances are declared in my Terraform manifests. The state is synced to an encrypted S3 bucket to avoid getting in trouble in case something happens to my development laptop.</li><li><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a>: I build everything as Docker images. Even stateful components like Clickhouse or Redis are packaged and shipped as Docker containers to my cluster. It also makes my stack very portable, as I can run it anywhere I can run Docker.</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a>: Allowed me to simplify the operational aspects tremendously. However, I wouldn‚Äôt bindly recommend it to everyone, as I already felt comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. I also rely on managed offerings, which helps reduce the burden too.</li><li><a href="https://github.com/features/actions" target="_blank" rel="noopener">GitHub Actions</a>: Normally I‚Äôd use <a href="https://circleci.com/" target="_blank" rel="noopener">CircleCI</a> in the past (which is also great), but for this project I prefer to use GitHub Actions as it removes yet another service which needs to have access to my repositories, and deployment secrets. However, CircleCI has plenty of good features, and I still recommend it.</li></ul><h2>Infrastructure</h2><p>I started in a single $5/mo instance in DigitalOcean, then moved to the managed Kubernetes offering as I was reinventing the wheel for a lot of things Kubernetes already gives me out of the box (service discovery, TLS certs, load balancing, log rotation, rollout, scaling, fault-tolerance, among others).</p><p>Unfortunately, I had <a href="https://www.digitalocean.com/community/questions/kubernetes-unable-to-connect-to-the-server" target="_blank" rel="noopener">reliability issues</a> with DigitalOcean's Kubernetes offering, even on larger instances. The cluster API would often go down randomly and no longer recover, this disrupted a lot of cluster services including the load balancer, which translated into downtime for me. I had to create a new cluster each time this happened, and while Terraform made it trivial, this was not something that inspired a lot of confidence about their managed service. I suspect their control plane was underprovisioned, which would be kind of understandable given the price tag.</p><p>Unfortunately I was not able to resolve the issue after several weeks. That's why I decided to move to <a href="https://www.linode.com/" target="_blank" rel="noopener">Linode</a>, and had exactly 0 problems during the 1.5 month-long honeymoon that followed.</p><p>However, I recently moved once again, this time to AWS due to a pretty good deal I received. It also enabled me to use managed services like RDS to offload managing PostgreSQL, which is a big plus. What made all these migrations relatively easy, was that all my infrastructure was described via Terraform and Kubernetes manifests. The migrations essentially consisted of an evening, some tea, and patience. But that's for another post.</p><ul><li><a href="https://aws.amazon.com/" target="_blank" rel="noopener">AWS</a>: Predictable, and lots of managed services. However, I use it at my full-time job, so I didn't have to spend too much time figuring things out. The main services I use are EKS, ELB, S3, RDS, IAM and private VPCs. I might also add Cloudfront and Kinesis in the future.</li><li><a href="https://www.cloudflare.com/" target="_blank" rel="noopener">Cloudflare</a>: I mainly use it for DDoS protection, serving DNS, and offloading edge caching of various static assets (currently shaves off 80% of the egress charges from AWS - their bandwidth pricing is insane!).</li><li><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let‚Äôs Encrypt</a>: Free SSL certificate authority. I use cert-manager in my Kubernetes cluster to automatically issue and renew certificates based on my ingress rules.</li><li><a href="https://www.namecheap.com/" target="_blank" rel="noopener">Namecheap</a>: My domain name registrar of choice. Allows MFA for login which is an important security feature. Unlike other registrars, they haven't surprised me with an expensive renewal every few years. I like them.</li></ul><h2>Kubernetes components</h2><p>The following components automate most of the devops work for me. I use several others too, but some of the main ones I use are:</p><ul><li><a href="https://github.com/kubernetes/ingress-nginx/" target="_blank" rel="noopener">ingress-nginx</a>: Rock-solid ingress controller for Kubernetes using NGINX as a reverse proxy, and load balancer. Sits behind the NLB which controls ingress to the cluster nodes.</li><li><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">cert-manager</a>: Automatically issue/renew TLS certs as defined in my ingress rules.</li><li><a href="https://github.com/kubernetes-sigs/external-dns" target="_blank" rel="noopener">external-dns</a>: Synchronizes exposed Kubernetes Services and Ingresses with DNS providers (such as Cloudflare).</li><li><a href="https://github.com/prometheus-operator/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a>: Automatically monitors most of my services, and exposes dashboards via Grafana.</li><li><a href="https://fluxcd.io/" target="_blank" rel="noopener">flux</a>: GitOps way to do continuous delivery in Kubernetes. Basically pulls and deploys new Docker images when I release them.</li></ul><h2>CLI tools</h2><p>There‚Äôs plenty here, but frequently used include:</p><ul><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">kubectl</a>: To interact with the Kubernetes cluster to watch logs, pods and services, SSH into a running container, and so on.</li><li><a href="https://github.com/wercker/stern" target="_blank" rel="noopener">stern</a>: Multi pod log tailing for Kubernetes. Really handy.</li><li><a href="https://htop.dev/" target="_blank" rel="noopener">htop</a>: Interactive system process viewer. Better than ‚Äútop‚Äù if you ask me.</li><li><a href="https://curl.se/" target="_blank" rel="noopener">cURL</a>: Issue HTTP requests locally, inspect headers.</li><li><a href="https://httpie.io/" target="_blank" rel="noopener">HTTPie</a>: Like cURL, but simpler for JSON APIs.</li><li><a href="https://github.com/rakyll/hey" target="_blank" rel="noopener">hey</a>: Load testing HTTP endpoints. Gives a nice latency distribution summary.</li></ul><h2>Monitoring</h2><ul><li><a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>: Efficient storage of time series data for monitoring. Tracks all the cluster and app metrics. It was a lot cheaper than using Cloudwatch for app metrics.</li><li><a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>: Nice dashboards for the Prometheus monitoring data. All dashboards are described in JSON files and versioned in the ‚Ä¶</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://panelbear.com/blog/tech-stack/">https://panelbear.com/blog/tech-stack/</a></em></p>]]>
            </description>
            <link>https://panelbear.com/blog/tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186342</guid>
            <pubDate>Mon, 23 Nov 2020 13:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Netlify Functions and the Twitter API v2 as a CMS for Your Gatsby Blog]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25186006">thread link</a>) | @pauliescanlon
<br/>
November 23, 2020 | https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/ | <a href="https://web.archive.org/web/*/https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://res.cloudinary.com/www-paulie-dev/image/upload/v1605613346/paulie.dev/2020/11/gatsby-netlify-twitterjpg_ok1k0q.jpg"></p><div><div><div><p>Date published: </p><!-- --><p>17-Nov-2020</p></div></div></div><hr><p>JavaScript</p><p>React</p><p>Gatsby</p><p>Netlify Functions</p><p>Twitter API v2</p><hr><p>Apologies in advance for the rather long-winded blog title but as it suggests in this post i'm going to explain how you can use <a href="https://www.netlify.com/products/functions/">Netlify Functions</a> to access your Twitter profile data using the <a href="https://developer.twitter.com/en/docs/twitter-api/early-access">Twitter v2 API</a> and display it on your Gatsby blog.</p><h2>A rather unique requirement</h2><p>This might be a specific to me but I wanted to solve a little problem I was having with my "digital footprint". As you can see I have this blog: <a href="https://paulie.dev/">https://paulie.dev</a> and a commercial portfolio: <a href="https://www.pauliescanlon.io/">https://www.pauliescanlon.io</a></p><p>Both sites are built on top of my Gatsby theme: <a href="https://gatsby-theme-terminal.netlify.app/">gatsby-theme-terminal</a> which is Open source and can be found on my <a href="https://github.com/PaulieScanlon/gatsby-theme-terminal">GitHub</a></p><p>Using a Gatsby Theme solves one of my issues as I'm able to have two sites that look and work pretty much the same way and any changes I make to the theme are inherited by both my sites. It's kind of like managing your own multi brand design system, but just for yourself.</p><p>There was one other problem though. ü§î</p><p>I wanted both sites to have the same "intro" section, but every time I made a change to one I had to make the same change to the other site to ensure they were both displaying the same intro text.</p><p>This might be fine if I weren't a developer but doing something twice is one time too many IMO.</p><p>It was also a little frustrating because I also wanted my Twitter profile description to be in sync with both the sites so, again another place to remember to update my personal blurb.</p><p>One option I considered would have been to hook up a Content Management System, and this would have been fine and it would have kept both my sites in sync but it wouldn't have been able to update my Twitter profile blurb...</p><p>So, I've decided to reverse engineer the Twitter API and use that as a CMS to populate both my sites. The idea is quite simple. I'll use the Twitter profile description as though it were a field from a CMS. Naturally any changes I make to this will appear on my Twitter profile and below is how I pull that same info into both of my sites.</p><h2>Demo</h2><p>Here's what I'll be showing you how to build:</p><ul><li>App / API <a href="https://gatsby-netlify-twitter.netlify.app/">https://gatsby-netlify-twitter.netlify.app</a></li><li>GitHub repo <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter">https://github.com/PaulieScanlon/gatsby-netlify-twitter</a></li></ul><p>... but the actual API I use for my blog and site is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Tech</h2><h3>Netlify Functions</h3><p>"Power your site without managing servers" is how Netlify describe Functions and for all intents and purposes thats exactly what they are. Similar to how you might create an <a href="https://expressjs.com/">Express</a> app and deploy it somewhere but without the hassle of having to setup server side environments and more crucially any really dweeby server uptime monitoring.</p><h3>Twitter API v2</h3><p>A set of endpoints that can be used to get data from Twitter. Any Twitter requests must be done server side and use a set of keys and tokens. You can't unfortunately hit the Twitter API from the browser so we need a "server" or as mentioned above, a Netlify Function</p><p>Using both of the above i've made my own API endpoint which goes off and hits the Twitter API and returns my Profile information which I can then display in the intro section of my blog and site. I've deployed this API to Netlify and it's completely de-coupled from either of my sites but will return data which can be fetched from client side "fetch" request from within my site and blog. That url again is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Before we start</h2><p>Before we get started there's a couple of things you'll need to have in place.</p><h3>Twitter API v2</h3><p>Apply for access to the <a href="https://developer.twitter.com/en/products/twitter-api">Twitter API</a>. This is quite a lengthy process so strap in and also bookmark this post as it might take a few days for Twitter to accept your application.</p><p>Once you have access you can head over to the <a href="https://developer.twitter.com/en/portal/dashboard">Developer Portal</a> and create a new project, and within the project you can create an "app", I called mine "paulie-api".</p><p>In here you'll find all the API keys and tokens required to access the Twitter API. Make a note of them somewhere as we'll be using them later.</p><h3>Netlify CLI</h3><p>To run Netlify Functions we'll be using <code>netlify dev</code> rather than <code>gatsby develop</code> or <code>yarn develop</code> so you'll need to install the <a href="https://docs.netlify.com/cli/get-started/">Netlify CLI</a></p><h2>The Build</h2><p>In order to develop you own API I found it easiest to have some kind of "site" running at the same time which will access the API endpoint and render the response on the page. In the demo repo you'll see i've set up a really simple Gatsby Site with one page that uses "fetch" to, er fetch and then render the data.</p><p>I've used <a href="https://theme-ui.com/home">Theme UI</a> for the style but naturally you can choose whatever you like to do this.</p><p>Whether you're starting from scratch or adding Netlify Functions to an existing project you'll need to start by adding a <code>functions</code> dir to the root of your project.</p><hr><pre><p><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p></pre><hr><p><code>functions</code> is kind of it's own application so it'll need it's own <code>package.json</code> and will have one dependency on <a href="https://github.com/HunterLarco/twitter-v2">twitter-v2</a></p><hr><pre><p><span></span><span>{</span><span></span></p><p><span>  </span><span>"name"</span><span>:</span><span> </span><span>"gatsby-netlify-twitter-api"</span><span>,</span><span></span></p><p><span>  </span><span>"version"</span><span>:</span><span> </span><span>"1.0.0"</span><span>,</span><span></span></p><p><span>  </span><span>"description"</span><span>:</span><span> </span><span>"An api for the Twitter v2 api"</span><span>,</span><span></span></p><p><span>  </span><span>"main"</span><span>:</span><span> </span><span>"index.js"</span><span>,</span><span></span></p><p><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"test"</span><span>:</span><span> </span><span>"echo \"Error: no test specified\" &amp;&amp; exit 1"</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span></span></p><p><span>  </span><span>"keywords"</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>  </span><span>"author"</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>  </span><span>"license"</span><span>:</span><span> </span><span>"ISC"</span><span>,</span><span></span></p><p><span>  </span><span>"dependencies"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"twitter-v2"</span><span>:</span><span> </span><span>"^0.1.2"</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>Next have a look at <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/.env.example">.env.example</a>. You'll need to create your own <code>.env</code> file and add the environment variables as seen in the <code>.env.example</code>. Naturally you'll want to change the <code>GATSBY_TWITTER_USERNAME</code> to your own Twitter username and the Twitter keys and tokens will be what I referenced earlier which are provided by the Twitter Developer Portal</p><hr><pre><p><span></span><span>GATSBY_API_URL</span><span>=</span><span>.</span><span>/</span><span>.</span><span>netlify</span><span>/</span><span>functions</span></p><p><span></span><span>GATSBY_TWITTER_USERNAME</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY_SECRET</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>=</span></p></pre><hr><p>Next create a Twitter client, this is what we'll use to pass the keys and tokens onto the Twitter API when we make a request</p><hr><pre><p><span></span><span>const</span><span> </span><span>Twitter</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"twitter-v2"</span><span>)</span><span></span></p><p><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  client</span><span>:</span><span> </span><span>new</span><span> </span><span>Twitter</span><span>(</span><span>{</span><span></span></p><p><span>    consumer_key</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY</span><span>,</span><span></span></p><p><span>    consumer_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY_SECRET</span><span>,</span><span></span></p><p><span>    access_token</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN</span><span>,</span><span></span></p><p><span>    access_token_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>You should now be looking at something similar to the below</p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>Now we need to create the "endpoint" that our frontend will hit, which in turn goes off and grabs the data from the Twitter API.</p><p>I created a dir called <code>twitter-user</code> and inside I create a new file and called it <code>twitter-user.js</code></p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- twitter-user</span></p><p><span>    </span><span>|</span><span>-- twitter-user.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>It's in here where we can use the <code>client.js</code> to hit a Twitter API endpoint and pass with it the required keys and tokens from the <code>client</code></p><hr><pre><p><span></span><span>const</span><span> </span><span>{</span><span> client </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"../client"</span><span>)</span><span></span></p><p><span>exports</span><span>.</span><span>handler</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>event</span><span>,</span><span> context</span><span>,</span><span> callback</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> client</span><span>.</span><span>get</span><span>(</span><span></span></p><p><span>    </span><span>`</span><span>users/by/username/</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_TWITTER_USERNAME</span><span>}</span><span>`</span><span>,</span><span></span></p><p><span>    </span><span>{</span><span></span></p><p><span>      user</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>        fields</span><span>:</span><span></span></p><p><span>          </span><span>"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld"</span><span>,</span><span></span></p><p><span>      </span><span>}</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span>  </span><span>callback</span><span>(</span><span>null</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>    headers</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>"Access-Control-Allow-Origin"</span><span>:</span><span> </span><span>"*"</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span></span></p><p><span>    statusCode</span><span>:</span><span> </span><span>200</span><span>,</span><span></span></p><p><span>    body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> user</span><span>:</span><span> data </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>In the above you can see we use our <code>client</code> to hit the <code>users/by/username</code> Twitter API endpoint which you can read more about <a href="https://developer.twitter.com/en/docs/twitter-api/users/lookup/introduction">here</a>, which returns a <code>data</code> object which I pass on to the callback body as <code>{ user: data }</code></p><p>This is the object that'll we receive in our frontend</p><p>The next bit will greatly depend on how you've set up your frontend but in the <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/src/pages/index.js">Demo</a> I have one <code>page</code> called <code>index.js</code> which uses a <code>useEffect</code> to "fetch" the data from the Netlify Function.</p><p>The example file contains a few extra bits for <code>isLoading</code> and <code>hasError</code> but the below should be enough to allow you hit to the Netlify Function which in turn hits the Twitter API and returns your profile information data.</p><hr><pre><p><span></span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span></span></p><p><span></span><span>const</span><span> </span><span>IndexPage</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>response</span><span>,</span><span> setResponse</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>fetch</span><span>(</span><span>`</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_API_URL</span><span>}</span><span>/twitter-user</span><span>`</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> response</span><span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>        </span><span>setResponse</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>error</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>error</span><span>(</span><span>{</span><span> error </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> user </span><span>}</span><span> </span><span>=</span><span> response</span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>pre</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>code</span><span>&gt;</span><span>{</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>user</span><span>,</span><span> </span><span>null</span><span>,</span><span> </span><span>2</span><span>)</span><span>}</span><span>&lt;</span><span>/</span><span>code</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;</span><span>/</span><span>pre</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>IndexPage</span></p></pre><hr><p><code>process.env.GATSBY_API_URL</code> is the path to the Netlify Function we added earlier to <code>.env</code> and i've hard-coded <code>/twitter-user</code> in the component / page as you might want to create different endpoints that return different data on different pages.</p><p>You might be wondering why this environment variable is prefixed with <code>GATSBY_</code>. This is so Gatsby can access it from the frontend. You can read more about Gatsby environment variables <a href="https://www.gatsbyjs.com/docs/environment-variables/#client-side-javascript">here</a></p><h3>IMPORTANT</h3><p>In order for Netlify Functions to work both locally and when deployed we need to ensure we've got <code>netlify-lambda</code> installed and have added both a <code>"start"</code> and <code>"postinstall"</code> script to the root <code>package.json</code> (not the <code>package.json</code> in <code>./functions</code>)</p><hr><pre><p><span>npm</span><span> </span><span>install</span><span> netlify-lambda --save -dev</span></p></pre><hr><pre><p><span>// ./package.json</span></p><p><span>...</span></p><p><span></span><span>  "scripts": {</span></p><p><span>    "develop": "gatsby develop",</span></p><p><span>    "build": "gatsby build",</span></p><p><span>    "clean": "gatsby clean",</span></p><p><span>    "serve": "gatsby serve",</span></p><p><span></span><span>+    "start": "npm run develop",</span></p><p><span>+    "postinstall": "netlify-lambda install"</span></p><p><span></span><span>  },</span></p><p><span>   "devDependencies": {</span></p><p><span></span><span>+   "netlify-lambda": "^1.6.3",</span></p><p><span></span><span>  }</span></p><p><span></span><span>...</span></p></pre><hr><p>Before we get too carried away, it's important to note that we'll no longer be using <code>gatsby develop</code> or <code>yarn develop</code> to start the Gatsby app, if you do that our Netlify Function won't be running and you'll get an error.</p><p>Instead, run <code>netlify dev</code> this is so both the Gatsby site and the Netlify Function are run at the same time.</p><p>Instead of visiting the usual <code>http://localhost:8000/</code> we'll now be visiting <code>http://localhost:8888/</code></p><p>And to ensure when we deploy everything works as it should you'll need to modify your <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/netlify.toml"><code>netlify.toml</code></a></p><p>For ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</a></em></p>]]>
            </description>
            <link>https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186006</guid>
            <pubDate>Mon, 23 Nov 2020 12:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detective Game Design Problems]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25185571">thread link</a>) | @jsnell
<br/>
November 23, 2020 | https://digitales.games/blog/detective-game-design-problems | <a href="https://web.archive.org/web/*/https://digitales.games/blog/detective-game-design-problems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="blog">
            <div>
                <div>
					
                    <div>

                        <div>


    <div>

                    <p>Game design is such a wide and varied discipline that job titles in the field have become increasingly granular over the years ‚Äì and ever since we started working on our debut title Lacuna, I've become more and more convinced that "detective game designer" merits its own denomination as well. Detective gameplay (or "investigation gameplay") poses a number of unique challenges centered around two main problems: the <strong>struggle between story and puzzles</strong> (or "cases") as well as <strong>communication between the player and the game</strong>.</p>
<p>Since some of the explanations will be using our own game as an example, let me give you a quick rundown: Lacuna is a story-driven adventure with platformer controls and investigation elements. Its four fundamental gameplay types are dialogs (with choices), moving around, examining objects, and solving puzzles. All of them are staples of the point &amp; click genre, but their execution is quite unique; I don't want to go into more detail here because it's not pertinent to the topic, but you can <a href="http://lacuna.game/">check out the game on Steam</a> if you want to know more.</p>
<p><img alt="Gameplay" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/gameplay-movement.gif"><br>
<em>This is what the game looks like</em></p>
<h2>Story vs. puzzles</h2>
<p>A handful of abstract game design principles lie at Lacuna's core. For instance, "no takebacks" dictates that the player only get one shot at every decision, dialog, and puzzle. The game auto-saves and doesn't allow you to go back if you performed poorly or regret an earlier decision. There's also "limited feedback", which means that the player often isn't told immediately whether a solution was correct and what the consequences of their actions and decisions will be.</p>
<p>However, there's one in particular I want to highlight here because it concerns the above mentioned divide between story and puzzling in detective games: <strong>No getting stuck.</strong></p>
<p>The thought process behind it was simple: In games with both a story and puzzles (e.g. most P&amp;C games), story progress is almost always tied directly to puzzle progress. Until you solve the puzzle at hand, you don't get to see the next part of the story. For some players, especially those most interested in the story, this can become a problem. If they're stuck for too long, there's a chance they'll just drop out and never pick the game up again. Even if that doesn't happen, hard puzzles always run the risk of messing up the story's pacing and interrupting your immersion in the game ‚Äì because you're becoming frustrated or, even worse, because you decide to tab out and Google the solution. To avoid people getting stuck, we considered a number of solutions:</p>
<p><strong>Solution 1: Make the puzzles very easy?</strong><br>
This isn't our favorite since it somewhat defeats the purpose of puzzles. They'd still play a role as a change of pace now and then, but if puzzles aren't a little hard, nobody will feel like a detective solving them. Some early puzzles in Lacuna are easy, but most aren't.</p>
<p><strong>Solution 2: Provide hints?</strong><br>
Hint systems can be found in many adventures featuring puzzles. Unfortunately, they often take the player out of the experience in one of three ways: In some cases, the hint is provided by extradiegetic UI (e.g. in the pause menu) and therefore seems to come out of nowhere in the game world. In other cases, the player character is the one giving the hint, disconnecting the player from their avatar‚Äôs perspective. The third option of NPCs providing hints is a little better; however, it is often hard to justify <em>why</em> an NPC would be able to point the player in the right direction without possessing the rest of the solution to the ongoing puzzle (and why they didn't volunteer it in the first place). The two types of (sort-of) hint systems we went with in Lacuna are <em>Highlight Mode</em>, which displays optional outlines around objects and NPCs that hold new information, and <em>redundant information</em>, meaning that sometimes the player is given two ways of obtaining an important clue.</p>
<p><img alt="Hints" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-hints.png"><br>
<em>"YOU ARE PLAYING A GAME RIGHT NOW"</em></p>
<p><strong>Solution 3: Decouple story progress from puzzle progress?</strong><br>
Why not simply make a story-driven game throughout which the player can solve the occasional puzzle if they feel like it? Well, because it would require that puzzles be somewhat detached from the story. As a result, they run the risk of feeling meaningless since solving them is not rewarding and failing is not punishing. However, this <em>can</em> work quite well when combined with...</p>
<p><strong>Solution 4: Make branching content for different solutions?</strong><br>
Instead of impeding the player‚Äôs progress, wrong or missing puzzle solutions could lead to a less desirable continuation and/or outcome of the story. Unfortunately, creating a new story branch for each and every wrong solution to a puzzle is hardly feasible. However, there are less extreme ways of realizing this. For instance, the game could account for the player‚Äôs <em>overall</em> puzzling performance at certain points in the game, e.g. trigger the ‚Äúgood‚Äù finale to an act if they got more than x% of the puzzles right, and the ‚Äúbad‚Äù one if not. There could also be cascading consequences of sorts, e.g. solving one case correctly may give the player an edge in a later one. These approaches have similar downsides as optional puzzles do, but to a lesser degree; puzzle success no longer being required for progress makes them feel more detached from the story and removes immediate feedback. Regardless, we have found this to be the best solution, which is why we employ it quite a bit in Lacuna (while trying to avoid all the pitfalls). By the way, if all of this is becoming too abstract for you, bear with us! The second half of this post is all about a real example from the game.</p>
<p><img alt="Detroit: Become Human" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-branching-content.jpg"><br>
<em>Detroit: Become Human offers an astonishing number of different outcomes depending on player action, but not everybody has that kind of money to burn</em></p>
<p>Despite all of these measures being taken to make sure that the player won't get stuck, Lacuna can still be called a hard game. While it's not difficult to get <em>to</em> the end, it's pretty difficult to get a <em>good</em> ending and not mess things up on your way there. In other words, rushing through the whole story is possible if you don't mind bringing it to a terrible conclusion.</p>
<h2>Communicating with the game</h2>
<p>While the previous chapter only concerns detective games that also prominently feature a story, this next one is relevant to pretty much every detective game every made. It addresses the topic of communication between the player and the game, and especially how the player can express their thoughts to it. Several principles have proven to make for a good experience across countless approaches to this problem over the years:</p>
<p><strong>Principle 1: Many channels out, few channels back in.</strong><br>
If the game conveys information to the player on many different channels and in many different ways, the process of piecing the solution together tends to feel more interesting and rewarding. In Lacuna, the player picks up clues from dialogs, objects, environments, the news, and e-mails (with all sorts of attachments). At the same time, the channels via which the player communicates that solution back to the game are kept to a minimum, namely cloze texts we like to call "Case Sheets" and (to a lesser degree) dialog choices. Having one or two central mechanics for player input makes the experience more coherent and transparent and facilitates designing the mysteries around it.</p>
<p><img alt="Obra Dinn" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-obra-dinn.jpg"><br>
<em>Return of the Obra Dinn by Lucas Pope provides a bunch of different sources of information, but just one central mechanic for the player to communicate back to the game</em></p>
<p><strong>Principle 2: Have the player communicate only the solution.</strong><br>
It is near impossible to create a system through which the player communicates to the game <em>how</em> they arrived at a solution. Luckily, this is not necessary. A well-designed puzzle provides all the information, then moves the entire solution process solely <em>into the player‚Äôs head</em>, and finally prompts the player to input only their answer. The player‚Äôs objective should be stated clearly, but in a very general way at the start of a case (e.g. ‚Äúfind the culprit‚Äù).</p>
<p><strong>Principle 3: Give the player maximum freedom in communicating the solution.</strong><br>
The way in which the player communicates the answer to the game is the most crucial part to get right. One aspect is to give the player many choices (or a large combination of choices) to pick from. Two things should be avoided: 1. Giving the player a high probability to succeed by picking a random answer. 2. Making it easy for the player to guess correctly because only one or a few of the available answers appear plausible. An example for a bad solution like this would be to give the player three dialog choices to solve the puzzle; even worse would be if one of them obviously made the most sense. A better approach would be to give the player a cloze text with a bunch of plausible options for each gap. Another possibility is to have the solution be an unguessable string of characters that the player needs to enter manually. Both ideas utilize combinatorial explosion to make guessing and brute-forcing nearly impossible.</p>
<p><img alt="Detective Grimoire" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-case-sheets.jpg"><br>
<em>Good luck brute-forcing your way through Detective Grimoire's cloze texts</em></p>
<h2>Puzzle example</h2>
<p>Hopefullly all this will become crystal clear when put to concrete use! The following is an early level in Lacuna. It doesn't contain some of the difficulties added later (like a large number of channels communicating potential evidence). In harder cases, the player will need to have paid attention to testimonies, news articles etc. from earlier levels to arrive at the correct conclusion, and some cases span multiple levels. Not this one, though; all the information required to solve it is directly contained in the clues and dialogs of the one level where it starts and ends.</p>
<p>This chapter won't reveal much of importance about the story, but it will spoil the solution to this one puzzle, so consider yourself warned.</p>
<h3>The puzzle</h3>
<p>Here's what happens: Our protagonist Neil is called to a ‚Ä¶</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitales.games/blog/detective-game-design-problems">https://digitales.games/blog/detective-game-design-problems</a></em></p>]]>
            </description>
            <link>https://digitales.games/blog/detective-game-design-problems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185571</guid>
            <pubDate>Mon, 23 Nov 2020 11:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Condemned for Providing Platform to Neo-Nazi Network]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25184311">thread link</a>) | @wikus
<br/>
November 22, 2020 | https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/ | <a href="https://web.archive.org/web/*/https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1222">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h3>Facebook is facing a new wave of criticism for providing a platform for a white supremacist network with over 80,000 online followers.</h3>
<ul>
<li>Facebook only removed these pages after being contacted by large media organisation the <em>Observer</em>. The Center for Countering Digital Hate claim they were made aware of this two years ago.</li>
</ul>
<p>The Guardian reports this Neo-Nazi network also has ties to the UK far right, <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">including a student facing terrorism charges</a>. Imran Ahmed, CEO of the Center for Countering Digital Hate, said:</p>
<blockquote>
<p>&nbsp;‚ÄúFacebook‚Äôs leadership endangered public safety by letting Neo-Nazis finance their activities through Facebook and Instagram. Facebook was first told about this problem two years ago and failed to act.‚Äù</p>
</blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg" alt="" width="800" height="534" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-300x200.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-768x512.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1536x1024.jpg 1536w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-2048x1365.jpg 2048w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-272x182.jpg 272w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>After the <em>Observer</em> contacted Facebook, they began taking down the material with a Facebook spokesperson stating:</p>
<blockquote><p>‚ÄúWe have removed the content which violates our policies prohibiting dangerous organisations. We regularly work to improve our technology to find and remove this content faster, and, while there is more work to do, we are making progress. We‚Äôve banned over 250 white supremacist organisations from Facebook and Instagram.‚Äù</p></blockquote>
<h4>Read more of the <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">full report on The Guardian</a>.</h4>
<hr>
<p><strong>Author‚Äôs Note: </strong>I highly recommend reading <a href="https://hfet.org/opinion-grading-facebooks-homework/"><strong>Grading Facebook‚Äôs Homework</strong></a>, which is an opinion piece on Facebook‚Äôs response to criticism.</p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184311</guid>
            <pubDate>Mon, 23 Nov 2020 07:22:11 GMT</pubDate>
        </item>
    </channel>
</rss>
