<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 28 Nov 2020 16:38:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 28 Nov 2020 16:38:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[1.5 is the midpoint between 0 and infinity in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25226941">thread link</a>) | @pimterry
<br/>
November 27, 2020 | https://blog.peterzhu.ca/ruby-range-bsearch/ | <a href="https://web.archive.org/web/*/https://blog.peterzhu.ca/ruby-range-bsearch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>What’s the midpoint between 0 and infinity? Well the answer differs depending on whether you are asking a mathematician, philosopher, or a Ruby developer. I’m not a mathematician or a philosopher, but I am a Ruby developer, so I can tell you than 1.5 is the midpoint between 0 and infinity.</p>  <p><a href="https://ruby-doc.org/core-2.7.2/Range.html#method-i-bsearch"><code>Range#bsearch</code></a> performs binary search within a range. For example, lets use it to find the first integer that’s larger than 42 (which is 43) and see the values it inspects to find it.</p> <div><div><pre><code><span>values</span> <span>=</span> <span>[]</span>

<span>found_value</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>).</span><span>bsearch</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>values</span> <span>&lt;&lt;</span> <span>i</span>
  <span>i</span> <span>&gt;</span> <span>42</span>
<span>end</span>

<span>puts</span> <span>"The integer larger than 42 is: </span><span>#{</span><span>found_value</span><span>}</span><span>"</span>
<span>puts</span> <span>"The following values were inspected:"</span>
<span>puts</span> <span>values</span>
</code></pre></div></div> <p>And when we run it, we get the following output:</p> <div><div><pre><code>The integer larger than 42 is: 43
The following values were inspected:
1
2
4
8
16
32
64
32
48
40
44
42
43
</code></pre></div></div> <p>We see typical binary search behavior.</p> <p>A co-worker recently asked me about some odd behavior when we change the starting value to a float. For example, consider the following code, which is the same as the one above but the range is between 0 and <code>Float::INFINITY</code>:</p> <div><div><pre><code><span>values</span> <span>=</span> <span>[]</span>

<span>found_value</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>Float</span><span>::</span><span>INFINITY</span><span>).</span><span>bsearch</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>values</span> <span>&lt;&lt;</span> <span>i</span>
  <span>i</span> <span>&gt;</span> <span>42</span>
<span>end</span>

<span>puts</span> <span>"The float larger than 42 is: </span><span>#{</span><span>found_value</span><span>}</span><span>"</span>
<span>puts</span> <span>"The following values were inspected:"</span>
<span>puts</span> <span>values</span>
</code></pre></div></div> <p>We then get the following output when we run it (note that the output has been truncated because it’s too long):</p> <div><div><pre><code>The float larger than 42 is: 42.00000000000001
The following values were inspected:
1.5
1.6759759912428246e+154
1.5921412270130977e+77
4.8915590244884904e+38
2.7093655358260904e+19
6375342080.0
97792.0
383.0
23.96875
95.8125
47.921875
31.96484375
39.92578125
43.923828125
41.9248046875
42.92431640625
42.424560546875
42.1746826171875
...
</code></pre></div></div> <p>The first few values we inspect in the binary search are rather odd: <code>1.5</code>, <code>1.6759759912428246e+154</code>, <code>1.5921412270130977e+77</code>, etc. Where do these numbers come from? To explain these values, we first have to understand how IEEE 754 floating-point numbers work.</p>  <p>Ruby floats are double-precision IEEE 754 floating-point numbers. If you don’t know the basics about how floating-point numbers are represented in memory, there are plenty of resources on the internet, <a href="https://fabiensanglard.net/floating_point_visually_explained/">here’s one</a>.</p> <p>Of special interest to us is how infinity is represented in floating-point. Infinity is a special value where the exponent bits are all 1’s and the significand bits (also known as fraction or mantissa) are all 0’s.</p>  <p>Ruby’s <code>Range#bsearch</code> is implemented in a C function called <a href="https://github.com/ruby/ruby/blob/5512de76033773a77f686f3cb2adc849356f7674/range.c#L680"><code>range_bsearch</code></a>. There are several cases it deals with, and the one of interest is the case when either endpoint is a float. In this case, it performs a clever trick. It reads the C double type of the Ruby float endpoints as 64-bit integers (<code>int64_t</code>)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Note that this is <strong>not</strong> the same as casting the double into integer type, this is directly reading the double as a 64-bit integer. Are you confused? I sure was when I first read this code so if you are too, it’ll make more sense later on. Trust me.</p> <p>Let’s revisit how infinity is represented in floating-point. Here’s it visualized (through the help of the amazing website <a href="https://float.exposed/">float.exposed</a>). We can see that the sign is 0 (this is a positive value), all exponent bits are 1, and all significand bits are 0.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/infinity.png"> </figure> <p>And of course, <code>0</code> is represented in floating-point with all the bits set to 0.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/zero.png"> </figure> <p>So what if we read these bits of the endpoint as if they were integers? Then our range would be between <code>0</code> and <code>9218868437227405312</code>. What’s the midpoint of this range? It’s <code>4609434218613702656</code>. Now let’s plug this value back into <a href="https://float.exposed/0x3ff8000000000000">float.exposed</a>.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/one_point_five.png"> </figure> <p>Oh look, it’s 1.5!</p> <p>Using this same technique, you can now find out why the binary search examines <code>1.6759759912428246e+154</code> and <code>1.5921412270130977e+77</code> after this. This is left as an exercise for the reader.</p>  <p>The reason why this works is simple once you wrap your head around it. It’s because the more significant bits are always in a more significant position (than the bits to the right of it) in floating-point numbers. This is obviously true for the significand. But this is also true for the exponent because the next power of 2 can’t be reached by just increasing the significand, the exponent has to be increased. So thus a larger exponent will always mean that the floating-point number has a larger magnitude.</p> <p>Once this is true, we can see why binary search works using this technique. It works because if <code>x</code> and <code>y</code> are doubles and <code>x &gt; y</code>, then we have shown that <code>double_as_int64(x) &gt; double_as_int64(y)</code> is also true. This is the requirement for binary search because the values remain strictly increasing (<em>technically</em> binary search only requires monotonically increasing, but strictly increasing is a tighter guarantee than monotonically increasing).</p>  <p>Ruby’s binary search in a range uses a clever technique to perform binary search when the endpoints are doubles while maintaining a worst-case runtime of <code>O(n log n)</code>. In fact, this technique isn’t specific to Ruby and can be used in any language that uses IEEE 754 floating-point numbers.</p>  </div> </article> </div></div>]]>
            </description>
            <link>https://blog.peterzhu.ca/ruby-range-bsearch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226941</guid>
            <pubDate>Fri, 27 Nov 2020 09:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Memorize Faster with the Spaced Repetition Learning Technique]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25226621">thread link</a>) | @rossnoel
<br/>
November 27, 2020 | https://productive.fish/blog/spaced-repetition/ | <a href="https://web.archive.org/web/*/https://productive.fish/blog/spaced-repetition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
        
        <p>
            05 Sep 2020 • 6 min read
        </p>
    

    <p>As many of us have experienced during school years, late-night learning is not the most effective technique. The information might have stuck around for a short period, but just after the day of the exam, it flew away with us unable to recall it. If you would like to remember more during and after your studies, forget the last-minute learning. Using spaced repetition, a method to rehearse educational material, you will not simply earn better grades, but studying would be an overall easier process and memorized information will be available to recall later in your life.</p>
<picture>
  <source type="image/webp" media="(max-width: 320px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-sm.webp 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-sm@2x.webp 2x">
  <source type="image/webp" media="(max-width: 1099px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-md.webp 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-md@2x.webp 2x">
  <source type="image/webp" media="(min-width: 1100px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition.webp 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition@2x.webp 2x">
  <source media="(max-width: 320px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-sm.jpg 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-sm@2x.jpg 2x">
  <source media="(max-width: 1099px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-md.jpg 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-md@2x.jpg 2x">
  <source media="(min-width: 1100px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition.jpg 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition@2x.jpg 2x">
  <img src="https://productive.fish/blog/spaced-repetition/spaced-repetition.jpg" alt="A person on a conveyor symbolizing repeating process">
</picture>
<p>The spaced repetition system is a learning technique in which the material previously learned is recalled by the learner from time to time at ever-increasing intervals. This method is based on the intermittent repetition effect on how we tend to forget information. The primary goal of the technique is to recall the material learned as infrequently as possible, just before we forget it. By approaching repetitions in this scientific way, time spent learning can be used much more efficiently.</p>
<h2>The neurological background of memorizing</h2>
<p>Learning always begins with perception, the form of how we collect information. This data travels through the nerve pathways to the place where the perception is processed, our brain. Some perceptions cause our bodies to react, which usually does not happen consciously.</p>
<p>Scientists once thought that the brain stores memories in a similar way to computers. It was later proved that the artificial approach is completely different: information is broken down into elements (bits) on the computer and is stored that way. The machines can store up to a certain amount of information on a storage device called a hard disk. If our brain would work similarly, despite having hundreds of billions of cells, our internal storage device would have filled up in a matter of hours.</p>
<p>Our brains work in a rather different way: since we always store information in context it is more about capturing the contents of things. That’s why when we recall a memory, related reminiscences come to mind, like smells or the color of the paper, or what we ate for dinner during learning.</p>
<h2>What makes spaced repetition so effective?</h2>
<p>Spaced repetition technique is one of the most effective learning techniques, which you probably use even if you do not know about it. Using this method consciously makes it far superior to standard learning.</p>
<p>There are three key values it provides:</p>
<div>
<p>Delays forgetting learned information by prolonging the forget-curve.</p>
<p>Active recall helps to keep memorized information fresh (as the context layers build-up, it gets easier to remember what you have learned).</p>
<p>Spaced repetition supports long term memory, so you won’t forget the learned information even after the exam.</p>
</div>
<h2>How to get started with the spaced repetition system?</h2>
<p>To put the above in practice, try to remember a movie you’ve seen more than one time. After you’ve watched it first, you understood it well, but a few weeks later you only remembered the title and main story points. You watched it with a friend two months later, and while watching, you have realized that you can recall the story and started to watch out for certain details in the background, or the listening closer to the music. When you watched it for the third time, you probably remembered all the names, a few exact quotes, and the story details too.</p>
<p>Of course, the typical study materials are far from a movie’s excitement, however, learning it works the same. Review your documents and memorize them for the first time. After you have finished, try recalling them in a suitable way: you can write them down or simply rehearse the answers out loud. (Trying to recall it through your inner voice is not the best idea as we all tend to cheat ourselves.)</p>
<p>If you recalled it correctly, put the documents down and start another activity. After an hour try to rehearse it again, maybe using a different method. Then again in a few hours, and on the next day morning. Keep lengthening these intervals until you are ready to face the exam.</p>
<h2>Applications and websites that support you along the journey</h2>
<p>Luckily, today we have multiple choices on how to organize our studies. Different websites, along with applications, will help to study faster and also memorize for the long-term. Let’s see 5 software programs and applications utilizing the spaced repetition system!</p>
<h3>1. <a href="https://quizlet.com/" target="_blank" rel="noopener noreferrer">Quizlet</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/Quizlet-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/Quizlet-logo.png" alt="Quizlet logo"></picture> <strong>Platforms:</strong> iOS, Android, web</p>
<p><strong>The basic idea:</strong> This is an application that you can use either through your browser or on any mobile device. With one account you can have all your data synchronized, so you can continue your studies away from the computer when it is time to repeat!</p>
<p>The basic idea of Quizlet is that you can search for subjects that already have their case sets and use those, or you can create your own “memorizing cards”. Just enter the term and the definition, and after you are ready, you can start the learning process. Quizlet is also utilized for high-level education and corporate usage, ranging from healthcare studies to Starbucks training programs.</p>
<p>The app is available for students and teachers as well. If you get the vibe of this tool and you want to support it, for a low amount of monthly payment you can also purchase Quizlet Go or Plus for wider and advanced toolkits to create enhanced study sets.</p>
<p><strong>How it fits with SRLT:</strong> After creating or choosing your flashcard set, you can start to memorize the information. When you feel ready, you can choose how to check your knowledge. First is the “Learning” phase: Quizlet will show you the term and you will have to answer it from multiple choices or you will have to type it from memory - and the software will immediately review it. Getting it correctly will set the term as “Familiar”, and after multiple times it will be changed to “Mastered”. Furthermore, this spaced repetition app will give you constant feedback based on your answers, where you are in the learning process, and what you should focus on.</p>
<h3>2. <a href="https://www.edapp.com/" target="_blank" rel="noopener noreferrer">EdApp</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/EdApp-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/EdApp-logo.png" alt="EdApp logo"></picture> <strong>Platforms:</strong> iOS, Android, web</p>
<p><strong>The basic idea:</strong> Signing up for EdApp will give you a choice if you want to educate others or yourself. The registration is fast, and you can immediately create your topic or search in the content library based on your interest.</p>
<p>The contents will be summarized using texts, gifs, and short videos because visualization had a great positive effect on memorizing capabilities. The presentations also have interactive parts, triggering the mind with the element of surprise, stabilizing the learned information. While you are stepping further, EdApp will give you milestones to know where you are in the process.</p>
<p><strong>How it fits with SRLT:</strong> With its sophisticated approach and triggering effects, this spaced repetition software helps to improve memorizing information. On its finalizing page it summarizes the studied content, and based on your answers it gives feedback.</p>
<h3>3. <a href="https://apps.ankiweb.net/" target="_blank" rel="noopener noreferrer">Anki</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/Anki-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/Anki-logo.png" alt="Anki logo"></picture> <strong>Platforms:</strong> Windows, Mac, Linux, iOS, Android, and any device with a web browser</p>
<p><strong>The basic idea:</strong> Anki is a simple, ad-free software that helps you to create flashcards. After downloading it to your computer or on your mobile phone, the first step is to generate decks, which will include flashcards. All cards have a front- and a backside that you can fill up with information. Also, you can insert pictures and other notes from your classes, so you can memorize those as well. You can also grade the difficulty of the lesson. Anki is mostly used by college students (especially in healthcare). It runs offline, and its ad-free, transparent user interface won’t cause any disturbance during studying.</p>
<p><strong>How it fits with SRLT:</strong> Based on how difficult you have found the lecture, the program will offer you three choices to choose from: to see the lesson again in one minute or to repeat it in ten minutes or four days.</p>
<h3>4. <a href="https://www.brainscape.com/" target="_blank" rel="noopener noreferrer">Brainscape</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/Brainscape-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/Brainscape-logo.png" alt="Brainscape logo"></picture> <strong>Platforms:</strong> web, Android, iOS</p>
<p><strong>The basic idea:</strong> Brainscape is a specialized spaced repetition system where the algorithm focuses on the areas which need improvements, based on your answers and learning patterns. This is a lively web surface because their team is openly active on other social media websites and showing their results and feedback from users and companies, furthermore, a blog, full of content, is available as well.</p>
<p><strong>How it fits with SRLT:</strong> Brainscape will effectively monitor and check your answers and will support you - if you are honest how well you have known the flash cards’ answers, based on a scale from 1 to 5. It will also measure time during your study phases and help you to memorize information faster.</p>
<h3>5. <a href="http://smartcardsplus.com/" target="_blank" rel="noopener noreferrer">SmartCards+</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/SmartCards-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/SmartCards-logo.png" alt="SmartCards+ logo"></picture> <strong>Platform:</strong> iOS</p>
<p><strong>The basic idea:</strong> Smartcards will support your studies with a learning curve, measure the optimal time, and suggest when to repeat your studies. This spaced repetition app is only available for iOS users.</p>
<p><strong>How it fits with SRLT:</strong> Its classical surface will help you not simply with drag and drop text flashcards, but you can also insert video and audio files to support the memorization process. Furthermore, typing an answer is also an option during the learning phase, and the program will color results to show if you were correct or not.</p>
<h2>Conclusion</h2>
<p>Learning accompanies us throughout our entire life, while as we age studying gets harder. Spaced repetition is a good-to-know tactic (or even life-hack) that you might have used before without consciously knowing it. Utilizing the method through one of the above spaced repetition software apps will help you to memorize learning materials more effectively and in less time. The method comes handy in all ages, regardless if you go to school, prepare for college exams, or do corporate training to develop your career.</p>


</article></div>]]>
            </description>
            <link>https://productive.fish/blog/spaced-repetition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226621</guid>
            <pubDate>Fri, 27 Nov 2020 08:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Smart Doorbell with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25225934">thread link</a>) | @bdcravens
<br/>
November 26, 2020 | https://www.technicallywizardry.com/diy-smart-doorbell-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.technicallywizardry.com/diy-smart-doorbell-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9354"><div><p>A DIY smart doorbell with a built-in <strong>camera</strong>, <strong>microphone</strong>, and <strong>speaker</strong>. This steampunk-themed design integrates with home assistant and our <a href="https://www.technicallywizardry.com/cabin/diy-multi-room-sound-system/" data-wpel-link="internal" rel="internal follow noopener noreferrer">multi-room audio system</a> to communicate with the rest of our <a href="https://www.technicallywizardry.com/cabin/" data-wpel-link="internal" rel="internal follow noopener noreferrer">DIY smart home</a>.</p><p>Rather than buying a Ring Doorbell (<em>or Nest, or one of the other competitors</em>) I built our own smart doorbell with a Raspberry Pi. The whole project cost about $150 (USD), which is about average for a smart doorbell, but it is much more full-featured than anything else you’ll find on the market. For example, it integrates with the rest of the home security system — using machine learning to identify humans, cars, animals, and more:</p><figure><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg.webp 2048w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-300x300.jpg.webp 300w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1024x1024.jpg.webp 1024w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-150x150.jpg.webp 150w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-768x768.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1536x1536.jpg.webp 1536w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-214x214.jpg.webp 214w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-540x540.jpg.webp 540w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-344x344.jpg.webp 344w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-442x442.jpg.webp 442w"><img src="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg" alt="DIY smart doorbell detects a guest visitor with AI computer vision" width="1024" height="1024" title="Detecting a person approaching" srcset="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg 2048w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-300x300.jpg 300w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1024x1024.jpg 1024w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-150x150.jpg 150w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-768x768.jpg 768w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1536x1536.jpg 1536w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-214x214.jpg 214w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-540x540.jpg 540w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-344x344.jpg 344w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-442x442.jpg 442w" sizes="(max-width: 1024px) 100vw, 1024px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x1024.png" data-srcset="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg 2048w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-300x300.jpg 300w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1024x1024.jpg 1024w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-150x150.jpg 150w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-768x768.jpg 768w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1536x1536.jpg 1536w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-214x214.jpg 214w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-540x540.jpg 540w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-344x344.jpg 344w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-442x442.jpg 442w"></picture><figcaption>The smart doorbell uses TensorFlow to detect people, cars, animals, and more.</figcaption></figure><p>But I’m getting ahead of myself.</p><h2><span id="Designing_the_Smart_Doorbell"></span>Designing the Smart Doorbell<span></span></h2><p>Doorbells live outside.</p><p>Okay, that’s obvious. But it was my first electronic project that needed to <em>survive the elements</em>. To that end, I decided to use a <strong>junction box</strong> to house the electronics themselves.</p><p>The next requirement was also obvious: a <strong>button</strong>. However, the concern with such a unique design is that visitors need to intuitively understand <em>what the device is</em>. I decided upon a durable metal button that also lights up. The intention is for the light of the ring to make the button obvious.</p><p>Finally, the camera &amp; speakers. This is arguably the most important security camera in the entire house, and I didn’t have a lot of space in the junction box, so I splurged on a <strong>night-vision IR camera</strong> with a microphone built-in. Throw in a tiny USB speaker, and we have <strong>bi-directional audio</strong>.</p><p>The complete part list:</p><article><div><a href="https://www.technicallywizardry.com/speaker-multi-room-wireless-receiver/" title="Related: Turn Any Speaker into a Multi-Room Wireless Receiver" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg" alt="multi-room audio speakers snapcast" srcset="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-300x169.jpg 300w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-768x432.jpg 768w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-540x304.jpg 540w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-344x194.jpg 344w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-300x169.jpg 300w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-768x432.jpg 768w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-540x304.jpg 540w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-344x194.jpg 344w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/speaker-multi-room-wireless-receiver/" title="Related: Turn Any Speaker into a Multi-Room Wireless Receiver" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><div><p>Building a multi-room home audio system begins by making "dumb speakers smart." Like with Sonos, these DIY wireless receiver(s) can be grouped together and play music from many different sources using pulse audio + snapcast.</p></div></div></div></div></article><h2><span id="Building_the_Doorbell"></span>Building the Doorbell<span></span></h2><p>I had some spare copper and brass parts lying around from <a href="https://www.technicallywizardry.com/magic/" data-wpel-link="internal" rel="internal follow noopener noreferrer">prior steampunk projects</a>. This came in handy when not all of the electronics could easily fit in the junction box.</p><p>I began by laying out the parts. Three holes were drilled in the sides of the junction box for the power cable, USB cables, and button wires. Plus, one larger hole in the cover to accommodate the camera:</p><figure><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 719px) 100vw, 719px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg.webp 959w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-281x300.jpg.webp 281w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-768x820.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-1439x1536.jpg.webp 1439w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806.jpg.webp 1918w"><img src="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg" alt="assembling the raspberry pi parts to create a smart doorbell" width="719" height="768" title="Smart doorbell parts" srcset="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg 959w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-281x300.jpg 281w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-768x820.jpg 768w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-1439x1536.jpg 1439w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806.jpg 1918w" sizes="(max-width: 719px) 100vw, 719px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-959x1024.png" data-srcset="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg 959w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-281x300.jpg 281w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-768x820.jpg 768w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-1439x1536.jpg 1439w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806.jpg 1918w"></picture><figcaption>The raspberry pi inside the junction box, with holes drilled in the sides for cables.</figcaption></figure><p>Before sealing the parts, though, it was time to prototype the doorbell itself.</p><h2><span id="Ringing_the_Doorbell"></span>Ringing the Doorbell<span></span></h2><p>The first order of business was to make the doorbell actually ring.</p><p>With the doorbell wire attached to GPIO18 (pin 12) on the Raspberry Pi, I then used the <strong>Serial Port</strong> input in <a href="https://www.technicallywizardry.com/node-red-docker-kubernetes/" data-wpel-link="internal" rel="internal follow noopener noreferrer">Node RED</a> to detect button-presses. To actually trigger a doorbell alert, as well as handle bi-directional (microphone/intercom) audio, see this post:</p><article><div><a href="https://www.technicallywizardry.com/loudspeaker-network-intercoms-alerts/" title="Related: Loudspeaker Network &amp; Audio Alerts with Home Assistant" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg" alt="the doorbell broadcasts to the loudspeaker network via node red" srcset="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/loudspeaker-network-intercoms-alerts/" title="Related: Loudspeaker Network &amp; Audio Alerts with Home Assistant" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><div><p>Aside from playing music, a multi-room audio system is also capable of becoming a loudspeaker network. Using Home Assistant, it's easy to broadcast audio alerts to the entire household.</p></div></div></div></div></article><h2><span id="Motion_Sensor_Doorbell_Camera"></span>Motion Sensor Doorbell Camera<span></span></h2><p>There’s also the topic of motion detection and video.</p><p>In this regard, the doorbell is just another CCTV camera. It uses the exact same setup described in the following series of posts. The motion detection and object recognition is what generates the images like the one at the top of this post.</p><article><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" alt="" srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><p>Protect a home with DIY CCTV security cameras. Includes motion detection, automatic recording, recognition of people/cars, alerts, and more.</p></div></div></div></article><p>With the coding done, it was time to put all the parts together…</p><h2><span id="Smart_Lock_Integration"></span>Smart Lock Integration<span></span></h2><p>With the basics covered, it was time to assemble and mount everything:</p><figure><a href="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 698px) 100vw, 698px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg.webp 931w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-273x300.jpg.webp 273w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-768x845.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-1397x1536.jpg.webp 1397w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg.webp 1862w"><img src="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg" alt="steampunk themed raspberry pi doorbell assembled" width="698" height="768" title="Smart doorbell assembled" srcset="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg 931w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-273x300.jpg 273w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-768x845.jpg 768w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-1397x1536.jpg 1397w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg 1862w" sizes="(max-width: 698px) 100vw, 698px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-931x1024.png" data-srcset="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg 931w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-273x300.jpg 273w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-768x845.jpg 768w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-1397x1536.jpg 1397w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg 1862w"></picture></a><figcaption>Adding some random copper and brass parts to create a steampunk theme.</figcaption></figure><p>I used hot glue on the openings of the junction box to seal it, where possible. The copper ring seen above also has a lip, protecting the camera from water. Plus, the whole thing is installed underneath a balcony, so not much water even has the chance to hit the doorbell.</p><p>The final pieces was to integrate the doorbell with a smart lock. Thankfully, Home Assistant makes this easy. We have this Yale Assure lock:</p><p>It communicates with Home Assistant via Z-Wave. What I like about this lock is that it can be programmed remotely to support different user codes (useful as an Airbnb host, or when you need to let a friend in). It also can detect which user pin code was used to open the door (and when) — great peace of mind when giving cleaners a code to the house.</p><figure><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 947px) 100vw, 947px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png.webp 1262w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-300x227.png.webp 300w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-1024x776.png.webp 1024w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-768x582.png.webp 768w"><img src="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png" alt="home assistant motioneye camera" width="947" height="717" title="Home Assistant " srcset="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png 1262w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-300x227.png 300w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-1024x776.png 1024w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-768x582.png 768w" sizes="(max-width: 947px) 100vw, 947px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-947x717.png" data-srcset="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png 1262w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-300x227.png 300w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-1024x776.png 1024w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-768x582.png 768w"></picture><figcaption>Home Assistant connects to MotionEye to show the camera, motion alerts, and other detections.</figcaption></figure><p>But, most importantly, it can be locked/unlocked with a tap in Home Assistant.</p><h2><span id="Source_Code_Recap"></span>Source Code: Recap<span></span></h2><p>I wish I could give you copy-and-paste code for this project, but a lot of it will depend on your exact hardware, speakers, cameras, etc. Instead, I’ll recap each piece involved and link to the articles/code where I explain how to implement them:</p><ul><li><a href="https://www.technicallywizardry.com/node-red-docker-kubernetes/" data-wpel-link="internal" rel="internal follow noopener noreferrer">Node Red uses gpiod</a> to trigger a flow when GPIO #18 (the doorbell button) fires.</li><li>The <a href="https://www.technicallywizardry.com/loudspeaker-network-intercoms-alerts/" data-wpel-link="internal" rel="internal follow noopener noreferrer">loudspeaker alert flow plays a wav file</a>.</li><li>I have <a href="https://www.technicallywizardry.com/speaker-multi-room-wireless-receiver/" data-wpel-link="internal" rel="internal follow noopener noreferrer">multiple DIY speakers</a> that play the alert around the house.</li><li><a href="https://www.technicallywizardry.com/diy-dashcam-raspberry-pi-zero-w-motion-eye/" data-wpel-link="internal" rel="internal follow noopener noreferrer">MotionEye drives the camera</a>, capturing stills and videos.</li><li>The <a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" data-wpel-link="internal" rel="internal follow noopener noreferrer">CCTV Security Cameras</a> handle person/object detection.</li><li><a href="https://www.technicallywizardry.com/tag/home-assistant/" data-wpel-link="internal" rel="internal follow noopener noreferrer">Home Assistant’s</a> Yale Lock integration allows us to lock/unlock. The Yale lock is a <a href="https://www.home-assistant.io/integrations/zwave/" target="_blank" rel="noopener nofollow external noreferrer" data-wpel-link="external">Z-Wave</a> device. Once paired with Home Assistant, it shows up as a lock and requires no further configuration.</li></ul><article><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" alt="" srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><p>Protect a home with DIY CCTV security cameras. Includes motion detection, automatic recording, recognition of people/cars, alerts, and more.</p></div></div></div></article></div></article></div>]]>
            </description>
            <link>https://www.technicallywizardry.com/diy-smart-doorbell-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25225934</guid>
            <pubDate>Fri, 27 Nov 2020 06:13:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psiloscoby: Psilocybin Brewed by Kombucha]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25224721">thread link</a>) | @greyface-
<br/>
November 26, 2020 | https://invisible.college/project/psiloscoby | <a href="https://web.archive.org/web/*/https://invisible.college/project/psiloscoby">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://invisible.college/project/psiloscoby</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224721</guid>
            <pubDate>Fri, 27 Nov 2020 01:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thunderbird 78.x is great but has issues for advanced PGP users]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25224515">thread link</a>) | @djsumdog
<br/>
November 26, 2020 | https://www.sindastra.de/p/1583/dear-mozilla-why-thunderbird-78-x-is-both-great-and-awful-pgp/ | <a href="https://web.archive.org/web/*/https://www.sindastra.de/p/1583/dear-mozilla-why-thunderbird-78-x-is-both-great-and-awful-pgp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="#content">Skip to content</a>
<div id="boxed-wrapper">

<div id="wrapper">

<header>


</header>

<main id="main">
<div>
<section id="content">
<article id="post-1583">

<div>
<ul>
<li>
<img width="500" height="492" src="https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg.png" alt="Thunderbird Logo" srcset="https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg-200x197.png 200w, https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg-400x394.png 400w, https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg.png 500w" sizes="(max-width: 800px) 100vw, 500px"> </li>
</ul>
</div>
<div>
<p>I am writing this post because Thunderbird 78.x has issues for advanced PGP users. But first, I’d like to say a few words to all the frustrated users: I hear you, I too am displeased with this update, but while it’s easy to complain and rant, we should look at the bright side and still be grateful that Mozilla thought of including PGP, as it makes it more accessible to users that are not as tech-savvy. It’s always good to push for privacy and having it built-in, and easy to use! But, there are issues with the new built-in PGP that we should talk about…</p>
<h2>Preface</h2>
<p>You know, as I stated in <a href="https://www.sindastra.de/p/1566/open-letter-why-it-security-is-obvious-to-me/" target="_blank" rel="noreferrer noopener">my open letter</a>: Security and privacy is important to me. Of course, this means I use PGP, or more specifically, GnuPG with smartcards.</p>
<p>I like FOSS, especially if it’s cross-platform as I use Linux, Mac and Windows (alphabetical order, no preference stated) and it’s great to be able to use your software on all your machines across all systems, and for free! The popular email client, Thunderbird is one such application that meets these criteria, and so is GnuPG (or GPG for short), a popular application that implements the OpenPGP specification.</p>
<p>GnuPG has a ton of features, among those features is the support of smartcards. Keep this in mind.</p>
<p>Now, let’s take a look at the situation in Thunderbird before, and then since version 78.x and what we can do about it.</p>
<h2>The situation <em>before</em> version 78.x</h2>
<p>Before Thunderbird 78.x (namely 68.x), if you had both Thunderbird and GnuPG installed, all you had to do was to install a Thunderbird addon known as Enigmail. This addon basically bridged the gap between Thunderbird and GnuPG, and essentially allowed you to experience full PGP within Thunderbird.</p>
<p>Of course this meant you had to install GnuPG on your system, then an addon, then generate and manage keys, and – although powerful – it was overall not as user-friendly as it could be.</p>
<p>So, even I as an advanced user, was excited that Thunderbird would come with PGP built-in in 78.x as I thought they might ship it with GnuPG, and something like Enigmail but built-in and maybe more user-friendly. At the very least having no third-party things to install sounds better. And convenience is nice, right? But I was wrong.</p>
<h2>The situation <em>since</em> version 78.x</h2>
<p>You see, Mozilla, the people behind Thunderbird did not ship it with GnuPG. Instead, they use a library called RNP. This library does not provide full-featured PGP.</p>
<p>RNP does for example, not support the use of smartcards. Which, basically means no PGP at all for me or any user with smartcards. Thunderbird does currently also not support using subkeys with detached primary key. Which means any advanced user that did a proper, more secure PGP setup, can also not use PGP with Thunderbird for the time being.</p>
<p>So, you might think to yourself: Just install Enigmail! Well, here’s the thing: Enigmail does not work with Thunderbird 78.x!</p>
<p>Thunderbird 78.x has hidden settings in the advanced configuration editor, that you can use to tell it to use external GnuPG, which is great! Except it doesn’t really work…</p>
<p>It did not work for me, and I tried many things, on different systems, followed different guides (including the official Mozilla Wiki), and heard the same from other users through the fediverse. For a friend of mine, setting up Thunderbird to use external GnuPG on Windows made it outright crash whenever trying to open a PGP encrypted email!</p>
<p>And this is basically the problem. On one hand, Mozilla was cool enough to include (some) PGP in Thunderbird which in theory makes it more accessible as you can generate and use keys with a few clicks, which is also good for us advanced users as we can then email privately with friends that would otherwise be unable to use PGP. But on the other hand the execution was bad in such a way that it stabs all the advanced users that were already using (advanced setups of) PGP.</p>
<h2>What to do about it (for now)</h2>
<p>Honestly, my advice to anyone that uses Thunderbird and depends on advanced PGP (smartcard etc.) for now: Just downgrade to Thunderbird 68.x and install Enigmail. It seems it will still receive updates for now and there’s no forced update to 78.x (yet). I just tried, and got an (undocumented) update for the 68.x version (namely 68.12.1).</p>
<p>Let’s hope they will keep providing security updates for 68.x until they have (hopefully) sorted out PGP in version 78.x so that we will eventually be able to upgrade, but without being pushed into a broken environment prematurely.</p>
<p>You can get the latest version of 68.x from here (official download link): <a href="https://download-installer.cdn.mozilla.net/pub/thunderbird/releases/68.12.1/" target="_blank" rel="noreferrer noopener nofollow">https://download-installer.cdn.mozilla.net/pub/thunderbird/releases/68.12.1/</a></p>
<p>Please note that, Thunderbird will notice that the current configuration is from a newer version after downgrading, which you cannot use. This will result in a little window informing you about that on startup. Your only two options are to quit the application, or to create a new (configuration) profile. This means you will have to set up your accounts again but at least PGP will work again (with Enigmail and GnuPG)!</p>
<p>Thank you and goodnight! :D</p>
</div>
<section>

<div>

<div>
Sindastra is a software developer with 10 years of experience, specialized in backend web development. In her spare time she hacks on things and educates herself on a variety of topics. She likes to play Minecraft with friends and especially enjoys hacking on the game's server code. </div>
</div>
</section>


<p>This site uses Akismet to reduce spam. <a href="https://akismet.com/privacy/" target="_blank" rel="nofollow noopener">Learn how your comment data is processed</a>.</p> </article>
</section>

</div> 
</main> 
 

</div> 
</div> 



<a></a>




</div>]]>
            </description>
            <link>https://www.sindastra.de/p/1583/dear-mozilla-why-thunderbird-78-x-is-both-great-and-awful-pgp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224515</guid>
            <pubDate>Fri, 27 Nov 2020 00:22:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at Chang’e 5 telemetry]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25224446">thread link</a>) | @kwk1
<br/>
November 26, 2020 | https://destevez.net/2020/11/a-look-at-change-5-telemetry/ | <a href="https://web.archive.org/web/*/https://destevez.net/2020/11/a-look-at-change-5-telemetry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9213">
		<!-- .entry-header -->

	
	<div>
		
<p><a href="https://en.wikipedia.org/wiki/Chang%27e_5">Chang’e 5</a> is a Chinese lunar sample return mission. It was launched a few days ago on 2020-11-23 from <a href="https://en.wikipedia.org/wiki/Wenchang_Satellite_Launch_Center">Wenchang</a> and <a href="https://twitter.com/coastal8049/status/1331782149490413568">is estimated</a> to perform lunar orbit injection on Saturday. Since then, a number of Amateurs such as <a href="https://twitter.com/usa_satcom/status/1331092113069543425">USA Satcom</a>, <a href="https://twitter.com/uhf_satcom/status/1331317024992210944">Paul Marsh M0EYT</a>, <a href="https://twitter.com/coastal8049/status/1331138035891650560">Scott Tilley VE7TIL</a>, <a href="https://twitter.com/supertrack_it/status/1331354629146365953">Fer IW1DTU</a> and others have been receiving the X-band signals from the spacecraft and posting reports over on Twitter. Meanwhile, <a href="http://r00t.cz/">r00t.cz</a> has been working in <a href="https://twitter.com/r2x0t/status/1331097492482646016">decoding the frames</a>, which has led him to the amazing achievement of being able to <a href="http://www.r00t.cz/Sats/Change5">retrieve a short video</a> from the signal.</p>



<p>In this post I will look at some of the frames demodulated by USA Satcom and Paul during the first couple of days of the mission. The frame structure has many similarities with Tianwen-1, which I have described in several posts, such as <a href="https://destevez.net/2020/08/tianwen-1-telemetry-framing-and-data/" data-type="post" data-id="8773">here</a> and <a href="https://destevez.net/2020/08/tianwen-1-high-speed-data-signal/" data-type="post" data-id="8871">here</a>. However, there are some interesting differences.</p>



<h4>Low data rate telemetry</h4>



<p>The low data rate telemetry signal is a PCM/PSK/PM signal with a subcarrier rate of 65536 Hz and a baudrate of 2048 baud. The coding is CCSDS concatenated frames with a Reed-Solomon codeword size of 252 bytes, so that a frame takes 2 seconds to transmit. The Reed-Solomon code uses the dual basis, as specified in the <a href="https://public.ccsds.org/Pubs/131x0b3e1.pdf">TM Synchronization and Channel Coding</a> blue book. This is very similar to Tianwen-1’s low rate signal. The only differences are that Tianwen-1 uses a baudrate of 16384 baud (so frames take 0.25 seconds to transmit), and the conventional Reed-Solomon basis (which is not standard CCSDS).</p>



<p>Chang’e 5 has been seen to use <a href="https://twitter.com/coastal8049/status/1331782140900503556">a number of different frequencies</a> at X-band. Here I will be looking at some frames received by USA Satcom on 2020-11-24 between 4 and 6 UTC.</p>



<p>The frames are CCSDS <a href="https://public.ccsds.org/Pubs/732x0b3e1.pdf">AOS frames</a> coming from spacecraft ID 91. The spacecraft ID is quite relevant, because the spacecraft has different detachable modules: a service module, a return module, a lander, and an ascent module. Most likely each of these modules uses a different spacecraft ID, and we are in fact seeing data from different spacecraft IDs.</p>



<p>Two virtual channels are in use. Virtual channel 1 contains most of the data (a total of 5888 frames), while virtual channel 2 contains only 5 frames.</p>



<p>The AOS frames in both virtual channels have an insert zone that is 8 bytes long. The purpose of the first 4 bytes is unknown, while the last 4 bytes are a little-endian timestamp encoded as the number of seconds elapsed since 2012-08-01 00:00:00 UTC. It is interesting to compare this timestamp format with <a href="https://destevez.net/2020/07/more-about-the-tianwen-1-timestamps/" data-type="post" data-id="8734">that used in Tianwen-1</a>, which uses a 48 bit big-endian timestamp that encodes 100us units since 2016-01-01 00:00:00 Beijing time. The change from big-endian to little-endian is peculiar, since somehow the CCSDS protocols favour big-endian fields, and the change from a Beijing time epoch to a UTC epoch is also an interesting curiosity.</p>



<p>The M_PDU protocol is used to multiplex CCSDS <a href="https://public.ccsds.org/Pubs/133x0b2e1.pdf">Space Packets</a> in the AOS frames.</p>



<p>The figure below shows the timestamps and virtual channel frame counter in the frames from virtual channel 1. The gaps correspond to time gaps between the different files provided by USA Satcom.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1.png"><img loading="lazy" width="625" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1.png 625w, https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1-300x186.png 300w" sizes="(max-width: 625px) 100vw, 625px"></a></figure>



<p>The Space Packets in virtual channel 1 use many different APIDs. I have been browsing through the plots of the data in each of the APIDs and they look reminiscent of Tianwen-1. There are many analogue telemetry channels, but I haven’t been able to spot any that has an obvious meaning, and there doesn’t seem to be any floating point data as in Tianwen-1. Here I show a few of the most interesting APIDs.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid58.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-644x654.png" alt="" width="483" height="491" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-644x654.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-295x300.png 295w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-768x780.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid58.png 903w" sizes="(max-width: 483px) 100vw, 483px"></a></figure>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid524.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-644x654.png" alt="" width="483" height="491" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-644x654.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-295x300.png 295w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-768x780.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid524.png 903w" sizes="(max-width: 483px) 100vw, 483px"></a></figure>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid815.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-644x649.png" alt="" width="483" height="487" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-644x649.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-298x300.png 298w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-150x150.png 150w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-768x774.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-100x100.png 100w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815.png 910w" sizes="(max-width: 483px) 100vw, 483px"></a></figure>



<p>The five frames in virtual channel 2 were transmitted consecutively, perhaps in response to a telecommand. Each of them contains a single Space Packet from APID 897 that occupies all the frame.</p>



<p>The data from these Space Packets looks like some kind of file download or memory dump. The first 8 bytes contain three fixed bytes that maybe identify the file or the region of memory followed by a 5 byte little-endian chunk counter. The transfer here uses only 5 chunks, and most of the data in the last chunk is filled with <code>0xaa</code> padding bytes. The figure below shows the data in this transfer, with one chunk per row. The data clearly shows patterns, but I have no idea what it is.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_vc2.png"><img loading="lazy" width="644" height="187" src="https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-644x187.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-644x187.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-300x87.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-768x223.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_vc2.png 864w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Chang’e transfer in APID 897</figcaption></figure>



<p>The code and data used in this part of the post, including the full plots of all the APIDs, can be found in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/CE5/CE-5%20frame%20analysis.ipynb">this Jupyter notebook</a>.</p>



<h4>High data rate telemetry</h4>



<p>The high data rate telemetry uses 2.5Mbaud BPSK <a href="https://twitter.com/r2x0t/status/1331351055972642818">according to r00t</a>. Coding is, as in the case of <a href="https://destevez.net/2020/08/tianwen-1-high-speed-data-signal/">Tianwen-1 high data rate long frames</a>, concatenated CCSDS frames using four interleaved Reed-Solomon codewords (with 255 bytes each).</p>



<p>The data used here is a short segment received by Paul on 2020-11-24 between 20:52 and 20:58 UTC at 8455 MHz. It is quite interesting to see the errors corrected by the Reed-Solomon decoder, which show large variability but indicate that Paul has more than enough SNR margin to decode the signal.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_rs.png"><img loading="lazy" width="612" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_rs.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_rs.png 612w, https://destevez.net/wp-content/uploads/2020/11/ce5_rs-300x190.png 300w" sizes="(max-width: 612px) 100vw, 612px"></a></figure>



<p>The data consists of AOS frames from spacecraft ID 26 (note this is a different spacecraft ID to the one in the low rate data used in the previous part). Virtual channels 38 and 63 are in use, with 18396 and 51850 frames respectively.</p>



<p>In contrast to the AOS frames used for the low data rate telemetry, here the AOS insert zone is only 6 bytes long, with 2 unknown bytes that always contain the value <code>0xf0f0</code> followed by a 4 byte timestamp using the same format as in the low data rate frames. There is no M_PDU. The data follows directly after the insert zone.</p>



<p>Virtual channel 63 consists solely of idle data. This is a standard feature of the AOS Space Data Link protocol called OID channel (only idle data), which is always virtual channel 63. The data in the frames of this virtual channel is filled with <code>0xaa</code> padding.</p>



<p>The figure below shows the timestamps and frame counter in the OID channel.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid.png"><img loading="lazy" width="644" height="385" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid-644x385.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid-644x385.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid-300x179.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid.png 647w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The frame loss computed from the jumps in the virtual channel frame counter shows that very few frames were lost. The large jumps near the end correspond to a gap in Paul’s data, which is divided into two files.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss.png"><img loading="lazy" width="625" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss.png 625w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss-300x186.png 300w" sizes="(max-width: 625px) 100vw, 625px"></a></figure>



<p>Virtual channel 38 is quite interesting. I <a href="https://twitter.com/ea4gpz/status/1331711668045434886">joked on Twitter</a> that it resembles the Inception film, because it has several layers of CCSDS protocols. The timestamps in this virtual channel are quite weird, since comparing with the timestamps from the OID channel they seem to run too fast and extend into the future. There is no way that the 18396 frames in this virtual channel are able to span one hour and 30 minutes as shown here. I’m not sure what’s happening with this.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc.png"><img loading="lazy" width="644" height="385" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc-644x385.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc-644x385.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc-300x179.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc.png 647w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>This shows the first frames in virtual channel 38. We can discern the AOS headers, then two parts that seem quite similar, and then a large section of <code>0xaa</code> padding.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data.png"><img loading="lazy" width="644" height="173" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-644x173.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-644x173.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-300x80.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-768x206.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data.png 877w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The data field of each of these AOS frames contains a single Space Packet, which is embedded directly without using M_PDU. The length of the Space Packet is 510 bytes including its header, which explains why the end of the AOS frame is filled with padding. These Space Packets belong to APID 92.</p>



<p>The contents of each of these Space Packets are two back to back AOS frames, which explains the repetition in the figure below. The AOS frames belong to spacecraft ID 197 (yet a new spacecraft!), virtual channel ID 52, and have the replay flag set.</p>



<p>The insert zone of these replayed AOS frames contains three unknown bytes followed by a 32 bit timestamp in the usual format. The timestamps and frame counts are shown below. The replay data is actually from the previous day, starting just 30 minutes after launch.</p>



<figure><img loading="lazy" width="631" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_replay_fc.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_replay_fc.png 631w, https://destevez.net/wp-content/uploads/2020/11/ce5_replay_fc-300x184.png 300w" sizes="(max-width: 631px) 100vw, 631px"></figure>



<p>These AOS frames have a CRC-16, in contrast with the usual AOS frames, which rely on the Reed-Solomon parity check bytes for error detection. The CRC of all the replay frames I’ve decoded is correct.</p>



<p>These replay AOS frames use M_PDU, and contain Space Packets from APIDs 301 and 2047 (the idle APID). As expected, the idle APID packets contain only zeros. The data in APID 301 is shown in the figure below. I am not sure how to interpret it, but some of the structure is evident.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid301.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-644x640.png" alt="" width="644" height="640" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-644x640.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-300x298.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-150x150.png 150w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-768x763.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-100x100.png 100w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301.png 923w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The data and code used in this part of the post can be found in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/CE5/CE-5%20high-speed%20frame.ipynb">this Jupyter notebook</a>.</p>



<p>Thanks to all the Amateur community for keeping these kind of activities going with fresh interest after each lunch and best of luck to the Chinese Lunar Exploration Program with their very interesting and challenging mission.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://destevez.net/2020/11/a-look-at-change-5-telemetry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224446</guid>
            <pubDate>Fri, 27 Nov 2020 00:06:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tiny badge led to dozens of sales and hundreds of new followers]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25224369">thread link</a>) | @rosiesherry
<br/>
November 26, 2020 | https://jakobgreenfeld.com/badge | <a href="https://web.archive.org/web/*/https://jakobgreenfeld.com/badge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Oh boy, am I glad that I trusted my gut feeling.</p>

<p>You probably know the type of badge I’m talking about.  It’s tiny, lives in the lower-right corner of the screen and says something like “by Jakob Greenfeld”.</p>

<p><img src="https://jakobgreenfeld.com/images/tinybadge.png" alt=""></p>

<p>But not too many indie makers seem to be using it. I hesitated myself. It makes the fact that the project is an indie project immediately obvious. Hence the project will be perceived as less professional. Also it possibly distracts customers and might annoy some of them.</p>

<p>So there are lots of reasons why you shouldn’t include a badge and not really many objective ones why you should.</p>

<p>Nevertheless, I decided to include one on all of my pages. The main reason was that I instantly like a page more if it has such a badge (and not some annoying chat widget or whatever.) It shows me directly that I’m a looking at a project by a fellow indie maker. I really think of the badge as some kind of membership card for the indie maker club.</p>

<p>Okay, enough of this. You’re probably not here to hear about my sentimental feelings.</p>

<p>So let’s get back to the main story.</p>

<p>Now what happened is that yesterday I’m getting lots of new followers even though I didn’t write a single tweet. Also I’m getting lots of Gumroad notifications.</p>

<p><em>“You have a new subscriber for <a href="https://gumspy.com/">Gum Spy</a>”, “You have a new subscriber for Gum Spy”, “You have a new subscriber for Gum Spy”….</em></p>

<p>Cool, but strange. Something must be happening but I have no idea what.</p>

<p>Then I get a DM from <a href="https://twitter.com/TrevMcKendrick">Trevor McKendrick</a> (Chief of Staff @ Lambda School).</p>

<p><img src="https://jakobgreenfeld.com/images/dm.png" alt=""></p>

<p>Apparently, Sam Parr and Shaan Puri talked about me on <a href="https://www.myfirstmillionpodcast.com/">their podcast</a>. The show has hundreds of thousands of listeners. I’m just a guy with 600 Twitter followers who launched his first paid product 4 weeks ago. This is insane.</p>

<p>In the <a href="https://open.spotify.com/episode/496MjbRwFPa52tqdJBvC3m?si=QrBc05p3TlOgEFDl9iqRNA">episode</a>, Shaan mentions that he discovered my stuff because of a tiny badge in the lower-right corner on the Gum Spy landing page.</p>

<p>Without the badge, my site would’ve been just another faceless project. But thanks to the badge, Shaan was quickly able to see that I’m a “build in public type of guy”, that I’m currently doing a <a href="http://jakobgreenfeld.com/mba">Bootstrap MBA learning experiment</a>,  that I recently launched similar projects. And this is why he decided to give me a shoutout on the show.</p>

<p>You probably thought the title of this post is clickbait. It’s not.</p>

<p>I really made dozens of sales (still counting) and got hundreds of new <a href="https://twitter.com/jakobgreenfeld">Twitter followers</a> and <a href="https://productideas.substack.com/">newsletter subscribers</a> only thanks to the tiny badge.</p>

<p>So what’s the takeaway? Use a “made by” badge on your sites, obviously.</p>

<p>And no worries, I’m not trying to sell you some “made by” badge service. The code for the badge I’m using is <a href="https://gist.github.com/levelsio/9c531122e557da6282458bbc2a8e2aff">freely available</a> (thanks <a href="https://levels.ui/">Pieter</a>!) and is so simple that really anyone can use it.</p>

  </div></div>]]>
            </description>
            <link>https://jakobgreenfeld.com/badge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224369</guid>
            <pubDate>Thu, 26 Nov 2020 23:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Due to a problem with AWS, many "smart" vacuums or doorbells will stop working]]>
            </title>
            <description>
<![CDATA[
Score 412 | Comments 320 (<a href="https://news.ycombinator.com/item?id=25224220">thread link</a>) | @benryon
<br/>
November 26, 2020 | https://eminetra.com.au/people-cant-vacuum-or-use-their-doorbell-because-amazons-cloud-servers-are-down/74505/ | <a href="https://web.archive.org/web/*/https://eminetra.com.au/people-cant-vacuum-or-use-their-doorbell-because-amazons-cloud-servers-are-down/74505/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>There is a problem with Amazon Web Services (AWS). And unfortunately, for those who own AWS-dependent vacuums or doorbells, many of the so-called “smart” objects will stop working.</p> <p>AWS is the largest cloud hosting software in the world. Over a decade, Amazon’s products have become essentially the backbone of the Internet.</p> <p>And early Thursday morning Australian time, problems began to occur at one of the major server centers. This is not the first time either.</p> <blockquote data-width="500" data-dnt="true"> <p lang="en" dir="ltr">AWS cloudwatch us-east-1 <a rel="nofollow" href="https://t.co/N04zQovN6C">pic.twitter.com/N04zQovN6C</a></p> <p>— Barry O’Neill (@barry_oneill) <a rel="nofollow" href="https://twitter.com/barry_oneill/status/1331595295487094784?ref_src=twsrc%5Etfw">November 25, 2020</a></p> </blockquote> <p>Immediately after people noticed, Amazon <a rel="nofollow" href="https://twitter.com/AWSSupport/status/1331687607172993024">Admitted</a> Internal dashboard issues for users.</p> <p>“We are still working on resolving issues affecting the Kinesis Data Streams API in the US-EAST-1 region, and the error rates for Kinesis and some of the affected services continue to improve. However, a full recovery is expected to take up to several hours. “</p> <p>Many of the services you know and love (Adobe Cloud Software, 1Password, Flickr) are all having problems due to outages.</p> <p>However, there were some unexpected issues as well. In short, many began to realize that they didn’t realize that the cloud computing they needed was really very dependent.</p> <p>First, the vacuum cleaner robot Roomba, which is loved by people, has stopped functioning.</p> <p>One user complained about Amazon, saying, “Part of AWS seems to be down and ruining Roomba.”</p> <blockquote data-width="500" data-dnt="true"> <p lang="en" dir="ltr">Some parts of AWS are down and seem to be ruining Roomba.</p> <p>— Matthew Green (@matthew_d_green) <a rel="nofollow" href="https://twitter.com/matthew_d_green/status/1331701425282437124?ref_src=twsrc%5Etfw">November 25, 2020</a></p> </blockquote> <p>Roomba’s manufacturer, iRobot, has confirmed that they are no longer functioning (along with robot mops).</p> <blockquote data-width="500" data-dnt="true"> <p lang="en" dir="ltr">The Amazon AWS outage is currently affecting the iRobot Home app. Our team is aware of the situation and is monitoring it and wants the app to come back online soon. We appreciate your understanding and cooperation.</p> <p>— IRobot (@iRobot) <a rel="nofollow" href="https://twitter.com/iRobot/status/1331667670383685635?ref_src=twsrc%5Etfw">November 25, 2020</a></p> </blockquote> <p>And then the doorbell came:</p> <p>“”<span>My doorbell doesn’t work because of a problem with AWS us-east-1, “another user tweeted.</span></p> <blockquote data-width="500" data-dnt="true"> <p lang="en" dir="ltr">My doorbell doesn’t work because of a problem with AWS us-east-1 ???????? ‍♂️</p> <p>— SJP (ಠ_ಠ) (@ SJP1804) <a rel="nofollow" href="https://twitter.com/SJP1804/status/1331643504443928578?ref_src=twsrc%5Etfw">November 25, 2020</a></p> </blockquote> <p>Some people have lost control of the Christmas illuminations!</p> <p>“Is there anyone else who can’t turn on Christmas lights because of AWS outages?” Asked a Twitter user.</p> <blockquote data-width="500" data-dnt="true"> <p lang="en" dir="ltr">Is there anyone else who can’t turn on Christmas lights because of AWS outages?</p> <p>— Brian Ragazzi (@brianragazzi) <a rel="nofollow" href="https://twitter.com/brianragazzi/status/1331682150542872578?ref_src=twsrc%5Etfw">November 25, 2020</a></p> </blockquote> <p>What we can do now is probably not a good idea to rely on the same company for half of our Internet infrastructure.</p> </div><p> People Can’t Vacuum Or Use Their Doorbell Because Amazon’s Cloud Servers Are Down <a href="https://www.gizmodo.com.au/2020/11/people-cant-vacuum-or-use-their-doorbell-because-amazons-web-services-cloud-servers-are-down/">Source link </a> People Can’t Vacuum Or Use Their Doorbell Because Amazon’s Cloud Servers Are Down</p></div>]]>
            </description>
            <link>https://eminetra.com.au/people-cant-vacuum-or-use-their-doorbell-because-amazons-cloud-servers-are-down/74505/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224220</guid>
            <pubDate>Thu, 26 Nov 2020 23:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risp (In (Rust) (Lisp))]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25222750">thread link</a>) | @leanthonyrn
<br/>
November 26, 2020 | https://stopa.io/post/222 | <a href="https://web.archive.org/web/*/https://stopa.io/post/222">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span><p>Many years ago, Peter Norvig wrote a beautiful article <a href="http://norvig.com/lispy.html" target="_blank">about creating a lisp interpreter in Python</a>. It’s the most fun tutorial I’ve seen, not just because it teaches you about my favorite language family (Lisp), but because it cuts through to the essence of interpreters, is fun to follow and quick to finish.</p><p>Recently, I had some time and wanted to learn Rust. It’s a beautiful systems language, and I’ve seen some great work come out from those who adopt it. I thought, <em>what better way to learn Rust, than to create a lisp interpreter in it?</em></p><p><strong>Hence, Risp — a lisp in rust — was born.</strong> In this essay you and I will follow along with <a href="http://norvig.com/lispy.html" target="_blank">Norvig’s Lispy</a>, but instead of Python, we’ll do it in Rust 🙂.</p><p>If you haven’t heard of lisp, some Paul Graham’s essays (<a href="http://www.paulgraham.com/progbot.html" target="_blank">one</a>, <a href="http://www.paulgraham.com/diff.html" target="_blank">two</a>, <a href="http://www.paulgraham.com/avg.html" target="_blank">three</a>), alongside some <a href="https://m.stopa.io/favorite-rich-hickey-talks-6bcb23da6ff2" target="_blank">Rich Hickey talks</a> will get you fired up. In short, everything is a list, everything is an expression, and that makes for a very powerful language.</p><p>Our structure will be similar to Norvig’s tutorial, though I depart slightly in two ways:</p><ol><li>Instead of 2 stopping points (Lispy Calculator and Full Lispy), we have 4 stopping points. This reflects the phases I took to build it in Rust.</li><li>Norvig’s syntax is based on Scheme. We will base it on Scheme too, but since I’m also a Clojure fan, I sometimes used slightly different naming, and different implementations for a few functions. I will note when I do that in the essay.</li></ol><p>Finally, this is the first program I wrote in Rust. I may have misused some things, so if you’re a Rust hacker, I’d love to hear your feedback 🙂.</p><p>With the notes out of the way, let’s get into it.</p><p>As Norvig suggests, our first goal is to create a subset of lisp, that can do what a basic calculator can do.</p><p>To make it as simple as possible to follow, for language 1, <strong>we’ll <em>only</em> support addition and subtraction.</strong> No variable definitions, no if statements, nada.</p><p>This departs a bit from Lispy, but I found this stopping point a lot more convenient when writing it in Rust. So, our goal:</p><pre><code><span>(</span><span>+</span><span> </span><span>10</span><span> </span><span>5</span><span> </span><span>2</span><span>)</span><span>//=&gt; 17</span>
<span>(</span><span>-</span><span> </span><span>10</span><span> </span><span>5</span><span> </span><span>2</span><span>) </span><span>//=&gt; 3</span></code></pre><p>The important process we need to remember is the flow of an interpreter:</p><p><em>our program</em> ⟶ <em><strong>parse</strong></em> ⟶ <em>abstract syntax tree</em> ⟶ <em><strong>eval</strong></em> ⟶ <em>result</em></p><p>We will need to <strong>parse</strong> our program and convert it into an abstract syntax tree. After that, we can <strong>eval</strong> the abstract syntax tree and get our result. (Refer to Norvig’s article for more detailed definitions and explanations).</p><h2 id="type-definitions">Type Definitions</h2><p>Risp can have three kinds of values for now:</p><pre><code><span>#[derive(Clone)]</span>
<span>enum</span><span> </span><span>RispExp</span><span> {</span>
<span>  </span><span>Symbol</span><span>(</span><span>String</span><span>),</span>
<span>  </span><span>Number</span><span>(</span><span>f64</span><span>),</span>
<span>  </span><span>List</span><span>(</span><span>Vec</span><span>&lt;</span><span>RispExp</span><span>&gt;</span><span>),</span>
<span>} </span></code></pre><p>We’ll also need an error type. We’ll keep this simple, but if you’re curious there <em>is</em> a <a href="https://news.ycombinator.com/item?id=19812159" target="_blank">more robust approach</a>.</p><pre><code><span>#[derive(Debug)]</span>
<span>enum</span><span> </span><span>RispErr</span><span> {</span>
<span>  </span><span>Reason</span><span>(</span><span>String</span><span>),</span>
<span>}</span></code></pre><p>Finally, we’ll need an <em>environment</em> type. This is where we will store defined variables, built-in functions, and so forth:</p><pre><code><span>#[derive(Clone)]</span>
<span>struct</span><span> </span><span>RispEnv</span><span> {</span>
<span>  data: HashMap</span><span>&lt;</span><span>String</span><span>, RispExp</span><span>&gt;</span><span>,</span>
<span>}</span></code></pre><h2 id="parsing">Parsing</h2><p>Our goal is to take our program, and build an abstract syntax tree from it. For us, that is going to be a <code>RispExp</code>. To do this, first we will take our program, and cut it up into a bunch of tokens:</p><pre><code><span>tokenize(</span><span>"(+ 10 5)"</span><span>) </span><span>//=&gt; ["(", "+", "10", "5", ")"]</span></code></pre><p>Here’s how we can do that in Rust:</p><pre><code><span>fn</span><span> </span><span>tokenize</span><span>(expr: </span><span>String</span><span>) -&gt; </span><span>Vec</span><span>&lt;</span><span>String</span><span>&gt; {</span>
<span>  expr</span>
<span>    .</span><span>replace</span><span>(</span><span>"("</span><span>, </span><span>" ( "</span><span>)</span>
<span>    .</span><span>replace</span><span>(</span><span>")"</span><span>, </span><span>" ) "</span><span>)</span>
<span>    .</span><span>split_whitespace</span><span>()</span>
<span>    .</span><span>map</span><span>(</span><span>|</span><span>x</span><span>|</span><span> x.</span><span>to_string</span><span>())</span>
<span>    .</span><span>collect</span><span>()</span>
<span>}</span></code></pre><p>Then, we can parse these tokens, into a <code>RispExp</code>:</p><pre><code><span>fn</span><span> </span><span>parse</span><span>&lt;</span><span>'a</span><span>&gt;(tokens: &amp;</span><span>'a</span><span> [</span><span>String</span><span>]) -&gt; </span><span>Result</span><span>&lt;(RispExp, &amp;</span><span>'a</span><span> [</span><span>String</span><span>]), RispErr&gt; {</span>
<span>  </span><span>let</span><span> (token, rest) </span><span>=</span><span> tokens.</span><span>split_first</span><span>()</span>
<span>    .</span><span>ok_or</span><span>(</span>
<span>      RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"could not get token"</span><span>.</span><span>to_string</span><span>())</span>
<span>    )?;</span>
<span>  </span><span>match</span><span> </span><span>&amp;</span><span>token[..] {</span>
<span>    </span><span>"("</span><span> </span><span>=&gt;</span><span> </span><span>read_seq</span><span>(rest),</span>
<span>    </span><span>")"</span><span> </span><span>=&gt;</span><span> </span><span>Err</span><span>(RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"unexpected `)`"</span><span>.</span><span>to_string</span><span>())),</span>
<span>    _ </span><span>=&gt;</span><span> </span><span>Ok</span><span>((</span><span>parse_atom</span><span>(token), rest)),</span>
<span>  }</span>
<span>}</span></code></pre><p><strong><em>Note:</em></strong> <em>I depart slightly from Norvig’s implementation, by returning the “next” slice. This lets us recurse and parse nested lists, without mutating the original list.</em></p><p>We get the token for the current position. If it’s the beginning of a list “(“, we start reading and parsing the tokens that follow, until we hit a closing parenthesis:</p><pre><code><span>fn</span><span> </span><span>read_seq</span><span>&lt;</span><span>'a</span><span>&gt;(tokens: &amp;</span><span>'a</span><span> [</span><span>String</span><span>]) -&gt; </span><span>Result</span><span>&lt;(RispExp, &amp;</span><span>'a</span><span> [</span><span>String</span><span>]), RispErr&gt; {</span>
<span>  </span><span>let</span><span> </span><span>mut</span><span> res: </span><span>Vec</span><span>&lt;</span><span>RispExp</span><span>&gt;</span><span> </span><span>=</span><span> </span><span>vec!</span><span>[];</span>
<span>  </span><span>let</span><span> </span><span>mut</span><span> xs </span><span>=</span><span> tokens;</span>
<span>  </span><span>loop</span><span> {</span>
<span>    </span><span>let</span><span> (next_token, rest) </span><span>=</span><span> xs</span>
<span>      .</span><span>split_first</span><span>()</span>
<span>      .</span><span>ok_or</span><span>(RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"could not find closing `)`"</span><span>.</span><span>to_string</span><span>()))</span>
<span>      ?;</span>
<span>    </span><span>if</span><span> next_token </span><span>==</span><span> </span><span>")"</span><span> {</span>
<span>      </span><span>return</span><span> </span><span>Ok</span><span>((RispExp</span><span>::</span><span>List</span><span>(res), rest)) </span><span>// skip `)`, head to the token after</span>
<span>    }</span>
<span>    </span><span>let</span><span> (exp, new_xs) </span><span>=</span><span> </span><span>parse</span><span>(</span><span>&amp;</span><span>xs)?;</span>
<span>    res.</span><span>push</span><span>(exp);</span>
<span>    xs </span><span>=</span><span> new_xs;</span>
<span>  }</span>
<span>}</span></code></pre><p>If it’s a closing tag of a list “)”, we return an error, as read_seq should have skipped past it.</p><p>Otherwise, it can only be an atom, so we parse that:</p><pre><code><span>fn</span><span> </span><span>parse_atom</span><span>(token: </span><span>&amp;</span><span>str</span><span>) -&gt; RispExp {      </span>
<span>  </span><span>let</span><span> potential_float: </span><span>Result</span><span>&lt;</span><span>f64</span><span>, ParseFloatError</span><span>&gt;</span><span> </span><span>=</span><span> token.</span><span>parse</span><span>();</span>
<span>  </span><span>match</span><span> potential_float {</span>
<span>    </span><span>Ok</span><span>(v) </span><span>=&gt;</span><span> RispExp</span><span>::</span><span>Number</span><span>(v),</span>
<span>    </span><span>Err</span><span>(_) </span><span>=&gt;</span><span> RispExp</span><span>::</span><span>Symbol</span><span>(token.</span><span>to_string</span><span>().</span><span>clone</span><span>())</span>
<span>  }</span>
<span>}</span></code></pre><h2 id="environment">Environment</h2><p>Let’s go ahead and create the default, global environment. As Norvig explains, environments are where we will store variable definitions and built-in functions.</p><p>To implement built-in operations <code>(+, -)</code>, we need a way to save rust function references. Let’s update <code>RispExp</code>, so that we can store rust function references:</p><pre><code><span>#[derive(Clone)]</span>
<span>enum</span><span> </span><span>RispExp</span><span> {</span>
<span>  </span><span>Symbol</span><span>(</span><span>String</span><span>),</span>
<span>  </span><span>Number</span><span>(</span><span>f64</span><span>),</span>
<span>  </span><span>List</span><span>(</span><span>Vec</span><span>&lt;</span><span>RispExp</span><span>&gt;</span><span>),</span>
<span>  </span><span>Func</span><span>(</span><span>fn</span><span>(</span><span>&amp;</span><span>[RispExp]) </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>RispExp, RispErr</span><span>&gt;</span><span>), </span><span>// bam</span>
<span>}</span></code></pre><p>Then, we can create a <code>default_env</code> function, that returns a <code>RispEnv</code>, which implements +, and -</p><pre><code><span>fn</span><span> </span><span>default_env</span><span>() -&gt; RispEnv {</span>
<span>  </span><span>let</span><span> </span><span>mut</span><span> data: HashMap</span><span>&lt;</span><span>String</span><span>, RispExp</span><span>&gt;</span><span> </span><span>=</span><span> HashMap</span><span>::</span><span>new</span><span>();</span>
<span>  data.</span><span>insert</span><span>(</span>
<span>    </span><span>"+"</span><span>.</span><span>to_string</span><span>(), </span>
<span>    RispExp</span><span>::</span><span>Func</span><span>(</span>
<span>      </span><span>|</span><span>args: </span><span>&amp;</span><span>[RispExp]</span><span>|</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>RispExp, RispErr</span><span>&gt;</span><span> {</span>
<span>        </span><span>let</span><span> sum </span><span>=</span><span> </span><span>parse_list_of_floats</span><span>(args)?.</span><span>iter</span><span>().</span><span>fold</span><span>(</span><span>0.0</span><span>, </span><span>|</span><span>sum, a</span><span>|</span><span> sum </span><span>+</span><span> a);</span>
<span>        </span>
<span>        </span><span>Ok</span><span>(RispExp</span><span>::</span><span>Number</span><span>(sum))</span>
<span>      }</span>
<span>    )</span>
<span>  );</span>
<span>  data.</span><span>insert</span><span>(</span>
<span>    </span><span>"-"</span><span>.</span><span>to_string</span><span>(), </span>
<span>    RispExp</span><span>::</span><span>Func</span><span>(</span>
<span>      </span><span>|</span><span>args: </span><span>&amp;</span><span>[RispExp]</span><span>|</span><span> </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>RispExp, RispErr</span><span>&gt;</span><span> {</span>
<span>        </span><span>let</span><span> floats </span><span>=</span><span> </span><span>parse_list_of_floats</span><span>(args)?;</span>
<span>        </span><span>let</span><span> first </span><span>=</span><span> </span><span>*</span><span>floats.</span><span>first</span><span>().</span><span>ok_or</span><span>(RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"expected at least one number"</span><span>.</span><span>to_string</span><span>()))?;</span>
<span>        </span><span>let</span><span> sum_of_rest </span><span>=</span><span> floats[</span><span>1</span><span>..].</span><span>iter</span><span>().</span><span>fold</span><span>(</span><span>0.0</span><span>, </span><span>|</span><span>sum, a</span><span>|</span><span> sum </span><span>+</span><span> a);</span>
<span>        </span>
<span>        </span><span>Ok</span><span>(RispExp</span><span>::</span><span>Number</span><span>(first </span><span>-</span><span> sum_of_rest))</span>
<span>      }</span>
<span>    )</span>
<span>  );</span>
<span>  </span>
<span>  RispEnv {data}</span>
<span>}</span></code></pre><p><strong><em>Note:</em></strong> <em>I am following Clojure’s spec for + and -.</em></p><p>To make this simpler, I made a quick helper, which enforces that all <code>RispExp</code> that we receive are floats:</p><pre><code><span>fn</span><span> </span><span>parse_list_of_floats</span><span>(args: </span><span>&amp;</span><span>[RispExp]) -&gt; </span><span>Result</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>f64</span><span>&gt;, RispErr&gt; {</span>
<span>  args</span>
<span>    .</span><span>iter</span><span>()</span>
<span>    .</span><span>map</span><span>(</span><span>|</span><span>x</span><span>|</span><span> </span><span>parse_single_float</span><span>(x))</span>
<span>    .</span><span>collect</span><span>()</span>
<span>}</span>
<!-- -->
<span>fn</span><span> </span><span>parse_single_float</span><span>(exp: </span><span>&amp;</span><span>RispExp) -&gt; </span><span>Result</span><span>&lt;</span><span>f64</span><span>, RispErr&gt; {</span>
<span>  </span><span>match</span><span> exp {</span>
<span>    RispExp</span><span>::</span><span>Number</span><span>(num) </span><span>=&gt;</span><span> </span><span>Ok</span><span>(</span><span>*</span><span>num),</span>
<span>    _ </span><span>=&gt;</span><span> </span><span>Err</span><span>(RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"expected a number"</span><span>.</span><span>to_string</span><span>())),</span>
<span>  }</span>
<span>}</span></code></pre><h2 id="evaluation">Evaluation</h2><p>Now, time to implement <strong>eval.</strong></p><p>If it’s a symbol, we’ll query for that symbol in the environment and return it (for now, it should be a <code>RispExp::Func</code>)</p><p>If it’s a number, we’ll simply return it.</p><p>If it’s a list, we’ll evaluate the first form. It should be a <code>RispExp::Func</code>. Then, we’ll call that function with all the other evaluated forms as the arguments.</p><pre><code><span>fn</span><span> </span><span>eval</span><span>(exp: </span><span>&amp;</span><span>RispExp, env: </span><span>&amp;</span><span>mut</span><span> RispEnv) -&gt; </span><span>Result</span><span>&lt;RispExp, RispErr&gt; {</span>
<span>  </span><span>match</span><span> exp {</span>
<span>    RispExp</span><span>::</span><span>Symbol</span><span>(k) </span><span>=&gt;</span>
<span>        env.data.</span><span>get</span><span>(k)</span>
<span>        .</span><span>ok_or</span><span>(</span>
<span>          RispErr</span><span>::</span><span>Reason</span><span>(</span>
<span>            </span><span>format!</span><span>(</span><span>"unexpected symbol k='{}'"</span><span>, k)</span>
<span>          )</span>
<span>        )</span>
<span>        .</span><span>map</span><span>(</span><span>|</span><span>x</span><span>|</span><span> x.</span><span>clone</span><span>())</span>
<span>    ,</span>
<span>    RispExp</span><span>::</span><span>Number</span><span>(_a) </span><span>=&gt;</span><span> </span><span>Ok</span><span>(exp.</span><span>clone</span><span>()),</span>
<span>    RispExp</span><span>::</span><span>List</span><span>(list) </span><span>=&gt;</span><span> {</span>
<span>      </span><span>let</span><span> first_form </span><span>=</span><span> list</span>
<span>        .</span><span>first</span><span>()</span>
<span>        .</span><span>ok_or</span><span>(RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"expected a non-empty list"</span><span>.</span><span>to_string</span><span>()))?;</span>
<span>      </span><span>let</span><span> arg_forms </span><span>=</span><span> </span><span>&amp;</span><span>list[</span><span>1</span><span>..];</span>
<span>      </span><span>let</span><span> first_eval </span><span>=</span><span> </span><span>eval</span><span>(first_form, env)?;</span>
<span>      </span><span>match</span><span> first_eval {</span>
<span>        RispExp</span><span>::</span><span>Func</span><span>(f) </span><span>=&gt;</span><span> {</span>
<span>          </span><span>let</span><span> args_eval </span><span>=</span><span> arg_forms</span>
<span>            .</span><span>iter</span><span>()</span>
<span>            .</span><span>map</span><span>(</span><span>|</span><span>x</span><span>|</span><span> </span><span>eval</span><span>(x, env))</span>
<span>            .</span><span>collect</span><span>::</span><span>&lt;</span><span>Result</span><span>&lt;</span><span>Vec</span><span>&lt;RispExp&gt;, RispErr&gt;&gt;();</span>
<span>          </span><span>f</span><span>(</span><span>&amp;</span><span>args_eval?)</span>
<span>        },</span>
<span>        _ </span><span>=&gt;</span><span> </span><span>Err</span><span>(</span>
<span>          RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"first form must be a function"</span><span>.</span><span>to_string</span><span>())</span>
<span>        ),</span>
<span>      }</span>
<span>    },</span>
<span>    RispExp</span><span>::</span><span>Func</span><span>(_) </span><span>=&gt;</span><span> </span><span>Err</span><span>(</span>
<span>      RispErr</span><span>::</span><span>Reason</span><span>(</span><span>"unexpected form"</span><span>.</span><span>to_string</span><span>())</span>
<span>    ),</span>
<span>  }</span>
<span>}</span></code></pre><p><strong>Aand, bam, we have eval.</strong></p><h2 id="repl">Repl</h2><p>Now, to make this fun and interactive, let’s make a repl.</p><p>We first need a way to convert our <code>RispExp</code> to a string. Let’s implement the <code>Display</code> trait</p><pre><code><span>impl</span><span> </span><span>fmt</span><span>::</span><span>Display</span><span> </span><span>for</span><span> </span><span>RispExp</span><span> {</span>
<span>  </span><span>fn</span><span> </span><span>fmt</span><span>(</span><span>&amp;</span><span>self</span><span>, f: </span><span>&amp;</span><span>mut</span><span> fmt::Formatter) -&gt; fmt::</span><span>Result</span><span> {</span>
<span>    </span><span>let</span><span> </span><span>str</span><span> </span><span>=</span><span> </span><span>match</span><span> </span><span>self</span><span> {</span>
<span>      RispExp</span><span>::</span><span>Symbol</span><span>(s) </span><span>=&gt;</span><span> s.</span><span>clone</span><span>(),</span>
<span>      RispExp</span><span>::</span><span>Number</span><span>(n) </span><span>=&gt;</span><span> n.</span><span>to_string</span><span>(),</span>
<span>      RispExp</span><span>::</span><span>List</span><span>(list) </span><span>=&gt;</span><span> {</span>
<span>        </span><span>let</span><span> xs: </span><span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span> </span><span>=</span><span> list</span>
<span>          .</span><span>iter</span><span>()</span>
<span>          .</span><span>map</span><span>(</span><span>|</span><span>x</span><span>|</span><span> x.</span><span>to_string</span><span>())</span>
<span>          .</span><span>collect</span><span>();</span>
<span>        </span><span>format!</span><span>(</span><span>"({})"</span><span>, xs.</span><span>join</span><span>(</span><span>","</span><span>))</span>
<span>      },</span>
<span>      RispExp</span><span>::</span><span>Func</span><span>(_) </span><span>=&gt;</span><span> </span><span>"Function {}"</span><span>.</span><span>to_string</span><span>(),</span>
<span>    };</span>
<span>    </span>
<span>    </span><span>write!</span><span>(f, </span><span>"{}"</span><span>, </span><span>str</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Then, let’s tie the interpreter process into a loop</p><pre><code><span>fn</span><span> </span><span>parse_eval</span><span>(expr: </span><span>String</span><span>, env: </span><span>&amp;</span><span>mut</span><span> RispEnv) -&gt; </span><span>Result</span><span>&lt;RispExp, RispErr&gt; {</span>
<span>  </span><span>let</span><span> (parsed_exp, _) </span><span>=</span><span> </span><span>parse</span><span>(</span><span>&amp;</span><span>tokenize</span><span>(expr))?;</span>
<span>  </span><span>let</span><span> evaled_exp </span><span>=</span><span> </span><span>eval</span><span>(</span><span>&amp;</span><span>parsed_exp, env)?;</span>
<span>  </span>
<span>  </span><span>Ok</span><span>(evaled_exp)</span>
<span>}</span>
<!-- -->
<span>fn</span><span> </span><span>slurp_expr</span><span>() -&gt; </span><span>String</span><span> {</span>
<span>  </span><span>let</span><span> </span><span>mut</span><span> expr </span><span>=</span><span> </span><span>String</span><span>::</span><span>new</span><span>();</span>
<span>  </span>
<span>  io</span><span>::</span><span>stdin</span><span>().</span><span>read_line</span><span>(</span><span>&amp;</span><span>mut</span><span> expr)</span>
<span>    .</span><span>expect</span><span>(</span><span>"Failed to read line"</span><span>);</span>
<span>  </span>
<span>  expr</span>
<span>}</span>
<!-- -->
<span>fn</span><span> </span><span>main</span><span>() {</span>
<span>  </span><span>let</span><span> env </span><span>=</span><span> </span><span>&amp;</span><span>mut</span><span> </span><span>default_env</span><span>();</span>
<span>  </span><span>loop</span><span> {</span>
<span>    </span><span>println!</span><span>(</span><span>"risp &gt;"</span><span>);</span>
<span>    </span><span>let</span><span> expr </span><span>=</span><span> </span><span>slurp_expr</span><span>();</span>
<span>    </span><span>match</span><span> </span><span>parse_eval</span><span>(expr, env) {</span>
<span>      </span><span>Ok</span><span>(res) </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"// 🔥 =&gt; {}"</span><span>, res),</span>
<span>      </span><span>Err</span><span>(e) </span><span>=&gt;</span><span> </span><span>match</span><span> e {</span>
<span>        RispErr</span><span>::</span><span>Reason</span><span>(msg) </span><span>=&gt;</span><span> </span><span>println!</span><span>(</span><span>"// 🙀 =&gt; {}"</span><span>, msg),</span>
<span>      },</span>
<span>    }</span>
<span>  }</span>
<span>}</span></code></pre><h2 id="aand-voila-language-10-is-done-heres-the-code-so-far-">Aand, voila, language 1.0 is done. <a href="https://gist.github.com/stopachka/22b4b06b8263687d7178f61fb22e1bf2" target="_blank">Here’s the code so far</a> 🙂</h2><p>We can now add and subtract!</p><pre><code><span>risp </span><span>&gt;</span>
<span>(</span><span>+</span><span> </span><span>10</span><span> </span><span>5</span><span> (</span><span>-</span><span> </span><span>10</span><span> </span><span>3</span><span> </span><span>3</span><span>))</span>
<span>// 🔥 =&gt; 19</span></code></pre><p>Okay, we have a basic calculator. Now, let’s add support for booleans, and introduce some equality comparators.</p><p>To implement bools, let’s include it in our <code>RispExp</code></p><pre><code><span>#[derive(Clone)]</span>
<span>enum</span><span> </span><span>RispExp</span><span> {</span>
<span>  </span><span>Bool</span><span>(</span><span>bool</span><span>), </span><span>// bam</span>
<span>  </span><span>Symbol</span><span>(</span><span>String</span><span>),</span>
<span>  </span><span>Number</span><span>(</span><span>f64</span><span>),</span>
<span>  </span><span>List</span><span>(</span><span>Vec</span><span>&lt;</span><span>RispExp</span><span>&gt;</span><span>),</span>
<span>  </span><span>Func</span><span>(</span><span>fn</span><span>(</span><span>&amp;</span><span>[RispExp]) </span><span>-&gt;</span><span> </span><span>Result</span><span>&lt;</span><span>RispExp, RispErr</span><span>&gt;</span><span>),</span>
<span>}</span></code></pre><p>Rust will tell us to update <code>Display</code></p><pre><code><span>impl</span><span> </span><span>fmt</span><span>::</span><span>Display</span><span> </span><span>for</span><span> </span><span>RispExp</span><span> {</span>
<span>  </span><span>fn</span><span> </span><span>fmt</span><span>(</span><span>&amp;</span><span>self</span><span>, f: </span><span>&amp;</span><span>mut</span><span> …</span></code></pre></span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/222">https://stopa.io/post/222</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/222</link>
            <guid isPermaLink="false">hacker-news-small-sites-25222750</guid>
            <pubDate>Thu, 26 Nov 2020 19:08:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five Second Feedback]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25221812">thread link</a>) | @mcrittenden
<br/>
November 26, 2020 | https://critter.blog/2020/11/26/5-second-feedback/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/11/26/5-second-feedback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-3448">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>The book <a href="https://www.goodreads.com/book/show/27316166-the-effective-manager">The Effective Manager</a> says you only need 5 to 15 seconds to deliver effective feedback. Here are the 4 steps:</p>



<ol><li>Ask (“Can I give you some feedback?”)</li><li>State the behavior (“When you X…”)</li><li>State the impact (“…the result is Y.”)</li><li>Encourage effective future behavior (“Keep it up!” for positive feedback or “Can you change that?” for negative feedback)</li></ol>



<p>Those steps should be followed whether you’re giving positive or negative feedback. </p>



<p>Here’s an example, pasted from the book:</p>



<blockquote><p><strong>Manager</strong>: Can I give you some feedback?<br><strong>Direct</strong>: Sure, boss.<br><strong>Manager</strong>: When you tell my boss bad news before me, even with the best of intentions, I end up getting in a lot of trouble for not knowing before he did. Can you try to tell me first, going forward?</p></blockquote>



<p>Boom, done in seconds. (And if you’re thinking “but it’ll take much longer when you account for the inevitable debate about what actually happened!” then there’s <a href="https://critter.blog/2020/11/27/future-focused-feedback/">an answer for that too</a>.)</p>



<p>The beautiful thing about this rapid feedback is the frequency that it allows. When it only takes a few seconds, why not give feedback every day? Why not 5 times a day? It lowers the threshold of what is worthy of feedback.</p>



<p>One caveat: the book has a 3 question test you have to ask yourself before you can deliver the feedback:</p>



<ol><li>Are you angry? If so, <em>don’t give the feedback</em>.</li><li>Are you focused on the past instead of the future (i.e., reminding them about something they did wrong or punishing them)? If so, <em>don’t give the feedback</em>.</li><li>Are you able to let it go? If not, <em>don’t give the feedback</em>. In other words, if you can’t let it go in terms of how you feel, you <em>should</em> let it go by not giving negative feedback. If you feel an urge to deliver feedback, you’re probably doing it for the wrong reasons.</li></ol>



<blockquote><p>If you’re not angry, if it’s not about the past or about punishment, and if you can let it go, then go ahead and give the feedback.</p></blockquote>



<p>There you have it. 5 second feedback. Lower the threshold for what’s feedback-worthy and delivery a steady stream of rapid feedback every day.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/11/26/5-second-feedback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25221812</guid>
            <pubDate>Thu, 26 Nov 2020 17:15:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the Racket Compiler with Chez Scheme]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25221147">thread link</a>) | @delmatte
<br/>
November 26, 2020 | https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484 | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="4198">An interview on Racket CS with programmers Gustavo Massaccesi Matthew Flatt</h2><div><div><div><p><a href="https://federicocarrone.medium.com/?source=post_page-----210e23a69484--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/56/56/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="28" height="28"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3852/1*so5Q8KpDmcaIAKUHU5V9mw.png" width="1926" height="968" srcset="https://miro.medium.com/max/552/1*so5Q8KpDmcaIAKUHU5V9mw.png 276w, https://miro.medium.com/max/1104/1*so5Q8KpDmcaIAKUHU5V9mw.png 552w, https://miro.medium.com/max/1280/1*so5Q8KpDmcaIAKUHU5V9mw.png 640w, https://miro.medium.com/max/1400/1*so5Q8KpDmcaIAKUHU5V9mw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*so5Q8KpDmcaIAKUHU5V9mw.png?q=20"></p></div></div></div><figcaption>Still from a <a href="https://www.youtube.com/watch?v=t09AJUK6IiM" rel="noopener">2018 talk by Matthew Flatt</a>, intervened by us</figcaption></figure><p id="3a1d">Racket flaunts the title of being <em>the programmable programming language</em>. With extensibility at its core, it takes metaprogramming to the next level by encouraging developers to implement their own DSLs to solve the problem at hand.</p><p id="3876">Following this same principle, its development team attacks the complexity of writing a compiler by stacking layers of DSLs to implement many of its components.</p><p id="1a3c">On the other hand, the project had many legacy components written in C that became a development bottleneck, so in 2017, Matthew Flatt made an announcement on a Racket Developers group:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2220/1*oXZFdbH7adA58JPU4Cu2tw.png" width="1110" height="274" srcset="https://miro.medium.com/max/552/1*oXZFdbH7adA58JPU4Cu2tw.png 276w, https://miro.medium.com/max/1104/1*oXZFdbH7adA58JPU4Cu2tw.png 552w, https://miro.medium.com/max/1280/1*oXZFdbH7adA58JPU4Cu2tw.png 640w, https://miro.medium.com/max/1400/1*oXZFdbH7adA58JPU4Cu2tw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*oXZFdbH7adA58JPU4Cu2tw.png?q=20"></p></div></div></div><figcaption><a href="https://groups.google.com/g/racket-dev/c/2BV3ElyfF8Y/m/4RSd3XbECAAJ?pli=1" rel="noopener">Source</a></figcaption></figure><p id="f313">Chez is <span id="rmm">a</span> Scheme implementation which was open sourced by Cisco in 2016. Its performance has no match among other schemes and it has a long history of being used in production.</p><p id="f163">To learn more about this endeavor, we contacted Gustavo Massaccesi, and Matthew Flatt, who were part of what is now called the <strong>Racket CS</strong> project. In this interview, they explain the background and details of this project.</p><p id="f0ef">We're big fans of Matthew Flatt's work and of the Racket endeavor. For further reading we recommend reading Flatt's article <a href="https://queue.acm.org/detail.cfm?id=2068896" rel="noopener">Creating languages in Racket</a>, <a href="https://gumroad.com/l/lop-in-racket-cultural-anthro" rel="noopener">this book</a> that interviews 38 Racket programmers, and the book <a href="https://beautifulracket.com/" rel="noopener">Beautiful Racket</a>, which Flatt prologued.</p></div></div></section><section><div><p id="68b3"><em>Join the Not a Monad Tutorial Telegram </em><a href="https://t.me/notamonadtutorial" rel="noopener"><em>group</em></a><em> or </em><a href="https://t.me/channel_notamonadtutorial" rel="noopener"><em>channel</em></a><em> to talk about programming, computer science and papers. See you there!</em></p></div></section><section><div><p id="f9ba"><em>If you are looking for good engineers send me an email to mail@fcarrone.com or you can also reach me via twitter at </em><a href="https://twitter.com/federicocarrone" rel="noopener"><em>@federicocarrone</em></a><em>.</em></p></div></section><section><div><div><h2 id="77cf"><strong>Tell us about Racket. What makes it stand out in the LISP family?</strong></h2><p id="b428">Let’s distinguish “Racket the language” and “Racket the project”.</p><p id="f2e2">The Racket language is a general-purpose, Scheme-like language with an especially rich set of constructs for extending the language — even by Scheme standards. Racket includes support for writing quick-and-dirty macros, but it also supports nice macros with a good error checking that avoid surprising errors created in the expanded code. The close integration of macros and modules, an enforced phase separation between run-time and compile-time code, and the `#lang` mechanism for selecting the surface syntax all distinguish Racket from other Lisp variants.</p><p id="d48e">Even the main language Racket is written in a simpler language, and that is written in an even more simple language. This tower of languages makes development easier. You can look under the hood and see all the internal languages, or just ignore all of them and get a nice high level language.</p><p id="36f0">Less prominent, but also as important in practice for building language abstractions and composing them into large systems, are Racket’s run-time constructs: first-class control with continuation marks, custodians for simple and reliable task termination, reachability-based memory accounting, message-based parallelism via places, and Concurrent ML-style constructs for event-driven programs. Many of these constructs need support at lower levels of the runtime system, but then they can be used to build a wide variety of languages and libraries that mesh well.</p><p id="cb77">The Racket project synthesizes research, production, and education efforts toward the overall language-building goal. The idea of “A Programmable Programming Language” serves along those directions, from building student-friendly learning environments to domain-specific languages in application to pushing the frontiers of language design and implementation.</p><p id="a39d">The main page is <a href="https://racket-lang.org/" rel="noopener">https://racket-lang.org/</a></p><h2 id="47bc"><strong>What does it mean that you can write your own language?</strong></h2><p id="8534">For example, when you install Racket, it comes with 20 or 30 additional languages. (I’m not sure if someone has counted all of them.)</p><p id="adb8">There are a few “Student” languages that are designed for students. They are less powerful but have more compile time checks to detect common errors in beginners. And they have different levels so once you master one, you can use the next one that includes more features.</p><p id="e7f1">Another language is Typed Racket, that adds types to the Racket expressions, so it refuses to compile unless the types check. And it also uses the type information to optimize the code, so the compilation is slower, but the generated code can be faster.</p><p id="b5fa">There are languages that implement the version of Scheme in R5RS and R6RS and many of the SRFI. And you can install a package that adds the version in the R7RS-small.</p><p id="8dd3">And there are also more different languages with a very different syntax like a complete implementation of Algol 60.</p><p id="d422">All these languages share the same backend and you can call the libraries written in one language from any of the other languages that are included in the distribution, the additional languages you can download as packages, or the languages you create.</p><p id="7932"><strong>What’s the difference between Racket and Scheme?</strong></p><p id="f375">Racket started out as a Scheme implementation, and we would still call it “a Scheme.” Even though it does not fit a Scheme standard, it’s obviously derived from Scheme. There are many specific differences, such as the fact that `cons` always creates an immutable pair in Racket, but the main difference is philosophy: Scheme is meant to be a small language that gives you just enough to express lots of things. Racket is meant to be a big language, and while it gives you the same core pieces (and more) that can express lots of things, it also codifies the way many things are done to enable more cooperating libraries and languages.</p><h2 id="0256"><strong>What is Chez Scheme, how is it different from other Scheme implementations?</strong></h2><p id="1fb3">Chez Scheme is one of the oldest Scheme implementations, and its evolution informed many parts of the Scheme standard through R6RS. (Racket’s influence on the Scheme standard, in contrast, is limited to aspects of the R6RS library design.) Chez Scheme is a relatively small language, but like all instantiations of Scheme, the implementation provides a lot more than the standard specifies.</p><p id="3c1c">Chez Scheme’s biggest claim to fame is its performance. It has always been among the best-performing Scheme implementations. Its object-tagging and allocation regime, its hybrid stack–heap implementations of continuations, and its compiler structure all remain state-of-the-art, even in 2020.</p><p id="3095">For most of its existence, Chez Scheme was a proprietary, closed-source implementation, but it became open source in mid-2016. As it happens, we started considering a new Racket reimplementation around the start of 2017.</p><h2 id="54ea"><strong>Why did you choose Chez Scheme over other Schemes to rebuild Racket?</strong></h2><p id="db07">The biggest weakness of the Racket BC (“before Chez”) implementation are its back-end compiler structure, its inefficient internal calling conventions (over-adapted to C), and its poor implementation of first-class continuations. Those are exactly the strengths of Chez Scheme. Furthermore, Racket’s evaluation model was always closely aligned with Chez Scheme, such as the emphasis on interactive evaluation and compilation.</p><p id="d9a4">It was clear up front that Chez Scheme lacked significant features that Racket needs, such as support for continuation marks and reachability-based memory accounting. However, the high quality of the Chez Scheme design and implementation, in contrast to old Racket’s implementation, made adapting Chez Scheme more appealing than retrofitting Racket’s old implementation further.</p><h2 id="28e7"><strong>Why reimplement with Chez Scheme to reduce the C part instead of implementing the C stuff in Racket?</strong></h2><p id="2658">Mostly, we did reimplement the C stuff in Racket. The I/O subsystem, the concurrency subsystem (which includes the scheduler for “green” threads, Concurrent ML-style events, and custodians), and the regexp matcher were all rewritten in Racket. Those pieces followed the rewrite of the macro expander in Racket. Other things that needed to be moved out of C, such as the compiler and the extensive support for numbers that Racket inherited from Scheme, were already written in Scheme in Chez Scheme’s implementation.</p><p id="b995">A big part of the process was to understand what to implement in Racket, what in Chez Scheme, and what new layers to introduce in translation. This work and reorganization benefits other Racket implementation efforts, such as Pycket and RacketScript.</p><h2 id="de40"><strong>Besides improving maintainability, what are the advantages of building Racket with CS over C?</strong></h2><p id="4952">With the exception of the garbage collector and similar low-level parts of the runtime system, much of Racket’s implementation benefits from higher-level abstractions. Writing a macro expander in C was a particularly poor choice, since higher-level abstractions obviously make tree manipulations easier, but the same reasons apply for the I/O layer or numeric primitives. Even the garbage collector in [the Racket variant of] Chez Scheme is now half implemented by a specification and compiler that are written in Scheme.</p><p id="60db">The other big advantage is that the Racket community has a lot of Racket programmers, not C programmers. It’s easier to convince a fan of Racket to look at some code in Racket or Chez Scheme and try to find some bug or a new feature to contribute. The people that like to read and write code in C are probably making contributions to a C compiler.</p><h2 id="e706"><strong>What were the most challenging parts to implement?</strong></h2><p id="971c">The most challenging part is not really one part, but the overall scale. Racket is a big language, and it all has to work the same in the new implementation. That means not just getting the right result and/or a specific kind of error message, but getting results with the same or better performance characteristics. For example, if a macro generates a giant expansion that nevertheless compiles in reasonable time in Racket BC, then it needs to compile in reasonable time in Racket CS.</p><p id="c985">When it comes to specific pieces that we had to implement, perhaps the most challenging were adding type reconstruction to the compiler, adding support for continuation marks, allowing record values to act as procedures, reimplementing Racket’s I/O, and upgrading Chez Scheme’s …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484">https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484</a></em></p>]]>
            </description>
            <link>https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484</link>
            <guid isPermaLink="false">hacker-news-small-sites-25221147</guid>
            <pubDate>Thu, 26 Nov 2020 16:06:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making a New World: Armistice Soundwave (2018)]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25221096">thread link</a>) | @Osiris30
<br/>
November 26, 2020 | https://codatocoda.com/blog/making-a-new-world-armistice-soundwave/ | <a href="https://web.archive.org/web/*/https://codatocoda.com/blog/making-a-new-world-armistice-soundwave/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7.jpg"><picture><source srcset="https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-1024x768.jpg.webp 1024w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-300x225.jpg.webp 300w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-768x576.jpg.webp 768w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-900x675.jpg.webp 900w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-450x338.jpg.webp 450w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-225x169.jpg.webp 225w" sizes="(max-width: 1000px) 900px, 900px" type="image/webp"><img src="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-1024x768.jpg" alt="" width="1024" height="768" srcset="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-1024x768.jpg 1024w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-300x225.jpg 300w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-768x576.jpg 768w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-900x675.jpg 900w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-450x338.jpg 450w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/Image-from-iOS-7-225x169.jpg 225w" sizes="(max-width: 1000px) 900px, 900px"></picture></a></p><p>W</p><p>e<span>&nbsp;worked with the team at Imperial War Museum to reimagine what the end of the First World War might have sounded like for their </span><i><span>Making a New World </span></i><span>season. They asked us to create an interpretation based on a unique image from their archive: a section of film called the </span><i><span>End of the War</span></i><span> which shows a before and after recording made by a â€˜sound rangingâ€™ unit at the end of the First World War, on 11 November 1918.</span></p><p><strong>Interpreting an image</strong></p><p><picture><source srcset="https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/The-End-of-the-War.jpg.webp 1072w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-300x95.jpg.webp 300w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-768x244.jpg.webp 768w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-1024x326.jpg.webp 1024w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-900x286.jpg.webp 900w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-450x143.jpg.webp 450w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-225x72.jpg.webp 225w" sizes="(max-width: 1000px) 900px, 900px" type="image/webp"><img src="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War.jpg" alt="" width="1072" height="341" srcset="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War.jpg 1072w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-300x95.jpg 300w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-768x244.jpg 768w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-1024x326.jpg 1024w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-900x286.jpg 900w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-450x143.jpg 450w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/The-End-of-the-War-225x72.jpg 225w" sizes="(max-width: 1000px) 900px, 900px"></picture></p><p><span>The </span><i><span>End of the War</span></i><span> shows a â€˜recordingâ€™ made on film of sound pressure impulses picked up by â€˜sound rangingâ€™ equipment stationed along the allied front.</span></p><p><span>The purpose of this equipment was to try and determine where enemy guns were positioned by analysing the length of time it took sound impulses from the firing of guns to arrive at the allied front. The sound ranging equipment used six tuned low frequency â€˜<a href="https://royalsocietypublishing.org/doi/abs/10.1098/rsta.1921.0011">microphones</a>â€™</span><span> (indicated by the six parallel lines on the film) arranged in a wide arc behind allied lines. The microphones were connected to a string galvanometer at a forward listening position. A low frequency signal picked up by one of these microphones would move a thin wire in the galvanometer and cast a shadow onto a piece of moving film.</span></p><p><span>The equipment takes advantage of both the consistency and relative difference between the speed of sound and the speed of light to create a visual recording of the sound impulses which would arrive at the microphones after the flash of the guns being fired. An operator would wait for the flash of an enemy gun to start the film rolling and the equipment would record the signals as they arrived progressively based on their proximity to the impulse source. </span></p><p><span>The film took around five minutes to develop after which trained analysts could decode the patterns on the film and use them to work out the positions of enemy guns using a process called <a href="https://en.wikipedia.org/wiki/Artillery_sound_ranging#cite_note-LawCosines-2">multilateration</a></span><span>.</span></p><p><span>By the end of WW1 sound ranging techniques could locate enemy guns within 25m to 50m under normal atmospheric conditions and even determine the <a href="https://www.aif.adfa.edu.au/OrderOfBattle/Thesis/index.html">caliber, number of guns and the target</a></span><span>. &nbsp;The document above gives us a great insight into how intense and chaotic the barrage of gunfire must have been to those fighting. The missing section that has been edited out of the film in the middle of the image also begs the question â€œwhat would those 2 minutes have sounded like?â€�</span></p><p><b>Forensic sound</b></p><p><span>Using this document, the team at IWM were keen for us to try and create an interpretation of how this â€˜missingâ€™ moment might have sounded as the introduction to a series of exhibitions they were working on to commemorate the centenary of the end of the First World War.</span></p><p><span>In order to go about creating a reconstruction, we had do a bit of â€˜forensicâ€™ work, corroborating historical information about the type of artillery that would have been in use by the US, German and French armies at this point in the war, with what the visual information from the sound ranging film tells us about the size, distance and frequency of blasts and finally, interpreting the kind of reverberation you would have expected to hear by looking at landscape photographs and archive film footage from the front.</span></p><p><span>As its basis, our reconstruction uses contemporary recordings of the Howitzer, Mauser, Stokes, Vickers and Lee Enfield guns made for the purposes of sound design in film and television</span><span>. These recordings were then grouped and triggered according to who was using them and in patterns that corresponded to archive <a href="https://www.youtube.com/watch?v=q2lGzfuJaok">newsreel</a> <a href="https://www.youtube.com/watch?v=aMf5MmicGlQ">footage</a> taken at the front</span><span>. The density of the gunfire was interpreted both from the sound ranging document and further archive footage. All of these elements were mixed together relative to each other and with respect to the distances over which the fighting was taking place. Finally, a convolution reverb</span><span> with an impulse response recorded in a relative â€˜free fieldâ€™ scenario was used to simulate the space and dispersion of the sound across the front</span>.</p><p><strong>Feeling sound: bone conduction</strong></p><p><span>The team at IWM were very keen to present this unique document and our reconstruction in a way that would not only bring them to life, but also make explicit the relationship between them for visitors. With this in mind, we drew inspiration from the mechanics of the â€˜sound rangingâ€™ equipment itself.</span></p><figure id="attachment_1477" aria-labelledby="figcaption_attachment_1477"><picture><source srcset="https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder.jpg.webp 800w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-300x225.jpg.webp 300w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-768x576.jpg.webp 768w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-450x338.jpg.webp 450w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-225x169.jpg.webp 225w" sizes="(max-width: 1000px) 900px, 900px" type="image/webp"><img src="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder.jpg" alt="" width="447" height="335" srcset="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder.jpg 800w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-300x225.jpg 300w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-768x576.jpg 768w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-450x338.jpg 450w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/800px-French_sound_ranging_recorder-225x169.jpg 225w" sizes="(max-width: 1000px) 900px, 900px"></picture><figcaption id="figcaption_attachment_1477">A French ‘sound ranging’ system from 1920s</figcaption></figure><p><span>The â€˜sound rangingâ€™ equipment that was deployed at the end of &nbsp;WW1 used an innovative Low Frequency Microphone developed by <a href="https://en.wikipedia.org/wiki/William_Sansome_Tucker">William Sansome Tucker</a></span><span> in 1916. &nbsp;This microphone used a Helmholtz resonator to detect the physical vibrations of low frequencies of the guns in order to record them onto film</span><span>.</span></p><p><span>The physicality of â€˜sound rangingâ€™ and the fact that the explosions of the guns firing would have been felt as shock waves by soldiers at the same time as being heard led us to the idea of trying to incorporate bone conduction into the exhibit, as a way of tying together our reconstruction with the physicality of â€˜sound rangingâ€™.</span></p><p><strong>How does bone conduction work?</strong></p><p>Normally sound waves reach our ears as vibrations travelling through the air to our eardrums, and then on to the Cochlea or inner ear, which is connected to the auditory nerve that transmits the sounds to our brain.</p><p>However, the ear is a very sensitive organ and it can also pick up vibrations through our skulls. The most obvious example of this is when you go to the dentist and have your teeth cleaned. Dentists often use electric polishers, these polishers make a sound that can be heard in the room, but also, when applied to your teeth and transmitted through your skull, heard directly through the process of ‘bone conduction’.</p><figure id="attachment_1481" aria-labelledby="figcaption_attachment_1481"><picture><source srcset="https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/large.jpg.webp 442w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/large-300x205.jpg.webp 300w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/large-225x154.jpg.webp 225w" sizes="(max-width: 1000px) 900px, 900px" type="image/webp"><img src="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/large.jpg" alt="" width="442" height="302" srcset="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/large.jpg 442w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/large-300x205.jpg 300w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/large-225x154.jpg 225w" sizes="(max-width: 1000px) 900px, 900px"></picture><figcaption id="figcaption_attachment_1481">Laurie Anderson, Handphone Table, 1978.</figcaption></figure><p>The logic of ‘bone conduction’ is that anything that vibrates can be put directly on your head and heard through your skull. It is also possible to ‘bridge’ a gap between something vibrating and your skull with an intermediary solid object.</p><p>As luck would have it, Laurie Anderson, in her piece ‘<a href="https://www.moma.org/documents/moma_press-release_327164.pdf">Handphone Table</a>‘ discovered that you can use your arms to ‘bridge’ the gap between a vibrating surface and your ears.</p><p>‘Handphone Table’ struck us as the perfect method for visitors to IWM to both hear and ‘feel’ our reconstruction of the WW1 armistice and with this in mind we set about designing a ‘sound bar’ which would enable this to happen.</p><figure id="attachment_1427" aria-labelledby="figcaption_attachment_1427"><picture><source srcset="https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-1024x728.jpg.webp 1024w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-300x213.jpg.webp 300w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-768x546.jpg.webp 768w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-900x640.jpg.webp 900w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-450x320.jpg.webp 450w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-225x160.jpg.webp 225w" sizes="(max-width: 1000px) 900px, 900px" type="image/webp"><img src="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-1024x728.jpg" alt="" width="1024" height="728" srcset="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-1024x728.jpg 1024w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-300x213.jpg 300w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-768x546.jpg 768w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-900x640.jpg 900w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-450x320.jpg 450w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/sound-bar-plan-1-225x160.jpg 225w" sizes="(max-width: 1000px) 900px, 900px"></picture><figcaption id="figcaption_attachment_1427">Early plans for the bone conduction ‘sound bar’, &nbsp;which included ear pieces that were later taken out.</figcaption></figure><p>The result is an exhibit that we hope enables visitors to experience something of the intense barrage of sound at the front in WW1 as if they themselves were the ‘sound ranging’ equipment, a symmetry which also hopefully helps project them into that moment in history.</p><p>Head over to our <a href="https://codatocoda.com/blog/case-studies/armistice-soundwave/">CASE STUDY</a>&nbsp;on the installation&nbsp;to get the behind-the-scenes low down!</p><figure id="attachment_1421" aria-labelledby="figcaption_attachment_1421"><a href="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072.jpg"><picture><source srcset="https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-1024x683.jpg.webp 1024w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-300x200.jpg.webp 300w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-768x512.jpg.webp 768w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-900x600.jpg.webp 900w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-450x300.jpg.webp 450w, https://codatocoda.com/mainsite/wp-content/webp-express/webp-images/doc-root/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-225x150.jpg.webp 225w" sizes="(max-width: 1000px) 900px, 900px" type="image/webp"><img src="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-1024x683.jpg" alt="" width="1024" height="683" srcset="https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-1024x683.jpg 1024w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-300x200.jpg 300w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-768x512.jpg 768w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-900x600.jpg 900w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-450x300.jpg 450w, https://codatocoda.com/mainsite/wp-content/uploads/2018/10/IWM_2018_090_0072-225x150.jpg 225w" sizes="(max-width: 1000px) 900px, 900px"></picture></a><figcaption id="figcaption_attachment_1421">Photograph courtesy of the Imperial War Museum&nbsp;</figcaption></figure></div></div>]]>
            </description>
            <link>https://codatocoda.com/blog/making-a-new-world-armistice-soundwave/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25221096</guid>
            <pubDate>Thu, 26 Nov 2020 16:01:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: React Native template for open source identity provider Ory Kratos]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25220614">thread link</a>) | @k8_maze
<br/>
November 26, 2020 | https://www.getory.io/login-user-management-mobile-apps-react-native-expo-template | <a href="https://web.archive.org/web/*/https://www.getory.io/login-user-management-mobile-apps-react-native-expo-template">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>This guide explains step-by-step how to add login, registration, logout, profile
management, password change, and many other profile-related flows to a React
Native application using the open source
<a href="https://github.com/ory/kratos">ORY Kratos</a> Identity and User Management Go
server.</p><figure><video autoplay="" muted="" loop=""><source src="https://d33wubrfki0l68.cloudfront.net/19cd7434c052d8cff4f2d590ecb150cced9677fa/9d370/static/login-86f2babbee36c56edcf74baa707dc9cb.mp4" type="video/mp4"><source src="data:video/webm;base64," type="video/webm"></video><figcaption>React Native Mobile App with Login and User Management using ORY Kratos as a backend.</figcaption></figure><p>As the user storage / identity management we will use the open source
<a href="https://www.ory.sh/kratos">ORY Kratos</a> project. The React Native application
shown in the screens below is available on at
<a href="https://github.com/ory/kratos-selfservice-ui-react-native">github.com/ory/kratos-selfservice-ui-react-native</a>
as well. Both are maintained by <a href="https://github.com/aeneasr">@aeneasr</a> and
<a href="https://github.com/zepatrik">@zepatrik</a>.</p><div>
  <div>
    <p>
        <a href="https://github.com/ory/kratos" rel="nofollow noopener">
          <img alt="ORY Kratos GitHub Card" src="https://gh-card.dev/repos/ory/kratos.svg?fullname=">
        </a>
      </p>
    <p>
        <a href="https://github.com/ory/kratos-selfservice-ui-react-native" rel="nofollow noopener">
          <img alt="ORY Kratos React Native Self-Service UI Reference for React Native GitHub Card" src="https://gh-card.dev/repos/ory/kratos-selfservice-ui-react-native.svg?fullname=">
        </a>
      </p>
  </div></div><p>You can download the app right now from the
<a href="https://apps.apple.com/fj/app/ory-profile-app/id1536546333">Apple App Store</a>
and
<a href="https://play.google.com/store/apps/details?id=com.ory.kratos_self_service_ui_react_native">Google Play Store</a>!</p><p>In the future, this guide will also cover Two-Factor-Authentication (2FA/MFA),
"Sign in with Google", password reset, email verification, phone number and SMS
verification, "Sign in with GitHub", "Sign in with Facebook" and many other
flows.</p><h2>Auth, Login, Registration, User Management React Native Template for Expo</h2><p>This guide assumes that you have worked with React and React Native before as we
will not cover React fundamentals and focus on implementing login, registration
and so on.</p><p>To make things a bit easier, we will use <a href="https://expo.io/"><code>expo</code></a>. At a
minimum, you need NodeJS and NPM installed locally. We will use the ORY Kratos
React Native Login, Registration and Profile Management template:</p><div data-language="shell-session"><pre><code><span><span>$</span> <span><span>npm</span> <span>install</span> -g expo-cli</span></span>
<span><span>$</span> <span>expo init login-signup-app -t @oryd/expo-login-registration-template --npm</span></span>

<span><span>#</span> <span>We also want to <span>install</span> and initialize all required components:</span></span>
<span><span>$</span> <span><span>cd</span> login-signup-app</span></span>
<span>~/login-signup-app</span><span><span>$</span> <span><span>npm</span> i</span></span>
<span>~/login-signup-app</span><span><span>$</span> <span><span>npm</span> run expo-install</span></span>
<span><span>#</span> <span>For iOS you also need to run:</span></span>
<span>~/login-signup-app</span><span><span>$</span> <span><span>npm</span> run pod-install</span></span></code></pre></div><p>In case you want to just start exploring, simply run:</p><ul><li><code>npm start</code> opens a dashboard where you can open iOS, Android, or web.</li><li><code>npm run android</code> opens the app as an android app (requires a connected
android VM or device).</li><li><code>npm run ios</code> opens the app in the iOS simulator (works only on mac OSX).</li><li><code>npm run web</code> opens the app as a browser app.</li></ul><p><span>
      <a href="https://www.getory.io/static/3f7a9052992066e46ac3a20778c72f93/1b920/expo-dashboard.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Expo CLI Dashboard for ORY Kratos React Native Reference Implementation" title="Expo CLI Dashboard for ORY Kratos React Native Reference Implementation" src="https://d33wubrfki0l68.cloudfront.net/0fa1f0c0658acfaa1ca57e7c87e03dad8d07a70c/58473/static/3f7a9052992066e46ac3a20778c72f93/914ae/expo-dashboard.png" srcset="https://d33wubrfki0l68.cloudfront.net/0b2b41046a6e6c5baa4e0b3ef0df36df1367278b/c29df/static/3f7a9052992066e46ac3a20778c72f93/2eb24/expo-dashboard.png 215w,https://d33wubrfki0l68.cloudfront.net/230d828a7603edb00344926d3968841a422eeb22/9ea51/static/3f7a9052992066e46ac3a20778c72f93/05ed2/expo-dashboard.png 430w,https://d33wubrfki0l68.cloudfront.net/0fa1f0c0658acfaa1ca57e7c87e03dad8d07a70c/58473/static/3f7a9052992066e46ac3a20778c72f93/914ae/expo-dashboard.png 860w,https://d33wubrfki0l68.cloudfront.net/1ff5db697a2b17f4154bc534aca4e4d94d4f70e4/55644/static/3f7a9052992066e46ac3a20778c72f93/46115/expo-dashboard.png 1290w,https://d33wubrfki0l68.cloudfront.net/6cc4c816f50b6253b8720b021534d99c99079cf4/97ad4/static/3f7a9052992066e46ac3a20778c72f93/6c86f/expo-dashboard.png 1720w,https://d33wubrfki0l68.cloudfront.net/2bcb0e6467c1731f45bda31a3202ff47324cc217/458bb/static/3f7a9052992066e46ac3a20778c72f93/1b920/expo-dashboard.png 5256w" sizes="(max-width: 860px) 100vw, 860px" loading="lazy">
  </a>
    </span></p><p>Running these commands directly will use our hosted demo environment of ORY
Kratos at
<a href="https://demo.tenants.staging.oryapis.dev/">demo.tenants.staging.oryapis.dev</a>.
Configure this in <code>app.config.js</code>:</p><div data-language="javascript"><pre><code><span>export</span> <span>default</span> <span>(</span><span>parent <span>=</span> <span>{</span><span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  
  <span>const</span> <span>{</span> config <span>=</span> <span>{</span><span>}</span> <span>}</span> <span>=</span> parent
  <span>const</span> <span>{</span> env <span>=</span> <span>{</span><span>}</span> <span>}</span> <span>=</span> process <span>||</span> <span>{</span><span>}</span>

  <span>const</span> <span>{</span>
    
    
    <span>KRATOS_URL</span> <span>=</span> <span>'https://demo.tenants.staging.oryapis.dev/api/kratos/public'</span><span>,</span>

    
    
    <span>SENTRY_DSN</span> <span>=</span> <span>'https://8be94c41dbe34ce1b244935c68165eab@o481709.ingest.sentry.io/5530799'</span>
  <span>}</span> <span>=</span> env

  <span>return</span> <span>{</span>
    <span>...</span>config<span>,</span>
    extra<span>:</span> <span>{</span>
      kratosUrl<span>:</span> <span>KRATOS_URL</span><span>,</span>
      sentryDsn<span>:</span> <span>SENTRY_DSN</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div><div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="16" viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</h5></p><p>Please be aware that the demo environment including its admin APIs is available
to everyone. Use only anonymised data when playing around with it! If you want
your own managed environment reach out to <a href="mailto:jared@ory.sh">jared@ory.sh</a> or
set up your own open source environment. Information on achieving that is
available in part two of this article.</p></div><h2>Native Mobile Profile Management</h2><p>This short screen capture shows using the apps' user login, user registration,
dashboard, and profile management features:</p><figure><video autoplay="" muted="" loop=""><source src="https://d33wubrfki0l68.cloudfront.net/ec87bf815a2e00831b99405a2ec5750e5c2ee4b0/a4660/static/signup-profile-settings-9cf04b266d8155b73f1d6fe7a558c8c8.mp4" type="video/mp4"><source src="https://d33wubrfki0l68.cloudfront.net/9d720a294030b6219c8879aa6cdca8907bfb763b/3e778/static/signup-profile-settings-a64f74022cb8f383f974e0185f149456.webm" type="video/webm"></video><figcaption>User Registration, Dashboard, Profile Management in React Native using ORY Kratos.</figcaption></figure><h2>User Management / Identity Management</h2><p>To manage identities, you may use the ORY Kratos CLI. An overview of all
commands can be found in the
<a href="https://www.ory.sh/kratos/docs/cli/kratos">ORY Kratos documentation</a> or by
running:</p><div data-language="shellsession"><pre><code><span><span>$</span> <span>docker run oryd/kratos:v0.5.4-alpha.1 <span>help</span></span></span></code></pre></div><p>To list all identities in the system, run:</p><div data-language="shell-session"><pre><code><span><span>$</span> <span>docker run oryd/kratos:v0.5.4-alpha.1 </span></span><span>\
  --endpoint https://demo.tenants.staging.oryapis.dev/api/kratos/admin \
  identities list

ID					VERIFIED ADDRESS 1		RECOVERY ADDRESS 1		SCHEMA ID	SCHEMA URL
f9c33e56-5b43-458a-8cfa-f38a4fb98b9c	office+demo@ory.sh		office+demo@ory.sh		default		https://demo.tenants.staging.oryapis.dev/api/kratos/public/schemas/default
[...]</span></code></pre></div><p>You can also search for the identity you just signed up using <code>jq</code>:</p><div data-language="shell-session"><pre><code><span><span>$</span> <span><span>yourEmail</span><span>=</span></span></span><span>&lt;the-email-you-used-for-signup&gt;
</span><span><span>#</span> <span>For example:</span></span>
<span><span>#</span>   <span><span>yourEmail</span><span>=</span>office+demo@ory.sh</span></span>
<span><span>$</span> <span>docker run oryd/kratos:v0.5.4-alpha.1 </span></span><span>\
  --endpoint https://demo.tenants.staging.oryapis.dev/api/kratos/admin \
  identities list -f json | \
</span><span>    jq '.[] | select(.traits.email == "'</span><span><span>$</span><span>yourEmail<span>'")'</span></span></span>

<span>{
  "id": "f9c33e56-5b43-458a-8cfa-f38a4fb98b9c",
  "recovery_addresses": [
    {
      "id": "bd7c396c-d893-4a2b-8627-b50aa38e2569",
      "value": "office+demo@ory.sh",
      "via": "email"
    }
  ],
  "schema_id": "default",
  "schema_url": "https://demo.tenants.staging.oryapis.dev/api/kratos/public/schemas/default",
  "traits": {
    "email": "office+demo@ory.sh",
    "name": {
      "first": "Aeneas",
      "last": "Hackerman"
    }
  },
  "verifiable_addresses": [
    {
      "id": "bee9b276-b57f-41dc-8c61-82eb83c2d4fd",
      "status": "completed",
      "value": "office+demo@ory.sh",
      "verified": true,
      "verified_at": "2020-11-26T08:45:22.094Z",
      "via": "email"
    }
  ]
}</span></code></pre></div><p>To learn more about administration of ORY Kratos' identities, head over to the
<a href="https://www.ory.sh/kratos/docs/admin/managing-users-identities">Managing Users and Identities Documentation</a>!</p><h2>Run ORY Kratos Login, Registration, 2FA Server Locally in Docker</h2><p>Instead of using the hosted demo environment, you can also deploy your own ORY
Kratos installation locally and run the React Native app against its API. To run
the app against a local deployment, check out
<a href="https://www.ory.sh/kratos">ORY Kratos</a> locally and run the quickstart:</p><div data-language="shell-session"><pre><code><span><span>#</span> <span>You might want to <span>cd</span> into another directory:</span></span>
<span><span>#</span> <span>$ <span>cd</span> <span>..</span></span></span>
<span><span>$</span> <span><span>git</span> clone https://github.com/ory/kratos.git</span></span>
<span><span>$</span> <span><span>cd</span> kratos</span></span>
<span><span>$</span> <span><span>git</span> checkout v0.5.4-alpha.1</span></span>
<span><span>$</span> <span>docker-compose -f quickstart.yml -f quickstart-standalone.yml </span></span><span>\
    up --build --force-recreate -d</span></code></pre></div><p>Next you need to set up port forwarding for the ORY Kratos Docker Image you just
started. We use the tool <a href="https://ngrok.com/"><code>ngrok</code></a>.</p><div data-language="shell-session"><pre><code><span><span>$</span> <span>ngrok http <span>4433</span></span></span>

<span>Account                       ...
Version                       ...
Region                        ...
Web Interface                 ...
Forwarding                    ...
Forwarding                    https://04ee3e08367a.ngrok.io -&gt; http://localhost:4433

Connections                   ttl     opn     rt1     rt5     p50     p90
                              0       0       0.00    0.00    0.00    0.00</span></code></pre></div><p>Copy the HTTPS forwarding URL (example from above
<code>https://04ee3e08367a.ngrok.io</code>) and in a new terminal, set it as an environment
variable and start the app:</p><div data-language="shell-session"><pre><code><span><span>#</span> <span>Change into the directory of your react native app:</span></span>
<span><span>$</span> <span><span>cd</span> login-signup-app</span></span>
<span><span>$</span> <span><span>KRATOS_URL</span><span>=</span></span></span><span>&lt;the-ngrok-url&gt; npm start
</span><span><span>#</span> <span>For example:</span></span>
<span><span>#</span> <span>$ <span>KRATOS_URL</span><span>=</span>https://04ee3e08367a.ngrok.io <span>npm</span> start</span></span></code></pre></div><p>Now your app will use the local deployment of ORY Kratos with your own database!</p><h2>React Native Navigation with Authentication Session</h2><p>The entrypoint for the app is
<a href="https://github.com/ory/kratos-selfservice-ui-react-native/blob/master/App.tsx"><code>App.tsx</code></a>.
Besides loading some fonts and setting up the views, this component includes the
structure of the application - including the navigation:</p><div data-language="tsx"><pre><code>
<span>export</span> <span>default</span> <span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>robotoLoaded<span>]</span> <span>=</span> <span>useFontsRoboto</span><span>(</span><span>{</span> Roboto_400Regular <span>}</span><span>)</span>
  <span>const</span> <span>[</span>rubikLoaded<span>]</span> <span>=</span> <span>useFontsRubik</span><span>(</span><span>{</span>
    Rubik_300Light<span>,</span>
    Rubik_400Regular<span>,</span>
    Rubik_500Medium
  <span>}</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span><span>SafeAreaProvider</span></span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span><span>SafeAreaView</span></span>
        <span>edges</span><span><span>=</span><span>{</span><span>[</span><span>'top'</span><span>,</span> <span>'left'</span><span>,</span> <span>'right'</span><span>]</span><span>}</span></span>
        <span>style</span><span><span>=</span><span>{</span><span>{</span>
          flex<span>:</span> <span>1</span><span>,</span>
          backgroundColor<span>:</span> theme<span>.</span>grey5
        <span>}</span><span>}</span></span>
      <span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span><span>AuthProvider</span></span><span>&gt;</span></span><span>
          </span><span><span><span>&lt;</span><span>ThemeProvider</span></span>
            <span>theme</span><span><span>=</span><span>{</span><span>{</span>
              <span>...</span>theme<span>,</span>
              regularFont300<span>:</span> rubikLoaded <span>?</span> <span>'Rubik_300Light'</span> <span>:</span> <span>'Arial'</span><span>,</span>
              regularFont400<span>:</span> rubikLoaded <span>?</span> <span>'Rubik_400Regular'</span> <span>:</span> <span>'Arial'</span><span>,</span>
              regularFont500<span>:</span> rubikLoaded <span>?</span> <span>'Rubik_500Medium'</span> <span>:</span> <span>'Arial'</span><span>,</span>
              codeFont400<span>:</span> robotoLoaded <span>?</span> <span>'Roboto_400Regular'</span> <span>:</span> <span>'Arial'</span><span>,</span>
              platform<span>:</span> <span>'react-native'</span>
            <span>}</span><span>}</span></span>
          <span>&gt;</span></span><span>
            </span><span><span><span>&lt;</span><span>ErrorBoundary</span></span><span>&gt;</span></span><span>
              </span><span><span><span>&lt;</span><span>Navigation</span></span> <span>/&gt;</span></span><span>
              </span><span><span><span>&lt;</span><span>ForkMe</span></span> <span>/&gt;</span></span><span>
            </span><span><span><span>&lt;/</span><span>ErrorBoundary</span></span><span>&gt;</span></span><span>
          </span><span><span><span>&lt;/</span><span>ThemeProvider</span></span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;/</span><span>AuthProvider</span></span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;/</span><span>SafeAreaView</span></span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span><span>SafeAreaProvider</span></span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>The most interesting component here is the <code>&lt;AuthProvider&gt;</code>. This component adds
an authentication / login context to the React Native component tree:</p><div data-language="tsx"><pre><code>
<span>export</span> <span>default</span> <span>(</span><span><span>{</span> children <span>}</span><span>:</span> AuthContextProps</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>[</span>sessionContext<span>,</span> setSessionContext<span>]</span> <span>=</span> useState<span>&lt;</span>
    SessionContext <span>|</span> <span>undefined</span>
  <span>&gt;</span><span>(</span><span>undefined</span><span>)</span>

  
  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>getAuthenticatedSession</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span>syncSession<span>)</span>
  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span>

  <span>const</span> <span>syncSession</span> <span>=</span> <span>(</span><span>auth<span>:</span> SessionContext</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span>auth<span>)</span> <span>{</span>
      <span>return</span> <span>setAuth</span><span>(</span><span>null</span><span>)</span>
    <span>}</span>

    
    <span>return</span> <span>(</span>
      <span>newKratosSdk</span><span>(</span>auth<span>.</span>session_token<span>)</span>
        
        <span>.</span><span>whoami</span><span>(</span><span>)</span>
        <span>.</span><span>then</span><span>(</span><span>(</span><span><span>{</span> data<span>:</span> session <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
          
          
          
          
          
          <span>setSessionContext</span><span>(</span><span>{</span> session<span>,</span> session_token<span>:</span> auth<span>.</span>session_token <span>}</span><span>)</span>
          <span>return</span> Promise<span>.</span><span>resolve</span><span>(</span><span>)</span>
        <span>}</span><span>)</span>
        <span>.</span><span>catch</span><span>(</span><span>(</span><span>err<span>:</span> AxiosError</span><span>)</span> <span>=&gt;</span> <span>{</span>
          <span>if</span> <span>(</span>err<span>.</span>response<span>?.</span>status <span>===</span> <span>401</span><span>)</span> <span>{</span>
            
            console<span>.</span><span>log</span><span>(</span><span>'Session is not authenticated:'</span><span>,</span> err<span>)</span>
          <span>}</span> <span>else</span> <span>{</span>
            
            console<span>.</span><span>error</span><span>(</span>err<span>)</span>
          <span>}</span>

          
          <span>setSessionContext</span><span>(</span><span>null</span><span>)</span>
        <span>}</span><span>)</span>
    <span>)</span>
  <span>}</span>

  <span>const</span> <span>setAuth</span> <span>=</span> <span>(</span><span>session<span>:</span> SessionContext</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>!</span>session<span>)</span> <span>{</span>
      <span>return</span> <span>killAuthenticatedSession</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setSessionContext</span><span>(</span>session<span>)</span><span>)</span>
    <span>}</span>

    <span>setAuthenticatedSession</span><span>(</span>session<span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>syncSession</span><span>(</span>session<span>)</span><span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>sessionContext <span>===</span> <span>undefined</span><span>)</span> <span>{</span>
    <span>return</span> <span>null</span>
  <span>}</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span><span>AuthContext.Provider</span></span>
      <span>value</span><span><span>=</span><span>{</span><span>{</span>
        
        session<span>:</span> sessionContext<span>?.</span>session<span>,</span>
        sessionToken<span>:</span> sessionContext<span>?.</span>session_token<span>,</span>

        
        isAuthenticated<span>:</span> <span>Boolean</span><span>(</span>sessionContext<span>?.</span>session_token<span>)</span><span>,</span>

        
        <span>syncSession</span><span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>getAuthenticatedSession</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span>syncSession<span>)</span><span>,</span>

        
        setSession<span>:</span> setAuth<span>,</span>

        
        didFetch<span>:</span> <span>true</span>
      <span>}</span><span>}</span></span>
    <span>&gt;</span></span><span>
      </span><span>{</span>children<span>}</span><span>
    </span><span><span><span>&lt;/</span><span>AuthContext.Provider</span></span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>The helper methods in
<a href="https://github.com/ory/kratos-selfservice-ui-react-native/blob/master/src/helpers/auth.tsx"><code>src/helpers/auth.tsx</code></a>
are simple wrappers around Expo's
<a href="https://docs.expo.io/versions/latest/sdk/securestore/">SecureStore</a>. In order
to work on the web as well, we use
<a href="https://github.com/react-native-async-storage/async-storage"><code>@react-native-community/async-storage</code></a>
as a fallback:</p><div data-language="tsx"><pre><code>




<span>export</span> <span>const</span> getAuthenticatedSession <span>=</span> <span>(</span><span>)</span><span>:</span> Promise<span><span><span>&lt;</span><span>SessionContext</span></span><span>&gt;</span></span><span> =&gt; </span><span>{</span></code></pre></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.getory.io/login-user-management-mobile-apps-react-native-expo-template">https://www.getory.io/login-user-management-mobile-apps-react-native-expo-template</a></em></p>]]>
            </description>
            <link>https://www.getory.io/login-user-management-mobile-apps-react-native-expo-template</link>
            <guid isPermaLink="false">hacker-news-small-sites-25220614</guid>
            <pubDate>Thu, 26 Nov 2020 15:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quake III Arena, K3s and a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25220328">thread link</a>) | @alexellisuk
<br/>
November 26, 2020 | https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

<figure>
    <img src="https://johansiebens.dev/uploads/2020-11-22/quake_iii_arena_.png"> 
</figure>


<p>Yesterday I saw this tweet of Chris Campbell passing by in my timeline:</p>



<p>Aah, the memories. Quake III Arena, one of my favourite first-person shooter games.</p>

<p>Years ago, I spent (and lost) so much time playing this fast-paced game with friends and foes, and now it is brought into the world of containers and Kubernetes with <strong><a href="https://github.com/criticalstack/quake-kube" target="_blank">QuakeKube</a></strong> by <a href="https://twitter.com/CapitalOneTech" target="_blank">Capital One Tech</a>.</p>

<blockquote>
<p><em>QuakeKube is a Kubernetes-ified version of</em> <a href="https://github.com/inolen/quakejs" target="_blank"><em>QuakeJS</em></a> <em>that runs a dedicated</em> <a href="https://en.wikipedia.org/wiki/Quake_III_Arena" target="_blank"><em>Quake 3</em></a> <em>server in a Kubernetes Deployment, and then allow clients to connect via QuakeJS in the browser.</em></p>
</blockquote>

<p>Of course, I couldn’t wait to give it a try, especially after reading the documentation, saying:</p>

<blockquote>
<p><em>Container images are being cross-compiled with</em> <a href="https://docs.docker.com/buildx/working-with-buildx/" target="_blank"><em>Docker Buildx</em></a> <em>so it can run on hardware with different architectures and operating systems. Currently, it is building for <code>linux/amd64</code> and <code>linux/arm64</code>.</em></p>
</blockquote>

<p><strong>ARM64 support!</strong> Great, it means I can run it on one of my Raspberry Pis!</p>

<h2 id="let-s-get-fragging">Let’s get fragging!</h2>

<p>Most of the work is already done by others, so with the proper tools and projects, it will take you only a few minutes to get everything up and running.</p>

<h3 id="prerequisites">Prerequisites</h3>

<ul>
<li>a Raspberry Pi with Ubuntu 20.04, which supports arm64<br></li>
<li><code>k3sup</code>, a light-weight utility to get from zero to KUBECONFIG with k3s on any local or remote VM.<br></li>
<li><code>arkade</code>, a simple Golang CLI with strongly-typed flags to install charts and apps to your cluster in one command.<br></li>
<li><code>kubectl</code><br></li>
<li>a DigitalOcean account and an API Token</li>
</ul>

<h3 id="installation">Installation</h3>

<p>First, install <code>k3s</code> on your Raspberry Pi running a arm64 OS like Ubuntu 20.04</p>
<div><pre><code data-lang="bash">$ k3sup install --ip <span>192</span>.168.0.52 --user ubuntu --k3s-extra-args <span>'--no-deploy servicelb --no-deploy traefik'</span></code></pre></div>
<p>After the installation of k3s on the Raspberry Pi, k3sup also downloads the required kubeconfig file in your current working directory.<br>
Make sure to configure <code>kubectl</code> to use this config file:</p>
<div><pre><code data-lang="bash">$ export KUBECONFIG<span>=</span><span>$(</span>pwd<span>)</span>/kubeconfig</code></pre></div>
<p>Next, install the inlets-operator with <code>arkade</code>:</p>
<div><pre><code data-lang="bash">$ arkade install inlets-operator --provider digitalocean --token-file ~/do-api-token</code></pre></div>
<p>The inlets-operator will create an inlets exit-node on DigitalOcean, giving the LoadBalancer services in the private k3s cluster a public IP address.</p>

<p>As clients connect to the server via QuakeJS in the browser with websockets, the OSS version of inlets will do just fine. If you want to have better support for TLS etc, I can highly recommend having a look at inlets PRO version.</p>

<p>Finally, take the example yaml file from the QuakeKube GitHub repository and make the appropriate changes. The service should be updated to a LoadBalancer instead of type NodePort, and of course you can change the configuration to tweak the game preferences to your own needs.</p>

<p>Example of a QuakeKube yaml file:</p>
<div><pre><code data-lang="yaml">apiVersion: apps/v1
kind: Deployment
metadata:
  name: quakejs
spec:
  selector:
    matchLabels:
      run: quakejs
  replicas: <span>1</span>
  template:
    metadata:
      labels:
        run: quakejs
      annotations:
        prometheus.io/scrape: <span>'true'</span>
        prometheus.io/port: <span>'8080'</span>
    spec:
      containers:
      - command:
        - q3
        - server
        - --config=/config/config.yaml
        - --content-server=http://localhost:<span>9090</span>
        - --agree-eula
        image: docker.io/criticalstack/quake:v1.<span>0.5</span>
        name: server
        ports:
        - containerPort: <span>8080</span>
        readinessProbe:
          tcpSocket:
            port: <span>8080</span>
          initialDelaySeconds: <span>15</span>
          periodSeconds: <span>5</span>
        volumeMounts:
        - name: quake3-server-config
          mountPath: /config
        - name: quake3-content
          mountPath: /assets
      - command:
        - q3
        - content
        - --seed-content-url=http://content.quakejs.com
        image: docker.io/criticalstack/quake:v1.<span>0.5</span>
        name: content-server
        ports:
        - containerPort: <span>9090</span>
        volumeMounts:
        - name: quake3-content
          mountPath: /assets
      volumes:
        - name: quake3-server-config
          configMap:
            name: quake3-server-config
        - name: quake3-content
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: quakejs
spec:
  type: LoadBalancer
  selector:
    run: quakejs
  ports:
    - port: <span>80</span>
      targetPort: <span>8080</span>
      name: http
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: quake3-server-config
data:
  config.yaml: <span>|
</span><span>    fragLimit: 25</span>
    timeLimit: 15m
    bot:
      minPlayers: <span>3</span>
    game:
      motd: <span>"Welcome to Critical Stack"</span>
      type: FreeForAll
      forceRespawn: <span>false</span>
      inactivity: 10m
      quadFactor: <span>3</span>
      weaponRespawn: <span>3</span>
    server:
      hostname: <span>"quakekube"</span>
      maxClients: <span>12</span>
      password: <span>"changeme"</span>
    commands:
      - addbot sarge <span>2</span>
    maps:
    - name: q3dm7
      type: FreeForAll
      timeLimit: 10m
    - name: q3dm17
      type: FreeForAll
    - name: q3wctf1
      type: CaptureTheFlag
      captureLimit: <span>8</span>
    - name: q3tourney2
      type: Tournament
    - name: q3wctf3
      type: CaptureTheFlag
      captureLimit: <span>8</span>
    - name: ztn3tourney1
      type: Tournament</code></pre></div>
<p>Apply the yaml manifest to your k3s cluster:</p>
<div><pre><code data-lang="bash">$ kubectl apply -f example.yaml 
deployment.apps/quakejs created
service/quakejs created
configmap/quake3-server-config created</code></pre></div>
<p>Wait until all pods are running, and until the inlets-operator created the exit-node:</p>
<div><pre><code data-lang="bash">$ kubectl get pods,service
NAME                                         READY   STATUS    RESTARTS   AGE
pod/inlets-operator-76fb794578-s2fg4         <span>1</span>/1     Running   <span>0</span>          147m
pod/quakejs-tunnel-client-6f7c986dfc-mdt5w   <span>1</span>/1     Running   <span>0</span>          50s
pod/quakejs-786cc496b-g7b7n                  <span>2</span>/2     Running   <span>0</span>          80s

NAME                 TYPE           CLUSTER-IP    EXTERNAL-IP                       PORT<span>(</span>S<span>)</span>        AGE
service/kubernetes   ClusterIP      <span>10</span>.43.0.1     &lt;none&gt;                            <span>443</span>/TCP        152m
service/quakejs      LoadBalancer   <span>10</span>.43.46.33   <span>143</span>.110.174.204,143.110.174.204   <span>80</span>:32116/TCP   80s</code></pre></div>
<p>And that’s it! Open up your favourite browser, load the application and start fraggin’!</p>

<figure>
    <img src="https://johansiebens.dev/uploads/2020-11-22/quakejs.png"> 
</figure>




<hr>

<p><strong>References:</strong></p>

<ul>
<li><a href="https://github.com/criticalstack/quake-kube" target="_blank">https://github.com/criticalstack/quake-kube</a><br></li>
<li><a href="https://github.com/inlets/inlets-operator" target="_blank">https://github.com/inlets/inlets-operator</a><br></li>
<li><a href="https://github.com/alexellis/k3sup" target="_blank">https://github.com/alexellis/k3sup</a><br></li>
<li><a href="https://github.com/alexellis/arkade" target="_blank">https://github.com/alexellis/arkade</a><br></li>
</ul>

      </div></div>]]>
            </description>
            <link>https://johansiebens.dev/posts/2020/11/quake-iii-arena-k3s-and-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25220328</guid>
            <pubDate>Thu, 26 Nov 2020 14:36:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Filesystem and Database are not cutting the problem space right]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25220165">thread link</a>) | @harporoeder
<br/>
November 26, 2020 | https://boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right | <a href="https://web.archive.org/web/*/https://boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-o1-section="main">
            <div data-o1-path="//boomla.com/sys/components/els/page-blog/el/introducing-reusable-components-2/main/layout/main/section-placeholder"><div>
<div data-o1-section="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main">



<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-4"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><p>This blog post explains the problems with using traditional filesystems and databases for <i>web development</i> and shows a better approach.</p><p>The fundamental problem is summarized by the following image:</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/fundamental-difference-between-filesystems-and-databases.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/fundamental-difference-between-filesystems-and-databases.png?height=1024&amp;o1-cache=813ef0bb6c6&amp;width=1024" alt="Fundamental difference between filesystems and databases"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-29"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><p>Traditional filesystems and databases have very different properties. Traditional filesystems are best suited for storing large objects while databases for structured data. Traditional filesystems have hierarchy (folders), databases have transactions.</p><p>This makes web development way more complex than it should be. Let's look at just one issue.</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-30"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h2>Where to store user uploaded images?</h2></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/where-to-store-user-uploaded-images.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/where-to-store-user-uploaded-images.png?height=1024&amp;o1-cache=fe8584f5156&amp;width=1024" alt="Where to store user uploaded images, on the Filesystem or in the Database?"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-10"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><p>As we are talking about an image <i>file</i>, it comes natural to store it on the traditional <b>filesystem</b>. Unfortunately, traditional filesystems don't support transactions. Getting the security aspects right is hard. It's a challenge to make consistent backups given that you can't just stop the world. Inevitably, a traditional filesystem will be modified while you are working on the backup. Sooner or later this will cause problems.</p><p><b>Databases</b> can solve all of the above. They have transactions. If you do a backup, it will likely be consistent by default. The problem is, databases are bad with large objects. They are a bad choice if you want to serve lots of users.</p><p>This is really frustrating. Why can't we have a storage system that combines the best of both worlds?</p><p>I want this:</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/the-desired-new-storage-system-that-has-the-properties-of-both-filesystems-and-databases.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/the-desired-new-storage-system-that-has-the-properties-of-both-filesystems-and-databases.png?height=1024&amp;o1-cache=1b28b66ba06&amp;width=1024" alt="The desired new storage system that has the properties of both filesystems and databases"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-7"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h2>The problem space is cut along the wrong dimensions</h2><p>Let's take a step back and look at the big picture. This is how the problem space for storing data is currently divided:</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/filesystem-and-database-cutting-the-problem-space.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/filesystem-and-database-cutting-the-problem-space.png?height=1024&amp;o1-cache=455ea105c46&amp;width=1024" alt="Filesystem and Database cutting the problem space"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-12"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><p>The problem space should be divided along <i>conflicting requirements</i>.</p><p>For <b>example</b>, storing ice cream and fruits have conflicting requirements. Ice cream has to be frozen while freezing directly harms fruits. Ice cream requires below zero temperatures while fruits require above zero temperatures. That's a hard conflict. <i>They require different storage solutions.</i></p><p>The thing is, traditional filesystem and database features have no conflicts. Or tell me a single feature that requires:</p><ul><li><p>the <i>lack of </i><b>hierarchy</b> support,</p></li><li><p>the <i>lack of </i><b>large object</b> support,</p></li><li><p>the<i> lack of</i> <b>transaction</b> support, or</p></li><li><p>the<i> lack of</i> <b>structured data</b> support.</p></li></ul><p>There is none. Lack of them doesn't add value, it only makes programming harder.</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-18"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h2>Conflicting requirements</h2><p>The real conflicting requirements are:</p><ul><li><p>Some changes <b>must be controlled </b>by the owners, while</p></li><li><p>other changes <b>can not be controlled</b>.</p></li></ul></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/conflicting-storage-system-requirements-by-web-development.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/conflicting-storage-system-requirements-by-web-development.png?height=1024&amp;o1-cache=9bc055b07c6&amp;width=1024" alt="Conflicting storage system requirements by web development"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-11"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h3>Controlled changes</h3><p>Some data of the website must be controlled, that is, only changed by the website's owners. This includes the codebase, the page structure, blog post contents, some assets like images and videos or even highly structured data like product features. Such data shall not be changing in the production environment<a href="#footnotes"><sup>1</sup></a> as that would mean your visitors see work-in-progress changes that may even break the website temporarily.</p><p>Controlled data shall be edited in <b>development environments</b> which shall be clone-able from the production environment. It often requires <b>version control</b> and <b>non-linear development</b> (branching and merging). Upon shipping a new version of the codebase to the production environment, the new state should<i> replace</i> the old state.</p><h3>Uncontrolled changes</h3><p>On the other hand, there are changes that simply <i>can not be controlled</i>. This includes user contributions like comments and webshop orders. It includes changes made by automatically executed scripts, for example one that resets counters at midnight. It shall include logs generated while serving requests.</p><p>Uncontrolled data consists of <b>linear, sequential changes</b> thus it requires linear snapshots not non-linear feature branches. When cloning the production environment for development purposes, uncontrolled data will typically need to be cloned as well thereby giving you complete freedom to try anything without a complex setup process. This also helps reproducing bugs in minimal time. Upon shipping a new version of the codebase to the production environment, the new state of uncontrolled data shall be typically <i>dropped</i> to prevent accidentally overwriting changes made in production.</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-6"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h2>The Boomla Filesystem</h2><p>Most websites and web apps need both a controlled and an uncontrolled storage area. Traditional filesystems and databases are used to store both due to the differences in their capabilities.</p><p>Boomla provides a radically simpler web development experience by cutting the problem space along real conflicting requirements, thereby eliminating accidental complexity:</p><ol><li><p>The Boomla Filesystem combines the properties of traditional filesystems and databases.</p></li><li><p>Boomla provides separate filesystems based on different storage requirements, one for controlled changes and one for uncontrolled changes.</p></li></ol><h3><span>Unified storage</span></h3><p>The Boomla Filesystem has a <b>tree structure</b> like a traditional filesystem having files. As expected, Boomla files can store <b>large objects</b>, like images and videos. To store <b>structured data</b>, Boomla files have file attributes to store custom anything in a key-value format, similar to database rows having fields. Finally, the Boomla Filesystem is <b>transactional</b>.</p><p>If you are interested in learning more, see the <a href="https://boomla.com/docs/how-it-works/anatomy-of-the-boomla-filesystem">Anatomy of the Boomla Filesystem</a>.</p><h3><span>The two Filesystems</span></h3><p>Every website contains two filesystem trees as explained above.</p><ul><li><p>The <b>Static Filesystem </b>is the controlled filesystem, and</p></li><li><p>the <b>Dynamic Filesystem</b> is the uncontrolled filesystem.</p></li></ul></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/each-website-has-a-static-filesystem-and-a-dynamic-filesystem.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/each-website-has-a-static-filesystem-and-a-dynamic-filesystem.png?height=1024&amp;o1-cache=5db4799c5d6&amp;width=1024" alt="Each website has a Static Filesystem and a Dynamic Filesystem"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-16"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h3>Eliminating global data</h3><p>We have addressed how to have a hierarchy of objects everywhere, even on the dynamic filesystem but if we store it as a separate filesystem tree, we are back to square one: a global shared namespace. Instead, what we need is the ability to <i>attach</i> dynamic volumes anywhere on the static filesystem, like so:</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/dynamic-volumes-attached-to-the-static-filesystem.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/dynamic-volumes-attached-to-the-static-filesystem.png?height=1024&amp;o1-cache=cb5a4070bc6&amp;width=1024" alt="Dynamic volumes attached to the Static Filesystem"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-21"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><p>The <i>existence</i> of these dynamic volumes must be version controlled but their contents must not be as they are constantly changing. They must be somehow stored on the dynamic filesystem instead.</p><p>Let's see an <b>example</b>. Imagine a comments element embedded into a page. It shall have its own dynamic volume with its own schema. The existence of the comments element must be version controlled but not the actual comments. They can't be: they would cause continuous merging issues.</p><p>Removing either the comments element itself (or even the page it is embedded in) must remove the comments element itself with all associated user comments. In the traditional setup, you would have to write lots of code yourself to figure out what data needs to be removed. This takes time (money) and may be non-trivial when there are several 3rd party plugins installed. With proper encapsulation, the system can automatically do this for you.</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/storing-comments-on-the-boomla-filesystem.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/storing-comments-on-the-boomla-filesystem.png?height=1024&amp;o1-cache=0e8deb4ac96&amp;width=1024" alt="Storing comments on the Boomla Filesystem"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-20"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><div><p>So here is how this works. Boomla files have a <i>link</i> property. You can attach a dynamic volume anywhere on your website's filesystem by simply setting the file's link property to <code>dynamic</code>.</p></div></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/the-underlying-structure-of-embedded-dynamic-volumes.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/the-underlying-structure-of-embedded-dynamic-volumes.png?height=1024&amp;o1-cache=2c2c8bfd096&amp;width=1024" alt="The underlying structure of embedded dynamic volumes"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-25"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><p>By doing so, the system will create a new volume on the hidden dynamic filesystem and map it to the linking file. (Using the linking file's file ID.) From that point on, you will be able to write the dynamic subtree as usual. It will appear as if it was part of your website's filesystem tree.</p><p>That way, in Boomla, deleting the page holding the comments will <i>also remove the actual comments</i>.</p><p>The root volume of the dynamic filesystem is hidden by design, it's not directly accessible. If you are interested, see the <a href="https://boomla.com/docs/how-it-works/anatomy-of-the-boomla-filesystem/file-link/dynamic-link">dynamic link docs</a> for more details.</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-19"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h2>Undo, redo</h2><p>One of the really powerful features of the Boomla Filesystem is that undo/redo is available for the entire website. It <i>makes</i> us experiment. We can try things, we can fail and we can always undo. It's a huge boost to <i>dare to try</i>.</p><p>The great news is, <b>undo/redo will still be available</b> when collaboration is enabled.</p><p>There is a little caveat though. In the <b>production environment</b> you may have multiple users making changes. You definitely don't want to accidentally undo a comment or an order made by someone else. Plus in production, the static filesystem is read-only as you probably don't want your visitors to see your work-in-progress. Because of this, undo/redo is not available in the production environment (master branch).</p><p>Once you clone the production environment and thus create a <b>development branch</b>, undo/redo will be available for your entire website. Changes made to the static and dynamic filesystems are bundled in a single atomic transaction, creating a single undo point. That way, whatever changes you make, you will be able to use undo/redo.</p><p>To rephrase, you either don't have undo/redo at all (master branch) or you have undo/redo for your entire website (secondary branches).</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-8"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><h2>Users, Access Control, Security</h2><p>Using a traditional filesystem and database poses another problem with access control.</p><p><b>Access control can only be enforced in a layer that has access to both users and data.</b> It's just impossible otherwise. Websites and web apps introduce their own user concepts. As a result, they should take over all access control responsibilities. Data access should only happen through a single, well defined layer.</p><p>Unfortunately, that didn't happen. Both databases and the underlying OS have their own user concepts with their own means of doing access control. Plus your chosen CMS or framework has its own user concept and access control mechanisms. Application developers have access to all of them. They have to call all the right functions themselves to make sure everything is secure. Every application developer has to be a security expert and not make mistakes.</p><p>If you are wondering how this could possibly be secure - don't worry, it isn't. <b>It's a complete disaster.</b> (Pro tip: make your competitors use this.)</p></div>

</div></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/traditional-security-model-vs-boomla-security-model.png"><p><img src="https://cdn.boomla.net/v2.0/boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/traditional-security-model-vs-boomla-security-model.png?height=1024&amp;o1-cache=4b6cc962a86&amp;width=1024" alt="Traditional security model vs Boomla security model"></p></div>
<div data-o1-path="//boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right/main/text-14"><div>




<div data-o1-contenteditable="body" data-o1-contenteditable-format="html"><p>By providing a single storage solution in a single layer with website users, <b>Boomla can do access control centrally</b>. Most importantly, it can be enforced so application developers don't need to do extra work to get it right. They don't need to be security experts.</p><p>Additionally, this new approach for separating data into static …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right">https://boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right</a></em></p>]]>
            </description>
            <link>https://boomla.com/blog/filesystem-and-database-are-not-cutting-the-problem-space-right</link>
            <guid isPermaLink="false">hacker-news-small-sites-25220165</guid>
            <pubDate>Thu, 26 Nov 2020 14:14:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parse, don’t type-check]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 115 (<a href="https://news.ycombinator.com/item?id=25220139">thread link</a>) | @todsacerdoti
<br/>
November 26, 2020 | https://neilmadden.blog/2020/11/25/parse-dont-type-check/ | <a href="https://web.archive.org/web/*/https://neilmadden.blog/2020/11/25/parse-dont-type-check/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3533">
	<!-- .entry-header -->

	
	
	<div>
		
<p>There’s a fantastic article from last year titled <a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, don’t validate</a>. I’d highly recommend it to any programmer (along with the more recent follow up <a href="https://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/">Names are not type safety</a>). The basic idea is that there are two ways to check that some input to a function is valid:</p>



<ul><li>A <em>validator</em> checks that the input is valid and throws an error if not. It doesn’t return anything. For example, checking that a list is not empty. </li><li>A <em>parser</em> does the same as a validator, but returns a more specific representation of the input that ensures that the required property is satisfied. For example, checking that a list is not empty and <em>returning a NonEmptyList type</em>. </li></ul>



<p>The thesis of the article is that parsers are preferable to validators. If you’ve not read the original article, please do so – it’s very well written and makes the case much better than I can summarise it. The essential message is to <em>make illegal states unrepresentable</em>. In the article, this is done by making use of the type system. This is a philosophy I entirely agree with, but I want to point out and expand upon one ironic aspect of the argument:</p>



<p><strong><em>A type checker is a paradigmatic example of a validator!</em></strong></p>



<p>A type checker, after all, takes as input an already parsed program representation and rejects it if it fails to type-check. It doesn’t return a more specific representation of the program. (Not to be confused with <em>type inference</em>, which does return more information, but only about the types). </p>



<p>So what would be the parser alternative to a type checker in a programming language? One approach would be to actually create a more specific grammar that eliminates illegal states. For example, if a given function requires a number that must be between one and five, then rather than having a generic syntax for function calls such as:</p>



<pre>fun_call ::= fun_name ‘(‘ integer ‘)’</pre>



<p>You would instead define specific grammar rules for the functions you provide:</p>



<pre>one_to_five ::= 1 | 2 | 3 | 4 | 5<br>fun_call ::= ‘lil_fac(‘ one_to_five ‘)’<br>         | ... other function definitions ...</pre>



<p>Creating such specific grammars is one approach to crafting <em><a href="https://www.martinfowler.com/bliki/DomainSpecificLanguage.html">domain-specific languages</a> </em>(DSLs). And indeed, DSLs are a great way of ensuring that illegal states aren’t representable. Of course, this is not a scalable solution if you want to make a general-purpose language with user-defined functions.</p>



<p>An alternative to having a very specific grammar is to instead <em>raise the level of abstraction</em>, so that it is easier to avoid invalid states. For example, a common source of programming errors is out of bounds indexing into arrays. This occurs because the programming language only offers a primitive indexing operation: <code>a[x]</code>. Here “x” is an integer but might be out of bounds, resulting in an exception or crash (if you’re lucky). One way we could prevent this would be to define a more specific type of “integers between zero and 12” so that the type system rejects any potentially invalid indexing operations, and then track this more precise type for each array — validation again. </p>



<p>A different approach would be to notice that there are typically a few common ways that you want to use an array and provide specific abstractions in the language that capture those uses. For example, it’s very common to want to iterate through the array performing some kind of calculation. Rather than making everyone manually write out the for-loops for doing this — do arrays in this language start at 0 or 1? Do they stop at array.length or array.length – 1? Do array indexes have a specific type? — you could instead offer a general <a href="http://www.cs.nott.ac.uk/~pszgmh/fold.pdf">fold </a>(reduce) operation. Likewise, instead of making people write their own hashtables you could provide one built-in to the language itself. By providing better abstractions you make it less likely that programmers will hit illegal states. </p>



<p>You can then go further and <em>remove</em> the more primitive operations, only allowing access to the higher level abstractions. Hopefully in 2020 most programmers would agree that removing goto statements in favour of higher level structured programming abstractions was a win, and the same can be true of other low-level constructs: nulls, raw memory pointers, etc. </p>



<p>In the world of computer security, there is a direct analogue of this discussion. The security model of most computer systems allows a separation between operations I <em>can</em> (try to) perform and operations I am <em>allowed</em> to perform: I can try and delete your website, but (hopefully) the request will be rejected as unauthorized. In contrast, in <a href="https://en.wikipedia.org/wiki/Object-capability_model">object-capability systems</a> my ability to even invoke such an operation depends upon me holding an unforgeable c<em>apability </em>granting me permission to perform it. It’s not possible to even attempt an operation that I am not allowed to perform. For example, in a REST API using <a href="https://neilmadden.blog/2019/01/16/can-you-ever-safely-include-credentials-in-a-url/">capability URIs</a>, I cannot simply send a DELETE request to /users/alice, but instead need to send it to some unguessable random URI – if I don’t already have that URI then I can’t even begin to send the request. Object-capability security therefore aims to make <em>unauthorized states unrepresentable</em>. </p>



<p>Perhaps the most widely known embodiment of the object-capability paradigm is the <a href="http://www.erights.org/">E programming language</a>: a <em>dynamically-typed</em> object-oriented programming language. Although now somewhat abandoned, it is a fascinating language with a lot of great ideas. E uses strong abstraction boundaries to ensure security. Be warned: the E website is a rabbit hole of incredible depth!</p>



<p>In my twenties, I used to do a lot of programming in <a href="https://wiki.tcl-lang.org/">Tcl</a>. A language that most would agree is about as far removed from a modern statically typed programming language as you can get. (Often pointed out with something close to utter disgust). And yet the idea of making illegal states unrepresentable was entirely natural to myself and other Tcl programmers. I would frequently start a programming project by creating a <a href="https://www.tcl.tk/man/tcl/TclCmd/interp.htm#M12">blank-slate interpreter</a>, stripping out all the built-in language constructs (<a href="http://nsl.com/">loops</a>, procedures, even <a href="https://tcl.tk/man/tcl/TclCmd/expr.htm">arithmetic</a>), and then adding back in a carefully selected set of high-level domain-specific primitives. This DSL would then become the application’s configuration file, safe in the knowledge that illegal configurations cannot be expressed. </p>



<p>To summarise, my point is not that type systems are bad or that the original essay is flawed. On the contrary, I thank the flying spaghetti monster almost every day for the type system in my day job (and that is only Java’s tepid concoction), and I think the “parse, don’t validate” essay is excellent. But the last two decades have seen such advances in type systems and the adoption of typeful programming patterns that we are in danger of thinking that type systems are the only way of achieving correctness in software construction. They are a tremendously powerful tool, but more basic techniques of abstraction and information hiding can be just as powerful. The goal of making illegal states unrepresentable should be one of the defining goals of software engineering, but there are many valid ways to crack that nut.</p>



<p><em>Shameless plug: I discuss capability URIs in depth in chapter 9 of <a href="https://www.manning.com/books/api-security-in-action">my book on API security</a>, just published by Manning. I also discuss using types to enforce security properties in chapter 6. </em></p>

<div>
	<!-- .author-avatar -->

	<div>
		

		<p>
			Security Director at ForgeRock. Experienced software engineer with a PhD in computer science. Interested in application security, applied cryptography, logic programming and intelligent agents.			<a href="https://neilmadden.blog/author/neilmadden/" rel="author">
				View all posts by Neil Madden			</a>
		</p><!-- .author-bio -->
	</div><!-- .author-description -->
</div><!-- .author-info -->
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://neilmadden.blog/2020/11/25/parse-dont-type-check/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25220139</guid>
            <pubDate>Thu, 26 Nov 2020 14:11:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I launched a paid community in one month]]>
            </title>
            <description>
<![CDATA[
Score 179 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25219924">thread link</a>) | @micropoet
<br/>
November 26, 2020 | https://monicalent.com/paid-community-launch/ | <a href="https://web.archive.org/web/*/https://monicalent.com/paid-community-launch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

          <article>

              

              
              <figure>
                  <img src="https://monicalent.com/images/blog/moraine-lake.jpg" alt="How My Paid Community Made $5K in Its First Week">
              </figure>
              

              <section>
                  <div>
                      

<p>Who’s got two thumbs and shipped her first of <a href="https://monicalent.com/12x-startup/">12 startups in 12 months</a> <em>on schedule</em>? That’s right, this girl.</p>

<p>In its first week, the <a href="https://bloggingfordevs.com/pro/" alt="Blogging for Devs Community (opens in a new tab)" target="_blank">Blogging for Devs Community</a>
 reached $5K in revenue through
a combination of lifetime deals, subscriptions, and my first ever Bitcoin transaction (thanks, Nico!).</p>

<p>A profitable first week isn’t what makes this a success in my book.</p>

<p>I’m <em>thrilled</em> at all the cool members who decided to join.
Exactly as I’d hoped, each person adds something unique and interesting to the community,
and I’m really excited to see where it goes.</p>

<p>So, welcome to my first monthly retrospective.</p>

<p>In this post I’ll be sharing a behind-the-scenes look at the first week of my paid community launch
and reveal what I’m shipping in November.</p>

<p>Below you’ll discover charts, graphs, screenshots, strategy, reflections, and my master plan
for growing Blogging for Devs through viral, generated content 🔮</p>

<p>I promise, it’s good.</p>



<p>First question: Did I really?</p>

<p>Before talking about what I’ve been up to in October, it’s important to
get on the same page about this:</p>

<p><strong>Even though I began charging to join the community this month, the community
itself was launched as a sort of “closed beta” back in July.</strong></p>

<p>The newsletter that helped me connect with first 100 free members (and most of the
paid members — more on that later) was launched in May.</p>

<p>You know what they say about overnight success.</p>

<p>Anyway, here’s what and how I launched in a month.</p>

<p><img src="https://bloggingfordevs.com/images/bfd-community-preview-image.png" alt="Blogging for Devs Pro Community"></p>

<p><a href="https://bloggingfordevs.com/pro/" alt="Blogging for Devs Community (opens in a new tab)" target="_blank">Blogging for Devs Community</a>
 is a paid
community for developers, makers, engineering managers, and technical founders to grow their blogs
through feedback, collaboration, and continuous learning.</p>

<p>We have accountability groups, virtual events and workshops, members-only resources and original content,
and most importantly — super kind and knowledgeable members.</p>

<p>For the first 250 people to join, it costs $12/month, $96/year, or $180 once.</p>

<p>The discussions are powered by <a href="http://circle.so/" alt="Circle (opens in a new tab)" target="_blank">Circle</a>
 and rocking
a custom theme I hacked together through highly specific CSS selectors and
vanilla JavaScript.</p>

<p><img src="https://monicalent.com/images/circle-code-snippets.png" alt="Vanilla JavaScript"></p>

<blockquote>
<p>And they say you only need to know React these days 😝</p>
</blockquote>

<p>It integrates with the Gatsby website through a custom OAuth provider, which uses Firebase
for authentication. It’s all serverless and cloud native and such.</p>

<p>In October, I built Events, a member RSS feed, signup, payment, the landing page, onboarding, profiles, welcome email sequence,
and a lean batch of starter content. I designed everything myself in Figma. For more granular detail on building the product,
you can see the day-to-day in my <a href="https://twitter.com/monicalent/status/1315678202988244993" target="_blank">twitter thread</a>.</p>

<p>Enough about tech, let’s talk launch.</p>

<p><img src="https://bloggingfordevs.com/images/bfd-pro-screenshot-2.png" alt="Blogging for Devs Community"></p>

<h2 id="success-metrics-why-you-won-t-find-an-overall-conversion-rate-in-this-report">Success metrics: Why you won’t find an overall conversion rate in this report</h2>

<p>My real goal for the community was to get
great people in, and not to overly optimize for converting anyone with a pulse.</p>

<p>That’s why my biggest launch fear wasn’t that no one would sign up.</p>

<p>It was that people I <em>don’t like</em> would sign up. Spammers, self-promoters, attention-seekers,
jerks.
Thankfully it hasn’t been the case and everyone is awesome so far 🤞</p>

<p>I try to scare those types away with a prominent Code of Conduct and an “Is this right for you?” checklist.</p>

<p><img src="https://monicalent.com/images/community-checklist.png" alt="Vanilla JavaScript"></p>

<p>That’s why I have no idea what my “conversion rate” for the community is and I don’t actually care.</p>

<p>I <em>do</em> pay attention to the opt-in rate for my free newsletter, though, so don’t take this as, “Girl doesn’t care about metrics.”</p>

<p>I care about metrics, just <em>not</em> on the community landing page.</p>

<p>The reason is, joining a community is a long-term thing.
Something like this often takes time and multiple exposures for people
to make the decision — it was the same for me and <a href="https://rosie.land/" alt="Rosieland (opens in a new tab)" target="_blank">Rosieland</a>
 and <a href="http://trends.co/" target="_blank">Trends</a>.</p>

<p>The more interesting question is this:</p>

<blockquote>
<p>What I can I learn about the members who did sign up, so I can find more people like them?</p>
</blockquote>

<p>With that, it’s chart time 👯‍♀️</p>



<p>Were paying members wooed by my slick landing page, or convinced by
a carefully crafted tweet?</p>

<p>Turns out, probably not.</p>

<p><img src="https://monicalent.com/images/community-launch-members.png" alt="Blogging for Devs Community Member Attribution"></p>

<p>Most new members were already subscribed to <a href="https://bloggingfordevs.com/" target="_blank">my free weekly newsletter</a> about blogging for developers, which is about 4,000 subscribers strong.</p>

<p>Every Friday for nearly six months, I’ve been sending out original content about
blogging, SEO, going viral, attracting an audience, and a splash of motivational moments. It takes me an entire day to write.</p>

<p>Out of 69 new paying members in the first week, <strong>only three were
unattributable</strong> at least one of three sources:</p>

<ol>
<li>Waitlister</li>
<li>Newsletter Subscriber</li>
<li>Twitter Follower</li>
</ol>

<p><img src="https://monicalent.com/images/community-launch-channels.png" alt="Blogging for Devs Paid Community Launch Channels"></p>

<blockquote>
<p><strong>Newsletter backstory:</strong> I started the newsletter in May, and it’s since grown to over 4,000 subscribers. If you want to know how, check out the writeups I’ve done <a href="https://bloggingfordevs.com/launch-a-newsletter/" alt="here (opens in a new tab)" target="_blank">here</a>
 and <a href="https://bloggingfordevs.com/product-hunt-launch/" target="_blank">here</a>.</p>
</blockquote>

<p>Many people had multiple touchpoints: subscriber <em>and</em> on the waitlist, or followed me on twitter
<em>and</em> subscriber to the newsletter.</p>

<p>However, only <strong>31% of new members follow me on Twitter</strong>. I’m not offended, to the contrary —
I prefer it.</p>

<p>Now I know that if I want to grow the community, the best thing I can do
is have more of the right people <strong>join the newsletter first</strong>.</p>

<p>That’s why my goal is to grow the newsletter, and trust that the community
will eventually benefit from the best subscribers joining up.</p>

<p>Let’s take a dip into revenue for a second.</p>

<h2 id="how-much-and-where-did-revenue-come-from">How much and where did revenue come from?</h2>

<p>As I said in the <a href="https://twitter.com/monicalent/status/1325008065041666049" alt="tweet (opens in a new tab)" target="_blank">tweet</a>
 where I collected ideas for this article, the $5K revenue is <em>not</em> MRR (monthly recurring revenue).</p>

<p>MRR for the Blogging for Devs Community is just $516 according to Stripe.</p>

<p>So where did the first week’s $5K in revenue come from?</p>

<p><img src="https://monicalent.com/images/community-launch-revenue.png" alt="Blogging for Devs Community Revenue"></p>

<p>Someone on Twitter recently asked me if I have any “thought leadership”
to spare on the topic of <strong>lifetime pricing</strong>.</p>

<p>I don’t.</p>

<p>Guess what, I’m neither optimizing for conversion nor <a href="https://en.wikipedia.org/wiki/Customer_lifetime_value" alt="LTV (opens in a new tab)" target="_blank">LTV</a>
 🙃</p>

<p>Offering a lifetime price at a lower cost than 2 years as a member is
really just a way for me to say “Thank you” to people who are in it for the long haul.</p>

<p>I see it as a mutual commitment.</p>

<h2 id="is-this-sustainable-yet">Is this sustainable yet?</h2>

<p>You might see $5K in a week and think it sounds like a lot of money. If only one
could extrapolate that to $20k/mo, then I’d be set.</p>

<p>But of course, it’s not the whole picture:</p>

<ul>
<li>Taxes and healthcare are super expensive here in Germany</li>
<li>I already spend over $300/mo on SaaS tools to run the community</li>
<li>Only $500 currently recurs monthly, assuming zero growth/churn</li>
</ul>

<p>Still, I have a <strong><em>very</em> long way to go</strong> before the community is sustainable.</p>

<p>That’s why my November startup is a side project to scale reach of the newsletter,
which should <em>in turn</em> drive the growth of the community.</p>

<p>I think marketers would call this a “funnel”.</p>

<p><img src="https://monicalent.com/images/community-funnel.png" alt="Blogging for Devs Community Funnel"></p>

<p>I think about it a little more like concentric circles approaching a core.</p>

<p>My next task is to expand the outermost ring with the kind of people who are
likely to join and enjoy the newsletter.</p>

<h2 id="my-master-plan-for-growing-blogging-for-devs-beyond-twitter-and-word-of-mouth">My master plan for growing Blogging for Devs beyond Twitter and word of mouth</h2>

<p>Channels die. Or at least, they become exhausted.</p>

<p>Although people still write me emails saying they’ve been following for
years, and just found out I have a newsletter — most of that is probably in the past.</p>

<p>People who know me, know about Blogging for Devs.</p>

<p>I really don’t want to spend all day on Twitter “growing my social media presence”.
I’d rather be building cool shit and helping other people build cool shit, too.
Let people find me through that.</p>

<p>Right now, word of mouth is what grows the newsletter.</p>

<p>Random mentions and links.  I find out through welcome emails or through
stalking my backlink reports from time to time.</p>

<p><img src="https://monicalent.com/images/newsletter-replies.png" alt="Lala"></p>

<blockquote>
<p>I do reply to everyone who emails me, but I was running a bit behind
after spending the prior week following the US election 🙈</p>
</blockquote>

<p>On average, I gain about 5-10 subscribers per day.</p>

<p>A prominent mention on Twitter, Indie Hackers, or the success of a subscriber’s
blog post can push than number over 100.</p>

<p><strong>The problem? Today, word of mouth isn’t sufficient to grow the newsletter quickly enough to reach sustainability in the near term.</strong></p>

<p>Ironically, I’m also a blogger with no spare time to grow it writing a ton of individual blog posts 😅</p>

<p>So how can I grow my newsletter about blogging, without blogging <em>myself</em>,
and without relying on Twitter for all my traffic?</p>

<p>Here comes the master plan. I hope it works.</p>

<h2 id="how-i-ll-build-traffic-to-blogging-for-devs-while-writing-virtually-no-blog-posts">How I’ll build traffic to Blogging for Devs (while writing virtually no blog posts)</h2>

<p>I have a theory. Well, I have a few theories.</p>

<p>The first one is this: Developers want to discover blogs written by other developers.
Reading company engineering blogs is fine, but quality content from their peers or individuals
they admire is far more interesting.</p>

<p>Most places to discover developer content feature individual articles. Hacker
News, Reddit, and Twitter all fundamentally work this way.</p>

<p>But what’s more interesting is the person behind the blog. Their personality, what makes them unique,
inspiring, and worth following in their own right.</p>

<p>To back this up, I present Exhibit A.</p>

<blockquote><div lang="en" dir="ltr"><p>Dear Tech Twitter:</p><p>What is your NUMBER ONE favorite blog by someone in tech, who has a <em>distinct writing style</em>? Where you read their articles for their <em>unique personality or voice</em>?</p><p>(Pls no list of twitter handles, direct link to the blog is 👍)</p></div>— Monica Lent (@monicalent) <a href="https://twitter.com/monicalent/status/1299054522074005504?ref_src=twsrc%5Etfw">August 27, 2020</a></blockquote> 



<p>Apart from the fact that asking for any kind of recommendation on Twitter is a
one-way ticket to pandemonium, you can tell from the replies that
people feel strongly about the topic. 400+ responses.</p>

<p>When I build something, I like that the topic evokes a response like this.</p>

<p><strong>It means people care.</strong></p>

<p>Extension of the theory (this time with less evidence): Many people who read
amazing tech blogs also aspire to create one themselves.</p>

<p>Ergo, if I create a place for people to discover the best developer blogs,
there’s a good chance people who show up will like my newsletter, too.</p>

<p>So here’s my plan.</p>

<p><img src="https://monicalent.com/images/bfd-rankings-social-preview.png" alt="Blogging for Devs Trends"></p>

<h2 id="what-i-m-launching-in-november">What I’m launching in November</h2>

<p>My plan is to crowdsource recommendations for the best …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://monicalent.com/paid-community-launch/">https://monicalent.com/paid-community-launch/</a></em></p>]]>
            </description>
            <link>https://monicalent.com/paid-community-launch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25219924</guid>
            <pubDate>Thu, 26 Nov 2020 13:42:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Learned About UX Writing from a British Prog Drummer and David Lynch]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25219036">thread link</a>) | @ingve
<br/>
November 26, 2020 | https://blogg.bekk.no/what-i-learned-about-ux-writing-from-a-british-prog-drummer-and-david-lynch-2b81f09aadfc | <a href="https://web.archive.org/web/*/https://blogg.bekk.no/what-i-learned-about-ux-writing-from-a-british-prog-drummer-and-david-lynch-2b81f09aadfc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p><a href="https://erik-mathisen.medium.com/?source=post_page-----2b81f09aadfc--------------------------------" rel="noopener"><img alt="Erik Mathisen" src="https://miro.medium.com/fit/c/96/96/1*Js3KmpC-WLG-xQ4kTspN6g.png" width="48" height="48"></a></p></div></div></div></div><p id="3a97"><em>There are so many brilliantly written articles about UX Writing out there so I decided to take a look at it from a more personal point of view.</em></p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1460/1*YjSEL3-Jo9Zgtj2mrX28HQ.png" width="730" height="410" srcset="https://miro.medium.com/max/552/1*YjSEL3-Jo9Zgtj2mrX28HQ.png 276w, https://miro.medium.com/max/1104/1*YjSEL3-Jo9Zgtj2mrX28HQ.png 552w, https://miro.medium.com/max/1280/1*YjSEL3-Jo9Zgtj2mrX28HQ.png 640w, https://miro.medium.com/max/1400/1*YjSEL3-Jo9Zgtj2mrX28HQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*YjSEL3-Jo9Zgtj2mrX28HQ.png?q=20"></p></div></div></div></figure><blockquote><p id="563f">“I mean it like it is, like it sounds.”</p></blockquote><p id="4a3b">Most fans of Twin Peaks will probably remember this line, even though it is overshadowed by a significant number of other quotes from TP. If you have not not seen it yet, go stream that masterpiece right now. #spoilers</p><p id="0d41"><strong>Why is this particular line so important?</strong> Because it is part of the keychain needed to unlock the many abstract concepts Lynch and Mark Frost presents to us, the viewers. The line is from the episode where Mike enters the dream of agent Cooper, revealing clues about Laura Palmers killer. What I find interesting about this line is its deceptive yet clear intention. The viewer is told what to pay attention to, but the dreamy context suggest we might be deceived.</p><p id="f29a">But some things are just what it is, how it sounds.</p><p id="57db"><em>Intuition guides us, one screen at the time.</em></p><p id="4949">For 10 years, I was writing for various advertising companies. My job was to craft words to lure the reader into whatever brand-context I was working on at that time, often with the help of abstractions of concepts, allegories, and other creative tools. It taught me a lot about perception and how I could, very subtly, plant hints for the viewer to decipher the brand message. But most importantly, it made me understand how the brain systematically create mental concepts to percieve and understand the world around it. Words play a crucial part in this process. An incredible 50 % of all words we hear cannot be understood out of context (when presented in isolation). By using concepts, the brain learns to categorize and make sense of all this variable noisy flow of information.</p><p id="b300">How ironic, you might think, that I found clarity in one of the most surreal dreamscapes ever to air on TV in our lifetime. To me, that’s the beauty of inspiration. It rises to our consciousness like wild salmon jumping upstream a river, striving to get a foothold in our mind amidst all the noise.</p><p id="4668">Like Lynch and Frost, I left the keys in plain sight for the audience to discover and interpret. Creative advertising requires just that, an idea we, the creators, code, and then let the audience decode. But UX Writing very often requires quite the opposite. You must write it like it is.</p><p id="856a">It has always been a beautiful mystery to me, how clarity has the power to shape us. How it informs us simply by being less intrusive or more truthful. <br>To me clarity is not the equivalent of writing short and efficient sentences. It can be about that, but not just that. Clarity is about finding the true essence of whatever you’re trying to convey. It’s what will make your followers believe you or not and go where you’re guiding them. Or not.</p><blockquote><p id="edd9"><strong><em>Just do it</em></strong></p><p id="2f63"><strong><em>I have a dream</em></strong></p><p id="78b1"><strong><em>Fire, walk with me</em></strong></p></blockquote><p id="d321">But clarity is also this</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1660/1*_pOIZ5e4OVW8mpSHrj55qA.png" width="830" height="1170" srcset="https://miro.medium.com/max/552/1*_pOIZ5e4OVW8mpSHrj55qA.png 276w, https://miro.medium.com/max/1104/1*_pOIZ5e4OVW8mpSHrj55qA.png 552w, https://miro.medium.com/max/1280/1*_pOIZ5e4OVW8mpSHrj55qA.png 640w, https://miro.medium.com/max/1400/1*_pOIZ5e4OVW8mpSHrj55qA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/42/1*_pOIZ5e4OVW8mpSHrj55qA.png?q=20"></p></div></div></div><figcaption>Airbnb safely disarming thousands of anxious customers with one single line of text.</figcaption></figure><p id="e258">The real challenge is to fuse the two worlds into one. For that to happen you’ll need to sit down, relax, focus, open your mind and just…</p><p id="cf21">In an interview with <a href="https://www.youtube.com/watch?v=VV7cZB7xqks" rel="noopener">Vanity Fair</a>, Jony Ive, former Chief Design Officer of Apple, said that Steve Jobs had an amazing ability to focus. He managed to eliminate the inevitable noise surrounding any world-changing project and devote all his attention to making it the next big thing.</p><p id="4ba2">Regardless of age, title and which floor you work on, there is a valuable lesson to be learned from this, Focus is needed to build great stuff, but it also essential for knowing when your brand needs to speak up. Or when to shut up.</p><p id="a94a">Understanding when to do what requires <strong>the ability to listen</strong>. I will listen to what the customer says about their experience. Pay attention to what the designers have to say about their intentions and challenges. Concentrate as programmers show me the project’s specifics and possibilities.</p><p id="879e">Jobs did this and was not afraid to change his mind should it benefit his creative singularity. It takes a great amount of willpower to let go of your own ideas.</p><p id="5d5c"><a href="https://youtu.be/woI6t8dCQcQ?t=594" rel="noopener">In an interview with Drumeo,</a> drummer Gavin Harrison, known for his musicality and passion for rhythmic design, shared his tips and methods for coming up with tasteful drum parts, improving your creativity, and your general mindset when playing the drums. While talking about his references from his younger days, he begins talking about drummers who play with time.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1500/1*IX7QE5zUqs3uLgxlMfOH8A.jpeg" width="750" height="500" srcset="https://miro.medium.com/max/552/1*IX7QE5zUqs3uLgxlMfOH8A.jpeg 276w, https://miro.medium.com/max/1104/1*IX7QE5zUqs3uLgxlMfOH8A.jpeg 552w, https://miro.medium.com/max/1280/1*IX7QE5zUqs3uLgxlMfOH8A.jpeg 640w, https://miro.medium.com/max/1400/1*IX7QE5zUqs3uLgxlMfOH8A.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*IX7QE5zUqs3uLgxlMfOH8A.jpeg?q=20"></p></div></div></div><figcaption>Gavin Harrison exploring rhytmic designs in his natural habitat.</figcaption></figure><p id="dfc5">“You’ve probably heard this expression before, but everybody’s job in the band is to play in time, but it’s the drummer’s job to make the time interesting. So, you don’t have to just play, say, if the first verse just needs two and four on the hi-hat, you don’t have to just sit there going… <em>&lt;taps uninspired on the hi-hat&gt;</em> …what I would do is listen to the vocalist and look for spaces to do small musical embellishments. <strong>Put it in the right place, and it’s beautiful. Do it every bar, and it’s horrible.”</strong></p><p id="2340">This is <strong><em>precisely</em></strong> what UX Writers should do (among many other important things). Listen to the project as a whole, look for spaces in between code, design, text, menus, forms — literally every point of interaction — to create something that elevates the project, and therefore the brand. Band. You know what I mean. And yes, I consider UX Writing to be an essential part of building and/or maintaining a brand.</p><p id="d052">Words are like <a href="https://en.wikipedia.org/wiki/Ghost_note" rel="noopener">ghost notes</a> providing subtle dynamics to the sonic scenery. They will make people feel something.</p><p id="5f16">Humans like to be liked. Brands too. Therefore we make and effort to portray ourselves, man and brand, in a way that will serve as purposeful and friendly for our peers. From a brand point of view we would very much like people to feel what we want them to feel about us. This is usually where marketing says “we got this”. And they probably do. Persuasion is needed to increase awareness and market shares. But what happens after we get their attention?</p><p id="fe63">This is where guidance and clarity is provided and needed, not juicy headlines and rethorical tropes. Now it’s time to go with (and steer) the flow.</p><p id="eca1">Some people understand this process intuitively and how to utilize it in many different ways. In a talk at Design Matters 2019, Senior Product Writer at Slack <a href="https://medium.com/u/6aad0c825c59?source=post_page-----2b81f09aadfc--------------------------------" target="_blank" rel="noopener">Andrew Schmidt</a> shared insight from Slacks early days on how language could be a tool for identifying “bad” design, and how they discovered when to inject brand personality and how to do it. They came up with a very simple and interesting rule:</p><p id="f0e8"><strong>Never try to make the user feel<br></strong>Instead, look for the feelings they’re already having.<br>And just be part of those.</p><p id="c24e"><strong>👇🏻</strong></p></div></div><div><div><p id="84c2">I believe Slack is on the right path when it comes to how they percieve UX Writing. They have chosen a much less intrusive approach in a world where our minds are bombarded with emotional hooks ready to be reeled in. But for enhancing your UX Writing, I think being subtle and aware (but don’t forget to surprise once in a while) will take you far.</p><p id="acbe">Is your brands presence needed for solving this particular task?<br>Or is it better to get out of the way for a bit? <br><a href="https://uxplanet.org/the-power-of-whitespace-a1a95e45f82b" rel="noopener"><strong>Treat words in the same way designers treat white space.</strong></a></p><p id="cf73">My family owns a summer cabin near the ocean. In my younger days, I would cruise around in our family’s tiny motorboat. That was when I learned the concept of a rudder, a gentle device for navigating smoothly across the sea. This information suddenly reappeared a few years ago when I was writing about ergonomic seating. The company I wrote for had designed a new office chair that kept the person in it slightly moving while sitting down. One of them sat in the chair and used their feet to move around. Seeing this, I suggested to the designers that the feet act as a rudder to navigate the body. According to them, this was a perfect description of what they had accomplished.</p><p id="c439"><strong>I looked. I listened. And I found the embellishment I was looking for.</strong></p><p id="5e4a">In this ocean of information we’re slowly drowning in, I like to think of microcopy as an invisible rudder for our intuition. It’s there to guide you through interactive waters, shallow or deep, without you seeing it. If you can see the rudder, you’ve probably hit bottom, and then you have to slow down to understand the situation. When designing interactivity, people crave fluidity. Like in a musical piece that captivates us or in a movie that enthralls us with great dialogue and scenery. Or even a game like Red Dead Redemption 2 whose job is to help us navigate 60+ hours of content while keeping us immersed in their universe. Well played.</p><p id="54c3">Our understanding of the world is layered in mental concepts. Everything can be stripped down to its very basic components. Even what we know to be basic components has its own basic components. By understanding this, one becomes humble when faced with the task of understanding complex matters. Or answering complicated questions.</p><p id="24c2">Whenever I write, my goal is always to find the simplest version of the truth intended. By truth, I mean the pieces of information I relay to people who desire an outcome of some sort, typically in an app or landing page. Sometimes I need to let function dictate what I write; other times, it feels like a good time to sparkle with some creativity.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2238/1*r7e4HbF2CWByVxNXGxryTg.png" width="1119" height="1117" srcset="https://miro.medium.com/max/552/1*r7e4HbF2CWByVxNXGxryTg.png 276w, https://miro.medium.com/max/1104/1*r7e4HbF2CWByVxNXGxryTg.png 552w, https://miro.medium.com/max/1280/1*r7e4HbF2CWByVxNXGxryTg.png 640w, https://miro.medium.com/max/1400/1*r7e4HbF2CWByVxNXGxryTg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*r7e4HbF2CWByVxNXGxryTg.png?q=20"></p></div></div></div><figcaption>A good example of creative microcopy. It could not have been created without insight from the parents, the kids and the restaurants point of view. Origin unknown. Let me know if you know and I’ll include it.</figcaption></figure><p id="94dd">Bill Bernbach, a legendary copywriter responsible for the famous Think Small ads for Volkswagen, once said that <em>creativity is the intangible thing that makes the difference.</em> It’s just something that feels right. Right? But at the same time, creativity is an extra layer for people to decode and make sense of. What I’m saying is being creative for creativity’s sake is not enough. It has to add meaning or value.</p></div></div><div><div><p id="54b7">Bill Bernbach also said that<em> </em><strong><em>advertising is fundamentally persuasion, and persuasion happens to be not a science but an art.</em></strong> This is also something I hold to be true. Although …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blogg.bekk.no/what-i-learned-about-ux-writing-from-a-british-prog-drummer-and-david-lynch-2b81f09aadfc">https://blogg.bekk.no/what-i-learned-about-ux-writing-from-a-british-prog-drummer-and-david-lynch-2b81f09aadfc</a></em></p>]]>
            </description>
            <link>https://blogg.bekk.no/what-i-learned-about-ux-writing-from-a-british-prog-drummer-and-david-lynch-2b81f09aadfc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25219036</guid>
            <pubDate>Thu, 26 Nov 2020 11:33:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FrontPage: The Good, The Bad, and The Ugly]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25218794">thread link</a>) | @pmlnr
<br/>
November 26, 2020 | https://invisibleup.com/articles/33/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/33/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/33/thumb.png" alt="FrontPage: The Good, The Bad, and The Ugly thumbnail">
	
	

	<p>PLEASE don't use FrontPage for modern web development! It's filled with security vulnerabilities and obsolete standards. The goal of this is not to convince you otherwise. The newest version came out almost two decades ago!</p>

<p>Microsoft FrontPage. The mere mention of that name is making most (if not all) of you seasoned web devs groan. "FrontPage was utter rubbish from dark ages of GeoCities" you say. "Everything it touched was ruined with horrific output and proprietary nonsense!" And yes, it was.</p>
<p>But... FrontPage as a concept. As a dream of what could have been, and a window into what <em>was</em>. Letting the typical home user at the time create websites, express creativity, and conquer the world by storm, all without being forced to learn HTML or CSS or JavaScript... In that regard, FrontPage couldn't be beat.</p>
<p>Let's talk about why Microsoft FrontPage was for a brief period of time the ultimate content creation tool of the Internet, and why it later fell from grace.</p>
<h2>History</h2>
<p>Before we can talk about goodness and ugliness, we need to talk about carphones and business meetings. Because this was 1994, when the Internet was still really new. At that point in time most internet chatter occured on Usenet groups (think something like Reddit) or BBS systems (think something like <a href="https://invisibleup.com/articles/5/">old AOL</a>; example pictured below). If you needed buisness stuff, like stocks or the such, you had to log onto the BBS of whoever had what you needed. This was kind of a pain.</p>
<p><img alt="A picture of a BBS (tilde.town) as of today" src="https://invisibleup.com/articles/33/BBS.png"></p>
<p>Enter Randy Forgaard and Charles H. Ferguson. Ferguson, renowned computer industry consultant, contacted MIT graduate Forgaard (over carphone, in case you were wondering) to discuss starting a new, internet-based company.</p>
<p>His idea was that many corporations such as the Dow Jones, Bloomberg, Apple, etc. were sinking millions into building their own, completely incompatible dial-in Internet services. Therefore, they should create a standardized, completely open server/client combo to replace all the independent efforts. This hopefully would reduce the cost of development for those corporations, and provide a market for growth by making buisnesses <em>want</em> to have an Interent presence.</p>
<p>The two decided to found their own company, Vermeer Technologies, Inc. A month later, still in the planning stages, they caught wind of the brand new World Wide Web out of CERN. It was decentralized, open, and even more robust than they were planning. It was just about perfect. The only issue was that it was rather a pain to make websites if you were just some lowly advertising manager or whoever. The web needed an authoring tool for websites.</p>
<p><img alt="FrontPage 1.0a, taken from WinWorldPC.com" src="https://invisibleup.com/articles/33/FP-1.0.png"></p>
<p>So, somehow, they managed to hire many professional coders for no salary whatsoever to work on FrontPage. (Early start-up culture, perhaps?) Evidently it worked, as FrontPage was released (only!) a week behind schedule on October of 1995. By then the World Wide Web was exploding, with a 20% increase in sites <em>per month</em>. FrontPage also managed to explode, receiving many awards and positive reviews. In fact, it was so good that Microsoft ended up buying them out. According to them, not only did it feel like a native Office application, it was perfect for their ongoing plan to become more internet centric.</p>
<p><img alt="FrontPage 97, taken from WinWorldPC.com" src="https://invisibleup.com/articles/33/FP-97.png"></p>
<p>FrontPage over the years got integrated into the Office suite and made a flagship product for Microsoft productivity products. By Office 2000, FrontPage had more Office integration than you should shake a stick at; nailing down the Office user interface and allowing imports and exports across the whole suite. There's... other stuff as well, but let's stay positive for now.</p>
<p>I'll be covering FrontPage 2002, as that's the version I own, and the one I have the most experience with.</p>
<h2>The Good</h2>
<p>The interface... is (in my opinion) one of the best interfaces for any program ever. No hyperbole. I think only the other Microsoft applications of the era like PowerPoint and Visio can top it. I can <em>see</em> why it won awards.</p>
<p><img alt="FrontPage's start screen with no webs open" src="https://invisibleup.com/articles/33/FP-Start.png"></p>
<p>Like any other Microsoft Office XP program, there's the sidebar on the right with common tasks. What you'll probably want to do is, of course, make a new site.</p>
<p>FrontPage's equivalent to "projects" are called "Webs". These Webs contain the files (all your HTML, CSS, images, etc.) and preferences (such as which web server to sync up with or what compatibility settings to use) for that website.</p>
<p><img alt="FrontPage's template selector" src="https://invisibleup.com/articles/33/FP-NewWeb.png"></p>
<p>Start by selecting a new "Empty Web". Up pops a bunch of templates, including the "Empty Web" template. A bit odd, but sure.</p>
<p><img alt="The &quot;Personal Homepage&quot; template in action" src="https://invisibleup.com/articles/33/FP-Template.png"></p>
<p>If you <em>were</em> to choose a template, it would give you a pre-populated fill-in-the-blanks site ready for your words and pictures. It takes some of the layout work and design originality out of it, but that <em>is</em> the purpose of a template after all. (Although, as a word of advice, <em>don't use these.</em> They're rather awfully designed from a web standards point of view. You can see it barely fitting in my window there. Imagine that on a smartphone.)</p>
<p><img src="https://invisibleup.com/articles/33/FP-BlankWeb.png" alt="FrontPage open to a new blank web. Folder list and Views bar are visible."></p>
<p>Anyways, once you open your blank web, you get... nothing! (That's what you asked for, isn't it?) No worries. Really, if you think about it, it would be rather silly to start making a page off the bat. You see, FrontPage takes a <em>project oriented</em> approach to things. While you easily <em>could</em> just sit down and start banging stuff out, that's really not the way FrontPage wants you to go.</p>
<p><img alt="FrontPage Navigation editor with some pages created and linked up." src="https://invisibleup.com/articles/33/FP-NavView.png"></p>
<p>Here's probably my favorite FrontPage feature: the Navigation editor. Here you create blank pages and link them together in a logical hierarchy. This closely resembles the process you'd usually take on paper when designing a website.</p>
<p><img alt="Navigation bar settings dialog" src="https://invisibleup.com/articles/33/FP-Navbar.png"></p>
<p>With this hierarchy, you can automatically create a navigation bar in all your pages that are properly linked. If you decide to make a new top-level page, for instance, every page on your site will be updated to feature that page. (To replicate that feature on this site, I had to use some pretty tricky template scripting with my custom Flask server. I'd vastly prefer something like this.)</p>
<p>This feature is also nice because it forces you to <em>think about your site</em>. You can't just sit down like it's Microsoft Word and bang out some pages. You need a coherent plan. Before you can even start, you need to sit down with your client/team/self and ask "What do you want on your website?" To most people it's obvious that you need a website. Everybody has a website. What's significantly less obvious is <em>what</em> needs to be on the website. And FrontPage's web editor allows you to play around with hierarchies and layouts before commiting to anything.</p>
<p><img alt="PowerPoint Slide Sorter mode&quot;" src="https://invisibleup.com/articles/33/PPT-SlideSorter.png"></p>
<p>One thing that's intersting is that Word, PowerPoint and Access all (vaguely) follow a similar model. Word has the Outline editor, PowerPoint has the Slide Sorter mode (pictured above, showing an interactive game I made when I was 11), and Access, being a typical database program, requires you to declare your tables before you can work on them.</p>
<p>What's even more interesting is that, with the exception of Access (which not many people used, mostly due to its cost and relative rarity), you were never <em>required</em> to have a plan before starting. Most people I've seen use Word just do straight typing, or perhaps work off another document with an outline. But the option was there! One could do their outline <em>in their document</em> and flesh out around that. Likewise with PowerPoint, as well.</p>
<p><img alt="Highlighted template include code" src="https://invisibleup.com/articles/33/FP-TemplateInclude.png"></p>
<p>Another common task in web design is defining a "template" page where you fill all your content into. For example, every page on this site you're reading on now has the same header and footer, and every article has the same sort of thumbnail image at the top. That was all scripted using template features.</p>
<p>FrontPage, being an Office product, supports templates. The implementation admittedly is <em>super</em> janky, but it's there. You can include pages within other pages just fine, it's just a little tricky to set up. (FYI, Word, Excel, and PowerPoint do templates too. It's one of their lesser-known features, IMHO.)</p>
<p><img alt="Report view window" src="https://invisibleup.com/articles/33/FP-Reports.png"></p>
<p>Another really neat feature: reports. Like a compiler in an IDE, FrontPage produces warnings, errors, and statistics for your site. At a glance I can view all broken links, orphaned pages, oversized images, etc. This is a <em>fantastic</em> feature, something that modern web dev software just <em>doesn't</em> have.</p>
<p><img alt="Hyperlinks view window" src="https://invisibleup.com/articles/33/FP-Links.png"></p>
<p>In the same vein as the Reports, you can see at a glance what links to what. It's a lot like the call chart in a software development IDE. I can see quickly every site linked from any page (shown here is <a href="https://invisibleup.com/articles/24/">the Sonic R color fix article</a>) and any subpages.</p>
<p><img alt="Tasks view, showing a task labeled &quot;Write FrontPage article&quot;" src="https://invisibleup.com/articles/33/FP-Tasks.png"></p>
<p>Last feature, although this isn't nearly as useful in the year 2020. In the tasks view, you can put up a list of tasks that needs to be accomplished. Already that seems rather nice for keeping track of what you need to do. It's a lot like GitHub or GitLab's issue tracker, in a sense.</p>
<p>However, if you connect to a server with FrontPage Web Extensions (I'll get to that...), you can share this task list with other people. You can (again, like an issue tracker) put up a task to be done by someone else and work on a task that somebody else put up. It's a <em>very</em> nice feature for web development, but nowadays this is normally handled by source control providers like GitHub or GitLab.</p>
<p><img alt="FrontPage editing the Sonic R color mod article" src="https://invisibleup.com/articles/33/FP-Editor.png"></p>
<p>And, of course, there's the webpage editor. This works almost exactly like Microsoft Word, with some web-flavored spice. You type words and they appear in the page. You make those words blue, they're blue. <em>That said</em>, when you edit elements like that, it inserts an HTML 3.2 style <code>&lt;FONT&gt;</code> tag instead of trying to match it to a CSS rule. There's ways around this, but you have to be very diligent in doing so. This is mostly just due to FrontPage being a product of its time, though.</p>
<p>FrontPage is a program about planning, executing, and reviewing. Take the Navigation editor. You plan out the content of your site. You sketch up the layout. Then you reflect on if your layout matches your requirements. Or the Reports. Create content, check reports. Or the Tasks. Plan out what you need to do, do that, and then check if the task is complete. That, right …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/33/">https://invisibleup.com/articles/33/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/33/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218794</guid>
            <pubDate>Thu, 26 Nov 2020 10:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Existential Haskell]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25218601">thread link</a>) | @runeks
<br/>
November 26, 2020 | https://blog.sumtypeofway.com/posts/existential-haskell.html | <a href="https://web.archive.org/web/*/https://blog.sumtypeofway.com/posts/existential-haskell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <p>The majority of software engineering literature portrays object-oriented programming as distinct from, and often irreconcilable with, functional programming. This is, of course, a false dichotomy, as the techniques encouraged by functional programming are applicable in even the most object-oriented languages. Yet object-orientation, being perhaps history’s most popular software paradigm, has popularized its tenets, and occasionally we can see them show up even in programming languages like Haskell, a language about as antithetical to the object-oriented philosophy as possible.</p>
<p>In this piece, I’ll describe a common example of <a href="https://en.wikipedia.org/wiki/Information_hiding">information hiding</a> in ALGOL-style languages like Java, then express that in terms compatible with Haskell. We’ll then use this technique to port a <em>responder chain</em> to Haskell, demonstrating how Haskell supports dynamic function dispatch in the presence of hidden type information. I write this not because I expect to break any new ground—all the techniques I use here are long-documented in the literature, and Haskell veterans will probably find little new in this post<span><label for="sn-0"></label><span>Those familiar with the care and feeding of existential types may wish to skip to the penultimate section, which contains a couple useful data types that I haven’t yet seen in the wild.</span></span>—but because the existing resources are scattered, perhaps oddly so given how central dynamic dispatch is to most programming languages that aren’t Haskell, and because exploring the edge cases in the design illustrates the compromises inherent in language and library design.</p>

<p>Most of the world’s statically-typed programming languages allow their users to write code resembling the following Java:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>public</span> <span>static</span> <span>Comparable</span> <span>someFn</span>() {</span>
<span id="cb1-2">    <span>return</span> <span>"a concrete String value"</span>;</span>
<span id="cb1-3">}</span></code></pre></div>
<p>Syntactically, this code is uncontroversial: it’s a function that returns a value. Its only interesting aspect lies in the function signature−even though the function body returns a value of type <code>String</code>, its return type is declared to be <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Comparable.html"><code>Comparable</code></a>, which is not a concrete data type, but a Java <a href="https://en.wikipedia.org/wiki/Interface_(computing)">interface</a>. As such, we cannot treat the result of this function call as the <code>String</code> it actually is; we can only interact with it via the methods defined on the <code>Comparable</code> interface. This application of the <a href="https://en.wikipedia.org/wiki/Rule_of_least_power">rule of least power</a> is a useful one, even in a strongly-typed language like Haskell: sometimes we want to hide the implementation details of a function’s return type.</p>
<p>We can try to write the same thing in Haskell:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>someComparableValue ::</span> <span>Ord</span> a <span>=&gt;</span> a</span>
<span id="cb2-2">someComparableValue _ <span>=</span> <span>"a concrete string value"</span></span></code></pre></div>
<p>Because this is not semantically-valid Haskell, we get the following error:</p>
<pre><code>&lt;interactive&gt;:3:27: error:
    • Couldn't match expected type ‘a’ with actual type ‘[Char]’
      ‘a’ is a rigid type variable bound by
        the type signature for:
          someComparableValue :: forall a. Ord a =&gt; Int -&gt; a
</code></pre>
<p>Haskell’s typechecker looks at the body of this function and says “hey, man, you’re returning a concrete string value here, not ’any type that is <code>Ord</code>–erable.’” Though this is a valid notion in Java, it’s not valid in Haskell. Another perspective on this is that Java allows a value to have more than one type: we can treat a Java string literal as a value of type <code>java.lang.String</code>, or of type<span><label for="sn-1"></label><span>even though <code>Comparable</code> is an interface, not a concrete type</span></span> <code>Comparable</code>, or of its superclass <code>java.lang.Object</code>. However, since Haskell doesn’t support inheritance, Haskell treats its values as having one, and only one, type. Working around this takes a judicious application of an existential type.</p>

<p>In Haskell, an <em>existential</em> data type is one that is defined in terms not of a concrete type, but in terms of a quantified type variable, introduced on the right-hand side of the data declaration. This is, as is the case for so many Haskell concepts, not a particularly helpful definition in the abstract. It’s easier to show than to tell, so let’s take a look at one of the canonical examples of an existential type: a <code>Showable</code> type that wraps any type that implements the <code>Show</code> interface.</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>data</span> <span>Showable</span> <span>=</span> <span>forall</span> a <span>.</span> <span>Show</span> a <span>=&gt;</span> <span>Showable</span> a</span></code></pre></div>
<p>There are several interesting things about this data type. Firstly, it uses the <code>forall</code> keyword to introduce the <code>a</code> type variable: given that we’re dealing with <em>exist</em>-ential types, it threw me for a loop that there wasn’t an <code>exists</code> keyword.<span><label for="sn-2"></label><span>Scala reserves a <code>forSome</code> keyword for this purpose, which I think reads a little more accurately in terms of the intent of introducing this type variable: using the phrase “for all” is a bit inapposite given that the <code>Showable</code> constructor is applied to single values at a time.</span></span> Considering the constructor of <code>Showable</code> is perhaps more enlightening:</p>
<div id="cb5"><pre><code><span id="cb5-1">λ<span>&gt;</span> <span>:</span>t <span>Showable</span></span>
<span id="cb5-2"><span>Showable</span><span> ::</span> <span>forall</span> a <span>.</span> <span>Show</span> a <span>=&gt;</span> a <span>-&gt;</span> <span>Showable</span></span></code></pre></div>
<p>We can read this as “<code>Showable</code> is a constructor that takes, for all types <code>a</code> such that <code>a</code> implements <code>Show</code>, an <code>a</code> value, and returns a value of type <code>Showable</code>, the internal <code>a</code> value of which is no longer visible to the world once it’s been applied.”</p>
<p>Secondly, we can’t use a <code>newtype</code> to declare an existential. Attempting to write the following:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>newtype</span> <span>Showable</span> <span>=</span> <span>forall</span> a <span>.</span> <span>Show</span> a <span>=&gt;</span> <span>Showable</span> a</span></code></pre></div>
<p>results in an error message:</p>
<pre><code>• A newtype constructor cannot have a context in its type
  Showable :: forall a. Show a =&gt; a -&gt; Showable
• In the definition of data constructor ‘Showable’
  In the newtype declaration for ‘Showable’
</code></pre>
<p>When we consider typeclasses as <a href="https://blog.sumtypeofway.com/posts/fluent-polymorphism-type-applications.html">dictionaries</a>, this restriction makes more sense: in GHC Core, this <code>Show a</code> constraint will be represented as a hypothetical <code>ShowDict</code> data type containing implementations for the <code>show</code>, <code>showsPrec</code>, and <code>showList</code> functions. In this light, we can see that <code>Showable</code> takes <em>two</em> parameters, not one: an <code>a</code> value to wrap, as well as the <code>ShowDict</code> dictionary associated with that value’s type. Newtypes exist to wrap single values, and here we’re wrapping both a datum and its associated <code>Show</code> dictionary: as a result, here we need a <code>data</code> declaration, even though the associated <code>Showable</code> constructor takes only one value (in Haskell surface syntax). This is an understandable limitation, though it would be cool if existential values of this sort could opt into the <code>deriving</code> mechanism in the manner of newtypes.</p>
<p>A third interesting thing: we can’t write a function that unwraps this data type. What might seem like an intuitive type for the function is rejected:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>-- GHC will reject this.</span></span>
<span id="cb8-2"><span>unwrapShowable ::</span> <span>Showable</span> <span>-&gt;</span> (<span>forall</span> a <span>.</span> <span>Show</span> a <span>=&gt;</span> a)</span>
<span id="cb8-3">unwrapShowable (<span>Showable</span> a) <span>=</span> a</span></code></pre></div>
<p>We can see this explained a little more closely if we use the record selector syntax.</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>data</span> <span>Showable</span> <span>=</span> <span>forall</span> a <span>.</span> <span>Show</span> a <span>=&gt;</span> <span>Showable</span> {<span> getShowable ::</span> a }</span></code></pre></div>
<p>Attempting to use <code>getShowable</code> as a function that extracts some arbitrary <code>Show</code>–inhabiting type produces a well-explained error messages:</p>
<pre><code>&lt;interactive&gt;:1:1: error:
    • Cannot use record selector ‘getShowable’ as a function due to escaped type variables
      Probable fix: use pattern-matching syntax instead
    • In the expression: getShowable
</code></pre>
<p>The mental model I use here is that applying a constructor of an existential type serves as a sort of <a href="https://en.wikipedia.org/wiki/Event_horizon">event horizon</a> for type information. In other languages we can assemble heterogenous lists natively; in Haskell, by contrast, we have to opt into it explicitly: applying the <code>Showable</code> constructor to a value swallows its type information. We can’t write a function, whether the hand-written <code>unwrapShowable</code> or descending from our <code>getShowable</code> record selector, that unwraps some arbitrary type out of an existential. All that is retained is the ability, given a proper <code>case</code> statement to unwrap the value within the existential, to <code>Show</code> the value contained therein: it cannot <em>escape</em> its scope, as the error message above explains<span><label for="sn-3"></label><span>We can, however, use the <code>getShowable</code> record selector to update the wrapped value present in a <code>Showable</code>.</span></span>.</p>
<p>We can, as I mentioned above, cross the event horizon with a <code>case</code> statement, binding the <code>Show</code>–conforming contents to a variable name:</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>let</span> shown <span>=</span> <span>case</span> x <span>of</span> <span>Showable</span> val <span>-&gt;</span> <span>show</span> val</span></code></pre></div>
<p>Inside the right-hand-side of this <code>case</code> statement, we have a value <code>x</code> in scope. A quick inquiry with type holes reveals the type we expect:</p>
<pre><code>• Relevant bindings include
    x :: a (bound at &lt;interactive&gt;:28:15)
  Constraints include Show a (from &lt;interactive&gt;:28:11-15)
</code></pre>
<p>All we know about this value <code>x</code> is that we can call <code>Show</code> on it. Other than passing it to the basic combinators (<code>id</code> and <code>const</code>), that’s <em>all we can do</em> with this value. Any bit of type information has been lost, replaced instead with <em>capabilities</em>, via typeclasses. Again, when we consider typeclasses as dictionary parameters, we can visualize how this works on a core-calculus level: we discard type information, including only the relevant dictionaries provided by the context of the <code>forall</code>.</p>
<p>A fourth and final interesting thing about this type is that you can write it, using the <code>GADTs</code> GHC extension, without an explicit <code>forall</code> keyword:</p>
<div id="cb13"><pre><code><span id="cb13-1"><span>data</span> <span>Showable</span> <span>where</span></span>
<span id="cb13-2">  <span>Showable</span><span> ::</span> <span>Show</span> a <span>=&gt;</span> a <span>-&gt;</span> <span>Showable</span></span></code></pre></div>
<p>This stems from the fact that GADTs allow us to introduce per-constructor type variables and associated constraints, even if the type variable is not visible externally. Another thing to note is that data declarations containing existential values don’t have to be limited to a single value: they can hold concrete values, or values expressed with more <code>forall</code>–introduced type variables.</p>

<p>Being able to hide implementation details of a function’s return type is all well and good, but many users are going to need to convert (or attempt to convert) from an existential type back into a concrete type. Java provides this functionality with the <code>instanceof</code> operator and its cast syntax:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>Comparable</span> c = <span>someFn</span>();</span>
<span id="cb14-2"><span>if</span> c <span>instanceof</span> <span>String</span> {</span>
<span id="cb14-3">    <span>System</span>.<span>out</span>.<span>println</span>(<span>"Got a string: "</span> + (<span>String</span>)c);</span>
<span id="cb14-4">} <span>else</span> {</span>
<span id="cb14-5">    <span>System</span>.<span>out</span>.<span>println</span>(<span>"Casting to a String here would raise a ClassCastException"</span>);</span>
<span id="cb14-6">}</span></code></pre></div>
<p>This is a consequence of all Java objects descending from <code>java.lang.Object</code>, and the ability of the <code>instanceof</code> operator to query the type of an object at runtime. Though …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sumtypeofway.com/posts/existential-haskell.html">https://blog.sumtypeofway.com/posts/existential-haskell.html</a></em></p>]]>
            </description>
            <link>https://blog.sumtypeofway.com/posts/existential-haskell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218601</guid>
            <pubDate>Thu, 26 Nov 2020 10:15:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[6 Essential Things I Wish I Knew When I Started Programming]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25218351">thread link</a>) | @nickbull
<br/>
November 26, 2020 | https://blog.nickbulljs.com/6-essential-things-i-wish-i-knew-when-i-started-programming | <a href="https://web.archive.org/web/*/https://blog.nickbulljs.com/6-essential-things-i-wish-i-knew-when-i-started-programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I could probably achieve 300% more in 6 years as a programmer if I knew these things when I started.</p>
<h2 id="coding-is-not-about-the-coding">Coding Is Not About The Coding</h2>
<p>What do you think programming is about?</p>
<p>Writing code?</p>
<p>Writing good code?</p>
<p><strong>No.</strong></p>
<p>It's just a part of the truth.</p>
<p><strong>Programming is not about coding, programming is about solving problems with coding.</strong></p>
<p>End customers don’t care what technologies, languages, frameworks, or methodologies you use. They care only about one thing, whether your product solves their problem or not.</p>
<p>That’s why no one cares what technologies Google search is using under the hood. Until people can find relative information with it, they will use it.</p>
<p>It’s the number one thing I wish I knew when I started programming.</p>
<p>I would spend less time writing “best code” and more time solving customer’s problems best.</p>
<p><strong>Don’t write code just to write code, solve customer’s problems with the code.</strong></p>
<h2 id="communication-skills-more-important-than-coding-skills">Communication Skills More Important Than Coding Skills</h2>
<p>When I just started my career, lack of social skills was not my main problem. But when I moved higher, to the middle, senior, and leadership position, my weak soft skills became my Achilles heel.</p>
<p>When you work on a product with a group of different people (engineers, designers, managers), communication is the only thing that makes you a “team” and helps you effectively develop the product.</p>
<p>Lack of social skills does the opposite, it decreases the product development time and overall productivity.</p>
<p>Here is the real situation you might face:</p>
<p>The leadership team tells your product manager that they want to create a new product feature and put it in the next product release. It’s not urgent, they just want to release it as soon as possible (as always).</p>
<p>The product Manager calls you on Zoom, tells you what you need to build, and asks, <em>“How much time do you need to build it?”</em></p>
<p>You are doing a rough calculation and tell, <em>“I need 20 hours.”</em></p>
<p>The Product Manager is not satisfied with your answer. He wants to release it as soon as possible and show the management that he can deliver results fast (this is a very common situation).</p>
<p>So he asks you, <em>“Can you build it for 10 hours? We really need this feature in the next product release!”</em></p>
<p>And you know that you can if you cut the corners (no tests, messy code) but then you will need to refactor it, and it will take an additional 30 hours. Because other engineers will work with your messy code when you release it. And after refactoring, you will need to integrate their code with yours.</p>
<p>So here’s what will happen next. If you have bad social skills, you will not convince the Product Manager that you actually need 20 hours to build this feature. </p>
<p>Why?</p>
<p>Product Managers often have good social skills, from my experience. So if you can’t convince him that refactoring later is worse than spending 20 hours right now, he will easily argue with you and convince you that “refactoring later is okay.” And the whole team will lose additional 30 hours for this refactoring (I don't count the time to fix unpredictable bugs after).</p>
<p>But if you have good communication skills you will be able to convince him of the opposite.</p>
<p><strong>So improve your social skills as well as coding skills</strong> (send memes in the group chats on Slack or something).</p>
<p>And remember one simple truth:</p>
<p><strong>People work with people, not machines.</strong></p>
<h2 id="regular-breaks-help-to-program-better">Regular Breaks Help To Program Better</h2>
<p>For 4 years I always feel exhausted after work. Somehow I could productively work only for a couple of hours. After that, I didn't have much energy. Until I learned about the Pomodoro technique.</p>
<p>It’s quite simple. You work for 25 minutes and take a break for 5 minutes.</p>
<p>Your working routine becomes:</p>
<p>8:00-8:25 – Work</p>
<p>8:25-8:30 – Break</p>
<p>8:30-8:55 – Work</p>
<p>8:55-9:00 – Break</p>
<p>…</p>
<p>I tried it for a week and was surprised at how focused, energetic, and productive I became  (<a target="_blank" href="https://www.focusboosterapp.com/blog/the-science-behind-the-pomodoro-technique/">the science behind Pomodoro</a>)</p>
<p>Then I went further and implemented the <a target="_blank" href="https://twitter.com/nickbulljs/status/1303037682294173699">52+17 system</a> and my productivity levels spiked by 200%.</p>
<p><strong>So</strong> <strong>take regular breaks if you want to operate at your maximum capabilities.</strong></p>
<h2 id="10x-engineers-dont-exist">10X Engineers Don’t Exist</h2>
<p>At the beginning of my career, I thought that a great programmer is a person who knows tons of programming languages, frameworks, and methodologies.</p>
<p><strong>I was wrong.</strong></p>
<p>Such a mindset only gave birth to my impostor syndrome. I thought that I don't deserve my current position, my salary, that I am a “fraud.” So I started to follow every popular developer on Twitter, read every technical news, and thousands of developer blogs just to convince myself that I deserve what I have and to feel more close to the title “great developer.”</p>
<p><strong>This was not a healthy behavior.</strong></p>
<p>But it helped me to discover that a lot of people I followed (I thought were 10X engineers) actually didn’t know a lot of things. They may know how to do some complex things that require a lot of different deep knowledge in a couple of fields and at the same time don’t know some primitive things. Like to know how to design highly scalable database architectures but don’t know how vertical-align an element with CSS.</p>
<p>Big thanks to those developers, like Dan Abramov (creator of Redux) for <a target="_blank" href="https://overreacted.io/things-i-dont-know-as-of-2018/">this article</a>, they cured my imposter syndrome and showed me that it is okay not to know something.</p>
<h2 id="programming-is-not-hard-if-you-know-how-to-learn">Programming Is Not Hard If You Know How To Learn</h2>
<p>When I started to learn JavaScript, it was hard. <strong>Because I learned the wrong way.</strong></p>
<p>Read a lot of theory without the practice, no routine, no end goal. Chaos.</p>
<p>I thought it was normal to learn like this. Until I discovered <strong>deliberate practice.</strong></p>
<p>It’s a purposeful and systematic type of practice (learning).</p>
<p>The difference between normal practice and deliberate is that deliberate requires focused attention and is conducted with the specific goal of improving performance.</p>
<p>After I applied a deliberate practice, I began to notice how fast I'm progressing with learning JavaScript. My knowledge started to stick for a long time, not just for 5 minutes after tutorials. I created the end goal, why I am learning JavaScript, and understand what I need to learn, and what I don't.</p>
<p>📌 <em>Quick note: I’m creating a JavaScript course where I’m using deliberate practice to <strong>combine modern and practical JavaScript theory with a lot of real-world practice</strong> to teach you how to become a skilled JavaScript developer with knowledge of modern language features. <a target="_blank" href="https://javascriptcoursethatworks.com/">Join here.</a></em></p>
<p>So here is what you need to perform deliberate practice on your own:</p>
<ol>
<li><strong>Teacher:</strong> provides practice activities designed to help you improve performance.</li>
<li><strong>Perform at maximum effort:</strong> constantly being taken out of your comfort zone.</li>
<li><strong>Well defined and specific goals:</strong> not just “overall improvement.”</li>
<li><strong>To be in focus:</strong> give your full attention, no distractions.</li>
<li><strong>Do conscious actions:</strong> no autopilot.</li>
<li><strong>Instant response to feedback and modifying your strategy.</strong></li>
</ol>
<p>When you start learning a new language, technology, framework, whatever, stick to these rules to get big results as quickly as possible.</p>
<h2 id="there-is-no-best-programming-language">There is no “best programming language”</h2>
<p>There is no <strong>best "something"</strong> in our world. Only <strong>best in something</strong>.</p>
<p>Let’s take cars. How can we choose the best car in the world? By speed? By safety? By what criteria?</p>
<p>It’s impossible.</p>
<p>We can only choose the best car in a certain category. Like the safest car. Or the best offroad car.</p>
<p>And if we look deeper, every category solves some problems.</p>
<p>For example.</p>
<p><strong>Problem:</strong> We have children and we take them to school every day, we want our children to be safe on the way to school.</p>
<p><strong>Solution:</strong> Buy the safest car.</p>
<p><strong>Problem:</strong> We go camping every weekend, so we need some vehicle that can easily get us to places that are difficult to access.</p>
<p><strong>Solution:</strong> Buy the best off-road car.</p>
<p>The same is with programming languages. Some languages and tools are better at solving some problems than others.</p>
<p>If we want to build an interactive website, we choose JavaScript.</p>
<p>If we want to go with ML/AI, we choose Python.</p>
<p>Remember, <strong>there is no best programming language, there is the best programming language to ...</strong></p>
<p>So start with a problem first, then pick a language to solve it.</p>
<h2 id="in-the-end">In the end...</h2>
<p>If you like this article, share it with your friends and <a target="_blank" href="https://twitter.com/nickbulljs">follow me on Twitter</a>.</p>
<p>Also, every week I send out a "3–2–1" newsletter with 3 tech news, 2 articles, and 1 piece of advice for you.</p>
<p>📌 <a target="_blank" href="https://nickbulljs.com/">Subscribe to my 3–2–1 newsletter here</a> 📌</p>
</div></div>]]>
            </description>
            <link>https://blog.nickbulljs.com/6-essential-things-i-wish-i-knew-when-i-started-programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218351</guid>
            <pubDate>Thu, 26 Nov 2020 09:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf 2020: State of Retro Gaming in Emacs]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25218177">thread link</a>) | @sohkamyung
<br/>
November 26, 2020 | https://emacsconf.org/2020/schedule/27/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/schedule/27/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">





<p>Back to the <a href="https://emacsconf.org/2020/schedule/">schedule</a><br>
Previous: <a href="https://emacsconf.org/2020/schedule/26">Emacs as a Highschooler: How It Changed My Life</a><br>
Next: <a href="https://emacsconf.org/2020/schedule/28">Welcome To The Dungeon</a></p>

<p>Sunday, Nov 29 2020,  1:16 PM -  1:26 PM EST<br>
Sunday, Nov 29 2020, 10:16 AM - 10:26 AM PST<br>
Sunday, Nov 29 2020,  6:16 PM -  6:26 PM UTC<br>
Sunday, Nov 29 2020,  7:16 PM -  7:26 PM CET<br>
Monday, Nov 30 2020,  2:16 AM -  2:26 AM +08</p>



<p>Vasilij "wasamasa" Schneidermann</p>

<p>Many jokes have been made about the true nature of Emacs, such as it
being a fully-fledged operating system.  This talk will demonstrate
its suitability for playing retro games, then explore the inner
workings of a <a href="https://en.wikipedia.org/wiki/CHIP-8">CHIP-8</a> emulator capable of smooth video game emulation.</p>

<p>Back to the <a href="https://emacsconf.org/2020/schedule/">schedule</a><br>
Previous: <a href="https://emacsconf.org/2020/schedule/26">Emacs as a Highschooler: How It Changed My Life</a><br>
Next: <a href="https://emacsconf.org/2020/schedule/28">Welcome To The Dungeon</a></p>

<p>All times are approximate, and we might shuffle talks around as needed.
Please check <a href="https://emacsconf.org/2020">https://emacsconf.org/2020</a> a few days before the start of the
conference for instructions on how to watch and participate. See you then!</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/schedule/27/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218177</guid>
            <pubDate>Thu, 26 Nov 2020 08:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Move, iPad]]>
            </title>
            <description>
<![CDATA[
Score 238 | Comments 283 (<a href="https://news.ycombinator.com/item?id=25218050">thread link</a>) | @rcarmo
<br/>
November 26, 2020 | https://beckyhansmeyer.com/2020/11/25/your-move-ipad/ | <a href="https://web.archive.org/web/*/https://beckyhansmeyer.com/2020/11/25/your-move-ipad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Hear that? It’s the sound of Mac fans. No, not your shiny new M1 Mac’s fans—chances are, you’ll never hear those—but rather, the sound of <em>excitement</em> rippling through the Mac community. This is something big. Really big. Now, I’m only 33, but someday when I go full fuddy-duddy I will speak of this: the great Intel/Apple Silicon transition. The beginning of a new era at Apple.</p>



<p>All that sounds dramatic, of course, but it’s interesting to trace all of the different paths that led us to this point. The A-Series chips, the introduction of Metal, rapid machine learning gains, the gradually degrading repairability scores as components became more integrated, the Secure Enclave, a new super fast emulation layer, new unified memory architecture, and 5nm process… years and years of work have now come to fruition with the first Apple Silicon chips for Mac. And our minds are blown.</p>



<p>Suddenly, we’re handed a thin, entry-level fanless laptop that performs better than almost every other Mac computer out there, and a low-end MacBook Pro and Mac Mini that make current Mac Pro owners sweat and clutch their wheels. So many questions abound. What new hardware designs will these gains make possible? What on earth does Apple have in store for its high-end Macs? Will anyone else even be able to compete? It’s an exciting time to be a Mac lover, but, surprise: this post isn’t really about the Mac. It’s about the iPad.</p>



<p>There’s no question that Apple has struggled to craft a cohesive, compelling narrative for the iPad. For a long time, there seemed to be a distinct lack of product vision. Everyone likes to speculate over what role Steve Jobs ultimately intended the iPad to have in people’s lives, but not only is that pointless, it’s also irrelevant. We don’t need Steve to tell us what the iPad is good for. We know what it’s good for, and we can easily imagine what it <em>could</em> be good for, if only Apple would set it free.</p>



<p>Just as Apple left us with great expectations for its Pro Mac line-up, the latest iPad Air also raises the bar in new and interesting ways. The Air served as sort of an appetizer for the new M1 chips, while also receiving a generous trickle-down of features from the iPad Pro, including USB-C and support for the latest keyboard and Pencil accessories. There have been rumors of new mini-LED displays for the next-gen iPad Pros, but it’s going to take a lot more than new display tech to set the Pros apart.</p>



<p>Francisco Tolmasky (<a href="https://twitter.com/tolmasky/status/1330033394349125642?s=20">@tolmasky</a>) recently tweeted:</p>



<blockquote><p>“A sad but inescapable conclusion from the impressive launch of the M1 is just how much Apple squandered the potential of the iPad. The iPad has had amazing performance for awhile, so why is the M1 a game changer? Because it’s finally in a machine we can actually <em>do things on</em>.”</p></blockquote>



<p>Francisco is right: Power and performance aren’t the bottleneck for iPad, and haven’t been for some time. So if raw power isn’t enough, and new display tech isn’t enough, where does the iPad go from here? Will it be abandoned once more, lagging behind the Mac in terms of innovation, or will Apple continue to debut its latest tech in this form factor? Is it headed toward functional parity with the Mac or will it always be hamstrung by Apple’s strict App Store policies and seemingly inconsistent investment in iPadOS?</p>



<p>It’s clear that Apple <em>wants</em> the iPad Pro to be a device that a wide variety of professionals can use to get work done. And since so many people use web apps for their work, the introduction of “desktop” Safari for iPad was an important step toward that goal. The Magic Keyboard and trackpad was another step.</p>



<p>Here are ten more steps I believe Apple could and should take to help nudge the iPad into this exciting next era of computing.</p>



<ol><li>Give the iPad Pro another port. Two USB 4.0 ports would be lovely.</li><li>Adopt a landscape-first mindset. Rotate the Apple logo on the back and move the iPad’s front-facing camera on the side beneath the Apple Pencil charger to better reflect how most people actually use their iPad Pros.</li><li>Introduce Gatekeeper and app notarization for iOS. The process of side-loading apps should <em>not</em> be as simple as downloading them from the App Store. Bury it in Settings, make it slightly convoluted, whatever: just have an officially-sanctioned way of doing it.</li><li>Ruthlessly purge the App Store Guidelines of anything that prevents the iPad from serving as a development machine. Every kind of development from web to games should be possible on an iPad. And speaking of games—emulators should be allowed, too.</li><li>Release a suite of professional first-party apps at premium prices. If someone can edit 4K videos in Final Cut on their M1 MacBook Air, they should be able to edit 4K videos in Final Cut on their iPad Pro. I refuse to believe that these pro apps can’t be re-imagined and optimized for a touch experience. If Apple leads the way in developing premium software for iPad, others will follow.</li><li>Make it possible to write, release, and install plug-ins (if appropriate) for the aforementioned first party apps.</li><li>Bring App Library to the iPad and allow widgets to be positioned anywhere on the Home Screen. This isn’t groundbreaking, it just annoys the heck out of me.</li><li>Release a new keyboard + trackpad case accessory that allows the iPad to be used in tablet mode without removing it from the case.</li><li>Introduce Time Machine backups for iPadOS.</li><li>5G, ofc.</li></ol>



<p>In the end, fostering a vibrant community of iPad app developers can only stand to benefit the Mac (and vice-versa).</p>



<p>It’s simple: people love their iPads. They love them so much they wish they could do even more with them. The new M1 Macs should give iPad fans reason to be excited; now that we’ve seen hints of what future Macs can be, it’s time for the iPad to reassert itself—to remind us once again who it’s for, and what makes it special.</p>



<p>In other words: Your move, iPad.</p>
			</div></div>]]>
            </description>
            <link>https://beckyhansmeyer.com/2020/11/25/your-move-ipad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218050</guid>
            <pubDate>Thu, 26 Nov 2020 08:28:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracks in the Great Stagnation?]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 112 (<a href="https://news.ycombinator.com/item?id=25216017">thread link</a>) | @edward
<br/>
November 25, 2020 | https://www.agglomerations.tech/cracks-in-the-great-stagnation/ | <a href="https://web.archive.org/web/*/https://www.agglomerations.tech/cracks-in-the-great-stagnation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Cracks in the Great Stagnation">
            </figure>

            <section>
                <div>
                    <p>For the last 60 years, we’ve seen consistently low productivity growth rates in the US and across the Western world. Meanwhile, recent scientific discoveries seem to be <a href="https://www.theatlantic.com/science/archive/2018/11/diminishing-returns-science/575665/">less fundamental</a> to our understanding of the world than previous breakthroughs have been. While the growth of digital technology has been tremendous since the 1990s, it’s the only significant part of our world that seems to have been changing. To look up from our smartphones is to see a physical environment that looks basically the same as it did in 1970. Innovation has been constrained to the world of bits and left the world of atoms mostly untouched.</p><p>This might finally be changing. Last month, the economist Tyler Cowen <a href="https://www.bloomberg.com/opinion/articles/2020-10-05/how-much-worse-can-things-get-that-question-may-be-a-good-sign">speculated</a> that we may be seeing signs that this <a href="https://www.amazon.com/Great-Stagnation-Low-Hanging-Eventually-eSpecial-ebook/dp/B004H0M8QS">Great Stagnation</a> is ending. Since his article was published, we’ve already seen almost a dozen announcements that have only driven home the point further. There seem to be cracks in the Great Stagnation and light is peeking through on the other end. </p><p><strong>Innovation in the physical world</strong><br>Most obviously, the recent announcement of the <a href="https://www.statnews.com/2020/11/09/covid-19-vaccine-from-pfizer-and-biontech-is-strongly-effective-early-data-from-large-trial-indicate/">successful development of several vaccines</a> to the novel coronavirus are a sign that America (with some help from Germany) is still capable of achieving Big Things when we are pushed to it. Despite consistent failings of the US regulatory state in <a href="https://slatestarcodex.com/2020/04/14/a-failure-but-not-of-prediction/">delaying the adoption</a> of face masks and in <a href="https://thedispatch.com/p/timeline-the-regulationsand-regulatorsthat">slowing the rollout</a> of mass testing, the US essentially bet the farm that our strong biotech clusters would be able to create a vaccine to a new disease in record time, and it looks like we’re going to be able to do it in under a year! </p><p>It’s worth highlighting just how speedy this development timeline is when compared to the vaccines for diseases like polio and measles. </p><figure><img src="https://www.agglomerations.tech/content/images/2020/11/Vaccination-innovation-chart.png" alt="" srcset="https://www.agglomerations.tech/content/images/size/w600/2020/11/Vaccination-innovation-chart.png 600w, https://www.agglomerations.tech/content/images/size/w1000/2020/11/Vaccination-innovation-chart.png 1000w, https://www.agglomerations.tech/content/images/size/w1600/2020/11/Vaccination-innovation-chart.png 1600w, https://www.agglomerations.tech/content/images/size/w2400/2020/11/Vaccination-innovation-chart.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>https://ourworldindata.org/vaccination</figcaption></figure><p>And not only did we develop a new vaccine, we developed a new *type* of vaccine. mRNA vaccines have long been speculated to work, but this is the <a href="https://www.bostonherald.com/2020/11/20/pfizer-and-moderna-vaccines-showing-potential-success-of-mrna-platform-a-first/">first instance</a> of a successful vaccine application in humans using this technique. </p><p>In transportation, the promise of driverless cars has long been a centerpiece for a tech-optimistic vision of safer roads, better-designed cities, and eliminating the drudgery of a morning commute through traffic. But the technical delays of the last few years (when compared to the most optimistic timelines) have become a rallying cry for the <a href="https://blog.piekniewski.info/2018/05/28/ai-winter-is-well-on-its-way/">tech-skeptic</a> as well. </p><p>It seems like they may finally be getting here. A few weeks ago, <a href="https://arstechnica.com/cars/2020/10/waymo-finally-launches-an-actual-public-driverless-taxi-service/">Waymo announced</a> that their long-running pilot program in Arizona is going to be open to the public <a href="https://twitter.com/jjricks_/status/1316318196375330816">without any safety driver</a> in the front seat. Days later, Elon Musk and Tesla rolled out a new self-driving beta program. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">These two guys used a drone to make a video of Tesla's new "full self-driving" software in action. The drone, the self-driving car, and the global video-steaming service were all been science fiction when I was born. Living in the future is neat. <a href="https://t.co/4QqGcjFXsc">https://t.co/4QqGcjFXsc</a></p>— Timothy B. Lee (@binarybits) <a href="https://twitter.com/binarybits/status/1321102111883579397?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote>

</figure><p>This is a remarkable engineering feat, especially on Waymo’s end. It shows the company can successfully lead product development in an industry that relies on more stringent safety-critical engineering instead of the release-and-iterate model that its parent company grew up with. Waymo is evidence that Silicon Valley can “move at a moderate pace and not break things” when it needs to.</p><p>Granted, it’s unclear how long until and at what pace deployment of AVs to the rest of the country and the world will happen. If the Waymo model looks to be successful, it will be a steady, resource-intensive process of region-by-region expansion as the cars learn to handle new operational design domains and are rigorously validated in each city before the keys are turned over to the AI. In other words, expansion could look more like a cell phone coverage map than a software update that is instantaneously available everywhere. </p><p>But still, this is a significant, tangible mile marker that the industry has passed. AVs are operating in the wild now. We get to talk about *when* we reach the driverless future, not *if*. </p><p>In addition to the almost ho-hum daily progress in solar, wind, and battery technology where prices have fallen <a href="https://www.greentechmedia.com/articles/read/solar-pv-has-become-cheaper-and-better-in-the-2010s-now-what">90</a>, <a href="https://www.forbes.com/sites/energyinnovation/2020/01/21/renewable-energy-prices-hit-record-lows-how-can-utilities-benefit-from-unstoppable-solar-and-wind/?sh=491f10ec2c84">70</a>, and <a href="https://about.bnef.com/blog/battery-pack-prices-fall-as-market-ramps-up-with-market-average-at-156-kwh-in-2019">87</a> percent over the last ten years, we’ve also started to hear very promising reports about the development of more fundamental breakthroughs. The NYT reports that a compact nuclear fusion reactor is “<a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?action=click&amp;module=News&amp;pgtype=Homepage">Very Likely to Work</a>” after a major theoretical advancement. There was also a fantastic David Robert’s <a href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical">deep dive into geothermal energy</a> and the promise of advanced geothermal (whereby water pumped into the ground through a closed loop reaches a high enough temperature that it becomes “supercritical” and can carry 10x more energy per unit mass), in particular. Either technology, if perfected, would provide abundant, zero-carbon, baseload energy that is available anywhere around the world. </p><p>Cowen mentions briefly the huge market growth we’ve seen in lab-grown meat and plant-based alternatives. A few weeks ago it was announced that Impossible Foods, one of the largest actors in the industry is <a href="https://venturebeat.com/2020/10/20/impossible-foods-will-double-rd-to-eliminate-animal-farming/">doubling their R&amp;D team</a> as they seek to take on plant-based milk, steak, and fish as well as improve the supply chains for plant proteins. In tandem, McDonald’s <a href="https://www.washingtonpost.com/food/2020/11/10/mcdonalds-mcplant-sandwich/">just announced</a> that in 2021 they are going to be testing out a new McPlant menu.</p><p><strong>Digital innovation continues apace</strong></p><p>Not to be left out, in the digital world we’ve been seeing impressive progress as well. AI techniques like deepfakes which have been heralded as the <a href="https://www.sundayguardianlive.com/opinion/deepfakes-destroy-democracy">death knell for democracy</a> are now being <a href="https://arstechnica.com/gadgets/2020/11/nvidia-used-neural-networks-to-improve-video-calling-bandwidth-by-10x/">deployed by NVIDIA</a> to increase video fidelity while cutting bandwidth transmission for video calls by a factor of 10. In general, techniques to reduce bandwidth use are greatly underrated, and it’s going to be exciting to see the ways in which smarter compression can perhaps bring similar efficiency gains across the board. </p><p>And now factor in the steady rollout of 5G network technologies which promise to increase the raw bandwidth available to all mobile devices. With the combination of smarter compression and vastly increased bandwidth we could be looking at a baseline 50x increase in network capacity over the next decade. It’s hard to predict ahead of time what new applications will be enabled by all this new capacity, but in retrospect it could look like another example of <a href="https://diff.substack.com/p/how-bubbles-and-megaprojects-parallelize">parallel innovation</a> that both enables and is driven by the growth of VR/AR, driverless vehicles, and telehealth.*</p><p><em>*For those who are skeptical that increased capacity will generate new applications because a few cities have tried gigabit broadband<a href="https://www.wsj.com/graphics/faster-internet-not-worth-it/"> without much effect</a>, I would argue that both hardware and app developers are optimizing for the baseline user experience and we won’t see a ton of investment in new applications until we’ve changed the baseline capacity that developers can expect a sizeable user base to have. </em></p><p>Equally as impressive, Apple’s new M1 chip that was launched on November 10th seems to have taken the world by storm. As John Gruber <a href="https://daringfireball.net/2020/11/the_m1_macs">summarizes</a>: “To acknowledge how good they are — and I am here to tell you they are astonishingly good — you must acknowledge that certain longstanding assumptions about how computers should be designed, about what makes a better computer better, about what good computers need, are wrong.” Just as interesting is <a href="https://medium.com/pcmag-access/what-is-the-apple-m1-chip-613935ea0903">how they did it</a>. By miniaturizing the whole system architecture and integrating it onto a single chip (no discrete RAM, graphics card, etc.) Apple has managed to pump out massive efficiency gains both in processing power and in battery life. (There’s perhaps a metaphor here for the <a href="https://www.wsj.com/articles/breaking-up-big-tech-is-hard-to-do-1532290123">value of integration</a> for large tech firms as well…)</p><figure><img src="https://lh5.googleusercontent.com/tXP4ZnW93TIsJ_dJe3NVmevfz5eMUnNC6CS40Dz_S0568BDiQKr8K8LqT5Ja-kLnXUKnS1UkDQf_6WYzBhfGa4c99lQDfqudhQaDF-XCYBEkxNoP3Vo3FlGtLl3sGFQcdtHBlGbv" alt=""><figcaption>https://techcrunch.com/2020/11/17/yeah-apples-m1-macbook-pro-is-powerful-but-its-the-battery-life-that-will-blow-you-away/</figcaption></figure><p>Finally, the virtual reality space has seen its most impressive entrant in years with the arrival of the Quest 2 from Facebook on October 13th. There is no VR headset that matches it on a performance/cost basis, and the relative simplicity and elegance of the system makes it an ideal entry point. The deliberately low entry barrier of $299 is meant to entice a large enough user base that it kickstarts the virtuous cycle of having a significant enough market for dedicated VR developers to make significant investments in new applications, which then drives new user growth. Facebook believes we finally have a minimum viable product for VR that means this kind of two-sided market is possible, and it is betting billions of dollars to make it happen. Early signs seem to show that it is working as intended with <a href="https://www.theverge.com/2020/10/30/21541535/oculus-quest-2-preorders-sales-developers-zuckerberg">pre-orders reportedly 5x</a> larger than the original Quest, popular applications like Beat Saber seeing record growth, and all this with the upcoming holiday rush and a massive advertising blitz to come. </p><p>Notably, all of these announcements/developments I’ve outlined have occurred in just the last few months. This is by no means a comprehensive look at the exciting progress being made in many other fields. But the sheer scope and pace of tangible changes to our physical and digital words is something to be excited about.</p><p><strong>A few caveats </strong></p><p>Some of these innovations will boost productivity in the traditional ways that show up in economic growth statistics. We should strive for and celebrate those achievements. But some of these innovations won’t necessarily, instead they make human civilization more durable and sustainable in a variety of ways. In response, we should start to think of increased sustainability as a type of productivity. </p><p>A vaccine to the COVID pandemic is the most obvious example. While economic statistics won’t show a boost in productivity compared to the pre-COVID economy because of the vaccine, the ability to return to trend is itself incredibly valuable. In fact, measured labor productivity from the vaccine will likely fall as lower-wage …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation/">https://www.agglomerations.tech/cracks-in-the-great-stagnation/</a></em></p>]]>
            </description>
            <link>https://www.agglomerations.tech/cracks-in-the-great-stagnation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25216017</guid>
            <pubDate>Thu, 26 Nov 2020 01:14:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reasoning about Colors]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25215963">thread link</a>) | @todsacerdoti
<br/>
November 25, 2020 | http://notes.neeasade.net/color-spaces.html | <a href="https://web.archive.org/web/*/http://notes.neeasade.net/color-spaces.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">



<hr>
 


<p>
In July 2020 I went on a color-scheme vision quest. This led to some research on various <a href="https://en.wikipedia.org/wiki/Color_space">color spaces</a> and their utility, some investigation into the <a href="http://chriskempson.com/projects/base16/#styling-guidelines">styling guidelines</a> outlined by the base16 project, and the <a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/color.el">color utilities</a> that ship within the GNU Emacs text editor. This article will be a whirlwind tour of things you can do to individual colors, and at the end how I put these blocks together.
</p>

<div id="outline-container-orgbe4e3e9">
<h2 id="h-3fe0b0c6-76a6-4e9e-a061-66bd3ba54620"><span>1</span> <a href="#h-3fe0b0c6-76a6-4e9e-a061-66bd3ba54620">Motivation</a></h2>
<div id="text-h-3fe0b0c6-76a6-4e9e-a061-66bd3ba54620">
<p>
I've been a part of several Linux desktop customization communities since circa 2013. One big aspect of that is the colors used across various contexts – for me, it follows that part of the game is trying to make a cohesive system of colors that relate to each other in an understandable (and thus tweakable) way – know what I can do to individual colors when making a "color framework" helps immensely.
</p>

<p>
I'm colorblind. This means I might be really picky about some colors. For example, I don't like the color red used for emphasis in text – thin red lines look the same as thin black lines to me (and so, red text doesn't typically &gt;POP&lt; for me, unless it's bold or has some other emphasis included).
</p>

<p>
Bootstrapping builders exist for base16! If I can bootstrap on top of their system I get a lot of free coverage within the software ecosystem.
</p>

<p>
Plus, I just find this sort of thing really fun. Visual feedback is pleasing. Finding the right colors makes my lizard brain return to monke.
</p>
</div>
</div>

<div id="outline-container-orgbde706a">
<h2 id="h-3820d027-5602-4691-b9ca-b36aadd3871a"><span>2</span> <a href="#h-3820d027-5602-4691-b9ca-b36aadd3871a">Side note: The Canvas</a></h2>
<p>
This will be the focal point of inconsistency. The level of brightness, quality of screen, and ambient lighting level are all things that affect the value of the screen's <a href="https://en.wikipedia.org/wiki/White_point">white point</a>, which is what everything else is relative too. Luckily you can (attempt to) account for this as well.
</p>
</div>

<div id="outline-container-org3e178ba">
<h2 id="h-a71813d2-7e36-4f52-b22c-87e22d4a2620"><span>3</span> <a href="#h-a71813d2-7e36-4f52-b22c-87e22d4a2620">Color Spaces</a></h2>
<p>
Color spaces are ways of defining colors in different sets of properties. They are the main tool you will have for reasoning about tweaking <i>individual</i> colors. You can then mess with these and convert them back into a format you can render (typically RGB) within a <a href="https://en.wikipedia.org/wiki/Gamut">color gamut</a> (a range of supported colors). Here I will be pretty high level, focusing on some visuals for what sorts of things these properties look like. When I define the valid values for ranges, I will be using the scale I've implemented in my <a href="#h-cb3c6479-7d62-4028-8942-2b033bb1247a">helpers</a>.
</p>

<div id="outline-container-org0a664e8">
<h3 id="h-99356355-d54c-41d8-bc1a-6e14e29f42c8"><span>3.1</span> <a href="#h-99356355-d54c-41d8-bc1a-6e14e29f42c8">RGB</a></h3>
<div id="text-h-99356355-d54c-41d8-bc1a-6e14e29f42c8">
<p>
The one you know and love:  [R]ed, [G]reen, [B]lue. Your knobs are amounts of each. As you turn everything up, you approach <code>#ffffff</code> (and down, -&gt; <code>#000000</code>). This isn't particularly flexible in "ways you can think about colors".
</p>

<p>
Here is a gradient from <code>#cc3333</code> to <code>#33cc33</code> to <code>#3333cc</code>:
</p>

 


<p>
To show the lighting effect, let's repeat the above gradient, but instead of using <code>33</code> for filler, we'll use <code>99</code> – that's triple(!) the secondary color amounts:
</p>

 

</div>
</div>

<div id="outline-container-orgfc9a41c">
<h3 id="h-43869bc7-a7d1-410f-9341-521974751dac"><span>3.2</span> <a href="#h-43869bc7-a7d1-410f-9341-521974751dac">HSL</a></h3>
<div id="text-h-43869bc7-a7d1-410f-9341-521974751dac">
<p>
<a href="https://en.wikipedia.org/wiki/HSL_and_HSV">wikipedia: HSL and HSV</a>
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<tbody>
<tr>
<td>[H]ue</td>
<td>0-360</td>
<td>Color "direction"</td>
</tr>

<tr>
<td>[S]aturation</td>
<td>0-100</td>
<td>Color "strength"</td>
</tr>

<tr>
<td>[L]ightless</td>
<td>0-100</td>
<td>Light level</td>
</tr>
</tbody>
</table>

<p>
Saturation in HSL is a controlled version of chromacity ("distance from gray"). See the wiki section for more details.
</p>


<p><a href="http://notes.neeasade.net/assets/posts/color_cylinder.png"><img src="http://notes.neeasade.net/assets/posts/color_cylinder.png" alt="color_cylinder.png"></a>
</p>

<p>
Hue has several defined points (at rotating 60° angles), I like to think of it like a color compass:
</p>

<div>  
<p>red, 0°</p>
<p>yellow, 60°</p>
<p>green, 120°</p>
<p>cyan, 180°</p>
<p>blue, 240°</p>
<p>magenta, 300°</p>
 </div> 


<p> HSL: Hue rotation 0-360 (step 60°), saturation 50%, lightness 50% </p> 


<p>
Let's see the effect saturation has:
</p>

 


<p> HSL: saturation scale 0-100% (step 10%), lightness 50%, hue 240° (blue) </p> 


<p>
And lightness:
</p>

 


<p> HSL: lightness scale 0-100% (step 10%), saturation 50%, hue 240° (blue) </p> 

</div>
</div>

<div id="outline-container-org758eb61">
<h3 id="h-c147b84d-d95b-4d2d-8426-2f96529a8428"><span>3.3</span> <a href="#h-c147b84d-d95b-4d2d-8426-2f96529a8428">HSLuv</a></h3>
<div id="text-h-c147b84d-d95b-4d2d-8426-2f96529a8428">
<p>
<a href="https://www.hsluv.org/comparison/">hsluv</a> is an altered version of HSL that tries to be perceptually uniform with regards to lightness. HSL lightness by comparison is hard to make contrast comparisons in.
</p>

<p>
What does that mean for us? Well, let's take our above examples and recreate them in the HSLuv space:
</p>

<div>  
<p>red, 0°</p>
<p>yellow, 60°</p>
<p>green, 120°</p>
<p>cyan, 180°</p>
<p>blue, 240°</p>
<p>magenta, 300°</p>
 </div> 


<p> HSLuv: Hue rotation 0-360 (step 60°), saturation 50%, lightness 50% </p> 


<p>
Saturation:
</p>

 


<p> HSLuv: saturation scale 0-100% (step 10%), lightness 50%, hue 240° (blue) </p> 


<p>
Lightness:
</p>

 


<p> HSLuv: lightness scale 0-100% (step 10%), saturation 50%, hue 240° (blue) </p> 


<p>
These scales definitely look more consistent when reasoning about lightness values. HSL's hue feels all over the place by comparison – though at the same time that might be a more natural color mixing feel.
</p>
</div>
</div>

<div id="outline-container-org74be492">
<h3 id="h-9d5a1a9a-75d3-48f5-bf00-85332d9b023e"><span>3.4</span> <a href="#h-9d5a1a9a-75d3-48f5-bf00-85332d9b023e">CIELAB</a></h3>
<div id="text-h-9d5a1a9a-75d3-48f5-bf00-85332d9b023e">
<p>
<a href="https://en.wikipedia.org/wiki/CIELAB_color_space">wikipedia link</a>
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<tbody>
<tr>
<td>[L]ightness</td>
<td>0-100</td>
<td>Light level</td>
</tr>

<tr>
<td>[A] toggle</td>
<td>-100-100</td>
<td>green &lt;–&gt; red</td>
</tr>

<tr>
<td>[B] toggle</td>
<td>-100-100</td>
<td>blue &lt;–&gt; yellow</td>
</tr>

<tr>
<td>whitepoint</td>
<td>coordinates [X, Y, Z]</td>
<td>a point in the <a href="https://en.wikipedia.org/wiki/CIE_1931_color_space">CIE XYZ</a> space that defines "white" from the perspective of the image being displayed</td>
</tr>
</tbody>
</table>

<p>
The white point is a defined <a href="https://en.wikipedia.org/wiki/Standard_illuminant">standard illuminate</a>  not intrinsic to the value of a color. It is an additional piece of information you provide to functions when converting into and out of the CIELAB colorspace.
</p>

<p>
The standard white point is defined as <code>d65</code> – in this section, every conversion will be made with <code>d65</code>. Here is a table of commonly used white points and their meaning (for values, see the bottom of the wikipedia link).
</p>

<table>


<colgroup>
<col>

<col>
</colgroup>
<tbody>
<tr>
<td>d65</td>
<td>Noon Daylight: Television, sRGB color space (standard assumption)</td>
</tr>

<tr>
<td>d50</td>
<td>Horizon Light. ICC profile PCS</td>
</tr>

<tr>
<td>d55</td>
<td>Mid-morning / Mid-afternoon Daylight</td>
</tr>

<tr>
<td>d75</td>
<td>North sky Daylight</td>
</tr>
</tbody>
</table>

<p>
The knobs A and B allow you to play with the 4 primary colors of the LAB space. If you take a look at the values, you might notice that the more negative we go, we get "cooler" colors, while on the positive end, we get "warmer" colors.
</p>

<p>
Let's look at some LAB colors. The labels below will have the values of  <code>(L A B)</code> – Remember, A is green to red, B is blue to yellow (each with a value -100 to 100)
</p>

<div>  
<p>(50,-80,0)</p>
<p>(50,-60,0)</p>
<p>(50,-40,0)</p>
<p>(50,-20,0)</p>
<p>(50,0,0)</p>
 </div> 
 <div>  
<p>(50,0,0)</p>
<p>(50,20,0)</p>
<p>(50,40,0)</p>
<p>(50,60,0)</p>
<p>(50,80,0)</p>
 </div> 


<div>  
<p>(50,0,-80)</p>
<p>(50,0,-60)</p>
<p>(50,0,-40)</p>
<p>(50,0,-20)</p>
<p>(50,0,0)</p>
 </div> 
 <div>  
<p>(50,0,0)</p>
<p>(50,0,20)</p>
<p>(50,0,40)</p>
<p>(50,0,60)</p>
<p>(50,0,80)</p>
 </div> 


<div>  
<p>(50,-80,-80)</p>
<p>(50,-60,-60)</p>
<p>(50,-40,-40)</p>
<p>(50,-20,-20)</p>
<p>(50,0,0)</p>
 </div> 
 <div>  
<p>(50,0,0)</p>
<p>(50,20,20)</p>
<p>(50,40,40)</p>
<p>(50,60,60)</p>
<p>(50,80,80)</p>
 </div> 


<p> lab scales: -A -&gt; +A, -B -&gt; +B, {-A,-B} -&gt; {+A,+B} </p> 

</div>
</div>

<div id="outline-container-org7c35271">
<h3 id="h-c4f93e1f-4fa6-4ebc-99c1-18b6de0ef413"><span>3.5</span> <a href="#h-c4f93e1f-4fa6-4ebc-99c1-18b6de0ef413">LCH</a></h3>
<div id="text-h-c4f93e1f-4fa6-4ebc-99c1-18b6de0ef413">
<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<tbody>
<tr>
<td>[L]uminance</td>
<td>0-100</td>
<td>Light level</td>
</tr>

<tr>
<td>[C]hromacity</td>
<td>0-100</td>
<td>Distance from gray</td>
</tr>

<tr>
<td>[H]ue</td>
<td>0-360</td>
<td>Color "direction"</td>
</tr>
</tbody>
</table>

<p>
LCH is a "cylindrical" version of cieLAB. What that means for us is that Hue is different. Instead of 6 defined islands to sail to with our color compass, there are 4:
</p>

<div>  
<p>red, 0°</p>
<p>yellow, 90°</p>
<p>green, 180°</p>
<p>blue, 270°</p>
 </div> 


<p> LCH: Hue rotation 0-360 (step 90°), saturation 50%, luminance 50% </p> 


<p>
LCH lightness:
</p>
 


<p> LCH: lightness scale 0-100% (step 10%), chromacity 50%, hue 270° (blue) </p> 


<p>
Chromacity, "distance from gray" - very similar to Saturation (which I've seen cited as simply misnamed chromacity):
</p>

 


<p> LCH: chromacity scale 0-100% (step 10%), luminance 70%, hue 270° (blue) </p> 


<p>
Let's compare some spaces. We'll take some the RGB gradient from above, normalize the lightness in HSLuv and then maximize l[C]h, H[S]L, and H[S]Luv:
</p>

 


<p> original </p> 


 


<p> squash lightness to 50 in HSLuv </p> 


 
  
  


<p> 3 branches off of the above: LCH maximize C, HSL maximize S, HSLuv maximize S </p> 

</div>
</div>
</div>

<div id="outline-container-org972c46e">
<h2 id="h-e1c795a7-b3d9-4be3-9874-1b98a2069520"><span>4</span> <a href="#h-e1c795a7-b3d9-4be3-9874-1b98a2069520">Other stuff</a></h2>


<div id="outline-container-orgd1b048d">
<h3 id="h-c9cde0e6-ddb0-4f76-82ff-d730a3ce3f51"><span>4.1</span> <a href="#h-c9cde0e6-ddb0-4f76-82ff-d730a3ce3f51">Contrast</a></h3>
<div id="text-h-c9cde0e6-ddb0-4f76-82ff-d730a3ce3f51">
<p>
For text, the Web Content Assembly Guidelines (WCAG) recommend at least a 4.5:1 contrast ratio: <a href="https://www.w3.org/TR/WCAG/#contrast-minimum">link</a>. Let's take a look at some different text contrasts! I will steal the backgrounds used here from the base-16 grayscale sets: <code>#f7f7f7</code> and <code>#101010</code>. For reference, the contrast ratio between <code>#000000</code> and <code>#ffffff</code> is 21.0
</p>

<p>
Dark:
</p>

<div>  
<p>3.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>4.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>5.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>6.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>7.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>8.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
 </div> 


<p> dark contrast ratios, 3.0 - 9.0, step 1.0 </p> 


<p>
Light:
</p>

<div>  
<p>3.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>4.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>5.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>6.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>7.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
<p>8.0: Lorem ipsum dolor sit amet, <br> consectetur adipiscing elit, sed <br> do eiusmod tempor incididunt ut <br> labore et dolore magna aliqua.</p>
 </div> 


<p> light contrast ratios, 3.0 - 9.0, step 1.0 </p> 


<p>
I think it's pretty clear from these examples that higher contrast goes a long way in dark color schemes.
</p>
</div>
</div>

<div id="outline-container-org24bd016">
<h3 id="h-e260bdea-3408-47e6-a195-f5a62ed979bc"><span>4.2</span> <a href="#h-e260bdea-3408-47e6-a195-f5a62ed979bc">Distance</a></h3>
<div id="text-h-e260bdea-3408-47e6-a195-f5a62ed979bc">
<p>
Color distance is a measure of how far apart colors are by properties in spaces. For example, let's take the 'magenta' color from above, and increase it's brightness and hue until we're some minimal distance away. We'll aim for 33(out of 100) measured in the CIELAB space:
</p>

<div>  
<p>0</p>
<p>3</p>
<p>7</p>
<p>10</p>
<p>14</p>
<p>18</p>
<p>22</p>
<p>26</p>
<p>31</p>
<p>35</p>
 </div> 


<p> CIELAB distance from the start color is shown </p> 


<p>
Color distance is useful because it lets us measure a kind of similarity between colors. You can use this to control where you stop transformations (color space property tweaks).
</p>
</div>
</div>

<div id="outline-container-org015aa7b">
<h3 id="h-91fbcdc5-10ac-40ab-93d8-0d64cb1c7d01"><span>4.3</span> <a href="#h-91fbcdc5-10ac-40ab-93d8-0d64cb1c7d01">Gradients</a></h3>
<p>
A gradient is where you travel from one color's initial property values to some other color's property values, collecting the intermediate steps.
</p>
</div>

<div id="outline-container-org38c0fb3">
<h3 id="h-1ed7ea90-395e-4486-a11c-6f3c9054dd15"><span>4.4</span> <a href="#h-1ed7ea90-395e-4486-a11c-6f3c9054dd15">Pastel</a></h3>
<div id="text-h-1ed7ea90-395e-4486-a11c-6f3c9054dd15">
<p>
"Pastel Colors" when described in HSL have high lightness and low saturation. This …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://notes.neeasade.net/color-spaces.html">http://notes.neeasade.net/color-spaces.html</a></em></p>]]>
            </description>
            <link>http://notes.neeasade.net/color-spaces.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25215963</guid>
            <pubDate>Thu, 26 Nov 2020 01:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discord bans me for using their official client]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25214777">thread link</a>) | @jkcclemens
<br/>
November 25, 2020 | https://annaclemens.io/discord | <a href="https://web.archive.org/web/*/https://annaclemens.io/discord">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section>
      

      <p>
        Quick note: I don't really have a blog, but I wanted to publish this
        on my site, so this just has some quick styles applied.
      </p>

      <hr>

      <p>
	<strong>Resolution</strong>: My Discord account has been unbanned. After posting this page on Hacker News, the head of Discord's anti-abuse team saw it and looked into the issue. It turns out that my use of a third-party Discord client called Ripcord was the reason for my ban. At the time of the ban, I had been using this client for years, but I wasn't actively using it. I was actually using the official client, hence the older title of this page, but the third-party client was open on my laptop in the background. I leave this page here to chronicle how unacceptable Discord's response to this was.
      </p>

      <hr>

      <p>
        It's true: Discord banned me for using their own client. On 1
        November, I was scrolling through my old DMs. It was kind of messy, so
        I started to close some of them (which really just <em>hides</em>
        them). After closing maybe around seven of them, Discord booted me
        back to the login screen. I thought that was weird, but I grabbed my
        phone to scan the QR code to log in, but it didn't work. Annoyed, I
        manually typed in my login details only to find that my account has
        been disabled.
      </p>

      <h2>1 November</h2>

      <p>
        On the same day, 1 November, I opened a ticket (9765093) stating that
        I wasn't sure why my account was disabled and that I would like to
        know. They had sent me an email telling me that my account had been
        disabled, but the email only listed a vague list of reasons that could
        have caused the ban, and I didn't feel that I had done any of them.
      </p>

      <h2>3 November <small>2 days</small></h2>

      <p>
        On 3 November, two days later, Discord got back to me and let me know
        that I had received an email stating why my account was disabled
        (false) and that they had reviewed my ban and would not be reinstating
        my account.
      </p>

      <p>
        The same day, I responded to their email, stating that their
        explanation wasn't good enough and that I hadn't done anything
        wrong. I demanded they give me an actual reason and reinstate my
        account.
      </p>

      <h2>6 November <small>5 days</small></h2>

      <p>
        Three days go by with no response from Discord. On 6 November, I send
        another response to their email, reiterating my desires and asking
        that I at least be able to transfer power of my larger servers if they
        insist on being corrupt.
      </p>

      <h2>12 November <small>11 days</small></h2>

      <p>
        Another six days without a peep from Discord. 12 November: I send yet
        another response, reiterating what I had said in previous emails and
        asking to be put in contact with a GDPR officer to get the data I
        want.
      </p>

      <h2>14 November <small>13 days</small></h2>

      <p>
        After two more days, Discord <em>still</em> has <strong>not</strong> responded outside of
        the initial email I received. On 14 November, I file a new ticket
        (9984772) and mention my previous ticket number and restate that I
        would like a reason why my account was banned and to have my account
        reinstated, considering I hadn't actually done anything besides <em>use
        their official client</em>.
      </p>

      <h2>17 November <small>16 days</small></h2>

      <p>
        After three days, on 17 November, the new ticket gets a
        response. Discord gives me the same list of reasons (a list of bullet
        points that count as "spam and/or platform abuse") and assure me that
        they understand "you may not have malicious intent, [but] we have to
        protect Discord as a whole, and this behavio[u]r can hurt Discord and
        its users." They also go on to mention that as a "one-time gesture",
        they "went ahead" (past tense) and lifted the ban on my account.
      </p>

      <p>
        Hooray, I guess. I go to log in to Discord and it turns out that was a
        lie. My account is still disabled. I figure maybe it needs some time
        to propagate the change, but after hours and then days of trying, my
        account remains disabled. During these initial attempts on 17
        November, I sent a response to Discord, stating that I would like to
        know the real reason I was banned, since what I was doing while I was
        banned wasn't spam or platform abuse, it was closing old DMs manually
        with the official client, a supported use-case. I also made note that my
        account had not been unbanned.
      </p>

      <h2>18 November <small>17 days</small></h2>

      <p>
        On 18 November, my account is still banned despite Discord saying they
        would lift the ban, so I send a quick response asking when the ban
        will be lifted.
      </p>

      <h2>19 November <small>18 days</small></h2>

      <p>
        On 19 November, I ask again, noting that this is the third time I've
        replied to this ticket and still not received a response.
      </p>

      <h2>20 November <small>19 days</small></h2>

      <p>
        On 20 November, I open yet another new ticket (10088193), reference
        the old one, and ask why I haven't been unbanned, demanding that they
        honour their word and lift my ban.
      </p>

      <h2>25 November <small>24 days</small></h2>

      <p>
        On 25 November, <em>eight days</em> after I was told my account would be
        unbanned and <em>twenty-four days</em> after the ban in question, I still
        have not heard from Discord. I was (and am still) banned for doing
        nothing wrong. Discord did not deign to reply to my last ticket at
        all, but I'm filing another one today (25 Nov, 10166788). I will
        continue to update this log of communications as time goes on.
      </p>
    </section>
  

</div>]]>
            </description>
            <link>https://annaclemens.io/discord</link>
            <guid isPermaLink="false">hacker-news-small-sites-25214777</guid>
            <pubDate>Wed, 25 Nov 2020 22:01:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ten Commandments of Egoless Programming]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25213591">thread link</a>) | @kiyanwang
<br/>
November 25, 2020 | https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html?m=1 | <a href="https://web.archive.org/web/*/https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-1360687395129563554" itemprop="articleBody">
<p><span>We are nothing but the values we carry. All through my life thus far, I tried to influence people around me with the virtues I value. Thanks to some good reading habits I had inculcated, and the fortune of being in good community of peers and mentors alike, I managed to have read some real good books. This post is about the 10 commands of egoless programming in Weinberg's book. I shall explain the commandments based on my experience here.</span></p><p data-pm-slice="1 1 []"><span>So very many decades ago, Gerald M. Weinberg authored&nbsp;<a href="https://www.goodreads.com/book/show/2229333.Psychology_of_Computer_Programming"><u>The Psychology of Computer Programming</u></a>. In it, he listed <strong>The Ten Commandments of&nbsp;</strong><a href="https://en.wikipedia.org/wiki/Egoless_programming"><strong><u>Egoless Programming</u></strong></a>, which remains relevant even today for us as not just programmers but as team-members.</span></p><p><span>Weinberg is regarded as a pioneer in taking a people-centric approach to computing, and his work endures as a good guide to intelligence, skill, teamwork, and problem-solving power of a developer. When they appear to inspire and instruct, we find that they can apply to just about every business area, and even to life itself.</span></p><p><span>Here are the 10 important lessons developers, project managers, and stakeholders would do well to keep in mind during the project lifecycle.</span></p><ol><li><p><span><strong>Understand and accept that you will make mistakes.</strong><br>Mistakes are rarely fatal in our industry, so find them early, before they make it into production, learn from them, and move on.</span></p></li><li><p><span><strong>You are not your code.</strong><br>The point of a review is to find problems. Don't take it personally when one is found. Remember&nbsp;<a href="https://olxpeople.atlassian.net/wiki/spaces/OPETE/pages/940179552">my words</a>, “To err is only human, repeating it is what makes you either evil or insane”.</span></p></li><li><p><span><strong>No matter how much "karate" you know, someone else will always know more.</strong><br>Seek and accept input from others. You can learn new techniques if you just ask. Always remember, it is never too late to learn.</span></p></li><li><p><span><strong>Don't rewrite code without consultation.</strong><br>It is always a good idea to pair-up and have conversations on the code that you are tempted to re-write because you think it is bad. Your risks are much lesser if the code is backed by Unit tests. The least you can do is get it code reviewed before pushing code to main-stream branch.</span></p></li><li><p><span><strong>Treat people who know less than you with respect and patience.</strong><br>Don’t be a bully. Seriously, just don’t be one. Grow up!</span></p></li><li><p><span><strong>The only constant in the world is change.</strong><br>Things change, sometime for better and sometimes for worse. There are some things in your control which you can leverage to change things for better. Be the change that you wish for good. Also be willing to accept change for the overall good of the team.</span></p></li><li><p><span><strong>The only true authority stems from knowledge, not from position.</strong><br>Don't wield a title like a badge of "rightness."&nbsp;<span>If you want to be loved and respected in an egoless environment, cultivate knowledge. It may or may not lead to authority, but sure leads to love and respect from others. </span></span></p></li><li><p><span><strong>Fight for what you believe, but gracefully accept defeat.</strong><br>Open culture is not being polite in the front and back-bitching in the back. Rise up, voice your concerns, be heard, and make your point of view by doing your homework, all with an intent to help and learn otherwise. You can’t accept defeat, if you carry the burden of your ego. </span></p></li><li><p><span><strong>Don't be "the guy in the room".</strong><br>There are so many beer buddies, movie mates, cigarette companions, and what not, who can come together or fight fiercely on any non-professional topics by respecting each other; but definitely not discuss and debate openly, work related matters for team’s betterment. Just don’t be that guy in the room.  </span></p></li><li><p><span><strong>Critique code instead of people – be kind to the coder, not to the code.</strong><br>Pour your frustration on lifeless things instead of on emotional beings. Corollary, if someone were to show his frustrations on you instead of your work, be a little polite to him, discounting it as emotional down syndrome. I have been on both sides, and so will you sometime. Let us support one another and grow together.</span></p></li></ol><p><span>Just to re-iterate, these commandments are still incredibly relevant. Put it to deliberate practice and with time they will bring out a better developer and co-worker in you.</span></p><p><span>You can get this book from <a href="https://amzn.to/3lZvXr9" target="_blank">Amazon</a>.</span></p>

</div></div>]]>
            </description>
            <link>https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25213591</guid>
            <pubDate>Wed, 25 Nov 2020 19:59:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how Google will collapse]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 71 (<a href="https://news.ycombinator.com/item?id=25213493">thread link</a>) | @partingshots
<br/>
November 25, 2020 | http://www.sfu.ca/olc/blog/engage/how-google-will-collapse | <a href="https://web.archive.org/web/*/http://www.sfu.ca/olc/blog/engage/how-google-will-collapse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Previously published in&nbsp;<a href="https://hackernoon.com/how-google-collapsed-b6ffa82198ee">HACKERNOON</a>. Originally written by SFU Masters of Digital Media student Daniel Colin James.&nbsp;Re-published with permission of the writer.</em></p>
<p><em>Illustration Credit:&nbsp;</em><a href="https://mandelasmith.artstation.com/">Mandela Smith</a></p>
<hr>
<p>Google made almost all its money from ads. It was a booming business — until it wasn’t. Here’s how things looked right before the most spectacular crash the technology industry had ever seen.</p>
<div>
<h3>The crumbling of Google’s cornerstone</h3>
<p>Search was Google’s only unambiguous win, as well as its&nbsp;<a href="http://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html" rel="noopener" target="_blank" data-href="http://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html">primary source of revenue</a>, so when Amazon&nbsp;<a href="http://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/" rel="noopener" target="_blank" data-href="http://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/">rapidly surpassed Google</a>&nbsp;as the top product search destination, Google’s foundations began to falter.&nbsp;As&nbsp;<a href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/" rel="noopener" target="_blank" data-href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/">many noted</a>&nbsp;at the time, the online advertising industry experienced a major shift from search to discovery in the mid-2010s.</p>
<p>While Google protected its monopoly on the dying search advertising market, Facebook — Google’s biggest competitor in the online advertising space — got on the&nbsp;<a href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417" rel="noopener" target="_blank" data-href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417">right side of the trend</a>&nbsp;and dominated online advertising with its in-feed native display advertising.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.1.jpeg" width="533" height="239"></p>
<p><em><span>The people who turned to Amazon over Google? <a href="https://cdn.geekwire.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-13-at-10.40.08-AM.png">The 18-29 led the way</a></span></em></p>
<p>In late 2015, Apple — Google’s main competitor in the mobile space — added a feature to their phones and tablets that allowed users to block ads.</p>
<p>Devices running iOS were responsible for an&nbsp;<a href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue" rel="noopener" target="_blank" data-href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue">estimated 75%</a>&nbsp;of Google’s revenue from mobile search ads, so by making this move, Apple was simultaneously weighing in decisively on the great ad blocking debate of the 2010s and dealing a substantial blow to the&nbsp;<a href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/" rel="noopener" target="_blank" data-href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/">future of online advertising</a>.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.3.jpeg" width="533" height="196"></p>
<p><em><sub>The rising number of users blocking ads on mobile showed no signs of slowing down</sub></em></p>
</div>
<div>
<p>A year later, as the internet went mobile, so too did ad blocking. The number of people blocking ads on a mobile device grew&nbsp;<a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" rel="noopener" target="_blank" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">102% from 2015 to 2016</a>; by the end of 2016, an estimated 16% of smartphone users globally were&nbsp;<a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" rel="noopener" target="_blank" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">blocking ads</a>&nbsp;when browsing the internet on a mobile device. The number was&nbsp;<a href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333" rel="noopener" target="_blank" data-href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333">as high as 25%</a>&nbsp;for desktop and laptop users in the United States, a country that accounted for&nbsp;<a href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/" rel="noopener" target="_blank" data-href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/">47% of Google’s revenue</a>.</p>
<p>The people most likely to block ads were also the most valuable demographic:&nbsp;<a href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546" rel="noopener" target="_blank" data-href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546"><em>millennials and high earners</em></a><em>.</em></p>
<p><em><img src="http://www.sfu.ca/olc/sites/default/files/1.4.png" width="533" height="300"><br></em></p>
</div>
<div>
<p><em><sub>Young users are a good indicator for the future of technology, and&nbsp;<a href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546" rel="noopener" target="_blank" data-href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546">they were heavy users of ad blocking&nbsp;software</a></sub></em></p>
<p><strong>Internet users had spoken, and they hated ads.</strong></p>
<p>In early 2017, Google announced its plans to build an ad blocker into its popular Google Chrome browser. Google’s ad blocker would only block ads that were deemed unacceptable by the&nbsp;<a href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads" rel="noopener" target="_blank" data-href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads">Coalition For Better Ads</a>, effectively allowing the company to use its dominant web browser to strengthen its already dominant advertising business.</p>
<p>Even after making this desperate and&nbsp;<a href="http://fortune.com/2017/04/20/google-ad-blocker/" rel="noopener" target="_blank" data-href="http://fortune.com/2017/04/20/google-ad-blocker/">legally questionable</a>&nbsp;move, it would quickly become clear to Google that even though ads were getting better, ad blocking numbers would&nbsp;<a href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/" rel="noopener" target="_blank" data-href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/">continue to rise</a>. Google had given even more people a small taste of what an ad-free internet experience could look like.&nbsp;<strong>The company discovered that it wasn’t just annoying ads that people didn’t like; it was ads in general.</strong></p>
<p><strong><img src="http://www.sfu.ca/olc/sites/default/files/1.5.png" width="533" height="300"></strong></p>
<p><em><sub>The advertising industry trying to figure out why people hated ads so much</sub></em><strong><br></strong></p>
</div>
<p>A key platform where Google served ads was YouTube, which it bought in 2006 and quickly turned into one of its biggest entities. But even with a&nbsp;<a href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html" rel="noopener" target="_blank" data-href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html">sixth of the world</a>&nbsp;visiting this video-sharing behemoth every month, YouTube&nbsp;<a href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967" rel="noopener" target="_blank" data-href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967">never became profitable</a>. In an attempt to combat the effect of ad blockers, YouTube launched an ad-free subscription model in late 2015, but the subscription numbers were&nbsp;<a href="http://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music" rel="noopener" target="_blank" data-href="http://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music">underwhelming</a>.</p>
<p>YouTube’s already insurmountable problems multiplied in early 2017 as advertisers&nbsp;<a href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube" rel="noopener" target="_blank" data-href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube">began to pull out amid ad placement controversies</a>, and huge revenue generators began to&nbsp;<a href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797" rel="noopener" target="_blank" data-href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797">leave the site</a>. Even those who weren’t blocking ads had trained themselves to ignore them entirely. Researchers dubbed this phenomenon “<a href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/" rel="noopener" target="_blank" data-href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/">banner blindness</a>”. The average banner ad was clicked on by a dismal&nbsp;<a href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/" rel="noopener" target="_blank" data-href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/">0.06% of viewers</a>, and of those clicks, roughly&nbsp;<a href="http://www.goldspotmedia.com/fat-finger-report/" rel="noopener" target="_blank" data-href="http://www.goldspotmedia.com/fat-finger-report/">50% were accidental</a>.</p>
<p>Research showed that&nbsp;<a href="http://www.bannersnack.com/blog/build-trust-display-ads/" rel="noopener" target="_blank" data-href="http://www.bannersnack.com/blog/build-trust-display-ads/">54% of users</a>&nbsp;reported a lack of trust as their reason for not clicking banner ads and 33% found them completely&nbsp;<a href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf" rel="noopener" target="_blank" data-href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf">intolerable</a>. These figures painted a pretty grim picture for the sustainability of online advertising, but especially for Google’s position within the industry.</p>
<p><em>Google’s mighty engine had started to sputter.</em></p>
<p><strong>A chance to pivot, and how Google missed&nbsp;it</strong></p>
<p>If losing a major portion of their audience and annoying the rest wasn’t bad enough, Google also failed to get ahead of one of the biggest shifts in technology’s history. They recognized the importance of artificial intelligence but their approach missed the mark. Since Google’s search pillar had become unstable, a lot was riding on the company’s strategy for artificial intelligence.</p>
<p><em>“We will move from mobile first to an AI first&nbsp;world.”</em></p>
<p>Google’s then-CEO Sundar Pichai&nbsp;<a href="https://blog.google/topics/inside-google/this-years-founders-letter/" rel="noopener" target="_blank" data-href="https://blog.google/topics/inside-google/this-years-founders-letter/">famously predicted</a>&nbsp;in 2016 that “<em>the next big step will be for the very concept of the ‘device’ to fade away”&nbsp;</em>and that<em>&nbsp;“over time, the computer itself — whatever its form factor — will be an intelligent assistant helping you through your day. We will move from mobile first to an AI first world.”</em></p>
<p>Google’s ability to acknowledge the coming trend and still fail to land in front of it reminded many observers of its catastrophic failures in the booming industries of social media and instant messaging.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.6.jpeg" width="533" height="296"></p>
<p><em><sub>Sundar Pichai wondering how to monetize a virtual assistant</sub></em></p>
<p><strong>Google vs.&nbsp;Amazon</strong></p>
<p>Meanwhile, in 2014, Amazon released a product called Amazon Echo, a small speaker that could sit in your home and answer questions, perform tasks, and buy things online for you. The Echo was a&nbsp;<a href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1" rel="noopener" target="_blank" data-href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1">smash success</a>. Google released its copycat product, Google Home, two years later, but it was already&nbsp;<a href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology" rel="noopener" target="_blank" data-href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology">too late to catch up</a>, and had no clear revenue strategy.</p>
<p>Alexa — the assistant that lived inside the Echo — on the other hand, was quickly integrated into several products and services, and its monetization model was clear, viable, and most importantly future-friendly. The Echo made it easy to order products through Amazon, and every time someone used an Echo to purchase something, Amazon made money.</p>
<p>Google extended the reach of their virtual assistant by building it into Android, but doing so still didn’t provide an answer for how the technology would generate enough revenue to sustain Google’s expanding repertoire of expensive innovations.</p>
<p>Google’s ads relied on screens, yet voice interaction subverted screens entirely. Google briefly tried playing audio ads with the Google Home, but consumers were&nbsp;<a href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/" rel="noopener" target="_blank" data-href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/">far from receptive</a>. Investors&nbsp;<a href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1" rel="noopener" target="_blank" data-href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1">started to voice their concerns in 2017</a>, but Sundar Pichai told them not to worry, leaving them to assume that Google would use their age-old strategy and analyze users’ voice searches so that users could be shown more suitable ads on devices with screens.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.7.jpeg" width="533" height="336"></p>
<p><em><sub>Alexa celebrating its victory over Google</sub></em></p>
<p>Headlines in early 2017&nbsp;<a href="https://www.wired.com/2017/01/ces-alexa-in-everything/" rel="noopener" target="_blank" data-href="https://www.wired.com/2017/01/ces-alexa-in-everything/">proclaimed</a>&nbsp;that “Alexa Just Conquered CES. The World is Next.” Amazon then made their technology&nbsp;<a href="http://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/" rel="noopener" target="_blank" data-href="http://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/">available</a>&nbsp;to third party manufacturers, putting even more distance between the two companies. Amazon&nbsp;<a href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/" rel="noopener" target="_blank" data-href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/">had already beaten Google once before</a>, holding 54% of the cloud computing market (compared to Google’s 3%) in 2016, and they were just getting started. By early 2017, Amazon&nbsp;<a href="http://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html" rel="noopener" target="_blank" data-href="http://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html">had begun closing in</a>&nbsp;on&nbsp;<a href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail" rel="noopener" target="_blank" data-href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail">the entire</a>&nbsp;<a href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4" rel="noopener" target="_blank" data-href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4">retail industry</a>.</p>
<p><strong>Ads weren’t&nbsp;forever</strong></p>
<p>At its peak, Google had a massive and loyal user-base across a staggering number of products, but advertising revenue was the glue that held everything together. As the numbers waned, Google’s core began to buckle under the weight of its vast empire.</p>
<p>Google was a driving force in the technology industry ever since its disruptive entry in 1998. But in a world where people despised ads, Google’s business model was not innovation-friendly, and they missed several opportunities to pivot, ultimately rendering their numerous grand and ambitious projects unsustainable. Innovation costs money, and Google’s main stream of revenue had started to dry up.</p>
<p>In a few short years, Google had gone from a fun, commonplace verb to a reminder of how quickly a giant can fall.</p>
<h2><img src="http://www.sfu.ca/~sfuolc/OLC/Website/Forall/About-Author-Top.png" width="517" height="16"></h2>
<p><em><img src="http://www.sfu.ca/olc/sites/default/files/1.2.jpg" width="90" height="90"></em><em>Daniel is a Master of Digital Media student, currently completing his internship as a product manager at a Vancouver-based blockchain startup called Covalent. Daniel likes writing code and writing words, and he’s not sure what’s next, but he’s excited about it. You can find out what he’s up to now by checking out&nbsp;</em><em><a href="https://www.linkedin.com/in/danielcolinjames/">his LinkedIn page</a></em><em>.</em></p>
<hr>
<h2><strong>Beyond the Article</strong></h2>
<ul>
<li>Check out how Daniel's article led him to get recommended by Google's VP of Design <a href="https://danielcolinjames.com/how-google-collapsed">here</a></li>
<li>See some of his other work on his <a href="https://danielcolinjames.com/">portfolio site</a></li>
</ul>
</div></div>]]>
            </description>
            <link>http://www.sfu.ca/olc/blog/engage/how-google-will-collapse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25213493</guid>
            <pubDate>Wed, 25 Nov 2020 19:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Technical phone screen superforecasters]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25213254">thread link</a>) | @leeny
<br/>
November 25, 2020 | http://blog.interviewing.io/technical-phone-screen-superforecasters/ | <a href="https://web.archive.org/web/*/http://blog.interviewing.io/technical-phone-screen-superforecasters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				
				
	
				<article id="post-2730">
					
					
	<header>
		<h2>
			<a href="http://blog.interviewing.io/category/uncategorized/">Uncategorized</a>		</h2>
		
		<span>
			Posted 
			
			on <i></i><time datetime="2020-11-25"> November 25th, 2020</time>.
		</span>
	</header>


					<section>
						
<p><em>Hey, Aline (founder of interviewing.io) here.&nbsp;This is the third post in our Guest Author series.</em></p>



<p><em>In this post, our latest Guest Author looks at interviews from the company’s perspective. So much engineering time goes into interviewing… <a href="http://blog.interviewing.io/you-probably-dont-factor-in-engineering-time-when-calculating-cost-per-hire-heres-why-you-really-should/">we know this firsthand</a>, but what can be done about it? Some companies solve this problem by introducing homework. In this post, our Author digs into some historical data to unearth a really clever, elegant way to save eng time that’s also better for candidate experience!</em></p>



<p><em>If you have strong opinions about interviewing or hiring that you’ve been itching to write about, we’d love to hear from you. Please email me at <a href="mailto:aline@interviewing.io" target="_blank" rel="noreferrer noopener">aline@interviewing.io</a> to get started.</em></p>



<hr>



<p><img loading="lazy" width="1708" height="1913" src="http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499.jpg" alt="Alexey K" srcset="http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499.jpg 1708w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-268x300.jpg 268w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-914x1024.jpg 914w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-200x224.jpg 200w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-768x860.jpg 768w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-1371x1536.jpg 1371w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-1680x1882.jpg 1680w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-860x963.jpg 860w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-680x762.jpg 680w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-400x448.jpg 400w, http://blog.interviewing.io/wp-content/uploads/2020/11/Alexey-scaled-e1606329022499-50x56.jpg 50w" sizes="(max-width: 1708px) 100vw, 1708px"><em>Alexey Komissarouk is a growth engineering leader. He’s currently working on growth at MasterClass. Before that, he spent 2016-2020 at Opendoor, first as an early engineer, then as an Engineering Manager. Between 2013 and 2016, he built out a&nbsp;<a href="http://calldownmule.com/">product engineering consulting company</a>, helping clients such as Dropbox, Pebble, Boomerang, and Binti grow and expand lines of business through a combination of product management and engineering. In his other lives, Alexey co-founded a boutique work+travel company, Hacker Paradise. Since the company’s inception in 2015, they’ve run trips to over a dozen locations and been joined by more than 800 alumni.</em></p>



<p>“The new VP wants us to double engineering’s headcount in the next six months. If we have a chance in hell to hit the hiring target, you seriously need to reconsider how fussy you’ve become.”</p>



<div><p>It’s never good to have a recruiter ask engineers to lower their hiring bar, but he had a point. It can take upwards of <a target="_blank" href="https://blog.interviewing.io/you-probably-dont-factor-in-engineering-time-when-calculating-cost-per-hire-heres-why-you-really-should/" rel="noreferrer noopener">100 engineering hours</a> to hire a single candidate, and we had over 50 engineers to hire. &nbsp;Even with the majority of the team chipping in, engineers would often spend multiple hours a week in interviews. Folks began to complain about interview burnout. Also, fewer people were actually getting offers; the <em>onsite pass rate</em> had fallen by almost a third, from ~40% to under 30%. This meant we needed even more interviews for every hire.</p><p><a target="_blank" href="https://twitter.com/visnup" rel="noreferrer noopener">Visnu</a> and I were early engineers bothered most by the state of our hiring process. We dug in. Within a few months, the <strong>onsite pass rate</strong> went back up, and interviewing burnout receded. &nbsp;<strong>We didn’t lower the hiring bar, though. There was a better way.</strong></p></div>







<span>Introducing: the Phone Screen Team</span>



<p>We took the company’s best technical interviewers and organized them into a dedicated Phone Screen Team. No longer would engineers be assigned between onsite interviews and preliminary phone screens at recruiting coordinators’ whims. The Phone Screen Team specialized in phone screens; everybody else did onsites.</p>







<span>Why did you think this would be a good idea?</span>



<p>Honestly, all I wanted at the start was to see if I was a higher-signal interviewer than my buddy Joe. So I graphed people’s phone screen pass rate against how those candidates performed in their onsite pass rate.</p>



<p>Joe turned out to be the better interviewer. More importantly, I stumbled into the fact that a number of engineers doing phone screens performed consistently better across the board. They both had more candidates pass their phone screens and then those candidates would get offers at a higher rate.</p>



<figure><img loading="lazy" width="1024" height="446" src="http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-1024x446.png" alt="" srcset="http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-1024x446.png 1024w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-300x131.png 300w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-200x87.png 200w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-768x335.png 768w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-1536x669.png 1536w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-860x375.png 860w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-680x296.png 680w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-400x174.png 400w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1-50x22.png 50w, http://blog.interviewing.io/wp-content/uploads/2020/11/alexeypost1.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Sample data, recreated for illustrative purposes</figcaption></figure>



<p>These numbers were consistent, quarter over quarter. As we compared the top quartile of phone screeners to everybody else, the difference was stark. Each group included a mix of strict and lenient phone screeners; on average, both groups had a phone screen pass rate of 40%.</p>



<p>The similarities ended there: the top quartile’s invitees were twice as likely to get an offer after the onsite (50% vs 25%). These results also were consistent across quarters.[1]</p>



<p>Armed with newfound knowledge of phone screen <a href="https://en.wikipedia.org/wiki/Superforecaster" target="_blank" rel="noreferrer noopener">superforecasters</a>, the obvious move was to have them do all the interviews. In retrospect, <a href="https://medium.com/@alexallain/what-ive-learned-interviewing-500-people-the-interviewer-skills-ladder-for-high-growth-software-37778d2aae85" target="_blank" rel="noreferrer noopener">it made a ton of sense</a> that some interviewers were “just better” than others.</p>



<p>A quarter after implementing the new process, the “phone screen to onsite” rate stayed constant, but the “onsite pass rate” climbed from ~30% to ~40%, shaving more than 10 hours-per-hire[2]. Opendoor was still running this process when I left several years later.</p>



<p>You should too[3], [4].</p>







<span>Starting your own Phone Screen Team</span>







<span>1. Identifying interviewers</span>



<p>Get your Lever or Greenhouse (or <a target="_blank" href="https://en.wikipedia.org/wiki/Applicant_tracking_system" rel="noreferrer noopener">ATS </a>of choice) into an analyzable place somewhere, and then quantify how well interviewers perform[5]. There’s lots of ways to analyze performance; here’s a simple approach which favors folks who generated lots of offers from as few as possible onsites and phone screens.</p>



<figure><img loading="lazy" width="732" height="111" src="http://blog.interviewing.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-10.52.57-AM.png" alt="" srcset="http://blog.interviewing.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-10.52.57-AM.png 732w, http://blog.interviewing.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-10.52.57-AM-300x45.png 300w, http://blog.interviewing.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-10.52.57-AM-200x30.png 200w, http://blog.interviewing.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-10.52.57-AM-680x103.png 680w, http://blog.interviewing.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-10.52.57-AM-400x61.png 400w, http://blog.interviewing.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-10.52.57-AM-50x8.png 50w" sizes="(max-width: 732px) 100vw, 732px"></figure>



<p>You can adjust the constants to where zero would match a median interviewer. A score of zero, then, is good. Your query will look something like this:</p>



<figure><table><thead><tr><th>Interviewer</th><th data-align="center">Phone Screens</th><th data-align="center">Onsites</th><th data-align="center">Offers</th><th data-align="center">Score</th></tr></thead><tbody><tr><td>Accurate Alice</td><td data-align="center">20</td><td data-align="center">5</td><td data-align="center">3</td><td data-align="center">(45 – 20 – 20) / 20 = 0.25&nbsp;</td></tr><tr><td>Friendly Fred</td><td data-align="center">20</td><td data-align="center">9</td><td data-align="center">4</td><td data-align="center">(60 – 36 – 20) / 20 = 0.2</td></tr><tr><td>Strict Sally</td><td data-align="center">20</td><td data-align="center">4</td><td data-align="center">2</td><td data-align="center">(30 – 16 – 20) / 20 = -0.3</td></tr><tr><td>Chaotic Chris</td><td data-align="center">20</td><td data-align="center">10</td><td data-align="center">3</td><td data-align="center">(45 – 40 – 20) / 20 = -0.75</td></tr><tr><td>No Good Nick</td><td data-align="center">20</td><td data-align="center">12</td><td data-align="center">2</td><td data-align="center">(30 – 48 – 20) / 30 = -1.9</td></tr></tbody></table></figure>



<p>Ideally, hires would also be included in the funnel, since a great phone screen experience would make a candidate more likely to join. I tried including them; unfortunately, the numbers get too small and we start running out of statistical predictive power.</p>







<span>2. Logistics &amp; Scheduling</span>



<p>Phone Screen interviewers no longer do onsite interviews (except as emergency backfills). The questions they ask are now retired from the onsite interview pool to avoid collisions.</p>



<p>Ask the engineers to identify and block off 4 hour-long weekly slots to make available to recruiting (recruiting coordinators will love you). Use a tool like <a target="_blank" href="http://youcanbook.me/" rel="noreferrer noopener">youcanbook.me</a> or <a target="_blank" href="https://calendly.com/" rel="noreferrer noopener">calendly</a> to create a unified availability calendar. Aim to have no more than ~2.5 interviews per interviewer per week. To minimize burnout, one thing we tried was to take 2 weeks off interviewing every 6 weeks.&nbsp;</p>



<p>To avoid conflict, ensure that interviewers’ managers are bought in to the time commitment and incorporate their participation during performance reviews.</p>







<span>3. Onboarding Interviewers</span>



<p>When new engineers join the company and start interviewing, they will initially conduct on-site interviews only. If they perform well, consider inviting them into the phone screen team as slots open up. Encourage new members to keep the same question they were already calibrated on, but adapt it to the phone format as needed. In general, it helps to <a target="_blank" href="https://triplebyte.com/blog/how-to-interview-engineers" rel="noreferrer noopener">make the question easier and shorter</a> than if you were conducting the interview in person.</p>



<p>When onboarding a new engineer onto the team, have them shadow a current member twice, then be reverse-shadowed by that member twice. Discuss and offer feedback after each shadowing.</p>







<span>4. Continuous Improvement</span>



<p>Interviewing can get repetitive and lonely. Fight this head-on by having recruiting coordinators add a second interviewer (not necessarily from the team) to join 10% or so of interviews and discuss afterwords.</p>



<p>Hold a monthly retrospective with the team and recruiting, with three items on the agenda:</p>



<ul><li>discuss potential process improvements to the interviewing process</li><li>review borderline interviews with the group to review together, if <a target="_blank" href="http://coderpad.io/" rel="noreferrer noopener">your interviewing tool</a> supports recording and playback</li><li>have interviewers read through feedback their candidates got from onsite interviewers and look for consistent patterns</li></ul>







<span>5. Retention</span>



<p>Eventually, interviewers may get burnt out and say things like “I’m interviewing way more people than others on my actual team – why? I could just go do onsite interviews.” This probably means it’s time to rotate them out. Six months feels about right for a typical “phone screen team” tour of duty, to give people a rest. Some folks may not mind and stay on the team for longer.</p>



<p>Buy exclusive swag for team members. Swag are cheap and these people are doing incredibly valuable work. Leaderboards (“Sarah interviewed 10 of the new hires this year”) help raise awareness. Appreciation goes a long way.</p>



<p>Also, people want to be on teams with cool names. Come up with a cooler name than “Phone Screen Team.” My best idea so far is “Ambassadors.”</p>







<span>Conclusion</span>



<p>There’s something very Dunder Mifflin about companies that create Growth Engineering organizations to micro-optimize conversion, only to have those very growth engineers struggle to focus due to interview thrash from an inefficient hiring process. These companies invest millions into hiring, coaching and retaining the very best sales people. Then they leave recruiting – selling the idea of working at the company – in the hands of an engineer that hasn’t gotten a lick of feedback on their interviewing since joining two years ago, with a tight project deadline on the back of her mind.</p>



<p>If you accept the simple truth that not all interviewers are created equal, that the same rigorous quantitative process with which you improve the business should also be used to improve your internal operations, and if you’re trying to hire quickly, you should consider creating a Technical Phone Screen Team.</p>







<span>FAQs, Caveats, and Preemptive Defensiveness</span>







<ol><li><strong>Was this statistically significant, or are you conducting pseudoscience? </strong>Definitely pseudoscience. Folks in the sample were conducting about 10 interviews a month, ~25 per quarter. Perhaps not yet ready to <a target="_blank" href="https://www.nature.com/articles/d41586-019-00857-9" rel="noreferrer noopener">publish in Nature </a>but meaningful enough to infer from, especially considering the relatively low cost of being wrong.&nbsp;</li></ol>



<ol start="2"><li><strong>Why didn’t the on-site pass rate double, as predicted?</strong> First, not all of the top folks ended up joining the team. Second, the best performers did well because of a combination of skill (great interviewers, friendly, high signal) and luck (got better candidates). Luck is fleeting, resulting in a <a href="https://en.wikipedia.org/wiki/Regression_toward_the_mean" target="_blank" rel="noreferrer noopener">regression to the mean</a>.</li></ol>



<ol start="3"><li><strong>What …</strong></li></ol></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.interviewing.io/technical-phone-screen-superforecasters/">http://blog.interviewing.io/technical-phone-screen-superforecasters/</a></em></p>]]>
            </description>
            <link>http://blog.interviewing.io/technical-phone-screen-superforecasters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25213254</guid>
            <pubDate>Wed, 25 Nov 2020 19:31:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sit Straight Up: How Dieting Is Like Posture]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25211957">thread link</a>) | @pbw
<br/>
November 25, 2020 | https://www.kmeme.com/2020/11/sit-up-straight-dieting-is-like-posture.html | <a href="https://web.archive.org/web/*/https://www.kmeme.com/2020/11/sit-up-straight-dieting-is-like-posture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6117893139176476722" itemprop="description articleBody">
<p>After years of struggling to lose weight, I've lost 30 pounds this year. My number one takeaway has been realizing I need to be mindful of what I eat all day, from eyes open to going to bed.</p>

<p>For years I'd been giving up single things. No soda or juice. No desserts. No chips. No fries. Yet incredibly, whatever I did it didn't make a dent, at least not for long. Which seemed totally impossible.</p>

<p>I'd just cut out thousands of calories! And... nothing. Eventually, I realized it was like pushing down on a waterbed. I'd just end up eating the calories somewhere else. Automatically and without fail.</p>

<div><p><a href="https://lh3.googleusercontent.com/-U2RZSjyEQRU/X8B4u5G8aVI/AAAAAAAFHHQ/_OawWuIiGL0lKvmMWlJnnVeqdd-SUMzJACLcBGAsYHQ/image.png"><img data-original-height="381" data-original-width="750" height="326" src="https://lh3.googleusercontent.com/-U2RZSjyEQRU/X8B4u5G8aVI/AAAAAAAFHHQ/_OawWuIiGL0lKvmMWlJnnVeqdd-SUMzJACLcBGAsYHQ/w640-h326/image.png" width="640"></a></p><p>Maintaining good posture is easy: when you notice you are slumping, sit up straight. The hard part is noticing. What's going on at that moment when you start to slump? The exact moment when your head tilts down or your back starts to curve? Where is your mind right at that moment? How are you letting this happen? I mean what the hell, who is minding the store here?</p></div>

<p>I feel like that's exactly where my mind was when I was making a late-night snack, or grabbing another handful of chips, or digging into another piece of pizza. I was there for those moments in a way, but also not there.</p><p>Honestly, sometimes I felt like a spectator. I'd look at the snack I fixed myself and say, “Boy I should not be eating this,” then I’d sit down and eat it. Afterward, I'd say, “I should not have eaten that”. Can I talk to a manager, is there no one in charge here?</p>

<p>What finally worked was pushing the desire to lose weight down deeply into every fiber of my being, so in those moments I was present, the “I” that I wanted to be was present. Once present, the choice was actually easy. If I'm trying to lose weight, which I am, should I eat this handful of M&amp;M's? No, no I should not.</p>

<p>How to stay present? I did mindfulness meditation for several years, and I think mindfulness is what we are talking about. It's the opposite of mindlessness, and mindlessness is the enemy. What they don't advertise is there are ways to increase mindfulness without meditation. They are just... a little weird.</p>

<p>When you have an itch, even an intense one, just observe it for a while. See what happens. Often it will go away. If it's unbearable then scratch it, but not every time, and not right away.</p>

<p>If you are doing anything rushed, like writing or cleaning or typing your password in wrong, once in a while do it really slow. Like impossibly slow. The other day I was tearing a perforated piece of paper such that I waited for each single pop, then pulled it a bit more. One time I shaved so slowly that I was enjoying listening to the individual whiskers snap.</p>

<p>The goal is not just “do things slowly”. The goal is to catch yourself doing something on auto-pilot and intervene with some deliberate action. To be aware of what you were doing, then modify what you were doing mindfully. It's best to do this for different activities, sporadically. Sense that the auto-pilot has taken over, then do something to disrupt that automatic behavior.</p><p><a href="https://lh3.googleusercontent.com/-fievTLupx7M/X76Ld1UoftI/AAAAAAAFHG8/qIy8zP7hJ3IFRLtE0MkjzJQpY7YMIONlgCLcBGAsYHQ/image.png"><img data-original-height="282" data-original-width="425" height="424" src="https://lh3.googleusercontent.com/-fievTLupx7M/X76Ld1UoftI/AAAAAAAFHG8/qIy8zP7hJ3IFRLtE0MkjzJQpY7YMIONlgCLcBGAsYHQ/w640-h424/image.png" width="640"></a></p>

<p>Sometimes if I'm on a mostly empty road, but I'm following someone too closely, I'll slow WAY down, until they are far in front of me. I've learned that for me this “following behavior” is very automatic.</p>

<p>After there's a gap I resume my exact same speed, but now I'm a constant five seconds behind. It's less stressful and safer, and the only downside is I'll arrive a whopping five seconds after they will. Notice you are doing something, then modify what you are doing.</p>

<p>When I finally put it together there was no grit your teeth effort required, it was just being consistently mindful of my goal, and therefore mindful as to whether my behavior was aligned with my goal. It required a light touch, not a heavy lift. If “I” was there, I'd make the right decision. If I was on auto-pilot, I'd make the wrong decision. So my goal was no longer really to lose weight, it was simply to always be there.</p>

<p><b>Related Posts on kmeme</b></p>
<ul><li><a href="https://www.kmeme.com/2020/09/lose-weight-with-nightmare-fuel.html">The Hungry Ancestor Diet</a></li>
<li><a href="https://www.kmeme.com/2019/09/mindfulness-is-driving-without-texting.html">Mindfulness is driving without texting</a></li>
<li><a href="https://www.kmeme.com/2016/03/mindfull-reps.html">Mindul Reps</a></li>
<li><a href="https://www.kmeme.com/2016/07/waking-up.html">Waking Up</a></li>
</ul>

</div></div>]]>
            </description>
            <link>https://www.kmeme.com/2020/11/sit-up-straight-dieting-is-like-posture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25211957</guid>
            <pubDate>Wed, 25 Nov 2020 17:49:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is Breach and Attack Simulation]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25209359">thread link</a>) | @dkccit
<br/>
November 25, 2020 | https://www.cloudcape.de/en/what-is-breach-and-attack-simulation/ | <a href="https://web.archive.org/web/*/https://www.cloudcape.de/en/what-is-breach-and-attack-simulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="35cb009c" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p>In recent years, more and more providers of so-called Breach and Attack Simulation platforms have emerged in the market. In 2017, Gartner included Breach and Attack Simulation as a new category in the “Hype Cycle for Threat-Facing Technologies” and it was even attested that Breach and Attack Simulation has the potential to become mainstream within the next 10 years. Some even speak of a technological revolution that will fundamentally change the way companies analyze their security status in the future.</p>
<p>In this blog article I would like to answer the following questions about Breach and Attack Simulation:</p>
<ul>
<li>What is behind this new technology?</li>
<li>What problems does BAS try to solve?</li>
<li>For which companies are BAS solutions particularly suitable?</li>
<li>Which solutions are on the market and how do they differ from each other?</li>
<li>How does Breach and Attack Simulation relate to classical <a href="https://www.cloudcape.de/en/penetration-testing/">penetration testing of enterprise networks</a>?</li>
</ul>
<p>So, here we go!</p>
<h2>What is Breach and Attack Simulation?</h2>
<p>Breach and Attack Simulation is a new way of testing IT security efforts that mimics real-world attack actions to determine if the company’s various security measures actually serve their purpose. There are three different types of BAS solutions:</p>
<p><strong>Agent-based BAS solutions:</strong></p>
<p>Agent-based solutions are the simplest form of BAS. Agents are deployed across the LAN and vulnerabilities are identified to determine which routes are open to a potential attacker to move around the network. An agent-based BAS solution is very similar to vulnerability scanning, but offers much more context.</p>
<p><strong>BAS solutions based on “malicious” traffic</strong></p>
<p>These BAS solutions generate intrusive traffic within the network between dedicated virtual machines that serve as targets for a wide range of attack scenarios. An overview is then created of which events have not been detected and blocked by the company’s own security controls. As with agent-based BAS solutions, you get information about how an attacker could move if he enters the network.</p>
<p><strong>Cloud-based BAS solutions</strong></p>
<p>BAS solutions that are cloud-based are the closest to a real attack. They simulate numerous attack scenarios from the outside via different entry points. (so-called multi-vector attacks) and thus also the network perimeter of the company. The cloud platforms are fed with the latest threats from a wide variety of sources and are therefore always very up-to-date. Being SaaS solutions, they can be implemented very quickly.</p>
<h2>What problems do BAS tools attempt to solve?</h2>
<p>BAS solutions give companies an answer to the question “Do our cybersecurity programs really work? Large companies invest heavily in security products, but still do not have the confidence that they can withstand increasingly sophisticated attacks. For financial and practical reasons it is also not possible to test entire enterprise production environments permanently and manually for security vulnerabilities. Breach and Attack Simulation fills exactly this gap and allows companies to get more out of their existing security solutions by enabling continuous testing of the enterprise network at low risk.</p>
<h2>For which companies are BAS solutions suitable?</h2>
<p>If you have a look around the BAS market, you will find that many offers are tailored to large enterprise customers with high security requirements, such as financial institutions and insurance companies. It is not surprising that Breach and Attack Simulation is especially interesting for this kind of companies. They typically have numerous security products in use, a dynamic IT landscape and a high level of IT maturity. In addition, there are high demands on IT security and high compliance pressure. High-end solutions like Breach and Attack Simulation are predestined for this environment.</p>
<p>However, there is also the possibility for smaller companies to use BAS technology. Some solution providers have made their BAS tools multi-tenant ready so that smaller companies can also benefit from them via partner companies.</p>
<p>Which products are on the market and how do they differ from each other? In the still very young BAS market, a number of companies and start-ups, mainly from Israel and the USA, are thriving. In the following I would like to introduce some selected solution providers:</p>
<p><strong>SafeBreach (Israel/USA)</strong></p>
<p>SafeBreach was founded in 2014 in Tel Aviv and is therefore one of the “older” players on the market. SafeBreach describes their product as a Continuous Security Validating Platform, which takes over the role of a virtual ethical hacker. The platform consists of two components: the cloud management console and on-premise virtual machines called “Breach Simulators”, which play so-called “War Games” among each other. SafeBreach’s solution is in fact based on “malicious” traffic that flows between the Breach Simulators themselves and the cloud.</p>
<p>SafeBreach is the pioneer in the BAS industry and now has an extensive “Hacker’s Playbook” with thousands of attack methods, which is constantly updated by the SafeBreach Lab.</p>
<p><strong>Cymulate (Israel)</strong></p>
<p>Cymulate was also founded in Israel in 2016. In 2018, Cymulate was named a “Cool Vendor” by Gartner and is probably the platform in the BAS market that gets the biggest hype. Among its successes, Cymulate has raised considerable amounts of funds from well-known venture capitalists. Cymulate advertises with particularly easy deployment and operation. Only a single agent is required in the network itself. The platform offers numerous attack vectors (e-mail gateway, web gateway, web application firewall, lateral movement, data loss prevention and endpoint security control) and can therefore simulate an Advanced Persistent Threat (APT). Great are the integrations to other security products, such as <strong><a href="https://www.cloudcape.de/en/vulnerability-management-as-a-service-en/">vulnerability management</a></strong>, SIEM and EDR solutions. Cymulate is very pricy. Currently, the <strong><a href="https://aws.amazon.com/marketplace/pp/B0882VSXXY?ref_=srh_res_product_title">7-Vector bundle costs 7000 USD per month via the AWS Marketplace</a></strong>. However, there is also a light version with fewer attack vectors available. On Youtube, you can get a good impression of the platform:</p>
<p><iframe title="Cymulate Immediate Threats Intelligence Module - Training" width="1200" height="675" src="https://www.youtube.com/embed/TzEdImSxNc0?start=29&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><strong>XM Cyber (Israel)</strong></p>
<p>XM Cyber is in my opinion another notable player in the BAS market. Since its foundation in 2016 by top leaders of the Israeli cyber intelligence community, the company has gained some attention and is currently expanding globally. The HaXM platform is relatively easy to roll out. A lightweight software agent must be installed on all critical assets, and the platform itself is delivered as Software-as-a-Service. For very security-conscious companies, the solution can also be set up on-premise. The simulations are performed in three steps:</p>
<ul>
<li>First, all critical assets are selected</li>
<li>Secondly, attacks are simulated and all attack vectors to critical assets are revealed (this is done very clearly in the platform’s “Battle Ground” dialogue box)</li>
<li>Lastly, detailed remediation reports and security evaluations can be exported</li>
</ul>
<p>This 3-minute demo of XM Cyber gives a very good impression of the platform and shows the impressive user interface.</p>
<p><iframe title="XM Cyber Breach and Attack Simulation Demo Video" width="1200" height="675" src="https://www.youtube.com/embed/inDj1MFxzvg?start=73&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<h2>How does Breach and Attack Simulation relate to manual penetration testing?</h2>
<p>The interesting question remains whether Breach and Attack Simulation can replace traditional penetration testing of networks in the future. Currently, the market adoption of Breach and Attack Simulation is not very widespread. As a penetration tester, I believe that you will not have to fear for your job any time soon. In addition, compliance requirements still demand the conducting of classic penetration tests. Last but not least, Breach and Attack Simulation is also a question of your budget – many small and medium-sized companies are already struggling to invest in a small penetration test, so it is quite doubtful if these companies will invest in an expensive BAS solution.</p>
<p>Some BAS tools on the market only offer attack scenarios that do not include exploits and should therefore be supplemented with manual pentesting in case of doubt. It should not be forgotten that a simulation remains a simulation and collected data is analyzed externally to determine what would happen in reality. This increases the probability of false positives and false negatives.</p>
<p>Despite the obstacles that BAS solution providers still have to overcome, I am very confident that Breach and Attack Simulation will, as it matures, greatly reduce the need for traditional network pentesting. With good BAS solutions, it is possible to “execute” exploits that cannot cause any damage. A conscientious pentester would not even address such exploits with typical pentesting tools, because there is always the danger of damaging the customer environment. In addition, Breach and Attack Simulation provides consistent results regardless of a person’s abilities, continuously and not just as a snapshot. I am very confident that soon there will be pentest-as-a-service offerings powered by Breach and Attack Simulation that will be available to organizations of all sizes.</p>
<h2>Conclusion</h2>
<p>It is worth keeping an eye on the developments on the BAS market. In the future, the importance of BAS solutions will most likely increase significantly. In my opinion, Breach and Attack Simulation has the potential to become a viable alternative to classical Network Penetration Testing with increasing technological maturity and decreasing costs.</p>
		</div>
				</div></div>]]>
            </description>
            <link>https://www.cloudcape.de/en/what-is-breach-and-attack-simulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25209359</guid>
            <pubDate>Wed, 25 Nov 2020 14:09:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libgen Storage Decentralization on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 276 | Comments 110 (<a href="https://news.ycombinator.com/item?id=25209246">thread link</a>) | @jerheinze
<br/>
November 25, 2020 | https://freeread.org/ipfs/ | <a href="https://web.archive.org/web/*/https://freeread.org/ipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
        
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                  
                
                
                
<p>IPFS is here. IPFS is a de-centralized file and webhosting protocol founded on ideals of freedom and openness. The Library Genesis collection is live on IPFS as of today, accessible via <a href="http://libgen.rs/">libgen.rs</a> and <a href="https://libgen.fun/">libgen.fun</a>. IPFS is like BitTorrent but has a single global swarm, and it's accessible on the web. You can learn about the IPFS project from <a href="https://ipfs.io/">IPFS.io</a> or <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">Wikipedia</a>.</p>
<p>IPFS is the next technical revolution in peer-to-peer networking, allowing people like you to share books with readers who request them. IPFS is the next best weapon in the fight against domain take-downs and internet censorship.</p>
<p>We can now each become a founding shelf for a free, global library. Let's start.</p>
<h2 id="get-started">Get started</h2>
<p>IPFS is simple. <em>Hosts</em> (you) <em>Pin</em> files (books) using <em>Content Identifiers</em> (CID Hashes) to share them on the IPFS network. CID Hashes can represent individual files or an entire folder. Pinning saves the files to your local computer so you can share them, and others can Pin them from you.</p>
<p>Each CID Hash for Library Genesis represents 1,000 books, or about 5 gigabytes of local file storage. 100 pins = 100,000 books! Who ever told you that you couldn't start your own library?</p>
<h2 id="copyright-warning">Copyright warning</h2>
<p>Before you begin, make sure you understand <a href="https://www.nolo.com/legal-encyclopedia/what-to-do-if-your-named-bit-torrent-lawsuit.html">the legal implications of hosting and sharing copyrighted material.</a></p>
<h2 id="installing-ipfs">Installing IPFS</h2>
<p>Are you a power-user or run a server? Jump to the section on <a href="#docker-for-servers">getting started with Docker.</a></p>
<p>If you're not, just install the <a href="https://ipfs.io/#install">IPFS Desktop client</a>. Make sure to read the <a href="#system-requirements">desktop system requirements.</a></p>
<h2 id="desktop-client">Desktop client</h2>
<h3 id="system-requirements">System requirements</h3>
<p>Note that IPFS Desktop client is an alpha-stage software still in development. The command line version of the software for servers/home servers is more mature.</p>
<ul>
<li>Requires internet serice provider with unlimited bandwidth. Do not install IPFS if you have a monthly bandwidth or data cap.</li>
<li>Recommended at least 16GB RAM and Intel i5 or equivalent processor</li>
<li>Recommended at least 100 mbps, gigabit connection preferred</li>
<li>Recommended <a href="#port-forwarding">port forwarding</a></li>
</ul>
<h3 id="get-started_1">Get started</h3>
<h4 id="pin-your-first-cid-hash">Pin your first CID Hash</h4>
<p>Click Files &gt; Import &gt; From IPFS</p>
<p>Then copy and paste in your first CID Hash containing 1,000 books (about 6GB). Once it's complete, jump to the <a href="#cid-hash-index">CID Hash index</a>.</p>
<pre><code>
bafykbzaceaeofefgje22l7rhgtcgs22m32f4ysw5nqa3ty5zawfovqam7pj2c

</code></pre>

<p><img alt="Screenshot" src="https://freeread.org/img/ipfs.2.png"></p>
<h2 id="docker-for-servers">Docker for servers</h2>
<p>Previously downloaded the Library Genesis torrents for the Library Genesis Seeding Project? Follow these steps then jump to <a href="#torrents">torrents</a>.</p>
<h3 id="system-requirements_1">System requirements</h3>
<ul>
<li>Docker (<a href="https://docs.docker.com/get-docker/">docker.com/get-docker</a>)</li>
<li>Requires internet serice provider with unlimited bandwidth. Do not install IPFS if you have a monthly bandwidth or data cap.</li>
<li>Requires between 10GB or more of hard-drive space. For more information refer to the <a href="https://cryptpad.fr/sheet/#/2/sheet/view/I5UinPRnv2LNZlMQcNODieaoo7W9L1KDbJMX36OKvdE/">CID Hash index with file sizes.</a></li>
<li>Recommended at least 16GB RAM and Intel i5 or equivalent processor</li>
<li>Recommended at least 100 mbps, gigabit connection preferred</li>
<li>Recommended <a href="#port-forwarding">port forwarding</a></li>
</ul>
<h3 id="get-started_2">Get started</h3>
<h4 id="create-your-docker-container">Create your docker container</h4>
<p>You can more documentation for the Go-based IPFS Docker container at <a href="https://hub.docker.com/r/ipfs/go-ipfs/">Docker Hub.</a>.</p>
<p>/export will store your downloaded files, while the books from pinned CID Hashes will be located in /ipfs/data/blocks.</p>
<pre><code>docker run -d \
--name go-ipfs \
-v $HOME/ipfs/export:/export \
-v $HOME/ipfs/data:/data/ipfs \
-p 4001:4001 \
-p 127.0.0.1:8080:8080 \
-p 127.0.0.1:5001:5001 \
ipfs/go-ipfs:latest 
</code></pre>

<pre><code>docker start go-ipfs
</code></pre>

<h4 id="pin-your-first-cid-hash_1">Pin your first CID Hash</h4>
<p>This 'docker exec' command runs your 'go-ipfs' container with container command 'ipfs pin add'. This CID Hash contains 1,000 books, to add it run:</p>
<pre><code>docker exec go-ipfs ipfs pin add bafykbzaceaeofefgje22l7rhgtcgs22m32f4ysw5nqa3ty5zawfovqam7pj2c --progress
</code></pre>

<p>Once it's complete, jump to the <a href="#cid-hash-index">CID Hash index</a>.</p>
<p>You can also access the WebUI and add or manage pins from there. Port 5001 is the API port of the IPFS docker container and contains the same UI as IPFS desktop. You can access the webui in your browser at <a href="http://127.0.0.1:5001/webui">http://127.0.0.1:5001/webui</a>.</p>
<h4 id="cid-hash-index">CID Hash index</h4>
<p>Once you've pinned your first 1,000 you can add the next 100,000 books of the Library Genesis Scitech collection here:</p>


<h4 id="port-forwarding">Port forwarding</h4>
<p>The IPFS swarm peer port is 4001. Opening it up will help you connect, but it is optional if you can't do so. To learn how to port forward port 4001 search your <a href="https://www.google.com/search?q=ac1750+port+forwarding"><em>router model + port forward.</em></a></p>
<h2 id="torrents">Torrents</h2>
<p>Many volunteers have helped seed the torrents with the <a href="https://www.reddit.com/r/DataHoarder/comments/ed9byj/library_genesis_project_update_25_million_books/">Library Genesis Seeding Project</a>.</p>
<p>If you already downloaded the torrents you can add torrent folders to IPFS using <code>ipfs add</code></p>
<p>Start go-ipfs normally with <code>docker start go-ipfs</code></p>
<p>Configure go-ipfs to allow you link folders to the Filestore:</p>
<pre><code>docker exec go-ipfs ipfs config --json Experimental.FilestoreEnabled true
</code></pre>

<p>Restart with <code>docker stop go-ipfs &amp;&amp; docker start go-ipfs</code></p>
<p>Add the folders from where you saved them, starting with folder 1000:</p>
<pre><code>docker exec go-ipfs ipfs add $home/books/1000/ -r -w --nocopy --hash=blake2b-256 &gt;&gt;  $home/books/ipfs-add.log
</code></pre>

<p>Watch the log and check out the network activity:</p>
<pre><code>docker exec go-ipfs tail -f $home/books/ipfs-add.log
docker exec go-ipfs ipfs stats bw --poll=true --interval=1s
</code></pre>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://freeread.org/ipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25209246</guid>
            <pubDate>Wed, 25 Nov 2020 13:58:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Xrepo – A modern cross-platform C/C++ package manager]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25209145">thread link</a>) | @waruqi
<br/>
November 25, 2020 | https://tboox.org/2020/11/15/xrepo-new-command/ | <a href="https://web.archive.org/web/*/https://tboox.org/2020/11/15/xrepo-new-command/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        <p>xrepo is a cross-platform C/C++ package manager based on <a href="https://github.com/xmake-io/xmake">Xmake</a>.</p>

<ul>
  <li><a href="https://github.com/xmake-io/xrepo">Github</a></li>
  <li><a href="https://xrepo.xmake.io/#/">Official Document</a></li>
</ul>

<p>It is based on the runtime provided by xmake, but it is a complete and independent package management program. Compared with package managers such as vcpkg/homebrew, xrepo can provide C/C++ packages for more platforms and architectures at the same time.</p>

<p>And it also supports multi-version semantic selection. In addition, it is also a decentralized distributed repository. It not only provides the official <a href="https://github.com/xmake-io/xmake-repo">xmake-repo</a> repository, It also supports users to build multiple private repositorys.</p>

<p>At the same time, xrepo also supports installing packages from third-party package managers such as vcpkg/homebrew/conan, and provides unified and consistent library link information to facilitate integration and docking with third-party projects.</p>

<p>If you want to know more, please refer to: <a href="https://xrepo.xmake.io/#/getting_started">Documents</a>, <a href="https://github.com/xmake-io/xrepo">Github</a> and <a href="https://gitee.com/tboox/xrepo">Gitee</a></p>

<p><img src="https://xrepo.xmake.io/assets/img/xrepo.gif" alt=""></p>

<h2 id="installation">Installation</h2>

<p>We only need install xmake to use the xrepo command. About the installation of xmake, we can see: <a href="https://xmake.io/#/guide/installation">Xmake Installation Document</a>.</p>

<h2 id="supported-platforms">Supported platforms</h2>

<ul>
  <li>Windows (x86, x64)</li>
  <li>macOS (i386, x86_64, arm64)</li>
  <li>Linux (i386, x86_64, cross-toolchains ..)</li>
  <li>*BSD (i386, x86_64)</li>
  <li>Android (x86, x86_64, armeabi, armeabi-v7a, arm64-v8a)</li>
  <li>iOS (armv7, armv7s, arm64, i386, x86_64)</li>
  <li>MSYS (i386, x86_64)</li>
  <li>MinGW (i386, x86_64, arm, arm64)</li>
  <li>Cross Toolchains</li>
</ul>

<h2 id="supported-package-repositories">Supported package repositories</h2>

<ul>
  <li>Official package repository <a href="https://github.com/xmake-io/xmake-repo">xmake-repo</a> (tbox &gt;1.6.1)</li>
  <li><a href="https://xmake.io/#/package/remote_package?id=using-self-built-private-package-repository">User-built repositories</a></li>
  <li>Conan (conan::openssl/1.1.1g)</li>
  <li>Vcpkg (vcpkg:ffmpeg)</li>
  <li>Homebrew/Linuxbrew (brew::pcre2/libpcre2-8)</li>
  <li>Pacman on archlinux/msys2 (pacman::libcurl)</li>
  <li>Clib (clib::clibs/bytes@0.0.4)</li>
  <li>Dub (dub::log 0.4.3)</li>
</ul>

<h2 id="suppory-distributed-repository">Suppory distributed repository</h2>

<p>In addition to directly retrieving the installation package from the official repository: <a href="https://github.com/xmake-io/xmake-repo">xmake-repo</a>.</p>

<p>We can also add any number of self-built repositories, and even completely isolate the external network, and only maintain the installation and integration of private packages on the company’s internal network.</p>

<p>Just use the following command to add your own repository address:</p>

<div><pre><code><span>$ </span><span>xrepo</span><span> add-repo myrepo https://github.com/mygroup/myrepo
</span></code></pre>
</div>

<h2 id="seamless-integration-with-xmake-project">Seamless integration with xmake project</h2>

<div><pre><code><span>add_requires</span><span>(</span><span>"tbox &gt;1.6.1"</span><span>,</span> <span>"libuv master"</span><span>,</span> <span>"vcpkg::ffmpeg"</span><span>,</span> <span>"brew::pcre2/libpcre2-8"</span><span>)</span>
<span>add_requires</span><span>(</span><span>"conan::openssl/1.1.1g"</span><span>,</span> <span>{</span><span>alias</span> <span>=</span> <span>"openssl"</span><span>,</span> <span>optional</span> <span>=</span> <span>true</span><span>,</span> <span>debug</span> <span>=</span> <span>true</span><span>})</span>
<span>target</span><span>(</span><span>"test"</span><span>)</span>
     <span>set_kind</span><span>(</span><span>"binary"</span><span>)</span>
     <span>add_files</span><span>(</span><span>"src/*.c"</span><span>)</span>
     <span>add_packages</span><span>(</span><span>"tbox"</span><span>,</span> <span>"libuv"</span><span>,</span> <span>"vcpkg::ffmpeg"</span><span>,</span> <span>"brew::pcre2/libpcre2-8"</span><span>,</span> <span>"openssl"</span><span>)</span>
</code></pre>
</div>

<p>The following is the overall architecture and compilation process integrated with xmake.</p>

<p><img src="https://xmake.io/assets/img/index/package_arch.png" width="650px"></p>

<h2 id="get-started">Get started</h2>

<h3 id="installation-package">Installation package</h3>

<h4 id="basic-usage">Basic usage</h4>

<div><pre><code><span>$ </span><span>xrepo</span><span> install zlib tbox
</span></code></pre>
</div>

<h4 id="install-the-specified-version-package">Install the specified version package</h4>

<div><pre><code><span>$ </span><span>xrepo</span><span> install "zlib 1.2.x"
</span><span>$ </span><span>xrepo</span><span> install "zlib &gt;=1.2.0"
</span></code></pre>
</div>

<h4 id="install-the-specified-platform-package">Install the specified platform package</h4>

<div><pre><code><span>$ </span><span>xrepo</span><span> install -p iphoneos -a arm64 zlib
</span><span>$ </span><span>xrepo</span><span> install -p android [--ndk=/xxx] zlib
</span><span>$ </span><span>xrepo</span><span> install -p mingw [--mingw=/xxx] zlib
</span><span>$ </span><span>xrepo</span><span> install -p cross --sdk=/xxx/arm-linux-musleabi-cross zlib
</span></code></pre>
</div>

<h4 id="install-the-debug-package">Install the debug package</h4>

<div><pre><code><span>$ </span><span>xrepo</span><span> install -m debug zlib
</span></code></pre>
</div>

<h4 id="install-the-package-with-dynamic-library">Install the package with dynamic library</h4>

<div><pre><code><span>$ </span><span>xrepo</span><span> install -k shared zlib
</span></code></pre>
</div>

<h4 id="install-the-specified-configuration-package">Install the specified configuration package</h4>

<div><pre><code><span>$ </span><span>xrepo</span><span> install -f "vs_runtime=MD" zlib
</span><span>$ </span><span>xrepo</span><span> install -f "regex=true,thread=true" boost
</span></code></pre>
</div>

<h4 id="install-packages-from-third-party-package-manager">Install packages from third-party package manager</h4>

<div><pre><code><span>$ </span><span>xrepo</span><span> install brew::zlib
</span><span>$ </span><span>xrepo</span><span> install vcpkg::zlib
</span><span>$ </span><span>xrepo</span><span> install conan::zlib/1.2.11
</span><span>$ </span><span>xrepo</span><span> install pacman:libpng
</span><span>$ </span><span>xrepo</span><span> install dub:log
</span></code></pre>
</div>

<h3 id="find-the-library-information-of-the-package">Find the library information of the package</h3>

<div><pre><code><span>$ </span><span>xrepo</span><span> fetch pcre2
</span>{
  {
    linkdirs = {
      "/usr/local/Cellar/pcre2/10.33/lib"
    },
    links = {
      "pcre2-8"
    },
    defines = {
      "PCRE2_CODE_UNIT_WIDTH=8"
    },
    includedirs = "/usr/local/Cellar/pcre2/10.33/include"
  }
}
</code></pre>
</div>

<div><pre><code><span>$ </span><span>xrepo</span><span> fetch --ldflags openssl
</span>-L/Users/ruki/.xmake/packages/o/openssl/1.1.1/d639b7d6e3244216b403b39df5101abf/lib -lcrypto -lssl
</code></pre>
</div>

<div><pre><code><span>$ </span><span>xrepo</span><span> fetch --cflags openssl
</span>-I/Users/ruki/.xmake/packages/o/openssl/1.1.1/d639b7d6e3244216b403b39df5101abf/include
</code></pre>
</div>

<div><pre><code><span>$ </span><span>xrepo</span><span> fetch -p [iphoneos|android] --cflags "zlib 1.2.x"
</span>-I/Users/ruki/.xmake/packages/z/zlib/1.2.11/df72d410e7e14391b1a4375d868a240c/include
</code></pre>
</div>

<div><pre><code><span>$ </span><span>xrepo</span><span> fetch --cflags --ldflags conan::zlib/1.2.11
</span>-I/Users/ruki/.conan/data/zlib/1.2.11/_/_/package/f74366f76f700cc6e991285892ad7a23c30e6d47/include -L/Users/ruki/.conan/data/zlib/1.2.11/_/_/package/f74366f76f700cc6e991285892ad7a23c30e6d47/lib -lz
</code></pre>
</div>

<h3 id="export-the-installed-packages">Export the installed packages</h3>

<p>xrepo can quickly export installed packages, including corresponding library files, header files, etc.</p>

<div><pre><code><span>$ </span><span>xrepo</span><span> export -o /tmp/output zlib
</span></code></pre>
</div>

<h3 id="search-supported-packages">Search supported packages</h3>

<div><pre><code><span>$ </span><span>xrepo</span><span> search zlib "pcr*"
</span>    zlib:
      -&gt; zlib: A Massively Spiffy Yet Delicately Unobtrusive Compression Library (in xmake-repo)
    pcr*:
      -&gt; pcre2: A Perl Compatible Regular Expressions Library (in xmake-repo)
      -&gt; pcre: A Perl Compatible Regular Expressions Library (in xmake-repo)
</code></pre>
</div>

<h3 id="show-package-environment-information">Show package environment information</h3>

<div><pre><code><span>$ </span><span>xrepo</span><span> env --show luajit
</span>{
   OLDPWD = "/mnt/tbox",
   HOME = "/home/ruki",
   PATH = "/home/ruki/.xmake/packages/l/luajit/2.1.0-beta3/fbac76d823b844f0b91abf3df0a3bc61/bin:/tmp:/tmp/arm-linux-musleabi-cross/bin:~/.local/bin: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
   TERM = "xterm",
   PWD = "/mnt/xmake",
   XMAKE_PROGRAM_DIR = "/mnt/xmake/xmake",
   HOSTNAME = "e6edd61ff1ab",
   LD_LIBRARY_PATH = "/home/ruki/.xmake/packages/l/luajit/2.1.0-beta3/fbac76d823b844f0b91abf3df0a3bc61/lib",
   SHLVL = "1",
   _ = "/mnt/xmake/scripts/xrepo.sh"
}
</code></pre>
</div>

<h3 id="load-package-environment-and-run-commands">Load package environment and run commands</h3>

<div><pre><code><span>$ </span><span>xrepo</span><span> env luajit
</span>LuaJIT 2.1.0-beta3 -- Copyright (C) 2005-2017 Mike Pall. http://luajit.org/
JIT: ON SSE2 SSE3 SSE4.1 BMI2 fold cse dce fwd dse narrow loop abc sink fuse
&gt;
</code></pre>
</div>

<div><pre><code><span>$ </span><span>xrepo</span><span> env -b "luajit 2.x" luajit
</span><span>$ </span><span>xrepo</span><span> env -p iphoneos -b "zlib,libpng,luajit 2.x" cmake ..
</span></code></pre>
</div>

<h3 id="show-the-given-package-information">Show the given package information</h3>

<div><pre><code><span>$ </span><span>xrepo</span><span> info zlib
</span>The package info of project:
    require(zlib):
      -&gt; description: A Massively Spiffy Yet Delicately Unobtrusive Compression Library
      -&gt; version: 1.2.11
      -&gt; urls:
         -&gt; http://zlib.net/zlib-1.2.11.tar.gz
            -&gt; c3e5e9fdd5004dcb542feda5ee4f0ff0744628baf8ed2dd5d66f8ca1197cb1a1
         -&gt; https://downloads.sourceforge.net/project/libpng/zlib/1.2.11/zlib-1.2.11.tar.gz
            -&gt; c3e5e9fdd5004dcb542feda5ee4f0ff0744628baf8ed2dd5d66f8ca1197cb1a1
      -&gt; repo: xmake-repo https://gitee.com/tboox/xmake-repo.git master
      -&gt; cachedir: /Users/ruki/.xmake/cache/packages/2010/z/zlib/1.2.11
      -&gt; installdir: /Users/ruki/.xmake/packages/z/zlib/1.2.11/d639b7d6e3244216b403b39df5101abf
      -&gt; searchdirs:
      -&gt; searchnames: zlib-1.2.11.tar.gz
      -&gt; fetchinfo: 1.2.11, system
          -&gt; version: 1.2.11
          -&gt; links: z
          -&gt; linkdirs: /usr/local/Cellar/zlib/1.2.11/lib
          -&gt; includedirs: /usr/local/Cellar/zlib/1.2.11/include
      -&gt; platforms: iphoneos, mingw@windows, macosx, mingw@linux,macosx, android@linux,macosx, windows, linux
      -&gt; requires:
         -&gt; plat: macosx
         -&gt; arch: x86_64
         -&gt; configs:
            -&gt; debug: false
            -&gt; vs_runtime: MT
            -&gt; shared: false
      -&gt; configs:
      -&gt; configs (builtin):
         -&gt; debug: Enable debug symbols. (default: false)
         -&gt; shared: Enable shared library. (default: false)
         -&gt; cflags: Set the C compiler flags.
         -&gt; cxflags: Set the C/C++ compiler flags.
         -&gt; cxxflags: Set the C++ compiler flags.
         -&gt; asflags: Set the assembler flags.
         -&gt; vs_runtime: Set vs compiler runtime. (default: MT)
            -&gt; values: {"MT","MD"}
</code></pre>
</div>

        </article></div>]]>
            </description>
            <link>https://tboox.org/2020/11/15/xrepo-new-command/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25209145</guid>
            <pubDate>Wed, 25 Nov 2020 13:47:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[View of Andromeda over Patagonia]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25207824">thread link</a>) | @jayass
<br/>
November 25, 2020 | https://misspellede.com/us/andromeda-over-patagonia/ | <a href="https://web.archive.org/web/*/https://misspellede.com/us/andromeda-over-patagonia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div> 
                            <p><img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/M31Horizon_Ferrarino_1080.jpg" alt="Andromeda over Patagonia cover image"></p>
            <p><a href="https://misspellede.com/us/cosmos/">cosmos</a></p><p>Gerardo Ferrarino • 2020-11-25</p><p>How far can you see?  The Andromeda Galaxy at 2.5 million light years away is the most distant object easily seen with your unaided eye.  Most other apparent denizens of the night sky -- stars, clusters, and nebulae -- typically range from a few hundred to a few thousand light-years away and lie well within our own Milky Way Galaxy.  Given its distance, light from Andromeda is likely also the oldest light that you can see.  Also known as M31, the Andromeda Galaxy dominates the center of the featured zoomed image, taken from the dunes of Bahía Creek, Patagonia, in southern Argentina.  The image is a combination of 45 background images with one foreground image -- all taken with the same camera and from the same location within 90 minutes.  M110, a satellite galaxy of Andromenda is visible just below and to the left of M31's core. As cool as it may be to see this neighboring galaxy to our Milky Way with your own eyes, long duration camera exposures can pick up many faint and breathtaking details.  Recent data indicates that our Milky Way Galaxy will collide and combine with the similarly-sized Andromeda galaxy in a few billion years.</p>

        </div>
    </article></div>]]>
            </description>
            <link>https://misspellede.com/us/andromeda-over-patagonia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207824</guid>
            <pubDate>Wed, 25 Nov 2020 10:43:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25206221">thread link</a>) | @azhenley
<br/>
November 24, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206221</guid>
            <pubDate>Wed, 25 Nov 2020 05:14:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 56 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I’m not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
    </channel>
</rss>
