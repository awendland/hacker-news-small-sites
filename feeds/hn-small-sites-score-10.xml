<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 08 Dec 2020 04:33:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 08 Dec 2020 04:33:50 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[An Airbnb Thanksgiving Burglary]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25321770">thread link</a>) | @dsr12
<br/>
December 5, 2020 | https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html | <a href="https://web.archive.org/web/*/https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://habrastorage.org/webt/mm/dk/wp/mmdkwpapgwobqrzcauk213qoglk.png" alt=""></p>



<p>I used <a href="https://www.airbnb.com/">Airbnb</a> for years in Russia, Germany, and the United States. All the time, the experience was great. At some point, I read a <a href="https://amzn.to/3o9JywH">book about Airbnb</a> to understand the company better.</p>

<p>For Thanksgiving week (November 21-29), five of my friends and I rented a house in Las Vegas.</p>

<p>The total price for nine days: <strong>$2543</strong>.</p>

<p>Previously people went to Vegas to spend time in casinos or walk on The Strip. This year, <a href="https://www.worldometers.info/coronavirus/">the pandemic</a> made it impossible.</p>

<p>It was not a problem for us. We did not plan to socialize; we were going rock climbing.</p>

<p><a href="https://www.mountainproject.com/area/105731932/red-rock">Red Rocks</a>, located next to Vegas, is an excellent place for traditional, sport, bouldering, multi-pitch climbing.</p>

<p>The plan was for some people to take days off and climb every day, and for others to work three days remotely and join the gang during the rest.</p>

<h2 id="incident">Incident</h2>

<p>We moved in on Saturday night. The next morning, excited, we woke up at 6am, had breakfast, verified that we closed back and front doors and at 7am drove to the Red Rocks Park.</p>

<p>We had a fantastic day of climbing, but after the sunset, we went home to realize that the window in one of the rooms was open and some of our belongings had disappeared.</p>

<ul>
  <li>Three work Macbook Pro (I do not include the price, they are replaced by our employees for free)</li>
  <li>One personal <a href="https://amzn.to/33uWB3F">Macbook Pro</a> ($1550)</li>
  <li><a href="https://amzn.to/2JCZWqE">Oculus Quest 2</a>. I just bought it. Really cool. Wanted to share the experience. ($399)</li>
  <li><a href="https://amzn.to/2VnyrUt">GoPro Hero 6</a> ($194)</li>
  <li><a href="https://amzn.to/36oMMGz">Lenovo Tab 4, 10.1in Android Tablet</a> ($190)</li>
  <li><a href="https://amzn.to/3lms9is">Sony WH1000XM3 Noise Cancelling Headphones</a> ($348)</li>
  <li><a href="https://amzn.to/3qbPNSm">Bose Quietcontrol 30 Wireless Headphones</a> ($169)</li>
  <li><a href="https://amzn.to/3fVzzIh">Bose Noise Cancelling Wireless Bluetooth Headphones 700</a> ($339)</li>
  <li><a href="https://amzn.to/37qgsSN">BlueTooth ledger</a> ($118)</li>
  <li>Two backpacks. (2 x $100)</li>
</ul>

<p><img src="https://habrastorage.org/webt/kz/an/pd/kzanpdzeno_6rkrjjgbrhbscbbs.jpeg" alt=""></p>

<p>I called the host, told her about the situation. She shared a set of images from the cameras and the next day sent the whole video.</p>

<!-- Courtesy of embedresponsively.com //-->

<p>
    <iframe src="https://www.youtube-nocookie.com/embed/cg3Z9ZxtKGw" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </p>

<p>We believe this is what happened:</p>

<p>At 8:55am, two hours after we left, someone</p>
<ol>
  <li>Openly came to the front door.</li>
  <li>Knocked in the door.</li>
  <li>Waved Lexus car keys at the camera. (We do not have Lexus.)</li>
  <li>Ringed the bell.</li>
  <li>Waited to verify that no one was at home.</li>
  <li>Got to the back of the house.</li>
  <li>Put gloves and balaclava on.</li>
  <li>Checked if the back door was open. It was not.</li>
  <li>Checked if he can open the window. And it was possible.
10 Moved the pool chair below the window.</li>
  <li>Got into the house.</li>
</ol>

<p>We called the police, and in two hours an officer came. He was polite and professional. He got the list of the stolen items, our version of the incident in the written form, and left.</p>

<p>I was curious, how did the burglar open the window? I checked, and the answer was simple: <strong>the lock on the window was not operational.</strong> No need to break anything, anyone can open the window from the outside!</p>

<p>If the weather was warmer, we would probably try to open windows the night we came. In that case we would discover the problem, but the night was cold and we did not touch the windows.</p>

<p>Till this moment, I was chill. Bad things happen. Burglars get into houses, and no one could be protected from it. We were safe in this incident, and from the money perspective, our loss was not huge.</p>

<p>But the fact that the lock on that window was not functioning is an issue (few more windows had the same problem). If the front door lock was broken it would be worse but even windows that could not be locked are sketchy.</p>

<p>In general, I prefer to blame myself for bad things that happen to me. This time I cannot figure out what was my fault. For sure, we could check all the locks in the house, but it is an overkill.</p>

<p>I am ok with making mistakes and paying for them. But this time, we paid for the host’s errors and Airbnb’s as a company.</p>

<ul>
  <li><strong>Host</strong>: the house was not ready for hosting the guests.</li>
  <li><strong>Airbnb</strong>: limitations of the onboarding policy. I believe there is a list of things that the house owner needs to mark to become a host, and either functioning window locks are not on the list, or it is not enforced.</li>
</ul>

<p>After we told the host about our discovery, she sent a person to lock all the windows completely. From now on, no one would be able to open them from inside or outside.</p>



<p>I wanted to reach out to Airbnb, tell them about the situation, and ask about the next steps.</p>

<p>Safety comes first. Hence I assumed that even if you are under stress and your brain is not functioning well, it is obvious how to contact the support team.</p>

<p>To my surprise, it is not the case.</p>

<p>I spent some time on the Airbnb website but could not figure out which phone number I should call.</p>

<p><strong>Message to AirBnb</strong>: It would be great if you simplify the design of the support page. When we talk about safety, it should be about efficiency and not about the visual appeal or cuteness level.</p>

<p>I would like it to be:</p>

<ul>
  <li>I open the Airbnb website =&gt; I see an obvious button/link to the support page.</li>
  <li>I open the support page =&gt; I see an obvious button/link to the hotline phone number.</li>
</ul>

<p>I posted the tweet about the incident and tagged Airbnb and Las Vegas police in it.</p>

<blockquote>— Vladimir Iglovikov (@viglovikov) <a href="https://twitter.com/viglovikov/status/1330741490759266304?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>


<p>A miracle happened. Airbnb contacted me and asked for my email to identify the account and to get more details.</p>

<p>My guess is that the Marketing team at Airbnb has alarms that trigger when someone mentions the company on social media.</p>

<p>Finally, after two hours, we got into the conversation about the incident, but the path to get there was not obvious at all.</p>

<p>Imagine how many people got into trouble in similar situations and did not leverage this communication channel?</p>

<p>I got an email:</p>

<blockquote>
  <p>My name is XXX, from the Airbnb claims team.</p>

  <p>I am contacting you regarding the incident that occurred during your reservation with YYY.</p>

  <p>As my colleague informed you in the previous email, we are only able to offer up to $500 for any stolen property. In order to proceed with this refund, I will need the following:</p>

  <p>*Original purchase invoice for the stolen items.</p>

  <p>This is requested as “proof of ownership”, if you don’t have the original purchase invoice, a picture of you where the item can be seen will also be accepted as proof of ownership.</p>
</blockquote>

<p>All this story is not about money. But getting compensated for the host’s and Airbnb’s mistake with cash or AirBnB credits would be nice. It does not address the issue with window locks but sweetens the situation.</p>

<p>We interpreted the email as: “We will compensate up to $500 per stolen item”. Using the numbers from the invoices, it summed to $2600.</p>

<p>We collected invoices, sent them to Airbnb, and got the reply with words: “After additional review, I’m happy to report that we have just released a payout in the amount of $500 to your Airbnb account. You can confirm in your Airbnb Transaction History.”</p>

<p>The guess about up to $500 per item was overly optimistic.</p>

<p>After the end of the stay, I got a message from the host:</p>

<blockquote>
  <p>Hi Vladimir,</p>

  <p>Thank you again for choosing our home for your vacation stay.</p>

  <p>I hope the home met (and even surpassed) your expectations. It was a sincere pleasure hosting you, and I really hope to host you again in the near future. I would be truly grateful for a 5 star review of your stay when you have a spare moment and I would definitely do the same for you.</p>

  <p>Also, please in the private comments if there is something, the home or myself can approve of please let me know.</p>
</blockquote>

<p>I understand that this is a standard template, but under the circumstances, it sounds strange and
does not fit the story and overall experience.</p>

<p>I did not plan to share the actual address of the property. The harm to the renting business could be material. But after this text, I changed my mind. It does not look like the host plans to revise the house and look for things that can and should be fixed. For example, the front door lock is barely working. The door could be open with a good push.</p>



<p>We had a great vacation. The weather was good, and the red rocks are remarkable. We had a lot of fun and plan to come back sometime soon.</p>

<p>Work laptops were replaced. We accepted the loss of personal items.</p>

<p>The Airbnb experience was not as smooth as we expected. Our things got stolen, and even on the other days, we did not feel comfortable leaving belongings in the house.</p>

<p>The host was responsive, but it is not enough. Communicating with guests and collecting money should not be the only responsibility. It is worth inspecting the house and fixing things that do not work as expected proactively, without waiting till the universe gives you feedback.</p>

<p>Overall, I believe that staying at AirBnB is safe, and such incidents are the exception rather than the rule, but, for sure, Airbnb has some work to do to improve communication and increase the guests’ safety. The compensation of $500 for all the stolen items does not look fair either.</p>

<p>I would like to end the story with some action items like: “<strong>Next time, when I rent a place, I will do XXX</strong>.” Nothing reasonable comes to my mind.</p>

<p>When I sit in front of the computer in San Francisco, the only thing that comes to my mind is to build a Face Recognition system and check the burglar’s face in it. Something similar to Clearview. Machine Learning is my expertise; creating such a system is straightforward but will take some time. Tempting. Thinking about it.</p>

<p>What would be your action item after such an experience?</p>

        
      </section></div>]]>
            </description>
            <link>https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321770</guid>
            <pubDate>Sun, 06 Dec 2020 07:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons for Early Stage Founders]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25321667">thread link</a>) | @sarathyweb
<br/>
December 5, 2020 | https://calv.info/early-stage-lessons | <a href="https://web.archive.org/web/*/https://calv.info/early-stage-lessons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In Segmentâ€™s early days, we hit countless problems as a founding team. And at the time, I thought those problems were unique to our own special snowflake of a founding journey. I chalked it up to us being new grads and first-time founders.</p><p>But as I've worked with more and more startups, I've realized just how wrong I was.</p><p>Over the past five years, I've made about 25 different seed-stage investments. In doing so, it's taught me a <em>LOT</em> about the common errors that startup founders make. Even across different industries and levels of experience, I see founders hitting the exact same set of problems we encountered in the early days of Segment!</p><p>This post shares a handful of the top lessons that benefit todayâ€™s early stage founders. Itâ€™s a list of the things I wish weâ€™d figured out earlier at Segment. [1]</p><p>This sounds incredibly boring... but the #1 mistake I see startups making is that they donâ€™t set goals. If you take one thing from this post, it's that you should set goals for where you want to be.</p><p>For the longest time at Segment, we didn't have goals. We moved ahead in various (often random) directions, and we would launch features consistently... but we never really set goals at all.</p><p>As we grew the company, we started to lose momentum. Teams were spending time on a bunch of stuff that frankly just didn't really matter to the overall business.</p><p>It wasn't until we hired our VP Eng, Tido, that we finally started setting focused and audacious product goals. Just by verbalizing where we wanted to go and then grading our results, our velocity improved by an order of magnitude.</p><p>I don't care if you call them OKRs, sprints, or something else entirely. Just set a deadline when you want to have something done and a metric you want to move or some other concrete result.</p><p>When early stage founders do attempt to set goals, I often see them agonize over what specific goals to choose. In practice, a "pretty good goal" is way better than "no goals at all". Perfect is the enemy of good.</p><p>If you don't yet have product-market fit, your goal should probably be getting your first 3-5 customers using the product. If you've hit the level where you now have dozens of users, your goal should be growing by an order of magnitude. It's better to get in the habit of setting and driving towards goals rather than being too worried about their exact semantics. Worst case, you just pick a better goal later.</p><p>A great set of goals answers the question: <em><strong>"what would have to be true in order for us to feel good about our progress at the end of the month?"</strong></em><em> [2]</em></p><p>If each teammate can independently answer "what are our goals for the month?" in the same way, you'll know you've succeeded. If youâ€™re looking for prior art, read <a href="https://www.amazon.com/Measure-What-Matters-Google-Foundation/dp/0525536221">Measure What Matters</a>. </p><p>If you strictly focus on making things true by a certain date, you are bound to make at least some progress towards your end result. </p><p>At the end of the day, every billion-dollar startup is really just the sum of many small deltas.</p><p>Let's get one thing straight: your investors won't know everything. But investors won't know <em>anything</em> if you don't keep them updated on how things are going.</p><p>For the longest time, we were fearful of our Segment investors, to the point that we wouldn't bother sending them emails unless they asked about us. I can say now with confidence that this was 100% the wrong approach.</p><p>We worried that investors would think that we were screwing up (true) and failing (true as well!). And while that might be the case, a founder-friendly investor won't think that way. Investors, especially angels, invested because they believe in <em>you</em>. If I didn't think a team would go somewhere, I wouldn't put money in.</p><p>With each investor, <strong>include the goals you're working towards, as well as the asks for them</strong>. I think monthly is about the right cadence for this in the early days, moving to quarterly around Series A/B time when you start partnering more with a few board members.</p><p>Simply writing the updates should clarify your own thinking tremendously. If it takes you more than 1-2h to put together an update on the most important things happening at the company, it's probably a sign that you should be doing more thinking about the big picture.</p><p>When asking for help, the things that our investors have been able to help us with evolved quite a bit over time. But here's a good rule of thumb for what to ask for:</p><ul><li><p><u>Seed/Pre-seed</u>: user-testing, intros to beta users, hiring</p></li><li><p><u>Series A</u>: hiring, early customers, go-to-market</p></li><li><p><u>Series B/C+</u>: comparables at other companies, senior/exec hires, specific expertise around things like management, infrastructure, systems, etc.</p></li></ul><p>Not all investors will be able to help with everything. But at the very least, sending them information will help you be top of mind. I've lost track of how many times a moment of serendipity where I'm catching up with an old friend has led to a meaningful conversation for a company I've invested in.</p><p>As an extra bonus, the strongest startups send these updates to everyone on their team. It's amazing how much putting the goals in writing helps everyone stay on the same page about what's most important.</p><p>One other note here: take pictures. I now wish we had far more pictures of Segment at every stage of the company. They help turn investor updates into cherished memories.</p><p>Okay, this lesson is taken directly from the YC playbook. And YET, I see so many founders (including YC founders) fail to launch their product. </p><p>If no one notices your launch... just ignore it and then launch again. If you're doing things right, you'll never run out of stuff to launch! [3]</p><p>Why is launching so important? Let me share a personal story...</p><p>We spent about 1.5 years building different iterations of analytics tools. For every iteration, we had a waitlist that users could sign up to use. We personally reached out to the users who we thought were the best fits, and then tried to set up time to use the product. </p><p>The result? Nobody cared. We had no users. We never launched. </p><p>When we finally launched Segment in it's current incarnation, we threw out that approach entirely. We put up a self-service flow, and let anyone who wanted to sign up for it.</p><p>That's when something strange happened... we attracted an entirely new set of developers who just were crawling out of the woodwork and excited to use the new product we'd built. They were coming from companies far outside of SV that we'd never heard of.</p><p>It floored me.</p><p><strong>Lesson learned: the people you happen to be talking to now are probably not the people who have the biggest problem in your space. Do everything you can to reach the folks with the biggest problem, and then, reduce any barriers they might encounter.</strong></p><p>I expect a bunch of you reading this post to ignore this advice, just like we did in the early days. It takes a certain confidence to launch something you've built and put it out there for the world to see. Ultimately though, the rewards are worth it. You'll see users coming from communities you've never even heard of.</p><p>Let me tell you a tale of two startups.</p><p><strong>Startup A</strong> is constantly putting up interesting content on their blog. Their founders are sharing product launches, engineering posts, and creatively brainstorming about what it takes to solve problems in their market.</p><p><strong>Startup B</strong> is operating in stealth. You can't find much about them online, but one of the founders reached out with a nice personalized email mentioning their funding by a top-tier VC. </p><p>Suppose you're looking for a job... do you pick Startup A or Startup B? In my experience, A almost always wins. Momentum is a compounding force.</p><p><strong>Unless you are working in a space that heavily depends on IP, you should probably be publishing more content about what you are doing.</strong> This could be open source, it could be a weekly newsletter, it could be a changelog. [4]</p><p>Whatever it is, it's going to help you both hire <em>and</em> attract customers. So much of the internet is merely about consuming, that just by putting ideas out there, youâ€™ll have a leg up on the competition.</p><p>In the early days of Segment, our <a href="https://segment.com/blog/show-hn-to-series-d/">user acquisition was powered by open source projects and blog posts</a>. But I've seen founders have success with Twitter, Substacks, Podcasts and a variety of different channels.</p><p>If you're looking for inspiration, the <a href="https://railway.app/changelog">Railway</a> and <a href="https://linear.app/changelog">Linear</a> changelogs are epic examples. Companies like <a href="https://baremetrics.com/blog/i-sold-baremetrics">Baremetrics</a> and <a href="https://buffer.com/resources/shareholder-update-q2-2020-and-july/">Buffer</a> differentiated themselves by just being open and honest. <a href="https://stripe.com/blog/globe">Stripe</a> and <a href="https://www.figma.com/blog/behind-the-feature-the-making-of-the-new-auto-layout/">Figma's blogs</a> not only share what they build, but how they built it.</p><p>There are three big inputs that all startups need to continue growing</p><ol><li><p>product capabilities</p></li><li><p>customers and users</p></li><li><p>hiring</p></li></ol><p>I've put them in roughly the order that most teams encounter them. </p><p>Startups begin with a small product that has a modicum of utility. It starts attracting a handful of customers organically. And as more and more customers start using the product, the founders realize that they need extra help to stay on top of all of those requests.</p><p>Remember though, the real goal here is #2. Itâ€™s not the size of your team, itâ€™s the value youâ€™re able to provide to the world. [5]</p><p>I see hiring a big team before you have product-market fit as a red flag. If the company doesn't yet have a set direction, it's going to be harder to pivot with 10 people than it is with 3.</p><p>But, I've worked with startups who have traction and runway... and just seem to be spinning their wheels under load from existing customers.</p><p>I get it. Hiring isn't the most fun, especially for an introvert. It's a lot of interviewing and feeling like there's a lot of rejection. Rejecting people sucks. Losing candidates sucks. For many of our roles at Segment, we've had to talk with 50-100 different people to make an eventual hire.</p><p><strong>If you have 24 months of runway, and a clear list of things youâ€™d do if you had more copies of yourself: you probably aren't spending time to hire the people you need.</strong></p><p>At Segment, my co-founder <a href="https://twitter.com/ivolo">Ilya</a> fulfilled this role. It was back in 2014, we were 12 people at the time, had raised a $10m Series A, and had $1m in revenue.</p><p>Thing…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calv.info/early-stage-lessons">https://calv.info/early-stage-lessons</a></em></p>]]>
            </description>
            <link>https://calv.info/early-stage-lessons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321667</guid>
            <pubDate>Sun, 06 Dec 2020 06:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic segmentation algorithms do not generalize to off-road datasets]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25321540">thread link</a>) | @srik901
<br/>
December 5, 2020 | https://unmannedlab.github.io/research/RELLIS-3D | <a href="https://web.archive.org/web/*/https://unmannedlab.github.io/research/RELLIS-3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
<a href="https://www.tamu.edu/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/tamu_logo.png" alt="Texas A&amp;M University" height="90px" width="450px"></a>    <a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="CCDC Army Research Laboratory" height="90px" width="270px"></a></p>
<p>
Peng Jiang<sup>1</sup>, Philip Osteen<sup>2</sup>, Maggie Wigness<sup>2</sup> and Srikanth Saripalli<sup>1</sup><br>
1. <a href="https://www.tamu.edu/">Texas A&amp;M University; </a> 2. <a href="https://www.arl.army.mil/">CCDC Army Research Laboratory</a><br>
<a href="https://unmannedlab.github.io/research/RELLIS-3D">[Website]</a> <a href="https://arxiv.org/abs/2011.12954">[Paper]</a> <a href="https://github.com/unmannedlab/RELLIS-3D">[Github]</a> 
</p>
<h2 id="overview">Overview</h2>
<p>Semantic scene understanding is crucial for robust and safe autonomous navigation, particularly so in off-road environments. Recent deep learning advances for 3D semantic segmentation rely heavily on large sets of training data; however, existing autonomy datasets represent urban environments or lack multimodal off-road data. We fill this gap with RELLIS-3D, a multimodal dataset collected in an off-road environment containing annotations for <strong>13,556 LiDAR scans</strong> and <strong>6,235 images</strong>. The data was collected on the Rellis Campus of Texas A\&amp;M University and presents challenges to existing algorithms related to class imbalance and environmental topography. Additionally, we evaluate the current state of the art deep learning semantic segmentation models on this dataset. Experimental results show that RELLIS-3D presents challenges for algorithms designed for segmentation in urban environments. Except for the annotated data, the dataset also provides full-stack sensor data in ROS bag format, including <strong>RGB camera images</strong>, <strong>LiDAR point clouds</strong>, <strong>a pair of stereo images</strong>, <strong>high-precision GPS measurement</strong>, and <strong>IMU data</strong>. This novel dataset provides the resources needed by researchers to develop more advanced algorithms and investigate new research directions to enhance autonomous navigation in off-road environments.</p>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/data_example.png">
</p>
<h3 id="recording-platform">Recording Platform</h3>
<ul>
  <li><a href="https://clearpathrobotics.com/warthog-unmanned-ground-vehicle-robot/">Clearpath Robobtics Warthog</a></li>
</ul>

<h3 id="sensor-setup">Sensor Setup</h3>
<ul>
  <li>64 channels Lidar: <a href="https://ouster.com/products/os1-lidar-sensor">Ouster OS1</a></li>
  <li>32 Channels Lidar: <a href="https://velodynelidar.com/vlp-32c.html">Velodyne Ultra Puck</a></li>
  <li>3D Stereo Camera: <a href="https://nerian.com/products/karmin2-3d-stereo-camera/">Nerian Karmin2</a> + <a href="https://nerian.com/products/scenescan-stereo-vision/">Nerian SceneScan</a></li>
  <li>RGB Camera: <a href="https://www.baslerweb.com/en/products/cameras/area-scan-cameras/ace/aca1920-50gc/">Basler acA1920-50gc</a> + <a href="https://www.edmundoptics.com/p/16mm-focal-length-hp-series-fixed-focal-length-lens/28990/">Edmund Optics 16mm/F1.8 86-571</a></li>
  <li>Inertial Navigation System (GPS/IMU): <a href="https://www.vectornav.com/products/vn-300">Vectornav VN-300 Dual Antenna GNSS/INS</a></li>
</ul>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/sensor_setup.png">
</p>
<h2 id="annotated-data">Annotated Data:</h2>
<h3 id="ontology">Ontology:</h3>
<p>With the goal of providing multi-modal data to enhance autonomous off-road navigation, we defined an ontology of object and terrain classes, which largely derives from <a href="http://rugd.vision/">the RUGD dataset</a> but also includes unique terrain and object classes not present in RUGD. Specifically, sequences from this dataset includes classes such as mud, man-made barriers, and rubble piles. Additionally, this dataset provides a finer-grained class structure for water sources, i.e., puddle and deep water, as these two classes present different traversability scenarios for most robotic platforms. Overall, 20 classes (including void class) are present in the data.</p>

<p><strong>Ontology Definition</strong> (<a href="https://drive.google.com/file/d/1K8Zf0ju_xI5lnx3NTDLJpVTs59wmGPI6/view?usp=sharing">Download 18KB</a>)</p>

<h3 id="images-statics">Images Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/img_dist.png">
</p>
<h3 id="image-download">Image Download:</h3>

<p><strong>Image with Annotation Examples</strong> (<a href="https://drive.google.com/file/d/1wIig-LCie571DnK72p2zNAYYWeclEz1D/view?usp=sharing">Download 3MB</a>)</p>

<p><strong>Full Images</strong> (<a href="https://drive.google.com/file/d/1F3Leu0H_m6aPVpZITragfreO_SGtL2yV/view?usp=sharing">Download 11GB</a>)</p>

<p><strong>Full Image Annotations</strong> (<a href="https://drive.google.com/file/d/16URBUQn_VOGvUqfms-0I8HHKMtjPHsu5/view?usp=sharing">Download 94MB</a>)</p>

<p><strong>Image Split File</strong> (<a href="https://drive.google.com/file/d/1zHmnVaItcYJAWat3Yti1W_5Nfux194WQ/view?usp=sharing">44KB</a>)</p>

<h3 id="lidar-scans-statics">LiDAR Scans Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/pt_dist.png">
</p>

<h3 id="lidar-download">LiDAR Download:</h3>

<ul>
  <li>
    <p>LiDAR with Annotation Examples (<a href="https://drive.google.com/file/d/1QikPnpmxneyCuwefr6m50fBOSB2ny4LC/view?usp=sharing">Download 24MB</a>)</p>
  </li>
  <li>
    <p>LiDAR with Color Annotation PLY Format (<a href="https://drive.google.com/file/d/1BZWrPOeLhbVItdN0xhzolfsABr6ymsRr/view?usp=sharing">Download 26GB</a>)</p>
  </li>
  <li>
    <p>LiDAR SemanticKITTI Format (<a href="https://drive.google.com/file/d/1lDSVRf_kZrD0zHHMsKJ0V1GN9QATR4wH/view?usp=sharing">Download 14GB</a>)</p>
  </li>
  <li>
    <p>LiDAR Annotation SemanticKITTI Format (<a href="https://drive.google.com/file/d/1LUmmO2imJ4m5uCtGv1FYusCo-bEPDbBx/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Scan Poses files (<a href="https://drive.google.com/file/d/1cyVqJEnlzO9ANOP7hU8GJk28ckPDUSGv/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Split File (<a href="https://drive.google.com/file/d/1raQJPySyqDaHpc53KPnJVl3Bln6HlcVS/view?usp=sharing">75KB</a>)</p>
  </li>
</ul>

<h3 id="calibration-download">Calibration Download:</h3>
<ul>
  <li>
    <p>Camera Instrinsic (<a href="https://drive.google.com/file/d/1NAigZTJYocRSOTfgFBddZYnDsI_CSpwK/view?usp=sharing">Download 2KB</a>)</p>
  </li>
  <li>
    <p>Camera to LiDAR (<a href="https://drive.google.com/file/d/1Xra1E8Bc4l5VwjjNm7o41nDFO29nmx-u/view?usp=sharing">Download 3KB</a>)</p>
  </li>
</ul>

<h2 id="benchmarks">Benchmarks</h2>

<h3 id="image-semantic-segmenation">Image Semantic Segmenation</h3>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vr3g6lCTKRM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h3 id="lidar-semantic-segmenation">LiDAR Semantic Segmenation</h3>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/wkm8UiVNGao" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2 id="ros-bag-raw-data">ROS Bag Raw Data</h2>

<p>Data included in raw ROS bagfiles:</p>

<table>
  <thead>
    <tr>
      <th>Topic Name</th>
      <th>Message Tpye</th>
      <th>Message Descriptison</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>/img_node/intensity_image</td>
      <td>sensor_msgs/Image</td>
      <td>Intensity image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/noise_image</td>
      <td>sensor_msgs/Image</td>
      <td>Noise image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/range_image</td>
      <td>sensor_msgs/Image</td>
      <td>Range image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/imu/data</td>
      <td>sensor_msgs/Imu</td>
      <td>Filtered imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/data_raw</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/nerian_stereo/left_image</td>
      <td>sensor_msgs/Image</td>
      <td>Left image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/nerian_stereo/right_image</td>
      <td>sensor_msgs/Image</td>
      <td>Right image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/odometry/filtered</td>
      <td>nav_msgs/Odometry</td>
      <td>A filtered local-ization estimate based on wheel odometry (en-coders) and integrated IMU from Warthog</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/imu</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>Point cloud data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/imu_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw imu data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/lidar_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw lidar data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/vectornav/GPS</td>
      <td>sensor_msgs/NavSatFix</td>
      <td>INS data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/IMU</td>
      <td>sensor_msgs/Imu</td>
      <td>Imu data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Odom</td>
      <td>nav_msgs/Odometry</td>
      <td>Odometry from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Pres</td>
      <td>sensor_msgs/FluidPressure</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/vectornav/Temp</td>
      <td>sensor_msgs/Temperature</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/velodyne_points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>PointCloud produced by the Velodyne Lidar</td>
    </tr>
  </tbody>
</table>

<h3 id="ros-bag-download">ROS Bag Download</h3>

<p><strong>ROS Bag Examples</strong> (<a href="https://drive.google.com/file/d/163pEtjMhcM1OJo36ZOi6_zDHpuPSL8us/view?usp=sharing">2GB</a>)</p>

<p><strong>Sequence 00000</strong>: Synced data: (<a href="https://drive.google.com/file/d/10dHPMCschg1dMeb_Y6pcPvC-HZQZ8_ek/view?usp=sharing">12GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1d-t4P1idWkfxDEkodBrsbd4B2nAc8rZ3/view?usp=sharing">23GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1IZ-Tn_kzkp82mNbOL_4sNAniunD7tsYU?usp=sharing">29GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qc7IepWGKr8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00001</strong>: Synced data: (<a href="https://drive.google.com/file/d/1I98lEog0xFFAVVZ_AEBvXzIEcFQ2bGRl/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1LogHRN1ElE2xryILMPU3OtnV6VCnjs52/view?usp=sharing">16GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1hf-vF5zyTKcCLqIiddIGdemzKT742T1t?usp=sharing">22GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nO5JADjDWQ0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00002</strong>: Synced data: (<a href="https://drive.google.com/file/d/1yhohyWOIIf00YLUZ1RT7ouq3B-iaOU91/view?usp=sharing">14GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1F_8yviLHcAVmBpWEyCITFd1nRgPRmkVX/view?usp=sharing">28GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1R8jP5Qo7Z6uKPoG9XUvFCStwJu6rtliu?usp=sharing">37GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aXaOmzjHmNE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00003</strong>:Synced data: (<a href="https://drive.google.com/file/d/1poY5eaKKhmjUQpF1rsoL4mm4wO7T8CJM/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1HDbtqaYhfeyLoq9UsxOhgCJl2urGVKUc/view?usp=sharing">15GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1iP0k6dbmPdAH9kkxs6ugi6-JbrkGhm5o?usp=sharing">19GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Kjo3tGDSbtU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00004</strong>:Synced data: (<a href="https://drive.google.com/file/d/1xLvai6rorpjxRZXraZK7qPsA1vYMkTHJ/view?usp=sharing">7GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1usxAjxHrw89R6rMA0GtmYQRtzIP-QGJF/view?usp=sharing">14GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1WV9pecF2beESyM7N29W-nhi-JaoKvEqc?usp=sharing">17GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/lLLYTI4TCD4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h2 id="full-data-download">Full Data Download:</h2>
<p><a href="https://drive.google.com/drive/folders/1aZ1tJ3YYcWuL3oWKnrTIC5gq46zx1bMc?usp=sharing">Access Link</a></p>

<h2 id="citation">Citation</h2>
<div><div><pre><code>@misc{jiang2020rellis3d,
      title={RELLIS-3D Dataset: Data, Benchmarks and Analysis}, 
      author={Peng Jiang and Philip Osteen and Maggie Wigness and Srikanth Saripalli},
      year={2020},
      eprint={2011.12954},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre></div></div>

<h2 id="collaborator">Collaborator</h2>
<p><a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="The DEVCOM Army Research Laboratory"></a></p>

<h2 id="license">License</h2>
<p>All datasets and code on this page are copyright by us and published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License.</p>



<p><a href="https://unmannedlab.github.io/research/SemanticUSL">SemanticUSL: A Dataset for Semantic Segmentation Domain Adatpation</a></p>

<p><a href="https://unmannedlab.github.io/research/LiDARNet">LiDARNet: A Boundary-Aware Domain Adaptation Model for Lidar Point Cloud Semantic Segmentation</a></p>

  </article></div>]]>
            </description>
            <link>https://unmannedlab.github.io/research/RELLIS-3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321540</guid>
            <pubDate>Sun, 06 Dec 2020 06:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Brown University know where you are?]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25319392">thread link</a>) | @jswrenn
<br/>
December 5, 2020 | https://jack.wrenn.fyi/blog/brown-location-surveillance | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/brown-location-surveillance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In September 2020, Brown University <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">accused students</a> of lying about their location; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/notice.png" height="auto" width="100%" alt="The University has learned that between September 14, 2020 and September 21, 2020 you were allegedly in the Providence area during which time your location of study was listed as remote. This alleged behavior is a violation of the Student Code of Conduct and the COVID-19 Campus Safety Policy. A copy of the Student Commitment to COVID-19 Community Health and Safety Requirements is attached for your review, along with this link to the COVID-19 Campus Safety Policy. failure to abide by these requirements is a violation of the Code of Student Conduct. 
Based on the details of the incident and your student conduct history, the Office of Student Conduct &amp; Community Standards has decided to allow you the opportunity to accept responsibility for the following prohibited conduct without having a COVID-19 Dean's Review Meeting:
• D.8 Failure to Comply
• D.13 Misrepresentation
"></p>
<p><strong>What was Brown's basis for these accusations?</strong></p>
<p>In an <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">interview with The Brown Daily Herald</a>, University Spokesperson Brian Clark said the University evaluated a variety of indicators, including:</p>
<ol>
<li>indications of building access,</li>
<li>indications of accessing private electronic services,</li>
<li>indications of accessing secure networks, and</li>
<li>reports from community members.</li>
</ol>
<p>The mechanics of that last indicator are pretty self-explanatory, but what about the others? <a href="https://it.brown.edu/services/type/canvas-learning-management-system">Canvas</a> <em>doesn't</em> <a href="https://knowyourmeme.com/memes/google-wants-to-know-your-location">Want To Know Your Location</a>. <strong>In this post, I'm going to break down the technical mechanisms behind each of these indicators.</strong></p>
<p>For the most part, I do not have insider knowledge on how Brown reached its decisions. Rather, I'm going to consider each of the indicators Brian Clark named, and describe the technical mechanisms to which Brown <em>could</em> have availed itself to generating location data.</p>
<h2 id="indications-of-building-access">Indications of Building Access</h2>
<p>This is an easy one. Brown's buildings are located on Brown's campus. Brown's campus is in Providence. If you are in Brown's buildings, you are on Brown's campus, in Providence. QED.</p>
<p>At Brown, building access is primarily regulated with electronic control systems (namely Software House's <a href="https://www.swhouse.com/products/software_CCURE9000.aspx"><strong>C•CURE 9000</strong></a> system), not mechanical keys.</p>
<p>Encoded on <a href="https://en.wikipedia.org/wiki/Magnetic_stripe_card#Track_2">track 2</a> of the magnetic stripe on every University ID card is a sixteen digit number that uniquely identifies the card:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-back.jpg" height="auto" width="100%" alt="Image of back of Brown ID card. A tall magnetic stripe runs across the entire width of the card."></p>
<p>Well, that's underwhelming — of <em>course</em> you can't <em>see</em> it! However, up until 2017 or 2018, this number was also <em>printed</em> on the front of ID cards, just above the card-holder's name:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-front.jpg" height="auto" width="100%" alt="Image fo the front of a Brown ID card, displaying the building access code: 6009553660926201"></p>
<p>This pseudo-random identifier (well, its last ten digits) are what uniquely identify you whenever you swipe your Brown ID card <em>anywhere</em>. And, if you lose your Brown ID card, this is the <em>only</em> thing that's changed when you're issued a replacement. Convenient! In contrast, when you lose your dorm room's mechanical key, Brown must replace (or rather, <a href="https://en.wikipedia.org/wiki/Rekeying">rekey</a>) the locks.</p>
<p>But, <em>also</em> unlike a mechanical key, <em>every</em> swipe of a Brown ID card is logged in a central database. <strong>The C•CURE 9000 lets administrators view the complete historical building access history of a person.</strong> Last Spring, Brown used this mechanism to identify and prod students who were slow to evacuate Providence.</p>
<h2 id="indicators-from-electronic-services">Indicators from Electronic Services</h2>
<p>University web services like Canvas <em>don't</em> directly ask you for your location. Nonetheless, accessing these services leaves a location finger print: your IP address.</p>
<p>Your <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> is a number that identifies your device (computer, phone, etc.) for the purposes of network routing. In principle, nobody but you and your internet provider know the <em>exact</em> mapping of your IP address to your physical address.</p>
<p>In practice, IP addresses can be used to <em>roughly</em> geolocate a device. Batches of IP addresses are associated <em>loosely</em> with geographic areas. Since every web service access leaves an IP address as a trace, there are tremendous incentives for advertisers to be able accurately identify what city or town an IP address is probably associated with.</p>
<p>Brown probably <em>isn't</em> analyzing the access logs of its <em>individual</em> web services (like Canvas). Rather, they need only to audit the access logs of its three identity access management (IAM) systems:</p>
<ul>
<li>The <a href="https://workspace.google.com/">Google Workplace</a> IAM system is used to control access to your @brown.edu email, and to the various Google Drive services. <a href="https://support.google.com/a/answer/4580120?hl=en"><strong>Google Workplace</strong> provides administrators with login audit logs that include users' IP addresses.</a></li>
<li>The <a href="https://www.shibboleth.net/">Shibboleth</a> IAM system controls access to all <em>other</em> Brown web services, such as Canvas. It's what you think of as your "Brown account". Shibboleth is <em>very</em> flexible, and can be <a href="https://wiki.shibboleth.net/confluence/display/IDP30/AuditLoggingConfiguration#AuditLoggingConfiguration-GenericFields">configured to log IP addresses</a>.</li>
<li><a href="https://duo.com/">DUO</a> is used to provide two-factor authentication for Shibboleth logins. <a href="https://help.duo.com/s/article/1023?language=en_US#docs-internal-guid-0aa3b4ce-c686-7559-8814-1377592fce4a:%7E:text=Access%20Device">It too provides administrators with detailed access logs</a>.</li>
</ul>
<p>You can partly view your Google Workplace login history for yourself by opening your Brown email and clicking "Details" in the bottom right-hand corner of the page; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/gmail-account-activity.png" height="auto" width="100%"></p>
<p>With <em>either</em> of these access logs in hand, Brown could then turn to any number of geolocation services (<a href="https://tools.keycdn.com/geo">like this one</a>) to guess your physical location.</p>
<h2 id="indicators-from-secure-networks">Indicators from Secure Networks</h2>
<p>This is another easy one. Brown's WiFI network <a href="https://jack.wrenn.fyi/blog/blog/brown-location-surveillance/Campus_Wireless_Coverage_Map_24x36_1.pdf">blankets Brown's campus</a>. Brown's campus is in Providence. If you are on Brown's WiFi network, you are on Brown's campus. QED.</p>
<p>What might surprise you is the sheer depth of surveillance that's capable with WiFi alone. This section will <em>barely</em> scratch the surface.</p>
<h3 id="identification">Identification</h3>
<p>Brown's WiFi routers each broadcast three <a href="https://en.wikipedia.org/wiki/Service_set_(802.11_network)">service sets</a>:</p>
<ol>
<li><a href="https://it.brown.edu/services/type/wireless-network-brown">Brown</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-network-eduroam">eduroam</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-access-brown-guest">Brown Guest</a></li>
</ol>
<p>The Brown and eduroam networks require that you authenticate with your Brown account credentials. Brown University is thus able to identify the owner of any device connected to these networks.</p>
<p>While Brown Guest does <em>not</em> require authentication, it still provides mechanisms of identification. Your network devices broadcast a unique identifier called a <a href="https://en.wikipedia.org/wiki/MAC_address"><strong>MAC address</strong></a>.</p>
<p><a href="https://drawings.jvns.ca/mac-address/"><img type="image/svg+xml" src="https://drawings.jvns.ca/drawings/mac-address.svg" height="auto" width="100%" alt="Comic by Julia Evans. Text: Every computer on the internet has a network card. When you make HTTP requests with Ethernet/WiFi, every packet gets sent to a MAC address. (&quot;Wait, how do I know someone else on the same network isn't reading all my packets?&quot; &quot;You don't! That's one reason we use HTTPS &amp; secure WiFi networks.&quot;) Your router has a table that maps IP addresses to MAC addresses.  (Read about ARP for more.)
"></a></p>
<p>Brown <a href="https://it.brown.edu/computing-policies/network-connection-policy#32:%7E:text=CIS%20maintains%20a%20database%20of%20unique,a%20computer%20when%20it%20is%20necessary.">maintains databases of the MAC addresses of all connected devices</a>.</p>
<p>If you have ever connected to an authenticated network, Brown will be able to de-anonymize your connections to Brown Guest — <em>unless</em> your device implements <a href="https://en.wikipedia.org/wiki/MAC_address#Randomization">MAC address randomization</a>, which (as the name suggests) randomizes your device's MAC address on a per-network basis.</p>
<h3 id="localization">Localization</h3>
<p>Brown's access points log the MAC addresses of the devices that have connected to them. As of 2015, Brown retained these logs for at least several years — possibly indefinitely. Since there are so many access points on campus, which access point you are connected to can narrow your location down to a particular room. <strong>Combined, these logs paint a <em>very</em> accurate picture of your location on campus at any time.</strong></p>
<p>You do not need to be <em>actively</em> browsing the internet for Brown to know where you are via this mechanism. As you walk through campus, your phone likely <em>automatically</em> reconnects to the nearest available access point. If you are within a literal stone's throw of campus, you should assume that Brown can (roughly) identify your location.</p>
<p>Furthermore, if you are in range of three or more of Brown's ARUBA access points, Brown can, in principle, precisely triangulate your location. This functionality is <a href="https://www.arubanetworks.com/pdf/technology/whitepapers/wp_Hybrid_WIDS.pdf">common</a> in enterprise-grade WiFi infrastructure. (If you've ever tried to run a "rogue" WiFi router in your dorm room and receive an angry knock on your door — this is the mechanism by which you were located.)</p>
<h2 id="how-do-i-find-out-more">How do I find out more?</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act"><em>Family Educational Rights and Privacy Act</em></a> empowers students to request their education records from their University.</p>
<p><iframe src="https://www.youtube.com/embed/jWzBrC8dVnw" frameborder="0" allowfullscreen=""></iframe></p>
<p>If you are a current Brown student and would like to go beyond my blog post and learn <em>exactly</em> how Brown University knows your location, <a href="https://www.brown.edu/about/administration/registrar/student-information-rightsferpa">file a FERPA request</a>. Brown University is obligated to respond within 45 days. You'll need to be specific with your request. I suggest requesting:</p>
<ul>
<li>the timestamps, MAC addresses and BSSIDs associated with your devices' connections to Brown University's wireless access points</li>
<li>the timestamps and locations associated with all building accesses conducted with your ID card</li>
<li>the login audit data associated with all Google Workplace, Shibboleth, and DUO authentications conducted by your accounts</li>
</ul>
<p>Additionally, the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation"><em>General Data Protection Regulation</em></a> gives EU citizens and residents expansive control over how their personally identifiable information (PII) is used, and the right to request a copy of or the destruction of collected data. I believe these requests should be directed to <a href="https://compliance.brown.edu/">Brown's compliance office</a>. You might be able to do this even if you're a Brown alumni.</p>
<p><strong>If you attempt either of these steps, <a href="mailto:jack@wrenn.fyi">please get in touch</a>!</strong> I'm very curious as to what Brown is <em>actually</em> doing.</p>
<h2 id="bonus-surveillance-cameras">Bonus: Surveillance Cameras</h2>
<p>As of February 2020, <a href="https://www.browndailyherald.com/2020/02/21/cameras-installed-hegeman-hall/#post-2838338:%7E:text=The%20University%20uses%20approximately%20800%20cameras,with%20high%20crime%20activity%2C%20Porter%20said."><em>eight hundred</em> surveillance cameras monitor campus 24/7</a>. Brown has as about as many surveillance cameras as it has full-time faculty! This map documents a <em>mere seven percent</em> of Brown University's total camera surveillance capacity:</p>

<p><small>This map displays data from <a href="https://www.openstreetmap.org/about">OpenStreetMap</a>. <a href="https://pietervdvn.github.io/Staging/surveillance.html?z=17&amp;lat=41.82681&amp;lon=-71.4016">Help improve its accuracy!</a></small></p><p>Brown University has a longstanding policy governing the appropriate uses of its surveillance cameras. <strong>Unfortunately, <a href="https://www.browndailyherald.com/2008/01/10/surveillance-cameras-on-campus-triple/#post-1679525:%7E:text=DPS%20would%20not%20release%20the%20University%E2%80%99s%20full%20policy%20on%20the%20surveillance%20camera%20system">this policy is secret</a>.</strong></p>
<p>While Brown probably does not <em>currently</em> have the capacity to both broadly and deeply inspect the firehose of data produced by these cameras, expect this to change in the near future. Axis Communications, Brown's primary supplier of surveillance cameras, <a href="https://www.axis.com/customer-story/3767">now touts cameras that can perform <em>on-board</em> facial recognition</a>. And Software House, the provider of the C•CURE 9000 access control system, has begun marketing the integration of facial recognition with its access control systems:</p>
<p><iframe src="https://www.youtube.com/embed/bk395D0tPRA" frameborder="0" allowfullscreen=""></iframe></p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/brown-location-surveillance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319392</guid>
            <pubDate>Sat, 05 Dec 2020 23:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Blub Studies]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318635">thread link</a>) | @edavis
<br/>
December 5, 2020 | https://www.benkuhn.net/blub/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/blub/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Sometimes people ask me what they should learn to become a better programmer. I feel like the default recommendation here is usually an obscure programming language or a textbook on some high-powered machinery like ML. So I always feel a little bit embarrassed and boring when I instead suggest going really deep on what you already know: your main programming language, web framework, object-relational mapper, UI library, version control system, database, Unix tools, etc. It’s not shiny or esoteric, but for me, building a detailed mental model of those (and how they compare to alternatives) might be the learning that’s contributed most to my effectiveness as an engineer.</p><p>A coworker coined the phrase “blub studies” to refer to this sort of mundane, ultra-specific-seeming knowledge. “Blub” comes from a Paul Graham essay, <a href="http://www.paulgraham.com/avg.html" target="_blank">Beating the Averages</a>, in which Blub is a hypothetical middlebrow language whose programmers get defensive when Graham asserts that Lisp is superior. Blub studies is the study of what goes on in the guts of these boring, everyday systems—not the kind you get tenure for inventing, but the kind people actually use.</p><p>Blub studies is a never-ending treadmill of engineering know-how. It’s the fiddly technical details of how Git stores data, or how Postgres locking semantics <a href="https://gocardless.com/blog/zero-downtime-postgres-migrations-the-hard-parts/" target="_blank">caused your migration to bring down prod</a>, or why <code>pip install</code> failed <em>this</em> time. It’s what goes on inside the boiler rooms of your computer. There’s a seemingly infinite amount of it, full of bespoke details for you to stumble over, and that makes it, often, unbelievably frustrating. Experts in shiny fields like machine learning write shiny-sounding articles like <em><a href="https://blog.acolyer.org/2018/01/31/a-theory-of-the-learnable/" target="_blank">A theory of the learnable</a></em>; experts in blub studies emit screeds like <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a> and <a href="https://www.stilldrinking.org/programming-sucks" target="_blank">Programming Sucks</a>.</p><p>In short, if you’re in search of generalizable knowledge that <a href="https://fs.blog/2019/02/compounding-knowledge/" target="_blank">compounds exponentially over time</a>, then blub studies looks like the crap you have to wade through to get to the good stuff. So it’s easy to see why people give up on understanding all the blub they’re surrounded by, except what they need to get the job done.</p><p>But for me, the opposite attitude has been more productive. <a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>—even if it’s hard and takes a while. Blub studies is more generalizable than it seems, and has its own way of compounding over time, too. That makes it a lot more useful than you’d expect.<sup><label for="sn0">✻</label><span><span><sup>✻</sup>
Of course, there are useless parts of blub studies: if this essay gets you excited to memorize a bunch of command-line flags, consider <a href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/" target="_blank">reversing this advice</a>. But in my experience, it’s more common to neglect the useful parts of blubs, than to over-index on trivia.</span></span></sup></p><hr><p>The most straightforward benefit of blub expertise is that it saves you time. <a href="https://twitter.com/geoffreylitt/status/1305214228991750144" target="_blank">“You can’t apply those brilliant insights you learned from SICP if you don’t have the knowledge base and emotional fortitude to fight through <code>pip install</code> first."</a> If you know how Git’s internal model works, you can get your repository out of its borked state without spending hours on Stack Overflow.</p><p>This effect is larger than it might seem. If you’re working with a system you don’t understand, you’re limited to debugging via guess-and-check, which can be arbitrarily slow. A more efficient method would be to <a href="https://twitter.com/b0rk/status/1265360282513281025?lang=en" target="_blank">get as much information as possible about your program’s execution</a> and then use that information to exclude most of the hypothesis space. But this requires a good understanding of both the system, and the tools available for inspecting it. If you’re tracking down, say, a networking problem, staring at some <code>tcpdump</code> output will often get you most of the way there, but only if you know how to interpret it and what to look for.</p><p>If you spend half your programming time debugging, and being a blub expert lets you debug twice as fast, then just the speed gain from blub expertise will let you increase your output by a third.<sup><label for="sn1">†</label><span><span><sup>†</sup>
If you think “half of programming time debugging” sounds high, imagine how much faster you’d be if all your code worked the first time.<p>Doubling debugging speed is probably a conservative estimate—you can save pretty much unlimited time via things like <a href="http://rachelbythebay.com/w/2020/10/14/lag/" target="_blank">“hmm, 40 milliseconds sounds like the timeout for Nagle’s algorithm, try setting <code>TCP_NODELAY</code>”</a>. I somewhat frequently debug tricky things 5x+ faster than coworkers, just because I’ve been working with our stack for a long time, so I know where to look for problems and how to quickly test hypotheses.</p></span></span></sup> That justifies a lot of time staring at <code>tcpdump</code> output! But there are also more subtle reasons I’ve gotten so much from blub studies. It’s both more general, lasts longer, and has more of a compounding effect, than I expected.</p><hr><p>Blub studies are surprisingly broadly applicable because, even if you’re learning about the details of some specific blubby system, that system’s design will contain a juicy non-blubby core of extractible general principles. Unlike many “general principles” people try to teach you, the ones you learn via blub studies are guaranteed to be important to at least one real-world system (the one you’re learning about). And you’ll see them realized in all their messy detail, which academic presentations often leave out.</p><p>Suppose your blub of choice is React. You might worry that learning the gory details will be useless if you ever move to a different part of the stack, or even a different web framework. And, yes, some of them will. But the core idea of React—writing pure render functions, using <a href="https://reactjs.org/docs/reconciliation.html" target="_blank">reconciliation</a> to make updates fast—is extremely powerful and general. In fact, it’s now been copied by the next generation of UI frameworks on both iOS (<a href="https://developer.apple.com/xcode/swiftui/https://developer.apple.com/xcode/swiftui/" target="_blank">SwiftUI</a>) and Android (<a href="https://developer.android.com/jetpack/compose" target="_blank">Jetpack Compose</a>). Learning the principles behind React makes it easier to learn those other frameworks. In fact, it can even be a useful source of ideas to “import” from one to the other. At Wave, for instance, we’ve gotten a lot of mileage out of importing ideas from <a href="https://relay.dev/" target="_blank">Relay</a> into our mobile apps.</p><p>This is a good example of an idea that, as far as I know, you can <em>only</em> learn about through blub studies. Academia didn’t give much attention to React-style UI programming. In fact, it doesn’t seem to view user-interface programming paradigms as a particularly interesting object of study at all. People do sometimes publish on it but, for instance, I couldn’t find any courses on it in MIT’s extensive course catalog.<sup><label for="sn2">‡</label><span><span><sup>‡</sup>
You could argue that this is because UI programming is “too applied” and one shouldn’t expect it to be covered in an academic curriculum. But computer science covers many other equally-“applied” areas, like networking, databases, operating systems, and graphics.</span></span></sup></p><hr><p>Blub studies also compound more than you’d naively expect, in two ways. First, knowing about one blub makes it easier to learn about alternative blubs that serve the same purpose—like the React/SwiftUI example above. Second, knowing more about one blub helps you learn blubs in <em>adjacent</em> parts of the stack more quickly.</p><p>Once, while pair programming with a more junior coworker, we were writing a complicated SQLAlchemy query. My coworker used <code>user.name</code> (the <code>name</code> field of an object stored in the <code>user</code> variable) instead of <code>User.name</code> (the <code>name</code> field of the <em>class</em> <code>User</code>) and was wondering why her query gave the wrong results. I tried to explain the “magic” by which <code>User.name</code> was an instance of <code>Column</code> while <code>user.name</code> was a simple <code>str</code>. I went around in circles for a little while until I eventually explained Python’s <a href="https://docs.python.org/3/howto/descriptor.html" target="_blank">descriptor protocol</a> to her (the language feature SQLAlchemy uses to enable the “declarative” ORM syntax). At that point, everything clicked—and I realized that Python’s <code>__dunder__</code> methods are the key to decoding quite a lot of “magical” seeming code. If you learn the Python language features well, lots of complicated libraries will become a lot easier to understand.</p><p>I had a similar experience myself with Kubernetes. The first time I tried to learn it, it was a bewildering morass of jargon—all those namespaces and containers and Pods and Deployments and Services and Ingresses just to get a simple HTTP server running! Then I read <a href="http://intronetworks.cs.luc.edu/" target="_blank">a networking textbook</a> and everything made much more sense. The (arguably) most complicated parts of Kubernetes exist to solve networking-related problems—allowing hundreds of containers to talk to each other independently while hosted on a much smaller set of computers—so the networking textbook gave me a schema onto which I could hang all my Kubernetes factoids. Once I knew how Linux’s IP routing, iptables, and network namespaces worked, it was much easier for me to understand what exactly something like “kube-proxy” was doing.</p><p>If you know enough different blubs, you can end up at the point where you don’t even need to look things up to figure out how they’re (probably) implemented. An experienced Python programmer can guess immediately how SQLAlchemy’s “declarative” ORM works under the hood. That’s the point when your blub expertise will really start compounding—almost as soon as you start working with something new, you’ll start figuring out how it works and extracting the kernel of generally-interesting ideas.</p><hr><p>Because of this compounding effect, the most important step toward becoming a blub master is to kickstart your “blub flywheel”—the virtuous cycle of blub accumulation—however you can. That means starting with whichever blubs are the easiest or most motivating to learn, and branching out from there. For me, the easiest place to start has been with blubs I’m already using at my day job. I have a couple strategies for getting the most out of those.</p><p>First, I’ll try to <em>go deeper than necessary</em>. If I really want to ship something, it’s easy to give into temptation to, say, Google an error message, copy-paste a fix from Stack Overflow, and move on with my day. But it often doesn’t take that much longer to actually read the error message, understand what it means, and try to figure out <em>why</em> that Stack Overflow answer fixed my problem. Similarly, if I’m stuck in a tricky yak shave, I’ll bias against “guess-and-check” style …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.benkuhn.net/blub/">https://www.benkuhn.net/blub/</a></em></p>]]>
            </description>
            <link>https://www.benkuhn.net/blub/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318635</guid>
            <pubDate>Sat, 05 Dec 2020 21:37:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Special Kind of Hell: intmax_t in C and C++]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25316933">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://thephd.github.io/intmax_t-hell-c++-c | <a href="https://web.archive.org/web/*/https://thephd.github.io/intmax_t-hell-c++-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>C and C++ as languages have a few things separating them from each other, mostly in their minute details and, occasionally, larger feature sets like designated initializers. But there is a disturbingly high amount of C++ that can simply do C’s job far better than C<!--more-->, including when it comes to solving some of the biggest problems facing the evolution of C and C++.</p>

<p>Let’s take a contemporary problem plaguing both C and C++, affecting everyone from standard library maintainers to project developers, that has been going on for the last 20 or so years: <code>intmax_t</code>.</p>



<p>The concept behind <code>intmax_t</code> is simple enough: it is the largest integer type that your implementation and its standard library support in conjunction. Here is a few things <code>intmax_t</code> controls inside the implementation:</p>

<ul>
  <li>numeric literals are preprocessed according to what <code>intmax_t</code> can handle (C and C++);</li>
  <li>it is the maximum number of bits that can be printed portably, e.g. with <code>printf("%j", (intmax_t)value)</code> (C and C++);</li>
  <li><code>intmax_t</code> is the largest type for which <code>std::numeric_limits</code> applies, including most types up to and including that type (C++ only);</li>
  <li><code>intmax_t</code> underpins <code>std::chrono</code>’s casts and similar (e.g. no information is lost during conversions out of and into the system) (C++ only);</li>
  <li>and, there are a set of integer operations provided by the standard library (like absolute value and quotient / remainder operations) that can be done with the maximum bit precision available to the implementation (C and C++).</li>
</ul>

<p>These properties forge the basis of <code>intmax_t</code>’s purpose. Lossless storage, pass-through operations, and more can all be achieved by relying on this implicit contract of the type. Since it is a type definition, the “real” integer type underneath it can be swapped out and people relying on it can be upgraded seamlessly!</p>



<p>We cannot upgrade seamlessly.</p>

<p>C has a much higher commitment to not breaking old code and keeping “developers close to the machine”. What this actually translates to for most Application Binary Interfaces is very simplistic “name mangling” schemes (i.e., none), <a href="https://twitter.com/__phantomderp/status/1329960075096694790">weak linkers</a>, and other shenanigans. The end result is that we expose C developers to platform details that become invisible dependencies for their code that must be preserved at all costs. For example, let’s take a C Standard function that uses <code>intmax_t</code>, <code>imaxabs</code>:</p>

<div><div><pre><code><span>intmax_t</span> <span>imaxabs</span><span>(</span><span>intmax_t</span> <span>j</span><span>);</span>
</code></pre></div></div>

<p>and, let’s try to figure out how we can upgrade someone off of this usage without breaking their code too badly. We will try fixing this in both C and C++.</p>



<p>Taking <code>intmax_t</code>, let’s do a no-brainer usage case: calling a function with <code>intmax_t</code> input and return types. The syntax and usage ends up looking like this:</p>

<div><div><pre><code><span>#include &lt;inttypes.h&gt;
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>original</span> <span>=</span> <span>(</span><span>intmax_t</span><span>)</span><span>-</span><span>2</span><span>;</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>imaxabs</span><span>(</span><span>original</span><span>);</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>val</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Easy enough! But, there’s also a hidden dependency here, based on how the code is compiled. While many people compile their C standard library as a static library and only generate final binary code for what they use as to have a “self-contained” binary, the vast majority of the shared ecosystem depends on shared libraries/dynamically linked libraries for the standard. This means that when a program is milled through an operating system at program startup, the “loader” runs off to find the symbol <code>imaxabs</code> inside some system library (e.g., <code>/lib/x86_64-linux-gnu/libc-2.27.so</code> for an “amd64” system). Harmless enough, right? Well, it turns out to be a bit of a problem in practice, because the name <code>imaxabs</code> is all that’s used in C to figure out what subroutine to talk with in some shared library,</p>

<p>and that name is completely inadequate.</p>

<p>Consider the following scenario:</p>

<ol>
  <li>The glibc maintainers decide they’re going to change from <code>long long</code> as their <code>intmax_t</code> and move to <code>__int256_t</code> for most platforms, because most platforms support it and they have a lot of customers asking for it.</li>
  <li>They upgrade the <code>libc</code> to its next version for various Linux distribution, and everyone links against it when they look for the default <code>libc</code>.</li>
  <li>You have an application. Your code was not changed or updated, so it was not recompiled. It calls <code>imaxabs</code>. The argument it passes is a <code>long long</code>, because that was the type at the time you last compiled and shipped your software.</li>
  <li>The <code>imaxabs</code> used to lookup the function to call finds the version that takes a <code>__int256_t</code> in the new <code>libc</code>.</li>
  <li>Different registers are used to pass and return the function value than expected by the <code>imaxabs</code> function call in the <code>libc</code> binary, because your application is in <code>long long</code> mode but glibc expects a <code>__int256_t</code>.</li>
  <li>All hell breaks loose.</li>
</ol>

<p>This is one of the manifestations of what is called an “Application Binary Interface (ABI) Break”. ABI Breaks are generally undetectable, silent breaks that occur within the runtime of a program that completely destroy any dependency your program has on that functionality for correctness. It typically happens when a subtle detail – the registers used to negotiate a large integral value between a shared library and its application, the amount of padding a structure might have on a certain build, the ordering and layout of class members, the interpretation of bits even if the layout or passing convention of a type never changes, and even more – changes.</p>

<h2 id="but-c-is-abi-stable">“But C Is ABI-Stable?!”</h2>

<p>Not necessarily. C is a simple language, and it both sells itself on and prides itself as such. So much so, that it’s even part of the <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2021.htm">language’s rolling charter</a>. There’s barely any name mangling because there’s no overloading. If you want “virtual functions” you need to hand-craft your virtual table structure and initialize it yourself. There’s barely any lookup or entity negotiation: what you write – <a href="https://twitter.com/thingskatedid/status/1328918322507706368">however scary or cursed</a> – is what you get, in a general sense. (No, it’s not “portable assembly”. Compilers tear C code apart and make it far more efficient than the code people stuff into it. It’s not even a direct model of the machine anymore: just an abstract one.)</p>

<p>Still, sometimes even C can’t get away from it. The function <code>imaxabs</code> relates to exactly one entity that, for historical reasons, was pinned to a function taking and returning a <code>long long</code>. Upgrading it means dealing with this schism between what the user expects (<code>intmax_t</code> that got upgraded and can print <code>__int128_t</code>/<code>__int256_t</code>) with old, non-recompiled code that maintains the old invariant (<code>long long</code>, a 64-bit number).</p>



<p>Okay, so symbols can be repurposed between library versions that lead to ABI breaks. What are the ways to defend against such a world, in C?</p>

<h2 id="macros">Macros?</h2>

<p>Macros! Object-like macros are fun. You could do something like this…</p>

<div><div><pre><code><span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<p>… as a way to provide the <code>imaxabs</code> function. It is a bit like artisanal, hand-crafted, free-range, and organic ABI versioning (or, as I have affectionately come to call it: personal masochism to make up for language failures). This mostly works, until… it doesn’t!</p>

<h3 id="714">§7.1.4</h3>

<p>This is the “ABI Breaks Guaranteed” section in the C Standard. It’s real name is “§7.1.4 Use of library functions”. Reproduced below is the relevant piece that condemns us, emphasis mine:</p>

<blockquote>
  <p>Any function declared in a header may be additionally implemented as a function-like macro defined in the header, so if a library function is declared explicitly when its header is included, one of the techniques shown below can be used to ensure the declaration is not affected by such a macro. <strong>Any macro definition of a function can be suppressed locally by enclosing the name of the function in parentheses</strong>, because the name is then not followed by the left parenthesis that indicates expansion of a macro function name. For the same syntactic reason, it is permitted to take the address of a library function even if it is also defined as a macro. <strong>The use of <code>#undef</code> to remove any macro definition will also ensure that an actual function is referred to</strong>.</p>
</blockquote>

<p>Not only can a user suppress a function-like macro invocation by using the same trick used on <code>&lt;windows.h&gt;</code> like <code>(max)(value0, value1)</code>, but the C Standard Library permits them to also undefine function names:</p>

<div><div><pre><code><span>// implementer code: inttypes.h</span>
<span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<div><div><pre><code><span>// user code: main.c</span>
<span>#include &lt;inttypes.h&gt;
</span>
<span>#undef imaxabs // awh geez
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
	<span>intmax_t</span> <span>absval</span> <span>=</span> <span>imaxabs</span><span>(</span><span>val</span><span>);</span> <span>// awH GEEZ</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>absval</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Mmm……</p>

<h3 id="implementation-specific-strategies">Implementation-specific strategies</h3>

<p>Alright, the C Standard basically loads a double barrel and brings our only standardized mitigation strategy out back behind the barn. What’s left? Well, implementation-specific insanity, that’s what:</p>

<div><div><pre><code><span>extern</span>
<span>intmax_t</span>
<span>__glibc228_imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>

<span>__attribute</span><span>((</span><span>symbol</span><span>(</span><span>__MANGLE</span><span>(</span><span>__glibc228_imaxabs</span><span>))))</span>
<span>extern</span>
<span>intmax_t</span>
<span>imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>
</code></pre></div></div>

<p>This is pseudo-code. But, wouldn’t you believe it, some implementations actually do things very similar to this to get around these problems! The things they do are far more involved, like actually dropping down to the level of the linker and creating symbol maps and other exceedingly painful workarounds. The sed scripts and the awk scripts and the bash starts coming out, people are doing lots of text processing to get symbol names and match them to versioned symbol names…</p>

<p>It’s a mess.</p>

<p>Still, given the mess, it does save us from the problem. In C code you get to use “the real name” <code>imaxabs</code> as Our Lord and Savior intended, the binary gets linked to <code>___glibc228_imaxabs</code>, and everyone’s happy. There’s only one problem with this kind of fix…</p>

<p>It’s Quality of Implementation (QoI).</p>

<p>QoI is great for the pure, theoretical standard. We get to write sexy narratives in the C standard and call them “Recommended Practice”, with little footnotes furtively implying a more wonderful world while waggling our eyebrows seductively at hot, young developers in our area. Just come along, it’s going to be so great, we’re going have soooooo much fun, just go with that lovely little implementation right over there, you’re making such fine progress, enjoy yourself and come back soon my …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/intmax_t-hell-c++-c">https://thephd.github.io/intmax_t-hell-c++-c</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/intmax_t-hell-c++-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316933</guid>
            <pubDate>Sat, 05 Dec 2020 18:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Walking]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25316328">thread link</a>) | @KlimYadrintsev
<br/>
December 5, 2020 | https://klimy.co/blog/benefits-of-walking | <a href="https://web.archive.org/web/*/https://klimy.co/blog/benefits-of-walking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How long does it take to walk 1 mile?</h2>
<p>As both research and actual scientific measurements, an average adult will walk 1 mile in 15 to 18 minutes at moderate to a brisk pace. Or in other words, 3 to 4 miles per hour.</p>
<p>This is a general measure for a healthy adult between 20 and 50 years old, at dry weather, on relatively flat terrain, with no destruction from cars and other environments.</p>
<p>If you are either less healthy or subjected to any of the environmental distractions, your speed, of course, will be lower.</p>
<h2>Average walking speed by age group and gender</h2>
<p>There is little difference between male and female, with males walking on average 2% faster.</p>
<p>The table below shows the speed of walking based on age and gender:</p>
<pre><code>| Age      | Sex    | Meters per second | Miles per hour |
|----------|--------|-------------------|----------------|
| 20 to 29 | Male   | 1.36              | 3.04           |
|          | Female | 1.34              | 3.0            |
| 30 to 39 | Male   | 1.43              | 3.2            |
|          | Female | 1.34              | 3.0            |
| 40 to 49 | Male   | 1.43              | 3.2            |
|          | Female | 1.39              | 3.11           |
| 50 to 59 | Male   | 1.43              | 3.2            |
|          | Female | 1.31              | 2.93           |
| 60 to 69 | Male   | 1.34              | 3.0            |
|          | Female | 1.24              | 2.77           |
| 70 to 79 | Male   | 1.26              | 2.82           |
|          | Female | 1.13              | 2.53           |
| 80 to 89 | Male   | 0.97              | 2.17           |
|          | Female | 0.94              | 2.10           |
</code></pre>
<h2>Benefits of walking</h2>
<p>There has been a great deal of research that showed that walking brings a huge advantage to humans. To both <a href="https://journals.sagepub.com/doi/abs/10.1177/0013916518800798">physical, and mental well being.</a> The benefits are as follows:</p>
<p>Physical:</p>
<ul>
<li>Burning calories. A direct way to reduce and to control your weight.</li>
<li>Lower glucose level and blood sugar levels. <a href="https://care.diabetesjournals.org/content/early/2013/06/03/dc13-0084">Research</a> has focused on short walks, where it helped reduce glucose intolerance.</li>
<li><a href="https://bjsm.bmj.com/content/45/12/987?sid=fe62a8c5-430b-4506-b854-20b62e8a5e9e">Help deal with infection and possibly Covid.</a></li>
<li>Help boost immune function.</li>
<li>Give additional energy to do other tasks due to increased efficiency of nutrients absorption and conversion.</li>
<li>Prolonging life. There is a <a href="https://bjsm.bmj.com/content/52/12/761">research that showed</a> evidence of having a relationship between physical activity and overall life expectancy. </li>
<li>Strengthen the heart. Even 20 minutes of daily walking has shown to reduce the risk of stroke by at least 20%.</li>
</ul>
<p>Mental:</p>
<ul>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving self esteem</a> by 45%.</li>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving mood</a> by 54%.</li>
<li>Additional time on focusing on self-education with educational podcasts and books. <a href="https://digitalcommons.georgiasouthern.edu/nyar_savannah/2020/2020/90/">Research</a> has shown that it leads to better learning of the material, longer retention, better engagement in post-walk discussions, better behaviour and mood, AND improved health literacy.</li>
<li>Improving <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">goal setting</a> in other areas by targeting non-specific goals which in consequence lead to better results.</li>
<li>Walking helps you get your thoughts in order. Whenever you are alone with yourself, and you are unable to really look at the phone, you are finally able to understand what is happening with yourself with no distractions.</li>
<li>Improve the creative part of the brain. While walking, <a href="https://psycnet.apa.org/record/2014-14435-001">research showed</a>, that it is easier to come up with great ideas.</li>
<li>Save money on medications. With the amount of food, we consume and with costly medicine, walking and doing exercises can help you save money and nerves.</li>
</ul>
<h2>Covid and sitting time</h2>
<p>In the world of pandemics and covid, it has been evident that humans are sitting more and more and do less and less exercises. There is a <a href="https://www.sciencedirect.com/science/article/pii/S221133552030214X">great research</a> that shows that 2020 has caused a sharp increase in average sitting time. The data is staggering.</p>
<p><code>Overall, 42.6% of participants reported sitting for &gt; 8 h/day (95% CI: 41.2%–44.0%) and 72.5% (71.2%–73.7%) reported being either sufficiently (150–300 MVPA minutes) or highly active (&gt;300 min).</code></p>
<p>If you want to boost your health and still to be able to keep up with a busy schedule walking or running can be the best idea for spending your free time. In the world where only entertainment inside your house is minimal. If being glued to the screen is no longer an option, than being outside can boost your health and your mental capabilities immensely.</p>
<p><img alt="walking in the park grass and women leg" src="https://i.gyazo.com/ecae9926d17ad69ded99b1a445482e9a.jpg"></p>
<h2>Tips on how to start walking</h2>
<h3>How to make walking a habit?</h3>
<p>The walk starts with the first step. It would be best if you did not put huge goals onto yourself. Start somewhere small, then later you can always adjust based on how you feel.</p>
<p>Start by putting on clothes(plus a mask) and go outside. Going back to your apartment would feel bad at that point.</p>
<p>Next, you should walk around your building or up and down the street.</p>
<p>Next, you walk around the block and later you can finally go for huge walks that can be a couple of hours long.</p>
<p>Don’t try to start at the last step that would only make you quit before you get the full benefit of the habit.</p>
<p>Peg your walking habit to something else. If you go for a coffee every morning, go to a coffee house that is further away. If you are usually riding a tube to work, start the journey at the stop further away from you</p>
<h3>Identify as a walker</h3>
<p>If you would like to start walking you need to think of <strong>how do you become a walker.</strong></p>
<p>You need to make sure you identify as someone who goes on walks, then keeping up with the habit will be much easier.</p>
<p>Next time someone asks you, whatever you do any exercises or what you love doing with your free time, you need to want to say that you love walking. At that point, you will be able to keep on walking and improving your health immensely.</p>
<h2>How much walking per week is enough?</h2>
<p>I think that it is tough to give a simple number for everyone, but if you are in the age range of 18-50, then:</p>
<ul>
<li>150 to 300 minutes per week is an ideal level if you are walking with moderate speed</li>
<li>75 to 150 minutes per week if you are walking with a brisk pace.</li>
</ul>
<p>Don’t think that doing extra physical exercise will be useless. In contrast, anything above that time limit will give even higher benefits to your health, so take the timing above as a general guideline. Do as much as you want.</p>
<h2>Personal tips on walking more</h2>
<h3>Wake up earlier</h3>
<p>Right now it is very easy to blame everything on covid and health, but not many people <a href="https://klimy.co/blog/how-to-wake-up-early">wake up very early in the morning</a>, that gives people that live in the city an ability to walk as much as they want, even in usually crowded spaces.</p>
<p>Also, your excuse of not having enough time can not be reinforced if you have an extra hour in the morning.</p>
<h3>Get a pet (dog)</h3>
<p>Even though it can seem like a lousy idea, multiple research papers show a relationship between owning a dog and the number of steps you do daily. If you are struggling to make time, your favourite pet will make you find time for walks.</p>
<p><img alt="man and dog walking in forest autumn" src="https://i.gyazo.com/5e16de8c0474f84f4285df88fab28c14.jpg"></p>
<h3>Podcasts and Audiobooks</h3>
<p>I love learning and listening to books. I do it all the time even when I am at home at my desk, so a change of pace for me is always going for an extended walk where I can do the same thing.</p>
<p>What I discovered is that I understand and remember information much better when I have consumed it while walking. That makes me spend twice as little time and getting twice the result. </p>
<p>Podcasts have been my go-to method of getting new relevant news and information in my field of expertise. Since I have started a habit of walking, I have been on top of my field and able to implement solutions that I would have never thought of otherwise.</p>
<h3>Music</h3>
<p>I also love discovering new music. Sometimes when I really need to get my head around something I go for a brisk walk with my favourite songs. This helps me to unwind and later really understand the problem.</p>
<p>Most of the time while on the walk, I solve the problem that I had, and in my experience would off taken me much more time to solve.</p>
<h3>Walking groups</h3>
<p><img alt="walking groups picture" src="https://i.gyazo.com/26609ccb0d7ae90e9f746389479a32b0.jpg"></p>
<p>Sometimes socialising can be hard and especially when all of your friends are on the lockdown and all of the socialising places, such as restaurants, are closed. </p>
<p>That is where walking groups can come into play! You can find someone who is staying healthy and being diligent with their health and walk together! That will allow you to catch up and have social interaction, that we humans require.</p>
<h5>So what this means?</h5>
<p>Now you have a social responsibility in your habit, and the whole activity can let you be more motivated to do it.</p>
<p>Also, walking groups normally allow you to meet new people and to bond better with existing relationships.</p>
<p>Also, walking groups is a great way to speed up your walking pace and improve your health.</p>
<h2>How do I get better at walking?</h2>
<p>If you would like to improve the speed at which you walk, there are multiple ways to do so:</p>
<ul>
<li>As mentioned above, walking groups are amazing for giving you a speedup of pace, just make sure to not overdo it.</li>
<li>Walking poles (tracking poles) are an easy way to speed up the pace. They are especially useful for those with back or leg injury, that immensely help reduce the stress on joints and back as well as speed up the pace. There is a lot of research behind use cases and benefits of using them.</li>
<li>Treadmills. If you are unable to properly walk in the wild or in the park, get yourself a treadmill. Although they can be expensive, some are very cheap and immensely powerful alternatives provide the same result. You don’t need something overly expensive. Treadmills are great for controlling your pace as well as letting you support yourself with the rails that are at either side of the treadmill.</li>
<li>Have an open goal. Whenever you are walking, the <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">research has shown</a> that having an open goal to where you want to walk or for how long will extend the amount of walking that you will eventually do.</li>
<li>Keep track of your metrics. Understanding what your heart rate and your pace are, is vital for your well being and motivation. Seeing that you have improved over a period of time is the greatest motivator there is.</li>
<li>Strive towards a 13 minutes per mile goal. The 13 minutes per mile has been shown to be the meeting point between fast walkers and the joggers. As …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klimy.co/blog/benefits-of-walking">https://klimy.co/blog/benefits-of-walking</a></em></p>]]>
            </description>
            <link>https://klimy.co/blog/benefits-of-walking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316328</guid>
            <pubDate>Sat, 05 Dec 2020 17:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improbable Inspiration: Bayesian Networks (1996)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25315982">thread link</a>) | @1e
<br/>
December 5, 2020 | https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html | <a href="https://web.archive.org/web/*/https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td>

      <span face="Arial,Helvetica" color="#003366">

      <b>Improbable Inspiration</b><p>
      The future of software may lie in the obscure theories of an
      18th century cleric named Thomas Bayes.

      </p><p>

      By LESLIE HELM, Times Staff Writer

      </p><hr>
      <p>

      When Microsoft Senior Vice President Steve
      Ballmer first heard his company was planning to make a huge
      investment in an Internet service offering movie reviews and
      local entertainment information in major cities across the
      nation, he went to Chairman Bill Gates with his concerns.

      </p><p>

      &nbsp;&nbsp;&nbsp; After all, Ballmer has billions of dollars of
      his own money in Microsoft stock, and entertainment isn't
      exactly the company's strong point.

      </p><p>

      &nbsp;&nbsp;&nbsp; But Gates dismissed such
      reservations. Microsoft's competitive advantage, he responded,
      was its expertise in "Bayesian networks."

      </p><p>

      &nbsp;&nbsp;&nbsp; Asked recently when computers would finally
      begin to understand human speech, Gates began discussing the
      critical role of "Bayesian" systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Ask any other software executive about
      anything "Bayesian" and you're liable to get a blank
      stare.

      </p><p> 

      &nbsp;&nbsp;&nbsp; Is Gates onto something? Is this
      alien-sounding technology Microsoft's new secret weapon?

      </p><p>

      &nbsp;&nbsp;&nbsp; Quite possibly.
      
      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks are complex diagrams that
      organize the body of knowledge in any given area by mapping out
      cause-and-effect relationships among key variables and encoding
      them with numbers that represent the extent to which one
      variable is likely to affect another.

      </p><p>

      &nbsp;&nbsp;&nbsp; Programmed into computers, these systems can
      automatically generate optimal predictions or decisions even
      when key pieces of information are missing.

      </p><p>

      &nbsp;&nbsp;&nbsp; When Microsoft in 1993 hired Eric Horvitz,
      David Heckerman and Jack Breese, pioneers in the development of
      Bayesian systems, colleagues in the field were surprised. The
      field was still an obscure, largely academic enterprise.

      </p><p>
 
      &nbsp;&nbsp;&nbsp; Today the field is still obscure. But scratch
      the surface of a range of new Microsoft products and you're
      likely to find Bayesian networks embedded in the software. And
      Bayesian nets are being built into models that are used to
      predict oil and stock prices, control the space shuttle and
      diagnose disease.

      </p><p>

      &nbsp;&nbsp;&nbsp; Artificial intelligence (AI) experts, who saw
      their field discredited in the early 1980s after promising a
      wave of "thinking" computers that they ultimately
      couldn't produce, believe widening acceptance of the Bayesian
      approach could herald a renaissance in the field.

      </p><p>
      
      &nbsp;&nbsp;&nbsp; Bayesian networks provide "an
      overarching graphical framework" that brings together
      diverse elements of AI and increases the range of its likely
      application to the real world, says Michael Jordon, professor of
      brain and cognitive science at the Massachusetts Institute of
      Technology.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is unquestionably the most
      aggressive in exploiting the new approach. The company offers a
      free Web service that helps customers diagnose printing problems
      with their computers and recommends the quickest way to resolve
      them. Another Web service helps parents diagnose their
      children's health problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; The latest version of Microsoft Office
      software uses the technology to offer a user help based on past
      experience, how the mouse is being moved and what task is being
      done.

      </p><p>

      &nbsp;&nbsp;&nbsp; "If his actions show he is distracted,
      he is likely to need help," Horvitz says. "If he's
      been working on a chart, chances are he needs help formatting
      the chart."

      </p><p>

      &nbsp;&nbsp;&nbsp; "Gates likes to talk about how computers
      are now deaf, dumb, blind and clueless. The Bayesian stuff helps
      deal with the clueless part," says Daniel T.  Ling,
      director of Microsoft's research division and a former IBM
      scientist.

      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks get their name from the
      Rev. Thomas Bayes, who wrote an essay, posthumously published in
      1763, that offered a mathematical formula for calculating
      probabilities among several variables that are causally related
      but for which--unlike calculating the probability of a coin
      landing on heads or tails--the relationships can't easily be
      derived by experimentation.

      </p><p>

      &nbsp;&nbsp;&nbsp; Early students of probability applied the
      ideas to discussions about the existence of God or efforts to
      improve their odds in gambling. Much later, social scientists
      used it to help clarify the key factors influencing a particular
      event.

      </p><p>

      &nbsp;&nbsp;&nbsp; But it was the rapid progress in computer
      power and the development of key mathematical equations that
      made it possible for the first time, in the late 1980s, to
      compute Bayesian networks with enough variables that they were
      useful in practical applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; The Bayesian approach filled a void in the
      decades-long effort to add intelligence to computers.

      </p><p>

      &nbsp;&nbsp;&nbsp; In the late 1970s and '80s, reacting to the
      "brute force" approach to problem solving by early
      users of computers, proponents of the emerging field of
      artificial intelligence began developing software programs using
      rule-based, if-then propositions. But the systems took time to
      put together and didn't work well if, as was frequently the
      case, you couldn't answer all the computer's questions clearly.

      </p><p>

      &nbsp;&nbsp;&nbsp; Later companies began using a technique
      called "neural nets" in which a computer would be
      presented with huge amounts of data on a particular problem and
      programmed to pull out patterns. A computer fed with a big stack
      of X-rays and told whether or not cancer was present in each
      case would pick out patterns that would then be used to
      interpret X-rays.

      </p><p>

      &nbsp;&nbsp;&nbsp; But the neural nets won't help predict the
      unforeseen. You can't train a neural net to identify an incoming
      missile or plane because you could never get sufficient data to
      train the system.

      </p><p>

      &nbsp;&nbsp;&nbsp; In part because of these limitations, a slew
      of companies that popped up in the early 1980s to sell
      artificial intelligence systems virtually all went bankrupt.

      </p><p>

      &nbsp;&nbsp;&nbsp; Many AI techniques continued to be
      used. Credit card companies, for example, began routinely using
      neural networks to pick out transactions that don't look right
      based on a consumer's past behavior. But increasingly, AI was
      regarded as a tool with limited use.

      </p><p>

      &nbsp;&nbsp;&nbsp; Then, in the late 1980s--spurred by the early
      work of Judea Pearl, a professor of computer science at UCLA,
      and breakthrough mathematical equations by <a href="http://www.hugin.dk/">Danish researchers</a>--AI
      researchers discovered that Bayesian networks offered an
      efficient way to deal with the lack or ambiguity of information
      that has hampered previous systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz and his two Microsoft colleagues, who
      were then classmates at Stanford University, began building
      Bayesian networks to help diagnose the condition of patients
      without turning to surgery.

      </p><p>

      &nbsp;&nbsp;&nbsp; The approach was efficient, says Horvitz,
      because you could combine historical data, which had been
      meticulously gathered, with the less precise but more intuitive
      knowledge of experts on how things work to get the optimal
      answer given the information available at a given time.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz, who with two colleagues founded
      Knowledge Industries to develop tools for developing Bayesian
      networks, says he and the others left the company to join
      Microsoft in part because they wanted to see their theoretical
      work more broadly applied.

      </p><p>

      &nbsp;&nbsp;&nbsp; Although the company did important work for
      the National Aeronautics and Space Administration and on medical
      diagnostics, Horvitz says, "It's not like your grandmother
      will use it."

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft's activities in the field are now
      helping to build a groundswell of support for Bayesian ideas.

      </p><p>

      &nbsp;&nbsp;&nbsp; "People look up to Microsoft," says
      Pearl, who wrote one of the key early texts on Bayesian networks
      in 1988 and has become an unofficial spokesman for the
      field. "They've given a boost to the whole area."
                     
      </p><p>

      &nbsp;&nbsp;&nbsp; A researcher at German conglomerate Siemens
      says Microsoft's work has drawn the attention of his superiors,
      who are now looking seriously at applying Bayesian concepts to a
      range of industrial applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; Scott Musman, a computer consultant in
      Arlington, Va., recently designed a Bayesian network for the
      Navy that can identify enemy missiles, aircraft or vessels and
      recommend which weapons could be used most advantageously
      against incoming targets.

      </p><p>

      &nbsp;&nbsp;&nbsp; Musman says previous attempts using
      traditional mathematical approaches on state-of-the-art
      computers would get the right answer but would take two to three
      minutes.

      </p><p>

      &nbsp;&nbsp;&nbsp; "But you only have 30 seconds before the
      missile has hit you," says Musman.

      </p><p>

      &nbsp;&nbsp;&nbsp; General Electric is using Bayesian techniques
      to develop a system that will take information from sensors
      attached to an engine and, based on expert opinion built into
      the system as well as vast amounts of data on past engine
      performance, pinpoint emerging problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is working on techniques that will
      enable the Bayesian networks to "learn" or update
      themselves …</p></span></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</a></em></p>]]>
            </description>
            <link>https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315982</guid>
            <pubDate>Sat, 05 Dec 2020 16:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Flaws of Human Thinking]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25315667">thread link</a>) | @dandanua
<br/>
December 5, 2020 | https://dandanua.github.io/posts/major-flaws-of-human-thinking/ | <a href="https://web.archive.org/web/*/https://dandanua.github.io/posts/major-flaws-of-human-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As in the lovely child’s quote found on the internet —</p><blockquote><p>I know everything. Except anything I don’t.</p></blockquote><p>— we think that we see everything around us. But we don’t. There are so many things that greatly affect our lives, yet we don’t aware of them. One type of such things is deep inside us — the flaws of our own thinking. Here is my top list of those flaws.</p><h2 id="1-wishful-thinking-conservatism-and-conformism"><strong>1. Wishful thinking, conservatism and conformism</strong></h2><p>By <em>wishful thinking</em> I don’t mean optimism, which is rather speculation about the future. Wishful thinking is when we put more weight on the present knowledge that is pleasant to us, and at the same time ignore the knowledge that is not so nice. For example, people like to ignore the knowledge that puts them in a bad light. This is clearly seen in toxic relationships, where an abuser justifies his actions by “the care” of its victim. A dictator probably thinks that he is doing the best for its nation, while completely ignoring his incapabilities and bad doings. The same is true for groups of people or even nations. An invasion is commonly portrayed as liberation.</p><p>On the other hand, anyone who had experienced an addiction probably knows how it can alter decision-making. “Vodka is an antiseptic, didn’t you know? Let’s drink those bottles so we’ll be healthier!” Gambler thinks that he is going to make money, so his family will be happy. An ordinary gamer thinks that other real affairs are not that important, so it’s ok to spend more time on the game.</p><p>This is just few examples, but such thinking is so common that I don’t think a single book will be enough to collect all different “use cases”.</p><hr><p>Another flaw of our thinking is <em>conservatism</em> — an insufficient ability to change our common views and beliefs with the new data, new evidence. This is understandable — changing basis views leads to a reconsideration of all related knowledge. An enormous amount of rebuilding is required. Our biological brains just can’t do that in a short time, also it’s much harder with age. Because of this, we give much more weight to old knowledge rather than new evidence, thus making a conservatism bias.</p><p>In our rapidly changing world, this problem will have even more impact.</p><hr><p><em>Conformism</em> is when we weigh our knowledge in accordance with our community. The effect of this is highly underrated. An ordinary human thinks that “her thoughts are her own”, without realizing to what extent they are shaped by a community. I think that we’re all conformists to some degree. And it’s hard to imagine what’s that means not to be. This is proved by numerous experiments with a group of actors and one unsuspicious testee, where actors trick the testee to make some ridiculous statements or to do some crazy actions, like the one described <a href="https://www.youtube.com/watch?v=vjP22DpYYh8">here</a>. We are social creatures.</p><p>An extreme version of conformist thinking is the one imposed by religion. I’m not against religions in general, they can be useful, but a blind belief, an unquestioning subordination to “sacred” authorities — that’s just a disaster for a clear mind. A clear mind should have the ability to stress any dogmas.</p><h2 id="2-binary-black-and-white-thinking-overgeneralization"><strong>2. Binary (black-and-white) thinking, overgeneralization</strong></h2><p>Good-evil, smart-stupid, beautiful-ugly, tall-short, fast-slow, and so on and on. We think in binary terms. Our language reflects that. And some people are stuck very hard in such thinking. The worst case of it is <em>all-or-nothing</em> thinking, when any result other than the best is considered as a failure. It causes stress and depression in people. They don’t realize anymore why the world is so mean to them. They stop seeing how many gradients are there, and also how colorful our world is.</p><p>A similar flaw is <em>overgeneralization</em>. We put into the same category very broad types of information. Prejudice, labeling, stereotypes are all related to overgeneralization.</p><h2 id="3-self-projecting-thinking"><strong>3. Self-projecting thinking</strong></h2><p>Mind reading is an ability that everyone would like to have. It would be so easier to communicate. Also, it’s an advantage if we could read the thoughts of our rivals. While we can’t do it in reality, we’re still trying to predict other people’s thoughts, both in collaboration and confrontation.</p><p>To make such predictions we use two main assumptions:</p><ol><li>Other people see the same things as we do.</li><li>Other people are like us, thus their way of thinking is similar to ours.</li></ol><p>Based on these assumptions we use our way of thinking to deduce the thoughts of others. And this is very natural since we have to model another person’s thinking somehow. But the only model that we have is ours. It’s the only model that we can use. So, we essentially project our mind into another person’s head.</p><p>This has a fatal flaw. Because both main assumptions are only half true. While we see the same bits of the world, perception is a way more complex process. From bits we see high-order patterns, but they can be very personal. People could see different patterns and focus on different things. Also, the same bits (e.g. colors) can cause different emotions. Associations are also personal. The way we do conclusions is also very different in people because every person has its own experience, principles, beliefs, preferences, etc. We do not understand how unique the mind of every human.</p><p>And this causes a lot of trouble. People are fighting because of misunderstandings. In most situations they don’t realize, that they are fighting against their own reflection (from a distorting mirror).</p><h2 id="4-human-centric-thinking"><strong>4. Human-centric thinking</strong></h2><p>Humans are extremely focused on their own businesses. Yes, we are successful as a whole, in comparison to other creatures. But we are still part of nature. We follow its laws. Despite this, we neglect nature and the life of other species at scale.</p><p>Moreover, we value leaders, rulers and heroes amongst us much more than others. Even in fiction secondary characters usually die (who cares), while all hail goes to the main performers. We think that leaders are responsible for like 99% of the job done. Thus, we are trying to analyze them, rather than abstract patterns, situations and laws of nature. For example, from the popular culture it may look like Hitler was solely responsible for WWII and the Holocaust. Yeah, sure. How about WWI? Or any other war, genocide, mass conflict in human history? It’s silly to think that all these things were mainly because of leaders. This is just how humans work. In every moment in history there is a mix of wishes, intentions, beliefs, possibilities, thoughts of a total population. It could be that nature just picks a random guy as a leader that represents the mass.</p><p>On the other hand, we think that human is a singular, indivisible unit. That’s also not true. We are a composition of attributes, that are selected by evolution. Any child has some attributes from its mother and some attributes from its father. Human is a composable organism, the same is true for its mind. I’m sure that everyone experienced competing thoughts in his head. There is a natural selection of thoughts ongoing in the mind of every human.</p><h2 id="5-false-associations-confusion-of-causation-and-correlation"><strong>5. False associations, confusion of causation and correlation</strong></h2><p>Our thinking is associative, and we can make connections very fast based on very small data. A typical example is superstition, which is clearly seen in <a href="https://www.psychologistworld.com/superstition">pigeon experiments</a>.</p><p>Survival bias and filtering are accompanying flaws that lead to false associations. In probability theory, this is related to the fact that independent events are not necessary conditionally independent.</p><p>Even when our associations are quite objective we can make false conclusions about the causes. In fact, in probability theory and statistics the notion of a <em>cause</em> is not even defined. Events can be either correlated or independent in this theory. To deduce <em>what causes what</em> we use other tools, like common sense, physics, etc. Typically, to deduce a causation from two correlated events, we check two main things:</p><ol><li>One event is earlier in time than another one.</li><li>There is no common cause that could explain the correlation.</li></ol><p>This is hard stuff even for scientists. Because you have to exclude any possible common cause. Earlier we could use physical locality of events to exclude a lot of possible common causes. But with the advance of quantum mechanics, even locality is not a reliable factor anymore.</p><h2 id="final-words"><strong>Final words</strong></h2><p>There are a lot of other flaws, if you want to learn more you can start <a href="https://en.wikipedia.org/wiki/Cognitive_bias">here</a> and <a href="https://en.wikipedia.org/wiki/Cognitive_distortion">here</a>. But those described above I find the most impactful. I feel them myself and meet them all the time.</p></div></div>]]>
            </description>
            <link>https://dandanua.github.io/posts/major-flaws-of-human-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315667</guid>
            <pubDate>Sat, 05 Dec 2020 16:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Wrote a Book on Data Analysis with Rust Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25314170">thread link</a>) | @DataCrayon
<br/>
December 5, 2020 | https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
    <div id="et-boc">
			
		<!-- #end wrapper --><div>
			<div>
		<div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				
				
				<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they’re implemented in practice.</p>
			</div>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				
				
				<div>
					<div data-columns="4">
	<figure>
		<p><a href="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg"><img width="480" height="679" src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" alt="" loading="lazy" title="cover_darn" data-caption="" data-src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image_width="480" data-large_image_height="679" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg 480w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-212x300.jpg 212w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-300x424.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></a></p>	</figure>
</div>

				</div>
			</div>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				<div>
					 <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_row_inner --><div>
				<div>
				
				
				<div>
				
				
				<ul>
					<li><a href="#">Description</a></li>
				</ul>
				<div>
					<div>
					<div>
						<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.</p>
<ul>
<li><strong>Discounted</strong>&nbsp;<strong>Price</strong> that will grow as the book does,</li>
<li>All code examples in <strong>Rust</strong>,</li>
<li><strong>Rust (Jupyter) Notebooks</strong> for each Section,</li>
<li>Supplementary <strong>Video Tutorials</strong>,</li>
<li>Format: <strong>PDF download</strong>,</li>
<li><strong>Unlimited</strong> downloads and access to updates.</li>
</ul>
<p>Get it now to enhance your work in Rust, NDArray, Data Science, Data Analysis, and Machine Learning.</p>

					</div><!-- .et_pb_tab_content" -->
				</div>
				</div> <!-- .et_pb_all_tabs -->
			</div> <!-- .et_pb_tabs -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row_inner -->
			</div> <!-- .et_pb_column -->
				</div> <!-- .et_pb_row -->
				
			</div> <!-- .et_pb_section --> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				 <!-- .et_pb_text --><p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/shahin_square.jpg" alt="" title="shahin_square" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square.jpg 288w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-150x150.jpg 150w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-100x100.jpg 100w" sizes="(max-width: 288px) 100vw, 288px"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><p>Dr. Shahin Rostami is a <a href="http://staffprofiles.bournemouth.ac.uk/display/srostami" target="_blank" rel="noopener noreferrer">Senior Academic (Associate Professor)</a> and <a href="https://www.linkedin.com/in/shahinrostami/" target="_blank" rel="noopener noreferrer">Consultant</a> in Data Science and Artificial Intelligence, with applications in the areas of Healthcare and Defence.</p>
<p>As a <a href="https://www.heacademy.ac.uk/system/files/downloads/UK%20Professional%20Standards%20Framework%20%28PSF%29_1.pdf">Senior Fellow</a> of the Higher Education Academy and <a href="https://shahinrostami.com/">Programme Leader</a> for many postgraduate programmes, he aims to contribute openly available learning resources through this website and his <a href="https://www.youtube.com/shahinrostami" target="_blank" rel="noopener noreferrer">YouTube channel</a>.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Dr. Rostami writes and maintains the works published and offered through this website. You can expect ongoing updates and support through the communication channels listed below.</p>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/author-icon-03-2.png" alt="" title=""></span>
			</p><div>
				
				
				<div><p>The aim is to generate everything in this book through code! This means you’ll see the code for all the figures and tables, including things like flowcharts.</p>
<p>Every section is intended to be independent and <span jsslot=""><span data-dobid="hdw">reproducible</span></span>, so you’ll find some repetition as you progress from one section to another.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h2>10% discount on books.</h2>
<p>Join the newsletter to receive book and software updates, as well as discounts and occasional freebies! Your email will only used for this newsletter.</p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_code --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column --> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
		    </div></div>]]>
            </description>
            <link>https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314170</guid>
            <pubDate>Sat, 05 Dec 2020 12:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std::visit is everything wrong with modern C++ (2017)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 206 (<a href="https://news.ycombinator.com/item?id=25314126">thread link</a>) | @xucheng
<br/>
December 5, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fiancée cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let’s talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let’s say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods—e.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on—but this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It’s called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let’s take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we’ll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn’t make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we’re given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm—<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That’s a bit better, but the standard library doesn’t provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We’ll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11’s <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don’t like any of these options, you could
use C++17’s compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about—and grok—the new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you’re an experienced C++ developer,
but several are certainly “advanced” features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn’t to disparage the folks on the ISO C++ committee
who picked this approach.
I’ve had beers with some of them,
and they’re smart, kind, hardworking people.
I’m sure that I’m missing important context since I’ve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider’s perspective, the disparity in complexity between the
problem being solved (“What’s in here?”)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other…
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn’t</em> to
make it a tool for the masses, shouldn’t it be?)
The very least C++17 could do—if the committee didn’t have the time or resources
to get pattern matching into the language—is provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I’d assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don’t flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it’s completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they’re looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I’m also not here to claim that C++ is too complicated for its own good,
but it’s certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I’m sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it’s hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There’s a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you’ll quickly realize that
metaprogramming needn’t require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you’ll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>—which themselves have been a breath of fresh air—are
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That’s a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn’t going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I’ll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they’re worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
“If you can’t program in a language with ugly warts, maybe C++ isn’t the language
you should be programming in.”</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314126</guid>
            <pubDate>Sat, 05 Dec 2020 12:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Down Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25314066">thread link</a>) | @lelf
<br/>
December 5, 2020 | https://greydanus.github.io/2020/12/01/scaling-down/ | <a href="https://web.archive.org/web/*/https://greydanus.github.io/2020/12/01/scaling-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <div>

  

  <article>
  

<div>
    <div>
    <video id="demoDisplay">
    	<source src="https://greydanus.github.io/assets/scaling-down/construction.mp4" type="video/mp4">
    </video>
    <p>Constructing the MNIST-1D dataset. As with the original MNIST dataset, the task is to learn to classify the digits 0-9. Unlike the MNIST dataset, which consists of 28x28 images, each of these examples is a one-dimensional sequence of points. To generate an example, we begin with 10 digit templates and then randomly pad, translate, add noise, and transform them as shown above.</p>
  	</div>
</div>





<p>By any scientific standard, the Human Genome Project <a href="https://deepblue.lib.umich.edu/handle/2027.42/62798">was enormous</a>: it involved billions of dollars of funding, dozens of institutions, and over a decade of accelerated research. But that was only the tip of the iceberg. Long before the project began, scientists were hard at work assembling the intricate science of human genetics. And most of the time, they were not studying humans. The foundational discoveries in genetics centered on far simpler organisms such as peas, molds, fruit flies, and mice. To this day, biologists use these simpler organisms as genetic “minimal working examples” in order to save time, energy, and money. A well-designed experiment with Drosophilia, such as <a href="https://pubmed.ncbi.nlm.nih.gov/10746727/">Feany and Bender (2000)</a>, can teach us an astonishing amount about humans.</p>

<p>The deep learning analogue of Drosophilia is the MNIST dataset. A large number of deep learning innovations including <a href="https://jmlr.org/papers/v15/srivastava14a.html">dropout</a>, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">convolutional networks</a>, <a href="https://arxiv.org/abs/1406.2661">generative adversarial networks</a>, and <a href="https://arxiv.org/abs/1312.6114">variational autoencoders</a> began life as MNIST experiments. Once these innovations proved themselves on small-scale experiments, scientists found ways to scale them to larger and more impactful applications.</p>

<p>They key advantage of Drosophilia and MNIST is that they dramatically accelerate the iteration cycle of exploratory research. In the case of Drosophilia, the fly’s life cycle is just a few days long and its nutritional needs are negligible. This makes it much easier to work with than mammals, especially humans. In the case of MNIST, training a strong classifier takes a few dozen lines of code, less than a minute of walltime, and negligible amounts of electricity. This is a stark contrast to state-of-the-art vision, text, and game-playing models which can take months and <a href="https://arxiv.org/abs/2004.08900">hundreds of thousands of dollars</a> of electricity to train.</p>

<p>Yet in spite of its historical significance, MNIST has three notable shortcomings. First, it does a poor job of differentiating between linear, nonlinear, and translation-invariant models. For example, logistic, MLP, and CNN benchmarks obtain 94, 99+, and 99+% accuracy on it. This makes it hard to measure the contribution of a CNN’s spatial priors or to judge the relative effectiveness of different regularization schemes. Second, it is somewhat large for a toy dataset. Each input example is a 784-dimensional vector and thus it takes a non-trivial amount of computation to perform hyperparameter searches or debug a metalearning loop. Third, MNIST is hard to hack. The ideal toy dataset should be procedurally generated so that researchers can smoothly vary parameters such as background noise, translation, and resolution.</p>

<p>In order to address these shortcomings, we propose the MNIST-1D dataset. It is a minimalist, low-memory, and low-compute alternative to MNIST, designed for exploratory deep learning research where rapid iteration is a priority. Training examples are 20 times smaller but they are still better at measuring the difference between 1) linear and nonlinear classifiers and 2) models with and without spatial inductive biases (eg. translation invariance). The dataset is procedurally generated but still permits analogies to real-world digit classification.</p>

<div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_a.png"></p><p>Constructing the MNIST-1D dataset. Like MNIST, the classifier's objective is to determine which digit is present in the input. Unlike MNIST, each example is a one-dimensional sequence of points. To generate an example, we begin with a digit template and then randomly pad, translate, and transform it.</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_b.png"></p><p>Visualizing the performance of common models on the MNIST-1D dataset. This dataset separates them cleanly according to whether they use nonlinear features (logistic regression vs. MLP) or whether they have spatial inductive biases (MLP vs. CNN). Humans do best of all. Best viewed with zoom.</p>
  </div>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/tsne.png">
  </p>
  <p>Visualizing the MNIST and MNIST-1D datasets with tSNE. The well-defined clusters in the MNIST plot indicate that the majority of the examples are separable via a kNN classifier in pixel space. The MNIST-1D plot, meanwhile, reveals a lack of well-defined clusters which suggests that learning a nonlinear representation of the data is much more important to achieve successful classification. Thanks to <a href="https://twitter.com/hippopedoid">Dmitry Kobak</a> for making this plot.</p>
</div>

<h2 id="example-use-cases">Example use cases</h2>

<p>In this section we will explore several examples of how MNIST-1D can be used to study core “science of deep learning” phenomena.</p>

<p><strong>Finding lottery tickets.</strong> It is not unusual for deep learning models to have ten or even a hundred times more parameters than necessary. This overparameterization helps training but increases computational overhead. One solution is to progressively prune weights from a model during training so that the final network is just a fraction of its original size. Although this approach works, conventional wisdom holds that sparse networks do not train well from scratch. Recent work by <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a> challenges this conventional wisdom. The authors report finding sparse subnetworks inside of larger networks that train to equivalent or even higher accuracies. These “lottery ticket” subnetworks can be found through a simple iterative procedure: train a network, prune the smallest weights, and then rewind the remaining weights to their original initializations and retrain.</p>

<p>Since the original paper was published, a multitude of works have sought to explain this phenomenon and then harness it on larger datasets and models. However, very few works have attempted to isolate a “minimal working example” of this effect so as to investigate it more carefully. The figure below shows that the MNIST-1D dataset not only makes this possible, but also enables us to elucidate, via carefully-controlled experiments, some of the reasons for a lottery ticket’s success. Unlike many follow-up experiments on the lottery ticket, this one took just two days of researcher time to produce. The curious reader can also <a href="https://bit.ly/3nCEIaL">reproduce these results</a> in their browser in a few minutes.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a2.png">
  </p>
  <p>Finding and analyzing lottery tickets. In <b>a-b)</b>, we isolate a "minimum viable example" of the effect. Recent work by <a href="https://arxiv.org/abs/1906.02773">Morcos et al (2019)</a> shows that lottery tickets can transfer between datasets. We wanted to determine whether spatial inductive biases played a role. So we performed a series of experiments: in <b>c)</b> we plot the asymptotic performance of a 92% sparse ticket. In <b>d)</b> we reverse all the 1D signals in the dataset, effectively preserving spatial structure but changing the location of individual datapoints. This is analogous to flipping an image upside down. Under this ablation, the lottery ticket continues to win.</p>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b2.png">
  </p>
    <p>Next, in <b>e)</b> we permute the indices of the 1D signal, effectively removing spatial structure from the dataset. This ablation hurts lottery ticket performance significantly more, suggesting that part of the lottery ticket's performance can be attributed to a spatial inductive bias. Finally, in <b>f)</b> we keep the lottery ticket sparsity structure but initialize its weights with a different random seed. Contrary to results reported in <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a>, we see that our lottery ticket continues to outperform a dense baseline, aligning well with our hypothesis that the lottery ticket mask has a spatial inductive bias. In <b>g)</b>, we verify our hypothesis by measuring how often unmasked weights are adjacent to one another in the first layer of our model. The lottery ticket has many more adjacent weights than chance would predict, implying a local connectivity structure which helps gives rise to spatial biases.</p>
</div>

<p>You can also visualize the actual masks selected via random and lottery pruning:
<br></p>





<p><strong>Observing deep double descent.</strong> Another intriguing property of neural networks is the “double descent” phenomenon. This phrase refers to a training regime where more data, model parameters, or gradient steps can actually <em>reduce</em> a model’s test accuracy<sup id="fnref:fn1" role="doc-noteref"><a href="#fn:fn1">1</a></sup> <sup id="fnref:fn2" role="doc-noteref"><a href="#fn:fn2">2</a></sup> <sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3">3</a></sup> <sup id="fnref:fn4" role="doc-noteref"><a href="#fn:fn4">4</a></sup>. The intuition is that during supervised learning there is an interpolation threshold where the learning procedure, consisting of a model and an optimization algorithm, is just barely able to fit the entire training set. At this threshold there is effectively just one model that can fit the data and this model is very sensitive to label noise and model mis-specification.</p>

<p>Several properties of this effect, such as what factors affect its width and location, are not well understood in the context of deep models. We see the MNIST-1D dataset as a good tool for exploring these properties. In fact, we were able to reproduce the double descent pattern after a few hours of researcher effort. The figure below shows our results for a fully-connected network and a convolutional model. We also observed a nuance that we had not seen mentioned in previous works: when using a mean square error loss, the interpolation threshold lies at \(n * K\) model parameters where \(n\) is the number of training examples and \(K\) is the number of model outputs. But when using a negative log likelihood loss, the interpolation threshold lies at \(n\) model parameters – it does not depend on the number of model outputs. This is an interesting empirical observation that may explain some of the advantage in using a log likelihood loss over a MSE loss on this type of task. You can reproduce these results <a href="https://bit.ly/2UBWWNu">here</a>.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_a.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_b.png">
  </p>
  <p>Observing deep double descent. MNIST-1D is a good environment for determining how to locate the interpolation threshold of deep models. This threshold is fairly easy to predict in fully-connected models but less easy to …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greydanus.github.io/2020/12/01/scaling-down/">https://greydanus.github.io/2020/12/01/scaling-down/</a></em></p>]]>
            </description>
            <link>https://greydanus.github.io/2020/12/01/scaling-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314066</guid>
            <pubDate>Sat, 05 Dec 2020 12:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Smart TV is probably ignoring your PiHole]]>
            </title>
            <description>
<![CDATA[
Score 400 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25313776">thread link</a>) | @giuliomagnifico
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313776</guid>
            <pubDate>Sat, 05 Dec 2020 11:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[72% of smart TVs and 46% of game consoles hardcode DNS settings]]>
            </title>
            <description>
<![CDATA[
Score 459 | Comments 596 (<a href="https://news.ycombinator.com/item?id=25313480">thread link</a>) | @boramalper
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313480</guid>
            <pubDate>Sat, 05 Dec 2020 10:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make slides with text, markdown, YAML, JSON or JavaScript, your call]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25313347">thread link</a>) | @abusedmedia
<br/>
December 5, 2020 | https://play.presenta.cc/v2 | <a href="https://web.archive.org/web/*/https://play.presenta.cc/v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://play.presenta.cc/v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313347</guid>
            <pubDate>Sat, 05 Dec 2020 10:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Between two Lisps]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25313311">thread link</a>) | @galfarragem
<br/>
December 5, 2020 | https://ane.github.io/2020/10/05/between-two-lisps.html | <a href="https://web.archive.org/web/*/https://ane.github.io/2020/10/05/between-two-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Out of all Lisps the ones I’ve come to appreciate the most are <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a> and <a href="https://common-lisp.net/">Common
Lisp</a>. <!--break-->These two languages are fundamentally very different: Scheme
is a minimalist language built on the foundations of <a href="https://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a>, while
Common Lisp is a multi-paradigm synthesis of many Lisps before it. Common Lisp
is a large standard with many implementations, Scheme is a collection of an
evolving but minimalistic standard with many implementations. The core of Scheme
is quite small compared to Common Lisp. The latest standard <a href="http://www.r6rs.org/final/r6rs-lib.pdf">R6RS</a> is about 65
pages, while the ANSI Common Lisp standard from 1994 is about 1100 pages. The
<a href="https://srfi.schemers.org/">Scheme Requests for Implementation</a> process aims to standardize additional
features (like <a href="https://srfi.schemers.org/srfi-64/srfi-64.html">test suites</a>) that implementations may implement.</p>

<p>Common Lisp has some wonderful features, <a href="http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html">conditions and restarts</a>, the <a href="https://lispcookbook.github.io/cl-cookbook/clos.html">Common
Lisp Object System (CLOS)</a>, <a href="http://www.paulgraham.com/onlisp.html">the macro system</a>, among many other things. The <a href="http://joaotavora.github.io/sly/">SLY
IDE for Emacs</a> is <em>amazing</em>, and the <a href="http://www.sbcl.org/">Steel Bank Common Lisp</a> compiler is really
great. It has <a href="https://www.quicklisp.org/index.html">Quicklisp</a> and <a href="https://common-lisp.net/project/asdf/">ASDF</a> for package and build management,
respectively. I find the developer experience of Common Lisp to be superior to
almost anything imaginable, and this is not an empty statement: having used all
sorts of IDEs and editors for over 25 years, I have seen <em>many</em>.</p>

<h3 id="tastes-differ">Tastes differ</h3>

<p>That said, Common Lisp is <em>weird</em>. What I find particularly jarring is that
functions and variables live in different namespaces: if you put a function into
a variable, you can’t just use it like a function, you have to <code>funcall</code> it.
Having programmed in lots of languages of the ML family this is just, well, odd;
but this is due to historical reasons and there are <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">sound technical reasons for
it</a>.  There are other
oddities, some strange things like <code>(cdr '())</code> is not an error (in Scheme it
is), <code>()</code> and <code>nil</code> are equal (in Scheme <code>#f</code> and <code>()</code> are separate things), and
so on.</p>

<p>This isn’t really a fault in Common Lisp: other languages have impacted my taste
and preferences to bias me in the direction of Scheme, but that is not to say I
cannot work with Common Lisp’s idiosyncracies. Actually, I don’t mind them, I
just <em>notice</em> them.</p>

<p>I like the naming styles of Scheme more, as well. It has <code>string?</code> vs <code>string-p</code>
for predicate functions, <code>set!</code>  for state modifying functions, <code>foo-&gt;bar</code> for
conversions, these make code quite easier to read. Scheme has hygienic macros,
Guile has the traditional <code>defmacro</code> as well.</p>

<p>Many nice Scheme features are available in Common Lisp libraries. Pattern match
is available in the <a href="https://github.com/guicho271828/trivia">trivia</a> library. Named lets are easy to implement with a macro.</p>

<p>Common Lisp aficionados are quick to point out things Scheme <em>doesn’t</em> have:
keyword arguments, docstrings, rest arguments, but my Scheme implementation of
choice Guile has these built into the language.</p>

<h3 id="productivity-matters">Productivity matters</h3>

<p>Guile is in a strange niche is that its primary <em>raison d’être</em> is to be an
extension language for the GNU project. Like Emacs Lisp is for extending Emacs,
Guile is the <em>de facto</em> language for GNU programs for extension and scripting.</p>

<p>Guile doesn’t have Quicklisp and its package manager and build system is
basically nonexistent for the first and <a href="https://www.gnu.org/software/autoconf/">Autoconf</a> for the second. There is
<a href="https://lists.gnu.org/archive/html/guile-user/2017-03/msg00168.html">sentiment</a> in the Guile community to have <a href="https://guix.gnu.org/">Guix</a> as the package manager for
Guile. This might sound a bit onerous, since Guix is also a complete package
management for many other things than Guile, but consider this: as Andy Wingo
points out in his message that Guile libraries often come with C extensions,
Guile packages need some sort of managed build system for building the C
extensions. Since it doesn’t have one, to solve the problem of building a
package manager you’d also have to build a build system that can manage C code
and packages needed by the C code bits. To do this elegantly is a gargantuan
task, for instance, <a href="https://wiki.call-cc.org/man/5/Extensions#installing-eggs-that-use-libraries">chicken-install just asks you to put compiler/linker flags
on the command line before calling it</a>, so it obviously is a hard problem.</p>

<p>Now, Guix solves all that, and more, in a manner that is quite elegant and
interesting. But it’s not as lightweight as something like Quicklisp or
<a href="https://wiki.call-cc.org/man/5/Extensions"><code>chicken-install</code></a> from <a href="http://call-cc.org/">CHICKEN Scheme</a>. What is more, Guix works only on GNU/Linux
systems really, so macOS and Windows users won’t be able to do use your library
if you plan on distributing it via Guix. Duh, it’s the GNU project, but
portability is always nice.</p>

<p>But in Common Lisp I can write <code>(ql:quickload :alexandria)</code> and voilà, it will
automatically install the <a href="http://quickdocs.org/alexandria/">Alexandria</a> library that I can use. Then again, in
Common Lisp it’s somewhat rarer to have C extensions, so I don’t know how ASDF
handles that.</p>

<p>It is unfair to compare <a href="http://joaotavora.github.io/sly/">SLY</a> to <a href="https://www.nongnu.org/geiser/">Geiser</a>, the best Emacs Scheme integration
package.  SLY is based on <a href="https://common-lisp.net/project/slime/">SLIME</a> which has <em>decades</em> of man-years of work behind
it. Geiser is able to support multiple Scheme implementations and it is quite
impressive in this regard. But SLY obviously has much more (e.g. an interactive
debugger). That said, Geiser has nice Guile support, and Guile is in general the
most Common Lisp-y of all Schemes, in fact, it has</p>

<ul>
  <li>an imitation of CLOS in the form of <a href="https://www.gnu.org/software/goops/">GOOPS</a></li>
  <li>docstrings and keyword, rest, and optional arguments for function
definitions</li>
  <li>an interactive REPL and a mutable top-level (unlike many Schemes)</li>
  <li>a nice module system</li>
  <li><a href="https://www.gnu.org/software/guile/manual/html_node/Defmacros.html"><code>defmacro</code></a> and exceptions somewhat <a href="https://www.gnu.org/software/guile/manual/html_node/Raising-and-Handling-Exceptions.html">similar to Common Lisp restarts </a></li>
</ul>

<p>and some nice things Common Lisp doesn’t have like first-class
continuations. But then again I would use those rarely.</p>

<h3 id="when-would-i-pick-one-over-the-other">When would I pick one over the other?</h3>

<p>If I were to write an extensible C/C++/Rust program that I <em>know</em> will need to use
a low-level language, I might do the low level bits using a low level language
and then write the rest in Guile. Guile makes it very easy to spin up a REPL
socket to do something like <code>myprogram --repl=12345</code> that you can connect to, and
the interop between C and Guile is fantastic, it has to be, as it’s primarily an
extension language.</p>

<p>On the other hand, if were to build a wholly standalone application, the choice is
not as obvious. I could do the whole thing in either language. Common Lisp can
build native executables, although their size will be large (who cares?) since
the binary will include the whole Lisp implementation. Guile cannot compile to
native code so you’ll have to write a script executable, but that doesn’t really
matter.</p>

<p>Scenarios where I would pick Guile:</p>

<ul>
  <li>when I’m making an extensible program that has to have some C/C++ bits but I
want to make it scriptable by users</li>
  <li>when I want to write a native binary but not write too much C/C++ code</li>
  <li>I just want to write Scheme, because Scheme is a bit more elegant</li>
  <li>the project has something to do with the <a href="https://www.gnu.org/software/autoconf/">GNU project</a></li>
</ul>

<p>On the other hand, Common Lisp makes the most sense if I just want to enjoy a
seriously rapid development experience, a large standard library and language,
and I don’t mind having 50MB binaries (again, who cares?) if I were to write
standalone programs. Guile can’t do that, but it’s easy to either write Guile
scripts or a C program that essentially bootstraps a binary to load a Scheme
runtime. This is how <a href="http://lilypond.org/">LilyPond</a> is written, for example.</p>

<p>So the answer to which one is decidedly <strong>both</strong>! Both languages are really fun to
write. At the moment I don’t do Lisp at my day job so it’s all for fun
anyway. If this were for professional purposes, I don’t know. Very often a
strict requirement for professional work is to be able to be productive. In that
regard I think Common Lisp has a significant edge, not only due to its superior
development experience, but its history as a real production language. There are
actual companies doing stuff in Common Lisp. I have not heard of any
professional (in the industrial sense) uses of Guile, notwithstanding that many
projects powered by Guile (Guix, etc.)  are <em>extremely</em> professional in the way
they are written and maintained. But Common Lisp has <em>more</em> libraries and
companies behind it.</p>

<h3 id="what-about-clojure">What about Clojure?</h3>

<p>I’ve actually had the pleasure to use Clojure for personal fun, and a little bit
of professional use. I wrote a couple of libraries (<a href="https://github.com/ane/vigil">vigil</a> and <a href="https://github.com/ane/task">task</a>) and my
experience with has always been positive and its development experience is
excellent. Clojure isn’t a true Lisp, or well, it is part of the <em>Lisp
family</em>. Its ability to interface with the JVM makes it easy to leverage the
thousands of JVM libraries out there.</p>

<p>I’d gladly do it again, though I feel that Common Lisp with CLOS and its module
system makes it somewhat easier to practice <a href="https://en.wikipedia.org/wiki/Programming_in_the_large_and_programming_in_the_small"><em>programming in the large</em></a>. Clojure
explores interesting territories with <a href="https://clojure.org/guides/spec">spec</a>, so it is interesting to see what
direction the language will take in the future.</p>

<h3 id="final-words-emacs-lisp">Final words: Emacs Lisp</h3>

<p>There’s also a parenthetical elephant in the room here: Emacs Lisp! An old
descendant of <a href="https://en.wikipedia.org/wiki/Maclisp">MacLisp</a>, it’s actually quite fun to write, and the fact that Emacs
itself is the interpreter, you have superb introspectability for any Elisp
code. Most of the Lisp I write these days is probably Emacs Lisp. It’s very
close to Common Lisp. <a href="https://www.gnu.org/software/emacs/manual/html_mono/cl.html#Overview">cl-lib</a> adds a sufficient amount of convenience from
Common Lisp to make Elisp writing quite enjoyable. <a href="https://www.gnu.org/software/emacs/manual/html_mono/eieio.html#Top">EIEIO</a> adds a subset of CLOS
that can be used seamlessly with cl-lib. The condition system is missing.</p>

<p>I’ve also done a fair bit of <a href="https://fennel-lang.org/">Fennel</a>, a Lisp that compiles to Lua. I used it to
write a <a href="https://github.com/ane/mudrally">small game</a> and it was fun to write since you could develop the game in a
REPL.</p>

<p>All in all, Lisp in all its variants is the most fun I’ve ever had while
programming a computer. Guile and Common Lisp are definitely the most fun I’ve
had programming in <em>Lisp</em>.</p>

  </div></div>]]>
            </description>
            <link>https://ane.github.io/2020/10/05/between-two-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313311</guid>
            <pubDate>Sat, 05 Dec 2020 10:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maybe we shouldn't want a fully decentralized web]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 415 (<a href="https://news.ycombinator.com/item?id=25312854">thread link</a>) | @talhah
<br/>
December 5, 2020 | https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spent a large part of 2019 working with the distributed and decentralized web, especially IPFS, also known as the “Inter-Planetary File System”. I’ve written a few articles on the topic, on how you can host a web app on IPFS, one of which even ended up on the front page of HackerNews.</p><p>For about a year, I hosted my blog and other apps through an IPFS cluster. I wrote a utility for making pinning files easier on Pinata, a third-party cloud service for IPFS. I made some small contributions to the IPFS core projects. I built some projects with it, including one that I never released–nor fully completed–that used both IPFS and Ethereum. And I even gave a talk about hosting static web apps on IPFS at Node+JS Interactive last December in Montreal.</p><p>That all changed in the Spring of 2020. I called myself out of the distributed web.</p><p>My blog and other apps I built aren’t hosted on IPFS anymore. I don’t participate in those online communities anymore. I’ve stopped writing about the distributed and researching about it. I’ve shelved all my projects that were using those technologies.</p><p>I also updated my blog posts about IPFS adding a note that my blog isn’t hosted that way anymore. More than a few people asked me why, and I always gave the same answer: a mix of technical issues and mostly personal reasons. So, I think it’s time I explain the personal reasons.</p><p>First, I need to explain why I got involved with IPFS in the first place.</p><p>When I first read about IPFS, my mind immediately saw it as an exciting new platform I could build my apps for. The premise of a fully-decentralized platform included unlimited scalability, ultra-high availability and resiliency, no single points of failure, and resistance against attacks like DDoS.</p><p>Coming from a background in which I am always thinking about SLAs, number of nines of uptime, disaster recovery, etc, IPFS sounded like a dream platform that would magically solve all my concerns. And, aside from some performance issues at times, it did. Plus, the small engineer inside me was really excited about being able to play with a new, shiny toy, that had lots of hype around it!</p><p>What happened next for me was a reckoning with the reality of what many people behind the IPFS core project and the community around it saw: the dream of a radically open, unfiltered, and by-design un-censorable platform.</p><p>I have recently opened up about my experience, over a decade ago, with building an app with good intentions but that was then misused (<a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html"><em>That time I accidentally built a spying app</em></a>). I learned early on in my life and (pre-)professional career about the importance of ethics in software development, and I am now a proponent of the idea that just because something <em>can</em> be built, it doesn’t mean it <em>should</em> be built.</p><p>And that brings me back to why, after spending some time in the world of the decentralized web, I have called myself out, and why I think that should things like IPFS actually become mainstream, they might cause more harm than good in the world.</p><p><strong>I have seen, and I am seeing every day, the dangers of completely unrestricted speech, and I don’t want to be the one enabling that.</strong></p><p>I know that last sentence is a strong ideological statement; some might call it a <em>political</em> statement, but for me it’s more than just political, which is often used to describe extemporary beliefs.</p><p>Many of you reading this will not agree with me, and that’s fine. I’m not going to try and change your beliefs with this blog post. Rather, I’m looking to explain why, while I respect that others might have differing opinions, I stopped doing anything that would actively advance a technology whose ethics I question. To put it in other terms: your freedom of speech isn’t my obligation to enable you and give you a platform.</p><p>In short, I think that while the Internet has helped the world in countless of ways, it has also brought out the worst in people.</p><p>I do believe we need some filters on the Internet. It’s not just about stopping criminal activities, terrorism and child pornography: while I am obviously unsupportive of all them, I also think they’re not the biggest dangers coming from the Internet (yet they’re a very convenient pretext for politicians).</p><p>Instead, I think that regular people’s writings on the Internet is hurting the world on a bigger scale. And the collective sentiment is often manipulated by some “agitators” that are exploiting anonymous online speech for their own agendas: that includes online militias–for example sponsored by foreign governments–whose goal is to destabilize a society.</p><p>In the last few years, completely unregulated online speech has given rise to fake news and conspiracy theories that have actually killed people. It’s offered a megaphone to those promoting dangerous ideas like white supremacy, Islamophobia, anti-Semitism, homophobia and other anti-LGBTQ positions, and sometimes outright Nazism. It has tilted many democracies towards right-wing populism and fascism.</p><p>All these extreme ideas have divided societies and increased social tensions. And they’re responsible for a number of acts of terrorism which caused the death of too many people.</p><p>Given our experiences so far, there’s no sign that indicates that a fully decentralized and unrestrained web would be anything but a dangerous wild west.</p><p>In fact, despite being tightly centralized and controlled, social media companies are facing significant challenges regulating what people write on their platforms, and in fact they are usually at the center of every scandal of these years. Decentralization and less control won’t be the solution to this issue, but rather the opposite.</p><p>If you believe that I’m overthinking this, and that it’s not going to be bad <em>this time</em>, I urge you to think twice.</p><p>First, there’s no indication that a new Web would be better than the previous one just on virtue of being decentralized. The same actors that are using today’s Internet to wreak havoc around the world would not disappear in the new Internet, and actually, they could be even more unrestrained.</p><p>Second, while almost everyone in the communities supporting a distributed web are good people, with good intentions, seeing some names in there is concerning to me. Regarding IPFS, advocates (at least for a while) included people like Nick Lim of BitMitigate and VanwaNet, companies responsible for rescuing, among others, <a href="https://www.geekwire.com/2017/seattles-bitmitigate-now-protecting-pro-nazi-site-daily-stormer-web-attacks/">pro-nazi website</a> The Daily Stormer <a href="https://arstechnica.com/information-technology/2019/11/breaking-the-law-how-8chan-or-8kun-got-briefly-back-online/">and the platform</a> 8chan, a cesspool full of Nazi propaganda, child pornography, and other hate speech. Gatherings on 8chan have been <a href="https://en.wikipedia.org/wiki/8chan#2019_shootings">blamed</a> for at least three mass shootings in 2019 alone, including the one in the <a href="https://time.com/5648479/8chan-ban-new-zealand/">mosque in Christchurch</a>, all of them motivated by racial hatred.</p><p>The first real examples of the distributed web aren’t particularly encouraging either. Among some of the most popular apps (“popular” in relative terms, of course) for the distributed web is DTube, a sort of YouTube that is built on top of IPFS. As you can expect, the website is full of questionable content, including conspiracy theories, cryptocurrency scams, weapons, RT&nbsp;International’s <a href="https://www.theguardian.com/commentisfree/2019/jul/26/russia-disinformation-rt-nuanced-online-ofcom-fine">Russian propaganda</a>… and of course, porn.</p><p>In essence, if it’s true that <em>a good beginning makes a good ending</em>… with such a mixed beginning, the outlook isn’t too rosy.</p><p>I understand that my opinion is somehow a minority one, and people will continue to build IPFS and other technologies part of the distributed web. There’s also a chance they might become successful and potentially get mainstream adoption–although at this stage the barrier to entry is too high for the average user.</p><p>However, I feel that it’s my responsibility to not be helping to advance this technology and the beliefs of at least some advocates in the world of the distributed web hold. If the advancement occurs, it won’t be because of my help.</p><hr><p><em>PS: The idea that freedom of speech is an absolute right that should have (almost) no limitations is not a universal one. While that right is granted to people living in all democratic countries, outside of North America it’s accepted that such right comes <a href="https://www.nytimes.com/2019/08/06/world/europe/el-paso-shooting-freedom-of-speech.html">with limitations</a>, and usually that has roots in the history of those places.</em></p><p><em>For example, in Italy where I grew up, the same constitution that grants freedom of expression (speech, press, etc) also criminalizes “apology of fascism”, or propagating the ideas of fascism; it also sets other limits on speech that is hateful or discriminatory. Other European countries have similar laws, such as the outlawing of Nazi rhetoric and symbology in Germany.</em></p></article></div>]]>
            </description>
            <link>https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312854</guid>
            <pubDate>Sat, 05 Dec 2020 08:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Tire-pressure monitoring system Sensors: Let's try a DoS attack]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25312714">thread link</a>) | @pabs3
<br/>
December 4, 2020 | http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack | <a href="https://web.archive.org/web/*/http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <td>&nbsp; &nbsp;</td>

  <!-- left column -->
  <td>

<!--
   <p>
   <br />
   <b>About</b> <br />
   Dieter Spaar's blog, Dieter Spaar's personal Blosxom blog.<br /><br />
   Dieter Spaar<br />
   <a href="mailto:spaar@mirider.com">spaar@mirider.com</a> <br />
   </p>
-->

   <p>
   <a href="http://www.mirider.com/weblog/index.rss">RSS</a>
   </p>

   <p>
     <b>Dieter's Web</b> <br>
     <a href="http://www.mirider.com/">mirider.com</a><br>
   </p>

   <p>
   <b>Projects I am participating</b> <br>
    <a href="http://bb.osmocom.org/" target="_blank">OsmocomBB</a><br>
    <a href="http://openbsc.osmocom.org/" target="_blank">OpenBSC</a><br>
    
   </p>

   <p>
   <b>Categories</b> <br>
   </p>
   <ul>
<li><a href="http://www.mirider.com/weblog/index.html">Root</a> (24)
<ul>
<li><a href="http://www.mirider.com/weblog/automotive/index.html">automotive</a> (3)
</li>
<li><a href="http://www.mirider.com/weblog/gsm/index.html">gsm</a> (17)
</li>
<li><a href="http://www.mirider.com/weblog/misc/index.html">misc</a> (1)
</li>
<li><a href="http://www.mirider.com/weblog/sdr/index.html">sdr</a> (2)
</li>
</ul>
</li>
</ul>


   <p>
   <b>Archives</b> <br>
   </p>
   <ul>
	<li><a href="http://www.mirider.com/weblog/2020/">2020</a> (1)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2020/12/index.html">December</a> (1)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2018/">2018</a> (5)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2018/09/index.html">September</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/05/index.html">May</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/03/index.html">March</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/01/index.html">January</a> (2)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2013/">2013</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2012/">2012</a> (4)
	</li>
	<li><a href="http://www.mirider.com/weblog/2011/">2011</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2010/">2010</a> (8)
	</li>
</ul>


<!--
   <p>
   <b>Flavours</b> <br />
   There's more than one way to view this weblog; try these flavours on
   for size.
    <li><a href="http://www.mirider.com/weblog/index.index">index</a></li>
    <li><a href="http://www.mirider.com/weblog/index.1993">circa 1993</a></li>
    <li><a href="http://www.mirider.com/weblog/index.rss">RSS</a></li>
   </p>
-->
   <p>
   <b>Other Bloggers</b> <br>
    <a href="http://laforge.gnumonks.org/weblog/" target="_blank">Harald Welte</a><br>
    <a href="http://openbts.blogspot.com/" target="_blank">David Burgess</a><br>
   </p>

<!--
   <p>
   
   </p>
-->

   <p>
    <br>
    <a href="http://www.blosxom.com/"><img src="http://mirider.com/weblog/pb_blosxom.gif" alt="blosxom"></a>
   </p>

   <p>
    <br>
    <a href="http://www.mirider.com/#Site%20Contact">Contact/Impressum</a>
   </p>

  </td>

  <td>&nbsp; &nbsp;</td>

  <td>&nbsp; &nbsp;</td> 

  <!-- main blog entry column -->
  <td> 

   <br>

<span>Fri, 04 Dec 2020</span>
<div>
<p><a name="20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack"><b>Modern TPMS Sensors: Let's try a DoS attack</b></a></p><p>
TPMS (Tire-pressure monitoring system) sensors have been researched extensively
many years ago, they periodically transmit the tire pressure, temperature
and a unique ID which can be misused for tracking a vehicle. But there is
another aspect: modern TMPS sensors also have a receiver which is typically
used to trigger the data transmission when a new TPMS sensor is presented to
the vehicle ("learning procedure").
</p>

<p>
Here in Europe TPMS sensors usually transmit on the 433 MHz ISM band. The
receiver operates on 125 kHz, very similar to LF RFID. A simple way to make
use of the receiver is just to look for the presence of the 125 kHz carrier
and then trigger data transmission. Current sensors are usually more evolved
and use a modulated carrier which contains command packets and only if the
correct command is received data transmission is triggered.
</p>

<p>
If you already have a receiver you can do of course more than just trigger
data transmission: For example there might be support for different
commands, some sensors even allow firmware updates this way.
</p>

<p>
One such command which is typically supported is switching the sensor into
"Shipping" mode. Why would you need that? When the sensor is operating
normally it waits for motion (there is an acceleration/shock sensor inside)
and only starts periodic data transmission when the wheel is rotating. This
is used to safe battery life. When the TPMS sensor is not yet mounted in the
tire it should not react on motion, that’s why there is this "Shipping" mode.
In this mode the sensor only wakes up every few seconds and looks if there
is a 125 kHz signal, if yes it checks for a valid command, for example the
command to trigger data transmission which usually also leaves "Shipping"
mode and switches the sensor into normal operation.
</p>

<p>
This "Shipping" mode can be misused: If you can switch a TPMS sensor of a
vehicle’s wheel into "Shipping" mode the sensor will no longer transmit data
and the vehicle's tire pressure control light will go on after a while.
Just to make it clear: This warning light is annoying to the driver, it
does not affect safety of the car because the deactivated TMPS sensor has
not affected the actual tire pressure.
</p>

<p>
I have looked at a few TPMS sensors for different cars if this really works,
I choose sensors for BMW and Ford cars. Please note that most certainly
other car manufactures are affected too, mainly because there are only a
few manufactures of TPMS sensors which deliver their sensors to various
car manufactures. My choice for BMW and Ford came from the fact that I
found lots of cheap, used sensor for those cars.
</p>

<p>
Also I only looked at "OEM" sensors for BMW and Ford, which means that those
sensors are mounted by the car manufacturer. There are also so called
"Universal" sensors which are typically mounted by tire dealers, there
are some notes about them at the end of this text.
</p>

<p>
It is quite easy to build a tool for transmitting data on 125 kHz: There
is this cheap EL-50448 TMPS sensor activation tool which only transmits a
carrier without modulation. However the hardware can easily be modified
to modulate the carrier: Most of the time OOK (On-Off Keying) is used
for communication, which means that the carrier is just turned on and off.
The EL-50448 uses a power driver with an unused "enable" pin to generate
the carrier, you can use this "enable" pin to modulate the carrier. The
data rate is slow, a frequently used rate is 3900 baud.  Most of the time
Manchester encoding of the data bits is used, which means that the carrier
changes twice as much (7800 changes per second). This is nothing special
and can be done with probably any microcontroller you prefer to use. The
hardware costs for such a setup are below EUR 20, the transmission range
is about 20 centimeters.
</p>

<p>
How can you find the command to switch to Shipping" mode? Brute force by
trying all possible commands is only an option if the command is short.
The reason is that the sensor only looks for the LF 125 kHz signal every
few seconds. If the command is not longer than two bytes brute force is
possible (it takes a few days), for longer commands it is impractical.
Please note that you also have to find a way to detect if the command you
send causes a reaction of the TPMS sensor, e.g. by monitoring the power
consumption of the sensor or receiving the 433 MHz data signal (which of
course only works if the command you send causes a data transmission).
</p>

<p>
Another option is looking at those TPMS tools which tire dealers and
car repair workshops use to check TPMS sensors. Some of those tools
might support switching a TPMS sensor into "Shipping" mode.
</p>

<p>
Those are the results I found (I won't go into the details to avoid misuse):
</p>

<ul>
<li><b>BMW:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. Also if the sensor detects a
  fast pressure change (e.g. by inflating the tire) the sensor leaves
  "Shipping" mode. The command length is four bytes so brute force is no option. 

</li>

<li><b>Ford:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" (the same manufacture as above for the BMW sensor) can be switched
  into "Shipping" mode, it is the same command as used by the BMW sensor
  from above. The deactivated TPMS sensor can be activated again with a
  different command.
  
  A certain sensor used in several car models from TPMS Sensor manufacturer
  "B" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. The command in this case is
  only two bytes and I tried all combinations which resulted in several more
  "interesting" commands, a few examples:


    <ul>
<li>
      It is possible to completely turn off the TPMS sensor. In this case it
      will no longer react on anything, you have to break open the sensor
      case and apply a hardware reset or disconnect the battery to reactivate
      it again.
</li>

<li>
      It is possible to switch the sensor into continuous "carrier transmit"
      mode on 433 MHz. In this mode the sensor will continuously transmit
      the 433 MHz carrier until the battery is empty or you apply a hardware
      reset (see above), it will not react on anything else. There are two
      other similar commands which transmit on the upper and lower shifted
      frequency (the sensor uses FSK modulation, Frequency Shift Keying, when
      transmitting data).
</li>
</ul>      

  Those examples show that it is basically possible to destroy this specific
  sensor by transmitting the appropriate command. Also if the sensor is in
  "carrier transmit" mode it probably disturbs the remote control car
  key fob which usually uses the same frequency as the TPMS sensor.
</li>
</ul>

<p>
You have to be close to the sensor to send those LF 125 kHz signals but it
only takes a few seconds to send the signal. Using a larger antenna (which is
basically a coil) for the transmitter, e.g. large enough to fit in a suitcase,
might extend the transmission range to more than a meter. 
</p>

<p>
How can those problems be avoided? This is actually quite easy, the command
to switch into "Shipping" mode should not be allowed if the measured tire
pressure is above a certain limit, which means that the sensor is mounted in
the tire of a vehicle. This also applies to those other commands of the sensor
from manufacturer "B" which are probably some kind of factory test or developer
commands. Please note that during my tests the commands I described were
possible even when the measured tire pressure was in the range of a typical
vehicle wheel.
</p>

<p>
I contacted the car manufactures (BMW and Ford) before I published this
article, this is the experience I made:
</p>

<ul>
<li>
  <b>BMW:</b>
  The contact information for reporting security issues can be found on
  the BMW website. I had a phone call with the responsible person within
  a few days after reporting the issue. BMW already knew the problem, they
  found it during an internal review. Their latest TPMS sensors have fixed
  the issue by blocking certain commands if the tire pressure is above a
  certain limit.
</li>

<li>
  <b>Ford:</b>
  I wasn't able to find a security contact on the website of Ford Germany
  so I contacted the person responsible for "Public Relation". He promised
  to look for someone who takes care of the issue I reported, after several
  days I got a reply that it is possible to disturb the TPMS system due to
  the nature of radio transmission and that this is a known problem. I wasn't
  able to communicate directly with the responsible person and I then replied
  that the reported issue is not about disturbance but a "Denial of Service"
  and that it is even possible to destroy a certain TPMS sensor used in Ford
  cars. I didn't receive any further information about the security issue, I
  notified them again after several weeks that I am now going to publish
  the issue which was acknowledged.
</li>
</ul>

<p>
Some notes about those "Universal" sensors tire dealers normally use: Those
sensors are "Universal" because they can be programmed for different car
models. The main benefit for the tire dealer is that only a few different
kind of "Universal" sensors have to be on stock, it’s not necessary to have
lots of different "OEM" TPMS sensors for every possible car model lying
around. The programming of those …</p></div></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</a></em></p>]]>
            </description>
            <link>http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312714</guid>
            <pubDate>Sat, 05 Dec 2020 07:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Manpages Like a Pro (2018)]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25311867">thread link</a>) | @woodruffw
<br/>
December 4, 2020 | https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jan 22, 2018</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h3 id="preword">Preword</h3>

<p>I often reference the <a href="https://en.wikipedia.org/wiki/Man_page">manpages</a> when giving a development
presentation or talk, but I’ve only recently come to realize how few people are both <em>comfortable</em>
with the <code>man</code> interface and adept at discovering information through it.</p>

<p>This post is my attempt to share some of the tricks and techniques I’ve picked up over years of
reading manpages.</p>

<h2 id="a-quick-recap">A Quick Recap</h2>

<p>The manpages (short for “manual pages”) are the oldest and longest-running documentation collection
on *nix, stemming back to the
<a href="https://www.bell-labs.com/usr/dmr/www/1stEdman.html">first edition of the Unix Programmer’s Manual</a>
in 1971.</p>

<p>On a modern system, the <code>man</code> command is the most common way to access the manpages:</p>

<div><div><pre><code><span># access the first manpage named "time", which happens to be time(1)</span>
man <span>time</span>

<span># access a specific section's "time", in this case the C time function</span>
man 2 <span>time</span>

<span># attempt to access a nonexistent "time" in section 5</span>
man 5 <span>time</span>
</code></pre></div></div>

<p>Because the manpages were originally published on paper, they were (and continue to be) typeset with
<a href="https://en.wikipedia.org/wiki/Troff"><code>troff</code></a> on most systems. Today, the <code>man</code> command (and other
manpage readers) invoke <code>troff</code> internally and pipe the output to the user’s
<a href="https://en.wikipedia.org/wiki/Terminal_pager">pager</a> (like <code>more</code> or <code>less</code>).</p>

<p>In fact, a very simple manpage reader (which only works with section 1) can be implemented with
just three commands pipelined together:</p>

<div><div><pre><code><span>function </span>myman <span>{</span>
    <span># `-t` and `-e`: run `tbl` and `eqn` on the input, for tables and equations</span>
    <span># `-mandoc`: use a set of troff macros specifically for manpages</span>
    <span># `-Tutf8`: output UTF-8 text rather than PostScript</span>
    <span>gunzip</span> &lt; /usr/share/man/man1/<span>"</span><span>${</span><span>1</span><span>}</span><span>.1.gz"</span> | groff <span>-t</span> <span>-e</span> <span>-mandoc</span> <span>-Tutf8</span> | less
<span>}</span>

myman gcc
myman <span>ls</span>
</code></pre></div></div>

<p>Apart from their simplicity and adherence to the UNIX philosophy, <code>man</code> and the manpages serve a
number of important roles:</p>

<ul>
  <li>
    <p>They provide a categorization: section 1 is for system commands, 2 for system calls, 3 for library
functions, and so forth. This categorization is followed both by the system itself (which populates
several of the sections) and by programs installed by the user or package manager.</p>
  </li>
  <li>
    <p>They provide offline documentation: <code>man</code> doesn’t require an internet connection, and can provide
much of the documentation that an internet search would yield.</p>
  </li>
  <li>
    <p>They offer <em>canonical</em> information: searching for a command or function online might tell you
whether it exists, but won’t tell you the flags, arguments, or behavior specific to your system.
For example, <code>man ls</code> will tell you whether your system’s <code>ls</code> is BSD or GNU (and the differences
therebetween). The manpages (on Linux) will also tell you which feature macros you’ll need to define
in a C program in order to use a function (or a variant of a function).</p>
  </li>
</ul>

<p>So, let’s move on to some techniques.</p>

<h2 id="colorized-manpages">Colorized manpages</h2>

<p>One of the simplest things you can do to enhance the readability of manpages within <code>man</code> is to
colorize the pager’s output:</p>

<p><img src="https://blog.yossarian.net/assets/gcc_man.png" alt="A colorized version of `man gcc`"></p>

<p>In <code>less</code>, this is accomplished by setting the <code>LESS_TERMCAP_*</code> environment variables to your
preferred ANSI color codes. Here are the variables you can set:</p>

<div><div><pre><code>LESS_TERMCAP_mb <span># blinking mode (not common in manpages)</span>
LESS_TERMCAP_md <span># double-bright mode (used for boldface)</span>
LESS_TERMCAP_me <span># exit/reset all modes</span>
LESS_TERMCAP_so <span># enter standout mode (used by the less statusbar and search results)</span>
LESS_TERMCAP_se <span># exit standout mode</span>
LESS_TERMCAP_us <span># enter underline mode (used for underlined text)</span>
LESS_TERMCAP_ue <span># exit underline mode</span>
</code></pre></div></div>

<p>You may be able to set others corresponding to the
<a href="https://www.gnu.org/software/termutils/manual/termcap-1.3/html_chapter/termcap_5.html">termcap capability names</a>,
but the variables above should cover all of your manpage needs.</p>

<p>By way of example, here is the <code>bash</code> function I use to colorize my manpages:</p>

<div><div><pre><code>man<span>()</span> <span>{</span>
    <span>env</span> <span>\</span>
    <span>LESS_TERMCAP_mb</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_md</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_me</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_se</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_so</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;44;33m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_ue</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_us</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;32m"</span><span>)</span><span>"</span> <span>\</span>
    man <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
<span>}</span>
</code></pre></div></div>

<p>Note that you don’t need to use escape sequences as above — <code>tput</code> will work just fine.</p>

<h2 id="other-sections">Other sections</h2>

<p>I mentioned some of the big sections above: 1 for system commands, 2 for system calls, and so on.</p>

<p>90% of <code>man</code> lookups will be in those three, but there are a few lesser-known sections that can also
be useful:</p>

<ul>
  <li>
    <p><code>man 4</code> - Special files and devices</p>

    <p>On Linux, section 4 is used to document special files, usually representing some aspect of
  the machine or its peripherals. For example, <code>man 4 mem</code> will tell you how to use the
  <code>/dev/mem</code>, <code>/dev/kmem</code>, and <code>/dev/port</code> files to read from and write to the system’s main
  memory.</p>
  </li>
  <li>
    <p><code>man 5</code> - Configuration files and formats</p>

    <p>You probably know the <code>/etc/shadow</code> file, but do you know how its format is specified?
  <code>man 5 shadow</code> will tell you that. Similarly, <code>man 5 deb</code> describes the <code>.deb</code> package format,
  and <code>man 5 ppm</code> lists the spec for <a href="https://en.wikipedia.org/wiki/Netpbm_format">PPM images</a>.</p>
  </li>
  <li>
    <p><code>man Np</code> - POSIX pages</p>

    <p>These pages come in handy for contrasting POSIX behavior with the system’s behavior.</p>

    <p>Some examples:</p>

    <div><div><pre><code>  <span># compare the system ls (on Linux, GNU) to the POSIX ls behavior</span>
  man 1 <span>ls
  </span>man 1p <span>ls</span>

  <span># compare the read syscall to the POSIX read function</span>
  <span># note the categorization: POSIX read is a function, not a syscall!</span>
  man 2 <span>read
  </span>man 3p <span>read</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="searching-and-navigating">Searching and navigating</h2>

<p>Like colorization, searching is more of a general <code>less</code> feature than one specific to <code>man</code>. That
being said, <code>less</code>’s searching and navigating features can make browsing the manpages a much faster
and more pleasant experience.</p>

<p>Searches in <code>less</code> can be forwards or backwards, using the <code>/</code> and <code>?</code> commands respectively. The
search syntax is mostly POSIX ERE, but with some additions (<code>man less</code> has the details!).</p>

<p>For example, to find the first instance of “x86” in <code>man gcc</code> (watch the bottom of the screen for
the search prompt):</p>

<p><a href="https://asciinema.org/a/Wc0OiKVTrTDiP4tG9bPRWtDwM" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wc0OiKVTrTDiP4tG9bPRWtDwM.png">
</a></p>

<p>Observe that instances of the search term are highlighted with the standout colors from before.</p>

<p>Once a search term is entered, its results can be navigated via the <code>n</code> and <code>N</code> commands, which
move forwards and backwards in the results list respectively. For example, going through all
of the results for “Windows”:</p>

<p><a href="https://asciinema.org/a/n3S3wteHmbdPrtmyTSkCSVMiX" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_n3S3wteHmbdPrtmyTSkCSVMiX.png">
</a></p>

<p>When the last result has been jumped to, the statusbar changes to “Pattern not found”. Once that
happens, as in the video above, previous results can be returned to by hitting <code>N</code>.</p>

<p>Even this can be simplified: the <code>&amp;</code> command can be used to display only lines that match the given
pattern. For example, retrieving every line that contains either “ARM” or “ABI”:</p>

<p><a href="https://asciinema.org/a/Wh8QZ4eideLNmCMBmAkYExgEm" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wh8QZ4eideLNmCMBmAkYExgEm.png">
</a></p>

<p>The effect is more dramatic when searching for the definition of a flag (in this case <code>-D</code>):</p>

<p><a href="https://asciinema.org/a/17Kcnb8PBNIz8JdogOFKVeDQn" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_17Kcnb8PBNIz8JdogOFKVeDQn.png">
</a></p>

<p>These commands are just the tip of the iceberg — <code>less</code> supports searching multiple files at
once, jumping around scopes (opening and closing parentheses, braces, brackets), and marking the
current location for later return. Each of these is documented on the help screen, which you can
get to in any <code>less</code> session via the <code>h</code> command:</p>

<p><a href="https://asciinema.org/a/8i6kyFTbFttVTgDNbgnzyJvGB" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_8i6kyFTbFttVTgDNbgnzyJvGB.png">
</a></p>

<h2 id="wrapup">Wrapup</h2>

<p>Before picking up these tricks (especially searching), the manpages were an item of last resort
for me: I would search the internet or ask a friend, with mixed results. I had no real idea how to
use <code>less</code>, and would just clumsily page around until I found what I was looking for. More often
than not, I would give up entirely.</p>

<p>At the end of the day, the manpages (and the <code>man</code> interface) are not perfect — there’s no
hyperlinking or real cross-referencing, and the entire corpus is written in a 45+ year old
typesetting language designed for <em>physical</em> output, not display in a virtual terminal.</p>

<p>That being said, they’re a <em>fantastic</em> initial resource for pretty much anything concerning your
system — they remain up-to-date (unlike blogs and articles), they’re accurate and concise, and
they’re <em>very</em> UNIX-y (text files and pipelines!).</p>

<hr>

<h3 id="addendum">Addendum</h3>

<p>This post was discussed on <a href="https://news.ycombinator.com/item?id=25311867">HN</a>; a response
by <a href="https://news.ycombinator.com/item?id=25313405">‘djeiasbsbo</a> includes some additionally
useful tricks and advice.</p>


<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311867</guid>
            <pubDate>Sat, 05 Dec 2020 04:53:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Poker Hands Geometrically]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25311545">thread link</a>) | @chairmanwow1
<br/>
December 4, 2020 | https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands | <a href="https://web.archive.org/web/*/https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  
<p>An interesting way for getting an intuitive sense for why <a href="https://en.wikipedia.org/wiki/Poker_probability" title="Poker hand probabilities">certain hands</a> are rare in poker, I've laid out all the cards in a standard deck in a grid:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/blank_1024x1024.png?v=1607133617" alt="Array of Playing Cards" width="1024x1024" height="1024x1024">
</p>


<p>When I first learned to play poker, it took a while before I could get an intuitive understanding of the relationships between the various poker hands. Calculating their likelihood definitely helped get a handle on how many ways for a specific hand to actually occur there were.</p>

<p>Nonetheless, I think laying the hands out in a grid like this would have given me an intuitive understanding of the game much more quickly.&nbsp;</p>
<h2>Poker Hands shown geometrically</h2>
<p>So the lowest poker hand, high card, is the most common happening 50% of the time, but will rarely be the winning hand:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/High_Card_1024x1024.png?v=1607134813" alt="High Card" width="1023" height="1023"></p>

<p>The next highest hand is a single pair which has a geometric interpretation of one column with two dots in it:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Pair_1024x1024.png?v=1607134853" alt="Pair" width="1024x1024" height="1024x1024"></p>

<p>Two pair has a similar flair to it, except this one has 2 vertical lines:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Two_Pair_1024x1024.png?v=1607134962" width="1024x1024" height="1024x1024"></p>

<p>Three of a kind is similar in spirit, but is much rarer than the two preceding hands happening once every 50 hands:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/three_of_a_kind_1024x1024.png?v=1607135086" alt="3 of a kind" width="1024x1024" height="1024x1024"></p>

<p>For a straight, we need 5 cards that are in order without any gaps and can look kind of like a nice scatter plot:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_1024x1024.png?v=1607135179" alt="Straight" width="1024x1024" height="1024x1024"></p>

<p>A flush requires all 5 cards in the hand to be in a single horizontal row, but there can gaps between them:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/flush_84512f1f-428d-4ed7-b703-9372fc3575d6_1024x1024.png?v=1607135233" alt="Flush" width="1024x1024" height="1024x1024"></p>

<p>A full house requires that all points be split into two lines of 3 and 2 points each:</p>

<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/full_house_1024x1024.png?v=1607135454" alt="Full House" width="1024x1024" height="1024x1024"></p>

<p>Four of a Kind requires a vertical line that spans the entire grid with an extra point tucked away somewhere:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/4_of_a_kind_1024x1024.png?v=1607135655" alt="4 of a kind" width="1024x1024" height="1024x1024"></p>

<p>A straight flush is one of the tidiest hands as it requires all cards to be colinear on the same row and be immediately adjacent to each other:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_flush_1024x1024.png?v=1607135809" alt="Straight Flush" width="1024x1024" height="1024x1024"></p>

<p>The best hand that you can get is a subset of all the straight flushes that you can get. It's just a straight flush all the way against the right side of the grid with the 5 highest cards:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Royal_Flush_1024x1024.png?v=1607135877" alt="Royal Flush" width="1024x1024" height="1024x1024"></p>


<p>Looking at poker this way made me realize that there are some interesting hands that we could add to the game.&nbsp;</p>
<h2>Rectangle</h2>
<p>This hand is formed when you have 4 points that are <a href="https://mathworld.wolfram.com/Collinear.html" title="Mathematical Definition of colinearity">colinear</a> in both orthogonal axes (form a rectangle):&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Rectangle_1024x1024.png?v=1607136065" alt="Rectangle Hand" width="1024x1024" height="1024x1024"></p>

<h2>Flower</h2>
<p>This one seems like it would be complicated to spot in the wild, but in reality it's a lot like a full house. You need a Three of a Kind and the other two cards need to be the same suit as one of your 3oK cards, and just before and after it. So, maybe it is a little complicated to spot, but it certainly is an interesting idea.&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Screen_Shot_2020-12-04_at_18.42.56_1024x1024.png?v=1607136337" alt="Flower Hand" width="1024x1024" height="1024x1024"></p>

<h2>Want More?</h2>
<p>If you found this interesting, you'll probably love the 3D reconstruction we did of <a href="https://evermontbills.com/pages/walter-white-did-not-have-80m" title="Walter White's Cash Pile Counting">Walter White's cash pile</a> in order to count it.&nbsp;</p>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311545</guid>
            <pubDate>Sat, 05 Dec 2020 03:48:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Microsoft crushed Slack]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310547">thread link</a>) | @theBashShell
<br/>
December 4, 2020 | https://www.platformer.news/p/how-microsoft-crushed-slack | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/how-microsoft-crushed-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg&quot;,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1771463,&quot;alt&quot;:&quot;Image of Slack running on a laptop. Muhammed Abiodun / Unsplash&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt="Image of Slack running on a laptop. Muhammed Abiodun / Unsplash"></a><figcaption>(Muhammed Abiodun / Unsplash)</figcaption></figure></div><p>Slack’s life as an underdog darling of Silicon Valley ended on November 2, 2016. That’s when the upstart communication startup <a href="https://www.theverge.com/2016/11/2/13497766/slack-microsoft-teams-new-york-times-ad">published an open letter to Microsoft in the </a><em><a href="https://www.theverge.com/2016/11/2/13497766/slack-microsoft-teams-new-york-times-ad">New York Times</a></em>, offering the tech giant an insincere “welcome” to the world of workplace chat software. The occasion was <a href="https://www.theverge.com/2016/10/25/13405200/microsoft-teams-slack-competitor-launch">Microsoft’s launch of Teams</a>, a Slack clone that would come bundled with the company’s popular Office 365 suite of products.</p><p>In its letter, Slack warned Microsoft that “Slack is here to stay,” adding: “we’re just getting started.” But the 4 million users it had at the time would increase to just 12 million four years later, while Microsoft — which added Teams to its 365 bundle without increasing the price — <a href="https://www.theverge.com/2020/10/27/21537286/microsoft-teams-115-million-daily-active-users-stats">took Teams from zero to 115 million users</a>. </p><p>That disparity helps to explain why <a href="https://www.nytimes.com/2020/12/01/technology/salesforce-slack-deal.html">Slack sold itself this week to Salesforce</a>. The deal, which values Slack at $27.7 billion on revenues of $833 million over the past year, has largely been greeted with cheers. (Ben Thompson <a href="https://stratechery.com/2020/salesforce-acquires-slack-salesforces-reasoning-salesforces-opportunity/">offers a typically excellent rundown of the opportunity here for both Salesforce and Slack</a>.)</p><p>But it also feels like the end of an era — one where workers gained new power to bring their own tools to the office, and decide for themselves how they wanted to get work done. Slack first succeeded with small teams who wanted to accelerate their work, and was often dragged into organizations by early adopters. But today, waves of consolidation are leaving people with fewer real choices.</p><p>The rise of smart phones in the early 2010s brought with it a new surge of workplace productivity tools that made mincemeat of everything that had come before them. Box and Dropbox brought easy file storage and sharing. Evernote introduced the idea of ubiquitous, cloud-synchronized note-taking. Sunrise created a more social calendar, while Mailbox and Acompli reimagined email for the mobile phone.</p><p>Slack tiptoed into the conversation in the middle of the decade, and almost immediately became the fastest-growing enterprise software tool of all time. In 2015, just 18 months after it launched, <a href="https://www.theverge.com/2015/6/24/8836087/slack-1-million-daily-users">Slack reported having more than 1 million daily users</a> —&nbsp;a figure then unheard-of in enterprise software.</p><p>It had a great backstory —&nbsp;a last-ditch pivot from a failed video game called Glitch —&nbsp;and, in Stewart Butterfield, one of the tech world’s most charming founders. It also had a bold pitch: it was going to “kill email” —&nbsp;or, at the very least, reduce your reliance on it. And it would do so by integrating hundreds of other services into real-time work chat, creating a kind of all-knowing command console for your organization.</p><p>The company embodied the belief, so common in Silicon Valley, that the best product would win in the end. “Building a product that allows for significant improvements in how people communicate requires a degree of thoughtfulness and craftsmanship that is not common in the development of enterprise software,” the company wrote in its open letter to Microsoft. “How far you go in helping companies truly transform to take advantage of this shift in working is even more important than the individual software features you are duplicating.”</p><p>And yet if there’s a lesson of the past four years, it’s that thoughtfulness and craftsmanship only got the company about 10 percent as far as Microsoft did by copy-pasting Slack’s basic design. In its open letter, Slack famously told Microsoft: “You’ve got to do this with love.” In 2020, looking at Slack’s size, the idea seems laughable. What’s love got to do with it?</p><p>The thing is, I <em>hate</em> that this was the outcome for Slack. I love good productivity tools, and was rooting for Slack to someday become as good as the company hyped it up to be. (And perhaps it still will: like most giants Salesforce has a mixed track record when it comes to the success of its acquisitions, but some seem to be thriving. When I asked about this on Twitter, people had <a href="https://twitter.com/caseynewton/status/1333891286185644032?s=21">a lot of good things to say about post-acquisition Heroku</a>.)</p><p>But Slack’s struggle to succeed as an independent company sadly mirrors that of many one-time innovators in enterprise productivity. Mailbox died and Acompli sold to Microsoft, where it became the mobile Outlook app. Evernote is a pale shadow of its former self. Of that early cohort, only Box and Dropbox became — and still remain —&nbsp;public companies.</p><p>Why is this the case? To get some insight, I called up Aaron Levie, Box’s affable CEO. In Levie’s telling —&nbsp;and he also wrote <a href="https://blog.box.com/salesforce-slack-and-future-work">a blog post about the Slack sale</a> — it all comes down to sales. The idea that workers would someday choose all their own tools was always a fantasy, he told me, in part because most workers don’t event want to think about their tools. In such a world, the winning app will almost always be one with a giant, er, salesforce behind it. </p><p>Microsoft had one. Slack didn’t. Enter Salesforce.</p><p>“The reality with the enterprise is that you can have the best product, but that’s not good enough,” Levie told me. “You need distribution. And what Salesforce has — they have the procurement officers, they have the finance people. They have all of the apparatus you need to interact with to sell software, and they have it for the top 100,000 corporations around the world.”</p><p>Levie is bullish on the acquisition, because it puts Slack and Salesforce on more even ground. </p><p>“The only advantage Microsoft has is distribution, and so now they’ve neutralized the advantage that Microsoft has had,” he said. “All of a sudden, they can actually fulfill the ultimate promise of the opportunity, because they have 10 times the amount of salespeople that can go distribute this thing into corporations around the world.”</p><p>Assuming Levie is right — and I wouldn’t bet against him — that means the medium-term future of work is increasingly a choice between three giants: Microsoft, Salesforce, and (in a distant third) Google. And with that, the golden age of worker choice in productivity tools seems to be coming to an end.</p><p>That’s not to say that the incumbents won’t always face new challengers. But I wonder whether the low ceiling that Slack turned out to have has implications for some of the other fast-growing productivity companies of the current moment. Should Slack’s sale diminish our expectations for Airtable, or Notion, or Coda? Don’t get me wrong — I’m confident their investors will all get their money back, and then some. But do they have a real future outside the arms of a monolith?</p><p>If not, then the productivity market will become as consolidated as any number of other spaces on the internet, from app stores to search engines to social networks. And as our government antitrust regulators begin to awaken after a long period of hibernation, I wonder if they’ll have anything to say about it.</p><h3>The Ratio</h3><p><em>Today in news that could affect public perception of the big tech companies</em></p><p>⬆️ <strong>Trending up</strong>: <strong><a href="https://techcrunch.com/2020/12/02/google-news-showcase-paywalled-stories/">Google</a></strong><a href="https://techcrunch.com/2020/12/02/google-news-showcase-paywalled-stories/">’s new paid deals with publishers mean that access to some paywalled content will now be available to readers for free</a>. Good for publishers, good for Google, good for democracy. (Anthony Ha / <em>TechCrunch</em>)</p><p>🔃 <strong>Trending sideways: <a href="https://www.geekwire.com/2020/microsoft-will-remove-user-names-productivity-score-feature-privacy-backlash/">Microsoft </a></strong><a href="https://www.geekwire.com/2020/microsoft-will-remove-user-names-productivity-score-feature-privacy-backlash/">made changes to the “productivity score” feature in its 365 platform, which gave employers fine-grained data on individual employees’ use of email, chat, and other features</a>. Critics called it “full-fledged workplace surveillance tool;” Microsoft says it will now detach the data from individual employee names.  (Todd Bishop / <em>GeekWire</em>) </p><p>🔃 <strong>Trending sideways:</strong> <strong><a href="https://www.theinformation.com/articles/amazon-drops-pandemic-test-to-track-warehouse-workers-through-wi-fi?utm_source=twitter&amp;utm_medium=page">Amazon </a></strong><a href="https://www.theinformation.com/articles/amazon-drops-pandemic-test-to-track-warehouse-workers-through-wi-fi?utm_source=twitter&amp;utm_medium=page">abandoned a test of a worker safety measure that involved tracking the location of warehouse workers through their personal cell phones</a>. Big week for pushback on worker surveillance initiatives! (Mark Di Stefano / <em>The Information</em>)</p><p>⬇️ <strong>Trending down</strong>: <strong><a href="https://www.theverge.com/2020/12/2/22047383/google-spied-workers-before-firing-labor-complaint">Google</a></strong><a href="https://www.theverge.com/2020/12/2/22047383/google-spied-workers-before-firing-labor-complaint"> illegally spied on workers before firing them, according to a new lawsuit by the National Labor Relations Board</a>. Two employees were fired for looking at their colleagues’ calendars as part of an organizing effort. Google says it didn’t do anything wrong. (Zoe Schiffer / <em>The Verge</em>)</p><h3>Governing</h3><p>⭐ <strong><a href="https://www.washingtonpost.com/technology/2020/12/01/trump-repeal-section-230-ndaa/">In a pair of late-night tweets, President Trump</a></strong><a href="https://www.washingtonpost.com/technology/2020/12/01/trump-repeal-section-230-ndaa/"> threatened to veto the defense reauthorization act if Congress does not repeal Section 230 of the Communications Decency Act</a>. But it’s <a href="https://www.protocol.com/Politics/trumps-section-230-veto-threat">not clear he has the leverage to make it happen</a>. (Tony Romm /  <em>Washington Post</em>)</p><p><a href="https://www.washingtonpost.com/politics/2020/12/02/technology-202-aclu-sues-dhs-over-purchase-cellphone-location-data-used-track-immigrants/">The ACLU sued the Department of Homeland Security over its purchase of cellphone location data to track immigrants</a>. Separately, the department’s inspector general said he would investigate the matter after Senate Democrats began asking questions. (Cat Zakrzewski / <em>Washington Post</em>)</p><p><a href="https://techcrunch.com/2020/12/01/massachusetts-votes-to-pass-statewide-police-ban-on-facial-recognition/">Massachusetts passed a statewide ban on the use of facial recognition technology by police</a>. It may be the largest US ban of facial recognition tech yet, and is part of a growing patchwork of laws regulating it around the country. (Taylor Hatmaker and Zack Whittaker / <em>TechCrunch</em>)</p><p><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">EveryAction</a></strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">, a </a><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">Salesforce</a></strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">-like platform for liberal campaigns and causes, acquired the organizing company </a><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">Mobilize</a></strong>. The move bolsters what Bloomberg calls “the central nervous system for practically all of Democratic politics.” (Joshua Green / Bloomberg)</p><p><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html">Amid rising tensions between China and Australia, </a><strong><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html">WeChat</a></strong><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html"> deleted the Australian prime minister’s response to a fabricated image sent by a Chinese foreign affairs official</a>. <strong>Twitter</strong> left the post up. (Eryk Bagshaw, Anthony Galloway and Shane Wright / <em>Sydney Morning Herald</em>)*</p><p>* <em>The description of this item has been corrected from an earlier, incorrect characterization</em>.</p><h3>Industry</h3><p>⭐ <strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Facebook</a></strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/"> teamed up with former employees of popular game developer </a><strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Telltale</a></strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/"> for </a><em><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Rival Peak</a></em><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">, a new reality show where viewers will influence the story</a>. It feels … maybe a little too high-concept? We’ll see. Gene Park had the details at the <em>Washington Post</em>:</p><blockquote><p><em>Rival Peak</em> is a Facebook Watch program in which artificial intelligence-driven “contestants” will live, work and exist for every minute of the day within the fictional region of Rival Peak, a mountainous forest region that emulates the Pacific Northwest. With a diverse cast of internationally-based characters, …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.platformer.news/p/how-microsoft-crushed-slack">https://www.platformer.news/p/how-microsoft-crushed-slack</a></em></p>]]>
            </description>
            <link>https://www.platformer.news/p/how-microsoft-crushed-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310547</guid>
            <pubDate>Sat, 05 Dec 2020 01:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25310462">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310462</guid>
            <pubDate>Sat, 05 Dec 2020 00:52:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I accidentally built a spying app]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25310316">thread link</a>) | @akeck
<br/>
December 4, 2020 | https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In the fall of 2007, my parents gave me an unforgettable gift for my sixteenth birthday: a first-generation iPhone.</p><p>I still clearly remember watching the keynote in which Steve Jobs announced the first Apple-branded phone a few months earlier. As a teenager attending high school in my hometown of Vicenza, Italy, I tuned into the livestream just before dinner, carefully listening to every word he said. That evening, Jobs started announcing a “widescreen iPod with touch controls”, a “revolutionary mobile phone” and a “breakthrough Internet communications device”–theatrically pausing before confessing that he was actually talking about one single device: the iPhone. Thousands of miles away from me, you could hear attendees exploding cheerfully through the live feed. Jobs went on demoing this amazing invention that, a decade later, would end up changing much more than the mobile phones market: it directly or indirectly impacted our society through mobile web, app stores, changing work-life balance, and social media.</p><p>October came, and so did the day I finally got my iPhone. I was really excited as I was the first one in my social circle with one. Every other teenager (and adult!) that saw my phone reacted in awe and with lots of curiosity. More than a few were also secretly envious, something I secretly did not mind. To add to the novelty, at the time the iPhone was only available for sale in the US.</p><p>To get an iPhone for me, my father had to ask a friend traveling to New York on a business trip to bring one back on the plane with her. That was not the end of it, however, as all phones were locked to the AT&amp;T network. In order for me to be able to use my iPhone in Italy, I had to unlock it.</p><p>That process required learning a variety of tools and techniques developed by hackers in the community, then documented in various blogs and forums. The first step was to <em>jailbreak</em> the phone, which gave you full access to the system and allowed you to run third-party apps. Then you’d have add one of those “hacking” apps to your phone, which patched the bootloader to remove the lock the US carrier had put on it. Despite sounding like a mouthful, the iPhone hacking community had worked hard on the User Experience (UX), making this entire process relatively easy for most people with basic tech skills.</p><hr><p>I really loved my shiny, new iPhone, and I was so excited about it that I was willing to accept many of its original limitations. It only supported slow 2G networks, didn’t have copy/paste, couldn’t transfer files via Bluetooth to my friends, and <a href="https://www.apple.com/hotnews/thoughts-on-flash/">famously</a> didn’t support Adobe Flash, which was ubiquitous on the web at the time.</p><p>However, there was one thing I really couldn’t stand: the Messages application could only store 1,000 texts (SMS).</p><p>That was 2007 — before the days of WhatsApp, Facebook Messenger, Telegram, etc. Instant messaging was something people did on their PCs only, with things like Windows Live Messenger (née MSN Messenger) or AIM.</p><p>For a high schooler like me, text messaging was the main way I kept in touch with my friends daily (<em>what was I supposed to do, call them?</em>). With my carrier giving me a whopping 100 free texts per day (seriously, we had to pay for them), between sent and received texts it would take less than a week to reach the storage limit of 1,000.</p><p>That’s when it all started.</p><p>Because my iPhone was already “hacked” (jailbroken), as a requirement for unlocking it and use it in Italy, I had full system access already. That allowed me to c extract any document I wanted, including my phone’s text message database.</p><p>It wasn’t even a month since I got my iPhone that I had already built a small “app” running on my laptop to archive my text messages forever. I would manually extract the SMS database from my iPhone, copy it to my laptop, then use a set of scripts written in PHP (the only programming language I knew at the time) to store the messages in a local database, and finally display them using a web-based interface.</p><p>This thing I put together worked just fine for me, but I immediately realized the “business potential” of what I had just created. Just like myself, I assumed many others had the same annoyance. I could have used what I learned to help them too, and maybe make some pocket change in the process. As a matter of fact, I did consider myself an enterprising teenager.</p><p>The idea had potential, and the “app” I built for myself already provided solid foundations, so I just needed to do a bit more work to turn it into a commercially-viable project.</p><p>The biggest challenge was making the solution more accessible to others, including those who were not particularly tech-savvy. That’s when I started learning about app development for iPhone.</p><p>Famously, Apple did not want the iPhone to support third-party apps at the beginning, saying developers should build web apps instead. That policy didn’t last long, and with the iPhone OS 2 update, launched in mid-2008, the official App Store came to life: the rest, as they say, is history.</p><p>However, the hacking community had already found a way to sideload apps and had even developed an “app store” called Cydia where you could find games, apps, and even mods to enhance the capabilities of the operating system itself. Cydia came preinstalled on every <em>jailbroken</em> iPhone, which meant potentially hundreds of thousands of people had access to it.</p><p>Everyone could build apps that would be published on Cydia, as long as you knew how to–something that was not remotely as easy to do as it is with today’s tools. As an enterprising teenager with quite a bit of free time on my hand during those winter afternoons and evenings, I took on that challenge.</p><hr><p>The first version of YouArchive.It came out in January 2008.</p><p>Today, you would describe YouArchive.It as a cloud service to store iPhone text messages. You could store all your messages in there, then read and search them using a web-based application.</p><p>There’s still a video left on YouTube showing the application in action (this was the third, and last, version):</p><p><iframe src="https://www.youtube-nocookie.com/embed/ps5ohEhO3S4" allowfullscreen="" title="YouTube Video"></iframe></p><p>With YouArchive.It came an iPhone application too. Published on the Cydia app store, it allowed importing messages into the “cloud service” directly from the phone.</p><p>YouArchive.It was free to use with a limit of 80,000 text messages. Because personal communications can be sensitive, all messages were stored encrypted. With a one-time payment of just €5 (about $6), you could become a VIP, remove any limit and enjoy unlimited storage.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*vTxYRljXFl3IBXGRsXOVag.png" alt="A screenshot of iTextUploader running on a first-generation iPhone"></p><figcaption>A screenshot of iTextUploader running on a first-generation iPhone</figcaption><p>For the next year and a half, YouArchive.It continued to grow organically. A few blogs and websites dedicated to iPhone “hacking” and to the underground app stores wrote about the app. Even a small radio program in the US featured it</p><p>I continued developing the app as a side project while in high school. I was also providing tech support and maintaining the infrastructure.</p><p>Listening to users' feedback, I would periodically add new features. YouArchive.It started displaying emojis as soon as the iPhone supported that (outside of Japan, it required downloading an app to enable them). Users asked for and got the ability to restore texts in another iPhone, before iCloud was available. I also implemented other privacy features such as requiring a password to open the mobile app.</p><blockquote><h3 id="what-i-didnt-realize-at-the-time-however-is-that-i-had-unknowingly-and-unwillingly-built-a-spying-tool-and-a-really-convenient-and-efficient-one">What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</h3></blockquote><p>Enough users were paying the fee to become VIP that I could cover the costs of running the service–this was before everyone was using Amazon Web Services or Microsoft Azure, so I was renting a co-located physical server which wasn’t cheap–and keep some pocket cash. Not much, but enough to pay for some hobbies and outings with friends.</p><p>Most importantly, building YouArchive.It gave me a lot of satisfaction and the opportunity to learn a lot of things about software development, business, dealing with customers and listening to their feedback.</p><hr><p>When I finally shut the service down, in June 2010, YouArchive.It had about 32,000 registered users who stored over 76 million messages.</p><p>The first, and stated, reason for the deprecation was a technical one: YouArchive.It’s iPhone app required using private APIs, which meant it could not be published on the App Store (and it still couldn’t to this day), limiting it to <em>jailbroken</em> phones only.</p><p>The second reason however was the most important to me, even though I have not revealed it until now.</p><p>About a year before the app closed, in April 2009 I implemented a new feature that was requested by many users: the ability to upload texts automatically, in background, without user intervention. For paying “VIP” users only, the mobile app could automatically send all new text messages to YouArchive.It, as often as every 15 minutes.</p><p>Automatic upload was an incredible convenience for many users that wanted to hoard their texts like me, to keep them forever, search within them, print or export them, or just liked having a backup.</p><p>What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</p><p>Thanks to background uploads, people could install the YouArchive.It app on another person’s iPhone, set it up, maybe even hide it (something possible on a <em>jailbroken</em> iPhone), and then watch as the text messages come in, almost real-time. Jealous partners, stalkers and the likes could install this tool on an unknowing victim’s phone with relative ease.</p><p>I can’t remember how I discovered that — it might have been a support request from a user or a post in a bulletin board. I also can’t know how many people were using YouArchive.It for their own archiving rather than to spy on others. Realizing what my users were doing, however, made me feel really uncomfortable and I did not want any part of that anymore.</p><p>As a senior in high school, barely eighteen years-old, I realized for the first time how technology can have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</a></em></p>]]>
            </description>
            <link>https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310316</guid>
            <pubDate>Sat, 05 Dec 2020 00:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Down Here, They Sometimes Call It 'Boy']]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25308101">thread link</a>) | @pelt
<br/>
December 4, 2020 | https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html | <a href="https://web.archive.org/web/*/https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                            

                                                        <!-- sphereit start -->
                            <!-- startprint -->

                            <!-- end article source sponsored -->

                                                                                                                                                                                                                                                                                                    
                                                                                        
                            
                            
                            
                            
                                
                                
                                                                                        
                                                            <div>
<p><a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4"> <img src="https://assets.realclear.com/images/52/527328_5_.jpg"> </a></p>

<p>Regnery Publishing</p>


</div>
<p><em>The following is an excerpt from "<a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4">Big White Ghetto: Dead Broke, Stone-Cold Stupid, and High on Rage in the Dank Woolly Wilds of the "Real America"</a>" by Kevin D. Williamson.</em></p>
<p>"Dogfood—yeah, <em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>—because it looks like ground-up dog food.” He’s embarrassed to be talking about this. “Or sand, because it’s brown. Or diesel. Or killa or 9-1-1. That’s the influence of rap culture down here.” He is a young, clean-cut, Eagle Scout–ish white kid, hesitant about using the words “rap culture,” like he’s not sure if he’s allowed to say that. But he goes on, matter-of-factly. He’s been off heroin for only a few months, so the details are fresh in his mind, even if he remains a little hazy on parts of his autobiographical timeline. “The 9-1-1, they call it that because they want you to know it’s potent, that you’ll have to go to the emergency room.”</p>
<p>That’s a weird and perverse and nasty kind of advertising, but then dope-buying psychology isn’t very much like Volvo-buying psychology: Crashing is just another part of the ride. One spiteful dealer boasts about spiking his product with excessive amounts of fentanyl—a pharmaceutical analgesic used for burn victims and cancer patients—his plan being to intentionally send overdosed users to the hospital or the morgue . . . for <em>m</em><em>a</em><em>r</em><em>k</em><em>e</em><em>t</em><em>i</em><em>n</em><em>g</em> <em>p</em><em>u</em><em>r</em><em>p</em><em>os</em><em>e</em><em>s</em>. Once the word got out about the hideous strength of his product, that killa went right out the door ricky-tick.</p>
<p>The young man explaining the current vocabulary of opiate addiction in Birmingham is barely old enough to buy a beer, and his face and voice are soft. He describes the past several years of his life: “dope-sick and stealing,” going from job to job—eight jobs in six months—robbing his employers of everything not physically nailed to the floor, alienating his family, descending. He was an addict on a mission: “You’re always chasing that first shot of dope, that first high—and the first one for me almost killed me. I was seventeen or eighteen years old, and I met a guy who had just got out of prison, doing a thirteen-year sentence for heroin possession and distribution. He was staying at the Oak Mountain Lodge, which is a nice little classic place.” (In 2013, four police officers and a drug dog had to be treated for exposure to dangerous chemicals after raiding a suspected meth lab in that hotel; the customer reviews online are decidedly mixed.) “I was <em>snorting </em>heroin when I met up with him, and set him up with my connect. He offered to shoot me up, and I wanted to do it. And I remember him looking me in the eyes and telling me, ‘If you do this, you’ll never stop, and you’ll never go back.’ And I said, ‘Let’s do it.’”</p>
<p>He doesn’t know what happened for the next several hours. When he regained consciousness, his junkie buddy’s girlfriend was worriedly ministering to him.</p>
<p>“That was first thing in the morning,” he says. “That night, I did another one.”</p>
<p>Same results. “I’d nodded out from snorting it, but there’s nothing like shooting it.”</p>
<p>He was, he says, a “pretty good junkie” for a time.</p>
<p>This particular opiate odyssey starts off in a Walgreens, something that turns out to be absolutely appropriate. I’m headed up the south coast and then inland on the heroin highway up to Atlanta, starting from the Port of Houston, which connects that city with 1,053 ports in nearly 200 countries and which in December alone welcomed the equivalent of 63,658 20-foot cargo containers of goods into the United States. There was, the feds are pretty sure, some dope squirreled away in there. In fact, all sorts of interesting stuff comes in and out of Houston. In May, U.S. Customs seized a Fast Attack Vehicle with gun mounts headed to the Netherlands. It hadn’t been ordered by the Dutch military. (Organized crime in the Netherlands is bananas: A raid in the summer of 2020 found Dutch police opening up a shipping container expecting to find it loaded with narcotics or stolen goods, but what they found instead was a dentist’s chair bolted to the floor and handcuffs hanging overhead—it was set up as a mobile torture chamber, God knows why.) I’m at Walgreens because I’ve got a long drive ahead and I’m going to be out of pocket for a bit, and I have a prescription to fill: an honest-to-goodness Schedule II Controlled Substance, in the official nomenclature, a term that covers some pretty interesting stuff, including the oxycodone and fentanyl I’ll be hearing so much about in the next few days. Some of us are going to heaven, some of us are going to hell, but all of us have to stop at Walgreens first.</p>
<p>The clerk is on the phone with a doctor’s office: “What’s your DEA number?”</p>
<p>For working-class white guys who haven’t found their way into the good jobs in the energy economy or the related manufacturing and construction booms that have reverberated throughout the oil patch, who aren’t college-bound or in possession of the skills to pay the bills, things aren’t looking so great: While much of the rest of the world gets healthier and longer-lived, the average life expectancy for white American men without college educations is declining. Angus Deaton, the Princeton economist who won the Nobel Prize in 2015, ran the numbers and found (in a study co-authored by his Princeton colleague Anne Case) that what’s killing what used to be the white working class isn’t diabetes or heart disease or the consumption of fatty foods and Big Gulps that so terrifies Michael Bloomberg, but alcohol-induced liver failure, along with overdoses of opioid prescription painkillers and heroin: Wild Turkey and hillbilly heroin, and regular old heroin, too, the use of which has increased dramatically in recent years as medical and law-enforcement authorities crack down on the wanton overprescription of oxy and related painkillers.</p>
<p>Which is to say: While we were <em>ignoring </em>criminally negligent painkiller prescriptions, we helped create a gigantic population of opioid addicts, and then, when we started paying attention, the first thing we did was take away the legal (and quasi-legal) stuff produced to exacting clinical standards by Purdue Pharma (maker of OxyContin) and others. So: lots of opiate addicts, fewer prescription opiates.</p>
<p>What was left was diesel, sand—<em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>.</p>
<p>The clerks at this Walgreens are super friendly, but the place is set up security-wise like a bank, and that’s to be expected. This particular location was knocked over by a young white man with a gun the summer before last, an addict who had been seen earlier lurking around the CVS down the road. This is how you know you’re a pretty good junkie: The robber walked in and pointed his automatic at the clerk and demanded oxy first, then a bottle of Tusinex cough syrup, and then, almost as an afterthought, the $90 in the till. Walgreens gets robbed a lot: In January, armed men stormed the Walgreens in Edina, Minnesota, and stole $8,000 worth of drugs, mainly oxy. In October, a sneaky young white kid in an Iowa State sweatshirt made off with more than $100,000 worth of drugs—again, mainly oxy and related opioid painkillers, from a Walgreens in St. Petersburg, Florida. Other Walgreens locations—in Liberty, Kansas; East Bradford, Pennsylvania; Elk Grove, California; Kaysville, Utah; Virginia Beach; New Orleans—all have been hit by armed robbers or sneak thieves over the past year or so, and there have been many more oxy thefts.</p>
<p>It won’t make the terrified clerks feel any better, but there’s poetic justice in that: In 2013, Walgreens paid the second-largest fine ever imposed under the Controlled Substances Act for being so loosey-goosey in handling oxy at its distribution center in Jupiter, Florida, that it enabled untold quantities of the stuff to reach the black market. The typical pharmacy sells 73,000 oxycodone pills a year; six Walgreens in Florida were going through more than 1 million pills a year—each. A few years before that, Purdue was fined $634.5 million for misleading the public about the addictiveness of oxycodone. Kentucky, which has been absolutely ravaged by opiate addiction, is still pursuing litigation against Purdue, and it has threatened to take its case all the way to the Supreme Court, if it comes to that.</p>
<p>Ground Zero in the opiate epidemic isn’t some exotic Taliban-managed poppy field or some cartel boss’s fortified compound: It’s right there at Walgreens, in the middle of every city and town in the country.</p>
<p>I pick up my prescription and get on my way.</p>
<p>The next afternoon, having driven past billboards advertising boudin and strip joints with early-bird lunch specials and casino after casino after sad little casino; help-wanted signs for drilling-fluid businesses and the Tiger Truck Stop (which has a twenty-four-hour Cajun café and an actual no-kidding <em>live tiger </em>in a cage out front); past Whiskey Bay and Contraband Bayou, where the pirate Jean Lafitte once stashed his booty; around the Port of New Orleans, another <em>entrepôt </em>for heroin and cocaine—it is almost as close to Cartagena as it is to New York—I arrive at a reasonably infamous New Orleans drug corner, where I inquire as discreetly as I can about the availability of prescription …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</a></em></p>]]>
            </description>
            <link>https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308101</guid>
            <pubDate>Fri, 04 Dec 2020 21:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PHP8, from a Security Point of View]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25308078">thread link</a>) | @todsacerdoti
<br/>
December 4, 2020 | https://dustri.org/b/php8-from-a-security-point-of-view.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/php8-from-a-security-point-of-view.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    <header>
      
    </header>
    <div>
      <p>PHP8 was <a href="https://www.php.net/releases/8.0/en.php">released</a> on the
26<sup>th</sup> of November 2020. It brought a lot of interesting things,
security-wise, but also showcases a couple of (minor) missed opportunities in my
opinion.</p>
<h2 id="type-safety"><a href="#type-safety">Type safety</a></h2>
<p>I'm a big fan on relying on typing to ensure security properties,
like <a href="https://web.dev/trusted-types/">Trusted types</a> in javascript: it
shouldn't compile if it's not secure.</p>
<p>PHP8 won't try to cast string into numbers anymore, thanks to the 
<a href="https://wiki.php.net/rfc/string_to_number_comparison">Saner string to number comparisons RFC</a>,
meaning that collision with hashes starting with <code>0e</code> and the likes are finally
a thing of the past! This is a subset of Snuffleupagus' <a href="https://snuffleupagus.readthedocs.io/features.html#preventing-sloppy-comparisons">sloppy comparison
prevention</a> feature.</p>
<p>The <a href="https://wiki.php.net/rfc/consistent_type_errors">Consistent type errors for internal functions RFC</a>
will prevent things like <code>0 == strcmp($_GET['username'], $password)</code> bypasses,
since <code>strcmp</code> won't return <code>null</code> and spit a warning any longer,
but will throw a proper exception instead. This was also a <a href="https://externals.io/message/106522">nice opportunity</a>
for PHP to add annotations for functions parameters and return types.</p>
<p>The <a href="https://wiki.php.net/rfc/arithmetic_operator_type_checks">Stricter type checks for arithmetic/bitwise operators</a>
and <a href="https://wiki.php.net/rfc/engine_warnings">PHP RFC: Reclassifying engine warnings</a> RFC
are in the same spirit.</p>
<h2 id="jit"><a href="#jit">JIT</a></h2>
<p>PHP8 comes with a <a href="https://wiki.php.net/rfc/jit">JIT</a> based on
<a href="https://luajit.org/dynasm.html">DynASM</a>, bringing an RWX memory space into
PHP's memory space, into a shared allocation, meaning that its offset won't
change between different PHP8+ processes.</p>
<p>Moreover, DynASM isn't designed with processing/compilation/execution of
untrusted code in mind, and doesn't do things like constants blinding and
advanced folding to mitigate against spraying, nor random padding/nop
insertion, nor ensuring that the memory region is never both writeable <em>and</em>
executable to prevent direct code injection. This means that it's now way
easier to gain native code execution when exploiting memory corruptions,
albeit to be fair, most attackers are happy with a php code execution,
and won't push further.</p>
<p>Having a JIT comes with a lot of code complexity and maintenance burden. I'll
be without doubt a <a href="https://bugs.php.net/search.php?cmd=display&amp;order_by=ts1&amp;direction=DESC&amp;limit=30&amp;package_name[]=JIT">great source of
bugs</a>,
for a minor speed improvement on real-life workloads.</p>
<h2 id="cryptography"><a href="#cryptography">Cryptography</a></h2>
<ul>
<li><code>password_hash</code> now automatically generates a salt, accepting a
    user-provided one is deprecated.</li>
<li><code>crypt</code> will now fail instead of silently falling back to
    <a href="https://en.wikipedia.org/wiki/Crypt_(C)#Traditional_DES-based_scheme">DES</a>
    when an unknown salt format was provided. The parameter is also made
    mandatory, hashing without a salt is now unsupported.</li>
<li><a href="https://tools.ietf.org/html/rfc5652">RFC 5652</a> is now exposed via the OpenSSL extension.</li>
</ul>
<h2 id="misc"><a href="#misc">Misc</a></h2>
<ul>
<li>The <a href="https://www.php.net/manual/en/language.operators.errorcontrol.php">error control operator</a>, aka <code>@</code>
    won't silence fatal errors anymore, meaning that poorly written webshells will have more chances
    to leave traces in your logs.</li>
<li><code>libxml_disable_entity_loader</code> is now deprecated, even if it's not (yet) reflected in php's documentation.
    This is acceptable since PHP8 now requires at least libxml 2.9.0,
    which comes with external entity loading disabled by default.</li>
<li>Access to undefined constants will throw an error, instead of being silently
  interpreted as a string, no more <code>SALT</code> being silently converted to <code>"SALT"</code>.</li>
<li><code>create_function</code> was <a href="https://github.com/php/php-src/commit/ee16d99504f0014c3d292809da927fb622293f41">removed</a>, closing its infamous code injection vector.</li>
<li><code>array_key_exists</code> throws when passed an array/object, instead of silently
  doing nonsense.</li>
<li>The <code>e</code> modifier in <code>mb_ereg_replace</code> has been removed.</li>
<li>Metadata associated with a phar will
  <a href="https://wiki.php.net/rfc/phar_stop_autoloading_metadata">no longer be unserialized</a>,
    killing a low-hanging
    <a href="https://github.com/s-n-t/presentations/blob/master/us-18-Thomas-It's-A-PHP-Unserialization-Vulnerability-Jim-But-Not-As-We-Know-It.pdf">RCE vector</a>.</li>
<li><code>FILTER_SANITIZE_MAGIC_QUOTES</code>, <code>get_magic_quotes_gpc</code> and <code>get_magic_quotes_runtime</code> have been removed,
  people will now have to do proper sanitization instead.</li>
<li>As usual, a couple of memory safety issues were fixed,
    <a href="https://bugs.php.net/bug.php?id=80242">some</a>
    <a href="https://bugs.php.net/bug.php?id=76618">exploitable</a>.</li>
<li><a href="https://github.com/jvoisin/snuffleupagus">Snuffleupagus</a> is currently being
    ported to php8!</li>
</ul>
<h2 id="missed-opportunities"><a href="#missed-opportunities">Missed opportunities</a></h2>
<p><a href="https://wiki.php.net/rfc/engine_warnings#undefined_variable">Undefined
variables</a>, as
opposed to constants, are still not an error, meaning that things like <code>solt</code>
instead of <code>salt</code> might (and will) go unnoticed.</p>
<p>Converting an <code>Array</code> to a string will only yield a <code>Warning</code> instead of an
error, albeit that now that <code>__toString</code> <a href="https://wiki.php.net/rfc/tostring_exceptions">can <em>finally</em>
throw</a>, it might hopefully change
in the near future.</p>
<p>Albeit significant <a href="https://wiki.php.net/rfc/easy_userland_csprng">CSPRNG</a>
<a href="https://wiki.php.net/rfc/random-function-exceptions">improvements</a> have been
merged in PHP7, PHP8 didn't seize the opportunity to keep the momentum and to
aliases <code>rand</code> and <code>mt_rand</code> to <code>random_int</code>, like
<a href="https://snuffleupagus.readthedocs.io/features.html#weak-prng-via-rand-mt-rand">Snuffleupagus</a> is doing.</p>
<p>An other missed opportunity in my opinion is that there is <a href="https://bugs.php.net/bug.php?id=50715">still no
way</a> to disable some <a href="https://www.php.net/manual/en/wrappers.php">PHP's wrappers</a>, except via
<a href="https://www.php.net/manual/en/function.stream-wrapper-unregister.php"><code>stream_wrapper_unregister</code></a>
but this can be reversed with
<a href="https://www.php.net/manual/en/function.stream-wrapper-restore.php"><code>stream_wrapper_restore</code></a>.
Wrappers are scary: the main use I've seen for the <a href="https://www.php.net/manual/en/wrappers.php.php#wrappers.php.filter"><code>filter://</code>
one</a> is
exfiltrating data via <code>php://filter/convert.base64-encode/resource=/some/file</code>, and is a <a href="https://www.netsparker.com/blog/web-security/php-stream-wrappers/">decent
amount of</a>
<a href="https://lightless.me/archives/include-file-from-zip-or-phar.html">arcane</a>
<a href="https://gynvael.coldwind.pl/?lang=en&amp;id=671">stuff</a> lurking in the shadows.
Providing a way to reduce this attack surface (like making streams opt-in)
would be welcome.</p>
    </div>
  </article>
</section>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/php8-from-a-security-point-of-view.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308078</guid>
            <pubDate>Fri, 04 Dec 2020 21:14:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Continuous Integration Mystery]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25306898">thread link</a>) | @basicallydan
<br/>
December 4, 2020 | https://danhough.com/blog/ci/ | <a href="https://web.archive.org/web/*/https://danhough.com/blog/ci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
			<p>
				<span>Published 03 December 2020 in Vancouver, BC, Canada</span>
				
				<span title="It took me about 5 minutes to read this blog post back to myself.">(~5min read)</span>
				
			</p>
		</header>
		<p>Yesterday I faced a version control situation I rarely face.</p>

<p>It showed me that I may rely a little too much on the green light from CI tools like CircleCI and GitHub Actions when deciding whether it’s safe to merge a branch.</p>

<p>Here’s what happened:</p>

<ol>
  <li>My colleague added new <code>expect</code> clauses to a test, plus the code to <strong>pass it</strong>.</li>
  <li>They merged this into the main branch via a PR.</li>
  <li>Later, I forked off of the main branch.</li>
  <li>I added <strong>more new clauses</strong> to the test my colleague had earlier modified.<br>I worked on it for the rest of the day.</li>
  <li>I made a <strong>pull request</strong>.</li>
  <li>Next, two colleagues reviewed my work and approved it on GitHub.<br>All the pre-merge checks on CircleCI were passing, including tests and style checks.<br>I rebased and decided to save the merge for the morning.</li>
  <li>Soon after, an error was found related to the code the first colleague had deployed.<br>They <strong>reverted</strong> the PR they had merged on Day 1.</li>
  <li>Not long after, I checked my PR again - there were no merge conflicts.<br><strong>I merged my code</strong>.</li>
</ol>

<p>An hour or so later, another colleague tells me that, according to CircleCI, a test I wrote was failing on the main branch. How could this be, they said? It appears to have been passing on the branch it came from!</p>

<p>What is the cause of this mysterious failure?</p>

<p>I’d recently touched that test, so I looked at the error and quickly worked out what it was: The test I’d added to was failing because one of it’s <code>expect</code> clauses relied on code which had been been reverted - it was no longer a valid expectation. GitHub didn’t run a new diff on my PR after the removal of the clause in question from the main branch; the reverted test code simply looks ‘unchanged’ in the diff, as if it had been and was still there.</p>

<p>I didn’t remove it, I didn’t rebase, and my PR ended up re-adding the recently-removed <code>expect</code> clause even though it didn’t appear to.</p>

<p>Is there a lesson to be learned here?</p>

<p>On one hand, the process is working. There was a merge error caused by the <code>git</code> equivalent of a race condition, we were told about it, and we were able to resolve it. Why bother running tests on the main branch before you deploy unless you are concerned that there is a chance they’ll fail?</p>

<p>Maybe the lesson is to keep on doing what we’re doing.</p>

<p>On the other hand, the process felt like it was disrupting the order of things. Something like this is often said: “if you have a reliable QA and CI process, then if something is on the main branch it should be deployable.” And yet here was an anomalous case which suggested otherwise.</p>

<p>Perhaps, then, the lesson is that our QA and CI process isn’t robust enough. Should CI create a merged branch behind-the-scenes and run tests on <em>that</em> before allowing the branch to be merged?</p>

<p>I’m not sure. In the meantime, while I try to decide what the lesson is, I think I’ll just rebase my branches more often.</p>

<p>A <a href="https://news.ycombinator.com/item?id=25306898">discussion has begun on Hacker News</a>, please share your thoughts if you have any.</p>

		<p>Heckle me on Twitter <a href="http://twitter.com/basicallydan">@basicallydan</a>.</p>
	</div></div>]]>
            </description>
            <link>https://danhough.com/blog/ci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306898</guid>
            <pubDate>Fri, 04 Dec 2020 19:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Myth of Code Coverage]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25306071">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://preslav.me/2020/12/03/the-myth-of-code-coverage/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/12/03/the-myth-of-code-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body"><p>One question I often ask potential software engineering candidates is to pinpoint the percentage of code coverage in an ideal project. Interestingly enough, many of them jump to the sky with numbers beyond 90%. They would start preaching how well-tested code is more reliable and brings more value to all stakeholders. When I ask about the current projects they work on, the reality looks a bit more down to earth.</p><p>Want to know my answer? I'd say it's <strong>around 66.7%</strong>.</p><p>The reasons for that vary, but allow me to be blunt and say that <strong>1/3 of the code every software project is irrelevant, buggy, overly complicated, or simply sucks.</strong> It has a reason to be where it is, but chances are, one year down the road, it will become a liability. Being dogmatic about tests and covering every line will only make it more difficult to get rid of it.</p><p>See, no two lines of code are equal in value and importance. Adding a new feature to an existing application affects its capabilities only marginally. However, it takes a proportionally large amount of time to develop and integrate due to the existing complexity. The bigger the complexity, the longer it takes to introduce new functionality. By the time the feature finds itself in production, it may as well be already irrelevant.</p><blockquote>The only sure-fire way to improve code coverage (and by that keep software relevant) is to identify and remove the unnecessary code.</blockquote><p>How do you identify irrelevant code? Don't search for it. Instead, let it reveal itself to you. One dimension of software that few teams make good use of, is its history. Git is a great analysis tool. Start using it not only to prevent future problems but also, to understand where and how often certain parts of the code change over time.</p><p>Chances are, you will find pieces of code that have undergone fewer changes than the rest in long periods. Those are the pillars of your application - the 2/3s that <strong>must be well-tested</strong>.</p><p>You will also find others where changes occur more or less every week. Ask yourselves whether those are still relevant, both from a technical and business perspective. Adding tests for the sake of coverage would have the opposite effect of increasing the code quality. In a perfectly-design software project, the part that is allowed to change most often is the configuration. A simple analysis of the code change frequency would show whether that is the case. If it isn't, try separating the moving parts from the core logic. If this is not feasible either, most probably those portions of the code don't belong to the codebase anyway. Turning them into interchangeable scripts (even stored in a separate repository) is one way of tackling them in their own right.</p><p>Let's not get too much into technical details. I have already alluded to the work of <a href="https://twitter.com/AdamTornhill">Adam Tornhill</a> on code analysis in a previous post of mine:</p><figure><a href="https://preslav.me/2020/03/01/use-the-git-history/"><div><p>Use the Git History to Identify Pain Points in Any Project</p><p>Have you heard of Adam Tornhill [https://twitter.com/AdamTornhill]’s work? If
not, I highly recommend that you set some time aside and check out Your Code as
a Crime Scene [https://amzn.to/32DM1G9] or Software DEsign X-Rays
[https://amzn.to/2vtbjdR…</p><p><img src="https://preslav.me/favicon.png"><span>Preslav Rachev</span></p></div><p><img src="https://www.gravatar.com/avatar/fd47e6bba1f42ecacf2e7af9e4c5fb52?s=250&amp;d=mm&amp;r=x"></p></a></figure><p>In a future post, I will discuss some of the new ideas I applied to the simple git one-liner I presented there.</p></div>
</div></div>]]>
            </description>
            <link>https://preslav.me/2020/12/03/the-myth-of-code-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306071</guid>
            <pubDate>Fri, 04 Dec 2020 18:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fable 3: F# to JavaScript compiler]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 123 (<a href="https://news.ycombinator.com/item?id=25305650">thread link</a>) | @adamnemecek
<br/>
December 4, 2020 | https://fable.io/blog/Announcing-Nagareyama-4.html | <a href="https://web.archive.org/web/*/https://fable.io/blog/Announcing-Nagareyama-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today is the day, Fable 3 Nagareyama is officially released! Does this mean the latest version is bug-free? Probably not, but at least the install command is shorter. We have also tested the release candidates in many projects and managed to fix all the outstanding issues so if you find a problem when upgrading your Fable 2 project you may even consider yourself lucky (also, please report).</p>
<p>First things first, I have to acknowledge all the people that have contributed to this release: from Don Syme himself to ncave, our mysterious contributor, and all the early-users that have helped polish this release. Very importantly, the teachers too that take care of my children in difficult times so I can focus on programming. The fact that so many people can collaborate together to put a project like Fable forward still feels like magic to me and I can only say a big THANK YOU to you all. I'm also very happy this is coincidental with the release of F# 5, as incredibly smart people are putting a lot of effort to make the development experience with the language really pleasant. Quoting Krzysztof Cieślak, what a great time to be an F# developer!</p>
<p>How can you try Fable 3, you say? This is it:</p>
<pre><code>dotnet tool install fable
dotnet fable src</code></pre><p>(Change "src" with the path to your project.) It's that easy, type <code>dotnet fable --help</code> to see more options. Of course you still need extra tooling to bundle the JS code, spin off a development server, etc. If you're upgrading an app using Webpack, please <a href="https://github.com/MangelMaxime/fulma-demo/pull/43">check this PR for reference</a>.</p>
<p>Let's quickly go through the highlights of Nagareyama:</p>
<ul>
<li>It's Fable v3. Three is bigger than two, that's already a win.</li>
<li>There are no breaking changes, your Fable 2 project should compile as is with Nagareyama (you may need to update some libraries).</li>
<li>It's a dotnet tool, following suit with most F# project. Remember when Fable, Paket and Fake had each their own way to be downloaded and version-managed? Those days are happily gone!</li>
<li>It removes the inter-process communication with JS, greatly simplifying Fable usage and development.</li>
<li>The previous point together with other fixes have improved the compilation speed by a big deal. Expect it to be at least cut in half in most cases!</li>
<li>Fable is not tightly coupled with a specific bundler anymore like Webpack so you can use any tool you like! (Webpack is still a great choice.)</li>
<li>A lot of effort has been also put to prettify the generated code, making it more readable and easier to debug if needed.</li>
<li>Nagareyama can accept plugins by library authors. Zaid is already using this feature to make it much simpler to <a href="https://youtu.be/a6Ct3CM_lj4?t=860">write React components compatible with JS tooling</a>.</li>
</ul>
<p>You can check the <a href="https://fable.io/blog/Announcing-Nagareyama-3.html">previous posts</a> for more details.</p>


<p>So what are you waiting for? Give Nagareyama a try and let the world know if it goes well... and let us know (privately) if it doesn't 😅 Have fun!</p>
</div></div>]]>
            </description>
            <link>https://fable.io/blog/Announcing-Nagareyama-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305650</guid>
            <pubDate>Fri, 04 Dec 2020 18:08:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TerminusDB 4.0 'Data and Content Management in a Box']]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25305296">thread link</a>) | @LukeEF
<br/>
December 4, 2020 | https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          

<p><strong>Version 4.0 of TerminusDB - the Star’s End Release</strong> * - is a big step forward in solidifying and extending the functionality of TerminusDB and TerminusHub.</p>

<p><a href="https://terminusdb.com/">TerminusDB</a> is an <a href="https://github.com/terminusdb/terminusdb">open source</a>, revision control graph database designed for distributed collaboration. TerminusDB allows you to push, pull, time-travel and merge data, much in the way that is possible with code in Git.</p>

<p>With this release TerminusDB takes a significant step towards our vision of a general-purpose tool for data &amp; content management and collaboration.</p>

<p>TerminusDB 4.0 extends the revision control features to allow greater visibility and reproducability by allowing you to look inside individual commits to see what changes were made. Provenance, lineage, and compliance are increasingly essential in the management of data and content.</p>

<p>The <em>major</em> additional features are:</p>

<h3 id="model-building-tool">Model Building Tool</h3>

<p>The database ships with an integrated visual schema building tool. It allows users to build complex data models using point and click tooling. This makes building models significantly quicker, more efficient, and inclusive of a broader range of people by lowering the technical bar for the application of business rules to your data.</p>

<p>It lets you visually design knowledge graphs in the same way they are presented to business users. We have tried to make the tool easy to use, while preserving the ability to model the most complex domains.</p>

<p>Like everything in TerminusDB, the models are versioned so you can make changes in testing and if it breaks your database, you can easily roll back to an earlier working version. This <strong>collaborative knowledge graph design and implementation functionality</strong> does not exist elsewhere.</p>

<p>You can currently share your models/schemas through TerminusHub - the next step is to make modelling and collaboration even easier by providing data-libraries on TerminusHub, including schema.org but also basic standard models for common domains such as CRM, accounting, and inventory. Users can then generate and share models with collaborators or the broader public.</p>

<h3 id="document-editor">Document Editor</h3>

<p>TerminusDB 4.0 has full surfability, clickability and editability of database documents through the console. It is a wiki or catalogue of all your data that you can edit in place. You don’t have to write code or execute a query, just edit the document directly. If you have a collaborative project, this is a useful approach to building and curating data assets.</p>

<p>The documents link to associated documents delivering a linked data application. You can filter documents, you can find the document you want using search, you can create a new document in the interface - it is a <strong>general-purpose tool for managing your data</strong>.</p>

<p>This is the beginning of the TerminusDB content management system, which we will be expanding over the coming months - next step is to provide web accessibility to TerminusHub databases and then a publisher API to provide the ability to publish the results of any query as a static content set.</p>

<h3 id="csv-manager">CSV Manager</h3>

<p>With a single click, you can now build a database from a CSV or a group of CSVs. You can easily use TerminusDB and TerminusHub as a place to version and collaborate when working with CSV data. This will be especially useful with fast changing data as frequently used in machine learning and data science projects.</p>

<p>We have tried to make it as simple as possible for users to interact with the CSV tooling. You can view and edit CSVs directly in the document viewer. You can also add CSVs from this interface. No need to write code.</p>

<p>The database automatically spots if the CSV is already in the database and will just add the delta. There is an append mode that just adds the data that is not there and an update mode that updates the entire CSV.</p>

<p><strong>Manage your CSVs and other data via TerminusDB and Hub.</strong></p>

<h3 id="command-line-interface">Command Line Interface</h3>

<p>We are excited to launch the TerminusDB CLI. You can connect to TerminusDB with a Git-like CLI to run queries or use the revision control features.</p>

<p>You can create databases and branches, you can list databases/branches, you can query in the command line and you can load CSVs. You also get full error reporting in the CLI. Use the CLI to import a CSV, commit changes and push the changes to TerminusHub.</p>

<p>The CLI will continue to develop and add new operations. We will make it easier to execute queries directly from the CLI. We’re also planning to launch CLIs for the JavaScript and Python clients.</p>

<p>TerminusDB is a big step towards our ambition to be a complete decentralized data and content management system that is accessible to all.</p>

<p><strong>END</strong></p>

<p>* Star’s End is a reference to the mysterious location of the Second Foundation in the Asimov series of novels. The home of the First Foundation was Terminus.</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/4.0_2.png" alt=""></p>

        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/12/03/terminusdb-4-0-the-stars-end-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305296</guid>
            <pubDate>Fri, 04 Dec 2020 17:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting a 100% local app to the web]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25304100">thread link</a>) | @jlongster
<br/>
December 4, 2020 | https://actualbudget.com/blog/porting-local-app-web | <a href="https://web.archive.org/web/*/https://actualbudget.com/blog/porting-local-app-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>While researching <a href="https://actualbudget.com/blog/cursed-caching-curious">a curious caching bug</a>, I got inspired to take another look at how Actual stores data locally on the web. There's some history I need to explain. Years ago, Actual was only going to be a desktop app. That means <em>all</em> of your data is stored locally. No server.</p><p>Then I realized how important mobile is, and that most people don't want to worry about losing their data if they drop their computer in the ocean. A syncing engine was born, and desktop and mobile apps have happily synced their data ever since. A copy is kept on a server so users can login and easily view their data, and if they worry about privacy they can enable <a href="https://actualbudget.com/docs/overview/syncing-across-devices/#end-to-end-encryption">end-to-end encryption</a>.</p><p>In the last year I grew jealous of web apps. Look at how easily they can deploy… how quickly they can drop users right into the app. No install required. Here I am asking users to download an 80MB file just to run the app. That download absolutely kills conversion rates, and makes the login flow, support, a/b testing and <em>everything</em> much harder.</p><p>I love desktop apps because you have access to much better tech (like native sqlite3), the app is super fast (no network calls), and the user owns their data. However, I can't ignore that the benefits of the web <a href="https://www.kalzumeus.com/2009/09/05/desktop-aps-versus-web-apps/">dwarfs these advantages</a>.</p><p>I started thinking about a web version of Actual. After some hacking, <a href="https://app.actualbudget.com/">I got it working</a> without changing the architecture. That means all your data is still stored locally in the browser, and there are no network calls. It's a completely 100% "local" app in the browser [0].</p><p>I haven't marketed the web version much because it hasn't been tested enough, and it needs improvements like lazy loading code to make it load faster. The biggest thing I'm worried about is the data storage layer. Since <strong>all your data is local</strong>, if something goes wrong there you could potentially lose data. And we're really stressing the browser's persistant db by storing everything in it.</p><p>To be clear: <strong>we are not deprecating the desktop version</strong>. However in the future the web version will be the primary platform, with the choice to download the desktop version if desired.</p><p>The way it works a bit unusual. Here's a high-level overview:</p><ul><li>Actual uses <a href="https://www.sqlite.org/index.html">sqlite3</a>. This is a hard requirement. The app runs tons of complex SQL queries to aggregate financial data and it's so good at doing it. Queries are easy to express and run super fast.</li><li>On desktop and mobile, native sqlite3 is used. The web does not support sqlite3, however. To get around this, Actual uses a <a href="https://github.com/sql-js/sql.js">wasm version</a> of sqlite3 and creates an in-memory db.</li><li>The obvious problem is persistence. When you make changes, we need to persist them somewhere so when the user reloads they don't lose their data. Luckily we are using <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type#State-based_CRDTs">state-based CRDT's</a> and all updates come through as a list of "messages". If you are online, these messages get synced to our server so when you reload, all your data should sync up.</li><li>It's not ideal to require a big sync every time you open the app though. Also, if you are offline there shouldn't be any chance of losing data. To solve this, Actual persists each message into IndexedDB. When the app opens, it applies all messages from the local IndexedDB to get up-to-date.</li><li>It's <em>still</em> not ideal to require applying any messages on load. It won't scale - if you use the app for months you'll accumulate tens of thousands of messages. IndexedDB would grow indefinitely and loading the app would get slower. To solve this, when the stored messages crosses a threshold it flushes the entire sqlite3 db to IndexedDB and clears all the messages.</li><li>That means both a binary representation of the sqlite3 db and a list of messages is persisted in IndexedDB. On load, the app creates the in-memory sqlite3 db from the snapshot and applies any remaining messages from IDB.</li></ul><p>Turns out this is similar to how a <a href="https://sqlite.org/wal.html">write-ahead log</a> works.</p><p>I was worried about the reliability of IndexedDB. Reading the docs it seems like browsers might delete databases as needed, but in practice this doesn't seem to happen [1]. It's probably a much bigger problem on mobile where memory is scarce, but I don't mess with the mobile web (use a native app instead). I was also worried about hitting the limit of IDB storage, but as explained next that hasn't been a problem.</p><p>This technique started as an experiment, but it has worked surprisingly well. I have 5 years worth of data in Actual, and the size of the sqlite3 db is 9.7MB. The threshold of the messages table is around 50KB, so in total I'm storing ~10MB in IndexedDB for a user who's been around for 5 years. It's not even close to hitting the IndexedDB max storage limit, which these days is at least 500MB.</p><p>While it has worked so far, I want to be 100% confident in this approach. I've been digging deep into how each browser stores IndexedDB data on disk and discovered a couple improvements I can make. I was going to write about them in this post, but I ended up writing more about the overall approach. In the next post I'll dig deep into how IndexedDB works across browsers.</p><p>[0] While I didn't talk about it in this post, this also means that the entire app runs in the browser. The "backend" runs in a background worker thread and everything happens locally.</p><p>[1] If the local data does somehow get corrupted or deleted, it's not a <em>huge</em> deal. All changes are still sent off and stored on a server (which is how all other devices get synced). If something goes wrong, the app can re-download your data from the server. The only case where you'd lose data is if you were offline and lost your local data, which is to be expected.</p></div></div></div>]]>
            </description>
            <link>https://actualbudget.com/blog/porting-local-app-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304100</guid>
            <pubDate>Fri, 04 Dec 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A World Rendered Beautifully: The Making of the BFCM 3D Data Visualization]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25303999">thread link</a>) | @dmalik
<br/>
December 4, 2020 | https://shopify.engineering/bfcm-3d-data-visualization | <a href="https://web.archive.org/web/*/https://shopify.engineering/bfcm-3d-data-visualization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>
  <em><strong><a href="https://shopify-bfcm.splashthat.com/" target="_blank" title="How it's made: The Black Friday &amp; Cyber Monday Live Map" rel="nofollow noopener noreferrer">Join us on Monday, December 7</a>, for a behind the scenes look at how and why we visually bring this
      exciting data to life. Shopify’s AR/VR team will take you through the
      technical journey from idea to execution and answer your questions
      live!</strong></em>
</p>
<p>
  <strong>﻿By Mikko Haapoja and Stephan Leroux</strong>
</p>
<p>
  2020 Black Friday Cyber Monday (BFCM) is over, and another BFCM Globe has
  shipped. We’re extremely proud of the globe, it focused on realism,
  performance, and the impact our merchants have on the world.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/LPm0xjr2lzo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>The Black Friday Cyber Monday Live Map</figcaption>
</figure>
<p>
  We knew we had a tall task in front of us this year, building something that
  could represent orders from our one million merchants in just two months. Not
  only that, we wanted to ship a data visualization for our merchants so they
  could have a similar experience to the BFCM globe every day in their Live
  View.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/_r6ut_Z7pss?playlist=_r6ut_Z7pss&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>Prototypes for the 2020 BFCM Globe and Live View. **</figcaption>
</figure>
<p>
  With tight timelines and an ambitious initiative, we immediately jumped into
  prototypes with three.js and planned our architecture.
</p>

<p>
  As we planned this project, we converged architecturally on the idea of
  layers. Each layer is similar to a React component where state is minimally
  shared with the rest of the application, and each layer encapsulates its own
  functionality. This allowed for code reuse and flexibility to build both the
  Live View Globe, BFCM Globe, and beyond.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/D56O11Y46o0?playlist=D56O11Y46o0&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>A showcase of layers for the 2020 BFCM Globe. **</figcaption>
</figure>
<p>
  When realism is key, it’s always best to lean on fantastic artists, and that’s
  where
  <a href="https://twitter.com/byrondelgado" target="_blank" title="Byron Delgado on Twitter" rel="nofollow noopener noreferrer">Byron Delgado</a>
  came in. We hoped that Byron would be able to use the 3D modeling tools he’s
  used to, and then we would incorporate his 3D models into our experience. This
  is where the <code>EarthRealistic</code> layer comes in.
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/N4oeDV4rNQo?playlist=N4oeDV4rNQo&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    <code>EarthRealistic</code> layer from the 2020 BFCM Globe. **
  </figcaption>
</figure>
<p>
  <code>EarthRealistic</code> uses a technique called physically based
  rendering, which most modern 3D modeling software supports. In three.js,
  physically based rendering is implemented via the
  <code>MeshPhysicalMaterial</code> or
  <code>MeshStandardMaterial</code> materials.
</p>
<p>
  To achieve realistic lighting, <code>EarthRealistic</code> is lit by a 32bit
  EXR Environment Map. By using a 32bit EXR, it means we can have smooth image
  based lighting. Image based lighting is a technique where a “360 sphere” is
  created around the 3D scene, and pixels in that image are used to calculate
  how bright Triangles on 3D models should be. This allows for complex lighting
  setups without much effort from an artist. Traditionally images on the web
  such as JPGs and PNGs have a color depth of 8bits. If we were to use these
  formats and 8bit color depth, our globe lighting would have had horrible
  gradient banding, missing realism entirely.
</p>

<p>
  Once we converged on physically based rendering and image based lighting,
  building the carbon offset layer became clearer. Literally!
</p>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/GQ2OJCiT-wA?playlist=GQ2OJCiT-wA&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    Carbon Offset visualization layer from the 2020 BFCM Globe. **
  </figcaption>
</figure>
<p>
  Bubbles have an interesting phenomenon where they can be almost opaque at a
  certain angle and light intensity but in other areas completely transparent.
  To achieve this look, we created a custom material based on
  MeshStandardMaterial that reads in an Environment Map and simulates the bubble
  lighting phenomenon. The following is the easiest way to achieve this with
  three.js:
</p>
<ol>
  <li>
    Create a custom Material class that extends off of MeshStandardMaterial.
  </li>
  <li>
    Write a custom Vertex or Fragment Shader and define any Uniforms for that
    Shader Program.
  </li>
  <li>
    Override
    <code>onBeforeCompile(shader: Shader, _renderer: WebGLRenderer): void&nbsp;</code>on your custom Material and pass the custom Vertex or Fragment Shader and
    uniforms via the Shader instance.
  </li>
</ol>
<p>
  Here’s our implementation of the above for the Carbon Offset Shield Material:
</p>
<ul>
  <li>
    <a href="https://gist.github.com/ShopifyEng/5e8bfa0de5630779ad7350c7a73cb650" target="_blank" rel="nofollow noopener noreferrer">ShieldMaterial.ts</a>
    - Our custom Carbon Offset Visualization Material
  </li>
  <li>
    <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf" target="_blank" rel="nofollow noopener noreferrer">CustomMeshStandardMaterial.ts</a>
    - Abstraction on top of MeshStandardMaterial
  </li>
  <li>
    <a href="https://gist.github.com/ShopifyEng/cc1679cfb054f85c8689037e5d168f68" target="_blank" rel="nofollow noopener noreferrer">shield.frag</a>
    - Custom Fragment shaders that make MeshStandardMaterial look like a bubble
  </li>
</ul>
<p>
  Let’s look at the above, starting with our Fragment shader. In shield.frag
  lines 94-97
</p>
<figure>
  
</figure>
<p>
  These two lines are all that are needed to achieve a bubble effect in a
  fragment shader.
</p>
<p>
  To calculate the <code>brightness</code> of an rgb pixel, you calculate the
  length or magnitude of the pixel using the GLSL length function. In three.js
  shaders, <code>outgoingLight</code> is an RGB <code>vec3</code> representing
  the outgoing light or pixel to be rendered.
</p>
<p>
  If you remember from earlier, the bubble’s brightness determines how
  transparent or opaque it should appear.&nbsp; After calculating brightness, we can
  set the outgoing pixel’s alpha based on the brightness calculation. Here we
  use the GLSL <code>mix</code> function to go between the expected alpha of the
  pixel defined by <code>diffuseColor.a</code> and a new custom uniform defined
  as <code>maxOpacity</code>. By having the concept of min or expected opacity
  and max opacity, Byron and other artists can tweak visuals to their exact
  liking.
</p>
<p>
  If you look at our shield.frag file, it may seem daunting! What on earth is
  all of this code?&nbsp; three.js materials handle a lot of functionality, so it’s
  best to make small additions and not modify existing code. three.js materials
  all have their own shaders defined in the
  <a href="https://github.com/mrdoob/three.js/blob/dev/src/renderers/shaders/ShaderLib/" target="_blank" title="ShaderLib folder in three.js repo" rel="nofollow noopener noreferrer">ShaderLib folder</a>. To extend a three.js material, you can grab the original material shader
  code from the <code>src/renderers/shaders/ShaderLib/</code> folder in the
  three.js repo and perform any custom calculations before setting
  <code>gl_FragColor</code>. An easier option to access three.js shader code is
  to simply <code>console.log</code> the <code>shader.fragmentShader</code> or
  <code>shader.vertexShader</code> strings, which are exposed in the
  <code>onBeforeCompile</code> function:
</p>
<figure>
  
</figure>
<p>
  <code>onBeforeCompile</code> runs immediately before the Shader Program is
  created on the GPU. Here you can override shaders and uniforms.
  CustomMeshStandardMaterial.ts is an abstraction we wrote to make creating
  custom materials easier. It overrides the
  <code>onBeforeCompile</code> function and manages uniforms while your
  application runs via the
  <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf#file-custommeshstandardmaterial-ts-L51" target="_blank" title="setCustomUniform in CustomMeshStandardMaterial.ts" rel="nofollow noopener noreferrer"><code>setCustomUniform</code></a>
  and
  <a href="https://gist.github.com/ShopifyEng/5a0c15b0c83ed00b66267b93994714cf#file-custommeshstandardmaterial-ts-L60" target="_blank" title="getCustomUniform in CustomMeshStandardMaterial.ts" rel="nofollow noopener noreferrer"><code>getCustomUniform</code></a>
  functions. You can see this in action in our custom Shield Material when
  getting and setting <code>maxOpacity</code>:
</p>
<figure>
  
</figure>
<h2>Using Particles to Display Orders</h2>
<figure>
  <p><iframe width="560" height="315" src="https://www.youtube.com/embed/jGUDfU1c_xE?playlist=jGUDfU1c_xE&amp;autoplay=1&amp;loop=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
  <figcaption>
    Displaying orders on Shopify from across the world using particles. **
  </figcaption>
</figure>
<p>
  One of the BFCM globe’s main features is the ability to view orders happening
  in real-time from our merchants and their buyers worldwide. Given Shopify’s
  scale and amount of orders happening during BFCM, it’s challenging to visually
  represent all of the orders happening at any given time. We wanted to find a
  way to showcase the sheer volume of orders our merchants receive over this
  time in both a visually compelling and performant way.&nbsp;
</p>
<p>
  In the past, we used visual “arcs” to display the connection between a buyer’s
  and a merchant’s location.
</p>
<figure>
  <img alt="The BFCM Globe from 2018 showing orders using visual arcs." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/old-globe.jpg?v=1607052787" src="https://cdn.shopify.com/s/files/1/0779/4361/files/old-globe.jpg?v=1607052787">
  <figcaption>
    The BFCM Globe from 2018 showing orders using visual arcs.
  </figcaption>
</figure>
<p>
  With thousands of orders happening every minute, using arcs alone to represent
  every order quickly became a visual mess along with a heavy decrease in
  framerate. One solution was to cap the number of arcs we display, but this
  would only allow us to display a small fraction of the orders we were
  processing. Instead, we investigated using a particle-based solution to help
  fill the gap.
</p>
<p>With particles, we wanted to see if we could:</p>
<ul>
  <li>Handle thousands of orders at any given time on screen.</li>
  <li>Maintain 60 frames per second on low-end devices.</li>
  <li>
    Have the ability to customize style and animations per order, such as
    visualizing local and international orders.
  </li>
</ul>
<p>
  From the start, we figured that rendering geometry per an order wouldn't scale
  well if we wanted to have thousands of orders on screen. Particles appear on
  the globe as highlights, so they don’t necessarily need to have a 3D
  perspective. Rather than using triangles for each particle, we began our
  investigation using three.js <code>Points</code> as a start, which allowed us
  to draw using dots instead. Next, we needed an efficient way to store data for
  each particle we wanted to render. Using <code>BufferGeometry</code>, we
  assigned custom attributes that contained all the information we needed for
  each particle/order.
</p>
<figure>
  
</figure>
<p>
  To render the points and make use of our attributes, we created a
  <code>ShaderMaterial</code>, and custom vertex and fragment shaders. Most of
  the magic for rendering and animating the particles happens inside the vertex
  shader. Each particle defined in the attributes we pass to our
  <code>BufferGeometry</code> goes through a series of steps and
  transformations.
</p>
<p>
  First, each particle has a starting and ending location described using
  latitude and longitude. Since we want the particle to travel along the surface
  and not through it, we use a geo interpolation function on our coordinates to
  find a path that goes along the surface.
</p>
<figure>
  <img alt="A photo of a globe with an order represented as a particle traveling from New York City to London. The vertex shader uses each location’s latitude and longitude and determines the path it needs to travel." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-1.jpg?v=1607053616" src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-1.jpg?v=1607053616">
  <figcaption>
    An order represented as a particle traveling from New York City to London.
    The vertex shader uses each location’s latitude and longitude and determines
    the path it needs to travel. **
  </figcaption>
</figure>
<p>
  Next, to give the particle height along its path, we use high school geometry,
  a parabola equation based on time to alter the straight path to a curve.
</p>
<figure>
  <img alt="A photo of a globe with particles that follow a curved path away from the earth’s surface using a parabola equation to determine its height." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-2.jpg?v=1607053702" src="https://cdn.shopify.com/s/files/1/0779/4361/files/particle-diagram-2.jpg?v=1607053702">
  <figcaption>
    Particles follow a curved path away from the earth’s surface using a
    parabola equation to determine its height. **
  </figcaption>
</figure>
<p>
  To render the particle to make it look 3D in its travels, we combine our
  height and projected path data then convert it to a vector position our shader
  uses as it’s <code>gl_Position</code>. With our particle now knowing where it
  needs to go, using a <code>time</code> uniform, we drive animations for other
  changes such as size and color. At the end of the vertex shader, we pass the
  position and point size to render onto the fragment shader that combines the
  calculated color and alpha at the time for each particle.
</p>
<p>
  Once …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/bfcm-3d-data-visualization">https://shopify.engineering/bfcm-3d-data-visualization</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/bfcm-3d-data-visualization</link>
            <guid isPermaLink="false">hacker-news-small-sites-25303999</guid>
            <pubDate>Fri, 04 Dec 2020 16:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mannequin.js: An Articulated Mannequin Figure Library]]>
            </title>
            <description>
<![CDATA[
Score 149 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25302602">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://boytchev.github.io/mannequin.js/ | <a href="https://web.archive.org/web/*/https://boytchev.github.io/mannequin.js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<ul>
  <li><a href="#About">About</a></li>
  <li><a href="#Initialization">Initialization</a>
    <ul>
      <li><a href="#Minimal-program">Minimal program</a></li>
      <li><a href="#Figure-types">Figure types</a></li>
    </ul>
  </li>
  <li><a href="#Body-parts">Body parts</a>
    <ul>
      <li><a href="#Central-body-parts">Central body parts</a></li>
      <li><a href="#Upper-limbs">Upper limbs</a></li>
      <li><a href="#Lower-limbs">Lower limbs</a></li>
    </ul>
  </li>
  <li><a href="#Body-posture">Body posture</a>
    <ul>
      <li><a href="#Static-posture">Static posture</a></li>
      <li><a href="#Dynamic-posture">Dynamic posture</a></li>
    </ul>
  </li>
  <li><a href="#Other-functions">Other functions</a>
    <ul>
      <li><a href="#Custom-colors">Custom colors</a></li>
      <li><a href="#Hiding-body-parts">Hiding body parts</a></li>
      <li><a href="#Custom-body-parts">Custom body parts</a></li>
      <li><a href="#Global-position">Global position</a></li>
    </ul>
  </li>
  <li><a href="#Future-plans">Future plans</a></li>
</ul>


<p><strong>Mannequin.js</strong> is a simple library of an articulated mannequin figure. The shape of the figure
and its movements are done purely in JavaScript. The graphics is implemented in
<a href="https://threejs.org/">Three.js</a>. Click on an image to open a live demo.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-custom-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-custom-body-parts.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-point.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-point.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-scene.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-scene.jpg" width="150"></a></p>

<p>This is the fourth incarnation of the mannequin figure. The first one was implemented
in Elica. The second one was implemented in C/C++ and OpenGL. The third one
was implemented in JS/Three.js and is a direct predecessor of the current mannequin.js.
Since its first incarnation, mannequin.js is used in the course <em>Fundamentals of Computer Graphics</em> for Computer Sciences undergraduate students from the
<a href="https://www.fmi.uni-sofia.bg/en">Faculty of Mathematics and Informatics</a>
at <a href="https://www.uni-sofia.bg/index.php/eng">Sofia University</a>.</p>

<p>Mannequin.js is licensed under <strong>GPL-3.0</strong>.</p>

<p>Three.js is included in this repository to safeguard against incompatibilities with future versions. Three.js is not a part of mannequin.js.</p>



<p>The <strong>mannequin.js</strong> library is provided as a JavaScript file that has to
be include along with three.js.</p>

<h3 id="minimal-program">Minimal program</h3>

<p>Here is a minimal program that creates a male figure in the browser (<a href="https://boytchev.github.io/mannequin.js/examples/example-minimal.html">live example</a>):</p>

<div><div><pre><code><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;html&gt;</span>
  <span>&lt;head&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"three.min.js"</span><span>&gt;&lt;/script&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"mannequin.min.js"</span><span>&gt;&lt;/script&gt;</span>
  <span>&lt;/head&gt;</span>
  <span>&lt;body&gt;</span>
    <span>&lt;script&gt;</span>
      createScene();
      var man = new Male();
    <span>&lt;/script&gt;</span>
  <span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<p>The helper function <code>createScene()</code> provides a default set-up of the scene and its elements, like lighting, camera, ground, etc. Another helper function, <code>animate(t)</code> is responsible for defining figures’ postures at moment <em>t</em>. If the set-up is done with a custom function, then it should also manage the animation loop by itself.</p>

<h3 id="figure-types">Figure types</h3>

<p>Mannequin figures are created as instances of classes <code>Male()</code>, <code>Female()</code> or <code>Child()</code> (<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg"></a></p>

<div><div><pre><code><span>var</span> <span>man</span> <span>=</span> <span>new</span> <span>Male</span><span>();</span>
    <span>man</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>20</span><span>,</span><span>3.5</span><span>,</span><span>0</span><span>);</span>
    <span>man</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>120</span><span>);</span>
    <span>:</span>
<span>var</span> <span>woman</span> <span>=</span> <span>new</span> <span>Female</span><span>();</span>
    <span>woman</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>-</span><span>20</span><span>,</span><span>2</span><span>,</span><span>0</span><span>);</span>
    <span>woman</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>60</span><span>);</span>
    <span>:</span>
<span>var</span> <span>kid</span> <span>=</span> <span>new</span> <span>Child</span><span>();</span>
    <span>kid</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>8</span><span>;</span>
    <span>kid</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>);</span>
    <span>:</span>
</code></pre></div></div>

<p>These three classes have a common predecessor – the class <code>Mannequin(feminine,height)</code>, where <em>feminine</em> is boolean and defines whether the shape is feminine or masculine, and the second parameter is a number for relative height (adults have height 1).</p>



<p>All types of figures have the same structure of joints. For example, the right arm of a figure is accessed by <code>r_arm</code>. Left and right body parts are in respect to the figure, not to the viewer (<a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-body-parts.jpg"></a></p>

<p>Each body part has rotation methods that turn it around a pivot point.
The first parameter <em>angle</em> of the methods is the angle of rotation in degrees,
so 180 is half turn and 360 is full turn. Negative angles are allowed and
they represent turning in the opposite direction. Some methods have an optional
second parameter for <em>direction</em> of motion, which could be the constant <code>LEFT</code> or
<code>RIGHT</code>.</p>

<h3 id="central-body-parts">Central body parts</h3>

<p>The central body parts are the ones which have single instances - <em>head</em>, <em>neck</em>, <em>torso</em>, <em>pelvis</em> and the body as a whole. To move the whole <strong>body</strong> use methods <em>bend</em>, <em>turn</em> and <em>tilt</em> of the figure (<a href="https://boytchev.github.io/mannequin.js/examples/example-body.html">live example</a>):</p>

<ul>
  <li><code>figure.bend ( angle )</code></li>
  <li><code>figure.turn ( angle )</code></li>
  <li><code>figure.turn ( angle, direction )</code></li>
  <li><code>figure.tilt ( angle )</code></li>
  <li><code>figure.tilt ( angle, direction )</code></li>
</ul>

<p>The <strong>head</strong> supports similar methods: <em>nod</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-head.html">live example</a>):</p>

<ul>
  <li><code>figure.head.nod ( angle )</code></li>
  <li><code>figure.head.turn ( angle )</code></li>
  <li><code>figure.head.turn ( angle, dir )</code></li>
  <li><code>figure.head.tilt ( angle )</code></li>
  <li><code>figure.head.tilt ( angle, dir )</code></li>
</ul>

<p>The <strong>torso</strong> has the same methods as the whole body: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-torso.html">live example</a>):</p>

<ul>
  <li><code>figure.torso.bend ( angle )</code></li>
  <li><code>figure.torso.turn ( angle )</code></li>
  <li><code>figure.torso.turn ( angle, direction )</code></li>
  <li><code>figure.torso.tilt ( angle )</code></li>
  <li><code>figure.torso.tilt ( angle, direction )</code></li>
</ul>

<p>Although the <strong>neck</strong> is a separate part of the body, it is not controlled individually. Instead, a part of the head motion is distributed over the neck. Similarly, the <strong>pelvis</strong> is not controlled individually. Instead, the whole body is controlled by bending, turning and tilting.</p>

<h3 id="upper-limbs">Upper limbs</h3>

<p>The upper limbs are symmetrical body parts: <em>arm</em>, <em>elbow</em>, <em>wrist</em> and <em>fingers</em>.</p>

<p>Both <strong>arms</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm1.html">live example</a>). The following list refers to the right arm, however, the same methods are available for the right hand:</p>

<ul>
  <li><code>figure.r_arm.raise ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle, direction )</code></li>
  <li><code>figure.r_arm.turn ( angle )</code></li>
  <li><code>figure.r_arm.turn ( angle, direction )</code></li>
</ul>

<p>If the <em>direction</em> parameter is omitted, then the default motions of <em>straddle</em> and <em>turn</em> are symmetrical. For example, the left arm is straddled to the left, while the right arm is straddled to the right (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm2.html">live example</a>).</p>

<p>The motion of the <strong>elbow</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-elbow.html">live example</a>). Negative values for <em>angle</em> result in unnatural elbow position.</p>

<ul>
  <li><code>figure.r_elbow.bend ( angle )</code></li>
</ul>

<p>The <strong>wrists</strong> have the same methods as the torso: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-wrist.html">live example</a>), but similar to the arms, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_wrist.bend ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle, direction )</code></li>
  <li><code>figure.r_wrist.tilt ( angle )</code></li>
  <li><code>figure.r_wrist.tilt ( angle, direction )</code></li>
</ul>

<p>The last body parts of the upper limbs are the <strong>fingers</strong>. They can only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-fingers.html">live example</a>), however, they are composed of two segments and the bending angle is distributed over both of them.</p>

<ul>
  <li><code>figure.r_fingers.bend ( angle )</code></li>
</ul>

<h3 id="lower-limbs">Lower limbs</h3>

<p>The lower limbs are symmetrical body parts: <em>leg</em>, <em>knee</em> and <em>ankle</em>.</p>

<p>Both <strong>legs</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-leg.html">live example</a>). Straddling and turning are symmetrical if <em>direction</em> is not set.</p>

<ul>
  <li><code>figure.r_leg.raise ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle, direction )</code></li>
  <li><code>figure.r_leg.turn ( angle )</code></li>
  <li><code>figure.r_leg.turn ( angle, direction )</code></li>
</ul>

<p>The motion of the <strong>knee</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-knee.html">live example</a>). Negative values for <em>angle</em> result in unnatural knee position.</p>

<ul>
  <li><code>figure.r_knee.bend ( angle )</code></li>
</ul>

<p>The <strong>ankles</strong> have the same methods as the wrists: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-ankle.html">live example</a>), but similar to the legs, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_ankle.bend ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle, direction )</code></li>
  <li><code>figure.r_ankle.tilt ( angle )</code></li>
  <li><code>figure.r_ankle.tilt ( angle, direction )</code></li>
</ul>



<p>The posture of a figure is defined by a setting the rotations of body parts. The order of rotations is fixed independent on the order of rotations in the user program (<a href="https://boytchev.github.io/mannequin.js/examples/example-order.html">live example</a>). For example:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>produces the same posture as:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
</code></pre></div></div>

<p>Sometimes this might lead to unexpected results, especially if the user assumes an order of rotations that is different from what mannequin.js uses. This might happen when a body part is rotated around 3 or 2 axes.</p>

<h3 id="static-posture">Static posture</h3>

<p>The static posture defines the position of body part that do not change. By default, when a figure is created, its body parts are set to the default posture. This version of mannequin.js does not provide posture editor, so all rotations has to be defined programmatically.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg"></a></p>

<p>Sometimes it is better to define the figure step by step. Tai Chi Chuan posture (<a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html">live example</a>) could start by defining the whole body position:</p>

<div><div><pre><code><span>// overall body position</span>
<span>man</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>7.7</span><span>;</span>
<span>man</span><span>.</span><span>tilt</span><span>(</span><span>5</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>bend</span><span>(</span><span>15</span><span>);</span>

<span>// torso and head</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>tilt</span><span>(</span><span>15</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>15</span><span>);</span>
<span>man</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>70</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>Then the orientation of the legs can be set:</p>

<div><div><pre><code><span>// right leg</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>raise</span><span>(</span><span>85</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>straddle</span><span>(</span><span>40</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>r_knee</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>bend</span><span>(</span><span>35</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>15</span><span>);</span>

<span>// left leg</span>
<span>man</span><span>.</span><span>l_leg</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>l_knee</span><span>.</span><span>bend</span><span>(</span><span>25</span><span>);</span>
<span>man</span><span>.</span><span>l_ankle</span><span>.</span><span>bend</span><span>(</span><span>42</span><span>);</span>
</code></pre></div></div>

<p>Finally, the arms are fixed:</p>

<div><div><pre><code><span>// left arm</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>raise</span><span>(</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>60</span><span>);</span>
<span>man</span><span>.</span><span>l_elbow</span><span>.</span><span>bend</span><span>(</span><span>155</span><span>);</span>
<span>man</span><span>.</span><span>l_wrist</span><span>.</span><span>turn</span><span>(</span><span>50</span><span>);</span>
<span>man</span><span>.</span><span>l_fingers</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>10</span><span>);</span>

<span>// right arm</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>tilt</span><span>(</span><span>70</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_elbow</span><span>.</span><span>bend</span><span>(</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>r_wrist</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>r_fingers</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
</code></pre></div></div>

<h3 id="dynamic-posture">Dynamic posture</h3>

<p>The dynamic posture – i.e. a posture that changes over time – is set with the same methods that are used for static posture. Mannequin.js defines an empty function <code>animate(t)</code>, which is called in the animation loop once for each frame. All changes of a posture should be defined inside this function (<a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html">live example</a>). The parameter <em>t</em> is the time, measured in tenths of seconds. This function is set up in <code>createScene()</code>. If <em>createScene</em> and <em>animate</em> are not used, then the animation loop should be managed manually.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-dynamic.jpg"></a></p>

<div><div><pre><code><span>function</span> <span>animate</span><span>(</span><span>t</span><span>)</span>
<span>{</span>
    <span>var</span> <span>time1</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>))</span><span>/</span><span>3</span><span>,</span>
        <span>time2</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>-</span><span>60</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>-</span><span>90</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>-</span><span>120</span><span>))</span><span>/</span><span>3</span><span>;</span>

    <span>ball</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>

    <span>child</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>
    <span>child</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>4</span><span>+</span><span>cos</span><span>(</span><span>90</span><span>*</span><span>time1</span><span>);</span>

    <span>child</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>-</span><span>20</span><span>*</span><span>time1</span><span>+</span><span>20</span><span>*</span><span>time2</span><span>);</span>
    <span>child</span><span>.</span><span>tilt</span><span>(</span><span>10</span><span>*</span><span>time1</span><span>);</span>
    <span>:</span>
	
    <span>scene</span><span>.</span><span>rotation</span><span>.</span><span>y</span> <span>=</span> <span>rad</span><span>(</span><span>30</span><span>*</span><span>time1</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>To make the animation loop faster, all constant rotations should be defined outside <em>animate</em>. Also, if a rotation changing in the loop, there is no need to set it up outside the loop.</p>



<p>Apart for moving body parts, the current version of mannequin.js provides basic functionality for additional modification or accessing the figure.</p>

<h3 id="custom-colors">Custom colors</h3>

<p>By default, all figures use a predefined set of global colors for body parts. Global colors are stored in <code>Mannequin.colors</code> array as six <a href="https://threejs.org/docs/#api/en/math/Color">Three.js colors</a> or lowercase <a href="https://www.w3schools.com/colors/colors_names.asp">HTML/CSS color names</a> in specific order – head, shoes, pelvis, joints, limbs and torso:</p>

<div><div><pre><code><span>Mannequin</span><span>.</span><span>colors</span> <span>=</span> <span>[</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// head</span>
    <span>'</span><span>gray</span><span>'</span><span>,</span>		<span>// shoes</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// pelvis</span>
    <span>'</span><span>burlywood</span><span>'</span><span>,</span>	<span>// joints</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// limbs</span>
    <span>'</span><span>bisque</span><span>'</span>		<span>// torso</span>
<span>];</span>
</code></pre></div></div>

<p>The global color of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boytchev.github.io/mannequin.js/">https://boytchev.github.io/mannequin.js/</a></em></p>]]>
            </description>
            <link>https://boytchev.github.io/mannequin.js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302602</guid>
            <pubDate>Fri, 04 Dec 2020 14:35:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has AI 'solved' protein folding?]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25302487">thread link</a>) | @stuartbman
<br/>
December 4, 2020 | https://explainthispaper.com/ai-solving-protein-folding/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/ai-solving-protein-folding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<h2><b>Has AI 'solved' protein folding? 📎</b></h2>
<div>
<p><i>article</i></p>
<div>
<p>Improved protein structure prediction using potentials from deep learning</p>
<p>Andrew W. Senior, Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre, Tim Green, Chongli Qin, Augustin Žídek, Alexander W. R. Nelson, Alex Bridgland, Hugo Penedones, Stig Petersen, Karen Simonyan, Steve Crossan...</p>
<p><a href="https://www.nature.com/articles/s41586-019-1923-7.epdf?author_access_token=Z_KaZKDqtKzbE7Wd5HtwI9RgN0jAjWel9jnR3ZoTv0MCcgAwHMgRx9mvLjNQdB2TlQQaa7l420UCtGo8vYQ39gg8lFWR9mAZtvsN_1PrccXfIbc6e-tGSgazNL_Xd">Nature</a>
</p></div>
</div>
<div>
<h3>TL;DR</h3>
<p><span><p>Predicting protein folding is a massive problem with huge potential to help us understand disease. It’s been stuck in a rut for the past 50 years, but one team of researchers has come out of nowhere and claims to have solved the problem. But have they?</p></span>
</p></div>
<h3 grey-text="" text-darken-4="">Clinical Need</h3>
<section>
<div>
<p><span>
<div><p>Proteins are made up of amino acids. Getting the amino acid sequence for a protein is pretty easy these days. But going from this sequence to the 3-dimensional shape of the protein is really hard.</p><p>For decades, researchers have worked out protein structures using slow and expensive techniques such as <sample>x-ray crystallography</sample>. So far we’ve only solved about 170,000 proteins using these approaches. Yet more than 200 million proteins have been discovered across all forms of life 😳</p><p>Being able to predict a protein’s shape based on its amino acid sequence would be a game changer. We could design drugs faster by targeting proteins more effectively. But computer-based predictions haven’t been accurate enough to be useful. Until now…</p></div>
</span>
</p>
<div>

<p>X-ray crystallography uses the diffraction of x-rays to work out the shape of a protein. The pictures are murky and there's a lot of guesswork involved!</p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>

</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">What did they do?</h3>
<div><p>The team created a deep learning pipeline for predicting protein shape from its amino acid sequence.</p><p>They entered this neural network into the “Critical Assessment of Protein Structure Prediction” (CASP) competition. Teams are given amino acids sequences for ~100 proteins with unknown structures and asked to predict protein shape. The predictions are given a score from 0-100. Slow techniques (like x-ray crystallography) score above 90.</p></div>
<h3 grey-text="" text-darken-4="">How did the model work?</h3>
<section>
<div>
<p><span>
<div><p>The first version of their model (AlphaFold) performs the following stages:</p><p>First, it looks for similar sequence fragments to the protein of interest from a large protein sequence database. This helps identify features of the protein at interest. An <sample>autoencoder</sample> predicts which protein shape the sequence fragment most likely represents.</p><p>These features are then fed into a convolutional neural network which predicts the distances between different parts of the protein sequence. Predicting distances enables it to also predict contact points.</p><p>Then, using the predicted distances and contact points, the model considers all the possible shapes of the protein and identifies the most likely one.</p></div>
</span>
</p>
<div>

<p>This is a type of neural network that compresses data into a bottleneck of it's most important features, and measures it's performance by reconstructing that bottleneck back up to size. It's an in depth topic worth <a href="https://www.jeremyjordan.me/autoencoders/#:~:text=Autoencoders%20are%20an%20unsupervised%20learning,representation%20of%20the%20original%20input.">reading more on</a></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<p>With the updated model (AlphaFold-2) they made some changes. They haven't released a paper yet (only an abstract), but from what we can tell they used an <sample>attention-based deep learning</sample> to fit over the whole shape of the protein, not just the fragments.</p>
</span>
</p>
<div>

<p>Instead of working over the whole sequence at once, this method allows the learning to 'attend' to subsections individually. This is a bit like trying to translate a long german word- instead of trying to decode the whole word, you break it into sub-words and see how they match, then put it all together.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">How did the model perform?</h3>
<div><p><img alt="Animated Protein" height="450" src="https://explainthispaper.s3.amazonaws.com/images/protein.width-800.png" width="800"></p><p>From the start of the competition in 1994 up to 2016, CASP scores had been around 40. The first time DeepMind entered, they scored up to 60. This year- AlphaFold scored an average of 92.4, smashing the threshold of 90/100!</p><p>In fact, the organisers of the competition thought that DeepMind had been cheating, so they set them a special challenge- a membrane protein from an ancient species of <i>archaea</i>. For 10 years with no success, research teams tried every trick in the book to get an x-ray crystal structure of the protein.</p><p>AlphaFold had no problem, returning an image of a three part protein with two helical arms. In hindsight, this structure fit the x-ray crystallography data perfectly, effectively going beyond the limitations of current human research.</p></div>
<h3 grey-text="" text-darken-4="">So what?</h3>
<section>
<div>
<p><span>
<div><p>This is a thorny problem that researchers and pharmaceutical companies have been working on for 50+ years. This model could predict the shape of proteins without unreliable experimental measurements. This would mean faster development of a wide range of drugs, from cancer drugs that better target proteins for cell replication, to antibiotics that target surface receptors of microbes.</p><p>What’s more, this model was cheap to train- just weeks on quite a <sample>small cluster of servers</sample></p><p>It's worth saying that this isn't the whole picture of protein folding- this still doesn't inform how proteins change shape in the presence of other molecules (like oxygen near haemoglobin). These are also the crystallised protein forms rather than the true 'in vivo' structures, so there may be some errors in translation, but that remains to be seen.</p></div>
</span>
</p>
<div>

<p>Using Google's <a href="https://cloud.google.com/tpu/pricing#pricing_calculator">pricing calculator</a> and the details from the blog post, this could be trained for around $21,000. In the grand scheme of biology and pharmaceuticals, this is pennies!<br></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>

</div>
</div><div>
<h2>The latest papers in your inbox</h2>
<p>Keep up to date with the latest research, summarised concisely and clearly.</p>



</div></div>]]>
            </description>
            <link>https://explainthispaper.com/ai-solving-protein-folding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302487</guid>
            <pubDate>Fri, 04 Dec 2020 14:25:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker’s Guide to Online Anonymity]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25302389">thread link</a>) | @r4um
<br/>
December 4, 2020 | https://anonymousplanet.github.io/thgtoa/guide.html | <a href="https://web.archive.org/web/*/https://anonymousplanet.github.io/thgtoa/guide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<ul>
  <li><a href="#introduction">Introduction:</a></li>
  <li><a href="#requirements">Requirements:</a></li>
  <li><a href="#understanding-some-basics-of-how-some-information-can-lead-back-to-you-and-how-to-mitigate-those">Understanding some basics of how some information can lead back to you and how to mitigate those:</a>
    <ul>
      <li><a href="#your-ip-address">Your IP address:</a></li>
      <li><a href="#your-dns-requests">Your DNS requests:</a></li>
      <li><a href="#your-imei-and-imsi-and-by-extension-your-phone-number">Your IMEI and IMSI (and by extension, your phone number):</a></li>
      <li><a href="#your-wi-fi-mac-address">Your Wi-Fi MAC address:</a></li>
      <li><a href="#your-bluetooth-mac-address">Your Bluetooth MAC address:</a></li>
      <li><a href="#your-operating-systems-and-apps-telemetry-services">Your Operating Systems and Apps telemetry services:</a></li>
      <li><a href="#the-wifis-and-bluetooth-devices-around-you">The WIFIs and Bluetooth devices around you:</a></li>
      <li><a href="#your-metadata-including-your-geo-location">Your Metadata including your Geo-Location:</a></li>
      <li><a href="#your-smart-devices-in-general">Your Smart devices in general:</a></li>
      <li><a href="#your-devices-can-be-tracked-even-when-completely-powered-off">Your Devices can be tracked even when completely powered off:</a></li>
      <li><a href="#your-rfid-enabled-devices">Your RFID enabled devices:</a></li>
      <li><a href="#your-files-propertiesmetadata">Your Files Properties/Metadata:</a></li>
      <li><a href="#your-anonymized-torvpn-traffic">Your “Anonymized” Tor/VPN traffic:</a></li>
      <li><a href="#your-crypto-transactions">Your Crypto transactions:</a></li>
      <li><a href="#exploits-in-your-apps">Exploits in your apps:</a></li>
      <li><a href="#your-cloud-backupssync-services">Your Cloud backups/sync services:</a></li>
      <li><a href="#your-digital-fingerprint-and-footprint">Your Digital Fingerprint And Footprint:</a></li>
      <li><a href="#your-real-life">Your Real Life:</a></li>
      <li><a href="#your-browser-and-device-fingerprints">Your Browser and Device Fingerprints:</a></li>
      <li><a href="#your-face-and-other-biometrics">Your Face and other Biometrics:</a></li>
      <li><a href="#phishing">Phishing:</a></li>
      <li><a href="#forensics">Forensics:</a></li>
      <li><a href="#advanced-targeted-techniques">Advanced targeted techniques:</a></li>
      <li><a href="#notes">Notes:</a></li>
    </ul>
  </li>
  <li><a href="#general-preparations">General Preparations:</a>
    <ul>
      <li><a href="#picking-your-route">Picking your route:</a>
        <ul>
          <li><a href="#budgetmaterial-limitations">Budget/Material limitations:</a></li>
          <li><a href="#skills">Skills:</a></li>
          <li><a href="#adversaries-threats">Adversaries (threats):</a></li>
        </ul>
      </li>
      <li><a href="#steps-for-all-routes">Steps for all routes:</a>
        <ul>
          <li><a href="#get-a-burner-phone">Get a burner phone:</a></li>
          <li><a href="#get-an-anonymous-pre-paid-sim-card">Get an anonymous pre-paid SIM card:</a></li>
          <li><a href="#get-an-usb-key">Get an USB key:</a></li>
          <li><a href="#find-some-safe-places-with-decent-public-wifi">Find some safe places with decent public WIFI:</a></li>
        </ul>
      </li>
      <li><a href="#the-tails-route">The TAILS route:</a></li>
      <li><a href="#steps-for-all-other-routes">Steps for all other routes:</a>
        <ul>
          <li><a href="#get-a-laptop-for-your-anonymous-activities">Get a laptop for your anonymous activities:</a></li>
          <li><a href="#a-note-for-linux-users-to-avoid-wasting-your-time-later">A note for Linux users to avoid wasting your time later:</a></li>
          <li><a href="#biosuefi-settings-of-your-laptop">Bios/UEFI Settings of your laptop:</a></li>
          <li><a href="#tamper-protect-your-laptop">Tamper protect your laptop:</a></li>
        </ul>
      </li>
      <li><a href="#the-whonix-route">The Whonix route:</a>
        <ul>
          <li><a href="#picking-your-host-os-the-os-installed-on-your-laptop">Picking your Host OS (the OS installed on your laptop):</a></li>
          <li><a href="#enable-mac-address-randomization-on-your-laptop">Enable MAC address randomization on your laptop:</a></li>
          <li><a href="#setting-up-a-safe-browser-on-your-host-os">Setting up a safe Browser on your Host OS:</a></li>
          <li><a href="#enable-some-additional-privacy-settings-on-your-host-os">Enable some additional privacy settings on your Host OS:</a></li>
          <li><a href="#windows-host-os-encryption">Windows Host OS encryption:</a></li>
          <li><a href="#virtualbox">Virtualbox:</a></li>
          <li><a href="#get-an-anonymous-cash-paid-vpn-subscription">Get an anonymous (cash-paid) VPN subscription:</a></li>
          <li><a href="#download-various-utilities">Download various utilities:</a></li>
          <li><a href="#whonix-virtual-machines">Whonix Virtual Machines:</a></li>
          <li><a href="#windows-10-virtual-machine">Windows 10 Virtual Machine:</a></li>
          <li><a href="#vpn-client-installation-cash-paid">VPN client installation (cash-paid):</a></li>
          <li><a href="#keepassxc">KeePassXC:</a></li>
        </ul>
      </li>
      <li><a href="#the-qubes-route">The Qubes Route:</a></li>
    </ul>
  </li>
  <li><a href="#creating-your-anonymous-online-identities">Creating your anonymous online identities:</a>
    <ul>
      <li><a href="#understanding-the-methods-used-to-prevent-anonymity-and-verify-identity">Understanding the methods used to prevent anonymity and verify identity:</a>
        <ul>
          <li><a href="#captchas">Captchas:</a></li>
          <li><a href="#phone-verification">Phone verification:</a></li>
          <li><a href="#e-mail-verification">E-Mail verification:</a></li>
          <li><a href="#user-details-checking">User details checking:</a></li>
          <li><a href="#proof-of-id-verification">Proof of ID verification:</a></li>
          <li><a href="#ip-filters">IP Filters:</a></li>
          <li><a href="#browser-and-device-fingerprinting">Browser and Device Fingerprinting:</a></li>
          <li><a href="#human-interaction">Human interaction:</a></li>
          <li><a href="#user-moderation">User Moderation:</a></li>
          <li><a href="#behavioral-analysis">Behavioral Analysis:</a></li>
          <li><a href="#financial-transactions">Financial transactions:</a></li>
          <li><a href="#sign-in-with-some-platform">Sign-in with some platform:</a></li>
          <li><a href="#live-face-recognition-and-biometrics-again">Live Face recognition and biometrics (again):</a></li>
          <li><a href="#manual-reviews">Manual reviews:</a></li>
        </ul>
      </li>
      <li><a href="#getting-online">Getting Online:</a></li>
      <li><a href="#creating-new-identities">Creating new identities:</a></li>
      <li><a href="#protonmail">ProtonMail:</a></li>
      <li><a href="#google">Google:</a></li>
      <li><a href="#twitter">Twitter:</a></li>
      <li><a href="#linkedin">Linkedin:</a></li>
      <li><a href="#microsoft">Microsoft:</a></li>
      <li><a href="#instagram">Instagram:</a></li>
      <li><a href="#facebook">Facebook:</a></li>
      <li><a href="#github">Github:</a></li>
      <li><a href="#discord">Discord:</a></li>
      <li><a href="#telegram">Telegram:</a></li>
      <li><a href="#reddit">Reddit:</a></li>
      <li><a href="#chan">4chan:</a></li>
      <li><a href="#crypto-wallets">Crypto Wallets:</a></li>
      <li><a href="#what-about-those-mobile-only-apps-whatsappsignal">What about those mobile only apps (Whatsapp/Signal):</a></li>
      <li><a href="#anything-else">Anything else:</a></li>
      <li><a href="#maintenance-tasks">Maintenance tasks:</a></li>
    </ul>
  </li>
  <li><a href="#backup-your-work-safely-and-anonymously">Backup your work (safely and anonymously):</a></li>
  <li><a href="#covering-your-tracks">Covering your tracks:</a>
    <ul>
      <li><a href="#protecting-yourself-against-forensics">Protecting yourself against forensics:</a></li>
      <li><a href="#tails">Tails:</a></li>
      <li><a href="#windows-1">Windows:</a>
        <ul>
          <li><a href="#diagnostic-data-and-telemetry">Diagnostic Data and Telemetry:</a></li>
          <li><a href="#eventlogs">Eventlogs:</a></li>
          <li><a href="#veracrypt-history">Veracrypt History:</a></li>
          <li><a href="#external-tool-cleaning">External Tool Cleaning:</a></li>
          <li><a href="#shellbags">Shellbags:</a></li>
          <li><a href="#wi-fi-history">Wi-Fi History:</a></li>
        </ul>
      </li>
      <li><a href="#how-to-securely-wipe-your-whole-laptop-if-you-want-to-erase-everything">How to securely wipe your whole laptop if you want to erase everything:</a>
        <ul>
          <li><a href="#linux-1">Linux:</a></li>
          <li><a href="#windows-2">Windows: </a></li>
        </ul>
      </li>
      <li><a href="#if-you-think-you-got-burned">If you think you got burned:</a>
        <ul>
          <li><a href="#if-you-have-some-time">If you have some time:</a></li>
          <li><a href="#if-you-have-no-time">If you have no time:</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#some-last-opsec-thoughts">Some last OPSEC thoughts:</a></li>
  <li><a href="#appendix-a-windows-installation">Appendix A: (Windows Installation)</a>
    <ul>
      <li><a href="#installation">Installation:</a></li>
      <li><a href="#privacy-settings">Privacy Settings:</a></li>
    </ul>
  </li>
  <li><a href="#appendix-b-windows-additional-privacy-settings">Appendix B: (Windows Additional Privacy Settings)</a></li>
  <li><a href="#appendix-c-windows-installation-media-creation">Appendix C: (Windows Installation Media Creation)</a></li>
</ul>

<p>Version 0.1.1 (draft), December 2020 (work in progress, some parts are incomplete) by AnonymousPlanet</p>

<p>This guide is open-source, licensed under Creative Commons Attribution 4.0 International (cc-by-4.0).</p>

<p>Feel free to submit issues/recommendations/ideas using Github Issues at: <a href="https://github.com/AnonymousPlanet/thgtoa/issues">https://github.com/AnonymousPlanet/thgtoa/issues</a></p>

<p>PDF version of this guide at: <a href="https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf">https://github.com/AnonymousPlanet/thgtoa/raw/main/guide.pdf</a></p>



<p>Making a social media account with a pseudonym or artist/brand name is easy. And it’s enough is most use cases to protect your identity as the next George Orwell. There are plenty of people using pseudonyms all over Facebook/Instagram/Twitter/Linkedin/TikTok/Snapchat/Reddit/… But the vast majority of those are anything but anonymous and can easily be traced to their real identity by your local cops, random people within the OSINT<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> (Open-Source Intelligence) community and trolls<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> on 4chan<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This is a good thing as most criminals/trolls are not really tech savvy and will be identified with ease. But this is also a bad thing as most political dissidents, human rights activists and whistleblowers can also be tracked rather easily.</p>

<p>This updated guide aims to provide introduction to various tracking techniques, id verification techniques and guidance to creating and maintaining anonymous identities online including social media accounts safely.</p>

<p>Will this guide help you protect yourself from the NSA, the FSB, Mark Zuckerberg or the Mossad if they’re out to find you? Probably not … Mossad will be doing “Mossad things” <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup> and will probably find you no matter how hard to try to hide<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>You have to consider your threat model<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> before going further.</p>

<p><img src="https://anonymousplanet.github.io/thgtoa/media/image1.jpeg" alt=""></p>

<p>(Illustration by xkcd.com, licensed under CC BY-NC 2.5)</p>

<p>Will this guide help you protect your privacy from OSINT researchers like Belingcat<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> , Doxing<sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup> trolls on 4chan<sup id="fnref:9" role="doc-noteref"><a href="#fn:9">9</a></sup> and others that have no access to the NSA toolbox? More likely. Tho I wouldn’t be so sure about 4chan.</p>

<p>It’s also important to understand this guide is the humble result of years of experience and testing from a single individual (myself) and that many of those systems that aim to prevent anonymity are opaque closed-source systems. Most of those guidelines are guessed based on experience. These experiences take a lot of time and resources and are unfortunately far from being scientific. <strong>Your mileage may vary.</strong></p>

<p>You might think this guide has no legitimate use but there are many<sup id="fnref:10" role="doc-noteref"><a href="#fn:10">10</a></sup><sup id="fnref:11" role="doc-noteref"><a href="#fn:11">11</a></sup> such as:</p>

<ul>
  <li>
    <p>Evading Censorship</p>
  </li>
  <li>
    <p>Evading Oppression</p>
  </li>
  <li>
    <p>Evading Unlawful Government Surveillance</p>
  </li>
  <li>
    <p>Whistle Blowing</p>
  </li>
  <li>
    <p>Journalism</p>
  </li>
  <li>
    <p>Activism</p>
  </li>
</ul>

<p>This guide is written for use by those good intended individuals who might not be knowledgeable enough to consider the big picture of online anonymity.</p>

<p>This guide is not intended for:</p>

<ul>
  <li>
    <p>Creating machine accounts of any kind (bots).</p>
  </li>
  <li>
    <p>Creating impersonation accounts of existing people (identity theft).</p>
  </li>
  <li>
    <p>Helping malicious individuals conduct unlawful or unethical activities (like trolls).</p>
  </li>
  <li>
    <p>Use by minors.</p>
  </li>
</ul>

<p>Feel free to report issues or recommend improvements in this repository if you have any.</p>

<p><strong>Use at your own risk. Anything in here is not legal advice and you should verify compliance with your local law before use (IANAL</strong><sup id="fnref:12" role="doc-noteref"><a href="#fn:12">12</a></sup><strong>).</strong></p>



<ul>
  <li>
    <p><strong>Be a permanent Adult resident in Germany where the courts have upheld up the legality of not using real names on online platforms (§13 VI of the German Telemedia Act of 2007</strong> <sup id="fnref:13" role="doc-noteref"><a href="#fn:13">13</a></sup><strong>). Alternatively be resident of any other country where you can validate and verify this is legal yourself.</strong></p>
  </li>
  <li>
    <p>This guide will assume you already have access to some PC (Windows/Linux) laptop computer (not a work/shared device).</p>
  </li>
  <li>
    <p>Don’t be evil (for real this time)<sup id="fnref:14" role="doc-noteref"><a href="#fn:14">14</a></sup>.</p>
  </li>
  <li>
    <p>Have patience as this process could take several weeks to finalize.</p>
  </li>
  <li>
    <p>Have a little budget to dedicate to this process (you’ll need at least budget for an USB key).</p>
  </li>
  <li>
    <p>Have a lot of free time on your hands to dedicate to this process.</p>
  </li>
  <li>
    <p>Be prepared to read a lot of references (do read them), guides (don’t skip them) and follow a lot of how-to tutorials thoroughly (don’t skip them either).</p>
  </li>
</ul>

<p><strong>This guide will (for the moment) not recommend using MacOS due to the latest Big Sur update which forces “unblockable” telemetry</strong><sup id="fnref:15" role="doc-noteref"><a href="#fn:15">15</a></sup><sup id="fnref:16" role="doc-noteref"><a href="#fn:16">16</a></sup> <strong>and because MacOS doesn’t offer MAC address randomization.</strong></p>



<p>There are many ways you can be tracked besides browser cookies and ads, your e-mail and your phone number. And if you think only the Mossad or the NSA/FSB can find you, you would be terribly wrong.</p>

<p>Here is a non-exhaustive list of some of the many ways you can be de-anonymized:</p>

<h2 id="your-ip-address">Your IP address:</h2>

<p>Your IP address<sup id="fnref:17" role="doc-noteref"><a href="#fn:17">17</a></sup> is the most known and obvious way you can be tracked. That IP is the IP you’re using at the source. This is where you connect to the internet. That IP is usually provided by your ISP (Internet Service Provider) (xDSL, Mobile, Cable, Fiber, Cafe, Bar, Friend, Neighbor). Most countries have data retention regulations<sup id="fnref:18" role="doc-noteref"><a href="#fn:18">18</a></sup> which mandates keeping logs of who is using what IP at a certain time/date for up to several years or indefinitely. Your ISP can tell a third party that you were using a specific IP at a specific date and time, years after the fact. If that IP (the origin one) leaks at any point for any reason, it can be used to track down you directly. In many countries, you won’t be able to have internet access without providing some form of identification to the provider (address, ID, real name, e-mail …).</p>

<p>Useless to say that most platforms (such as social networks) will also keep (sometimes indefinitely) the IP addresses you used to sign-up but also those you used to sign-in.</p>

<p>For those reasons, we’ll need to not use that origin IP (the one tied to your identification) or hide it as much as we can through a combination of various means:</p>

<ul>
  <li>
    <p>Using a public WIFI service (free).</p>
  </li>
  <li>
    <p>Using an anonymous VPN service<sup id="fnref:19" role="doc-noteref"><a href="#fn:19">19</a></sup> (paid by cash).</p>
  </li>
  <li>
    <p>Using the Tor Anonymity Network<sup id="fnref:20" role="doc-noteref"><a href="#fn:20">20</a></sup> (free).</p>
  </li>
</ul>

<p>All those will be explained later in this guide.</p>

<h2 id="your-dns-requests">Your DNS requests:</h2>

<p>DNS stands for “Domain Name System”<sup id="fnref:21" role="doc-noteref"><a href="#fn:21">21</a></sup> and is a service used by your browser (and other apps) to find the IP addresses of a service. It’s pretty much a huge “contact list” (phone book for older people) that works like asking it a name and it returns the number to call. Except it returns an IP instead.</p>

<p>Every time your browser wants to access a certain service such as Google through <a href="https://www.google.com/">https://www.google.com</a>. Your Browser (Chrome or Firefox) will query a DNS service to find the IP addresses of the Google web servers.</p>

<p>Usually the DNS service is provided by your ISP and automatically configured by the network you’re connecting to. This DNS service could also be subject to data retention regulations or will just keep logs for other reasons (data collection for advertising purposes for instance). Therefore this ISP will be capable of …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://anonymousplanet.github.io/thgtoa/guide.html">https://anonymousplanet.github.io/thgtoa/guide.html</a></em></p>]]>
            </description>
            <link>https://anonymousplanet.github.io/thgtoa/guide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302389</guid>
            <pubDate>Fri, 04 Dec 2020 14:14:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Reading]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25302132">thread link</a>) | @accountLost
<br/>
December 4, 2020 | https://maartenvandoorn.nl/reading-guide/ | <a href="https://web.archive.org/web/*/https://maartenvandoorn.nl/reading-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1454">

	<!-- .entry-header -->



	<div>

		
<figure><img src="https://cdn-images-1.medium.com/max/2600/1*0tmBPKA1YGo82VNeMS3KhA.jpeg" alt=""><figcaption> <a rel="noreferrer noopener" href="https://unsplash.com/photos/9pw4TKvT3po?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Let’s make that magic&nbsp;happen</a> </figcaption></figure>



<p>Learning is a heavily misunderstood&nbsp;concept.</p>



<p>As a&nbsp;paradigm&nbsp;example of&nbsp;deep work,&nbsp;we understand that, when reading, directing your full attention to the material at hand is essential.&nbsp;Graspingcomplex information is hard.</p>



<p>But this is only half the battle.</p>



<p>After some string of words hits your retina and has made its way to your brain, you’re&nbsp;not done.</p>



<p>In a&nbsp;cruel&nbsp;irony,&nbsp;these hours of&nbsp;deep work&nbsp;often cause&nbsp;flow&nbsp;states&nbsp;and the feeling that ‘you’ve had a good day’ and learned a&nbsp;shitload&nbsp;of new stuff.</p>



<p>But for many reading&nbsp;episodes&nbsp;this feeling is&nbsp;deceptive.&nbsp;There is anineliminable&nbsp;aspect to learning that takes place&nbsp;<em>after&nbsp;</em>the&nbsp;glorious&nbsp;flow state.</p>



<p>The&nbsp;other half of the battle is&nbsp;to&nbsp;transfer the newly acquired intelligence from your working memory to your&nbsp;long-term&nbsp;understanding and&nbsp;integrate&nbsp;it into your standing stack of mental models.</p>



<p>If you don’t&nbsp;facilitate&nbsp;this, your learning&nbsp;gains&nbsp;are only a&nbsp;fraction&nbsp;of what they could have been.</p>



<p>In this article,&nbsp;I’m going to breakdown how to win the battle and the war — how to&nbsp;avoid&nbsp;these traps and organize your reading habit for a maximalReturn On Investment (ROI)&nbsp;on reading hours.</p>



<p>This is what we’ll cover:</p>



<pre><strong>Table of Contents</strong></pre>



<pre>1. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1b1d">Meta-Learning</a><br>2. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1d70">Learning is a two-step process</a><br>3. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9181">Remembering the right things</a><br>4. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7b89">Enter: Mental models</a><br>5. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a837">Learning = upgrading your mental models</a></pre>



<pre>6. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f0d0">How to ‘get it in there’ (macro-level)</a><br>7. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8823">How to ‘get it in there’ (micro level)</a><br>7.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#19fe">Know your why</a></pre>



<pre>8. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d988">Active reading</a><br>8.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#414f">How to make a mind map</a><br>8.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#ad79">Which Returns are you aiming for?</a><br>8.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d61e">Written active recall with bullet points</a><br>8.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a187">How to actively read a book</a><br>8.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8ead">Remember your why (yes, again)</a></pre>



<pre>9. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#4e04">Advanced active reading</a><br>9.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9782">The QEC method</a><br>9.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8dac">Keep a running tally</a><br>9.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#dc6b">Put your unconsciousness to work</a><br>9.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7a10">Pulling it all together</a><br>9.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#6b84">How to actively read a book (advanced)</a></pre>



<pre>10. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#926b">Organizing repetition and reflection</a><br>10.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f934">Setting up and using your review cycle</a><br>10.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#5182">Improved learning: engage in active recall</a></pre>



<pre><a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#fc24">Conclusion: The cycle of learning</a></pre>



<p>Warning: this is a very&nbsp;nerdy&nbsp;post.</p>



<h3 id="1b1d">Meta-Learning</h3>



<p>Meta-learning&nbsp;is knowing how to learn.&nbsp;It is one of the most important skills to learn, yet few people know how to do to it.</p>



<p>Reading and writing is what I do for a living, and, interestingly, a lot of non-imaginary&nbsp;friends have been asking me how I learn.&nbsp;This is special, becausemost of the times when people don’t know how to do something, they go&nbsp;togreat&nbsp;lengths&nbsp;<em>not&nbsp;</em>to notice their&nbsp;deficiency.</p>



<p>Could it be that many students turned ‘knowledge workers’ have the&nbsp;naggingfeeling that something is missing in their skillset because they were never taught&nbsp;meta-learning?</p>



<p>This is not their fault, but a&nbsp;<a href="https://medium.com/the-understanding-project/schools-dont-support-personal-development-they-distort-it-7e1c227eb01d" target="_blank" rel="noreferrer noopener">lack in our education system</a>.</p>



<p>As Adam Robinson observed on the&nbsp;<a href="https://fs.blog/adam-robinson-pt2/" rel="noreferrer noopener" target="_blank"><em>Farnam Street&nbsp;</em>podcast</a>:</p>



<blockquote><p>“<strong>No one ever shows us how to learn, ever</strong>.&nbsp;Nowhere in school.&nbsp;For example, imagine, Shane, [Shane is the host of the FS podcast] in French class, French 101, your first French class, your teacher said,&nbsp;“Everyone, you’re going to have to learn a lot of vocabulary in this class so before I teach you any words I’m going to teach you a way to remember vocabulary.”&nbsp;They never do that.&nbsp;They just go, “We’re going to have a quiz on these 30 words on Monday.&nbsp;Good luck.”&nbsp;But they don’t teach us how to learn actually, or remember things.”</p></blockquote>



<p>This is&nbsp;weird, because,&nbsp;in today’s high-information world,&nbsp;people need the ability to&nbsp;<em>make sense of</em>&nbsp;complexity and to&nbsp;<em>combine</em>&nbsp;many bits of data into a broad picture of the world.</p>



<p>Merely&nbsp;<em>acquiring</em>information is&nbsp;<em>not&nbsp;</em>(yet) learning.</p>



<p>Learning itself is a skill, and knowing how to do it well is an incredibly valuable advantage.</p>



<p>We take this is for granted, but how to do this is&nbsp;far from&nbsp;obvious&nbsp;and doesn’t get taught in the curriculum.</p>



<hr>



<h3 id="1d70">Learning is a&nbsp;two-step&nbsp;process</h3>



<p>So, how do we learn?</p>



<p>Before we attempt to answer the question,&nbsp;let’s get clear&nbsp;on what a&nbsp;satisfactoryanswer needs to get us.&nbsp;What does it&nbsp;<em>mean&nbsp;</em>to learn?&nbsp;When have you learned something?</p>



<p>In the introduction, I stated that&nbsp;just studying the information isn’t enough(no matter how intense your focus was).&nbsp;Learning has&nbsp;two phases — not one.</p>



<ol><li>Read/listen&nbsp;the damn thing</li><li>Process and&nbsp;recall&nbsp;what you’ve just ‘learned’</li></ol>



<p>A lot has been said about the first phase — about deep work, concentration, blocking out&nbsp;distractions, and so&nbsp;forth.&nbsp;This makes sense:&nbsp;if you’re checking Facebook all the time,&nbsp;your mind is not ‘there’, and you might as well not have spent your afternoon ’reading’ this book.</p>



<p>This is all great and I‘m a big fan, but in the&nbsp;meantime, we’re ignoring step two.</p>



<p>If you don’t spend time revisiting and grappling with the book either,&nbsp;<em>the same applies</em> — you might as well not have read it.&nbsp;In the long run, there is no difference between skipping the first or the second stage (except whether you passed that French test in high school back in 2019…).</p>



<p>After you’ve killed Cersei, you’ve still got the&nbsp;White Walkers to deal with.&nbsp;If you don’t, you lose either way.</p>



<p>That is why students who&nbsp;binge-study&nbsp;the night before the exam quite literally forget everything two days later:&nbsp;while all these&nbsp;lame&nbsp;French words were still in their short-term memory,&nbsp;allowing them to pass the test,&nbsp;the information never&nbsp;transitioned&nbsp;to their long-term understanding — and so, sooner or later, it&nbsp;evaporated.</p>



<p>To learn,&nbsp;you need to transfer the newly acquired intelligence from&nbsp;your working memory to your long-term understanding.</p>



<p><strong>The jump from short-term memory to long-term understanding doesn’t happen automatically.</strong><strong>The default mode, after you close your books for the day, is not&nbsp;</strong><strong>retainment</strong><strong>&nbsp;but&nbsp;<em>forgetting</em></strong><strong>.</strong></p>



<p>This learning guide&nbsp;is not about&nbsp;<a href="https://medium.com/the-understanding-project/why-you-dont-need-to-read-those-productivity-guides-347fe02cc196" target="_blank" rel="noreferrer noopener">how to do generic deep work</a>.&nbsp;It explains how to maximize the ROI on hours spent reading,&nbsp;<em>assuming</em>&nbsp;you did them ‘deep work style’.</p>



<h3 id="9181">Remembering the right&nbsp;things</h3>



<p>First, I need to discuss a common&nbsp;objection&nbsp;that denies phase two of learning matters.&nbsp;If you have no&nbsp;quibble&nbsp;with memorization, and doing the required effort, you can skip this section.</p>



<p>“But Mr. Maarten,” the protest goes, “you mention ‘processing’ and ‘remembering’ into my ‘long-term understanding’, but isn’t memorizing pointless?&nbsp;My Google Assistant can look everything up and also is smarter than me, says my Google Assistant.”</p>



<p>Indeed,&nbsp;Albert Einstein is&nbsp;<a href="https://medium.com/the-polymath-project/studying-history-is-more-important-than-ever-in-todays-economy-c99fde4be7d0" target="_blank" rel="noreferrer noopener">supposed</a>&nbsp;to have said:&nbsp;“Never&nbsp;memorize&nbsp;what you can look up in a book”.&nbsp;In Einstein’s days, books were&nbsp;unequaled&nbsp;as a source of information.&nbsp;We, on the other hand, live in an age where nearly everything can be accessed through the magic vehicle of internet.&nbsp;Following Einstein’s logic, then,&nbsp;<em>nothing&nbsp;</em>is worth memorizing anymore, because&nbsp;<em>everything</em>&nbsp;can be looked up.</p>



<p>But, of course, that is probably not what old Albert was getting at.</p>



<p>Most likely,&nbsp;the advice he wanted to&nbsp;dispense&nbsp;was that&nbsp;you should not waste your time by committing unimportant details to memory.&nbsp;Rather,&nbsp;your&nbsp;focus should be on understanding the bigger picture — on&nbsp;how things relate to each other.</p>



<p>This reminds me of Elon Musk’s&nbsp;approach to learning.&nbsp;He&nbsp;<a href="https://www.reddit.com/r/IAmA/comments/2rgsan/i_am_elon_musk_ceocto_of_a_rocket_company_ama/" rel="noreferrer noopener" target="_blank">recommends</a>viewing knowledge as a tree:</p>



<blockquote><p>Make sure you understand the fundamental principles, the trunk and big branches, before you get into the leaves/details or there is nothing for them to hang on to.</p></blockquote>



<p>To ‘learn’, we need to do more than merely feeding ourselves new information.&nbsp;Expanding our intelligence requires&nbsp;<em>connecting</em>&nbsp;new materials to what we already knew&nbsp;(the second phase of learning).&nbsp;That, in turn, requires something to connect&nbsp;<em>to.</em></p>



<p>There’s no adding branches without a solid trunk.</p>



<p>The very possibility of genuine insight requires a memorized base.&nbsp;Without it, data you consume will not be added to your tree of knowledge.&nbsp;Instead, they will float in the air for a couple of weeks or so, before being taken away by the wind.</p>



<p>Knowledge, gone.&nbsp;Time, wasted.</p>



<p>What I’m saying is&nbsp;<em>not&nbsp;</em>that we should&nbsp;devise&nbsp;techniques which enable us torecite&nbsp;everything we’ve learned.&nbsp;That’s why we’re not talking about, for example,&nbsp;retaining&nbsp;the date of the French revolution.</p>



<p>However,&nbsp;you&nbsp;<em>should&nbsp;</em>learn by heart the lessons it tells you about how the world works&nbsp;and update your representation of reality&nbsp;accordingly.</p>



<p>In&nbsp;other words,&nbsp;you should use it to&nbsp;inform&nbsp;your&nbsp;unconscious — the&nbsp;sum&nbsp;of your mental models.</p>



<h3 id="7b89">Enter: Mental&nbsp;models</h3>



<p>I’ve long been skeptical about mental models since (1) they’re all the rage now and (2) no one seems to be able to explain in concrete terms what they are. A dangerous combination.</p>



<p>It turned out my doubt was due to ignorance on my part.</p>



<p>A mental model,&nbsp;as&nbsp;<a href="https://en.wikipedia.org/wiki/Mental_model" rel="noreferrer noopener" target="_blank">Wikipedia</a>&nbsp;tells us, is</p>



<blockquote><p>An explanation of someone’s thought process about how something works in the real world.&nbsp;<strong>It is a representation of the surrounding world</strong>, the relationships between its various parts and a person’s intuitive perception about his or her own acts and their consequences.</p></blockquote>



<p>Every problem and situation is just another ‘one of those’ — another one of a certain type.&nbsp;Figuring out what type it is and reflecting on principles for handling that type of issue will help you do a better job.</p>



<p>On the conscious level, mental models allow us to ‘fit’ different possible interpretations onto reality to see if it is ‘one of those’.</p>



<p>For example,&nbsp;according to&nbsp;<a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor" rel="noreferrer noopener" target="_blank">Hanlon’s Razor</a>&nbsp;one should&nbsp;“never attribute tomalice&nbsp;that which is adequately explained by carelessness”.&nbsp;When your coworker hands you crappy slides for the presentation you have to give in five minutes — what’s going on here?</p>



<p>Which ‘one of those’ do we have here?</p>



<p>You can see&nbsp;how different mental models in our heads will cause us to reach different conclusions about the correct interpretation of the situation.</p>



<p>A mental model is a mental, simplified&nbsp;depiction&nbsp;of how something works.They are how we order complexity, why we consider some things more relevant than others, and how we reason.&nbsp;They help us filter, organize and understand.</p>



<p>For instance, according to&nbsp;<a href="https://en.wikipedia.org/wiki/Pareto_distribution" rel="noreferrer noopener" target="_blank">Pareto distribution</a>,&nbsp;“for many events,&nbsp;roughly 80% of the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maartenvandoorn.nl/reading-guide/">https://maartenvandoorn.nl/reading-guide/</a></em></p>]]>
            </description>
            <link>https://maartenvandoorn.nl/reading-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302132</guid>
            <pubDate>Fri, 04 Dec 2020 13:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Google Analytics without GDPR consent]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25301500">thread link</a>) | @evrimfeyyaz
<br/>
December 4, 2020 | https://evrim.io/using-google-analytics-without-gdpr-consent/ | <a href="https://web.archive.org/web/*/https://evrim.io/using-google-analytics-without-gdpr-consent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://evrim.io/using-google-analytics-without-gdpr-consent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301500</guid>
            <pubDate>Fri, 04 Dec 2020 12:23:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Sea Turtles Find Their Way]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25301247">thread link</a>) | @dnetesn
<br/>
December 4, 2020 | http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>T</span>he air was warm as the skies grew dark over Diego Garcia. As the nearly full moon reached its highest point, a green sea turtle scuttled her way onto the sand. The ocean giant was more than a meter wide and nearly as long from nose to tail. Her carapace, mottled with splotches of green and black, was slick with salt water.&nbsp;</p>

<p>Turtles glide through the sea with a certain reptilian elegance, but on land their awkward, plodding movements evoke a wind-up toy in need of a few more cranks. After shuffling a suitable distance from the waterline, the turtle began to excavate a shallow hole, using her arms and legs like spades to fling pebbles and sand through the air. Nearly exhausted, she finally began to relax as she released dozens of ping-pong ball-sized eggs into the ground.</p>
<p>It was likely the first time in years sheâ€™d set flipper on dry land. Other than the moments after they hatch and crawl into the surf, sea turtles spend their entire lives in the ocean. Only when females return to lay eggs on the same beaches where they hatched do they leave the water—just briefly, for a few hours, before slipping back into the sea. They may lay several clutches of eggs during the mating season before setting off for their foraging territories. There they stay for several years, regaining energy by feasting on seagrass, before returning to their natal beach, mating just offshore, and beginning the cycle anew.</p>
<p>Having carried out the full extent of her duties as a mother, this turtle had completed a ritual thatâ€™s played out countless times on Diego Garcia, a footprint-shaped atoll in the Indian Ocean's Chagos Archipelago. Green sea turtles have used the atoll as an incubator for hundreds or thousands of generations, or perhaps longer. Each generation disperses and returns; precisely where these now-endangered reptiles go, what route they take to get there, and how they navigate, is a mystery.</p>
<p>And so on that moonlit night in October of 2017 volunteers from the U.S. military facility on Diego Garcia helped <a href="https://www.swansea.ac.uk/staff/science/biosciences/esteban-n/" target="_blank">Nicole Esteban</a>, a marine biologist and sea turtle conservationist at Swansea University, fasten a GPS transmitter to the top of the turtle's shell while she laid her eggs. The volunteers nicknamed the turtle Serenity and watched as she and the computer on her back crept back into the waves and disappeared.</p>
<p>Three months later, Serenity reached her foraging waters along a small island called Farquhar Atoll in the Seychelles archipelago. It is some four thousand kilometers west of Diego Garcia, but the GPS signals traced a circuitous route that wound through more than six thousand kilometers of open ocean. Had she had taken a more direct path, she could have accomplished the entire journey in under a month.</p>
<blockquote>Precisely where these now-endangered reptiles go, what route they take to get there, and how they navigate, is a mystery.</blockquote>
<p>It was an unusual trip in other ways, too. Typically when biologists track turtles from their nesting beaches on small islands, most wind up in coastal territory, having paddled across the open ocean until hitting a continental shelf and then turning left or right. But Serenity ended up on a flyspeck island, and many others of her cohort—Estebanâ€™s team tagged a total of 35 turtles over five years—followed suit.</p>
<p>"A number of these turtles migrated to very, very small island targets, some not more than a couple of hundred meters square,â€� says Alex Rattray, a biologist at Deakin University who was also involved in the research. A few did travel more than 5000 kilometers west to the coastlines of Somalia and Mozambique, but others pulled up short of the coast, joining Serenity elsewhere in the Seychelles archipelago; still others swam north to the Maldives islands.</p>
<p>Their destinations underscored the extraordinary nature of sea turtle migration. Itâ€™s astonishing enough that a sea turtle can navigate across thousands of miles of open ocean, with no discernible landmarks, and wind up in the correct place. Even more astonishing is when the correct place is a dot of sand with nothing but blue until the horizon in every direction.</p>
<p>It's a feat that bewildered Charles Darwin. "Even if we grant to animals a sense of the points of the compass, of which there is no evidence," he wrote, "how can we account, for instance, for the turtles which formerly congregated in multitudes, only at one season of the year, on the shores of the Isle of Ascension, finding their way to that speck of land in the midst of the great Atlantic Ocean."</p>
<p>Since Darwin wrote those words in 1873, scientists have tried to understand just how turtles make these awesome journeys. Before the invention of GPS technology, sailors crossing the globe relied on a combination of complex mechanical instruments and accurate timepieces. Much remains unknown about how turtles accomplish the same task, the only tools at their disposal resting within their own brains and bodies—but biologists have come a long way in understanding how sea turtles find their way.</p>
<center>
<iframe width="733" height="412" src="https://player.vimeo.com/video/486666840?color=ffcd05&amp;title=0&amp;byline=0&amp;portrait=0" frameborder="0" allowfullscreen=""></iframe>
</center>
<p>The animated travel tracks of 35 green sea turtle migrations tracked from nesting beaches in the Chagos archipelago. Hays et al./<em>Current Biology</em></p>

<p><span>I</span>n the first month after slipping off the beaches of Diego Garcia, Serenity had logged nearly four thousand kilometers. She was still in the open ocean, north and a little east of Madagascar. Rattray wouldn't know it yet, but when he switched his computer on to check on her progress, he would find Serenity at almost precisely the longitude of her final destination in <a href="https://en.wikipedia.org/wiki/Farquhar_Atoll" target="_blank">Farquhar Atoll</a>. There was just one problem: was she was at the wrong latitude.</p>
<p>The turtle had missed her target by some two hundred kilometers. That would be like walking from New York City to Los Angeles, but accidentally winding up in Tijuana, Mexico instead. But rather than take a right turn and swim north, she kept heading west, further and further away from her goal.</p>
<p>So how did she get back on course?</p>
<p>Whether you're a sea turtle or a ship's captain, finding your way around the planet requires two tools: a map and a compass. A map tells you where you are relative to some other location: where you started out, for example, or where you want to go. A compass helps to keep you moving in a reasonably straight line.</p>
<p>"There's all sorts of ways to set and maintain a heading," says marine biologist <a href="https://lgl.com/en/staff/staff-directory/179-putman-nathan" target="_blank">Nathan Putman</a>, who studies navigation in sea turtles and salmon. Animals who have good vision can orient based on the polarization of sun light, as some birds are thought to do, or based on the position of stars in the night sky, as in dung beetles. If animals can marry their vision to an internal clock, then they can use the sun's position as a compass, accounting for its movement across the sky throughout the day. It's thought that a time-compensated sun compass, as it is called, is one of the tools that migrating monarch butterflies use to maintain their headings.</p>
<p>Other animals might orient based on the direction that persistent winds blow or the direction waves travel through the ocean. Indeed, when loggerhead sea turtles first hatch on Florida beaches, they know to swim directly into oncoming waves, a strategy that deposits them into the Gulf Stream, part of a larger network of currents called the North Atlantic Sub-tropical Gyre. These currents, which stretch from the eastern seaboard across to southern Europe and northern Africa, encircle a region known as the Sargasso Sea. By staying within the gyre, vulnerable young sea turtles can remain relatively safe.</p>
<p>In 1989 a meteorological fluke helped Ken Lohmann, a biologist at the University of North Carolina at Chapel Hill, confirm that hatchlings use waves as a guide. That year, Hurricane Hugo temporarily caused waves to travel towards the open ocean rather than towards Florida's Atlantic coast. When Lohmann dropped newly hatched turtles into these conditions, they swam into the waves, just as their innate programming instructed them to—and as a result, they went the wrong way.</p>
<p>But what if turtles were to hatch on a calm, windless night with no waves to point the way? Lohmann brought hatchlings into a laboratory to find out. In complete darkness and with no other cues available to guide them, they swam towards the northeast, which in their natural environs would have safely launched them into the Gulf Stream. When he then induced an artificial magnetic field around the tanks, the turtles continued in what they thought was a northeasterly direction. In reality, thanks to Lohmann's magnetic misdirection, they were swimming in precisely the opposite direction. The results confirmed that they really did use Earth's magnetic field.</p>
<blockquote>Sea turtles hatch with at least two strategies for finding their way pre-programmed into their brains: the movement of waves and the Earth's magnetic field.</blockquote>

<p>Taken together, Lohmannâ€™s experiments revealed that sea turtles hatch with at least two strategies for finding their way pre-programmed into their brains: the movement of waves and the Earth's magnetic field.</p>
<p>Currents around Diego Garcia are of course different from those off the Florida coast. Turtles born in Diego Garcia are delivered into the South Equatorial Current, which is part of a larger system called the Indian Ocean Gyre. The parameters of Earth's magnetic field differ as well. But the underlying principle remains the same: turtles are born with a set of instructions that, at least most of the time, safely delivers them into the open ocean.</p>
<p>"Offshore migration is really just the first part in a longer transoceanic migration,â€� says Lohmann, one that occupies the first five to eight years of a sea turtleâ€™s life—a period sometimes called â€œthe lost years,â€� spent in the open ocean, where sea turtles were once thought to lazily drift wherever the currents took them. But Lohmann realized that this strategy could be deadly.&nbsp;</p>
<p>If turtles in Florida floated passively on the North Atlantic Sub-tropical Gyre, for example, then after they cross the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way">http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/644/how-sea-turtles-find-their-way</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301247</guid>
            <pubDate>Fri, 04 Dec 2020 11:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wikipedia's in Trouble (2019)]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 86 (<a href="https://news.ycombinator.com/item?id=25300942">thread link</a>) | @sanqui
<br/>
December 4, 2020 | http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
I got involved in wikipedia <a href="https://en.wikipedia.org/w/index.php?title=User%3ASpencerk&amp;action=history&amp;year=2006&amp;month=-1&amp;tagfilter=">very early</a>.

It was one of the most revealing things in my life, watching it being laughed at, to become the center of, and authority of, human knowledge.

It was obvious that it was working. The lag of this was 5 years or more.

Wikipedia was an experiment that proved itself, when every graph was going up and to the right.

Some of the graphs are now going down.

</p><p>Wikipedia's Markup language:</p><p>
One of the central design decisions in wikipedia is that <span>all information</span> is stored in an editable document.
This poses a huge amount of challenges for caching and scaling wikipedia. It's not a database, that you can run a script on.

Worse though, is that all of it's content is buried in this ad-hoc, impenetrable, opaque, and mostly <i>un-parsable</i> format.

If wikipedia had used <i>markdown</i>, <i>html</i>, or some <i>standardised format</i>, any parser would flip-it into other future formats.

Wikipedia's custom language is just <a href="https://github.com/spencermountain/wtf_wikipedia/blob/master/README.md">clearly insane</a>, undocumented, hopeless.
There's a team <span>(of great people!)</span> at wikimedia <a href="https://phabricator.wikimedia.org/tag/parsoid/">constantly working on it</a>, and unable to make any backwards-incompatible changes. I imagine their lives are hard.
People are creating weird new syntax concepts all the time.

Here's the markup for the <b>first sentence</b> of the Albert Einstein wikipedia article:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/albert-einstein.jpg">

The first wikimedia parser was called <a href="https://github.com/earwig/mwparserfromhell/">mwparserfromhell</a>. DBPedia, <a href="https://upload.wikimedia.org/wikipedia/commons/a/a9/LOD_Cloud_2014-08.svg">the center of the semantic web</a>, after years of work, has only ever offered limited parsing from categories and infoboxes.
Much of the early-years at <b>Freebase</b> were spent trying, with limited-success, at parsing wikipedia.
I've spent <a href="https://github.com/spencermountain/wtf_wikipedia/graphs/commit-activity">years</a> trying to parse it myself.
I'm a shitty programmer. <i>WolframAlpha</i>, and many other serious companies are using my parser,
       which is <span>down right hilarious</span>.

<img id="rtl" src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/rtl.jpg"></p><p>yes, arabic editors must write it in right-to-left, <a href="https://youtu.be/OCQd02hORJQ">somehow</a>.</p><p>

It's hard to describe how much of a serious problem this is.
Wikipedia's content is never going to go anywhere, or be used by anything.

Wikipedia may slowly die-off - like myspace, or geocities - but it's information will not go on.

Play-around in the official wikipedia android app. Many pages are unreadable.
There is a good-deal of <i>clearfix</i>, and <span>table-span</span> logic, mushed right into the syntax.
Most developers will not touch this kind of stuff.

There will be no move to a wikipedia 2.

</p><p>Static copies of dynamic content</p><p>
The contents of the english wikipedia dump are as follows, (as of Jan 2019):
</p><p>
of the <b>14m</b> records in the wikipedia dump, only <b>5.5m</b> (40%) are public-facing articles.

   <span>Yup.</span>
This does not include deleted pages, or old versions, either.


<b>Redirects:</b>
A computer-science 101 problem is to implement a fuzzy string matching. There's usually a section in the textbook about it:
</p><div>
<p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/clr.jpg"></p><p>oh yes, right here in chapter 34.</p><p>
there are <b>8,550,441</b> redirects in wikipedia.
They are mostly typos, or case-changes, and are mostly created by hand, every day.

<span>and what happens to a redirect when a page gets deleted, or merged, or spli - <a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot">Yup</a>.</span>
</p></div>

<p><b>Talk pages:</b>
Wikipedia has 35m registered users. When a user joins, a bot will often send them a <a href="https://en.wikipedia.org/wiki/Template:Welcome">{{welcome}}</a> template.
Sometimes nice users will do it themselves. It looks <a href="https://en.wikipedia.org/wiki/User_talk:Kj_aviator">like this</a>.

   - when this happens, this creates a new user page, with <b>a copy of this text</b> each time.

There are millions of examples of this in the dump. The same text, verbatim over and over.

The same process happens with <b>'Wikiprojects'</b>. Bots go around adding templates, by creating a talk page, and adding a template to it.

The same process happens with <i>deleted pages, fair-use warnings, and some bot edits</i>. Each time an edit happens, a new page is created, and boilerplate text gets thrown into it.
Resulting in <a href="https://en.wikipedia.org/wiki/Talk:XTC_discography">this</a>:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/boilerplate.png"></p><hr><p>
So let's get things straight:
in <b>1993</b>, a small japanese game company created <a href="https://en.wikipedia.org/wiki/A-Rank_Thunder_Tanjouhen">this videogame</a>:
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/thunder.jpg">
</p><p>
• In <b>2008</b>, a wikipedia user created the article with <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">two sentences and a link</a>.

• In the past 10 years since, the page has been edited <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">26 times by bots</a>.

• this created a Talk page filled with <a href="https://en.wikipedia.org/wiki/Talk:A-Rank_Thunder_Tanjouhen">11 automated sentences</a>.

A huge bulk of the wikipedia database is this boilerplate text. See <a href="https://en.wikipedia.org/wiki/Talk:764_Gedania">this asteroid</a>, <a href="https://en.wikipedia.org/wiki/Talk:NS3_(HCV)">this virus</a>, or this <a href="https://en.wikipedia.org/wiki/Talk:Oceania_Judo_Union">judo club</a>.

... and remember, if we wanted to change this text, we'd have to go and edit each of these pages - and because this syntax is so nuts, <b>bots have a hard time</b> making even simple stylistic changes, without ruining a whole page.

oh, so what happens to these auto-generated talk pages when a page is deleted, merged, or spli- <a href="https://en.wikipedia.org/wiki/Talk:578_Happelia">yup</a>

<b id="automation">Automated articles:</b>
There is a lot of disagreement about how much of wikipedia is generated by bots, and if this matters.
There's no way of knowing. Any boring-themed article with a few sentences, a reference, and an infobox probably won't get deleted.
So nothing's stopping you from spitting-out articles from a <b>database of enzymes</b>, or <b>college rugby players</b>, or season statistics for defunct sports teams.
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/enzymes.jpg">
  <img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/subgiants.png">
</p><p>
I have nothing against bots, I have nothing against the long-tail, but I think automated article-creation is responsible for a good amount of the wikipedia's claimed growth, over the past few years.
We need to be up-front about this, if we're talking about the health of the project.

Here's the distribution of words in english wikipedia, by the size of articles:
</p>

<div>
<p><span>ok hey,</span> I don't mind that the wm developers didn't develop a fancy search index, in 2001.
That's fine.
Nobody could have predicted the success and scale of wikipedia early on.
</p><p>
What angers me though
         - <i>and it should anger you</i> -
is that these problems has not been fixed in the <b>18 years</b> since.

God damn them.

Well-meaning people are wasting their time on this <span>everyday</span>.

Any <i>startup job-interview</i> asks questions about implementing a system like this.
Any CS grad can create a lucene index, to handle typos.
Some of it is complicated. Some of it is basic competence.

<span>It's annoying to whine</span>,
     but at some point, we're right to be angry at wikipedia.

            that it cannot find 2nd gear,
     when the rest of the world is zipping-along.
</p>
</div>

<p>Wikidata</p><p>
In 2007 Danny Hillis raised $57 million dollars,<a href="https://www.crunchbase.com/organization/metawebtechnologies#section-overview">[1]</a> bought-out the <b>entire</b> MIT semantic-web group,
hired 50~ employees, (including <a href="https://www.apple.com/leadership/john-giannandrea/">this person</a>, <a href="https://www.amazon.com/Toby-Segaran/e/B001I9RQVS">this person</a>, <a href="http://davidhuynh.net/">this person</a>) and got an office in the mission.

They reconciled all of wikipedia, the entire musicbrainz database, the entire open-library database, the tvdb database, and all of wordnet.
They signed a (massive) deal to import <b>all collections of the stanford library</b>.<a href="https://www.clir.org/pubs/reports/pub152/stanford-linked-data-workshop/">[2]</a>

They hit <b>high-90%</b> classification of all <a href="https://research.google.com/pubs/archive/44818.pdf"><b>50 million</b></a> entities (wikipedia has 5m)
They were evaluated at very-high 90's accuracy by several third-parties.

Facebook, Bing, Amazon, and Google all began using its data in nearly real-time in their search products.

This was one of the largest and most ambitious software projects in history.

In 2010 freebase was bought for a whack of money, and then killed-off by google.
When google announced they would be shutting down the API, they offered to import all of this data to a new wikimedia project called <span>wikidata</span>.

Wikidata was 4-or-5 Lua developers, in Germany, on a few research grants.

</p><p>and they said no. 😐</p><p>

so they said this data didn't meet it's guidelines regarding sourced data.

    <i>... aren't you pulling information <b>from wikipedia</b> blindly?</i>

    <i>... what about your (~60%) unreferenced facts?</i>

    <i>... aren't you <b>multiplying vandalism</b> from multi-lingual wikipedias?</i>

    <i>... how do you use, or verify references?</i>

They built a tool to <b>hand-transfer each freebase fact</b>, which if you have a calculator, may seem funny.
<span>(at 10 people clicking full-time, would have taken 10 million years)</span>

8 years later, <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a> remains tiny, buggy, unused, and worse - <i>majority unreferenced</i>.
I mean, they're pulling their data from wikipedia, which gets vandalized almost every minute!

It's accomplished very-little from its 5-year plan. They write academic papers.
They still don't really offer a rest api.
       ...creating new types or properties is I think, possible? or it's supposed to be...

It's got few of the safeguards, momentum, features, and ambition that Freebase had a full decade ago.
If wikidata was a company, it would not exist anymore, and you wouldn't have heard of it.

But Wikimedia places <b>banner-ads</b> on <span>hours of eye-blistering user-created content</span>,
begging children, students, and poor-people for money.
and they choose to be this petty, pithy and behind-the-times.

</p><p>Category-system</p><p>
It's a beautiful idea, to classify information with category-scheme, <a href="https://humane.computer/review-the-science-of-managing-our-digital-stuff/">until it falls-apart</a>.

<a href="http://www.shirky.com/writings/ontology_overrated.html"><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/shirky-category.jpg"></a>
Wikipedia has many-thousands of categories. They <a href="https://en.wikipedia.org/wiki/Wikipedia:Dump_reports/Category_cycles">loop-around</a> all-over the place.

</p><p>
People:
    → Musicians
        → Singers
              → American_Idol
                  → Books_about_American_Idol
</p><p>
or worse:
</p><p><span>Albanian language</span>:
    → Albanian-speaking countries and territories
      → Kosovo (region)
        → Kosovo
          → Kosovar society
            → Languages of Kosovo
              → <span>Albanian language</span>
</p><p>
if you're ever too-cheerful, and wanting to feel depressed, have a visit <a href="https://en.wikipedia.org/wiki/Wikipedia:Categories_for_discussion/Log/Today">Categories for deletion/Today</a>,
where you'll see precious human-life spent debating whether <b>'Category:Goth'</b> should exist, if it is a genre of music, if it's is a fashion-style, etc.

Work is being ravenously deleted all the time. You'll get sad thinking about it.

</p><p>Templates</p>
<div>
  <p>what about all this stuff →</p>
  <p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/infobox.png">
</p></div><p>
You're right.

Wikipedia has good structured-data in <b>infoboxes, lists, tables, citations, etc</b>.

The issue is, as of Feb 2019, Wikipedia has <b>634,755 different kinds of templates</b> (see this <a href="https://s3-us-west-1.amazonaws.com/spencer-scratch/allTemplates-2018-10-26.tsv">21mb download</a>).

Yes, there are all different.

Yes, there are <span>templates-within-templates-with-escaping-with-escaping</span>.

Even if you parse them perfectly, how do you know that for <a href="https://en.wikipedia.org/wiki/Template:HorseDeathYear">Template:HorseDeathYear</a>, the third parameter is the <b>birth date of the horse</b>, and the fourth is the birth-month?

see, for example:

• <a href="https://en.wikipedia.org/wiki/Category:16-Team_bracket_templates">Tennis Brackets vs Table Tennis Brackets</a>

• '<a href="https://en.wikipedia.org/wiki/Template:Birth_date_and_age">Birth_date_and_age</a>' vs '<a href="https://en.wikipedia.org/wiki/Template:Birth-date_and_age">Birth-date_and_age</a>'.

• <a href="https://en.wikipedia.org/wiki/Template:Trapezoidnotation">a template for a Trapezoid unicode symbol</a>
It's just a straight-up mess.

If you're thinking, <i>gee wikipedia editors must feel exhausted and stupid</i> - you're right.

<a href="https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Template:Retired&amp;limit=500">Many</a>…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</a></em></p>]]>
            </description>
            <link>http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300942</guid>
            <pubDate>Fri, 04 Dec 2020 10:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made 24 high-quality Covid illustrations. Free for commercial and personal use]]>
            </title>
            <description>
<![CDATA[
Score 317 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25300594">thread link</a>) | @andyydao
<br/>
December 4, 2020 | https://www.pixeltrue.com/frontliner-heroes | <a href="https://web.archive.org/web/*/https://www.pixeltrue.com/frontliner-heroes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
<div data-collapse="small" data-animation="default" data-duration="400" role="banner"><div data-w-id="829bd4f8-a52c-9bed-f351-1f1c429ebfb2"><p><a href="#" id="w-node-1f1c429ebfb3-a3ea6df0"><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859794cc27d27_COVID%20Logo.svg" loading="lazy" alt=""></a></p><div id="w-node-1f1c429ebfb6-a3ea6df0"><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 1439px) 20px, (max-width: 1919px) 25px, 30px" srcset="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-500.png 500w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-800.png 800w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-1080.png 1080w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png 1214w" alt=""></p></div></div></div><div><div data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1b"><p data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1c">Frontliner Heroes</p><p>24 high-quality Covid illustrations. Free for commercial and personal use.</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c6728188179a7570d_Hero%20Illustration.svg" loading="eager" width="462" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c20" alt=""><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c672818d125a7570c_Background.svg" loading="lazy" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c21" alt=""></p></div><div><div><div><div><p>Frontliner Heroes comes with exciting scenes that are commonly used to stop the spread of COVID. In addition, we'll be continually adding new illustration to this pack!</p></div></div></div></div><div><p><h2>24 Illustrations to fight against COVID!</h2></p></div><div><div><h2>Sample Applications</h2><p>These illustrations are perfect for any type of project. Simply Drag and drop them in and you're ready to go!</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b4456b3fd49b0f42063_Sample%20Applications.svg" loading="eager" alt=""></p></div><div><p><h2>Awesome Features</h2></p><div id="benefits"><div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410cacea1ebe4_Group%2084.png" alt=""></p><div><h3>Fully Vector<br></h3><p>All illustrations are fully vector meaning you can enlarge illustrations without quality loss<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe94105ee6a1ebe8_Group%20174.svg" alt=""></p><div><h3>Customizable<br></h3><p>Easily change illustration scenes to match your brand using common programs like Sketch and Figma.<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410876ca1ebe6_Group%20148.png" alt=""></p><div><h3>Different File Formats<br></h3><p>With our Frontliners pack you'll get access to all source files - this includes SVG, PNG&nbsp;and AI&nbsp;files.<br></p></div></div></div></div></div><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->


<!-- Hotjar Tracking Code for www.pixeltrue.com -->






<!-- Memberstack --> 
 








<meta name="p:domain_verify" content="efd5329f8b1be336c6381d60a312999c">



<!-- Facebook Pixel Code -->


<!-- End Facebook Pixel Code -->


<!-- Global site tag (gtag.js) - Google Analytics -->














</div>]]>
            </description>
            <link>https://www.pixeltrue.com/frontliner-heroes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300594</guid>
            <pubDate>Fri, 04 Dec 2020 09:40:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I cannot convince Twitter that I am human]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25300445">thread link</a>) | @gregdoesit
<br/>
December 4, 2020 | https://www.swyx.io/proving-our-humanity/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/proving-our-humanity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>If you swung by my Twitter profile in the last week, you probably saw this:</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/olflh5jfvk5clb15p5z9.png" alt="Alt Text">
</p>
<p>I'm not sure of the precise causes of me being locked out, but I have several abnormal usage factors that probably put me on the high end of Twitter's bot risk system:</p>
<ul>
  <li>I currently live in Singapore but am primarily active during US hours and have a US Phone Number</li>
  <li>I post about 30 tweets a day, probably on the high end of most Twitter users. (30 sounds like a lot, but it's mostly replies, and I maybe post 2-3 actual top tweets a day)</li>
  <li>I switch between and manage three different accounts (<a href="https://twitter.com/Coding_Career">Coding Career</a> and <a href="https://twitter.com/SvelteSociety">Svelte Society</a>) multiple times a day</li>
  <li>As far as I know I have not been reported on, but I do have people that strongly dislike me and they may have used the report button against me. Can't rule that out as a factor.</li>
  <li>Anecdotally <a href="https://twitter.com/b2m9/status/1295748479713779712?s=20">some IPs seem more risky</a> than others - I also use a VPN for work which probably shows me jumping across multiple countries in a single day, which is certainly suspicious on the face of it</li>
  <li>I have also noticed I get verification checks more often when I use scheduled tweets.</li>
</ul>
<p>If you clicked through my scary profile you also saw this:</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/6xjg8jxiwgidwffvwsnu.png" alt="Alt Text">
</p>
<p>I swear that I haven't mass unfollowed everybody! Most people see this and assume that I used some script to mass unfollow everyone and therefore got flagged as a bot. <strong>The reality is the exact opposite</strong> - I got flagged as a bot, and by default Twitter temporarily removes all follows.</p>
<p>It will be restored once I regain my Twitter account (I've filed a support ticket and am trying to reach out to friends at Twitter for help), but this is the exact user experience I wanted to talk about for this post.</p>
<p>First, a quick detour for a personal anecdote.</p>
<section>
  <h2 id="aside-my-time-as-a-cuban-detainee"><a href="#aside-my-time-as-a-cuban-detainee">Aside: My Time As A Cuban Detainee</a></h2>
  <p>A long time ago I visited Havana with some college friends. Right after landing we headed into a restaurant, all our luggage in tow. After we were done eating, I stood up and turned around - only to find all my luggage gone! Someone had stolen it while we were eating. The restaurant staff of course swore up and down that they had not seen who had taken it.</p>
  <p>Losing all your luggage on day 1 of a weeklong trip sucks, but what is worse is that <strong>my passport was in my luggage</strong>. I needed it to head back to the US at the end of my trip.</p>
  <p>If you've never lost a passport while traveling before, it's a quick trip to bureaucratic hell. If your country has an embassy where you are traveling, you can usually get it reissued in the embassy. But we were in <em>Cuba</em> - and my country had no embassy here. We reported my case to the authorities, but they had no idea what to do. I was an edge case. Worse still, because I said I had come from the US and couldn't produce any papers to prove my identity, I was detained at the police headquarters for questioning on suspicion of being a spy. (<em>I was never really at any risk - being Asian and speaking poor Spanish, I would have made for a pretty lousy spy</em>).</p>
  <p>There was a lot to figure out over the ensuing <em>month</em> of my ordeal - money, lodging, language barriers, administrative hurdles. My family and friends hit the panic button for me and my case reached the ears of both Arlen Specter on the US Senate Foreign Relations Committee and George Yeo, the Singapore Foreign Affairs Minister. We eventually worked it out, but every night for 4 weeks I would wander up and down <a href="https://en.wikipedia.org/wiki/Malec%C3%B3n,_Havana">the Malecón</a>, listening to the crashing waves, not knowing when I could ever leave the country. If I could swim <a href="https://en.wikipedia.org/wiki/Southernmost_point_buoy">the 90 miles to Key West</a> and <a href="https://en.wikipedia.org/wiki/Wet_feet,_dry_feet_policy">dry my feet</a>, I might theoretically make it back to the US on my own.</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/3i8nh2cgaoj3jlrl9ecm.jpg" alt="Alt Text">
  </p>
  <p>But most of all, I thought a lot about <strong>the humanity of having a piece of paper be more important than the human it represents</strong>. I could be physically standing in front of the immigration officer with a lie detector test on and steadfastly stating all manner of provable personal detail, and they would not let me through unless I had a small piece of paper the size of my hand.</p>
  <p>We do this a lot - passports, voter registration cards, national ID systems, licenses, and insurance proofs - mostly because some humans are untrustworthy and try to exploit the system.</p>
  <p>But we often fail to design for people who are innocent and simply don't fit the system in some way.</p>
</section>
<section>
  <h2 id="the-consequences-of-not-being-provably-human"><a href="#the-consequences-of-not-being-provably-human">The Consequences of Not Being Provably Human</a></h2>
  <p>Twitter has a way in which they expect you to verify you are human - you should get a call or text message with a code, that you then enter to prove humanity. This is what I normally get (about once every 1-2 months), and I can receive text messages from Twitter, so I can usually prove humanity with no issue.</p>
  <p>This time, for some reason, I am on a code path that doesn't offer a text message option, and Twitter somehow doesn't make international US number calls, leading to this infinite loop that I think is a bug:</p>
  
  <p>As a result of this unfortunate design:</p>
  <ul>
    <li>My friends think I mass unfollowed them, because Twitter temporarily reduced my follow count to 0</li>
    <li>People who DM me think I am ignoring them, because Twitter doesn't inform them that I am currently locked out</li>
    <li>None of my past tweets show up at all in <a href="https://twitter.com/search?q=from%3Aswyx&amp;src=typed_query">Twitter search</a>, which is problematic because I <a href="https://twitter.com/swyx/status/1245281982797373441?lang=en">use Twitter as a Second Brain</a>. If you read any of my blogposts, you will see that the rich link density of my references mainly come from taking notes in public over an extended period of time.</li>
    <li>I was unable to engage in the normal personal and professional activity I would do during Black Friday and AWS Re:invent</li>
  </ul>
  <p>I've filed a support ticket with Twitter, but you can imagine that support for a 330 million user service isn't very responsive. People who have been through this tell me the only way to resolve it is to hit up a Twitter employee to get past the masses of unrelated and less urgent support issues.</p>
</section>
<section>
  <h2 id="humans-proving-humanity-to-machines"><a href="#humans-proving-humanity-to-machines">Humans Proving Humanity To Machines</a></h2>
  <p>In the grand scheme of things, I know this is minor. I've actually taken it as a welcome social media detox, which I usually take voluntarily in December anyways. But when it's not on my terms, I lose the ability to manage the personal and professional relationships I've painstakingly built up over the past 3-4 years.</p>
  <p>Above all, I think there's an <em>indignity</em> in humans having to prove to machines that they are human, and the error resolution mechanism is to send a ticket to a faceless and unresponsive support email, and the only real way to get around it is again to re-establish human connections.</p>
  <p>I think more about all the other ways that we as software developers and designers fail to honor the dignity of humans trying to interact with the systems we create.</p>
  <p><a href="https://www.theverge.com/2019/2/1/18205610/google-captcha-ai-robot-human-difficult-artificial-intelligence">In 2014</a>, Google pitted one of its machine learning algorithms against humans in solving the most distorted text CAPTCHAs: the computer got the test right 99.8 percent of the time, while the humans got a mere 33 percent. It doesn't impact everyone equally - if you as a sighted, able bodied user struggle with CAPTCHAs, imagine the elderly or differently abled. Most services do not offer any alternative resolution when you cannot prove you are human. This is a problem when your service has essentially killed off the offline alternative and is essential for their basic needs.</p>
  <p>In Eric Meyer's <a href="https://meyerweb.com/eric/thoughts/2016/01/25/designing-for-crisis-design-for-real-life/">Designing for Crisis</a>, he describes how an inaccessible hospital website nearly risked the life of his daughter. I shudder to think how it might be made worse by perfectly well meaning software engineers who don't think about the humanity of the failure path. Imagine if you had to log in to something to save your child's life, and it presented you with a CAPTCHA you couldn't pass.</p>
  <hr>
  <p><em>Update: <a href="https://twitter.com/swyx/status/1334901024201445376?s=20">I've been helped</a>, thank you for reaching out. In case you were wondering what it looks like from Twitter's side, this is what they emailed:</em></p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/wgdlczuq2k5ay8uhql2q.png" alt="Alt Text">
  </p>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/proving-our-humanity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300445</guid>
            <pubDate>Fri, 04 Dec 2020 09:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Elixir]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25300420">thread link</a>) | @bendiksolheim
<br/>
December 4, 2020 | https://functional.christmas/2020/4 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today I want to give you an introduction to the programming language Elixir, some of its features and why you might want to check it out!</p>
</section><article><section><h2>The basics</h2>
<p>First things first: Elixir is a concurrent functional language that runs on the Erlang VM. It is inspired by many different languages where Ruby and Erlang are most obvious ones based on the syntax.</p>
<p>Elixir is a <a href="https://thinkingelixir.com/elixir-in-the-type-system-quadrant/">strong, dynamically typed language</a>. This puts it in the same category as Ruby and Python and it has optional functionality for compile time type checking as well.Elixirs data structures are immutable, but variables can be reassigned/rebound. <sup><sup id="fnref-2"><a href="#fn-2">2</a></sup></sup> This was a bit strange for me in that I got started with FP through Elm where there are no variables, just constants.</p>
<p>Elixir inherits a lot its data structures and related syntax from Erlang which in many ways is its biggest influence. <a href="https://elixir-lang.org/blog/2013/08/08/elixir-design-goals/">Elixir Design Goals</a> describes the relation to Erlang like this:</p>
<blockquote>
<p>Elixir is meant to be compatible with the Erlang VM and the existing ecosystem. When we talk about Erlang, we can break it into three parts:</p>
<ul>
<li>A functional programming language, called Erlang</li>
<li>A set of design principles, called OTP (Open Telecom Plaform)</li>
<li>The Erlang Virtual Machine, referred to as EVM or BEAM</li>
</ul>
<p>Elixir runs in the same virtual machine and is compatible with OTP. Not only that, all the tools and libraries available in the Erlang ecosystem are also available in Elixir, simply because there is no conversion cost from calling Erlang from Elixir and vice-versa.</p>
</blockquote>
<p>This is a great feature of Elixir that we will talk more about later.</p>
<p>As for other inspirations Elixir has docstrings from Python, polymorphism and protocols from Clojure, macros and meta-programming from different Lisps, just to name a few. <sup><sup id="fnref-1"><a href="#fn-1">1</a></sup></sup></p>
<h3>Hello World!</h3>
<p>As I said, Elixir is a concurrent functional programming language. For the functional part it means that Elixir mainly uses functions and modules for code structure and has other features that are associated with functional languages. We'll talk about the concurrent part later. </p>
<p>A hello world example in Elixir might look something like this:</p>
<div data-language="elixir"><pre><code><span>defmodule</span> HelloWorld
  <span>def</span> hello_world <span>do</span>
    IO<span>.</span>puts<span>(</span><span>"Hello, World!"</span><span>)</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>Here we define a module with a function that simply writes "Hello, World!" to the console.</p>
<h2>Killer applications</h2>
<p>Many programming languages has <a href="https://en.wikipedia.org/wiki/Killer_application">"killer apps"</a>; libraries, frameworks and use cases, that in themself are enough to justify the transition to the language or try it out. For Ruby it was the web framework Ruby on Rails and in many ways Elixir has its own Rails: Phoenix.</p>
<h3>Phoenix web framework</h3>
<p><a href="https://www.phoenixframework.org/">Phoenix</a> is inspired by Rails (the team originally behind Elixir was previously a Ruby shop) and was an early addition to the Elixir community. The creators of Phoenix has learned from years of Rails development and made their own opinions in addition to the natural changes needed when going from an object oriented language to a functional language.
Compared to Rails Phoenix has with the help of the Erlang VM great performance. Some of you might have heard about Phoenix' amazing <a href="https://www.phoenixframework.org/blog/the-road-to-2-million-websocket-connections">2 million simultaneous web sockets</a> benchmark!</p>
<h3>The Nerves Project</h3>
<p>Another interesting project in the Elixir ecosystem is the embedded/IoT project <a href="https://www.nerves-project.org/">Nerves</a>. Nerves makes it possible to use Elixir code to create embedded system where previously you would have had to use a low level language like C. This does not stop you from bringing your own code (like C, C++, Python, Rust, and more) while using Nerves as a platform for your IoT project.
The project web site says:</p>
<blockquote>
<p>Nerves is a complete IoT platform and infrastructure for you to build and deploy maintainable embedded systems.</p>
</blockquote>
<h2>The BEAM and OTP</h2>
<p>When talking about the advantages of Elixir it is hard to not talk about the advantages of Erlang and its virtual machine, the BEAM (Bogdan's Erlang Abstract Machine). It is in many ways the biggest selling point for Elixir. We are now talking about the concurrent part of Elixir. Erlang and the BEAM has shown its resiliency over many years, exemplified in giving Ericsson 9 nines (99.9999999%) availability in their AXD301 switch.<sup><sup id="fnref-3"><a href="#fn-3">3</a></sup></sup> It is known for its "let it break" philosophy and self-healing properties and by being compatible with Erlang, Elixir inherits a lot of these traits.</p>
<p>Elixirs creator, Jose Valim, attributes one of the motivational factors for the creation of Elixir to the rise of multi-core CPUs and the need to utilize these. Ruby and other languages with a global interperter lock (GIL) limits this, but the Erlang VM and the tools and design prinsiples of OTP have proven to be a great choice for creating concurrent, performant and resilient applications.</p>
<h3>Everything is a process</h3>
<p>Everything in the BEAM is a process. These are not OS processes, but lightweight processes which can be cheaply spawned and killed. In his PhD thesis the co-inventor of Erlang, Joe Armstrong, summarized Erlangs principles regarding processes:</p>
<blockquote>
<ul>
<li>Everything is a process.</li>
<li>Processes are strongly isolated.</li>
<li>Process creation and destruction is a lightweight operation.</li>
<li>Message passing is the only way for processes to interact.</li>
<li>Processes have unique names.</li>
<li>If you know the name of a process you can send it a message.</li>
<li>Processes share no resources.</li>
<li>Error handling is non-local.</li>
<li>Processes do what they are supposed to do or fail.</li>
</ul>
</blockquote>
<p>Sidenote: For some this may sound vaguely familiar. Some object oriented languages has had similar principles, but instead of processes they are applied to objects. Smalltalk is reported to be one of the inspirations to Erlang and it is fun to think about Erlang being a functional language but still be more object oriented than some object oriented languages. This is of course not the case as the definition of OOP has changed over time and Erlang is a functional language, but it is fun to ponder the similarities. 😄 Back to the main story! 😅</p>
<p>These unique principles for processes where they communicate through messages lays a great foundation for creating concurrent application, but there is one more piece to the puzzle: OTP.</p>
<h3>OTP - The Open Telecom Platform</h3>
<p>As with so many other parts of this article OTP is a big topic and could be a separate article, but I'll try make it short! Today the name is a bit strange but it was created by Ericsson for their telephone switches in the 80s and 90s so in that context in makes more sense.</p>
<p>OTP is an integral part of many Erlang applications. In essence OTP is a set of design principles and standards including tools and libraries to make it easier to create applications that adheres to them.<sup><sup id="fnref-4"><a href="#fn-4">4</a></sup></sup> </p>
<p>Since Elixir is compatible with OTP we can leverage these principles and technologies that has been battle tested in high-pressure and critical applications for decades!</p>
<h2>The take-away</h2>
<p>Luckily you don't need to understand or know much about Erlang, BEAM and OTP.
Without deep knowledge of these topics you can still reap the benefits of highly performing web applications and resilient IoT applications. It would certainly help but it is not a prerequisite. This is the great thing about Elixir: it is an approachable language with battle tested underpinnings! 💪</p>
<p>It might not be your idea of a perfect language. It is not mine either, but that does not stop me from using the great tools at my disposal. If you are all into Haskell or the likes it might not be something you would use and that is OK. Whatever your preferences are you might now know a little more about Elixir and Erlang and some more knowledge is always a good thing. 😄</p>
<p>If you would like to check Elixir out I recommend checking out <a href="https://elixir-lang.org/getting-started/introduction.html">the official Getting started guide</a> or the interactive guide <a href="https://try-elixir.herokuapp.com/">Try Elixir</a> and then trying out a project with Phoenix or Nerves. Hands-on experience is always better than something you read on the internet! 🤓</p>
<p>Psst! By the way: there are other languages that run on the BEAM. <a href="https://lfe.io/">Lisp variants</a> and lately some work on <a href="https://gleam.run/">strong statically compiled ML-like languges</a> if you are into that!</p>
</section></article></div>]]>
            </description>
            <link>https://functional.christmas/2020/4</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300420</guid>
            <pubDate>Fri, 04 Dec 2020 09:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-host your fonts for better performance]]>
            </title>
            <description>
<![CDATA[
Score 592 | Comments 398 (<a href="https://news.ycombinator.com/item?id=25300396">thread link</a>) | @zwacky
<br/>
December 4, 2020 | https://wicki.io/posts/2020-11-goodbye-google-fonts/ | <a href="https://web.archive.org/web/*/https://wicki.io/posts/2020-11-goodbye-google-fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div>
  <div>
    <div>
      
      <p>
        
          November 30, 2020
        
      </p>

      <figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/goodbye-google-fonts.jpg" alt="Google Fonts"> 
</figure>

<p>I’ve used Google Fonts in prototypes and in 10M+ MAU products. It’s incredibly easy to get started with and provides an amazing font discovery. That’s also why it’s currently still used on over <a href="https://trends.builtwith.com/websitelist/Google-Font-API">42M websites</a>!</p>
<p>This convenience has its price: Performance. Many <a href="https://blog.cloudflare.com/fast-google-fonts-with-cloudflare-workers/">have</a> <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">already</a> <a href="https://www.keycdn.com/blog/web-font-performance#disadvantages-of-web-fonts">pointed</a> <a href="https://blog.logrocket.com/self-hosted-fonts-vs-google-fonts-api/">out</a> the cost of multiple requests. If you want the remaining speed boost, then you’re best off downloading your used Google Fonts and self-host them.</p>
<p>This is nothing new. In fact it’s been advocated already for years. Even Google themselves <a href="https://www.youtube.com/watch?v=Mv-l3-tJgGk&amp;feature=youtu.be&amp;t=24m58s">advised others to self-host fonts</a> in their Google I/O ‘18 talk about web performance.</p>
<h2 id="self-hosting-fonts-vs-google-fonts">Self-hosting fonts vs Google Fonts</h2>
<p>By nature Google Fonts, even with all its font and CSS optimisations, can’t be faster than self-hosted fonts.</p>
<p>Sia wrote <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">a great post</a> where she compared the performance between Google Fonts and self-hosted fonts without the impact of a CDN.</p>
<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/with-google-fonts.png" alt="Network flow with Google Fonts"> <figcaption>
            <p>Optimised Google Fonts loading with preconnect</p>
        </figcaption>
</figure>

<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/without-google-fonts.png" alt="Network flow with self-hosting fonts"> <figcaption>
            <p>Optimised self-hosting fonts with preload</p>
        </figcaption>
</figure>

<hr>
<h2 id="the-old-performance-argument">The old performance argument</h2>
<p>So if the bottom-line performance is in self-hosting fonts’ favour: What was the argument that convinced us developers that Google Fonts is at least as performing as the self-host approach?</p>
<p>Google Fonts was designed to be distributed on a global CDN and reap the caching benefits from it. Users request fonts via said CDN. Chances are that they have downloaded the font resources at an earlier point already from a different site.</p>
<blockquote>
<p>“[…] Our cross-site caching is designed so that you only need to load a font once, with any website, and we’ll use that same cached font on any other website that uses Google Fonts.”</p>
<p>— <a href="https://fonts.google.com/about">https://fonts.google.com/about</a></p>
</blockquote>
<h2 id="invalidating-the-old-performance-argument">Invalidating the old performance argument</h2>
<p>Since Chrome v86, released October 2020, cross-site resources like fonts can’t be shared on the same CDN anymore. This is due to the partitioned browser cache (Safari has had this for years already).</p>
<p>In <a href="https://developers.google.com/web/updates/2020/10/http-cache-partitioning">this Google post</a> they explain what the partitioned browser cache is. It got only introduced to prevent a possible cross-site tracking mechanism.</p>
<h2 id="cache-partitioning-in-other-browsers">Cache partitioning in other browsers</h2>
<p>Safari really cares about privacy. It circumvented this very cross-site tracking attack for years already. Then finally comes Chrome. Other browsers that are based off Chromium, still need to signal or implement the feature.</p>
<ul>
<li>✅ <strong>Chrome</strong>: since v86 (October 2020)</li>
<li>✅ <strong>Safari</strong>: since 2013</li>
<li>🚫 <strong>Firefox</strong>: planning to implement</li>
<li>🚫 <strong>Edge</strong>: most likely soon</li>
<li>🚫 <strong>Opera</strong>: most likely soon</li>
<li>🚫 <strong>Brave</strong>: most likely soon</li>
<li>🚫 <strong>Vivaldi</strong>: most likely soon</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Google Fonts resources will be redownloaded for every website, regardless it being cached on the CDN. Self-host your fonts for better performance. The old performance argument is not valid anymore.</p>
<p>Thanks for checking this post out!</p>


      
      <hr><div>
  <p><img src="https://wicki.io/images/me_huc890d15b6e9f2ce8978e9aa27127dd5e_67203_350x0_resize_q75_box.jpg" alt="Simon Wicki">
    
  </p>

  <div>
    <div>
      <p>
        <strong>Simon Wicki</strong> is a Freelance Frontend Developer in
				Berlin. Passionate and fluent in Vue, Angular, React and Ionic. Interested in 
				Tech, frontend &amp; non-fiction books
      </p>
      <p>
        <a href="https://twitter.com/zwacky" onclick="ga('send', 'event', 'clickout', 'bottom_cta', '\/posts\/2020-11-goodbye-google-fonts\/')" target="_blank">
          <img src="https://wicki.io/images/svg/twitter.svg" alt="Twitter" title="Twitter">
          Follow @zwacky
        </a>
      </p>
    </div>
  </div>
</div>

    </div>
  </div>
</div>


        </div></div>]]>
            </description>
            <link>https://wicki.io/posts/2020-11-goodbye-google-fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300396</guid>
            <pubDate>Fri, 04 Dec 2020 09:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project Loom and Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25300233">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html | <a href="https://web.archive.org/web/*/https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<h2>Why Loom?</h2>
<p>In 1998, it was amazing that the Sun Java Web Server (the precursor of Tomcat) ran each request in a separate thread, and not an OS process. It was able to serve thousands of concurrent requests this way! Nowadays, that’s not so amazing. Each thread takes up a significant amount of memory, and you can’t have millions of threads on a typical server.</p>
<p>That’s why the modern mantra of server-side programming is: “Never block!” Instead, you specify what should happen once the data is available.</p>
<p>This asynchronous programming style is great for servers, allowing them to handily support millions of concurrent requests. It isn’t so great for programmers.</p>
<p>Here is an asynchronous request with the <code>HttpClient</code> API:</p>
<pre>HttpClient.newBuilder()
   .build()
   .sendAsync(request, HttpResponse.BodyHandlers.ofString())
   .thenAccept(response -&gt; . . .);
   .thenApply(. . .);
   .exceptionally(. . .);
</pre>
<p>What we would normally achieve with statements is now encoded as method calls. If we loved this style of programming, we would not have statements in our programming language and merrily code in Lisp.</p>
<p>In JavaScript, code tagged as “async” is rewritten into method calls like the ones that you’ve just seen. But that means you can only call async methods from other async methods, and your API splits into a sync and an async part, forcing you to duplicate functionality.</p>

<p>Project Loom takes its guidance from languages such as Erlang and Go, attacking the root of the problem by making blocking very cheap. You run tasks in “virtual threads”, a nearly unlimited resource that is mapped into actual “carrier” threads. When a virtual thread blocks, it is “parked” and another virtual thread runs on the carrier thread. The name is supposed to remind you of virtual memory that is mapped to actual RAM.</p>
<p>Before you complain about the name, remember that naming is hard. The Loom team previously tried “fiber”, but it is already used elsewhere with a slightly different meaning. And “lightweight” or “new” thread might look foolish when something lighter-weight or newer comes along.</p>
<p>After experimenting with separate classes for OS threads and virtual threads, they ended up deciding to use a single class for both—the familiar <code>java.lang.Thread</code>—in order to ease migration.</p>
<p>Of course, good old <code>java.lang.Thread</code>, which has been around for 25 years, ever since Java 1.0, has its share of cruft. Awkward cancellation, thread groups, priorities, depreceated methods <code>stop</code>,<code>suspend</code>, <code>resume</code>. The Loom team felt that these liabilities were minor since most programmers never explicitly use the <code>Thread</code> API but launch tasks with an <code>ExecutorService</code>. (Of course, the same argument would support coming up with a cleaner virtual thread API instead.)</p>
<p>If you have been around for a very long time, you may remember that early versions of Java had “green threads” that were mapped to an OS thread. However, there is a crucial difference. When a green thread blocked, its carrier thread was also blocked, preventing all other green threads from making progress.</p>

<p>You can download binaries of Project Loom at <a href="http://jdk.java.net/loom/">http://jdk.java.net/loom/</a>. They are updated regularly.</p>
<p>As already mentioned, a virtual thread is an object of the <code>Thread</code> class. Here are three ways of producing fibers. First, there is a new factory method that constructs and starts a virtual thread:</p>
<pre>Thread thread = Thread.startVirtualThread(runnable);
  // <cite>Note that the thread is already started</cite></pre>
<p>This is good for demos, tutorials or quick-and-dirty experiments in JShell.</p>
<p>For more customization, there is a builder API:</p>
<pre>Thread thread = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .build();</pre>
<p>However, as you have been told for many years now, it is better to use an executor service than to manually construct <code>Thread</code> instances. The static method <code>Executors.newVirtualThreadExecutor()</code> provides one. (The existing executor services are not useful for virtual threads. It would be counterproductive to pool them!)</p>
<p>For example,</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor();
exec.submit(runnable1);
exec.submit(runnable2);
</pre>
<p>As with the other factory methods in the <code>Executors</code> class, you can optionally supply a <code>ThreadFactory</code>. And the new <code>Thread.Builder</code> class has an easy way to provide a factory, instead of a single instance:</p>
<pre>ThreadFactory factory = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .<b>factory()</b>;

ExecutorService exec = Executors.newThreadExecutor(factory);
</pre>
<p>Let’s try this out. As a first test, we just sleep in each task.</p>
<pre>import java.util.concurrent.*;

public class Test {
   public static int DELAY = 10_000;
   public static int NTASKS = 1_000_000;

   public static void run(Object obj) {
      try {
         Thread.sleep((int) (DELAY * Math.random()));
      } catch (InterruptedException ex) {
         ex.printStackTrace();
      }
      System.out.println(obj);
   }

   public static void main(String[] args) {
      ExecutorService exec = Executors.newVirtualThreadExecutor();
      for (int i = 1; i &lt;= NTASKS; i++) {
         String taskname = "task-" + i;
         exec.submit(() -&gt; run(taskname));
      }
      exec.close();
   }
}
</pre>
<p>Run the program and it just works. Then try using OS threads—change to <code>Executors.newCachedThreadPool()</code> or <code>Executors.newFixedThreadPool(NTASKS)</code>. The program will run out of memory; on my laptop, after about 25,000 threads.</p>
<p>Ok, but in practice, you don’t want to sleep, but do useful work. Consider a program adapted from one of <a href="https://www.javaspecialists.eu/about/heinz/">Heinz Kabutz</a>‘ puzzlers, The program fetches a daily image, from Dilbert or Wikimedia. It consists of classes <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> and <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageInfo.java"><code>ImageInfo</code></a>. The code is an impenetrable maze of twisty passages, all alike (i.e. helper functions yielding completable futures).</p>
<p>With virtual threads, simply read web contents synchronously. It blocks, but we don’t care. All the complexity goes away. The control flow is simple and comprehensible.</p>
<pre>exec.submit(() -&gt; {
    String pageURL = info.getUrlForDate(date);
    String page = getSync(pageURL, HttpResponse.BodyHandlers.ofString());
    String imageURL = info.findImage(page).getImagePath();
    byte[] image = getSync(imageURL, HttpResponse.BodyHandlers.ofByteArray());
    info.setImageData(image);
    process(info);
    return null;
});</pre>
<p>Here is the simplified <a href="http://horstmann.com/unblog/2020-12-05/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> code.</p>
<p><b>Pro tip: </b>The statement <code>return null;</code> makes the lambda into a <code>Callable</code> instead of a <code>Runnable</code>, so that you don’t have to catch checked exceptions 😜</p>
<p>Try this out with something you care about. Call web services and make database connections, without worrying about callbacks. When blocking is cheap, a whole lot of accidental complexity goes away. Of course, to use this in a web app framework, you’ll have to wait for your framework provider to run your code in virtual threads.</p>
<h2>Structured Concurrency</h2>
<p>In <a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">this highly recommended article</a> (from which the images below are taken), Nathaniel Smith proposes structured forms of concurrency. Here is his central argument. Launching a task in a new thread is really no better than programming with GOTO, i.e. harmful:</p>
<pre>new Thread(runnable).start();</pre>
<p><img src="http://horstmann.com/unblog/2019-12-05/sequential-and-go-to-schematic.svg" alt=".svg" width="38%"></p>
<p>When multiple threads run without coordination, it’s spaghetti code all over again. In the 1960s, structured programming replaced <code>goto</code> with branches, loops, and functions:</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/control-schematics.svg" alt=".svg" width="42%"></p>
<p>When you look at a line of code, you know how the program got there.</p>
<p>Structured concurrency does the same for concurrent tasks. We should know, from reading the program text, when they all finish.</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/nursery-schematic-unlabeled.svg" alt=".svg" width="30%"></p>
<p>That way we can control the resources that the tasks use, and we know when it is time to move on.</p>
<p>In Loom, the <code>ExecutorService</code> implements this basic construct. <code>ExecutorService</code> has a <code>close</code> method that blocks until all of its virtual threads have completed. (I used this method in the first sample program to keep <code>main</code> alive until all virtual threads are done. In the past, you had to call the <code>awaitTermination</code> method instead.)</p>
<p>Conveniently, <code>ExecutorService</code> implements the <code>AutoCloseable</code> interface, so that you can just use a <code>try</code>-with-resources statement:</p>
<pre>try (ExecutorService exec = Executor.newVirtualThreadExecutor()) {
   for (int i = 0; i &lt; NTASKS; i++) {
      exec.schedule(() -&gt; run(i));
   }
} // <cite>Blocks until all threads completed</cite>
</pre>
<p>I wrote a simple web crawler as a demonstration of virtual threads—here is the <a href="http://horstmann.com/unblog/2020-12-05/Crawler.java"><code>Crawler</code></a> class. In my first attempt, I fired off a new virtual thread for each URL in a page. If I had wanted to become Google, I could have let my crawler run forever. But I wanted to go no more than 3 hops from the starting point. With “fire and forget”, there is no way of knowing when the recursion is done.</p>
<p>Instead, for each page, I make a new executor service and wait for completion. That way, the whole program completes when all pages have been crawled.</p>
<p>This seems a lot of blocking. But in Loom, blocking is cheap, so we shouldn’t worry about that.</p>
<p>We are used to having one executor service as thread pool for all our tasks. But in Loom, you are encouraged to use a separate executor service for each task set.</p>
<h2>Deadlines</h2>
<p>When crawling the web, you are likely to encounter dead links. Reading from one should time out eventually, but it can take surprisingly long.</p>
<p>The standard remedy is, of course, to provide a timeout. Loom prefers deadlines to timeouts, so you specify</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor().withDeadline(
   Instant.now().plus(30, ChronoUnit.SECONDS))
</pre>
<p>Why deadlines? In general, timeouts compose poorly. Suppose you have to accomplish two sequential tasks with an overall timeout of 10 seconds. You don’t want to give each of the tasks a timeout of 5 seconds. After all, if one takes 6 seconds and the other 3 seconds, you still come in under the finish line. To get the timeout of the second task, you’d have to measure the duration of the first task and subtract that from the overall timeout. With deadlines, it is much simpler. Each task gets the same deadline.</p>
<p>The call <code>exec.close()</code> blocks until all virtual threads have completed or the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</a></em></p>]]>
            </description>
            <link>https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300233</guid>
            <pubDate>Fri, 04 Dec 2020 08:24:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monoliths as a Service]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25299598">thread link</a>) | @gdeglin
<br/>
December 3, 2020 | https://www.themostfamousartist.com/maas | <a href="https://web.archive.org/web/*/https://www.themostfamousartist.com/maas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a13f76d094074a98b8e4"><p><h3>PO BOX 4115</h3><h3>SANTA FE, NM 87502</h3><h3><strong>© 2020 THE MOST FAMOUS ARTIST, LLC</strong></h3></p></div></div>]]>
            </description>
            <link>https://www.themostfamousartist.com/maas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299598</guid>
            <pubDate>Fri, 04 Dec 2020 06:22:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faroe Island roundabout under the Atlantic Ocean]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25299574">thread link</a>) | @sohkamyung
<br/>
December 3, 2020 | https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/ | <a href="https://web.archive.org/web/*/https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299574</guid>
            <pubDate>Fri, 04 Dec 2020 06:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Manage My Random Daily Notes]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 180 (<a href="https://news.ycombinator.com/item?id=25299442">thread link</a>) | @hachibu
<br/>
December 3, 2020 | https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/ | <a href="https://web.archive.org/web/*/https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/featured.png"><figcaption><p>Illustration: Hachibu</p></figcaption></figure><p>For years, I kept track of random notes by creating a text or Markdown
file on my desktop. And at the end of the day, I would delete that file and
start over again the next day. Inspired by the minimalism of <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>,
I created a similar system to manage my own notes.</p><p>Keep reading for more details or skip to the code: <a href="https://github.com/hachibu/note.sh">github.com/hachibu/note.sh</a>.</p><h4 id="introduction">Introduction</h4><p>As I mentioned before, I used to keep a single notes file on my desktop, and I
would delete it everyday. I would use this notes file to keep track of random
thoughts and details related to my work and personal life. My notes file might
contain code snippets from work, inspirational quotes, or it might have my
latest and greatest open-source software idea, or maybe even the beginning of a
new blog post. Anyway, I loved the simplicity of it, and I didn’t want any more
apps, databases or logins in my life.</p><p>But it wasn’t until I started using <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>
that I considered writing a script to manage my own notes. The brilliant part
about <code>todo-txt-cli</code> is that it’s just text files stored in my Dropbox and a
small shell script to interface with those files.</p><p>Inspired by the minimalism of <code>todo-txt-cli</code>, I built <a href="https://github.com/hachibu/note.sh">note.sh</a>.
In total, the entire project consists of 1 Bash script, 1 environment variable
to configure the notes directory and 1 symlink to install it to your
<code>/usr/local/bin</code> directory.</p><h4 id="how-it-works">How It Works</h4><p>The way it works is that every time I run the script, it opens the note for that
day in my editor of choice. For example, if today was December 2, 2020 then the
script would open a file named <code>2020-12-02.md</code> in the notes directory.</p><p>I use Vim as my editor, and I have my notes stored on Dropbox so I can access
them on all of my computers. So, my shell RC file looks like this.</p><div><pre><code data-lang="shell"><span>export</span> <span>EDITOR</span><span>=</span><span>"vim"</span>
<span>export</span> <span>NOTE_DIR</span><span>=</span><span>"</span><span>$HOME</span><span>/Dropbox/Notes"</span>
</code></pre></div><p>And my Dropbox directory looks like this.</p><p><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/dropbox-screenshot.png" alt="Dropbox Screenshot"></p><p>For searching, the script accepts a pattern and runs a recursive grep over the
notes directory. I chose grep because I use this script on both Mac and Linux,
and I wanted the script to be as portable as possible.</p><h4 id="conclusion">Conclusion</h4><p>I’ve been using this script for several months across several computers, and I
still love it. I don’t search as often as I thought I would, but it’s comforting
to know it’s all there if I need it. I also ended up creating an alias for my
script so all I need to type is the letter <code>n</code> to run the script.</p><p>In the future, I’d like to add a test suite to the code base, figure out how
to create a Homebrew formula, and add archiving for older notes.</p></div></div>]]>
            </description>
            <link>https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299442</guid>
            <pubDate>Fri, 04 Dec 2020 05:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Dothraki Horde, Part I: Barbarian Couture]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25299176">thread link</a>) | @parsecs
<br/>
December 3, 2020 | https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the first part of a three part (II, III) look at the Dothraki, the fictional horse-borne nomads of the <em>Game of Thrones</em> / <em>A Song of Ice and Fire</em> series and the degree to which George R.R. Martin’s claim that they are “an amalgam of a number of steppe and plains cultures” holds up to scrutiny.  This is something that I have been suggesting I would get to since (checks notes),<a href="https://acoup.blog/2019/05/04/new-acquisitions-that-dothraki-charge/"> May.  Of Last Year.</a>  So it is about time we actually get to it.</p>



<p>The plan is for this series to run in three parts.  Part I (this part) will discuss how the Dothraki <em>look</em> in the setting.  Part II will look at broader questions of social organization and culture (I am nearly certain this is one of those cases where there will be a IIa and a IIb, but my hope for brevity springs eternal).  Part III will look at military culture.  In all three parts I am going to use both the books and the show – noting where they diverge – in part because the heaviest characterization the Dothraki got in the show was when Martin was still significantly involved with it (meaning that large parts of it likely still reflect his vision), but also because the show is how the vast majority of people experience this particular fiction.  Both the original text and the show derived from it deserve to have their vision discussed.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>First, a <strong>content warning for this series</strong>: this is discussing <em>A Song of Ice and Fire</em> and <em>Game of Thrones</em> which features a lot of content which is not G-rated.  More to the point, it is a discussion of what – I will argue – Martin presents as one of, if not the most brutal and sexually violent society in that setting.  And that means those themes are going to come up here (less in this essay, but more in the other parts); we are going to remain serious and adult about those things of course, but they will be a part of this analysis nonetheless.  If that is not for you, by all means feel free to check out for a few weeks.</p>



<p>Before we get into the main point, <strong>I want to note that I am going to reference my series on the <a href="https://acoup.blog/2020/01/17/collections-the-fremen-mirage-part-i-war-at-the-dawn-of-civilization/">Fremen Mirage</a> <em>a lot</em> here</strong>, because there is a lot of Fremen stuff going on with how Dothraki society is depicted.  As a result, it may be useful to go back and read those, but just to recap, we may define the Fremen Mirage this way:</p>



<p><a href="https://acoup.blog/2020/02/21/collections-the-fremen-mirage-interlude-ways-of-the-fremen/"><strong>The Fremen Mirage is a literary trope, <em>unconnected to historical reality</em>, which presents societies as a contrast between unsophisticated, but morally pure, hyper-masculine and militarily effective ‘strong men’ societies honed by ‘hard times’ (that is, the Fremen of the term) and a sophisticated but effeminate and decadent ‘weak men’ societies weakened by ‘good times,’ frequently with an implicit assertion of the superior worth of the former.</strong></a></p>



<p>Next, a note on citation here from the books.  My understanding is that different printings of the books have different pagination, which seems to be why the Wiki of Ice and Fire cites by chapter numbers (except that the chapters of the books, as printed, <em>aren’t numbered</em> in the print editions I’ve seen, making this classical-style citation extremely cumbersome and inexact).  I am going to cite by the page numbers of my edition, which is the 2011 Bantam Books Trade Paperback Edition (the box set).  Hopefully that will be enough.</p>



<p>Finally, a note on my expertise here.  <strong>I am not a scholar of either the peoples of the Eurasian Steppe or the American Great Plains</strong>.  The former group does intrude into my period and study, as steppe nomads, in the form of Scythians, Sarmatians and Huns did interact (sometimes peacefully, sometimes violently) with the broader Mediterranean world.  Consequently, my knowledge of steppe peoples tend to be better that my knowledge of the Native American peoples of the Great Plains, but I have tried, within the limits of time and availability, to do my research. <strong> I actually think, in a strange sense, this is useful, because my own initial unfamiliarity with the topic has demonstrated to me just how <em>basic</em> the level of research and reading necessary to avoid the failures of this depiction are</strong>.  You do not, in turns out, need to be an experienced scholar on the topic; just a few books and a couple of emails is enough to already radically improve on what we see and read in <em>A Song of Ice and Fire</em>, much less the absolute <em>mess </em>of what we see in <em>A Game of Thrones</em>.</p>



<p>Writing this has been tricky.  I am well aware that both of these broad cultural groups (that is, Steppe peoples and Plains Native Americans) are often represented in popular culture only in the form of inaccurate and demeaning stereotypes.  I do not want to be just another link in that chain of poor understanding.  I have thus tried to root my argument here, wherever possible, in either the writings of specialist scholars (there will be more of that next week as we get into subsistence patterns, warfare, etc.) or primary evidence, particularly in terms of <em>period photographs</em>, when it comes to clothing and dress.  With luck I have not erred overmuch.</p>



<figure><img data-attachment-id="5355" data-permalink="https://acoup.blog/1024px-skythian_archer_plate_bm_e135_by_epiktetos/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg" data-orig-size="1024,991" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-skythian_archer_plate_bm_e135_by_epiktetos" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Scythians#/media/File:Skythian_archer_plate_BM_E135_by_Epiktetos.jpg">Via Wikipedia</a>, an Attic vase-painting of a Scythian archer (c. 500 BCE).  The Scythians, like the Huns and Mongols, were a Eurasian Steppe people, many of them horse-borne nomads of the same sort.  Far from being drab, their clothing was colorful and distinctive, including their particular hats, which show up not only in Greek but also in Persian artwork.</figcaption></figure>



<h2>…But, Why?</h2>



<p>But before we get into the issue proper, it is important to clear away the standard objections, both why subject <em>A Song of Ice and Fire</em> (and its spin-off properties) to critical analysis at all and also why, if we are going to do that, we are going to focus squarely in on the Dothraki.  The answer to the first is something that we’ve rehearsed a number of times, but bears restating: for most of its readers (and the watchers of <em>A Game of Thrones</em>), <em>A Song of Ice and Fire</em> will be their primary exposure to the idea of the Middle Ages.  This is particularly true because of the reputation that the series has for being ‘<a href="https://acoup.blog/2019/05/28/new-acquisitions-not-how-it-was-game-of-thrones-and-the-middle-ages-part-i/">how it really was</a>,’ a reputation that George R.R. Martin has consciously cultivated (as with his classic complaint of <a href="https://youtu.be/p-VxvKoDFIw">‘what was Aragorn’s tax policy’</a> – there is a rich irony that, had Martin understood rulership in the Middle Ages better, he would have understood why Aragorn’s tax policy was less important).  Martin has been quite open that he “<a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">draw[s] inspiration from history</a>” and that fact has long been a selling point of the series over more obviously fantastical kinds of medieval-themed high fantasy as well as a <a href="https://ew.com/article/2015/06/03/george-rr-martin-thrones-violence-women/">response to some of the series’ more controversial moments</a>.</p>



<p><strong>Naturally, that cloak of verisimilitude has tended to intensify the degree to which elements of <em>A Song of Ice and Fire</em> is taken by its readers and viewers as representative of the Middle Ages more generally.</strong>  And of course as I have noted in the (quite recent) past,<strong> <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">fiction is often how the public conceptualizes the past and that concept of the past shapes the decisions we make in the present</a></strong>.  In the case of <em>A Song of Ice and Fire</em> in particular, this vision of the past is <a href="https://acoup.blog/2019/06/12/new-acquisitions-how-it-wasnt-game-of-thrones-and-the-middle-ages-part-iii/">particularly worth interrogating</a> because it serves as the basis for a<a href="https://youtu.be/ek2O6bVAIQQ"> parable on power and violence</a>.</p>



<p>But <em>even if it didn’t</em>, it would still be worth discussing these aspects of the universe of <em>A Song of Ice and Fire</em>, because that is what we are supposed to do with cultural products, with <em>literature</em>.  <strong>I am sometimes baffled that the very fans who insist that their particular loves be treated seriously, as <em>art</em> are the same fans who react with frustration if one then sets out to interrogate those same genres the way one would interrogate serious art or literature</strong>.  This is it, after all!  This is what you (we, really) wanted!  A (quite unimpressive, I’ll grant you) ivory tower academic is taking this genre seriously and subjecting it to serious criticism!  Isn’t that what emerging genres often hope for, to be taken seriously as ‘high’ literature?</p>



<p><strong>And of course we should take it seriously.</strong>  And here I want to speak briefly to the purpose of these sorts of endeavors, <strong>because the goal here is not to force anyone to dislike <em>A Song of Ice and Fire</em></strong>.   We’re not here to ‘cancel’ <em>ASOIF</em> any more than we were going to ‘cancel’ <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/"><em>AC:Valhalla</em> two weeks ago</a> (a game I continue to play, I might add).  Instead, discussing cultural products like this is a form of inoculation against their potentially negative aspects, because once a reader knows that, for instance, the depiction of a given culture in a work of fiction has relatively little to do with any real world culture, they can compartmentalize that to the fiction itself; <strong>it loses its power to mislead</strong> <strong>and so may be enjoyed in safety, as it were</strong>.  And there are good things in <em>A Song of Ice and Fire</em> and in the first six or so seasons of <em>Game of Thrones</em>; but we also need to be honest about the failings.</p>



<p>(Of course, more broadly, doing this as a practice exercise is a key part of building up that skill – what we may term ‘critical reading’ – more generally, rendering the alert reader more resistant to this sort of thing, both in its unintended form (as, I suspect, in this case) or  in its more dangerous<em> intended form</em>.  Put another way, developing critical reading skills is one important way to make one’s self a harder target for misinformation, including historical misinformation.)</p>



<h2>A Dash of Pure Fantasy</h2>



<p>Alright, so <em>A Song of Ice and Fire</em> is worth looking at closely.  So why <em>this</em> part of the fiction?  It comes down to something <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">George R.R. Martin wrote</a>:</p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299176</guid>
            <pubDate>Fri, 04 Dec 2020 05:05:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No dog food today – the Linux Foundation annual report]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25298501">thread link</a>) | @BerkhanBerkdemi
<br/>
December 3, 2020 | https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html | <a href="https://web.archive.org/web/*/https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><a href="https://daniel-lange.com/categories/17-Strategy"><img title="Strategy: Airplanes are interesting toys but of no military value. (Marechal Ferdinand Foch, Professor of Strategy, Ecole Superieure de Guerre)" alt="Strategy" src="https://daniel-lange.com/uploads/strategy.serendipityThumb.jpg"></a></p><p>The Linux Foundation has published its <a href="https://www.linuxfoundation.org/wp-content/uploads/2020/11/2020-Linux-Foundation-Annual-Report_113020.pdf">annual report</a> today. LWN <a href="https://lwn.net/Articles/838871">calls it glossy</a> and yeah, boy, it is shiny.</p>

<p>So shiny that people that work in the publishing industry immediately see this has been produced with the Adobe toolchain which - unfortunately - is one of the big suites of software not yet available for Linux.</p>

<p>Checking the PDF file metadata reveals the keywords "open source, open standards, open hardware, open data". That is what the Linux Foundation is about. Good stuff.</p>

<p><!-- s9ymdb:667 --><img width="552" height="676" src="https://daniel-lange.com/uploads/entries/Linux-Foundation-Annual-Report-2020-cover.jpg" title="Mouseovers are for xkcd!" alt="Linux Foundation annual report 2020 cover"></p>

<p>The PDF producer meta data for the annual report PDF has been set to "Linux kernel 0.12.1 for Workgroups" and the PDF creator meta data element to "Sharp Zaurus XR-5000 (Maemo5) Edition". Somebody thought to better hide the real data and had some tongue-in-cheek ideas. Kudos.</p>

<p>But nicer would have been to use Open Source software to produce the report, not?</p>

<p>Running <code>strings 2020-Linux-Foundation-Annual-Report_113020.pdf | grep Adobe | wc -l</code> gives us 1229 lines and confirms the suspicion of the toolchain.</p>

<p>A stale <code>/Title (Annual Report 2020) /Producer (macOS Version 10.15.7 \(Build 19H15\) Quartz PDFContext)</code> has been forgotten in the document to tell us about the platform.</p>

<p>So, ladies and gentlemen, the Linux Foundation 2020 annual report has been produced on a Mac.</p>

<p>Running Adobe Creative Cloud on MacOS Catalina 10.15.7.</p>

<p>Which is proprietary software. Its kernel (and some userland pieces) are based on BSD. Not Linux.</p>

<hr>

<p>The image on the front page also struck me as a bit odd ... using a ballpoint pen on the laptop screen?</p>

<p>Unbranded laptop.
Unbranded cup in the foreground.</p>

<p>Kid in the background <em>not</em> paying attention to his tablet.</p>

<p>All of that cries stock image so loud it hurts.</p>

<p>Google currently finds ~560 uses of the picture and any <a href="https://www.shutterstock.com/support/article/Do-I-need-to-credit-Shutterstock-the-artist-when-I-use-Images-or-Footage">editorial use</a> nicely tells us that it is © <a href="https://www.shutterstock.com/de/g/draganagordic">Dragana Gordic / Shutterstock</a>.</p>

<p>The image is "Smiling mom working at home with her child on the sofa while writing an email. Young woman working from home, while in quarantine isolation during the Covid-19 health crisis".</p>

<p>See the <a href="https://www.dailymail.co.uk/news/article-8683629/Staff-working-home-nearly-extra-hour-day-research-shows-send-emails.html">Daily Mail</a> for a wonderful example of the working mum in context. I hope, if her laptop had been powered on, it would have run Linux. I mean, what else would still run on an old white MacBook with an Intel "Core 2 Duo" processor from 2008?</p>

<p><!-- s9ymdb:668 --><img width="504" height="742" src="https://daniel-lange.com/uploads/entries/DailyMail-screenshot-stock-image.png" title="O.k., here you go: Shiny, too!" alt="Daily Mail screenshot of the same stock image used"></p>

                </div><div id="extended">
        <p>Bonus round:</p>

<p>The Ethernet port, the USB ports and the headset connector are on the left side of the MacBook. The Daily Mail got it right.</p>

<p>Mirroring images is usually not a good idea. To Linux Foundation's defense ... similar pictures are available <a href="https://www.shutterstock.com/de/image-photo/busy-young-woman-son-home-shot-1680921679">already mirrored on Shutterstuck</a> next to the <a href="https://www.shutterstock.com/de/image-photo/smiling-mom-working-home-her-child-1680923362">correctly oriented picture</a>.</p>

        </div></div>]]>
            </description>
            <link>https://daniel-lange.com/archives/166-No-dog-food-today-the-Linux-Foundation-annual-report.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298501</guid>
            <pubDate>Fri, 04 Dec 2020 03:18:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PixelNeRF Neural Radiance Fields from One or Few Images]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25298426">thread link</a>) | @choppaface
<br/>
December 3, 2020 | https://alexyu.net/pixelnerf/ | <a href="https://web.archive.org/web/*/https://alexyu.net/pixelnerf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p id="paper-title">
            
            <h3>
                Neural Radiance Fields from One or Few Images
            </h3>
            <h3>
                <small title="Note: This is a joke">IEEE International Conference on Neural Radiance Fields (ICNeRF)</small>
            </h3>
        </p>

        
        
        <div>
            <div>
                <div id="dynamic-teaser">
                     <!-- row -->

                     <!-- row -->
                    <div id="teaser-dtu">
                        <div>
                            <p>3 Input Views</p>
                            
                            <p><strong>pixelNeRF</strong></p>
                            <p>3-view NeRF</p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_inputs.jpg">
                            </p>
                            
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_outputs_sm.gif">
                            </p>
                        </div> <!-- row -->
                    </div>
                </div> <!-- dynamic-teaser -->
                <!-- <img id="teaser" src="img/teaser.png" class="img-responsive" alt="teaser figure"> -->
                <p>
                    We propose pixelNeRF, a learning framework that predicts a continuous neural scene representation conditioned on
                    one or few input images.
                    The existing approach for
                    constructing neural radiance fields&nbsp;<a href="https://www.matthewtancik.com/nerf">[Mildenhall et al. 2020]</a>
                    involves optimizing the representation to every scene independently, requiring many calibrated views and significant compute time.
                    We take a step towards resolving these shortcomings
                    by introducing an architecture that conditions a NeRF on image inputs in a fully convolutional manner. This allows the network to be trained across multiple scenes to learn a scene prior, enabling it to perform novel view synthesis in a feed-forward manner from a sparse set of views (as few as one).
                </p>

            </div>
        </div>
        <div id="overview-video">
            <div>
                <h4>Narrated Overview</h4>
                <p>
                    <iframe src="https://www.youtube.com/embed/voebZx7f32g" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </p>
            </div>
        </div>
        <div>
            <div>
                <p>
                    Leveraging the volume rendering approach of NeRF, our model can be trained directly from images with no explicit 3D supervision.
                    We conduct extensive experiments on ShapeNet benchmarks for single image novel view synthesis tasks with held-out objects as well as entire unseen categories.
                    We further demonstrate the flexibility of pixelNeRF by demonstrating it on multi-object ShapeNet scenes and real scenes from the DTU dataset. In all cases, pixelNeRF outperforms current state-of-the-art baselines for novel view synthesis and single image 3D reconstruction.
                </p>
                <p><img src="https://alexyu.net/pixelnerf/img/pipeline.png" alt="pipeline">
            </p></div>
        </div>
        <div>
            <div>
                <h4>Feed-forward NeRF from One View</h4>
                <p>
                    Using multiview image supervision, we train a single pixelNeRF to 13 largest object categories
                    in ShapeNet in order to perform novel-view synthesis on unseen objects.
                    Our approach operates in <strong>view-space</strong>—as opposed to canonical—and requires <strong>no test-time optimization</strong>.
                    Nevertheless, in terms of image metrics, we significantly outperform existing methods quantitatively, as shown in the paper.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_000.gif" alt="shapenet results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_001.gif" alt="shapenet results animated">
                    </p></div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Scene-level Representation</h4>
                <p>
                    Since our method requires <strong>neither canonical space nor object-level information such as masks</strong>,
                    it can represent scenes with multiple objects, where a canonical space is unavailable,
                    without modification.
                    Our method can also <strong>seemlessly integrate multiple views</strong> at test-time to obtain better results.
                    SRN performs extremely poorly here due to the lack of a consistent canonical space.
                </p>
                <div>
                    <div>
                        <div>
                            <p>2 Input Views</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                    <div>
                        <div>
                            
                            <p>1 Input View</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Real-world Scenes</h4>
                <p>
                    We show that our method can also conduct wide-baseline view synthesis on more complex real scenes from the <a href="http://roboimagedata.compute.dtu.dk/?page_id=36">DTU MVS</a> dataset,
                    producing reasonable results when given only 1-3 views at inference time.
                    Moreover, it is feed-forward without requiring test-time optimization for each scene.
                </p>
                <div>
                    
                    <div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu_inputs.jpg" alt="DTU 3 input images">
                        </p>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu.gif" alt="DTU results animated">
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Generalization</h4>
                <p>
                    To demonstrate generalization capabilities,
                    we apply a model trained on ShapeNet planes, cars, and chairs to unseen ShapeNet categories.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_000.gif" alt="shapenet unseen category results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_001.gif" alt="shapenet unseen category results animated">
                    </p></div>
                </div>
                <p>
                    Separately, we apply a pretrained model on real car images after background removal.
                </p>
                
                
            </div>
        </div>
        <div>
            <div>
                <h4>Related Links</h4>
                <ul>
                    <li>
                        NeRF was introduced in <a href="https://www.matthewtancik.com/nerf">Mildenhall et al. (2020)</a>
                    </li><li>
                        Local image features were used in the related regime of implicit surfaces in
                        <a href="https://shunsukesaito.github.io/PIFu/">Saito et al. (2019)</a>
                        and
                        <a href="https://arxiv.org/abs/1905.10711">Xu et al. (2019)</a>
                    </li><li>
                        Our MLP architecture is
                        inspired by
                        <a href="https://avg.is.tuebingen.mpg.de/publications/niemeyer2020cvpr">DVR</a>
                    </li><li>
                        Parts of our
                        PyTorch NeRF implementation are taken from
                        <a href="https://github.com/kwea123/nerf_pl">kwea123</a>
                    </li><li>
                        Also see the concurrent work
                        <a href="https://arxiv.org/abs/2010.04595">GRF</a>
                        which also introduces image features for NeRF, showing image features can even improve NeRF when a large number of views are available.
                </li></ul>
            </div>
        </div>
        
        <div>
            <div>
                <h4>Acknowledgements</h4>
                <p>
                    We thank Shubham Goel and Hang Gao for comments on the text. We also thank
                    Emilien Dupont and Vincent Sitzmann for helpful discussions.
                    This website is inspired by the template of <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                </p>
                <p>
                    Please send any questions or comments to <a href="https://alexyu.net/">Alex Yu</a>.
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexyu.net/pixelnerf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298426</guid>
            <pubDate>Fri, 04 Dec 2020 03:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A terminal-based workflow for research, writing, and programming]]>
            </title>
            <description>
<![CDATA[
Score 271 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25297268">thread link</a>) | @jerodsanto
<br/>
December 3, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p><a href="https://youtu.be/2SLZQQfMF8E"><img src="http://jacobzelko.com/assets/workflow_youtube_vid.jpg" alt=""></a></p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action-boom">My Workflow in Action <img title=":boom:" alt=":boom:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a5.png" height="20" width="20">
</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="floating-terminals">Floating Terminals</h3>

<p><img src="http://jacobzelko.com/assets/float_term.gif" alt=""></p>

<p>Floating terminals are immensely powerful and I love them!
This enables me to quickly pull up a terminal and do some changes without having to split tmux panes or get out of vim.
Furthermore, what is awesome is that you can use it as a sort of <code>vim-slime</code> tool to send lines of code to the floating terminal.
This is a great feature as it uses your last used floating terminal for its target - therefore, if you switch between projects a lot, just switch your floating terminal accordingly.
No need to keep opening and closing REPL sessions and such!</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I’ll have to spend valuable time getting my workflow set back up… Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It’s nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer – works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>



<p>These are parts of my workflow that I used to use.
They have been retired for a variety of reasons but all in an effort to improve my workflow.
I have kept these around in case anyone finds it useful!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><strong>Rationale for deprecation:</strong> I used to use <code>vim-slime</code> but deprecated it from my workflow because of the flexibility of floating terminals.
Not only could I use floating terminals to send code, I could also quickly flip through terminals in one button press.</p>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297268</guid>
            <pubDate>Fri, 04 Dec 2020 00:05:02 GMT</pubDate>
        </item>
    </channel>
</rss>
