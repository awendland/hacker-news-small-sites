<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 19 Dec 2020 16:56:03 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 19 Dec 2020 16:56:03 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Adding Composite Video to a Famicom]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25463627">thread link</a>) | @todsacerdoti
<br/>
December 17, 2020 | https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html | <a href="https://web.archive.org/web/*/https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Since I’ve been reading <a href="https://mitpress.mit.edu/books/i-am-error"><em>I Am Error</em></a>, I’ve been getting more and more interested in the technical aspects of the Famicom. Turns out all you really need to get me interested in your console is prose explanations of how a pattern table works. Also, I get to drip some molten lead into it so I can use a modern TV! Everyone wins.</p>

<p>When I was growing up, a lot of my friends had an NES, but I first had the ColecoVision and then a “Model 2” Sega Genesis when that came out. As a result, I’ve gone the last few decades thinking the NES was full of branded shovelware, because it turns out that’s <a href="https://www.youtube.com/watch?v=MzJ0M-erXAM">the exact kind of game that eight year old boys bought a lot of and then subjected their friends to</a>.</p>

<p>Later, when I was getting interested in collecting old videogames, the NES had already started its stratospheric price rise for many games, and with it the skeeziest members of the game-price-speculator community. None of the cool modern “community” stuff existed then (NESRGB, Everdrives, FDSStick) so I gave the entire system a wide berth and decided to wait until this whole fad was over and prices returned to normal. That hasn’t happened yet… however, in Japan, stuff is still really cheap due to the massive popularity of the Famicom, and the Famicom is different enough from the NES that I’m coming at it without the same preconceptions that I had of those childhood NESes.</p>

<p>Out of the box, the original Famicom only has RF output. If you’re not familiar, <a href="https://www.youtube.com/watch?v=8sQF_K9MqpA">this video by Gravis is the best I’ve seen on how RF output works</a>, and a Nintendo is even used to make it relevant to this post.</p>

<p>Not only does the Famicom only have RF output, the Japanese channel frequencies are such that that RF output only appears on channel 95 and 96 on a Western TV, which a lot of TVs simply can’t reach. On some models, you can <a href="https://www.youtube.com/watch?v=RVyFEMg0Kpg">tweak the pots on the RF can to bring that down to US channel 6</a> to get around this. However, I wanted to play my games on a Commodore 1702 or a PVM, neither of which have an antenna tuner of any kind. Doing a composite mod seemed like the easiest way forward.</p>

<h2 id="giving-it-a-good-squint">Giving It A Good Squint</h2>
<p>The first thing I noticed is that a Famicom is a <em>lot</em> smaller than an NES. They added a bunch of empty space for the American model in order to accommodate the “toaster” mechanism, I guess.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-vs-nes.jpg" alt="A Famicom is sitting on top of an American front-loading NES, which is a spoiled Western brat and doesn't like loading cartridges."></p>

<p>I thought I would hate the hard-wired controllers, but they’re actually really nice. You’re guaranteed to always get first-party controllers when you buy a used system, which is more than I can say for basically any other machine, that NES included. It would be nice if they were in better condition, but if they work I’ll be happy.</p>

<p>There’s a “Famicom Family” logo on the front sticker that I haven’t seen on most other Famicoms; from what I can tell, this is a good way to tell what machines are later models as it ties into <a href="https://maru-chang.com/hard/hvc/english.htm">some kind of later branding</a>.</p>

<h2 id="opening-it-up">Opening It Up</h2>
<p>When mine arrived from Japan, it looked dirty and pretty beaten up, but that’s okay for a test machine. I can always get a nicer one later; another thing to hoard.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-case-damage.jpg" alt="The missing chunk of plastic near the player 1 controller slot."></p>

<p>A corner of the plastic near the player-1 controller mount was missing, and there was grit in the textured plastic. I took a few trips to the sink with the plastic and scrubbed, but the yellowing is obviously not going to come out with soap and water.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-opened.jpg" alt="The Famicom's bottom cover is opened, revealing the underside of the motherboard."></p>

<p>I opened it up - screws were tight, a good sign - and then took a look at the board. It’s a late model, as evidenced by the big power/RF module soldered to the board instead of attached by a ribbon cable.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-gross-pot.jpg" alt="There is a green potentiometer with some gunk and tree debris (seeds?) on it."></p>

<p>This console has spent some time in an old shed or something, based on how much of Mother Nature had crept inside of it, but at least I didn’t find any stray cigarettes inside it unlike the above NES. The motherboard cleaned up quickly with some spray alcohol and cotton swabs.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-1989-copyright.jpg" alt="The copyright reads © 1989 Nintendo"></p>

<p>The board is a 1989, which was a pretty good year for Nintendo. <a href="https://arstechnica.com/gaming/2013/07/time-to-feel-old-inside-the-nes-on-its-30th-birthday/3/">The Famicom apparently kept getting made until <em>2003</em></a>. It would be cool to track one of those down.</p>

<p>I wanted to deep-clean the dirty, scratched-up controllers as well - the controllers still had their protective plastic wrap on them, but they were scratched anyway! - and make sure that the silicone on the D-pads were in good shape, but I stripped one of the screws on controller 1 pretty severely in a moment of clumsiness. I’ll drill that out later and service it, but in the meantime let’s get back to the composite mod.</p>

<h2 id="motherboard-work">Motherboard Work</h2>
<p>I got sort of lucky in having a late-model board. On the later boards there’s a dedicated “video” pin that is broken out near the RF jack that I could just solder to, rather than lifting pin 21 (<a href="http://wiki.nesdev.com/w/index.php/PPU_pin_out_and_signal_description"><code>VOUT</code></a>) of the PPU. This way, you can keep both the RF and composite. Reportedly, this creates a bunch of ‘jailbar’ interference, so I’ve done what others have and lifted pin 21 of the PPU. Sometimes the hard way is the best way.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-pin21-lifted.jpg" alt="Pin 21 lifted out of the PPU. Ignore the Sharpie mark telling me which pin is 21, as if I could have forgotten"></p>

<p>This wasn’t too hard to desolder and lift, but the pin would have looked a lot less mangled if I had also desoldered R6 first to get it out of the way. I had to use a little bit too much force on my “prying tweezers” to lift it out, which could have easily broken the leg on a newer chip where the legs are much more fragile. Thanks, 80s technology!</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-decoupling-caps.jpg" alt="The axial decoupling caps are added."></p>

<p>I also added decoupling caps between 5V and GND on the CPU and PPU chips. It’s just good practice! These 0.1µF axial ceramic cuties were lying in my cap pile ever since I used a handful of them for <a href="https://www.leadedsolder.com/tag/tandy1000sx">the cursed Tandy 1000SX</a>, so I was happy to slam two more of them in. The recipe I was following used <code>/RESET</code> as the 5V source, which feels a little sketchy, but it means you don’t have to run long wires all the way to the other end of the chip. Then again, the copper pour on the back of the board <em>is</em> 5V…</p>

<p>I thought 0.1µF might be a little small, but it’s easy to change these out for a 1µF or larger cap if it doesn’t have much effect. You probably shouldn’t pick decoupling caps based on aesthetics.</p>

<h2 id="video-amplification">Video Amplification</h2>
<p>The whole idea behind the composite mod is that you’re building a simple signal amplifier to replace the one that was originally inside the RF can.</p>

<p>As the baseband video signal comes out of PPU pin 21, you need to step it up to a level that the TV can easily understand. The video chip’s output transistors are simply not designed to directly drive a television, and after the weak signal goes all the way through the AV cable into the back of the TV, there’s probably not much left to pick up anyway.</p>

<p>There are a lot of homebrew mods for this, ranging from cutting out and reusing the stock transistors on the motherboard to building a whole protoboard circuit with some new parts.</p>

<p>After doing some more research, I decided I would try a part that I’ve been meaning to try for a while, <a href="https://www.ti.com/product/THS7314">the TI THS7314 video amplifier IC</a>. It’s used a lot for <a href="https://www.retrorgb.com/thsamps.html">the amplification of analogue RGB signals</a>, and it should work really well for my one-channel signal. The part is designed specifically for this application, and should both install cleanly and produce nice-looking video.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-ths7314-board.png" alt="The prototype board as seen from KiCad. It's very simple, with only a 'video in,' 'audio in,' and 'power in' pinout which then goes to the THS7314 chip."></p>

<p>I made a quick, super-simple little board that basically just broke out the pins of the video amp chip, and sent it to fab at OSH Park. They’ve recently added free (if slow - over a month) shipping to Canada, which makes them a really desirable option for running off onesy-twosie little mod boards like this during the current shipping nightmare we find ourselves in.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-boards-osh.jpg" alt="The two variants of the board - one with the traditional &quot;homebrew amp&quot; design, and the other with the TI THS7314 video amplifier chip."></p>

<p>I made boards to do two variants, one with the original “homebrew” amplifier circuit and one with the THS7314. If the THS7314 doesn’t work out for whatever reason, I can just put in the usual circuit that the community prefers. However - spoilers - the THS7314 worked fine, so I never actually constructed the traditional design.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-av-mod-v0.2-assembled.jpg" alt="The v0.2 board, assembled. A cap leg comes out of the &quot;R&quot; audio hole, and then directly around in a 180 to the &quot;L&quot; audio hole."></p>

<p>I should have added a jumper to the board to solder left and right audio together (the Famicom is monoaural.) This ugly cap leg trick should be fine for awhile. I decided on a 220µF capacitor for audio, because that’s what was on the top of the cap bin when I opened it.</p>

<h2 id="sound">Sound</h2>
<p>The Famicom supports audio coming from the cartridge, which is why Castlevania III on the Famicom has such better music than that on the NES. I definitely want to be able to hear the cartridge audio, so it’s worth pulling the audio from somewhere other than directly out of the CPU (which also contains the sound hardware – lower chip counts = more profit for Nintendo.) The “<a href="https://wiki.nesdev.com/w/index.php/Cartridge_connector">audio output</a>” pin on the cartridge contains the Famicom’s sound after it has been mixed between the expansion audio and the system audio, where it normally then travels immediately to the RF can for output. Since we’re no longer putting that audio into the RF output stream, it needs to get broken out and fed into the TV using the usual RCA jacks as well.</p>

<p>Reportedly, the GPM-02 motherboard has <a href="https://nerdlypleasures.blogspot.com/2018/01/famicom-nes-simple-tweaks-to-restore.html">a different ‘mix’ between the expansion audio and the system audio compared to the original Famicom motherboard</a>. You can revert back to the original model’s amplifier behaviour by removing the 43kΩ resistor at R7 and replacing it with a 100kΩ part.</p>

<p>I also removed the choke at FC1 on the motherboard, so that the sound didn’t go into the RF can where it might pick up other noise. To source audio, I just went from the “expansion audio” pin (#46) on the cartridge port and added a 220µF capacitor.</p>

<p><img src="https://www.leadedsolder.com/assets/famicom-gpm02-audio-mods.jpg" alt="The two audio mods done. R7 is replaced with a 100kΩ resistor that I had on hand (sorry it's so big... and backward) and FC1 is removed entirely."></p>

<p>I only had a giant 100kΩ resistor on hand, so that’s the one that went in. This bugs me more than I thought it would.</p>

<p>These changes <a href="https://www.youtube.com/watch?v=gD22orMjz48">seem to make a pretty significant impact</a>. I generally don’t have an ear for little tweaks, but this is big enough that even I can pick it out. There’s whole instruments that seem to be missing from the unmodified mix.</p>

<h2 id="getting-the-signal-out">Getting The Signal Out</h2>
<p>There’s a lot of different ways I’ve seen of actually getting the composite signal out of the Famicom and into a way that you can plug it into a TV:</p>
<ul>
  <li>Cut out the RF box’s antenna jack, and <a href="http://8bitplus.co.uk/projects/famicom-av-mod-nintendo/">replace it with a TRRS jack</a>, which carries all four signals for RCA on one jack;</li>
  <li><a href="https://www.boards.ie/vbulletin/showthread.php?t=2056561579">Drill holes in the side</a> and put in some panel-mount RCA connectors;</li>
  <li><a href="https://www.youtube.com/watch?v=ky8rFPbzGMU">Run a female or male RCA cable squid out of the case</a> (usually …</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html">https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html</a></em></p>]]>
            </description>
            <link>https://www.leadedsolder.com/2020/12/17/famicom-composite-mod-v1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463627</guid>
            <pubDate>Fri, 18 Dec 2020 03:54:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur bug prevents upgrades to the next version]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25463521">thread link</a>) | @groobongithub
<br/>
December 17, 2020 | https://micromdm.io/blog/big-sur-softwareupdate/ | <a href="https://web.archive.org/web/*/https://micromdm.io/blog/big-sur-softwareupdate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><br><span>Date: Thu, Dec 17, 2020</span><br><span>Reading Time: 7 minutes</span></p><p>If you work with Apple in some capacity, you know that they’re not very likely to admit mistakes. I’m not aware of Apple publishing postmortems after outages or providing details about known issues. So it’s up to the developer and admin communities at large to help each other learn about outages and potential causes. With the release of macOS 11.1 this week I’ve been debugging a new issue with the Mac software update process, one which will affect most enterprise users. I decided I should write about it and let everyone know what the issue is, workarounds, and how to avoid it. I’ve also been paying close attention to some recent changes to the software update mechanism, so I’ll try to mention them below as well.</p><h2 id="a-macos-11-bug-prevents-upgrades-to-the-next-version">A macOS 11 bug prevents upgrades to the next version</h2><p>After macOS 11.1 was released earlier this week, many users <a href="https://twitter.com/Contains_ENG/status/1339399335298166785">started reporting</a> that they were not able to see the software update. Others reported that they saw it, but were not able to download it. I personally experienced this issue when 11.1 was in beta and filed a case with Apple about it, but then moved on to other problems. When the final release came out this week, there were widespread reports of it on the MacAdmins Slack. Reading through system logs, I as well as other admins were able to find what appears to be the root cause. <strong>Under certain conditions, macOS 11.0.1 and macOS 11.1 hosts are requesting the update server send the 11.0.1 update, instead of requesting the next available one. The server rejects this update as it’s already either installed or older.</strong> This somehow corrupts the state of the software update process, and the update is no longer visible as an option in System Preferences.</p><figure><img src="https://micromdm.io/big_sur_softwareupdate/log.jpg"></figure><h3 id="workarounds">Workarounds</h3><ul><li>The update is visible again immediately after the restart. But it’s unclear if the update can always be installed after it’s visible since the condition that made it fail to download the first time can be triggered again.</li><li>Removing the MDM enrollment profile causes the update to be seen again. I and several others tested this extensively, and it’s definitely the enrollment profile, not some other policy managed by MDM. This is obviously a terrible workaround and I’d hesitate to mention it to users as it could cause security agents to stop working, and countless approval dialogs we’re so familiar with. Not to mention some of you have the MDM enrollment profile as non-removable or users who are not administrators, so they don’t have permission to unenroll. Getting them back enrolled in the MDM might prove to be a challenge too.</li><li>Distributing the full 11.1, and eventually the 11.2 installers.</li></ul><h3 id="can-apple-fix-this-bug-without-manual-intervention">Can Apple fix this bug without manual intervention?</h3><p>Apple is well aware this is a problem now, so I am confident the issue will be addressed in 11.2. Unfortunately, it is a client-side issue affecting both 11.0.1 and 11.1 clients. So there’s not much Apple <em>can</em> do to provide a fix. One potential solution I see is for Apple to detect the wrong request and instead of rejecting the download, offer the right file archive instead. But this is a complex system and it’s unclear if the server-side changes alone are enough.</p><p>Something else Apple could try is to side load a patch through another software update. There’s background configuration and malware removal tools that are likely capable of fixing the issue on the system. But it’s an ugly hack and one I’d personally stay clear of even if the option was available.</p><p>In my opinion, the most likely outcome is that the bug will be fixed in 11.2, but clients that have already upgraded to Big Sur (or any M1 macs you might’ve bought) will have to work around the problem themselves. If we’re lucky Apple will publish a support article and that will be that.</p><h2 id="what-else-you-need-to-know">What else you need to know</h2><p>Big Sur has changed the software update mechanism entirely, especially on Apple Silicon macs. It’s a long time coming and Apple spoke about some of this at WWDC in the MDM and IT sessions, so it shouldn’t be entirely surprising. But a lot was left unsaid for us to discover on our own.</p><ul><li>Combo update packages are <a href="https://eclecticlight.co/2020/12/17/apple-has-stopped-providing-standalone-installers-for-macos-updates/">no longer published</a> on the Apple website. This might surprise many of you who rely on distributing them. The main reason is that the entire format of the updates has changed, and it’s also no longer possible to install updates without the Mac having access to the internet. The updates must come from Apple, and they must be managed by <code>softwareupdate</code> and related processes on the system.</li><li>On Apple Silicon, third party processes are no longer able to script the <code>softwareupdate</code> command. Running the software update command as a root process now prompts for the administrator password, who also needs to be a secure token user. There are only two possible options for OS updates to be applied; either the human user of the device itself or the MDM process <a href="https://support.apple.com/guide/deployment-reference-macos/using-secure-and-bootstrap-tokens-apdff2cf769b/1/web/1.0">which has special permission</a>. It might also be possible for the Mac to update itself with the auto-update mechanism, but there are too many bugs right now to observe how well that works. My personal experience is that it doesn’t and I’m greeted with a password prompt to enter the next day…</li><li>Specifying a custom URL for the <code>softwareupdate</code> process to pull updates from is no longer possible. Apple advertised this deprecation for all of last year, so it should surprise no one but it hurts. <a href="https://github.com/wdas/reposado">Reposado</a> was one of several great tools that made it possible to have unstable/beta/stable tracks within an organization.</li><li>—ignore is gone as a flag. It <a href="https://mrmacintosh.com/10-15-5-2020-003-updates-changes-to-softwareupdate-ignore/">was gone</a> in 10.15.5 briefly too, so you likely know about this one. This time it’s gone for good and never coming back. An MDM server can delay the client from seeing OS updates for up to 90 days only, but that is the absolute maximum going forward. Even for a future major release like macOS 12. If this is important to you, file feedback for Apple to provide a second deferral option, specific to major version numbers.</li></ul><p>I work with the MDM protocol a lot day-to-day and have been <a href="https://micromdm.io/blog/os_update/">testing</a> software updates for a while. I was even <a href="https://micromdm.io/blog/wwdc20-what-s-new-in-managing/">optimistic</a> about what it would look like in Big Sur back in June. Apple had promised it’s an entirely new implementation, closer to what is available on iOS and that everything would work better than before. But we’re not off to a good start, and all the concerns I had for several years now are back. The <a href="https://developer.apple.com/documentation/devicemanagement/commands_and_queries">design</a> of OS updates in MDM is brittle, requiring multiple remote procedure calls to accomplish something that was previously done by a few lines of shell scripting. And that would be bad on its own, but the bad design is coupled with a buggy implementation; there are many known issues, besides the one I described above. Unless something drastically changes, we’re likely to see many months, if not years of software update bugs that are entirely out of our control.</p><p>Apple was never particularly great at building systems for the enterprise. But, until recently, the Unix components were available for software developers and system administrators to work with. The end result ended up being that if you made an investment within your organization, macOS was a great experience for end-users. It took a lot of work, but it was all achievable. Today, Apple is no better at developing systems that are required in the enterprise. But the ball is entirely in their court. Apple still makes great tools for consumers, and there will be a demand from employees to provide them with Apple gear. But, if Apple can’t start acting on our collective feedback, the experience of using a Mac in the workplace will quickly become unbearable to most.</p></div></div></div>]]>
            </description>
            <link>https://micromdm.io/blog/big-sur-softwareupdate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25463521</guid>
            <pubDate>Fri, 18 Dec 2020 03:35:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WeWork: How the $3.5B Flex Space Giant Is Engineering a Comeback]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25462692">thread link</a>) | @gk1
<br/>
December 17, 2020 | https://sacra.com/research/wework-engineering-a-comeback/ | <a href="https://web.archive.org/web/*/https://sacra.com/research/wework-engineering-a-comeback/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="light-at-the-end-of-the-tunnel">Light at the end of the tunnel</h2><p>WeWork is inarguably one of the most controversial companies in the world. Its unsustainable growth strategy destroyed billions in shareholder value. Has WeWork finally hit rock bottom, or is it a falling knife?&nbsp;</p><p>We don’t have a crystal ball, but based on the work we have done, we believe WeWork has most of the pieces in place for a powerful turnaround.</p><p>In January 2019, WeWork was valued at $47B, making it the second-largest private company at the time, 15x the price of its closest competitor. After its failed IPO at the end of 2019, it nosedived to $7.3B. In March 2020, just as offices around the world were closing amid the coronavirus outbreak, SoftBank refused to participate in a $3B tender offer of early employee shares. The valuation of WeWork fell all the way to $2.9B, down 94% from its peak.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/d878dff8-8141-42de-9292-25cabe8af273_Screen+Shot+2020-12-17+at+14.23.03.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>WeWork’s rise from startup to $47B company took 9 years—its fall back down to $2.9B took just over 1.</em></p><p>The private markets have gone from euphoria to disillusion with WeWork. The company was downgraded again by credit rating agency Fitch in October 2020, and its cash burn through the year so far is estimated to be above $1.6B.</p><p>Our research shows that after all the recent changes, there is a light at the end of the tunnel. We aggregated public data, analyzed financial data, talked to real estate brokers, developers, industry experts and built a model.&nbsp;</p><p>We can scoff at WeWork’s one-page long community adjusted EBITDA, but the company has been undergoing a reorganization towards profitability.&nbsp;</p><p>Key decisions include rightsizing their real estate portfolio, exiting 66 unprofitable leases, effecting a favorable shift in customer mix shift with 60% revenue now coming from enterprises, reducing the size of the workforce from 14,000 to 5,000 and hiring a new management team.&nbsp;</p><p>In addition to WeWork’s internal efforts, the most unexpected tailwind is that the global experiment of remote working that we’ve seen during COVID may give rise to a structurally more flexible and distributed workforce in the near future. Ironically, the economic downturn many thought would sink WeWork may become the very cause of its survival.&nbsp;</p><p>A capital-light strategy is also on the horizon (a genuine one this time). Once the dust settles, WeWork could leverage its existing business and office management services and transform itself into a franchise provider.</p><div>
            <p>Join our list for access to an exclusive 1-hour analyst conference call on the future of WeWork's business.</p>
            
        </div>
    <h2 id="wework-s-road-to-redemption--">WeWork’s road to redemption&nbsp;&nbsp;</h2><ul><li><strong>Our DCF model gives WeWork a valuation of $3.5B.</strong> At this price, WeWork equity resembles a call option, with limited downside but asymmetric upside.</li><li><strong>The site economics behind WeWork's core business are surprisingly positive. </strong>24 months after opening, the average WeWork location can generate a 20% contribution margin, compared with economics from more stable peers. A big reason for WeWork’s cash burn was its lack of mature locations. In 2019, WeWork had the biggest flexible workspace footprint, but the lowest % of mature sites, comparing with its profit-making peers.</li><li><strong>WeWork has become much more prudent in new location openings.</strong> Mature locations are expected to grow to 50% by the end of 2020 and reach 100% in 2022.</li><li><strong>WeWork has spent 2020 stabilizing its core operations</strong> with 4 key measures.</li><li><strong>60% of WeWork's customers are now enterprises.</strong> During the pandemic, WeWork leased 3.5 million square feet to enterprise clients, including TikTok, Mastercard, Microsoft, Citigroup and Deloitte.</li><li><strong>WeWork's new CEO is a real estate veteran.</strong> The current CEO is a disciplined operator with successful turnaround experience.</li><li><strong>WeWork has rightsized its real estate portfolio.</strong> We estimate WeWork has exited 66 locations and amended about 150 leases, driving higher average occupancy and margins across their portfolio.</li><li><strong>WeWork has cut costs.</strong> WeWork has shrunk its workforce by 60% and cut many experimental growth projects, such as WeLive, WeGrow and self-driving chairs. Operating expenses are trending down significantly, from 86% of revenue in 2018 to an estimated 50% in 2019.</li><li><strong>Market dynamics are changing.</strong> Post-COVID, 80% of people want to return to the office a few days a week but keep the benefit of flexibility. Ironically, the downturn many thought would sink WeWork may become the very cause of its survival.</li><li><strong>WeWork is quietly transitioning to an integrated, tech-enabled ecosystem coordinator.</strong> Despite the large cost-cutting, WeWork continues to invest in community services, aka, the "killer app". For example, WeWork Labs is a community digital platform. It provides cross-sector incubator services to support companies to acquire skills, meet peers and experts.</li><li><strong>WeWork could reshape the real estate stack. </strong>It could leverage its physical locations and build a tech-enabled layer on top, thereby, transform into a middleware to connect people and optimize spaces.</li></ul><h2 id="valuation--wework-is-worth--3-5b">Valuation: WeWork is worth $3.5B</h2><p>Our base case discounted cash flow (“DCF”) model implies a 2021 forward equity value of $3.5B for WeWork.&nbsp;</p><p>WeWork still has the shape of a distressed company. The capital structure is heavily indebted and equity is at the bottom of the pecking order. Nevertheless, the equity resembles the asymmetric risk/reward profile of an out of the money call option.&nbsp;</p><p>In other words, given the current financial and operating dynamics of the company, for every one unit of enterprise value increase, the upside is amplified for the equity holders.&nbsp;</p><p>For anyone to stand behind WeWork now, however, they must be comfortable with a lot of macro uncertainties related to GDP, unemployment, speed of returning to the office and the opportunities around what the future of workspace would look like.&nbsp;</p><p>If WeWork can stabilize their operations in the near term through delayed capital spending, improved occupancy and regained focus, there could be a meaningful upside.</p><p>We highlight the structure of our model below.&nbsp;</p><p>Our aim with our model is to capture WeWork’s key growth and cost drivers to have a sense of the company’s profit-making potential. We used company disclosures from 2019 and turnaround guidance to form the base case assumptions. Our model calculates enterprise value by subtracting net debt and capitalized operating leases to derive equity value.&nbsp;</p><p>We can summarize our DCF into three distinct phases:</p><ul><li>Phase 1: 2020 - 2024 turnaround and stabilization.&nbsp;</li><li>Phase 2: 2025 - 2030 disciplined growth in the core business, expansion in franchise model and other business services.&nbsp;</li><li>Phase 3: 2031+ steady-state growth at 2%, with the overall occupancy to remain at 90%.&nbsp;</li></ul><p>We disaggregate revenue into total workstations, total memberships and average revenue per member (“ARPM”) to derive occupancy rates. We also build a CapEx profile based on cost per workstation to calculate location level contribution margin (WeWork defines contribution margin as membership revenue minus location operating expenses before headquarter administrative costs, growth expenses, marketing and stock-based compensation).&nbsp;</p><img src="https://images.prismic.io/sacra/40c25e89-a189-4840-9598-e31e51bb39f4_Screen+Shot+2020-12-17+at+16.39.31.png?auto=compress,format"><p><em>WeWork's revenue drivers. </em></p><p>WeWork doubled its total workstations between 2016 and 2019. As a result, mature locations accounted for only c.30% of the overall portfolio. To preserve cash and streamline operations, the pace of expansion has slowed significantly. The base case assumes total workstations to grow at 5% p.a. to reach 1.2M by 2024.&nbsp;</p><p>We illustrate our key revenue and cost assumptions below.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/651fa87a-afc1-4704-b255-af19682d60fe_Screen+Shot+2020-12-17+at+14.26.02.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Post the initial phase of “growth at all cost” prior to 2019, we model that between 2021 and 2024, WeWork would become more selective in new location openings, as well as, more prudent in the number of new openings.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/ff74c6c7-57a0-4331-973f-cb4f175995e7_Screen+Shot+2020-12-17+at+14.26.18.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Revenue: We model a slower revenue growth rate before WeWork achieves profitability.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/bc338059-f6b2-4418-a579-f4a85000e82a_Screen+Shot+2020-12-17+at+14.26.36.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Mixed shift: Enterprise memberships contribute 60% of the revenue in 2020. It is a positive trend that it almost doubled since 2017.&nbsp;</em></p>
        <div>
            <p><img src="https://images.prismic.io/sacra/bc174c16-e919-48b6-898e-94e5fb1e5aee_Screen+Shot+2020-12-17+at+14.26.48.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on WeWork, with appendix, DCF model, scenario analysis and key risks.</p>
                    <p><a href="https://sacra.com/research/wework-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>We model that, …</em></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/wework-engineering-a-comeback/">https://sacra.com/research/wework-engineering-a-comeback/</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/wework-engineering-a-comeback/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25462692</guid>
            <pubDate>Fri, 18 Dec 2020 01:20:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Hundred Different Misspellings of Schwarzenegger]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25462660">thread link</a>) | @cowllin
<br/>
December 17, 2020 | https://www.watercoolertrivia.com/blog/schwarzenegger | <a href="https://web.archive.org/web/*/https://www.watercoolertrivia.com/blog/schwarzenegger">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Arnold Alois Schwarzenegger was born in Austria on July 30, 1947. Famously, he reached stratospheric levels of notoriety and success in three wholly distinct professional fields: bodybuilding, acting, and politics, culminating in his eight years as the Governor of California.&nbsp;<br></p><p>For the past 73 years, Schwarzenegger has gone by Arnold, Ahnuld, Governator, <a href="https://en.wikipedia.org/wiki/Arnold_Schwarzenegger">Austrian Oak</a>, Terminator, Running Man, and dozens of other nicknames. In part because he’s charismatic and there’s nicknames aplomb to describe him, sure.&nbsp;<br></p><p><strong>But also because his last name is hard to spell. Like, really hard.</strong> We would know, because Water Cooler Trivia participants have spelled Schwarzenegger 255 different ways. And we’ve dug deep to explore that data.&nbsp;<br></p><p>255 different spellings. <a href="https://www.watercoolertrivia.com/blog/feature-emojis"><strong>We don’t grade responses based on spellings</strong></a>, so these are the spellings we’ve accepted as correct. We’ve got the full list of them at the end of this article, but we wanted to dig deeper into the data<br></p><h2>First things first: here’s the trivia question<br></h2><blockquote><strong>“What is the name of the Austrian bodybuilder who has been Mr. Universe three times and Mr. Olympia seven times?”</strong><br></blockquote><p>The answer, as you’ve surely guessed by now, is Arnold Schwarzenegger. We first wrote this question in April 2019, and since then…</p><ul role="list"><li><strong>3,019 different participants</strong> across 306 different groups have submitted a response</li><li><strong>2,681</strong> (89%) of folks got the question correct</li><li><strong>1,616</strong> (60%) of correct responses were spelled correctly [editor’s note: we suspect phone and browser autocorrect software lent a helping hand here]</li><li><strong>255</strong> different spellings of Schwarzenegger during that time<br></li></ul><p>And now, let’s look at the different ways in which Schwarzenegger has been spelled by Water Cooler Trivia participants.&nbsp;</p><h2>1. What are the most common misspellings?</h2><p>When you remove the correct spelling, you are left with 1,060 participants who spelled Schwarzenegger in 254 different ways.&nbsp;<br></p><p>The most common misspelling is to simply add a <strong>T </strong>after the <strong>R</strong>, a.k.a <strong>Schwartzenegger</strong>. This makes sense, as Schwartz itself is a fairly common German surname. 116 different respondents, 4% of all correct responses, spelled Arnold’s surname with that bonus <strong>T.</strong><br></p><p>Next up was <strong>Schwarzeneger</strong>, which removes a letter rather than adding one, this time removing one of the two <strong>G</strong>s. Again, this matches intuition. Double letters are hard to remember and frequently don’t add anything phonetically to a word. 88 different participants spelled it with this missing <strong>G</strong>, or 3% of all correct responses.<br></p><p>In third place was <strong>Schwarzenager</strong> with 56 people (2% of correct responses) both dropping that same <strong>G </strong>and then also swapping an <strong>E </strong>with a <strong>G. </strong>We get it, spelling is hard.<br></p><p>Below is a chart of the ten most common misspellings, and for the intrepid, here’s the <a href="https://docs.google.com/spreadsheets/d/1QqEL1IZvox3Aypi0YDStZ3QJ2_WuMTPwp7pOJ2batPE/edit#gid=756356712">full list</a> of misspellings.</p><figure id="w-node-73dd971f4f5a-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf08dd766ee0807d28_YMx1QfTHzO6c61u44T5MnhVihFk7AuJUa3aJXoUvDh8sLDYthwp4CYFclY0sUekxH3MYA1U9T9lu0OY0GBnxEtnBW-jUzNYQfk5iRSXSBP2musv3twFKBiNuMHwAPsVhEvrRVvUz.png" alt=""></p></figure><h2>2. Wait, how many letters is it?</h2><p>It’s 14 letters. S-c-h-w-a-r-z-e-n-e-g-g-e-r. But not everyone realized that.&nbsp;<br></p><p>Of the 255 total different spellings,&nbsp;</p><ul role="list"><li><strong>169</strong> (66%) had fewer than 14 letters</li><li><strong>24</strong> (9%) had more than 14 letters</li><li><strong>61</strong> (24%) correctly had 14 letters but were spelled incorrectly</li><li><strong>1</strong> (0.4%) correctly had 14 letters and was spelled correctly<br></li></ul><p>The most popular length was 13 letters with 31% of distinct spellings and 13% of all correct responses.</p><figure id="w-node-b1be6443de1a-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf088a2f4f273d8970_jDn-VaUiTJ_o9aGXBHJpAgFsSNJ4qViTLF0n0X5ZsN1kWQFbC7nS7JO88_K3BwfEaYJEkkT60LeNMN6-x7CwXgXXpJPsO7JLx7fPFXYMxPmM2bmSAaVNS0g1ttJBCkZDVdFqo_jX.png" alt=""></p></figure><h2>3. So it starts with an S... then a C… then...</h2><p>Schwarzenegger starts with the letter S. That’s fairly obvious. In fact, of the 255 distinct spellings that accepted as correct, 100% of them started with the letter <strong>S</strong>. However, once you move on to the second letter, <strong>only 58% of the spellings had C as the second letter.</strong><br></p><p>Unsurprisingly, the share of “correct” letters in terms of positions descends as you get further in the word, with a few noticeable deviations: interestingly, misspellings tend to correctly guess that the 11th letter is a <strong>G</strong> and the 14th letter is an <strong>R</strong>.<strong>&nbsp;</strong></p><figure id="w-node-3153958d4ef7-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcf6ef4066cb3b8bc5a_SVo29XaQjA6jKuUkHuTPk1t2s967m2NoVPJrmpRPCGKe3Hrzg40C8kdhQvOqWkjw_BH_8noZ2ds0YGXkppq-B22DsD0PZ6auFQTHvSlEjpjzYw7r1Htdz5sFgWl7oAdN6pVAGp-6.png" alt=""></p></figure><h4>Double Letters</h4><p>On that topic, Schwarzenegger has a double letter in it: two G’s as the 11th and 12th letter. This was a common source of misspellings, as 1<strong>47 of the distinct spellings (58%) guessed that there was only one G</strong> in the politician’s surname.<br></p><h4>Edit Distance</h4><p>Known as edit distance or Levenshtein distance, this is a measure of how many changes you need to make to a word or phrase in order to translate it into another word or phrase. <strong>So “bake” has a distance of one from “cake” or “ake” or “baked”.</strong><br></p><p>When you search the internet for <strong>Girrafe</strong> and the search engine asks <strong><em>“Did you mean Giraffe?”</em></strong><em> </em>they are making that guess because your search query only had an edit distance of two from the more common query term <strong>Giraffe</strong>. One deletion (the first <strong>R</strong>) and one insertion (the second <strong>F</strong>) turns your query into the correct word.&nbsp;<br></p><p>So, basically, this is a way to see <strong><em>how bad </em></strong>certain spellings were. Or, more optimistically, how generous we at Water Cooler Trivia are as graders.&nbsp;<br></p><p>Okay, with all that prologue finished, here’s the edit distance stats for the 255 distinct spellings of Schwarzenegger. Note that we are only surfacing the 1,060 responses that were incorrectly spelled.&nbsp;</p><ul role="list"><li><strong>34% had an edit distance of only one</strong>!</li><li>And another 28% were only off by two characters!</li><li>18% of misspellings had an edit distance of at least four</li></ul><figure id="w-node-00b9f866edfc-e7177fda"><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5fdbffcfee56eb8449ae2563_Qw6LyfdHxuw1-KuhsN3NFHyHzwr-1PnjCWoBqcc6pBTMNmr1DKqO-LmCkjcwMx-wn3K4inzJcTAnSOQCLQokxfe_psFkS6F8YkA4ohbuvw5kcvg7D9ApQtGulyfaG4kXCjRYgV-r.png" alt=""></p></figure><h2>4. What does Schwarzenegger even mean?</h2><p>I was wondering that too. It turns out the name has Germanic roots, divided neatly into two terms.</p><ul role="list"><li>"schwarzen" means "black"</li><li>&nbsp;"egg" refers to a ridge<br></li></ul><p>So the Governator’s surname <strong>translates most literally into English as Black Ridge</strong>, which happens to be the name of a U.S. <a href="https://www.blackridge.us/"><strong>technology services company</strong></a>.</p><h2>Closing thoughts...</h2><p>Looking to learn about more commonly-misspelled names or commonly-mistaken knowledge? Us too! We have a dataset of 2.5 million free text trivia responses. If you want to work with us to mine for fun data-driven stories, email <a href="https://www.watercoolertrivia.com/cdn-cgi/l/email-protection#680c091c09281f091c0d1a0b0707040d1a1c1a011e0109460b0705"><span data-cfemail="492d283d28093e283d2c3b2a2626252c3b3d3b203f2028672a2624">[email&nbsp;protected]</span></a> and we can find a way to work together.<br></p><p>Or if you just want to bring a <a href="https://www.watercoolertrivia.com/blog/how-weekly-trivia-impacts-your-mental-well-being"><strong>weekly trivia ritual</strong></a> to your team, that would make our hearts a-flutter. Get started with a four-week free trial at our <a href="http://watercoolertrivia.com/"><strong>homepage</strong></a>.<br></p></div></div>]]>
            </description>
            <link>https://www.watercoolertrivia.com/blog/schwarzenegger</link>
            <guid isPermaLink="false">hacker-news-small-sites-25462660</guid>
            <pubDate>Fri, 18 Dec 2020 01:15:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse engineering the Nest home/away API]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25459560">thread link</a>) | @emilburzo
<br/>
December 17, 2020 | https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/ | <a href="https://web.archive.org/web/*/https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
<p>A while ago I purchased a Nest camera because I liked the idea of only having to provide power and a WiFi connection to get a nice security system.</p>
<p>The fact that you could control it with <a href="https://support.google.com/googlenest/answer/9293712?hl=en">Works with Nest</a> (their open API) was a major factor in that decision.</p>
<p>Then Google bought Nest, and <a href="https://www.consumerreports.org/smart-home/things-to-know-about-works-with-nest-shutdown/">disabled access</a> for users who didn’t sign up in time (including me).</p>
<p>There were some promises that a new open API will be created “soon”.</p>
<p>Eventually, they released the <a href="https://developers.google.com/nest/device-access/api">Smart Device Management API</a>, and although you can do some things (get camera stream), you can’t set the “Home/Away” status.</p>
<p>Bummer.</p>

<p>You can read more about it <a href="https://support.google.com/googlenest/answer/9257400">here</a>, but <strong>TL;DR</strong> the Nest camera movement/sound alarms only trigger if it’s set to “Away”.</p>
<p>For reasons I don’t want to go into, the automatic Home/Away feature doesn’t work for me so I need a way to control it from code so it can be automated, as all good things.</p>

<p>Like all pros, my first try was to just open the Nest webapp with DevTools open, click the Home/Away toggle, copy as curl, run it from the CLI and… nothing.</p>
<p>Didn’t work.</p>
<p>Upon closer inspection I noticed the payload was binary, never a good sign :)</p>
<div><pre><code data-lang="bash">curl --data-binary <span>$'\nB\n\u001aSTRUCTURE_XXXXXXXXXXXXXXXX\u0012$XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\u0012\u0095\u0001\n\u000estructure_mode\u0012u\nTtype.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeRequest\u0012\u001d\u0008\u0002\u0010\u0001\u001a\u0017\n\u0015USER_XXXXXXXXXXXXXXXX\u001a\u000c\u0008ü¸Ìþ\u0005\u0010\u0080É\u0087¸\u0001'</span> <span>'https://grpc-web.production.nest.com/nestlabs.gateway.v1.ResourceApi/SendCommand'</span>  
</code></pre></div><p>(some details redacted)</p>

<p>The host endpoint at the end of the <code>curl</code> command was a very good hint that they are using <a href="https://grpc.io/">gRPC</a>, which I didn’t have any experience with so far.</p>
<p>On the gRPC website was our next clue:</p>
<blockquote>
<p>Define your service using Protocol Buffers, a powerful binary serialization toolset and language</p>
</blockquote>
<p>That matches the binary payload that we previously saw, now it’s getting exciting!</p>

<p>Since the simple payload replay didn’t do anything, I needed to figure out what’s actually in there.</p>
<p>The first (surprising) problem was actually just getting the binary payload into a text file, I guess the binary was getting messed up somewhere between the browser and the file I was pasting to.</p>
<p>The “Save all as HAR with content” feature was very helpful here, especially since there’s a base64 encoded field beneath the binary one.</p>
<p>Extracting that only took a bit of bash magic:</p>
<div><pre><code data-lang="bash">cat set-away-home.nest.com.har                           <span>\
</span><span></span>    | gron                                               <span>\
</span><span></span>    | grep <span>'json.log.entries[1].response.content.text'</span>   <span>\
</span><span></span>    | cut -d <span>'"'</span> -f <span>2</span>                                    <span>\
</span><span></span>    | base64 -d                                          <span>\
</span><span></span>    | base64 -d
</code></pre></div><p>(If you don’t know about <a href="https://github.com/tomnomnom/gron">gron</a>, you should definitely check it out, it makes JSON grep-able)</p>
<p>(No idea why it was base64-encoded twice)</p>

<p>Going through the official protobuf documentation it seemed like I needed the <code>.proto</code> files to do anything useful.</p>
<p>Which I couldn’t figure out how to extract from the Nest website, or if that’s even possible.</p>
<p>Luckily, I stumbled upon <code>protoc --decode_raw</code>, which gave the following output:</p>
<pre><code>1 {
  1 {
    1: "STRUCTURE_XXXXXXXXXXXXXXXX"
    2: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
  }
  2 {
    1 {
      1: "STRUCTURE_XXXXXXXXXXXXXXXX"
      2: "structure_mode"
      3: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
    }
    2: 4
    4 {
      1 {
        1: "type.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeResponse"
        2 {
          1: 1
        }
      }
    }
    6 {
      1 {
        1: "STRUCTURE_XXXXXXXXXXXXXXXX"
        2: "structure_mode"
        3: "XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX"
      }
      2 {
        1: "type.nestlabs.com/nest.trait.occupancy.StructureModeTrait.StructureModeChangeRequest"
        2 {
          1: 2
          2: 1
          3 {
            1: "USER_XXXXXXXXXXXXXXXX"
          }
        }
      }
      3 {
        1: XXXXXXXXXX
        2: XXXXXXXXX
      }
    }
  }
}
15: ""
2: ""
15: "\000\000"
</code></pre><p>Quite a heavy payload to set a flag.</p>
<p>Then I tried to manually create the <code>.proto</code> files going by the output from above.</p>
<p>Not fun.</p>
<p>By luck (aka searching GitHub for those types) I found out that somebody a lot smarter than me had actually <a href="https://github.com/derek-miller/nest-protobuf">managed to extract the proto files</a> from the Nest website, thank you stranger!</p>

<p>Time to make use of those <code>.proto</code> files.</p>
<p>Start up the IDE and follow the protobuf tutorial on how to build a payload.</p>
<p>It was a lot harder than I expected.</p>
<p>I’m sure most of the hardness came from me never using protobuf before, but it also took me a bit to realize that they serialize the command we care about (<code>StructureModeChangeRequest</code>) into a generic type (<code>ResourceCommandRequest</code>) which is then also serialized.</p>
<p>Eventually I was able to send the protobuf payload to the Nest API and oh boy, seeing that icon switch from “Home” to “Away” was like an early christmas :)</p>
<p><img src="https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/images/nest-home-away.gif" alt="Nest home to away animation"></p>
<p>Hmm, but why isn’t the HTTP connection closing? It just hangs there.</p>
<p>Comparing the headers from the original request I could see that there’s an <code>X-Accept-Response-Streaming: true</code> header, adding it caused the connection to directly close as expected.</p>
<p>Strange, especially since <code>false</code> keeps the connection open. Mystery for another day.</p>
<p>I packaged everything nicely into a <a href="https://github.com/emilburzo/nest-rest">GitHub repo</a> and moved on to the last part.</p>

<p>The standard approach here would be to install some location tracker on all the “home” phones and periodically send it to a server which then decides when to toggle the Nest status.</p>
<p>Although I actually built an <a href="https://graticule.link/">android location sharing app</a>, I didn’t like this approach due to having to make a tradeoff between battery life and responsiveness.</p>
<p>I also looked into Google Location Sharing, but it involved creating another Google Account, permanently sharing my location with it and using that as the source. Too fragile.</p>
<p>The solution I went with in the end was:</p>
<ul>
<li>assign static IPs to all the relevant phones</li>
<li>try to connect to them from the internal network</li>
</ul>
<p>If the response is <code>connection refused</code>, they are on the network/“home”.</p>
<p>Anything else, they aren’t “home”.</p>
<p>Well, maybe also <code>connection accepted</code> if you’re weird and have a server on your phone.</p>
<p>I’m still surprised how well this works, because I read a lot of “don’t do this” online with reasons like:</p>
<ul>
<li>phones will automatically switch off their WiFi overnight</li>
<li>they won’t respond when they are in deep sleep</li>
<li>etc</li>
</ul>
<p>Maybe I got lucky, but it works, and it works very well:</p>
<pre><code>2020-12-17 09:36:07 INFO     found hosts: ['192.168.0.30', '192.168.0.31']
2020-12-17 09:36:07 INFO     192.168.0.30 is home
2020-12-17 09:36:09 INFO     set status to: home (200)
2020-12-17 09:41:09 INFO     192.168.0.30 is home
2020-12-17 09:46:13 INFO     192.168.0.31 is home
2020-12-17 09:51:17 INFO     192.168.0.31 is home
[..]
2020-12-17 11:17:29 INFO     set status to: away (200)
2020-12-17 12:35:11 INFO     192.168.0.31 is home
2020-12-17 12:35:12 INFO     set status to: home (200)
2020-12-17 12:40:16 INFO     192.168.0.31 is home
</code></pre><p>The switch from Away -&gt; Home is quicker than doing it by hand :)</p>
<p>I prepared another <a href="https://github.com/emilburzo/nest-home-away">GitHub repo</a>, fired everything up, and… it works!</p>

<p>It really sucks that I had to spend a day for something that either should just work, or at least I should have access to change on my own.</p>
<p>If the camera quality wasn’t so high I would have just ditched it and gone self-hosted with a DVR/NVR.</p>
<p>It would have taken longer to build all the features, but then I have control over every part.</p>
<p>The Nest app is still annoying me to migrate to a Google account, so let’s see for how long this solution actually works.</p>
    </div></div>]]>
            </description>
            <link>https://blog.emilburzo.com/2020/12/reverse-engineering-nest-home-away-status-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459560</guid>
            <pubDate>Thu, 17 Dec 2020 19:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon disallows pointing out paid reviews]]>
            </title>
            <description>
<![CDATA[
Score 963 | Comments 422 (<a href="https://news.ycombinator.com/item?id=25459434">thread link</a>) | @kmod
<br/>
December 17, 2020 | http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/ | <a href="https://web.archive.org/web/*/http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-1067">
<p><span><span>17</span>Dec/20</span><span><a href="http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/#comments">11</a></span></p>

<p>I recently bought a webcam from Amazon (late to the party, I know), and when it came it was fine but not amazing.</p>
<p>When I went through the packaging I saw a little card saying "send us a screenshot of your 5-star review and we'll give you a $10 Amazon gift card":</p>
<p><img src="http://blog.kevmod.com/wp-content/uploads/2020/12/IMG_16902.jpg" alt="$10 for 5-star reviews" width="400/"></p>
<p>I thought that other Amazon shoppers would want to know that this was happening and that the reviews were less trustworthy, so I wrote up a review and submitted it to Amazon.</p>
<p>Yesterday I got a notification that my review was rejected.  I heard of Amazon being ham-fisted about this stuff but it was still shocking that it would happen to me:</p>
<p><img src="http://blog.kevmod.com/wp-content/uploads/2020/12/screenshot.png" alt="Amazon review rejection"></p>
<p>I assume they rejected this due to the first rule, "Feedback on the seller ... should be provided [elsewhere]".  I could understand this being a good policy in some cases, but here they're using it to justify silencing talk about reviews.  I suppose we don't know whether they disallow positive comments about other reviews, but I would guess that that never happens.</p>
<p>I remember that I used to use Amazon ratings as the main driver behind my purchases, so it's sad to see the review system become less helpful over time.  It's extra sad that Amazon would rather try to hide the issue and not improve it.</p>
<p>Update:<br>
My premise was that the reviews section should be helpful for making purchasing decisions.  Some people (including Amazon) are saying that the reviews should be about the product, which is coherent but I would argue makes them less useful.  For example I feel quite helped when a review for chocolate mentions that the chocolate arrived melted -- this is not a review about the product intrinsically, but is still very helpful for deciding whether or not to buy the item.  Similarly, as a purchaser I would want to see a warning that there may be paid reviews for the product, and I was very surprised to learn that Amazon disallows such warnings.</p>
<p>Update 2:<br>
I submitted feedback through the link they requested, and here's the result:</p>
<p>https://www.amazon.com/sp?_encoding=UTF8&amp;asin=B087NN41JH&amp;isAmazonFulfilled=1&amp;ref_=olp_merch_name_1&amp;seller=AD5F1I5PAE5XB</p>
<p>I don't think this serves either goal of educating future purchasers or changing the sellers behavior.</p>
<p>Update 3:<br>
I've chatted with an Amazon rep on the issue, and to their credit they seemed to take it seriously and "noted the report violation against the seller".  They said to expect an update in 2-3 business days, though it's not clear what sort of update it will be.</p>







</div></div>]]>
            </description>
            <link>http://blog.kevmod.com/2020/12/amazon-disallows-pointing-out-paid-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25459434</guid>
            <pubDate>Thu, 17 Dec 2020 19:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An introduction to property-based testing with QuickCheck]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25457744">thread link</a>) | @gbrown_
<br/>
December 17, 2020 | https://jesper.sikanda.be/posts/quickcheck-intro.html | <a href="https://web.archive.org/web/*/https://jesper.sikanda.be/posts/quickcheck-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
      Posted
      
            by Jesper
       on December 17, 2020
    </p>
    <p>In February, I will be teaching a new course on Functional Programming at TU Delft. The course will mostly cover Haskell using <a href="https://www.cs.nott.ac.uk/~pszgmh/pih.html">Graham Hutton’s excellent book</a>, though there will be a part on basic usage of dependent types in Agda towards the end as well. For the exercises, we will use the Delft-grown <a href="https://weblab.tudelft.nl/">Weblab platform</a> for letting the students code and run the automated tests using QuickCheck. Unfortunately for me, the book does not talk about QuickCheck at all. Fortunately for you, that means I decided to write a tutorial myself, which you can read here.</p>
<p>Of course there are many excellent QuickCheck tutorials out there already. However I found all of them either assumed too much Haskell knowledge (since I want to introduce QuickCheck as early as possible), skipped out on interesting parts (such as conditional and quantified properties), or were just not up-to-date with the latest version of QuickCheck (such as the new approach for generating random functions using <code>Fun</code>). So I hope this post closes a gap in the current menu of tutorials for at least a few people.</p>
<p>If you spot any errors or opportunities for improvement, please let me know. The students at TU Delft will be grateful!</p>

<p>When you were first learning to program, at some point you were probably told about the importance of writing <em>unit tests</em>: small test cases that each test a small piece of functionality of your code. And while it is true that writing unit tests is important, it is also at the same time <em>boring</em> and <em>difficult</em>. It is boring because you need to write many separate unit tests for each piece of functionality, which all look more or less the same. And it is difficult because it is very easy to miss a certain combination of inputs for which the program crashes. Would it not be nice if we could just write down how the program should behave and have the test cases be generated automatically? That is precisely the approach of <strong>property-based testing</strong>.</p>
<p>In short, property-based testing is an approach to testing where you as the programmer write down properties that you expect to hold of your program. When running the tests, the test runner will generate a lot of different random input values, and then check that the property holds for all these (combinations of) input values. Compared to writing individual unit tests, property-based testing has several advantages:</p>
<ul>
<li>You spend <strong>less time writing test code</strong>: a single property can often replace many hand-written test cases.</li>
<li>You get <strong>better coverage</strong>: by randomly generating inputs, QuickCheck will test lots of combinations you’d never test by hand.</li>
<li>You spend <strong>less time on diagnosis of errors</strong>: if a property fails to hold, QuickCheck will automatically produce a minimized counterexample.</li>
</ul>
<p><strong>QuickCheck</strong> is a tool for property-based testing of Haskell code. Since its introduction for Haskell in 1999, QuickCheck has become very popular as a testing framework and has been ported to many other programming languages such as C, C++, Java, JavaScript, Python, Scala, and many others (see <a href="https://en.wikipedia.org/wiki/QuickCheck">https://en.wikipedia.org/wiki/QuickCheck</a> for a more complete list). However, QuickCheck really benefits from the fact that Haskell is a pure language, so that is where the approach continues to be the most powerful.</p>
<p>This introduction will show you the basic usage of QuickCheck for testing properties of Haskell code, as well as how to use alternative random generators. All the functions that are used come from the module <code>Test.QuickCheck</code> from the QuickCheck package. This package can be installed using the Cabal package manager for Haskell by issuing the following command:</p>
<pre><code>&gt; cabal install QuickCheck</code></pre>

<p>To write a QuickCheck test case, all you have to do is define a Haskell function that defines a <strong>property</strong> of your program that you expect to hold. In the simplest case, a property is just a value of type <code>Bool</code>. For example, suppose we have written a simple Haskell function to calculate the distance between two integers:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>distance ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>Int</span></span>
<span id="cb2-2">distance x y <span>=</span> <span>abs</span> (y<span>-</span>x)</span></code></pre></div>
<p>We can then express the property that the distance between <code>3</code> and <code>5</code> equals <code>2</code>:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>prop_dist35 ::</span> <span>Bool</span></span>
<span id="cb3-2">prop_dist35 <span>=</span> distance <span>3</span> <span>5</span> <span>==</span> <span>2</span></span></code></pre></div>
<p>By convention, names of QuickCheck properties always start with <code>prop_</code>. We can express more general properties by defining a function that returns a <code>Bool</code>:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>-- The distance between any number and itself is always 0</span></span>
<span id="cb4-2"><span>prop_dist_self ::</span> <span>Int</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb4-3">prop_dist_self x <span>=</span> distance x x <span>==</span> <span>0</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span>-- The distance between x and y is equal to the distance between y and x</span></span>
<span id="cb4-6"><span>prop_dist_symmetric ::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb4-7">prop_dist_symmetric x y <span>=</span> distance x y <span>==</span> distance y x</span></code></pre></div>
<p>When testing a property that takes one or more inputs, QuickCheck will randomly generate several inputs (100 by default) and check that the function returns <code>True</code> for all inputs.</p>
<p>The main function used to call QuickCheck is <code>quickCheck</code>, which is defined in the module <code>Test.QuickCheck</code>. To import it, you can either add <code>import Test.QuickCheck</code> at the top of your file or import it manually if you are working from GHCi. Assuming you have installed the QuickCheck package, you can then load the file and run tests by calling <code>quickCheck</code>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>&gt;</span> ghci</span>
<span id="cb5-2"><span>GHCi</span>, version <span>8.10</span><span>.</span><span>2</span><span>:</span> https<span>://</span>www<span>.</span>haskell<span>.</span>org<span>/</span>ghc<span>/</span>  <span>:?</span> for help</span>
<span id="cb5-3"><span>Loaded</span> package environment from <span>~/.</span>ghc<span>/</span>x86_64<span>-</span>linux<span>-</span><span>8.10</span><span>.</span><span>2</span><span>/</span>environments<span>/</span>default</span>
<span id="cb5-4"><span>&gt;</span> <span>:</span>l QuickCheckExamples.hs</span>
<span id="cb5-5"><span>&gt;</span> quickCheck prop_dist35</span>
<span id="cb5-6"><span>+++</span> <span>OK</span>, passed <span>1</span> test<span>.</span></span></code></pre></div>
<p>QuickCheck tells us that everything is as it should be: it ran the test and got the result <code>True</code>. Since there are no inputs to the test, it is run only once. Let us try out some more properties!</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>&gt;</span> quickCheck prop_dist_self</span>
<span id="cb6-2"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span>
<span id="cb6-3"><span>&gt;</span> quickCheck prop_dist_symmetric</span>
<span id="cb6-4"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span></code></pre></div>
<p>Huge success! For each of the tests, QuickCheck has generated 100 random inputs and verified that for each one the property returns <code>True</code>.</p>
<p>To get more information about the test inputs that are generated by QuickCheck, you can replace the function <code>quickCheck</code> with <code>verboseCheck</code>. This will print out each individual test case as it is generated. Try it out for yourself!</p>
<h2 id="shrinking-counterexamples">Shrinking counterexamples</h2>
<p>What happens if there’s a mistake in our code? Say we forgot to write <code>abs</code> in the definition of <code>distance</code>?</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>&gt;</span> quickCheck prop_dist_symmetric</span>
<span id="cb7-2"><span>***</span> <span>Failed</span><span>!</span> <span>Falsified</span> (after <span>2</span> tests)<span>:</span>                  </span>
<span id="cb7-3"><span>0</span></span>
<span id="cb7-4"><span>1</span></span></code></pre></div>
<p>QuickCheck has found a counterexample: if the first input <code>x</code> is 0 and the second input <code>y</code> is 1, then <code>y-x</code> is not equal to <code>x-y</code>.</p>
<p>When QuickCheck finds a counterexample, it will not always return the first one it encounters. Instead, QuickCheck will look for the smallest counterexample it can find. As an example, let us try to run QuickCheck on the (false) property stating that every list is sorted.</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>sorted ::</span> <span>Ord</span> a <span>=&gt;</span> [a] <span>-&gt;</span> <span>Bool</span> </span>
<span id="cb8-2">sorted (x<span>:</span>y<span>:</span>ys) <span>=</span> x <span>&lt;=</span> y <span>&amp;&amp;</span> sorted (y<span>:</span>ys)</span>
<span id="cb8-3">sorted _        <span>=</span> <span>True</span></span>
<span id="cb8-4"></span>
<span id="cb8-5"><span>-- A (false) property stating that every list is sorted</span></span>
<span id="cb8-6"><span>prop_sorted ::</span> [<span>Int</span>] <span>-&gt;</span> <span>Bool</span></span>
<span id="cb8-7">prop_sorted xs <span>=</span> sorted xs</span></code></pre></div>
<div id="cb9"><pre><code><span id="cb9-1"><span>&gt;</span> verboseCheck prop_sorted</span>
<span id="cb9-2"><span>Passed</span><span>:</span>  </span>
<span id="cb9-3">[]</span>
<span id="cb9-4"></span>
<span id="cb9-5"><span>Passed</span><span>:</span> </span>
<span id="cb9-6">[]</span>
<span id="cb9-7"></span>
<span id="cb9-8"><span>Passed</span><span>:</span>  </span>
<span id="cb9-9">[<span>0</span>]</span>
<span id="cb9-10"></span>
<span id="cb9-11"><span>Failed</span><span>:</span>  </span>
<span id="cb9-12">[<span>2</span>,<span>1</span>,<span>3</span>]</span>
<span id="cb9-13"></span>
<span id="cb9-14"><span>Passed</span><span>:</span>                                 </span>
<span id="cb9-15">[]</span>
<span id="cb9-16"></span>
<span id="cb9-17"><span>Passed</span><span>:</span>                                                 </span>
<span id="cb9-18">[<span>1</span>,<span>3</span>]</span>
<span id="cb9-19"></span>
<span id="cb9-20"><span>Passed</span><span>:</span>                                                 </span>
<span id="cb9-21">[<span>2</span>,<span>3</span>]</span>
<span id="cb9-22"></span>
<span id="cb9-23"><span>Failed</span><span>:</span>                                                 </span>
<span id="cb9-24">[<span>2</span>,<span>1</span>]</span>
<span id="cb9-25"></span>
<span id="cb9-26"><span>...</span></span>
<span id="cb9-27"></span>
<span id="cb9-28"><span>***</span> <span>Failed</span><span>!</span> <span>Falsified</span> (after <span>4</span> tests <span>and</span> <span>3</span> shrinks)<span>:</span>    </span>
<span id="cb9-29">[<span>1</span>,<span>0</span>]</span></code></pre></div>
<p>The first list that is generated that is not sorted is <code>[2,1,3]</code>. Note that this will be a different list every time we run QuickCheck since it is randomly generated. However, QuickCheck does not stop there and instead tries smaller and smaller lists until it converges to a minimal counterexample: <code>[1,0]</code>. This process is called <strong>shrinking</strong>.</p>
<p>It is worth noting that despite the inherent randomness of QuickCheck, shrinking will often converge to one of a small set of minimal counterexamples. For example, if we run <code>quickCheck</code> many times on <code>prop_sorted</code>, we always end up with either <code>[1,0]</code> or <code>[0,-1]</code> as a counterexample.</p>
<p>The precise strategy that QuickCheck uses for shrinking counterexamples depends on the type of the counterexample:</p>
<ul>
<li><p>For numeric types such as <code>Int</code>, QuickCheck will try a random number that is smaller in absolute value (i.e.&nbsp;closer to 0).</p></li>
<li><p>For booleans of type <code>Bool</code>, QuickCheck will try to replace <code>True</code> with <code>False</code>.</p></li>
<li><p>For tuple types <code>(a,b)</code>, QuickCheck will try to shrink one of the components.</p></li>
<li><p>For list types, QuickCheck will try to either delete a random element from the list, or try to shrink one of the values in the list.</p></li>
</ul>
<h2 id="testing-many-properties-at-once">Testing many properties at once</h2>
<p>Instead of running individual tests from GHCi, you can also combine all your tests in a <code>main</code> function:</p>
<div id="cb10"><pre><code><span id="cb10-1">main <span>=</span> <span>do</span></span>
<span id="cb10-2">  quickCheck prop_dist35</span>
<span id="cb10-3">  quickCheck prop_dist_self</span>
<span id="cb10-4">  quickCheck prop_dist_symmetric</span></code></pre></div>
<p>This code makes use of Haskell <code>do</code> keyword that we will study in the chapter on monads. Once you have defined this <code>main</code> function, you can invoke it by calling <code>runghc</code> from the command line:</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>&gt;</span> runghc QuickcheckExamples.hs</span>
<span id="cb11-2"><span>+++</span> <span>OK</span>, passed <span>1</span> test<span>.</span></span>
<span id="cb11-3"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span>
<span id="cb11-4"><span>+++</span> <span>OK</span>, passed <span>100</span> tests<span>.</span></span></code></pre></div>
<p>Note that a file may only contain a single <code>main</code> function. In a realistic project, we would instead create a separate file that just defines all QuickCheck properties and puts them together in a <code>main</code> function.</p>
<p><strong>Remark.</strong> When you are writing code in the WebLab instance for this course, you do not need to write a main function for QuickCheck tests: WebLab will automatically collect all functions in the <code>Test</code> tab whose name starts with <code>prop_</code> and run <code>quickCheck</code> on each one.</p>

<p>The biggest challenge in making effective use of QuickCheck lies in coming up with good properties to test. So let us take a look at some examples of good properties to test.</p>
<h2 id="roundtrip-properties">Roundtrip properties</h2>
<p>When one function is an inverse to another function, we can create a property test for that. For example, we can test that reversing a list is its own inverse:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>prop_reverse_reverse ::</span> [<span>Int</span>] <span>-&gt;</span> <span>Bool</span></span>
<span id="cb12-2">prop_reverse_reverse xs <span>=</span> <span>reverse</span> (<span>reverse</span> xs) <span>==</span> xs</span></code></pre></div>
<p>As another example, we can test that inserting an element into a list and then deleting it again …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesper.sikanda.be/posts/quickcheck-intro.html">https://jesper.sikanda.be/posts/quickcheck-intro.html</a></em></p>]]>
            </description>
            <link>https://jesper.sikanda.be/posts/quickcheck-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25457744</guid>
            <pubDate>Thu, 17 Dec 2020 17:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make comic book layouts in the browser]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455659">thread link</a>) | @TiredGuy
<br/>
December 17, 2020 | https://andrewfulrich.gitlab.io/panelle/ | <a href="https://web.archive.org/web/*/https://andrewfulrich.gitlab.io/panelle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://andrewfulrich.gitlab.io/panelle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455659</guid>
            <pubDate>Thu, 17 Dec 2020 14:07:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[More information on the plant disturbance at Olkiluoto 2]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455279">thread link</a>) | @ericdanielski
<br/>
December 17, 2020 | https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html | <a href="https://web.archive.org/web/*/https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.tvo.fi/en/index/news/pressreleasesstockexchangereleases/2020/moreinformationontheplantdisturbanceatolkiluoto2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455279</guid>
            <pubDate>Thu, 17 Dec 2020 13:18:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cyberpunk 2077 Din Schachtdeckel]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25455049">thread link</a>) | @Fake4d
<br/>
December 17, 2020 | https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel | <a href="https://web.archive.org/web/*/https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Gamer diskutieren derzeit über deutsche DIN-Schachtdeckel in einem weltbekannten Computerspiel. Den RSV freut's.</strong></p>
<p>Im amerikanischen Schauplatz des Spiels "Cyberpunk 2077" kommen Schachtabdeckungen nach deutscher Bauart zum Einsatz – allerdings dort, wo es eigentlich nicht DIN-konform wäre. Nach ersten Diskussionen in sozialen Netzwerken gibt es nun sogar schon eine - nicht ganz ernst gemeinte - <a href="https://www.change.org/p/the-cyberpunk-developers-fix-the-manhole-covers-in-cyberpunk-2077" target="_blank" rel="noopener">Petition</a>, die die Entwickler zu mehr Sorgfalt auffordert.</p>
<p><strong>RSV: Endlich mehr Aufmerksamkeit für unsere Branche</strong></p>
<p>Volle Unterstützung gibt es auch vom RSV: "Wir freuen uns über die wachsende Anerkennung für diesen bisher unterbelichteten Bereich in der Öffentlichkeit und hoffen, dass die Entwickler dieses Detail der DIN-Norm zuliebe ausbessern", sagt RSV-Geschäftsführerin Reinhild Haacker dazu, nicht ohne Augenzwinkern. "Deutsche Qualität und Normen liegen uns beim RSV am Herzen. Es ist beruhigend zu wissen, dass deutsche Schachtdeckel – zumindest nach Einschätzung der Gaming-Entwickler – in 57 Jahren zum Einsatz kommen werden, und das sogar in den USA. Dennoch sehen wir uns verpflichtet, im Sinne der Qualitätssicherung darauf hinzuweisen, dass eine DIN 4271 Schachtabdeckung nicht, wie im Spiel gezeigt, auf einer Fahrbahn verbaut werden darf."</p>
<p><strong>Gamer stoßen Petition an</strong></p>
<p>In dem Computerspiel, das derzeit millionenfach gespielt wird, schlüpfen Gamer in die Rolle eines Hackers in einer fiktiven US-Metropole im Jahr 2077. Deutsche Fans des Spiels teilten auf Twitter und in Gaming-Foren Bilder des falsch verbauten DIN-Schachtdeckels, bevor sie scherzhaft eine <a href="https://www.change.org/p/the-cyberpunk-developers-fix-the-manhole-covers-in-cyberpunk-2077">Petition</a> zum Thema einleiteten.</p>
<p>Für das Spiel hatten die polnischen Entwickler übrigens sogar Stadtplaner engagiert, um möglichst realitätsnah rüberzukommen. Möglicherweise haben die vollmundigen Ankündigungen auch dazu geführt, dass Gamer - mit der gewohnten deutschen Gründlichkeit - besonders genau hinschauen.</p>
</div></div>]]>
            </description>
            <link>https://rsv-ev.de/cyberpunk-2077-din-schachtdeckel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455049</guid>
            <pubDate>Thu, 17 Dec 2020 12:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to let go of a lifelong dream]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25455014">thread link</a>) | @known
<br/>
December 17, 2020 | https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Emma Garber began dancing aged three. By the time she was a teenager â€“ following years of dedicated, exhausting, sometimes painful training â€“ it was her burning ambition to become a professional ballet dancer. â€˜I think around age 14, I sat my parents down and I said: <em>This is what I want to do with my life. This is what makes me happy</em>,â€™ she says.</p>
<p>All of us have dreams and hopes for our future. They are often career-focused, but not always. Some people dream of starting a family or living in another country, for instance. Our dreams form part of our identity, giving us purpose and direction. That is, until reality gets in the way, as so often happens: the change might come from within us, as our passion wanes, or the obstacles to realising the dream might become insurmountable (or a mixture of the two).</p>
<p>Garberâ€™s dream began to fade amid burnout and doubt during her freshman year at the University of Massachusetts. After a particularly terrible dance class, she recalls: â€˜I was like, <em>I donâ€™t think I want to do this for the rest of my life</em>. I stood up, I walked out, I called my mom and I was like, <em>I donâ€™t even know what I want to do with my life anymore</em>.â€™</p>
<p>You might be experiencing one of these unsettling fork-in-the-road moments yourself. Perhaps the dying breath of a fading dream is leaving you with intense feelings of regret and failure. You might fear how others will judge you. After all, in todayâ€™s culture, in many parts of the world, weâ€™re taught from a young age that success is born from stubborn perseverance.</p>
<p>â€˜To be gritty,â€™ writes the psychologist Angela Duckworth in her bestselling <a href="https://www.penguin.co.uk/books/110/1109188/grit/9781785042669.html" rel="nofollow noreferrer noopener">book</a> <em>Grit</em> (2016), â€˜is to fall down seven times, and rise eight.â€™ The gist of her advice has echoed through different eras. â€˜Many of lifeâ€™s failures are people who did not realise how close they were to success when they gave up,â€™ wrote the inventor Thomas Edison.</p>
<p>Given this dominant narrative of the virtues of perseverance, and considering how our ambitions can become a core part of our sense of self, itâ€™s understandable that you might be finding it difficult and unsettling to face the prospect of losing your dream. You can take comfort, though, in knowing that being adaptable and flexible in oneâ€™s ambitions is just as important as being gritty or determined. â€˜By definition, if you cannot achieve what you want to achieve, you will fail repeatedly if you donâ€™t stop,â€™ says Carsten Wrosch, a psychology professor at Concordia University in Montreal, who has been studying the construct of â€˜goal adjustment capacityâ€™ for more than 20 years.</p>
<p>Goal adjustment capacity â€“ which psychologists <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/jopy.12492" rel="nofollow noreferrer noopener">see</a> as a beneficial form of â€˜self-regulationâ€™ or â€˜self-managementâ€™ â€“ encapsulates two key components: the ability to disengage from fruitless goals and the ability to reengage in new, more productive goals. You could see it as knowing when and how to switch from one dream to another. Itâ€™s measured by agreement with questionnaire items such as â€˜Itâ€™s easy for me to stop thinking about the goal and let it goâ€™ and â€˜I tell myself that I have a number of other new goals to draw upon.â€™</p>
<p>Wrosch says that people who lack this capacity are inclined to â€˜bang their head against the wallâ€™ when theyâ€™re confronted by an unobtainable goal, and, long-term, theyâ€™re more prone to stress and chronic illness. In contrast, those with greater adjustment capacity â€˜have a much easier timeâ€™ â€“ they decommit to the fruitless goal and find a different ambition to pursue. The virtues of being flexible and adaptable are also recognised by careers researchers, who <a href="https://www.sciencedirect.com/science/article/abs/pii/S0001879116300604" rel="nofollow noreferrer noopener">refer</a> to â€˜career adaptabilityâ€™, aspects of which involve being curious about new opportunities and being confident in oneâ€™s ability to learn new skills. People who score highly in this trait are generally â€˜happier. They perform better. They get promoted â€¦ Just a whole range of good things,â€™ says Rajiv Amarnani, a lecturer in the University of Western Australia Business School. That youâ€™re contemplating giving up your dream suggests that you have a healthy willingness to adjust and adapt, which is to your advantage.</p>
<p>If youâ€™re nonetheless finding it difficult to look beyond the immediate sense of loss or failure, know that there are routes ahead and that other opportunities will emerge. By having the wisdom and flexibility to know when to let go, or when to redirect your passion, youâ€™ll be following in the footsteps of many who have achieved greatness. David Foster Wallace let go of his tennis-greatness dreams and became an acclaimed novelist and writer instead. Meanwhile, Roger Federerâ€™s dreams of tennis greatness came true, but only at the expense of his dream of becoming a professional footballer. And Maryam Mirzakhani let go her childhood dream of becoming a novelist but went on to be awarded the Fields Medal for mathematics in 2014 â€“ the first and only woman ever to receive the honour.</p>
<p>These are dramatic examples, but they show that the path to fulfilment isnâ€™t always smooth or direct. Once youâ€™ve come to terms with your loss, youâ€™ll find other passions. New dreams await.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>Come to terms with your decision</strong></p>
<p>As you let your dream go, you might be agonising over whether youâ€™re making a mistake. â€˜Thereâ€™s no good answer, thereâ€™s no formulaâ€™ for deciding whether to plough on or give up, says Wrosch. However, he recommends bearing in mind a phenomenon known as â€˜goal shieldingâ€™ â€“ when weâ€™re highly focused on a particular dream or ambition, we tend to filter out inconvenient information that might imperil the project. â€˜Motivational psychologists call it an â€œimplemental mindsetâ€�,â€™ says Wrosch. â€˜If you cross the Rubicon, you focus on what you want to achieve, and you donâ€™t have that balance [in how you process the situation] any more.â€™ For that reason, he says most us are, if anything, probably more at risk of stubbornly pursuing a dream for too long than giving up too early.</p>
<p>The author and entrepreneur Seth Godin agrees with Wrosch â€“ â€˜thereâ€™s no calculusâ€™ for deciding when to give up, he says. He too warns that most of us â€˜lie to ourselves all the time about whether we have the resources to get through the dipâ€™. â€˜The dipâ€™ is Godinâ€™s term â€“ taken from his 2007 <a href="https://www.penguinrandomhouse.com/books/300938/the-dip-by-seth-godin/" rel="nofollow noreferrer noopener">book</a> of the same name, and subtitled <em>A Little Book That Teaches You When to Quit (and When to Stick)</em> â€“ that he says refers to the â€˜difficult space in between the joy of starting and the benefit of getting to the other sideâ€™.</p>
<p>One way to think about this emotionally difficult moment is as a chance to be objective about your dream. Was pursuing it coming at great personal cost, in terms of your relationships and other goals in life? If so, that would suggest it was what psychologists call an â€˜obsessive passionâ€™ and youâ€™re wise to give it up (as distinct from a â€˜harmonious passionâ€™ that fits well into the rest of your life).</p>
<p>Also, try to think, if you can, more like a â€˜healthy perfectionistâ€™: recognise that letting go of your goals doesnâ€™t cast some final verdict on you as a person, and acknowledge the influence of circumstances beyond your control. Remember too that success isnâ€™t all or nothing â€“ although you might not have fulfilled your dream in its entirety, you will likely have learned much along the way, and you now have the chance to redirect your energy and passion in new ways. This is also a good time to seek the counsel of close family and friends. Theyâ€™ll be able to help you view your situation objectively and come to terms with your decision.</p>
<p><strong>Be realistic about what you just gave up</strong></p>
<p>When you decide to let go of a dream, itâ€™s almost inevitable that itâ€™s going to hurt, at least for a time, but there are ways to ease the discomfort and move on. â€˜My approach to this is starting with the tragic realism of it, that itâ€™s going to be hard, itâ€™s going to hurt,â€™ says Amarnani, who likens the experience of giving up a dream to a romantic breakup. â€˜To have an ambition is to have this vision of your future self, and to drop that is to drop a piece of you,â€™ he says.</p>
<p>That parallel with relationships offers an effective clue for how to cope. In the context of romantic relationships, Amarnani says that it can be therapeutic to be realistic, rather than idealistic, about the person youâ€™re breaking from, even to focus deliberately on their flaws. If weâ€™re honest, many of our dreams are romanticised, and itâ€™s worth remembering that what youâ€™re giving up is not that fantasy version of the future. We think of doctors as healing people, says Amarnani, or that staff at the United Nations are building peace, but then their daily reality is often far more mundane â€“ doctors are navigating the bureaucracy of their healthcare system; workers at the UN are pushing paperwork around.</p>
<p>Amarnani speaks partly from personal experience. He once harboured a dream to become a computational cognitive neuroscientist, but he suffered repeated rejections and then the financial crisis hit. He changed gears to become a management scholar â€“ â€˜I thought I was selling my soul,â€™ he says, â€˜but really what I was doing was just adjusting to the situation, being adaptable and trusting that, when you try something new, the passion will come.â€™ To help make peace with his decision, Amarnani focused on the negatives of the field he gave up â€“â€˜Decades of research on the brain has taught us next to nothing about the mindâ€™ â€“ and today he couldnâ€™t be happier that he gave up his dream. â€˜I grieved, genuinely,â€™ he says, â€˜but life does go on.â€™</p>
<p><strong>Find a new passion</strong></p>
<p>Itâ€™s a clichÃ© to say that one door closing means another opening, but itâ€™s true. By letting go of an impossible dream, youâ€™re freeing yourself to put time and effort into a potentially more rewarding project. Itâ€™s tempting to look at a high achiever such as Godin and assume that he arrived at his …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion">https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-let-go-of-a-lifelong-dream-and-redirect-your-passion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25455014</guid>
            <pubDate>Thu, 17 Dec 2020 12:37:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[51% of 4M Docker images have critical vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 323 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25454207">thread link</a>) | @AnnieNma
<br/>
December 17, 2020 | https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454207</guid>
            <pubDate>Thu, 17 Dec 2020 10:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25453663">thread link</a>) | @ingve
<br/>
December 17, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453663</guid>
            <pubDate>Thu, 17 Dec 2020 08:13:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deep learning tool that repairs damaged/faded photos]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25453481">thread link</a>) | @panabee
<br/>
December 16, 2020 | https://hotpot.ai/restore-picture?s=hn | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBox">

			<div>
				<p><img src="https://hotpot.ai/images/site/transparent.gif">
				</p>
			</div>

			

			<p><span>Restore</span>
			</p>

		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			Enable "Has Scratches" to explicitly remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453481</guid>
            <pubDate>Thu, 17 Dec 2020 07:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Code-Generated Art]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25453252">thread link</a>) | @dzink
<br/>
December 16, 2020 | https://www.editorx.com/shaping-design/article/creative-coding | <a href="https://web.archive.org/web/*/https://www.editorx.com/shaping-design/article/creative-coding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><p id="viewer-foo"><span><span>Have you ever experienced true novelty? Something so mind-altering that it questions your definition of what you’ve known to be true for so long. I imagine the first people to watch a film or see an airplane felt this. It’s an inexplicable energy that has the power to redefine. In many ways, artists have been at the center of challenging commonly held beliefs, and using entirely new mediums to express speculative ideas. </span></span></p><p id="viewer-fa7pc"><span><span>While never the first thing to come to mind when discussing art, creative coding is revolutionizing what art is and can be. As we enter a more digital world, creative coding may be the contemporary art movement we need in order to articulate major societal challenges we are facing as technology advances. </span></span></p><p id="viewer-gar4"><span><span>Put simply, creative coding is an emerging specialty that utilizes code and programming as a medium to create art. Programming’s versatility and ubiquitous nature makes it especially expressive, allowing it to manifest itself as digital paintings, data visualization, or even robotics. </span></span></p><p id="viewer-aesrq"><span><span>Unlike the functional focus of most uses of code - like the code lines of a navigation app - creative coding uses programming languages for a solely artistic purpose.</span></span></p><p id="viewer-bg2ev"><span><span>As artists, we generally hold a stigma regarding coding having high barriers to entry, and as engineers, we also hold a stigma surrounding the difficulties of creative expression. However, these fields no longer need to be separate entities, as they are more closely tied than people expect. </span></span></p><p id="viewer-80qt3"><span>With programming resources being incredibly open-source and <a href="https://www.editorx.com/shaping-design/article/drawing-inspiration-for-designers" target="_blank" rel="noopener"><u>creative inspiration</u></a> democratized across the internet, getting into this field is as easy as watching some coding tutorials on Youtube and making a Pinterest board. </span></p><p id="viewer-2vgh3"><span>If you haven’t already, you can <a href="https://www.editorx.com/shaping-design/article/should-designers-code" target="_blank" rel="noopener"><u>learn to code</u></a> by picking up a coding language such as HTML, CSS, and JavaScript. There are many online resources available, such as:</span></p><ul><li id="viewer-27t6d"><p><a href="https://www.w3schools.com/" target="_blank" rel="noopener"><u>W3Schools</u></a></p></li><li id="viewer-5oukm"><p><a href="https://www.youtube.com/watch?v=2qDywOS7VAc" target="_blank" rel="noopener"><u>Youtube Tutorials</u></a></p></li><li id="viewer-4rsku"><p><a href="https://www.linkedin.com/learning/" target="_blank" rel="noopener"><u>LinkedIn Learning</u></a></p></li><li id="viewer-a6fsj"><p><a href="https://www.learnpython.org/" target="_blank" rel="noopener"><u>Learnpython.org</u></a></p></li><li id="viewer-8el3i"><p><a href="https://www.codecademy.com/?g_network=g&amp;g_device=c&amp;g_adid=459321005730&amp;g_keyword=codecademy&amp;g_acctid=243-039-7011&amp;g_adtype=search&amp;g_adgroupid=70946090375&amp;g_keywordid=kwd-41065460761&amp;g_campaign=US_Brand_Core_Exact_Net+New+%28Auto+Tagging%29&amp;g_campaignid=1955172604&amp;utm_id=t_kwd-41065460761:ag_70946090375:cp_1955172604:n_g:d_c&amp;utm_term=codecademy&amp;utm_campaign=US_Brand_Core_Exact_Net%20New%20(Auto%20Tagging)&amp;utm_source=google&amp;utm_medium=paid-search&amp;utm_content=459321005730&amp;hsa_acc=2430397011&amp;hsa_cam=1955172604&amp;hsa_grp=70946090375&amp;hsa_ad=459321005730&amp;hsa_src=g&amp;hsa_tgt=kwd-41065460761&amp;hsa_kw=codecademy&amp;hsa_mt=e&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gclid=CjwKCAiAzNj9BRBDEiwAPsL0d6bnyHp-tuJuJPB6ESAc8vQsGp2os6n9SvJ_fN73bAazebYH-FcctRoCuOMQAvD_BwE" target="_blank" rel="noopener"><u>The Code Academy</u></a> </p></li><li id="viewer-6638e"><p><a href="https://processing.org/" target="_blank" rel="noopener"><u>Processing</u></a></p></li></ul><p id="viewer-cbn64"><span>From there, finding inspiration can be as simple as reading the rest of this article or exploring dedicated art-technology spaces such as <a href="https://www.artechouse.com/" target="_blank" rel="noopener"><u>Artechouse</u></a>.</span></p><p id="viewer-erafq"><span>Here are some interesting fields within creative coding that you can experiment with once you get started:</span></p><ul><li id="viewer-ehb6t"><p><span><strong>Machine learning:</strong> The development of computer algorithms that automatically learn and improve their performance through experience and data.</span>


</p></li><li id="viewer-32vc4"><p><span><strong>Projection mapping:</strong> A technique to project video on irregularly shaped surfaces, such as sculptures or buildings. </span>


</p></li><li id="viewer-f009e"><p><span><strong>Generative design:</strong> An iterative design process in which a program, usually using algorithms, generates a certain number of outputs based on a set of constraints.</span>


</p></li><li id="viewer-5n77p"><p><span><strong>Live coding:</strong> A form of performance art in which coders program in real-time. It usually involves sound, image and light design.</span></p></li></ul><p id="viewer-ep6sm"><span><span>To get some ideas flowing and inspire your own creative coding pieces, here are some examples of how expansive, stunning, and novel creative coding can be.</span></span></p><ol><li id="viewer-eeo5c"><p><span>Audience by Random International</span></p></li><li id="viewer-fha9v"><p><span>New Nature Digital Petting Zoo by Marpi Studio</span></p></li><li id="viewer-a5o8e"><p><span>Everything in Existence by fuse*</span></p></li><li id="viewer-8gq1n"><p><span>Infinite Command Team by Casey Reas </span></p></li><li id="viewer-4eu7u"><p><span>Land Lines by Zach Lieberman </span></p></li><li id="viewer-3unh"><p><span>ALGOBABEZ by Shelly Knotts</span></p></li><li id="viewer-538vu"><p><span>XYZT: Abstract Landscapes by Adrien M &amp; Claire B</span></p></li><li id="viewer-b7vhn"><p><span>Tecnicontrol by Bradley G Munkowitz (GMUNK)</span></p></li><li id="viewer-bprm6"><p><span>PEmbroider created at Frank-Ratchye STUDIO for Creative Inquiry</span></p></li><li id="viewer-akhtn"><p><span>Learning to See by Memo Akten</span></p></li></ol><p id="viewer-bahbh"><span><span>Random International is a London-based experimental art studio that has been pioneering the creative coding space for well over a decade now. Their work touches on deep social themes and has been exhibited internationally in spaces like the MoMa. </span></span></p><p id="viewer-fduu8"><span><span><em>Audience</em>, one of their earlier pieces of work from 2008, uses motion tracking software and creative coding to create an almost uncomfortable, anthropomorphic experience. As a gallery visitor steps in front of rows of individually dancing mirrors, they instantly synchronize and lock onto the viewer. With 100 mirrors now looking right back at you, you then become the focal point of your own onlooking. </span></span></p><p id="viewer-8dmeo"><span><span>Created by Marpi Studio, New Nature is a digitally interactive petting zoo that relies on gesture-based technology and programming to create virtual organisms. </span></span></p><p id="viewer-65ego"><span><span>Through machine learning, Marpi has forged a virtual terrarium of creatures and plants that rely on the physical interactions of the viewers to come alive. As viewers engage with the digital creatures, the artwork responds with real-time computer-generated motions, simulating the movement of an organic creature being pet. </span></span></p><p id="viewer-60ee9"><span><span><em>Everything in Existence</em> questions our perceptions of reality. Using real-time data processing tools and algorithmic software, fuse* creates a living piece of art that constantly evolves and adapts depending on its interactions with onlookers. </span></span></p><p id="viewer-bna5m"><span><span>The artworks are constantly generating new visuals in response to the viewers, their social networks, sound and more. This solo exhibition by fuse*, which premiered in Washington DC in 2019, creates digitally interactive experiences independently of an artist. Its self-sufficient and generative nature suggests an entirely new form of artistic expression.</span></span></p><p id="viewer-274p6"><span><span>Casey Reas’ <em>Infinite Command Team</em> investigates the relationship between particles that are encoded to construct images, and the code that forges those particles. </span></span></p><p id="viewer-c3cum"><span><span>Using pixelation of different weights and sizes, the piece creates a digital mosaic of television signals that become abstract and collage-like, reminiscent of TV channel-surfing. The piece is a celebration of art and technology that showcases the potential of combining digital fragments into a holistic piece of work. </span></span></p><p id="viewer-fhi88"><span><span>One of the most exciting aspects of creative coding is that it’s so readily available. Regardless of where you go in the world, there will always be code present guiding new innovations or digital platforms. </span></span></p><p id="viewer-8344v"><span><span>Creative coder Zach Lieberman takes advantage of how constantly present code is in our lives by using Google Maps to create art. In his proj</span>ect <a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><em><u>Land Lines</u></em></a>, Lieberm<span>an uses machine learning, optimized algorithms, and card power to harness images from Google Maps and match them with viewers’ drawings. </span></span></p><p id="viewer-ab3mh"><span><span>Lieberman asks his viewers to draw shapes and lines on the screen, which in turn are converted into real spaces on earth that resemble the line they drew. </span></span></p><div id="viewer-6292q"><a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="Land Lines by Zach Lieberman website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_1000%2Ch_715%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Land Lines by Zach Lieberman website screenshot"></p></div></div></a></div><p id="viewer-8vtqk"><span><span>Shelly Knotts takes creative coding to an entirely new plane in her live-coding pop band, ALGOBABEZ. Based in the UK, Shelly collaborates with other musicians and programmers in her pseudo-improvised live-coded music performances. Her coded music has been played to international audiences and explores themes of data, music, networks, and code.</span></span></p><p id="viewer-5b9e7"><span><span>Created by the company Adrien M &amp; Claire B, <em>XYZT</em> explores the intersection of mathematics and imaginary landscapes. </span></span></p><p id="viewer-bstnp"><span><span>Leveraging technology, programming, and lighting design, <em>XYZT</em> allows visitors to explore the four primary planes of existence: horizontal (the X axis), vertical (Y), depth (Z), and time (T). The exhibit allows for unparalleled interactivity across each of the planes, responding to visitors’ motion and creating new visuals in real time. </span></span></p><p id="viewer-3jqso"><span><span>In his creative coding work <em>Technicontrol</em>, Bradley Munkowitz, also known as GMUNK in the art community, investigates the ways in which robotics, code and screen content can result in a choreographed piece of work. </span></span></p><p id="viewer-b6arv"><span><span>Rather than using typical projection-mapped canvases, he pushed for LED-screen-wielding robots and a motion-controlled camera. The end result is a whimsical, technology-driven video piece with a truly marvelous storyline tracing the steps of a television abduction.</span></span></p><p id="viewer-178s8"><span><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><em><u>PEmbroider</u></em></a> is a<span>n open-source computational embroidery library. The goal of the creative coding library is to empower artists and craftspeople to make generative embroidery work for free. </span></span></p><p id="viewer-2ua6k"><span><span>Usually, tools such as this would be costly, and oftentimes are inaccessible to most artists or hobbyists. By creating an open-source repository, PEmbroider allows anyone to forge new, generative embroidery work through code. </span></span></p><div id="viewer-ecl5u"><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="PEmbroider creative coding website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_1000%2Ch_661%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="PEmbroider creative coding website screenshot"></p></div></div></a></div><p id="viewer-18rug"><span><span>Memo Akten is an artist and researcher who examines the nature of vision and perception through computational creativity and artificial intelligence. In his series of works, <em>Learning To See</em>, Akten has developed an artificial neural network to view and make sense of the world around us. </span></span></p><p id="viewer-bnqsf"><span><span>By comparing everyday objects with their interpretations through the eyes of neural networks, Memo Akten is able to digitally emulate the way we humans observe the world and make sense of objects.</span></span></p><p id="viewer-1q52f"><span><span>As he states, “it can only see through the filter of what it already knows. Just like us. Because we too, see things not as they are, but as we are.”</span></span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.editorx.com/shaping-design/article/creative-coding</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453252</guid>
            <pubDate>Thu, 17 Dec 2020 06:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React's UseRef Deep Dive]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25452146">thread link</a>) | @giovannibenussi
<br/>
December 16, 2020 | https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1 | <a href="https://web.archive.org/web/*/https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article"><header></header><p><code>useRef</code> allows you to keep a mutable value within a component, similar to <code>useState</code> or instance variables on a class, without triggering re-renders.</p><p>For example, this component stores the number of clicks for a button:</p><div data-language="jsx"><pre><code><span>function</span> <span>RefButton</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> clicks <span>=</span> <span>useRef</span><span>(</span><span>0</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks<span>.</span>current <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>.</span>current<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>This is how this component looks like (I added a re-render button so you can
actually test it out 😄):</p><div><h2>Interactive Example</h2><p>The example below is completely interactive, try clicking the "Clicks" button and then click on "Re-render".</p></div><p>As you can see, if you click the "Clicks" button it doesn't do anything. However, after click on "Re-render", it gets updated with the number of clicks we did previously.</p><h2>Difference with a variable</h2><p>You might wonder why not just use a simple variable as the example below:</p><div data-language="jsx"><pre><code><span>let</span> clicks <span>=</span> <span>0</span><span>;</span>

<span>function</span> <span>OutsideVariableButton</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>And here's an interactive example for it:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span></p></div><p>The button works the same way that our previous example. However, the problem arises when you have multiple instances of the same component like the example below. Try clicking just one of the buttons and then click on re-render to see the result.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span><span>outside variable</span><span>outside variable</span></p></div><p>As you were able to see, the clicks are not isolated. In fact, all the examples
from this article uses the same button component, so if you click the button
from the first example and then click on "re-render" on the second example, the count it is gonna be
incremented! What a bug 🐛.</p><p>On the other hand, <code>useRef</code> values are completely isolated between components:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>ref</span><span>ref</span><span>ref</span></p></div><h2>Difference with&nbsp;useState</h2><blockquote><p>The main difference between useState and useRef, is that useState triggers a
re-render and useRef doesn't.</p></blockquote><p>In the following example I added two buttons: one that updates its count with <code>useRef</code> and the other one with <code>useState</code>. I added some labels so you can identify them easily.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>state</span><span>ref</span></p></div><p>You'll notice that clicking on the button with <code>useRef</code> doesn't trigger a re-render and thus, the view isn't updated. On the other side, when you click on the button that uses <code>useState</code>, it will update its clicks count immediately.</p><p>To perform imperative actions on DOM nodes, React provides a way to get a
reference to them via refs. All you have to do is to assign a <code>ref</code> property to
a node with a ref object like this:</p><div data-language="jsx"><pre><code><span>function</span> <span>CustomInput</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>The way to get a DOM reference using refs works (informally 😅) as follows:</p><div><p><span>Today</span></p><div><p>React</p><p>Hey, what's up?<span>12:00</span></p></div><div><p>Could you give me a reference to this dom node?<span>12:00<svg style="color:#34B7F1" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><svg style="color:#34B7F1;margin-left:-12px" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg></span></p></div><div><p>React</p><p>Sure, I assigned it to the 'current' property of your ref.<span>12:00</span></p></div></div><p>On the first render, <code>inputRef</code>'s value will be <code>{ current: null }</code> and in the
following renders it will have its <code>current</code> property assigned to the specified DOM
node:</p><p>However, if you only reference <code>inputRef</code> inside <code>useEffect</code> then it'll always
reference the DOM node so you don't need to worry about it being undefined.</p><p>Let's update our example to get an idea of how this works:</p><div data-language="jsx"><pre><code><span>function</span> <span>AttachingToDomExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  console<span>.</span><span>log</span><span>(</span><span>"Render inputRef value:"</span><span>,</span> inputRef<span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"useEffect inputRef value:"</span><span>,</span> inputRef<span>)</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>Here's the console output when rendering this component:</p><table><thead><tr><th>Render</th><th>Location</th><th>Value</th></tr></thead><tbody><tr><td>1</td><td>Render</td><td>{ current: undefined }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>2</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>3</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr></tbody></table><p>As you can see, if you access the <code>inputRef</code> inside <code>useEffect</code> then you don't
need to worry about it being <code>undefined</code> because React will assign it
automatically for you.</p><p>Let's start with a simple real-world application for refs: <code>usePrevious</code>. This
hook stores the previous value for a given state variable.
<a href="https://reactjs.org/docs/hooks-faq.html#how-to-get-the-previous-props-or-state" target="_blank" rel="nofollow">It is even referenced on React's docs</a> as a way to "get the previous props or state". Let's see it in
action first:</p><div data-language="jsx"><pre><code><span>function</span> <span>UsePreviousExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>clicks<span>,</span> setClicks<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span>
  
  <span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span>clicks<span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setClicks</span><span>(</span>clicks <span>+</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
        Clicks: </span><span>{</span>clicks<span>}</span><span> - Before: </span><span>{</span>previousClicks<span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>Here's the output so you can play with it:</p><p>You can notice that the <code>previousClicks</code> variable stores the value for the previous render
for a given variable. Here's its implementation:</p><div data-language="jsx"><pre><code><span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    ref<span>.</span>current <span>=</span> value
  <span>}</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>Let's analyze how it works.</p><p>Let's simulate what happens on the first render. We can remove the call to
<code>useEffect</code> since it doesn't affect the return value on the first render:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>On the first render it is called with a value of <code>0</code>:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>0</span><span>)</span></code></pre></div><p>In this case, <code>usePrevious</code> will return <code>undefined</code>:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>After increase the value for count, here's how the <code>usePrevious</code> call will look:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>1</span><span>)</span></code></pre></div><p>Since <code>usePrevious</code> is called again, its effect needs to run:</p><div data-language="jsx"><pre><code><span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  ref<span>.</span>current <span>=</span> <span>0</span>
<span>}</span><span>)</span></code></pre></div><p>After this, the <code>usePrevious</code> function is called again:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>And so on. Here's the value for each render for both variables:</p><table><thead><tr><th>Render</th><th>clicks</th><th>previousClicks</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>undefined</td></tr><tr><td>2</td><td>1</td><td>0</td></tr><tr><td>3</td><td>2</td><td>1</td></tr><tr><td>4</td><td>3</td><td>2</td></tr></tbody></table><p>Callback Refs are a different way to set refs. It gives you a fine-grain control
over when refs are attached and detached because you provide a function instead
of a ref variable. This function gets called every time the component mounts and
unmounts.</p><p><a href="https://codesandbox.io/s/callback-ref-example-lqe8w?file=/src/App.js" target="_blank" rel="nofollow">Here's an example</a> that shows/hides an emoji every time you click its button.
The important thing here is the <code>ref</code> prop that we added. We use a function to log
the provided ref:</p><div data-language="jsx"><pre><code><span>const</span> <span>callback</span> <span>=</span> <span>(</span><span>ref</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"callback:"</span><span>,</span> ref<span>)</span>

<span>function</span> <span>App</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>show<span>,</span> setShow<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setShow</span><span>(</span><span>!</span>show<span>)</span><span>}</span></span><span>&gt;</span></span><span>
        </span><span>{</span>show <span>?</span> <span>"Hide"</span> <span>:</span> <span>"Show"</span><span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span>{</span>show <span>&amp;&amp;</span> <span><span><span>&lt;</span>span</span> <span>ref</span><span><span>=</span><span>{</span>callback<span>}</span></span><span>&gt;</span></span><span>👋</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div><p>Here's an interactive version of the previous code (you can check the output in
the console to see that I'm not lying 🙃):</p><p><em>Note: If you use callback refs as inline functions, it will be called
twice: one with <code>null</code> and another one with the DOM element.
This is because React needs to clear the previous ref every time the function is
created. A workaround for this is to use a class method.</em></p><div><h2>Warning</h2><p><a href="https://reactjs.org/docs/refs-and-the-dom.html#legacy-api-string-refs" target="_blank" rel="nofollow">String refs</a> are a legacy feature and they are likely to be removed in future React versions.</p></div><p>The way it works is that you provide a string as a ref value like <code>ref="exampleRef"</code> and it automatically gets assigned to <code>this.refs</code>.</p><p><em>Note: String refs can only be used with class components.</em></p><p>Here's an usage example:</p><div data-language="jsx"><pre><code><span>export</span> <span>default</span> <span>class</span> <span>App</span> <span>extends</span> <span>React<span>.</span>Component</span> <span>{</span>
  <span>render</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>this</span><span>.</span>refs<span>)</span><span>;</span>

    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span> <span>ref</span><span><span>=</span><span>"</span>exampleRef<span>"</span></span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span> dummy<span>:</span> <span>0</span> <span>}</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>Re-render</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Here's the value for <code>this.refs</code> across renders:</p><table><thead><tr><th>Render</th><th>this.refs</th></tr></thead><tbody><tr><td>1</td><td><code>{}</code></td></tr><tr><td>2</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>3</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>4</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr></tbody></table><p>As you can see, on the first render <code>this.refs.exampleRef</code> will be undefined and
on the following renders it will point out to the specified DOM node.</p><p>We saw what <code>useRef</code> is, how it differentiates with a plain old variable and
state variables, and we saw real world examples that uses it. I hope that most
of the content makes sense to you!</p><p>I'd love to hear your feedback. You can <a href="https://twitter.com/giovannibenussi" target="_blank" rel="nofollow">reach out to me on
Twitter</a> at any time :-)</p><hr></article></div></div>]]>
            </description>
            <link>https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25452146</guid>
            <pubDate>Thu, 17 Dec 2020 03:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passing of a Great Mind (1957)]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25451727">thread link</a>) | @unclefuzzy
<br/>
December 16, 2020 | https://qualiacomputing.com/2018/06/21/john-von-neumann/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/06/21/john-von-neumann/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2>Passing of a Great Mind</h2>
<h3>John von Neumann, a Brilliant, Jovial Mathematician, was a Prodigious Servant of Science and his Country</h3>
<p><em>by Clary Blair Jr</em>. –&nbsp;<em>Life Magazine</em>&nbsp;(February 25th, 1957)</p>
<p>The world lost one of its greatest scientists when Professor John von Neumann, 54, died this month of cancer in Washington, D.C. His death, like his life’s work, passed almost unnoticed by the public. But scientists throughout the free world regarded it as a tragic loss. They knew that Von Neumann’s brilliant mind had not only advanced his own special field, pure mathematics, but had also helped put the West in an immeasurably stronger position in the nuclear arms race. Before he was 30 he had established himself as one of the world’s foremost mathematicians. In World War II he was the principal discoverer of the implosion method, the secret of the atomic bomb.</p>
<p>The government officials and scientists who attended the requiem mass at the Walter Reed Hospital chapel last week were there not merely in recognition of his vast contributions to science, but also to pay personal tribute to a warm and delightful personality and a selfless servant of his country.</p>
<p>For more than a year Von Neumann had known he was going to die. But until the illness was far advanced he continued to devote himself to serving the government as a member of the Atomic Energy Commission, to which he was appointed in 1954. A telephone by his bed connected directly with his EAC office. On several occasions he was taken downtown in a limousine to attend commission meetings in a wheelchair. At Walter Reed, where he was moved early last spring, an Air Force officer, Lieut. Colonel Vincent Ford, worked full time assisting him. Eight airmen, all cleared for top secret material, were assigned to help on a 24-hour basis. His work for the Air Force and other government departments continued. Cabinet members and military officials continually came for his advice, and on one occasion Secretary of Defence Charles Wilson, Air Force Secretary Donald Quarles and most of the top Air Force brass gathered in Von Neumann’s suite to consult his judgement while there was still time. So relentlessly did Von Neumann pursue his official duties that he risked neglecting the treatise which was to form the capstone of his work on the scientific specialty, computing machines, to which he had devoted many recent years.</p>
<p><img data-attachment-id="26616" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_1_1/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1316%2C920&amp;ssl=1" data-orig-size="1316,920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_1_1" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1000%2C699&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;ssl=1" alt="von_neumann_1_1" width="1000" height="699" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>His fellow scientists, however, did not need any further evidence of Von Neumann’s rank as a scientist – or his assured place in history. They knew that during World War II at Los Alamos Von Neumann’s development of the idea of implosion speeded up the making of the atomic bomb by at least a full year. His later work with electronic computers quickened U.S. development of the H-bomb by months. The chief designer of the H-bomb, Edward Teller, once said with wry humor that Von Neumann was “one of those rare mathematicians who could descend to the level of the physicist.” Many theoretical physicists admit that they learned more from Von Neumann in methods of scientific thinking than from any of their colleagues. Hans Bethe, who was director of the theoretical physics division at Los Alamos, says, “I have sometimes wondered whether a brain like Von Neumann’s does not indicate a species superior to that of man.”</p>
<p><img data-attachment-id="26617" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_2/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" data-orig-size="226,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_2" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=223%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;ssl=1" alt="von_neumann_2" width="226" height="304" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The foremost authority on computing machines in the U.S., Von Neumann was more than anyone else responsible for the increased use of the electronic “brains” in government and industry. The machine he called MANIAC (mathematical analyzer, numerical integrator and computer), which he built at the Institute for Advanced Study in Princeton, N.J., was the prototype for most of the advanced calculating machines now in use. Another machine, NORC, which he built for the Navy, can deliver a full day’s weather prediction in a few minutes. The principal adviser to the U.S. Air Force on nuclear weapons, Von Neumann was the most influential scientific force behind the U.S. decision to embark on accelerated production of intercontinental ballistic missiles. His “theory of games,” outlined in a book which he published in 1944 in collaboration with Economist Oskar Morgenstern, opened up an entirely new branch of mathematics. Analyzing the mathematical probabilities behind games of chance, Von Neumann went on to formulate a mathematical approach to such widespread fields as economics, sociology and even military strategy. His contributions to the quantum theory, the theory which explains the emission and absorption of energy in atoms and the one on which all atomic and nuclear physics are based, were set forth in a work entitled <em>Mathematical Foundations of Quantum Mechanics</em>&nbsp;which he wrote at the age of 23. It is today one of the cornerstones of this highly specialized branch of mathematical thought.</p>
<p>For Von Neumann the road to success was a many-laned highway with little traffic and no speed limit. He was born in 1903 in Budapest and was of the same generation of <a href="http://slatestarcodex.com/2017/05/26/the-atomic-bomb-considered-as-hungarian-high-school-science-fair-project/">Hungarian physicists</a> as Edward Teller, Leo Szilard and Eugene Wigner, all of whom later worked on atomic energy development for the U.S.</p>
<p>The eldest of three sons of a well-to-do Jewish financier who had been decorated by the Emperor Franz Josef, John von Neumann grew up in a society which placed a premium on intellectual achievement. At the age of 6 he was able to divide two eight-digit numbers in his head. By the age of 8 he had mastered college calculus and as a trick could memorize on sight a column in a telephone book and repeat back the names, addresses and numbers. History was only a “hobby,” but by the outbreak of World War I, when he was 10, his photographic mind had absorbed most of the contents of the 46-volume works edited by the German historian Oncken with a sophistication that startled his elders.</p>
<p>Despite his obvious technical ability, as a young man Von Neumann wanted to follow his father’s financial career, but he was soon dissuaded. Under a kind of supertutor, a first-rank mathematician at the University of Budapest named Leopold Fejer, Von Neumann was steered into the academic world. At 21 he received two degrees – one in chemical engineering at Zurich and a PhD in mathematics from the University of Budapest. The following year, 1926, as Admiral Horthy’s rightist regime had been repressing Hungarian Jews, he moved to Göttingen, Germany, then the mathematical center of the world. It was there that he published his major work on quantum mechanics.</p>
<h4>The young professor</h4>
<p>His fame now spreading, Von Neumann at 23 qualified as a <em>Privatdozent</em>&nbsp;(lecturer) at the University of Berlin, one of the youngest in the school’s history. But the Nazis had already begun their march to power. In 1929 Von Neumann accepted a visiting lectureship at Princeton University and in 1930, at the age of 26, he took a job there as professor of mathematical physics – after a quick trip to Budapest to marry a vivacious 18-year-old named Mariette Kovesi. Three years later, when the Institute for Advanced Study was founded at Princeton, Von Neumann was appointed – as was Albert Einstein – to be one of its first full professors. “He was so young,” a member of the institute recalls, “that most people who saw him in the halls mistook him for a graduate student.”</p>
<p><img data-attachment-id="26618" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_3/" data-orig-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1210%2C1028&amp;ssl=1" data-orig-size="1210,1028" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_3" data-image-description="" data-medium-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=300%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1000%2C850&amp;ssl=1" loading="lazy" src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;ssl=1" alt="von_neumann_3" width="1000" height="850" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Although they worked near each other in the same building, Einstein and Von Neumann were not intimate, and because their approach to scientific matters was different they never formally collaborated. A member of the institute who worked side by side with both men in the early days recalls, “Einstein’s mind was slow and contemplative. He would think about something for years. Johnny’s mind was just the opposite. It was lightning quick – stunningly fast. If you gave him a problem he either solved it right away or not at all. If he had to think about it a long time and it bored him, hist interest would begin to wander. And Johnny’s mind would not shine unless whatever he was working on had his undivided attention.” But the problems he did care about, such as his “theory of games,” absorbed him for much longer periods.</p>
<h4>‘Proof by erasure’</h4>
<p>Partly because of this quicksilver quality Von Neumann was not an outstanding teacher to many of his students. But for the advanced students who could ascend to his level he was inspirational. His lectures were brilliant, although at times difficult to follow because of his way of erasing and rewriting dozens of formulae on the blackboard. In explaining mathematical problems Von Neumann would write his equations hurriedly, starting at the top of the blackboard and working down. When he reached the bottom, if the problem was unfinished, he would erase the top equations and start down again. By the time he had done this two or three times most other mathematicians would find themselves unable to keep track. On one such occasion a colleague at Princeton waited until Von Neumann had finished and said, “I see. Proof by erasure.”</p>
<p>Von Neumann himself was perpetually interested in many fields unrelated to science. Several years ago his wife gave him a 21-volume Cambridge History set, and she is sure he memorized every name and fact in the books. “He is a major expert on all the royal family trees in Europe,” a friend said once. “He can tell you who fell in love with whom, and why, what obscure cousin this or that czar married, how many illegitimate children he had and so on.” One night during the Princeton days a world-famous expert on Byzantine history came to the Von Neumann house for a party. “Johnny and the professor got into a corner and began discussing some obscure facet,” recalls a friend who was there. “Then an argument arose over a date. Johnny insisted it was this, the professor that. So Johnny said, ‘Let’s get the book.’ They looked it up and Johnny was right. A few weeks later the professor was invited to the Von Neumann house again. He called Mrs. von Neumann and said jokingly, ‘I’ll come if Johnny promises not to discuss Byzantine history. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qualiacomputing.com/2018/06/21/john-von-neumann/">https://qualiacomputing.com/2018/06/21/john-von-neumann/</a></em></p>]]>
            </description>
            <link>https://qualiacomputing.com/2018/06/21/john-von-neumann/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451727</guid>
            <pubDate>Thu, 17 Dec 2020 02:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sequoia PGP 1.0 Released: The Seedling Is a Sapling]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25448533">thread link</a>) | @dannyobrien
<br/>
December 16, 2020 | https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/ | <a href="https://web.archive.org/web/*/https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
                          <p>Version 1.0.  It’s here.  After three and a half years of development,
we are happy to announce the release of version 1.0 of Sequoia!</p>
<p>The release includes the low-level crate <a href="https://crates.io/crates/sequoia-openpgp"><code>sequoia-openpgp</code></a>, and a
program to verify detached signatures geared towards software
distribution systems called <a href="https://crates.io/crates/sequoia-sqv"><code>sqv</code></a>.</p>
<p>We will support this API with security updates for at least one year.
In 9 months, we will announce whether we will extend this commitment.
The two main criteria will be our financial situation (please
<a href="https://pep.foundation/support-pep/index.html">donate</a>, or sponsor a developer or two), and the number of users.</p>

<p>We actually <a href="https://mastodon.social/@sequoiapgp/103364362621954545">almost released</a> version 1.0 about a year ago.  All of the
features that we had planned for version 1.0 were implemented, we had
good test coverage, and we even had a few users.  But, we decided to
wait.  We decided to wait not because we thought of another feature,
or because we became aware of a significant bug, but because <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/465">we</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/466">decided</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/467">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/468">take</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/469">some</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/470">time</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/471">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/472">improve</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/473">our</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/474">documentation</a>.</p>
<p>Our goal was to make sure that every module had a helpful
introduction, and all public methods had a useful description, a link
to <a href="https://tools.ietf.org/html/rfc4880">the standard</a>, when appropriate, and a meaningful example.
Dividing the task between five people, we figured it would delay the
release by a month, perhaps two.  In the end, well, it took nearly a
year, and we had to scale our ambitions back a bit.  Nevertheless,
we’re quite happy with <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/index.html">the</a> <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html">result</a>.</p>
<p>First, the documentation is much better.  It’s of course hard to
quantify its quality.  But, we can distill a few numbers.  When we
started our documentation effort shortly after we released version
0.14, the Sequoia library had just over 11k lines of comments
including 53 documentation tests, and 37 kSLOC including 12 kSLOC of
unit tests.  The 1.0 release has over 33k lines of comments (190%
more) including 464 documentation tests (780% more), and 44 kSLOC (21%
or 7.5 kSLOC more) including 8k SLOC of additional unit tests.</p>
<p>Second, in the process of documenting our public API and writing
examples, we discovered many minor annoyances, some inconsistencies,
and more than a few bugs.  Since we hadn’t yet commited to a stable
API, we could and did fix them.</p>
<p>Finally, as the rate of change of the API had decreased, more projects
were willing to try out Sequoia.  They provided additional useful
feedback, which we integrated.</p>
<p>All in all, we feel that with version 1.0 we’ve not only checked the
<a href="https://www.tomsguide.com/news/cyberpunk-2077-is-a-disaster-on-ps4-and-xbox-one-and-it-gets-worse">right boxes</a>, but we also have a high-quality API and implementation
that we can be proud of.</p>

<p>Sequoia was started 3.5 years ago by Justus Winter, Kai Michaelis and
me, Neal Walfield.  Prior to working on Sequoia, the three of us had
worked together at <a href="http://www.g10code.de/">g10code</a> on <a href="https://gnupg.org/">GnuPG</a>.  The <a href="https://pep.foundation/">p≡p foundation</a> hired
us not only to create a new OpenPGP implementation using a new
architecture and programming language, but to improve the ecosystem
around privacy-preserving tools as a whole.</p>
<p>The Sequoia library is a first step in that direction.  But it is not
our end goal.  Indeed, over the past three years, we’ve helped other
OpenPGP implementations.  We’ve reported bugs that we’ve found (thanks
in particular to our <a href="https://tests.sequoia-pgp.org/">OpenPGP interoperability test suite</a>), and even
contributed some fixes to other OpenPGP implementations.</p>
<p>And, we’ve invested in tooling.  We developed <a href="https://gitlab.com/hagrid-keyserver/hagrid">Hagrid</a>, a new
verifying OpenPGP key server, which powers <a href="https://keys.openpgp.org/">keys.openpgp.org</a> and is
now maintained by Vincent Breitmoser.  We’ve helped <a href="https://openpgp-ca.gitlab.io/openpgp-ca/">OpenPGP CA</a>, a
tool written by Heiko Schaefer to create <em>federated</em> CAs for groups
like activists, lawyers, and journalists, but also companies, who
don’t want to trust centralized infrastructure whose primary
incentives are monetary.  OpenPGP CA significantly simplifies key
discovery and authentication for unsophisticated OpenPGP users.  We’ve
developed <a href="https://gitlab.com/koverto/koverto">Koverto</a>, an SMTP proxy, which makes it easy to sign and
encrypt mails sent by services that don’t support OpenPGP out of the
box, like most CMSes.  We developed a tool, <a href="https://gitlab.com/sequoia-pgp/keyring-linter"><code>sq-keyring-linter</code></a>
(<a href="https://packages.debian.org/sid/sq-keyring-linter">Debian</a>), to help users update their OpenPGP Certificates, so that
we can <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">finally get rid of SHA-1</a>.</p>
<p>We’re thinking big.  We’re thinking not only about mail encryption or
even encryption in general, but also about integrity and
authentication.  And, we’re thinking in particular, about <a href="https://en.wikipedia.org/wiki/Public_key_infrastructure">PKI</a>.  If
users can’t easily find the <strong>right</strong> certificate for a communication
partner, encryption and digital signatures are worthless, and possibly
even dangerous.</p>

<p>In designing Sequoia, we took a library-first approach.  Although we
have a command-line tool, <a href="https://docs.sequoia-pgp.org/sq/index.html"><code>sq</code></a>, which we are not yet releasing, we
intend for the library to always provide a richer, more expressive
interface.  We agree that there is value in process separation, but we
want to avoid the dangerous complexity of <em>safely</em> shelling out to
another program.</p>
<p>The sequoia-openpgp crate (Rust’s terminology for a library) is a
low-level, policy-free OpenPGP implementation.  Our goal was to
implement all of <a href="https://tools.ietf.org/html/rfc4880">RFC 4880</a>, and provide an API that can be used to
access and modify pretty much everything, but is simultaneously secure
by default.</p>
<p>We understand low-level to mean not only an API that provides getters
and setters, but an API that provides interfaces to parse and
serialize those fields, and can combine them in ways intended by the
standard, and needed by users.  For instance, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> data
structure encapsulates an OpenPGP certificate (casually referred to as
an OpenPGP key).  It canonicalizes the structure, and makes it easy to
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html#method.revocation_status">query its properties</a>.  But, it does so in such a way that it is
still possible for a user to inspect and modify the low-level bits
themselves without reimplementing the rest of the functionality.
Another example is the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>, which makes it easy to
parse and decrypt an OpenPGP message.</p>
<p>An example of how we make the API safe by default is that it is hard
to accidentally export secret key material.  In Sequoia, you have to
explicitly <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html#secret-keys">opt-in to export it</a>.  Similarly, when <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/packet/signature/struct.SignatureBuilder.html">updating a
signature</a>, the creation time, hash algorithm, and issuer are
automatically updated.  This is usually what the user wants, but is
easy to forget, and hard to debug when forgotten.  Critically, it is
easy to opt out when that behavior is not desired.</p>
<p>While developing Sequoia, we spent a lot of time thinking about
extremes and corner cases.  For instance, OpenPGP supports
notarizations (signatures over signatures), but as far as we know no
OpenPGP implementation supports them.  We implemented support for it
anyway, and it improved the ergonomics of the common case.</p>
<h2 id="notable-details">Notable Details</h2>
<p>The devel is in the details.  And while deviloping Sequoia, we paid
attention.  Here are a few noteworthy details:</p>
<p><a href="https://en.wikipedia.org/wiki/SHA-1">SHA-1</a> has been broken since 2005.  And, in 2011 NIST deprecated its
use.  Initially, we decided to simply reject any signature that used
SHA-1.  However, we were recently forced to <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">reevaluate</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/595">that
decision</a>: 22% of Debian developers use a certificate that relies on
SHA-1 as do 63% of Arch developers.  Even the Fedora release keys use
SHA-1.</p>
<p>We decided that we couldn’t simply reenable SHA-1.  After some
consideration, we’ve opted to <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/enum.HashAlgoSecurity.html">permit it</a> in contexts where collision
attacks similar to the one presented in <a href="https://sha-mbles.github.io/">SHA-1 is a Shambles</a> are
harder.  We also use a variant of SHA-1 called <a href="https://gitlab.com/sequoia-pgp/sha1collisiondetection">SHA1CD</a> (SHA-1
Collision Detection), which detects and neutralizes the known attacks
against SHA-1.  Among others, <a href="https://github.blog/2017-03-20-sha-1-collision-detection-on-github-com/">GitHub uses it</a>.  And, we have also
decided to <strong><a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/struct.StandardPolicy.html#method.reject_hash_at">start rejecting SHA-1 by default</a> at the beginning of
2023</strong>, i.e., in a bit more than two years.  This will hopefully give
Debian developers and others sufficient time to <a href="https://gitlab.com/sequoia-pgp/keyring-linter">fix</a> or replace their
certificates.</p>
<p>When we create a signature, we include a <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/597">salt</a>.  This makes it harder
for an attacker to predict what data a user will sign.  And, it foils
attacks where an attacker needs multiple signatures over the same
message.</p>
<p>Similar to <a href="https://www.undeadly.org/cgi?action=article;sid=20190621081455">OpenSSH</a>, we <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/mem/struct.Encrypted.html">encrypt secret key material</a> while it is in
memory.  This frustrates side-channel attacks.</p>
<p>Sequoia supports <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/serialize/stream/padding/index.html">padding messages</a> to obfuscate an encrypted
message’s length.  We include support for the <a href="https://bford.info/pub/sec/purb.pdf">padmé</a> scheme, but
other schemes can be plugged in.</p>
<p>To allow users to control the policy while still using higher-level
functionality, Sequoia uses a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/index.html">policy object</a>.  A policy object is
passed to any method that checks something for validity.  For
instance, when a method needs to determine whether a binding signature
should be used, it invokes the policy object’s <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/trait.Policy.html#method.signature"><code>signature</code> callback</a>.
Our experience suggests that this approach greatly simplifies dealing
with this <a href="https://en.wikipedia.org/wiki/Cross-cutting_concern">cross-cutting concern</a> in a highly flexible manner.</p>
<p>Policy objects can also be embedded in other objects.  For instance, a
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html"><code>ValidCert</code></a> encapsulates a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> and a policy object.  This
ensures that the application of the policy is consistent, and hard to
forget to apply.</p>
<p>In Sequoia, we prefer the use of formal grammars rather than ad-hoc
parsing when doing any non-trivial parsing.  For instance, when
verifying the structure of <a href="https://tools.ietf.org/html/rfc4880#section-11.1">OpenPGP Certificates</a> and <a href="https://tools.ietf.org/html/rfc4880#section-11.3">OpenPGP
Messages</a>, we use <a href="https://github.com/lalrpop/lalrpop">LALRPOP</a>, a parser generator, to generate the
parser.</p>
<p>Sequoia implements a streaming API.  If not careful, this can lead to
a consumer processing unauthenticated data, which was exploited by
<a href="https://efail.de/">EFAIL</a>.  To mitigate this type of failure, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>
withholds the last <code>O(1)</code> bytes of data, and only releases it if the
message can be authenticated.  This makes it harder for an attacker to
control what is released.  And for short messages, nothing is released
since the whole message is buffered.</p>
<p>We’ve tried to ensure that data structures that may be used in a
side-channel sensitive context use constant time comparisons.</p>
<p>Where possible, we use a device driver-style API so that it is
straightforward to add new backends.  For instance, our <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/trait.Signer.html"><code>Signer</code></a> and
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/struct.Decryptor.html"><code>Decryptor</code></a> traits make it easy to implement alternative signing and
decryption backends.  In addition to the in-memory implementations, we
already have implementations that use secret key material managed by
<a href="https://docs.sequoia-pgp.org/sequoia_ipc/gnupg/struct.KeyPair.html">gpg agent</a>.</p>
<p>We tried hard to provide helpful error messages.  This is particularly
difficult …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</a></em></p>]]>
            </description>
            <link>https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448533</guid>
            <pubDate>Wed, 16 Dec 2020 20:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Old New Adventure]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25448248">thread link</a>) | @Ygg2
<br/>
December 16, 2020 | https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>After two and a half years of being independent, I am returning to Google.</p>

<p>The time off was really valuable. I was still feeling residual effects from burnout on the Android team in late 2015, and also drained by family and personal things that were happening and needed more time and energy. I got that, and return recharged and with some insights that I hope will be useful. I’ll touch on a few of those in this post. Each could probably be its own blog post, but today I want to briefly note the event.</p>

<p>I am now a research software engineer on the Google Fonts team, working on a number of topics in font technology, including font design tools, GPU-accelerated font rendering, and evolution of font file formats to be more efficient and capable.</p>

<h2 id="on-open-source-sustainability">On open source sustainability</h2>

<p>Much has been written on open source sustainability, notably <a href="https://nadiaeghbal.com/">Nadia Eghbal</a>’s <em>Working in Public.</em> I won’t speak to open source more broadly (except to note how impressed I am with Blender and Krita), but for the specific task of building an ecosystem for a library, I think there is one model that actually works: being hired by a company that depends on that ecosystem.</p>

<p>To some extent, that’s an indictment of our capitalist system. In an ideal universe, there would be strong institutions dedicated to the public interest where open source developers could develop, researchers could research, and spend an absolute minimum of time and energy hustling for support. For software, in any case, universities are not that (as demonstrated by <a href="https://blog.cocalc.com/2019/04/12/should-i-resign-from-my-full-professor-job-to-work-fulltime-on-cocalc.html">William Stein’s experience with Cocalc at University of Washington</a>), otherwise I’d be quite tempted. In the actual world, working for a company like Google is about as close as you can come.</p>

<p>I remain skeptical of patronage-style platforms such as Patreon or Github Sponsors. I think it’s possible to make them work, but only for a small number of fortunate people, and even then, the incentives for creating maximum value aren’t that well aligned with the incentive structure of hustling on social media.</p>

<p>So me (re-)joining Google full time is basically a statement of confidence in this model of being employed to work on open source. Other models can work, and people should definitely find what works for them, but particularly for the projects I’m interested in, it makes sense.</p>

<h2 id="on-rust">On Rust</h2>

<p>I continue to love Rust, and believe it offers a stronger foundation for building software. I feel like I started my Rust journey in the early ’90s, when I was working on retrofitting <a href="https://theory.stanford.edu/~aiken/publications/papers/pldi95.pdf">static memory management</a> to ML, using explicit lifetime regions.</p>

<p>Rust adoption is trending up, including at Google. The language is in good shape, but the library ecosystem is still fairly immature, missing a number of critical pieces. Building up that ecosystem is an incredibly rewarding project.</p>

<p>I am particularly excited about Rust for font technology and infrastructure. Today, Python rules on the font design and production side, partly to the connection of typeface designer <a href="https://medium.com/type-thursday/learning-python-makes-you-a-better-designer-an-interview-with-just-van-rossum-8d4758c192d8">Just van Rossum</a> being Guido’s brother. The flexibility and expressiveness of Python makes it a good fit, but we’ve also gotten to a place where the <em>production</em> of fonts is done in Python, and the <em>consumption</em> is in C++.</p>

<p>Rust lets us build reliable, performant code that can also be deployed in production, and can be the basis of fluidly interactive UI tools. I’m not the only one who sees this potential; YesLogic is building their next-generation font shaper <a href="https://github.com/yeslogic/allsorts">Allsorts</a> in Rust, for many of the same reasons.</p>

<p>The Google Fonts team has been interested in adopting more Rust for a while, and part of my role is to facilitate that. I’m really looking forward to it.</p>

<h2 id="on-research">On research</h2>

<p>I have rebranded myself somewhat as a researcher, but that doesn’t <em>quite</em> capture the whole story either. I have always loved research, and that love sustained the energy to complete my <a href="https://levien.com/phd/phd.html">PhD</a>, but I also love building real things, and actually feel that many of these practical problems are more interesting than many of the abstract topics fashionable in academia. Just as much as writing papers and so on, I’m trying to build open source software and community around that. There isn’t really a word for this role, but even without such a word I’m trying to consciously create it for myself, and am grateful that Google is allowing me to try.</p>

<h2 id="on-the-work">On the work</h2>

<p>This is the most exciting part for me. I have a very long-term interest in 2D graphics, font technology, and UI, and have been doing a bunch of interesting things on all these fronts. I expect to spend most of my time continuing to advance research on all these frontiers.</p>

<p>The scope of these projects is large, and more ambitious than one person could really do. That’s one reason I’ve been consciously developing an open source community around them. That will continue.</p>

<p>Most of the day-to-day work on <a href="https://github.com/linebender/druid">Druid</a> and <a href="https://github.com/linebender/runebender">Runebender</a> will be done by Colin Rofls, though I very much enjoy getting my elbows in the code too and will be doing some of that.</p>

<p>A major focus will be building out the <a href="https://github.com/linebender/piet-gpu/blob/master/doc/vision.md">piet-gpu vision</a>. I believe a high-performance 2D rendering engine will be a great thing for the Rust ecosystem and with potential for large impact. It feels like good research; whether it goes into production at scale or not, I expect the things we learn from doing it will help inform the next generation of UI technology. That’s equally true for research into fundamental UI principles, for example the <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet</a> architecture for Druid.</p>

<p>There are also really exciting advances in <a href="https://github.com/linebender/spline">spline</a> technology in the pipeline. I think these have the potential to be a more appealing and productive basis for drawing fonts than cubic Béziers. The next big step is to validate whether they actually work as well as I’m hoping. That involves polishing the UX and integrating them into Runebender. If that turns out really well, a longer term (but more speculative) aspiration is to get them into a font format, where they could reduce binary size while increasing quality. It’s obvious the Google Fonts team is the best home for this work.</p>

<p>I have a lot of work in front of me, but am more excited than ever. On to an old new adventure, and may 2021 be a time of healing and renewed energy for all.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448248</guid>
            <pubDate>Wed, 16 Dec 2020 20:36:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Preview in macOS Big Sur is destroying PDFs]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 311 (<a href="https://news.ycombinator.com/item?id=25447830">thread link</a>) | @matrixagent
<br/>
December 16, 2020 | https://annoying.technology/posts/86f4ea27e4cd90d0/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/86f4ea27e4cd90d0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/35f98c21da204421e81bcfcb709f0b9a2563fde5/a3843/media/previeweatingpdfs.png"></p><p>This <a href="https://annoying.technology/media/previeweatingpdfs.png">image</a> has three components: On the left is an OCR’ed PDF from my ScanSnap iX500. I have selected most of the text, and on the right side you can see two copy&amp;paste results. In the upper half is the result directly after scanning, right after the bundled ABBYY FineReader that comes with the iX500 did its magic. In the lower half is the result <strong>after</strong> modifying (removed a blank page) and saving that same PDF in <em>Preview</em>.</p><p>Hard to believe, but that’s <a href="https://discourse.devontechnologies.com/t/odd-pdf-behavior/21400">not</a> <a href="http://www.documentsnap.com/ocr-text-macos-sierra-preview/">the</a> <a href="https://discussions.apple.com/thread/8010687">first</a> time Apple <a href="https://mjtsai.com/blog/2016/12/21/more-macos-preview-pdf-trouble/">messed this up</a>. Sure, even Apple can’t account for all use cases when changing complex stuff like internal PDF handling. But:</p><ul><li>The iX500 is an insanely popular and common scanner</li><li>I don’t know any OCR software that is more popular than ABBYY FineReader</li><li>macOS used to be the absolute best in class OS for dealing with PDFs by a <strong>long</strong> shot</li><li>IT HAPPENED BEFORE</li></ul><p>I wish Apple was still charging for OS updates, so I could at least refund it.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> This is such a nasty bug – if you don’t already know to expect it, you will only find out months or possibly years later. I almost missed it this time, because even after modifying and saving the file it’s still not happening. You have to completely close the file and reopen it, only then will you realize that it has been destroyed.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Yes, I blame only Apple for this. I’ll repeat what I told Philipp (noted Apple apologist!) when we argued about this last week after I discovered the problem: ABBYY says they don’t support Big Sur yet, that’s fine. But Apple didn’t tell me that I can’t upgrade to Big Sur when I use ABBYY. I’d be a lot less angry if there was a changelog or release notes <em>from Apple</em> where it says there is a known problem with OCR’ed PDFs in Preview. <em>Their</em> software is broken, <em>they</em> need to tell me. I don’t care if it only worked because they had workarounds for super shitty PDFs that ABBYY possibly produces, I just need my OS to keep working for me. This bug could hit me without even owning a scanner at all – someone sending me a PDF that I then unknowingly break before archiving it. That’s the part I’m mad about. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/86f4ea27e4cd90d0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447830</guid>
            <pubDate>Wed, 16 Dec 2020 20:07:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaSy Math: A Resource of SaaS Metrics for Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25444277">thread link</a>) | @randrews543
<br/>
December 16, 2020 | https://www.talkinsaasy.com/saasy-math | <a href="https://web.archive.org/web/*/https://www.talkinsaasy.com/saasy-math">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><h2 data-ix="fade-in-on-scroll-2">A collection of simple, easy to use SaaS metrics with formulas, sample calculations, and examples of how to find this data in your own tech stack</h2></p><div><div><p>Net Revenue Retention (NRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4ad78fde0b0a238a1870_Net%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Net Revenue Retention represents how well you are <strong>retaining</strong> and <strong>expanding</strong> your existing recurring revenue. NRR is most typically measured either annually or month-to-month, but you are always comparing a cohort (a group of customers acquired at the same time) to see how their subscription revenue fares over the given time period. Think about your Netflix subscription, when you first signed up, are you still subscribed? And are you paying the same about as before?</p><p>‍<strong>Quick and SaaSy Way To Calculate:</strong> Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month, then just divide that number by previous years MRR number and you have your annual net revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Net Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-revenue-retention" target="_blank">Net Revenue Retention</a></p></div></div></div><div><div><p>Gross Revenue Retention (GRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4aa6b26ad627a4efeb0f_Gross%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Gross Revenue Retention represents how well you are <strong>retaining</strong> your revenue and DOES NOT include how well you are expanding them. Similar to NRR, GRR measures customer cohorts aver a given time period to see how much of the initial MRR still remains over the given time period.</p><p><strong>Quick and SaaSy Way To Calculate:</strong> Similar to NRR, go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month but in the case of GRR, any customers who’s revenue expanded, you need to take out the additional revenue and just keep their original MRR. Then just divide that number by previous years MRR number and you have your annual gross revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Gross Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank">Net vs Gross Revenue Retention</a></p></div></div></div><div><div><p>Customer Churn</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca548eec3a202105d82b1e_Customer%20Churn.png" loading="lazy" alt=""></p></div><div><div><p>Customer Churn is the measure of how many customers cancel over time from a given cohort. While the goal is to always minimize churn as best possible, SaaS/Subscription will have some churn and tracking it is crucial for success. Similar to Revenue Retention</p><p><strong>Quick and SaaSy Way To Calculate: </strong>Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>, or go into your CRM such as <a href="https://www.salesforce.com/" target="_blank">Salesforce</a> or <a href="https://www.hubspot.com/" target="_blank">HubSpot</a>. From either system you want to look for the Customer/Account table from the systems API. From that table you want to look up and count all of the unique customer ID’s that where created in a given month. Then month-to-month you want to run a check on those same ID’s to see how many of them are still active customers and then divide that number by the initial number in their first month. Typically, startups will look at churn on a monthly and annual basis and we highly recommend you track the changes in churn over time (ie. If the rate of churn is decreasing or increasing over time). If you want to take this analysis to the next level shoot me us <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer churn can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/churn-isnt-always-bad" target="_blank">Churn Isn’t Always Bad</a>, <a href="#https://www.talkinsaasy.com/blog/revenue-churn-vs-customer-churn">Revenue Churn vs Customer Churn</a><br><a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank"></a></p></div></div></div><div><div><p>Customer Acquisition Cost (CAC)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca549a64abc2d9c6dfb094_Customer%20Acquisition%20Cost.png" loading="lazy" alt=""></p></div><div><div><p>Customer Acquisition Cost, or CAC, is the measure of how much a company must spend in order to acquire a new customer. Typically you look at CAC over a period of time (annually and/or month-to-month) to understand how it is trending for your business.<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>To get your expenses you will need to go into your accounting/financial system such as Quickbooks or Xero, and track down your sales and marketing expenses for a time frame. This will include salaries, tech spend, marketing spend and any other expenses that go into your customer acquisition funnel. You then want to go into your CRM or billing and subscription management system and run a count of all the unique customer ID’s that have a created date in the same time period. You then divide the cost by your new customer count and you have your average CAC. If you want to take this analysis to the next level shoot us an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer acquisition cost can differ throughout your customer base.</p><p>Related Blog&nbsp;Posts:<a href="https://www.talkinsaasy.com/blog/dont-get-fooled-by-cac"> Don't Get Fooled By CAC</a></p></div></div></div><div><div><p>Retention Margin</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fd6a337e1ad8f8787d82e4d_Retention%20Margins.png" loading="lazy" alt=""></p></div><div><div><p>Retention Margins is a measurement of the % of top-line revenue that is left over each month once you have taken out the cost of revenue (Gross Margins) and the cost of keeping (retaining) your recurring revenue customers. Think of retention margins as the the home profit on a per customer basis after you have retained them month-over-month<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>First you need to calculate your Gross Margin (Revenue-Cost of Revenue/Revenue). Then go into your accounting system like Quickbooks or Xero. You want to total up the amount of spend (payroll, overhead, etc.) for your customer service and success teams. You then want to add that number to your Cost of Revenue number and subtract that from your top-line revenue. That number is your retention profit (Take home $$$) after retaining your customers. Take your retention profit and divide it by your top-line revenue number and that will give you your retention margin.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/why-net-and-gross-revenue-retention-matter">Why Net AND&nbsp;Gross Revenue Retention Matter</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.talkinsaasy.com/saasy-math</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444277</guid>
            <pubDate>Wed, 16 Dec 2020 16:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Regret Quitting Astrophysics]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 140 (<a href="https://news.ycombinator.com/item?id=25444069">thread link</a>) | @petschge
<br/>
December 16, 2020 | http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/ | <a href="https://web.archive.org/web/*/http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-223">
	
	<!-- .entry-header -->

	<div>
		
<p>In 2013 I decided to quit my career in astrophysics, move back “home” and become a data scientist. The <a href="http://www.marcelhaas.com/index.php/2018/03/30/leaving-the-field-becoming-an-extronomer/">blog post</a> I wrote about my decision was probably my best read publication as a professional astronomer and it was moving to read all the reactions from people who were struggling with similar decisions. I meant every word in that blog post and I still agree with most of what I said. Now, 7 years after the fact, it is time to confess: I deeply regret quitting.</p>



<p>This post is meant to give my point of view. Many people who left academia are very happy that they did. Here I present some arguments why one might not want to leave, which I hope will be of help for people facing decisions like these.</p>



<p><span>I miss being motivated.</span> In the first few years after jumping ship many people asked me why I would ever wanted to <em>not</em> be a professional astronomer. I have always said that my day-to-day work wasn’t too different, except that what I did with data was about financial services or some other business I was in, rather than about galaxies and the Universe, but that the “core activities” of work were quite similar. That is kind of true. On an hour by hour basis, often I’m just writing (Python) code to figure things out or build a useful software product. The motivation to do what you do, though, is very <em>very</em> different. The duty cycle and technical depth of projects are short and shallow and the emphasis of projects is much more on getting working products than on understanding. I am doing quite well (in my own humble opinion), but it is hard to get satisfaction out of my current job.</p>



<p><img loading="lazy" width="546" height="340" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png" alt="" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png 546w, http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat-300x187.png 300w" sizes="(max-width: 546px) 100vw, 546px"></p>



<p><span>I miss academic research.</span> The seeds of astronomy were planted at very young age (8, if I remember correctly). The fascination for the wonders of the cosmos has changed somewhat in nature while growing up but hasn’t faded. Being at the forefront of figuring things out about the workings of the Universe is amazing, and unparalleled in any business setting. Having the freedom to pick up new techniques that may be useful for your research is something that happened to me only sporadically after the academic years. The freedom to learn and explore are valuable for creative and investigative minds and it doesn’t fit as well in most business settings that I have seen.</p>



<p><span>I miss working at academic institutions.</span> The vibe of being at a large research institute, surrounded by people who are intrinsically motivated to do what they do was of great value to me. Having visitors over from around the globe with interesting, perhaps related work was a big motivator. That journal clubs, coffee discussions, lunch talks, colloquiums etc. are all “part of the job” is something that even most scientists don’t always seem to fully appreciate. Teaching, at the depth of university level classes, as a part of the job is greatly rewarding (I do teach nowadays!).</p>



<p><span>I miss passion and being proud of what I do.</span> The <a href="https://www.google.nl/search?hl=nl&amp;q=sexiest+job+of+the+21st+century">internet </a>says I have ”the sexiest job of the 21<sup>st</sup> century”, but I think my previous job was more enjoyable to brag about at birthday parties. I can do astro as a hobby, but that simply doesn’t give you enough time to do something substantial enough.</p>



<p><span>I don’t miss …</span> Indeed, the academic career also had its downsides. There is strong competition and people typically experience quite some pressure to achieve. The culture wasn’t always very healthy and diversity and equality are in bad shape in academia. Success criteria of your projects and of you as a person are typically better motivated in business. The obligatory nomadic lifestyle that you are bound to have as an early career scientist were a very enjoyable and educational experience, but it can easily become a burden on your personal life. The drawbacks and benefits of any career path will balance out differently for everybody. If you get to such a point, don’t take the decision lightly.</p>



<div><figure><img loading="lazy" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png" alt="" width="89" height="89" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png 200w, http://www.marcelhaas.com/wp-content/uploads/2020/12/decision-150x150.png 150w" sizes="(max-width: 89px) 100vw, 89px"></figure></div>



<p>The people who questioned my decision to become an extronomer were right. I was wrong. It seems too late to get back in. I think I have gained skills and experience that can be very valuable to the astronomical community, but I know that that is simply not what candidates for academic positions are selected on. On top of that, being geographically bound doesn’t help. At least I will try to stay close to the field and who knows what might once cross my path.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444069</guid>
            <pubDate>Wed, 16 Dec 2020 15:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Linux and Bash for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443415">thread link</a>) | @tolstoyevsky
<br/>
December 16, 2020 | http://dagshub.com/blog/effective-linux-bash-data-scientists/ | <a href="https://web.archive.org/web/*/http://dagshub.com/blog/effective-linux-bash-data-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>In November 2020, DAGsHub gave a series of guest lectures to the excellent <a href="https://yandexdataschool.com/israel/">Y-DATA</a> course for aspiring data scientists, which we would now like to share with whoever finds it useful, in blog form!</p><h2 id="cut-to-the-chase-">Cut to the chase!</h2><ul><li><a href="#basics">Shell basics</a></li><li><a href="#the-shell">Background on shells</a></li><li><a href="#shell-variables">Shell variables</a></li><li><a href="#pipes">Pipes</a></li><li><a href="#redirects">Redirects</a></li><li><a href="#filesystem">Filesystem</a></li><li><a href="#runnable-files">Runnable files</a></li><li><a href="#package-managers">Package managers</a> (e.g. brew and apt)</li><li><a href="#shell-commands-inside-jupyter-notebooks">Shell commands inside Jupyter notebooks</a></li><li><a href="#text-editors-in-the-terminal">Text editors in the terminal</a></li><li><a href="#other-useful-commands">Other useful commands</a></li><li><a href="#ssh">SSH</a></li><li><a href="#tmux">tmux</a></li><li><a href="#running-commands-in-the-background">Running commands in the background</a></li><li><a href="#symbolic-links">Symbolic links</a></li><li><a href="#zsh-oh-my-zsh-powerlevel10k">Oh-my-zsh</a></li></ul><h2 id="intro">Intro</h2><p>The topic - system, IT, DevOps, MLOps, whatever other name you want to call it - how do you make the computer do what you want, outside the context of Python (or R or Matlab etc., we don't discriminate)? How do you get that beautiful neural network of yours to run on an actual server in the cloud, so that it can serve actual users?</p><blockquote>What to do when the bubble bursts, and you have to step outside the Jupyter notebook to fix things?</blockquote><p>Of course, this is a wide open question which requires a lot of previous knowledge to answer. In our lectures, we wanted to start by building a solid foundation for the students to stand on. So, we went to the classics - what is Linux? Why do people use it? What is Bash? How to use the terminal? How to exit vim?!</p><figure><img src="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="It's all about that base, no trouble!" srcset="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>It's all about that base, no trouble! Photo by <a href="https://unsplash.com/@arstyy?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Austin Neill</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Instead of creating yet-another-tutorial on how to move and copy files in terminals, we wanted to bring perspective: </p><ul><li>Why would you use Linux, Bash, and other system tools?</li><li>What's the smart way to do it, based on our subjective experience? </li><li>What common problems will you come across, and how to solve them?</li><li>What's the mental framework for working with these tools, to gain understanding and learn more by playing?</li></ul><p>So, this guide/cheatsheet is more about our tips and tricks, and is definitely not exhaustive. On the contrary - we wanted to make the most of students' time, and only talk about what's interesting. Other things can be learned on an as-needed basis.</p><h3 id="who-is-this-for">Who is this for?</h3><p>The curriculum and some of the tips are aimed at data scientists who want an introduction to the topics of Linux &amp; Bash. However, the data science orientation mainly comes into play in a few domain specific tips, and in the stated motivations to learn these things - if you're an aspiring web developer, there's no reason not to benefit from this guide as well!</p><h2 id="linux">Linux</h2><h3 id="what-is-linux">What is linux?</h3><ul><li>A family of open source operating systems.</li><li>Developed by Linus Torvalds, who also invented Git to manage the source code for Linux.</li><li>An operating system is a program that takes over a bit after your computer turns on.</li><li>For the first few seconds after your computer switches on, the motherboard runs a small hard-coded operating system called the BIOS, but it quickly hands control over to some operating system<em> kernel</em>, which is installed on one of the hard drives, a USB stick or CD.</li><li>From that point on, the kernel decides which programs to run when, and how to control physical devices (via drivers).</li><li>An <em>operating system</em> is a bundle of programs that come packaged together. The kernel is the most important part, but it comes with more programs which help the users communicate with the kernel.</li><li>e.g. File explorers are part of the OS, but not the kernel - they're just graphical interfaces which sit between the user and the kernel.</li><li>Operating systems normally also handle file systems, user permissions, memory management, and many other things.</li><li>The thing that unites all the different operating systems in the Linux family is they all use the same Linux kernel - other parts differ. More on that later in the section about distributions.</li></ul><figure><img src="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Penguins" srcset="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@topcools?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">topcools tee</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h3 id="what-is-linux-good-for">What is Linux good for?</h3><p>An operating system is, surprisingly, just a type of system. Systems are designed by humans, and better designs lead to better performance, stability, and flexibility. <strong>Linux is simply a better designed operating system</strong>. It's super flexible and stable - "blue screens of death" are exceedingly rare in production Linux servers, and their performance is very reliable. <strong>Which is why a vast majority of production systems run on Linux</strong>, and that's also why it's good for anyone working in tech to be Linux literate. That includes you, dear reader.</p><p>Being open source leads to high quality, as bugs have fewer dark places to hide in. Developers can peer under the covers to make sure their Linux applications will work well, rather than guessing and relying on questionable documentation from closed source operating system developers.</p><p>But with great power and flexibility comes a great ability to shoot yourself in the foot. Linux makes that easy as well.</p><h3 id="what-do-the-different-types-of-linux-mean">What do the different types of Linux mean?</h3><p>One of the confusing things when entering the Linux world is the giant jargon which is thrown in your face. It feels like the explanations expect you to already know and understand a bunch of other terms, without building understanding step by step. So, I'd like to give you a very brief summary of terms you might come across and what they mean.</p><h3 id="linux-like-systems">Linux-like systems</h3><p>Mac and Unix are very similar to, but are not Linux technically. You will have a hard time telling the difference, unless you dive deep.</p><p>Unix is older than Linux and extremely similar - In fact, Linux is an open source re-implementation of Unix (which was closed source, but very good). This is pretty much historic trivia, as Unix is rarely seen nowadays, but know that some people use the words Unix and Linux interchangeably.</p><p>In general, there’s a name for operating systems that look and feel like Unix – POSIX compliant, or *nix. When you see these words, translate them as “follows the conventions of Linux, such as basic commands for file manipulation (ls, cd, mkdir) and "/" as the root of the file system etc.”</p><p>GNU is a large set of free software which is the foundation for much of Linux – compilers, C libraries, programs to zip files, and many others. It's also the name of an independent POSIX operating system, with more hardcore ideology around free software than Linux.</p><p>All of the above systems, as well as Linux itself, are examples of POSIX compliant or *nix systems.</p><h3 id="linux-distributions-distros">Linux Distributions / Distros</h3><p>There are (too?) many flavours of “real Linux”, called distros or distributions. It can be a headache to differentiate them.</p><p>A distribution is like a "company", which invents a new operating system. They wrap the Linux Kernel with a new bundle of peripheral programs - i.e. they may use a different mix of GUI programs, support different hardware by default, etc. They release new versions occasionally.</p><p><strong>The bottom line – unless you know what you’re doing, <a href="https://ubuntu.com/download/desktop">just use Ubuntu</a></strong>. It’s the most user friendly, widely supported, and easy to install.</p><p><a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux">Red Hat Enterprise Linux</a>, or RHEL, is a different distro which is used sometimes in heavy duty production servers. <a href="https://getfedora.org/">Fedora</a> is the desktop equivalent of RHEL - usually, developers aiming to run their applications on RHEL servers will use Fedora for their development computers, to avoid compatibility issues.</p><p><a href="https://alpinelinux.org/">Alpine</a> is a super minimal distro which is used for many Docker images. <a href="https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">Read our blog post about Docker for more information</a>.</p><h2 id="interfaces">Interfaces</h2><p>When people think of Linux, they usually associate it with a scary terminal (plus attached Anonymous hacker with a hoodie 👩‍💻).</p><p>Don't Panic – it’s not so scary! Today, it’s really easy to install Linux on a computer, with a regular GUI wizard, if you pick a distro that cares about that sort of thing (for example, Ubuntu).</p><p>We'll focus on terminals / shells in this lecture, since that is always available, and generally where "real work" is done. Production servers will rarely have GUIs. Don't let that discourage you - after you get used to it, using the shell can become much more convenient than GUIs!</p><figure><img src="https://dagshub.com/blog/content/images/2020/12/image.png" alt="The Wizard will now install your software."><figcaption>The Wizard will now install your software.</figcaption></figure><h2 id="basics">Basics</h2><p>The following actions are very basic file manipulation commands - moving, copying, deleting, viewing, etc.<br>I think there are enough sources online to learn these basic commands, and so I won't be re-explaining them here. Below the list, I provide my recommended way to learn about them, so don't worry!</p><ul><li>ls</li><li>mv</li><li>cp</li><li>rm</li><li>pwd</li><li>cd</li><li>mkdir</li><li>echo</li><li>cat</li></ul><p><strong>The most convenient way I found to learn about these commands, even if you don't have a Linux terminal available, is to follow these tutorials:</strong></p><ol><li><a href="https://www.webminal.org/terminal/">https://www.webminal.org/terminal/</a><br><strong>Do up to and including lesson 3.</strong><br>Webminal includes an interactive terminal in the browser, which you can play with and use for the next tutorial (which doesn't have an interactive shell, only text and quizzes).</li><li><a href="https://linuxjourney.com/lesson/the-shell">https://linuxjourney.com/lesson/the-shell</a></li></ol><h2 id="the-shell">The Shell</h2><p>The shell (AKA terminal) is itself a program! It's in charge of things like: </p><ul><li>Taking keystrokes from the user</li><li>Displaying text output to the user.</li><li>Remembering what directory you're in currently (changed using <code>cd</code>, shown using <code>pwd</code>)</li><li>Turning your commands into <strong>new</strong> <strong>running programs &nbsp;- processes,</strong> by sending appropriate messages to the kernel</li></ul><p>For example, what does the shell do when I type <code>python hello_world.py</code> and press enter?</p><ul><li>It's in charge of knowing where the actual program called "python" is located in the file system - probably something like <code>/usr/bin/python</code>. In the end, the kernel is the only thing that can run new programs, and it expects absolute paths to files.</li><li>I can check where the shell is actually finding "python" by running <code>which python</code>. &nbsp;The <code>which</code> command outputs the full path found by the shell. How does it know? More on that later, in the section on runnable scripts.</li><li><code>which</code> is a useful command! Maybe you have several conflicting versions of python installed, and you're not sure which one is actually running and giving you problems. <code>which python</code> to the rescue!</li><li>Or maybe I have some runnable script, and I want to edit, delete or rename it, but I forgot where it's located. <code>which</code> to the rescue!</li><li>So, what actually happens is that the shell tells the kernel program: "Please take the program file located at <code>/usr/bin/python</code>, and turn that into a new running process with a single argument <code>/absolute/path/to/hello_world.py</code> , running inside the current …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://dagshub.com/blog/effective-linux-bash-data-scientists/">http://dagshub.com/blog/effective-linux-bash-data-scientists/</a></em></p>]]>
            </description>
            <link>http://dagshub.com/blog/effective-linux-bash-data-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443415</guid>
            <pubDate>Wed, 16 Dec 2020 15:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442991">thread link</a>) | @woodruffw
<br/>
December 16, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442991</guid>
            <pubDate>Wed, 16 Dec 2020 14:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolarWinds leaked FTP credentials through a public GitHub repo since 2018]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25442734">thread link</a>) | @hackerpain
<br/>
December 16, 2020 | https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/ | <a href="https://web.archive.org/web/*/https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.savebreach.com/content/images/size/w300/2020/12/ss_solar.png 300w,
                            https://www.savebreach.com/content/images/size/w600/2020/12/ss_solar.png 600w,
                            https://www.savebreach.com/content/images/size/w1000/2020/12/ss_solar.png 1000w,
                            https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png" alt="SolarWinds Leaked FTP Credentials through a Public GitHub Repo &quot;mib-importer&quot; since 2018">
            </figure>

            <section>
                <div>
                    <h2 id="what-could-go-wrong-when-your-employees-commit-internal-information-to-public-github-repos">What could go wrong when your employees commit internal information to public GitHub repos? </h2><p>While <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">we were the first to report on the SolarWinds security vulnerability that possibly could have exposed their Downloads FTP server</a> credentials letting attackers to push malicious binaries and attack the US government and <a href="https://solarwinds.com/">SolarWinds</a>' other high profile clients, some more information has surfaced regarding the SolarWinds security vulnerability since then, that gives more insight into what possibly was exposed and whether it could have led to this massive breach of the US government. While majority of security researchers are of the opinion that this wasn't the main reason of the breach, and that there was a complex and sophisticated supply chain attack targeting <a href="https://solarwinds.com/">SolarWinds</a>, we believe<strong> these small security lapses could have given the attackers a larger attack surface to carry out their attacks</strong> and eventually might have helped strengthen their foothold into the SolarWinds infrastructure, to perform reconnaissance and evade detection.</p><h3 id="plain-old-ftp-to-the-blame">Plain old FTP to the blame?</h3><p>As per the screenshot posted by Vinoth, which we wrote about in our previous <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">post</a>, SolarWinds were possibly using unencrypted plain FTP server for their Downloads server in the age of global CDN technologies. However, not a direct attack vector its very likely that the FTP server had more vulnerabilities and unencrypted communication can always be intercepted, and modified. But we don't believe this maybe something as concerning as the FTP password leak.</p><h2 id="solarwinds-credentials-were-possibly-leaking-since-2018">SolarWinds Credentials were possibly leaking since 2018</h2><p>Security researcher Vinoth Kumar, told us that "SolarWinds had been possibly exposing the FTP credentials to the Download server since at least 2018". To corroborate his claim, Vinoth shared the the following link to the Configuration file exposed that was exposed in the mib-importer GitHub repo possibly belonging to a <a href="https://github.com/xkozus00">SolarWinds employee</a>, <a href="https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config">https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config</a> and he further added that, upon supplying the <a href="https://github.com/xkozus00/mib-importer">repo base url</a> to the Web Archive, it shows Web Archive had first archived the page back in June 2018, and that was the last time the page was archived. So we concluded that the credentials to the FTP server and other potentially sensitive information in that exposed repository possibly existed for more than 1 year in the public domain until Vinoth reported it to the SolarWinds PSIRT.</p><figure><img src="https://savebreach.com/content/images/2020/12/image-3.png" alt="" srcset="https://savebreach.com/content/images/size/w600/2020/12/image-3.png 600w, https://savebreach.com/content/images/size/w1000/2020/12/image-3.png 1000w, https://savebreach.com/content/images/2020/12/image-3.png 1411w" sizes="(min-width: 720px) 720px"><figcaption>Screenshot of the SolarWinds GitHub repository archived by Web Archive</figcaption></figure><p>This shows that SolarWinds might have been exposing their sensitive internal credentials since a fairly long time before it was brought to their notice, which in turn might have given its attackers an opportunity to steal certificates and other valuable internal information about SolarWinds to carry out the large scale attack against US government and other top organizations using the backdoored SolarWinds Orion software.</p><h2 id="the-mib-importer-github-repository">The mib-importer GitHub repository</h2><p>A "mib-importer" public GitHub repository, possibly belonging to a SolarWinds employee with secrets (like FTP username and password) exposed, was found on GitHub by the security researcher in November 2019, which is said to have existed from around June 2018</p><p>Upon analyzing, the SaveBreach team found out that SolarWinds Orion lets users import MIB files into it. MIB files are used for monitoring network devices. Apparently, the mib-importer tool was developed by SolarWinds to import MIB files into Orion. We found the following data from the <strong><a href="https://support.solarwinds.com/SuccessCenter/s/article/Add-MIBs-to-the-SolarWinds-MIB-database">SolarWinds documentation pages</a> </strong>regarding importing &nbsp;MIB files (Reference – <a href="https://support.solarwinds.com/SuccessCenter/s/article/Upload-MIB-in-Orion-Universal-Device-Poller">1</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">2</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">3</a>)</p><p><a href="https://documentation.solarwinds.com/en/Success_Center/orionplatform/Content/Core-Management-Information-Base--MIB--sw1730.htm">From SolarWinds website</a> – </p><blockquote>Management Information Base (MIB) is a structure that describes all objects a device can report on, such as CPU, fan, or temperature. MIB contains the name, datatype, and the object identifier (OID). MIB is a hierarchical structure, displayed as a navigation tree. Every entry in the MIB tree is a value for a specific component on a specific device.</blockquote><blockquote>SolarWinds maintains a MIB database that serves as a repository for the OIDs used to monitor a wide variety of network devices. The MIB database is updated regularly.</blockquote><h2 id="qa-with-cybersecurity-researcher-vinoth">Q&amp;A with cybersecurity researcher Vinoth</h2><p>From our most recent conversation with Vinoth, it appears that the credentials and possibly more sensitive data about SolarWinds was lying in public domain for a long time before finally being taken down. Vinoth doubts that the data might have also included certificates and not just FTP credentials, which was alone sufficient to sign the malicious binaries and upload them to the FTP server while passing off as legitimate software.</p><p><strong>Q: Since when do you think the GitHub repo might have been exposed? Do you think the attackers could have gained persistence into their infrastructure for almost 3 years to carry out the attack?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: I’m not sure, even on June 2018, 40 commits were there (in that repo). There was only one page available on archive couldn’t find anything else.</p><p><strong>Q: The Attackers had put signed binaries on the Download server. What was the process the attackers might have followed after getting access to the file upload server to sign the binaries?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: Not sure, but I could have missed checking the repo which could have had the certificate in it.</p><p><strong>Vinoth had tweeted that the GitHub repo was open to public since 17th June, 2018</strong></p><figure><blockquote data-width="550"><p lang="en" dir="ltr">That Github repo was open to the public since 17 Jun 2018 😱 <a href="https://t.co/SHUWaPXIeK">pic.twitter.com/SHUWaPXIeK</a></p>— Vinoth Kumar (@vinodsparrow) <a href="https://twitter.com/vinodsparrow/status/1338956534147993601?ref_src=twsrc%5Etfw">December 15, 2020</a></blockquote>

<figcaption>Tweet by Vinod about the web archived GitHub repository page</figcaption></figure><h2 id="certificates-used-to-sign-malicious-binaries-exposed-through-github-repo">Certificates used to sign malicious binaries exposed through GitHub repo?</h2><p>This raises many questions. Were the certificates used to sign the binaries obtained from that public GitHub repository or, from any other information leaked publicly? &nbsp;Exposed certificate could have allowed hackers to sign their malicious SolarWinds Orion binaries and pass them off as legitimate software developed by SolarWinds, subsequently uploading them to the Downloads server with the previously found leaked FTP credentials.</p><h2 id="was-this-how-solarwinds-got-hacked">Was this How SolarWinds got hacked?</h2><p>We can come to a partial conclusion that the internal information exposed on GitHub was there for a sufficiently long time for the attackers to have already exploited them to gain their initial foothold. Although unclear at this point, as there maybe a more sophisticated and complex attack chain with evasion techniques as being claimed by FireEye and security researchers, but we do feel this might have been a precursor to the SolarWinds breach and the widespread cyber attack against the US Government.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaveBreach | Cyber Security, Bug Hunting &amp; Domain Acquisitions</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442734</guid>
            <pubDate>Wed, 16 Dec 2020 14:19:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tig – Text-mode interface for Git]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 96 (<a href="https://news.ycombinator.com/item?id=25442510">thread link</a>) | @lemonspat
<br/>
December 16, 2020 | https://jonas.github.io/tig/ | <a href="https://web.archive.org/web/*/https://jonas.github.io/tig/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tig is an ncurses-based text-mode interface for git. It functions mainly
as a Git repository browser, but can also assist in staging changes for
commit at chunk level and act as a pager for output from various Git
commands.</p>
</div></div>]]>
            </description>
            <link>https://jonas.github.io/tig/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442510</guid>
            <pubDate>Wed, 16 Dec 2020 14:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting started with C]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 101 (<a href="https://news.ycombinator.com/item?id=25442165">thread link</a>) | @hdante
<br/>
December 16, 2020 | https://not.cafe/2020/10/12/getting-started-with-c-programming.html | <a href="https://web.archive.org/web/*/https://not.cafe/2020/10/12/getting-started-with-c-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <article>
    

  <h5>Posted at <time>2020-10-13 00:32+0000</time>
  
          , <em>last edit: <time>2020-12-14 18:47+0000</time></em>
  
  </h5>

  
  

  <p><span>!☕</span> This tutorial will guide you through writing the
“Hello World” program in the C programming language. You’ll use Unix-style terminal
emulators and command-line tools to execute commands, Linux-style package managers to
install programs and libraries, the GNU nano text editor to write C code, the meson build
system to build executable programs and the Gtk+ library to write portable, cross-platform
graphical programs.</p>

<figure>
  <a href="https://commons.wikimedia.org/wiki/File:Ken_Thompson_(sitting)_and_Dennis_Ritchie_at_PDP-11_(2876612463).jpg" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg/599px-Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg" alt="Ken Thompson (sitting) and Dennis Ritchie at PDP-11">
  </a>
  <figcaption>
    <a href="https://en.wikipedia.org/wiki/Dennis_Ritchie" target="_blank">
    Dennis Ritchie
    </a> (standing), the creator of the C programming language, with
    <a href="https://en.wikipedia.org/wiki/Ken_Thompson" target="_blank">Ken Thompson</a>, the
    creator of Unix. Ken is using a
    <a href="https://en.wikipedia.org/wiki/Teleprinter" target="_blank">teletypewriter</a>
    (known as a tty on Unix) typewriter-style
    <a href="https://en.wikipedia.org/wiki/Computer_terminal" target="_blank">physical terminal</a>.
    Behind is the <a href="https://en.wikipedia.org/wiki/PDP-11" target="_blank">DEC PDP-11</a>
    minicomputer.
  </figcaption>
</figure>

<p>Instructions&nbsp;for&nbsp;three operating systems are provided: macOS, Ubuntu Linux and
Windows. The selected tools are personal favorites and were hand picked to allow the
fastest development and to allow identical development flows (and thus seamless
environment switching) on the three operating systems. All tools used in this tutorial are
<a href="https://en.wikipedia.org/wiki/Free_and_open-source_software" target="_blank">free, open source software</a>
and can be downloaded and used without any issues. No programming experience is required,
as this tutorial is for absolute beginners.</p>

<h3 id="before-we-start-terminals">Before we start: terminals</h3>

<p>There are a few notes for absolute beginners that will make our path easier and faster to
understand: to stay short, the tutorial will only guide through the setup process, but
will not teach the C language; references for next steps will be given at the end; some
program downloads may be large and take some time.</p>

<p>Programming languages and textual commands are very different from spoken languages:
programs must be written in a very strict way. Miss a comma and the program will stop
working. The most important rule for a beginner is that the C language, like most other
programming languages, is case sensitive, that is, upper case letters are considered
distinct from lower case letters and one can’t be swapped for the other. Keep this in mind
when typing the code and when in doubt copy and paste it to make sure all symbols are
correctly written.</p>

<figure>
  <a href="https://www.sydney.edu.au/science/psychology/pdp-11/terminals.html" target="_blank">
    <img src="https://not.cafe/assets/2020/terminals.jpeg" alt="PDP-11 terminals">
  </a>
  <figcaption>
    The <a href="https://en.wikipedia.org/wiki/VT52#VT55" target="_blank">DEC VT55</a>
    (display-style terminal, left side), the
    <a href="https://en.wikipedia.org/wiki/DECwriter" target="_blank">DECwriter</a>
    (dot-matrix printer-style terminal) and the
    <a href="https://en.wikipedia.org/wiki/Teletype_Model_33" target="_blank">Teletype ASR-33</a>
    (typewriter-style terminal).
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the terminal emulator application to type textual commands. I’ll
succintly explain what each command does and will show each command written after a dollar
sign. The dollar sign represents the terminal emulator’s prompt symbol, and that’s the
usual symbol that the command line input program, called the shell, displays when waiting
for a command. For example:</p>

<pre><code>$ ls -l
</code></pre>

<p>In the above example, we type after the prompt symbol: <code>ls[space][minus]l</code>, then press
<code>[enter]</code> to execute. In this example, we execute the <code>ls</code> program (list directory) with
the <code>-l</code> parameter (a specific parameter for the program, changes the output mode to long,
or more descriptive). Same example, but also showing the resulting output in my computer:</p>

<pre>$ ls -l
total 7344
-rw-r--r-- 1 hdante users    9999 set 19 19:12 coffee-34251.svg
-rw-r--r-- 1 hdante users     347 set 19 19:12 coffee-34251.svg.license
-rw-r--r-- 1 hdante users   16805 set 19 19:12 favicon.ico
-rw-r--r-- 1 hdante users    3253 set 19 19:12 favicon.svg
-rw-r--r-- 1 hdante users   11665 out  2 18:49 index.html
-rw-r--r-- 1 hdante users   17833 set 19 19:12 not-coffee.svg
-rw-r--r-- 1 hdante users 2372085 set 19 19:12 radio.caf
-rw-r--r-- 1 hdante users 2656465 set 19 19:12 radio.mka
-rw-r--r-- 1 hdante users 2401864 set 19 19:12 radio.opus
-rw-r--r-- 1 hdante users    3263 out  2 16:48 site.css
-rw-r--r-- 1 hdante users    2166 set 19 19:12 square.svg
$ </pre>

<p>So,&nbsp;after&nbsp;running the <code>ls</code> program with the <code>-l</code> parameter, it shows the long
description of current directory and another dollar symbol appears at the end, it’s
waiting for a new command. Don’t worry about understanding this example, I’ll also add
references at the end for learning more about using Unix-style command-line tools.</p>

<h3 id="installation">Installation</h3>

<figure>
  <a href="https://not.cafe/assets/2020/macos-terminal-app.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/macos-terminal-app.jpeg" alt="macOS Terminal App">
  </a>
  <figcaption>
    The
    <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)" target="_blank">
    macOS Terminal.app
    </a> is a
    <a href="https://en.wikipedia.org/wiki/Terminal_emulator" target="_blank">terminal emulator</a>.
    Modern terminals are software that emulate physical terminals.
  </figcaption>
</figure>

<p>Different&nbsp;procedures&nbsp;are required for each operating system. Pick the best one
for you. After installing, writing and running code will work the same way. We’ll write a
single cross-platform program that works on all three systems and build it using the same
cross-platform build tools.</p>

<h4 id="macos">macOS</h4>

<p>For macOS, only the terminal emulator comes installed with the operating system. The Apple
provided C compiler is the
<a href="https://en.wikipedia.org/wiki/Clang" target="_blank">LLVM clang compiler</a>,
contained in the “Xcode command line tools” package. To install it, open the Terminal
application by opening the Spotlight search input, then typing Terminal (or find it in the
Utilities folder inside Applications). In the terminal emulator, type:</p>

<pre><code>$ xcode-select --install
</code></pre>

<p>The Xcode installation program will start. Follow the instructions that will appear and in
the end, the LLVM clang C compiler will be installed. You can check if it’s working by
executing it with the <code>--version</code> parameter:</p>

<pre><code>$ clang --version
</code></pre>

<p>For installing packages like build tools, text editors and libraries, we’ll install the
<a href="https://en.wikipedia.org/wiki/Homebrew_(package_manager)" target="_blank">Homebrew package manager</a>,
which is the main Linux-style package manager for macOS. The package manager allows
single-command installing, configuring, upgrading and removing of packages from the
command line. Go to <a href="https://brew.sh/" target="_blank">brew.sh</a> and access the
instructions there, or simply execute this command to download and install it:</p>

<pre><code>$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
</code></pre>

<p>Notice that this command is already more complex than the previous ones, downloading and
executing the install script from the Homebrew source code repository, and gives a hint on
the power and efficiency of the command line. Don’t worry trying to understand it, we’re
installing Homebrew exactly to make it easy to execute complex package installations.
[<strong>edit 20201214</strong>: It might be necessary to restart the Terminal App and configure the
search path after installing <code>brew</code> to be able to use it. When in doubt, check the
<a href="https://docs.brew.sh/">Homebrew documentation</a>.]</p>

<p>Now that Homebrew is installed, you may install packages with <code>brew install</code> and search
packages with <code>brew search</code>. Search and install the GNU nano text editor with:</p>

<pre><code>$ brew search nano
$ brew install nano
</code></pre>

<h4 id="linux">Linux</h4>

<figure>
  <a href="https://not.cafe/assets/2020/gcc-on-ubuntu.png" target="_blank">
    <img src="https://not.cafe/assets/2020/gcc-on-ubuntu.png" alt="gcc on Ubuntu">
  </a>
  <figcaption>
    Installing gcc on Ubuntu Linux.
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the apt package manager available in
<a href="https://ubuntu.com/" target="_blank">Ubuntu Linux</a> from the Debian family, but
other Linux distributions using, for example,
<a href="https://www.redhat.com/sysadmin/how-manage-packages" target="_blank">yum</a>,
<a href="https://docs.fedoraproject.org/en-US/quick-docs/dnf/" target="_blank">dnf</a>,
<a href="https://wiki.archlinux.org/index.php/Pacman" target="_blank">pacman</a>,
etc. will work in pretty much the same way. On Linux the
<a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a>
usually comes preinstalled, so we’ll use it instead of clang, but they work the same way.
Open a terminal by clicking the activities menu on the top left of the screen and writing
terminal in the search input (or click on the terminal icon in the favorites bar). In the
terminal emulator, write:</p>

<pre><code>$ sudo apt-get install gcc
</code></pre>

<p>Ubuntu Linux and most other distributions require switching to administrator (root) mode
to install programs, so we use the <code>sudo</code> program to execute <code>apt-get</code> in root mode (you
may also use the <code>su</code> program, if <code>sudo</code> is not installed). Type your password and follow
the instructions. In the end, check gcc:</p>

<pre><code>$ gcc --version
</code></pre>

<p>You may install packages with <code>sudo apt-get install</code> and search packages with <code>apt-cache
search</code>:</p>

<pre><code>$ apt-cache search nano
$ sudo apt-get install nano
</code></pre>

<p>For other Linux distributions, use the appropriate package manager:</p>

<pre><code>$ yum search nano         # for RedHat Linux/CentOS
$ sudo yum install nano   # for RedHat Linux/CentOS
</code></pre>

<h4 id="windows">Windows</h4>

<figure>
  <a href="https://www.msys2.org/" target="_blank">
    <img src="https://not.cafe/assets/2020/msys2-website.jpeg" alt="MSYS2 website">
  </a>
  <figcaption>
    <a href="https://www.msys2.org/" target="_blank">MSYS2 website</a>. MSYS2 is a
    toolkit for Windows development that contains Unix-style tools.
  </figcaption>
</figure>

<p>For Windows we’ll use the
<a href="https://en.wikipedia.org/wiki/Mingw-w64#MSYS2" target="_blank">MSYS2 toolkit</a>,
which provides a terminal emulator, the pacman package manager and a complete set of
Unix-style command line tools. Download the MSYS2 installer from
<a href="https://www.msys2.org/" target="_blank">www.msys2.org</a> and follow the
instructions to install the package. When installed, MSYS2 will provide three sets of
programs, which are selected whenever opening the terminal emulator. They are called the
MSYS2 shell, the MINGW64 shell (pronounced mingwee 64) and the MINGW32 shell. The MINGW64
shell is the appropriate one to develop Windows programs. The MSYS2 is appropriate for
managing MSYS2 itself and the MINGW32 is the 32-bit version that shouldn’t be used
anymore. After installing MSYS2 it’s necessary to immediatelly upgrade it. Open the MSYS2
shell and type:</p>

<pre><code>$ pacman -Syu
</code></pre>

<p>Follow the instructions and if requested restart the terminal emulator. On Windows we’ll
use the <a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a> C
compiler (gcc):</p>

<pre><code>$ pacman -S mingw-w64-x86_64-toolchain
</code></pre>

<p>After installing, to test gcc, you must use a MINGW64 shell. If you’re running the MSYS2
shell for executing pacman, open another terminal running the MINGW64 shell and type:</p>

<pre><code>$ gcc --version
</code></pre>

<p>From now on, we’ll assume that the MINGW64 shell is being used. Notice that pacman runs
normally both on MSYS2 and MINGW64 shells. You may install packages with <code>pacman -S</code> and
search packages with <code>pacman -Ss</code>:</p>

<pre><code>$ pacman -Ss nano
$ pacman -S nano
</code></pre>

<h3 id="hello-world-">Hello, World !</h3>

<figure>
  <a href="https://not.cafe/assets/2020/nano-on-macos.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/nano-on-macos.jpeg" alt="GNU nano on macOS">
  </a>
  <figcaption>
    Writing the Hello World program using GNU nano on macOS.
  </figcaption>
</figure>

<p>After installing the compilers, remember installing the
<a href="https://en.wikipedia.org/wiki/GNU_nano" target="_blank">GNU nano</a> text editor:</p>

<pre><code>$ brew install nano    # (or apt-get, or pacman)
</code></pre>

<p>Now, let’s create a new root directory to store this project and all future code:</p>

<pre><code>$ mkdir code
$ cd code
</code></pre>

<p>The first command above creates a new directory called <code>code</code>. If it already exists, it
will complain. Change the name if you prefer something else. The second command changes
the current directory to the <code>code</code> directory (the current directory is the directory used
when file operations specify file names without …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://not.cafe/2020/10/12/getting-started-with-c-programming.html">https://not.cafe/2020/10/12/getting-started-with-c-programming.html</a></em></p>]]>
            </description>
            <link>https://not.cafe/2020/10/12/getting-started-with-c-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442165</guid>
            <pubDate>Wed, 16 Dec 2020 13:21:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiments on a $50 DIY air purifier that takes 30s to assemble]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 141 (<a href="https://news.ycombinator.com/item?id=25442097">thread link</a>) | @dyno-might
<br/>
December 16, 2020 | https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 15, 2020</strong></p>
            
            



<p>Bad air is bad for you. The air purifier market, though, is a mess. Every purifier uses incompatible proprietary filters, presumably to lock you into buying replacements. How do we know these actually work? Few seem to publish lab tests. And why does it cost $100-$300 for a big plastic box with a fan and a filter inside?</p>

<p>It’s common to build DIY air purifiers by basically strapping a filter to a fan. I like the idea of these, but again, it’s hard to be confident they really work. There’s a few experiments out there, but not enough to make me comfortable. So I decided to do some experimenting of my own. I made a purifier, generated smoke, and measured how well it removes tiny particles.</p>



<p>If you’re in a hurry, this post says that if you strap two HEPA filters to a box fan, it will clear the air of basically all the particles we can measure, and it will do it faster than a commercial filter that costs twice as much.</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="in a large room the DIY filter does slightly better than the commercial filter"></p>



<h3 id="diy-purifier">DIY purifier</h3>

<p>My DIY purifier was <em>very</em> simple. (I don’t want to promote any particular brands here. Contact me if you want the exact products.)</p>

<ul>
  <li>A standard box fan. (Cost: $19)</li>
  <li>Two HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick. (Cost: $35 for both)</li>
  <li>A bungie cord. (Cost: Free)</li>
</ul>

<p>Assembly takes about 30s. You put the filters on the intake side of the fan and strap them on with the bungie cord. Here’s a picture:</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_notape.jpg" alt="DIY purifier" max-width="60%" min-width="35%"></p>

<p>Timeless elegance and grace, it is not. I get the shakes just looking at that bit of crinkled filter.</p>

<h3 id="commercial-purifier">Commercial purifier</h3>

<p>As a comparison, I got a $100 air purifier from a well-known brand that’s intended for small rooms. It uses uses a single HEPA filter that’s about 25cm x 12cm and 4cm thick. Replacement filters currently cost around $25.</p>

<h3 id="smoke">Smoke</h3>

<p>It’s surprisingly hard to repeatedly generate a consistent amount of smoke. I tried burning various things (paper, cardboard) and found that the number of particles generated can vary by an order of magnitude, depending on the burn pattern. This is difficult to control and effectively random.</p>

<p>Ideally, I’d have liked to burn some food product like oil, since the kitchen is usually the biggest source of indoor air pollution. I couldn’t figure out a good way of doing this, either: You’d need to have the same amount of oil distributed in the same way and heated to the same temperature.</p>

<p>I finally settled on using incense. I cut sticks to the length of a standard credit card and then attached the ends horizontal to the ground. This seemed to be pretty consistent. In retrospect, I bet that burning toast in a toaster would work well. (I didn’t have one on hand.)</p>

<h3 id="measurements">Measurements</h3>

<p>I borrowed a cheap-ish ($100) air quality monitor from a friend. I think it’s made by some company in China and then re-sold by various white-label brands. I can’t figure out who the original manufacturer is. Based on data I’ve seen for the reliability of other air quality monitors, I wouldn’t trust the absolute numbers, but the I think the <em>relative</em> measurements should still be OK.</p>

<p>The typical measurement for particulate pollution is “PM 2.5” which is in units of μg/m³. This is intended to measure what you’d get if you did the following:</p>
<ul>
  <li>Take a cubic meter of air.</li>
  <li>Filter all the solid particles out of the air.</li>
  <li>Keep only the solid particles that are are 2.5 micrometers (μm) or smaller.</li>
  <li>Weigh all the particles you kept in micrograms (μg).</li>
</ul>

<p>Here are some ways to interpret these numbers:</p>
<ul>
  <li>The EPA says yearly averages should be below 12 and daily averages below 35.</li>
  <li>The average outdoor level ranges from 6 in Finland to almost 100 in Nepal. Rich countries are typically under 15. The highest levels are typically found in Asia and Africa.</li>
  <li>Cooking can easily cause PM 2.5 measurements to spike into the hundreds. I’ve observed myself that this can happen with only a small amount of visible smoke.</li>
</ul>

<h3 id="logging">Logging</h3>

<p>Since the air quality monitor doesn’t log data, I used an ultra-hacky alternative: I set the monitor next to a laptop running a stopwatch. I then aimed a tabet at both of those screens and took a timelapse video. Finally, I manually transcribed the data by going to each minute marker in the data. (This was even more tedious than it sounds.)</p>



<p>I ran a first experiment in a tiny room of around 8 ㎥. Due to worries that wind from the purifiers might change the speed the incense burned, I placed it on the opposite side of a wall, with a gap of around 20 cm near the ceiling.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_tinyroom.jpg" alt="tiny room setup"></p>

<p>I repeated the experiment once with no filter, once with a commercial filter, and once with the DIY filter. Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_linear.jpg" alt="smallroom measurements in linear space"></p>

<p>Things are a bit random around the beginning, probably due to the drifting of the smoke before it’s equalized in the room. With no filter at all, this spikes all the way to 1000 μg/m³, the maximum the instrument can show.</p>

<p>If we make the y-axis logarithmic, it becomes quite clear that the DIY filter is cleaning the air at a better rate. (This is the picture from the top of this page.)</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="smallroom measurements in log space"></p>

<p>If we take the EPA’s threshold of 12 μg/m³, the DIY filter gets there in around 15 minutes, while the commercial filter take around 25 minutes.</p>



<p>Thankfully, I don’t spend most of my time in an 8 ㎥ room. Thus, I repeated the experiment in a large room of around 100 ㎥. Here there was no wall between incense and purifier. Instead I left around a meter of distance between the incense and purifier and the purifier and the monitor.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_largeroom.jpg" alt="large room setup"></p>

<p>Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_linear.jpg" alt="large room measurements in linear space"></p>

<p>There’s even more randomness around the beginning, probably just due to how the smoke drifts around. Based on the room volume we’d expect a peak concentration with no filter of around 80 μg/m³ = 1000 μg/m³ * (8/100). Reassuringly, this is pretty close to what we see.</p>

<p>The DIY purifier looks a bit better. If we plot in log space, it’s more clear that it is indeed filtering at a better rate:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_log.jpg" alt="large room measurements in log space"></p>



<p>It’s common advice for DIY purifiers like this to seal around the edges of the filter so that all air must pass through it.  I share the intuition that this would help, but it’s hard to be sure: If you block airflow, you slow down the fan. This could be counterproductive.</p>

<p>In this case at least, experiment is easier than theory. I took packing tape and carefully sealed around the intake side.</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_tape.jpg" alt="DIY purifier with tape" max-width="60%" min-width="35%"></p>

<p>And the results are…</p>

<p><img src="https://dyno-might.github.io/img/purifier/taping.jpg" alt="taping around the filter has no effect"></p>

<p>…nothing!?</p>

<p>This was unexpected. I thought the tape would help, but I wouldn’t have been surprised if it hurt instead. Instead, there’s basically no difference at all. I don’t know enough about fluid dynamics to even speculate about what’s happening here, so I won’t try.</p>

<p>There could be some weird quirk in how I ran this experiment. This doesn’t necessarily mean that all the advice to tape around the filter is <em>wrong</em>. However, I’ve never seen any experriments that show taping helps either.</p>



<p><strong>Cost.</strong> The DIY purifier isn’t dramatically cheaper than the commercial one, but I expect the filters would need to be replaced much less often. The commercial purifier uses a single filter with an area of 300 cm², whereas the DIY purifier uses two filters with a total area of around 1400 cm², and also slightly thicker. It’s reasonable to assume the DIY filters could remove ~4 times as many particles before replacement.</p>

<p><strong>Durability.</strong> One concern is that box fans aren’t meant to be used with filters attached and could wear out. This is reasonable. However, box fans are much cheaper than commercial purifiers, and I’ve been using this particular fan with various filters attached for several years now without issue.</p>

<p><strong>Electricity.</strong> The cost of electricity is another factor. Typical box fans seem to use around 55W, whereas commercial purifiers typically use 30-45W. If electricity costs $0.13 / kWh, the box fan would cost around $62 to operate 24 hours a day for a year, while a 30-watt purifier would cost around $34. Obviously, these numbers decrease if you run the purifier less. Some (more expensive) commercial purifiers have air quality sensors built in and automatically turn on only when needed.</p>

<p><strong>MERV or HEPA?</strong> Most people who build box-fan purifiers use <a href="https://en.wikipedia.org/wiki/Minimum_efficiency_reporting_value">MERV</a>-rated filters intended for furnaces. Commercial air purifiers use <a href="https://en.wikipedia.org/wiki/HEPA">HEPA</a>-rated filters. Roughly speaking, HEPA filters are “better” in that they are rated to remove a higher percentage of particles in one pass. It’s not clear that HEPA filter will actual perform better when attached to a fan, though: A filter that catches fewer particles in one pass might still be better if it allows for faster airflow.</p>

<p><strong>That one video.</strong> If you’re reading this article after it was linked from some forum, I’d bet you that someone in the comments links to <a href="https://www.youtube.com/watch?v=kH5APw_SLUU">this video</a> from the Michigan Sinus Center. I found this inspirational, but note a couple of things: First, while the description says they use HEPA filter, the video clearly indicates a MERV filter. Again, that’s not necessarily bad! They claim that around 90% of particles sized 0.3 microns are larger are eliminated in a single pass. That’s good, but not totally reassuring. The question is, does it remove 99% in two passes? If 90% of the particles in the ambient air were large and the filter only catches large particles, then additional passes would never get rid of the most dangerous small particles. This is why I trust HEPA filters a bit more: since they remove almost all particles in one pass, I’m confident they should remove almost all particles eventually. This is also why I strongly prefer experiments that actually measure particles removed from the air in a room, rather than just the air coming out of the purifier.</p>

<p><strong>Further questions.</strong> There’s a lot of things that further experiments could look at:</p>

<ol>
  <li>Does the fan speed make a huge difference?</li>
  <li>How does the purifier compare to larger commercial purifiers?</li>
  <li>How do MERV-rated furnace-type filters compare under the same conditions?</li>
  <li>How can it not matter if there’s tape around the filters!?</li>
  <li>Does fan speed matter? (I always ran the box fan at maximum speed.)</li>
  <li>Is it better to put the filters on the intake or outtake side of the …</li></ol></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</a></em></p>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442097</guid>
            <pubDate>Wed, 16 Dec 2020 13:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For e-mobility 2020 brought significant progress, this is an extensive overview]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25441956">thread link</a>) | @Pabloemm
<br/>
December 16, 2020 | https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;The growing concept of e-Mobility as a Service
                </p>

                

                <h2 id="research-explanation">Research explanation of e-Mobility as a
                    Service</h2>

                <h3 id="emergence-of-emobility">Emergence of mobility concepts</h3>

                <p>
                    Before the digital revolution and user-centric approach, the concept of accessible, new forms of
                    transportation was the future vision of what life could be like. With the rapid growth of
                    technology, mobile devices, enhanced battery capacities, wide Internet connection, investments in
                    new unexplored forms of service delivery, and quick social adaptation in the last ten years we have
                    witnessed a great transformation.
                </p>
                <p>
                    Raising enthusiasm boosted consumption and proved that rapid adaptation is possible and widely
                    accepted. New economic models have begun to take into account sharing concepts and value the
                    tangible benefits of such solutions. In a sharing economy, not used assets such as parked cars and
                    extra bedrooms can be rented out. We transferred from owning to renting. And this concept widely
                    approved first by Uber users moved to other transport areas offering new possibilities. In the
                    Alternative Journal article,
                    <a href="https://www.alternativesjournal.ca/science-and-solutions/ours-better-yours" target="_blank" rel="nofollow">
                        ‘Ours is Better than Yours’
                    </a>
                    , Ray Tumulty (2014) the sharing economy is
                    described as a clearly urban phenomenon. To achieve economies of scale for shared economy services
                    satisfactory population density is required. Moreover, these services are seen as an extra option,
                    not a replacement for traditional sectors. Ridesharing is used along with public transportation in
                    cities.
                </p>
                <p>
                    With the growing success of rented items and services, new forms of transportation options come to
                    the market. The mobility concept grew to form a comprehensive ecosystem offering numerous moving
                    variants, such as city bikes, electric scooters, car rides, ticket purchasing options, city traffic
                    monitoring, planning the most convenient route, parking options, integrated payments, and available
                    charging options for ‘e’ users. All available in real-time from the mobile app on one’s phone. This
                    progress developed the term
                    <a href="https://solidstudio.io/blog/from-maas-to-emaas-how-e-is-taking-a-charge-over-the-markets.html" target="_blank" rel="nofollow">
                        Mobility as a service
                    </a>
                    , which covers a wide range of mobility services
                    available on the market, and its integral part becomes a shared economy providing extra value for
                    participants.
                </p>
                <p>
                    On a high-level, the MaaS ecosystem includes transport infrastructure, transportation services,
                    transport information, and payment services. Within the ecosystem, the common objective is the
                    delivery of a seamless mobility experience and transportation network improvement by utilizing the
                    benefits of each service - public and private. Besides, other participants such as local authorities
                    or data administration companies can collaborate to smooth the operation of the services and improve
                    their profitability.
                </p>
                <p>
                    MaaS as a definition is described as
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/6.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>
                <p>
                    One of the MaaS ecosystem examples was presented by the Siemens Mobility Division in 2016 for
                    Tampere City, Finland. The ecosystem is build of 4 main elements: service providers; a
                    business-to-business (B2B) platform; mobility retailers; and the users. The intention of the project
                    was to unite the existing and upcoming transport services with the operations of the local
                    paratransit services.
                </p>
                <p>
                    A similar approach on a high level was presented by König project ‘Mobility As A Service for Linking
                    Europe’. Four different levels define the public and regulatory level, the transport and logistics
                    service providers level, the mobility service level, and the end-user level. On the basis of similar
                    concepts and definitions, a framework for Mobility as a service was developed.
                </p>
                <p>
                    From a business perspective, MaaS is described by Kamargianni and Matyas in the paper ‘The Business
                    Ecosystem of Mobility-as-a-Service’[1](2017) as ‘the wider network of enterprises that influences how a
                    dominant company, in this case, the MaaS provider, creates and capture value’.
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/7.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    To support theoretical premises on shared mobility, a survey conducted by McKinsey&amp;Company (2017)
                    provides some insight into the consumer’s opinion on ride-hailing and car-sharing. Respondents were
                    asked how their usage of ride-hailing and car-sharing services will change within the next two
                    years. In both cases, over 60% responded that it will increase or increase significantly. Shared
                    mobility is mostly favored in urban areas, but seems to be less attractive for running errands or
                    multi-stop shopping trips.
                </p>

                <h3 id="what-is-e">What is ‘e’ all about?</h3>

                <p>
                    We are an integral part of the next global transformation, where alternative fuels and green energy
                    takes charge. The concept explained above has been extended with ‘e’ - a possibility to travel in an
                    eco-friendly way, where ‘e’ stands for electric solutions.
                </p>
                <p>
                    Electric Mobility as a service combines Mobility as a Service (MaaS), Electric Mobility Systems
                    (EMS), and Shared Electric Mobility Services (SEMS) [2]. As a concept eMaaS operates upon MaaS,
                    where the last one became one of the complementary components. With that defined, all MaaS
                    participants become, as a consequence, eMaaS attendees. Providing they offer electric mobility
                    solutions.
                </p>

                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/8.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    Electric Mobility System (EMS) covers technologies (batteries, charging technologies, drivetrains,
                    and EVs), infrastructure (physical and organizational of charging stations, electricity grid,
                    information and communication technology), and users (manufacturers, suppliers, end-users, service
                    providers, governments, and agents).
                </p>
                <p>
                    Shared Electric Mobility Services’ (SEMS) applies to a new economy implementation, where instead of
                    ownership there is an on-a-need basis share connected by the technology with users and providers.
                    SEMS replies to the environmental, social, financial, and transportation-related benefits that had
                    already been correlated to emobility and shared mobility practice connecting both. Five business
                    approaches are proposed:
                </p>
                <ul>
                    <li>
                        Membership-based (e.g. e-bike sharing, e-car sharing, e-ridesharing, e-ride hailing, e-scooter
                        sharing, e-bus sharing),
                    </li>
                    <li>
                        Peer-to-Peer(e.g. e-car sharing, e-bike sharing, e-scooter sharing),
                    </li>
                    <li>
                        Non-membership-based (e.g. e-car rental, elimousine rental),
                    </li>
                    <li>
                        For-hire (e.g. e-car/bike/scooter sharing, e-ridesharing e-carpooling),
                    </li>
                    <li>
                        Mass transit systems (e.g. e-Public Transport, airport autonomous shuttles).
                    </li>
                </ul>
                <p>
                    As a part of a wider concept, combined with two other components MaaS &amp; EMS, together provides
                    multiple eco-friendly transportation possibilities. Successful implementation of such a concept
                    requires multi-level support, well-designed system architecture, and an extensive network in public
                    structures.
                </p>

                <h3 id="user-centric">User-centric approach</h3>

                <p>
                    The user-centric approach will always be foreground. It applies to the development of the widely
                    recognized concept of e-mobility as a service. From accessible payment methods for single ticket
                    purchasing, subscriptions, to well-developed charging networks and various means of transport
                    access. At each stage of the proposition should be declared value.
                </p>
                <p>
                    We are still in the early stages of what could be called e-Mobility as a service. Most customer
                    journeys are under development, and achieving overall flow is still in its infancy. There is a lot
                    of research to be done, but there is room for the general necessary approaches. Each of the
                    participants, in order to achieve success and remain successful in this growing market, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</a></em></p>]]>
            </description>
            <link>https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441956</guid>
            <pubDate>Wed, 16 Dec 2020 12:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a crate for creating interactive chord diagrams in Rust]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25440590">thread link</a>) | @DataCrayon
<br/>
December 16, 2020 | https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]</pre>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440590</guid>
            <pubDate>Wed, 16 Dec 2020 09:31:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elderly patients 23% more likely to die if surgery is on the surgeon’s birthday]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 208 (<a href="https://news.ycombinator.com/item?id=25440322">thread link</a>) | @whx23
<br/>
December 16, 2020 | https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5563" role="main"><div><div><div><p>A <a href="https://www.bmj.com/content/371/bmj.m4381" target="_blank" rel="noreferrer noopener">new study has found</a> that elderly patients who underwent emergency surgery on their surgeon’s birthday had significantly higher 30-day mortality rates than patients whose surgery took place on any other day of the year. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The 30-day mortality rate (defined as death within 30 days after surgery)&nbsp;for the “surgeon’s birthday” group was 6.9%. This was 23% higher than the 5.6% rate for the “other day” group.</p><p>The study, which appears today in the <em>British Medical Journal</em> (<a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener">BMJ</a>),&nbsp;looked at 980,876 procedures performed in US hospitals by 47,489 surgeons.&nbsp;Of those procedures, 2,064 (0.2%) took place on a surgeon’s birthday.&nbsp;The patients were all Medicare beneficiaries aged 65 to 99. They had all undergone one of 17 common emergency surgical procedures between 2011 and 2014.</p><h2>Distractions during the most common emergency surgery types</h2><p>Examples of those 17 procedures included cardiovascular surgeries, hip and femur fracture, appendectomy, and small bowel resection. The study focused on&nbsp;emergency surgery, so as to&nbsp;minimize the potential selection bias. For example, surgeons might otherwise choose patients based on their illness severity, or patients might choose their surgeon.</p><p>As the authors write, “The effect size of surgeons’ birthday observed in our analysis (1.3 percentage point increase or a 23% increase in mortality), though substantial, is comparable to the impact of other events, including holidays (e.g., Christmas and New Year) and weekends.” <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>In fact, the <a href="https://amzn.to/3m5rimG" target="_blank" rel="noreferrer noopener">history of surgery</a> has often demonstrated that external factors can influence surgical outcomes. The authors refer to a 2014 study showing that <a href="https://pubmed.ncbi.nlm.nih.gov/23345314/" target="_blank" rel="noreferrer noopener">patients admitted to Scottish emergency rooms on&nbsp;public holidays had a 27% increase</a> in 30-day mortality.&nbsp;Other research has found, for example,&nbsp;that doctors are more likely to <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1910546" target="_blank" rel="noreferrer noopener">prescribe antibiotics</a> and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2749268" target="_blank" rel="noreferrer noopener">opioids</a> — and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733171" target="_blank" rel="noreferrer noopener">less likely to order&nbsp;cancer screening tests</a> — as the workday progresses. This is most likely because the “cumulative cognitive demand” of such decisions gradually takes its toll.&nbsp;</p><p>Research on judges has yielded similar results. It has found, for example, that external factors as diverse as outdoor temperatures and sports results can influence judges’ decisions.&nbsp;</p><h2>A natural experiment: ER surgery on the doctor’s birthday</h2><p>But the authors say the “natural experiment” in the present study is more revealing than, for example, holiday-related mortality rates. That is because “those events not only affect physicians’ performance but also influence patients’ decision to seek care (i.e., patients seeking care on these special days might be sicker than those seeking care on other days), as well as hospital staffing.” Unless, of course, the patients know their surgeon’s birthday, which is unlikely (though that may change if this study becomes widely known).&nbsp;</p><p>The 1.3% effect size was the result after a very through series of controls. These included, for example, excluding those surgeons with the highest patient mortality rates. Other controls included assigning a random “pseudo-birthday” to surgeons to see whether the results still held up, or checking whether the surgeon did an above-average number of procedures on their birthday. <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>Likewise, the researchers controlled for “milestone” birthdays (such as 40 or 50). They also controlled for whether a birthday fell on a Friday, which might make after-work birthday festivities more likely.&nbsp;Their findings also held up when the analysis was restricted to procedures with the highest average mortality, or to only the most ill patients.&nbsp;In fact, without these adjustments, the 30-day mortality rate difference between the birthday and non-birthday groups (the unadjusted rate) was even higher (7.0% vs. 5.6%, or a 1.4% difference).</p><h2><strong>Why</strong> does emergency surgery suffer on surgeon’s birthday?</h2><p>The authors propose a few potential explanations for this “birthday effect.”&nbsp;</p><p>These include hurrying through an emergency surgery to be on time for after-work birthday events; <a href="https://www.psychnewsdaily.com/study-finds-users-not-notifications-initiate-89-of-smartphone-interactions/" target="_blank" rel="noreferrer noopener">distracting</a> birthday-related phone calls or text messages; more conversations with well-wishing staff members; and a decreased likelihood to go back to the hospital that evening if a patient’s condition deteriorates.</p><p>They also found that some surgeons did not work on their birthdays. While 2,144 surgeons in this study performed procedures one day before their birthday, and 2,027 did so one day after their birthday, only 1,805 surgeons carried out procedures on their actual birthday. This does not affect the results of the study’s analyses. But it does suggest “that birthdays are an important enough factor for some surgeons to choose not to operate on that day, which supports the credibility of our assumption that a birthday could be a distracting factor for those surgeons who choose to operate on that day,” the authors write.&nbsp;</p><h2><strong>Limitations</strong> <strong>and future directions</strong></h2><p>The researchers emphasized that this study focused on common procedures, and on older Medicare patients. This means that the findings may not apply to other types of patients, or to other surgical procedures.</p><p>Still, the authors write, these results may lead to “additional support for surgeons who have potentially distracting events,” such as birthdays, “to make sure that patients receive high quality surgical care regardless of when undergo surgery.”</p><hr><p><strong>Study: </strong>“<a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">Patient mortality after surgery on the surgeon’s birthday: observational study</a>“<br><strong>Authors:</strong> Hirotaka Kato, Anupam B. Jena, and Yusuke Tsugawa<br><strong>Published in:</strong> <a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener"><em>The BMJ</em></a><br><strong>Publication date: </strong>December 10, 2020<br><strong>DOI:</strong> <a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">https://dx.doi.org/10.1136/bmj.m4381</a><br><strong>Photo: </strong>by&nbsp;<a href="https://pixabay.com/users/theshiv76-1022681/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Jason Shivers</a>&nbsp;from&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440322</guid>
            <pubDate>Wed, 16 Dec 2020 08:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research in Programming Languages (2012)]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25439629">thread link</a>) | @swyx
<br/>
December 15, 2020 | http://tagide.com/blog/academia/research-in-programming-languages/ | <a href="https://web.archive.org/web/*/http://tagide.com/blog/academia/research-in-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://tagide.com/blog/academia/research-in-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439629</guid>
            <pubDate>Wed, 16 Dec 2020 06:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Far Cry: How the Fire Burns and Spreads (2012)]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25437800">thread link</a>) | @fctorial
<br/>
December 15, 2020 | https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/ | <a href="https://web.archive.org/web/*/https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
			
<h2>INTRO</h2>



<p>A few years ago, I got the opportunity to architect and code the fire propagation system in Far Cry 2. &nbsp;At that time, &nbsp;it was a gigantic task and it scared the hell out of me. Luckily, it turned out well enough.</p>



<p>With the upcoming Far Cry 3, several people recently asked me how the system worked. I realized that I never took the time to write it down. So, before I forget and also because it might be useful to somebody out there, here’s a high level overview of its inner workings. &nbsp;Pretty programmer art included as a bonus.</p>



<p><em>Disclaimer: Although Far Cry 3 uses the same system I wrote, I was not involved in the project. They may or may not have changed / adapted or modified the algorithms. What I describe below is accurate for Far Cry 2.</em></p>



<figure><p>
<iframe title="Far Cry 3 incredible fire demo video" width="640" height="360" src="https://www.youtube.com/embed/zcmbWqJjCN4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>BASE STRUCTURE</h2>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACell1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>A 2D Grid good for grass fire. &nbsp;Here, a fire cell has 50 hitpoints</figcaption></figure></div>



<p>At the core, the fire propagation system is quite simple. Since gameplay is what’s important, we&nbsp;sacrifice some of the realism for fun. The fire propagation in&nbsp;Far Cry 2 &nbsp;(and Far Cry 3) has just enough realism to maintain the player’s&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Suspension_of_disbelief">suspension of disbelief</a>,&nbsp;but certainly not enough to get published anytime soon. Because I like to&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/KISS_principle">keep things simple</a>, it doesn’t involve any complicated mathematics, physics or fluid dynamics. That has the additional advantage to be fast to simulate and easy to understand.</p>



<p>The secret sauce is an&nbsp;equally spaced grid. It is true for grass, for objects as well as for trees. The only difference is that we use a 2D grid for grass and a 3D grid for objects and trees.</p>



<p>Each cell of the grid has a position in the world, a radius and&nbsp;<strong>hitpoints</strong>. The cells have a plethora of&nbsp;properties, but these three are the bare minimum to propagate fire.</p>



<h2>LIGHT MY FIRE! HOW TO START ONE?</h2>



<p>The game engine tracks all damage done in the game, might it be bullet shots, impacts or fire damage. When a game entity is damaged, it is notified by an event. The damage event includes how much damage was done, what kind it was and what caused it.&nbsp;&nbsp;If the kind of damage was fire based and the entity is flammable, then at least two things happen:</p>



<ul><li>Firstly, the fire grid is dynamically created for the damaged entity. We create them dynamically because we don’t want those grids&nbsp;to exist in the wild for no reasons. That would take memory, disk space, etc, so we create them as we go. But, once created, it remains as long as the game entity exists.</li></ul>



<ul><li>Secondly, we figure out which cell in the grid is closest to the damage source. That cell then takes the damage and its hitpoints are reduced accordingly.</li></ul>



<p>That’s where things get interesting – When a cell has been damaged by fire and has lost all its hitpoints;&nbsp;<strong>it catches fire</strong>.</p>



<p>While burning, the cell becomes a damager itself. It deals damage to its neighbour cells on the grid; cells that share an edge with it. By doing so, it reduces their hitpoints and when in turns these cells have lost all their hitpoints, they catch fire. That’s how the propagation is created.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg 700w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1-300x220.jpg 300w" sizes="(max-width: 700px) 100vw, 700px"><figcaption>Fire propagating from left to right. The cells on the fire front are being damaged.</figcaption></figure></div>



<p>Lastly, a cell from the grid as a finite lifetime. Otherwise, it would burn forever. It can be seen as the amount of energy given by the material that is burning. &nbsp;For instance,&nbsp;a piece of paper would most likely burn faster than a wood log, so it would be given a shorter lifetime value.</p>



<p>That’s it. A fully functional fire propagation system good enough for a AAA game!</p>



<h2>TECHNICALITIES</h2>



<p><strong>Simulate wet jungle VS dry patch of grass</strong><br>How to simulate a wet jungle versus a dry patch of grass? They behave differently. Quite easily!<br>Increase the fire cell’s hitpoints and it’s difficult to set it on fire and it’s slow to propagate.&nbsp;Decrease its burning lifetime and the fire dies out quickly. There, you just simulated a wet jungle environment.</p>



<p><strong>How to create the propagation grids</strong></p>



<p><strong><em>Grass / Land</em></strong><br>For grass wildfire, &nbsp;an axis-aligned 2D grid is built in realtime and projected on a 3D terrain. For each of the cell, we take care to determine if the cell position is underwater, or under an object such as a rock or a building. In which case, we disable that cell and it can no longer catch fire. We wouldn’t want to have fire propagating under rock, would we?<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg 512w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled-300x220.jpg 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>2D grid projected on a terrain. The cells under the rock are disabled.</figcaption></figure></div>



<p><strong><em>Objects</em></strong><br>For objects, it’s a little bit more complicated. First, we create an&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Bounding_volume">AABB</a>&nbsp;that entirely surrounds the object. &nbsp;Second, we somehow&nbsp;need to detect the shape of that object. After all, it could be a chair, an oil barrel or a whole house for all we know. To accomplish that, the &nbsp;bounding box is divided in equally spaced cubes.&nbsp;The size of each cube depends of the object size, the number of fire emitter we want to have, performance, memory, etc.</p>



<p>An iterative algorithm then go through all those cubes and test their location against the collision shape of the object.&nbsp;If the test return a positive result, this cube is kept, otherwise it is discarded. At the end, we have a collection of cubes that approximately&nbsp;represent the shape of the object to be burned. That’s our propagation grid.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg 800w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-300x183.jpg 300w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-768x469.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>Detection of the shape of an object</figcaption></figure></div>



<h2><strong>WIND EFFECT</strong></h2>



<p>The wind is an important disruptive factor for a wildfire and it adds a great layer of realism for the player. &nbsp;Here it could be tempting to&nbsp;over-think&nbsp;the design and go with a very complicated system. After all, it’s an active area of research and&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S1540748912001988">several</a>&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S0378475407002030">papers</a>&nbsp;on the subject are available online.</p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S0378475407002030-gr3-300x235-1.jpg" alt=""></figure></div>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S1540748912001988-gr3.jpg" alt=""></figure></div>



<p>Luckily, with what have been explained thus far, it’s quite easy to simulate if we accept to cut corners a bit.</p>



<p>In our system, the fire propagates by damaging the&nbsp;neighbor&nbsp;cells on a grid. And it is generally accepted that a fire should spread faster in the direction of the wind than against&nbsp;the wind? Then, with that in mind, we can create a rule where a burning cell deals more damage to its&nbsp;neighbor&nbsp;cells if that neighbor is in the direction of the wind.</p>



<p>We do that by getting the&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Dot_product">dot product</a>&nbsp;between the wind direction&nbsp;vector and the direction of the&nbsp;neighbor&nbsp;cell to damage.&nbsp;If the result is greater than zero, then that node is dealt greater damage. &nbsp;Likewise, if the result is negative, &nbsp;the node is against the wind and should be dealt less damage. To be fancy, the amount of damage is interpolated with the dot product result as shown in the picture below.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>The cell on fire causes more damage to its neighbor cells if they are in the direction of the wind.</figcaption></figure></div>



<p>With that rule alone, you will get a nice bell shaped fire front that propagates in the direction of the wind. Simple, yet believable&nbsp;enough to get the player’s stamp of approval.</p>



<p>It’s worth noting that we simulate gravity the exact same way.</p>



<h2>PROPAGATING TO THINGS AROUND AND CHAIN REACTIONS</h2>



<p>When a cell burns, it sends a “I’m on fire and I burn this much in this radius” message down&nbsp;the game event pipeline. This event is caught by objects, AI and other game systems that are in that area. They react&nbsp;to this message their own specific ways. The AI freaks out, the flammable objects get damaged and eventually catch fire. And, &nbsp;it is also true for dynamic objects. &nbsp;For example, if a burning oil barrel goes flying through the map, every step of the way, &nbsp;it will send that “i’m burning” message and a lot of things around might hear it.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg 719w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone-300x284.jpg 300w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>In the absence of wind, a cell on fire damages equally all its neighbors.</figcaption></figure></div>







<p>This causes a chain reaction effect where trees, explosive items, &nbsp;objects and patches of grass set each others on fire. &nbsp;It’s completely&nbsp;systemic and it makes it much more believable. It &nbsp;also scores pretty high on the&nbsp;player’s&nbsp;fun meter because it behaves as one would expect, yet as real fire, it sometimes gets totally out of control.</p>



<h2>OPTIMISATION</h2>



<p><strong>The Hair Transplant Strategy</strong></p>



<p>In an ideal world, we would have access to enough memory to hold&nbsp;an infinite number of particle emitters and we could display an infinite number of particles on screen.&nbsp;Unfortunately, the reality is that those numbers are actually pretty low.</p>



<p>To do more with less, we have to put our emitters where it really counts. Enters the hair transplant strategy! &nbsp;In Far Cry 2, the fire emitters are constantly being teleported around, most importantly, from the back of the camera to the front. The player’s point of view is monitored at all time and emitters that are burning out of sight are moved to a better location where they are also needed.</p>



<p>In addition, the emitters’s density is higher in close proximity of the player and lower as the distance increases. A kind of fire&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Level_of_detail">LOD&nbsp;</a>if you will.&nbsp;If things are getting bad and we still need more emitters but none are available, we increase the particle sizes to give them more volume and fill more space on screen.</p>



<p>With this strategy, and some others, we can simulate a wildfire that is several meters wide with a relatively low number of particle emitters.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/farc2-300x169.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>Credits: http://www.rockpapershotgun.com</figcaption></figure></div>



<p><strong>Event Pipeline</strong><br>Since the described system tried to avoid all complicated maths, generally speaking we will be GPU bound before being&nbsp;CPU bound.</p>



<p>That being said, the event pipeline could be a bottleneck. It works well when you have just a few cells on fire. But, it’s another story when you have thousands of them burning and&nbsp;advertising&nbsp;their state to the world. That will likely clog your CPU’s arteries.</p>



<p>The trick for me was to regroup the cells that were burning into&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Axis-aligned_bounding_box#Axis-aligned_minimum_bounding_box" target="_blank" rel="noreferrer noopener">AABB</a>&nbsp;groups. These groups would constantly merge, split and&nbsp;change shape to follow the evolution of the fire. The events would then be sent per AABB instead of per cell, which saves&nbsp;a significant amount of processing power. Additionally, the events would be spread out across several frames in order to distribute the load and avoid framerate spikes.</p>



<p><strong>Keeping things under control.</strong><br>In your game, if you don’t constrain the propagation somehow, it will either</p>



<ul><li>Burn the entire map and kill all the NPCs</li><li>Fill out the …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</a></em></p>]]>
            </description>
            <link>https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437800</guid>
            <pubDate>Wed, 16 Dec 2020 01:13:40 GMT</pubDate>
        </item>
    </channel>
</rss>
