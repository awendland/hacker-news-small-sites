<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 28 Aug 2020 00:57:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 28 Aug 2020 00:57:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[YC Software Startups: Value and Initial Programming Language Used]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24279611">thread link</a>) | @charliereese
<br/>
August 25, 2020 | https://charliereese.ca/article/top-50-y-combinator-tech-startups | <a href="https://web.archive.org/web/*/https://charliereese.ca/article/top-50-y-combinator-tech-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

			<div>

				<p>This article contains a list of the top 50 YC software startups (sourced from the October 2019 <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page). It also contains aggregated statistics for valuations and back-end programming languages used.</p>
<p>Values in this article are sourced, but I cannot guarantee their accuracy.</p>
<p>Follow me on Twitter <a href="https://twitter.com/charlieinthe6">@charlieinthe6</a> for similar content. <a href="https://news.ycombinator.com/item?id=24279611">View article comments on HackerNews</a>.</p>
<p>☕</p>
<p><strong>Table of Contents:</strong></p>
<ol>
<li><a href="#top-50">Top 50 Software Startups</a></li>
<li><a href="#stats">Aggregated Stats</a></li>
</ol>
<h3 id="top-50">1. Top 50 Software Startups:</h3>
<table>
<thead>
<tr>
<th>Company</th>
<th>Latest val ($MM)</th>
<th>Initial back-end language(s)</th>
<th>DataSci / LowLv</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://stripe.com/">Stripe</a>: <br>Payment / economic infrastructure for internet</td>
<td>36,000 <small> <a href="https://detroit.cbslocal.com/2020/08/11/general-motors-cfo-exits-suddenly-for-silicon-valley/">source</a> </small></td>
<td>Ruby <small> <a href="https://qr.ae/pN2pJk">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://getcruise.com/">Cruise</a>: <br>Building self-driving car tech</td>
<td>19,000 <small> <a href="https://www.thedrive.com/tech/27872/gm-cruise-divisions-new-1b-investment-sets-valuation-at-staggering-19b">source</a> </small></td>
<td>C++, Python <small> <a href="https://angel.co/company/cruise-automation/jobs/757823-staff-deep-learning-optimization-engineer">source</a>, <a href="https://angel.co/company/cruise-automation/jobs/841627-staff-software-engineer-c-frameworks">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://airbnb.com/">Airbnb</a>: <br>Marketplace to rent someone’s room</td>
<td>18,000 <small> <a href="https://sanfrancisco.cbslocal.com/2020/08/11/airbnb-ipo-reportedly-close-to-filing-wsj/">source</a> </small></td>
<td>Ruby <small> <a href="https://www.forbes.com/sites/quora/2018/02/20/what-technology-stack-does-airbnb-use/#448ff4184025">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://doordash.com/">DoorDash</a>: <br>Food delivery</td>
<td>16,000 <small> <a href="https://www.cnn.com/2020/06/18/tech/doordash-funding-valuation/index.html">source</a> </small></td>
<td>Python <small> <a href="https://medium.com/@DoorDash/implementing-rest-apis-with-embedded-privacy-a2394dc4dceb">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://twitch.tv/">Twitch</a>: <br>Gaming video platform / community</td>
<td>15,000 <small> <a href="https://www.cnbc.com/2020/06/16/amazon-media-assets-worth-500-billion-almost-as-much-as-aws-needham.html#:~:text=To%20get%20to%20%24500%20billion,business%20is%20at%20%243.8%20billion.">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://blog.twitch.tv/en/2015/12/18/twitch-engineering-an-introduction-and-overview-a23917b71a25/">source</a> (founded before Go)</small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://instacart.com/">Instacart</a>: <br>Grocery pick-up / delivery</td>
<td>13,700 <small> <a href="https://techcrunch.com/2020/06/11/instacart-raises-225-million-at-13-7-billion-valuation/">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/the-tech-behind-instacarts-grocery-delivery-service">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://dropbox.com/">Dropbox</a>: <br>File hosting / syncing</td>
<td>8000 (market cap @ Aug 2020) <small> <a href="https://finance.yahoo.com/quote/DBX?p=DBX">source</a> </small></td>
<td>Python <small> <a href="https://eranki.tumblr.com/post/27076431887/scaling-lessons-learned-at-dropbox-part-1">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://coinbase.com/">Coinbase</a>: <br>Cryptocurrency exchange</td>
<td>8,000 <small> <a href="https://www.coindesk.com/coinbase-existing-valuation-doesnt-need-ipo-lawyer-says">source</a> </small></td>
<td>Ruby <small> <a href="https://blog.coinbase.com/scaling-connections-with-ruby-and-mongodb-99204dbf8857">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://gusto.com/">Gusto</a>: <br>Employee payroll and benefits</td>
<td>3,800 <small> <a href="https://www.forbes.com/sites/donnafuscaldo/2019/07/24/gusto-amasses-3-8-billion-valuation-with-latest-fundraising-round/#50e7fa8d2820">source</a> </small></td>
<td>Ruby <small> <a href="https://boards.greenhouse.io/gusto/jobs/1337386?t=bae6d7cd1">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rappi.com/">Rappi</a>: <br>On-demand delivery</td>
<td>3,500 <small> <a href="https://techcrunch.com/2020/04/08/ifood-merges-with-delivery-heros-domicilios-com-to-challenge-rappi-in-colombia/">source</a> </small></td>
<td>Go, Node, Python, Java <small> <a href="https://www.rappi.com/jobs/position-detail?id=b88ad33f-7ad5-4e3b-8ecb-f13a3cce3a6a&amp;lang=lang">source</a> (may have used PHP - no source)</small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://flexport.com/">Flexport</a>: <br>Freight forwarding platform</td>
<td>3,200 <small> <a href="https://www.joc.com/technology/wework-spanner-flexports-works_20191021.html">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/how-flexport-builds-software-to-move-over-1-billion-dollars-in-merchandise">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://reddit.com/">Reddit</a>: <br>Online network of communities</td>
<td>3,000 <small> <a href="https://techcrunch.com/2019/02/11/reddit-300-million/">source</a> </small></td>
<td>Lisp <small> <a href="http://www.aaronsw.com/weblog/rewritingreddit">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://about.gitlab.com/">GitLab</a>: <br>DevOps platform</td>
<td>2,750 <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/09/17/gitlab-doubles-valuation-to-nearly-3-billion/#483591ce1794">source</a> </small></td>
<td>Ruby <small> <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://brex.com/">Brex</a>: <br>Corporate credit cards</td>
<td>2,750 <small> <a href="https://techcrunch.com/2020/05/19/brex-brings-on-150m-in-new-cash-in-case-of-an-extended-recession/">source</a> </small></td>
<td>Elixir <small> <a href="https://medium.com/brexeng/why-brex-chose-elixir-fe1a4f313195">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://pagerduty.com/">PargerDuty</a>: <br>SaaS incident response platform</td>
<td>2,270 <small> <a href="https://www.google.com/search?tbm=fin&amp;q=NYSE:+PD&amp;stick=H4sIAAAAAAAAAONgecRowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uXj10_UNDdOyCwszkotLeBaxcvhFBrtaKQS4AAASRGHASAAAAA&amp;sa=X&amp;ved=2ahUKEwjCtra68ZbrAhUYXc0KHdn_DoAQ3ecFMAB6BAhqEBc&amp;biw=1278&amp;bih=968#scso=_Z4c0X5TmCsjOtQbEu5zQAQ1:0">source</a> </small></td>
<td>Ruby <small> <a href="https://www.pagerduty.com/blog/elixir-at-pagerduty/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://checkr.com/">Checkr</a>: <br>Background checks</td>
<td>2,200 <small> <a href="https://www.forbes.com/sites/bizcarson/2019/09/19/checkr-background-funding-round/#552c8c845460">source</a> </small></td>
<td>Ruby <small> <a href="https://engineering.checkr.com/yet-another-attempt-at-faster-builds-caching-db-schema-efe63d367f5">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://podium.com/">Podium</a>: <br>Interaction management platform</td>
<td>1,500 <small> <a href="https://techcrunch.com/2020/04/07/utahs-podium-raises-125m-series-c-led-by-yc-after-reaching-100m-arr/">source</a> </small></td>
<td>Ruby <small> <a href="https://devchat.tv/elixir-mix/emx-072-people-centered-solutions-with-travis-elnicky/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://segment.com/">Segment</a>: <br>Customer data platform</td>
<td>1,500 <small> <a href="https://www.bloomberg.com/news/articles/2019-04-02/startup-segment-is-worth-1-5-billion-thanks-to-companies-troves-of-customer-data">source</a> </small></td>
<td>Go, JS <small> <a href="https://www.workatastartup.com/companies/88">source</a>, <a href="https://angel.co/company/segment/jobs/348613-senior-software-engineer">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://docker.com/">Docker</a>: <br>Build / deliver software in containers</td>
<td>1000 est. <small> <a href="https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise/">source</a>, <a href="https://techcrunch.com/2018/10/15/docker-has-raised-92-million-in-new-funding/">source</a> </small></td>
<td>Go <small> <a href="https://thenewstack.io/go-programming-language-helps-docker-container-ecosystem/">source</a>, <a href="https://techcrunch.com/2019/11/13/after-selling-enterprise-biz-docker-lands-35m-investment-and-new-ceo/">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://scale.com/">Scale</a>: <br>Training / validation data for ML</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/stevenli1/2019/12/22/scale-ai-growth-story/#3360214b6f4a">source</a> </small></td>
<td>Python, JS <small> <a href="https://scale.com/careers/41e05b90-7e65-4dac-8676-50be9c1afc27">source</a>, <a href="https://scale.com/careers/37b0c485-cd77-4170-ac07-a8521b9a10fc">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://amplitude.com/">Amplitude</a>: <br>Product / customer analytics</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/davidjeans/2020/05/20/amplitude-now-valued-1-billion-backed-sequoia-benchmark/#68a1ad2041c7">source</a> </small></td>
<td>Python, Java <small> <a href="https://news.ycombinator.com/item?id=13301832&amp;p=2">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://zapier.com/">Zapier</a>: <br>Connect apps and automate workflows</td>
<td>1000 est. (20x 2018 ARR) <small> <a href="https://www.drift.com/blog/how-zapier-grew/">source</a> </small></td>
<td>Python <small> <a href="https://zapier.com/blog/zapier-tech-stack/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://faire.com/">Faire</a>: <br>B2B wholesale marketplace</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/laurendebter/2019/10/30/faire-wholesale-marketplace-series-d-1-billion-valuation/#21c2bdfb7aa9">source</a> </small></td>
<td>Java <small> <a href="https://boards.greenhouse.io/faire/jobs/4187498002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://plangrid.com/">PlanGrid</a>: <br>Construction software</td>
<td>875 <small> <a href="https://techcrunch.com/2018/11/20/autodesk-agrees-to-buy-plangrid-for-875-million/#:~:text=Autodesk%20announced%20plans%20to%20acquire%20PlanGrid%20for%20%24875%20million%20today.">source</a> </small></td>
<td>Python <small> <a href="https://stackoverflow.com/jobs/companies/plangrid">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a>: <br>User analytics</td>
<td>865 <small> <a href="https://www.forbes.com/pictures/feki45efhmk/mixpanel/#71dc3892190f">source</a> </small></td>
<td>Python<small> <a href="https://boards.greenhouse.io/mixpanel/jobs/1545756?gh_jid=1545756">source</a> (founded before Go)</small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://benchling.com/">Benchling</a>: <br>Biotech research</td>
<td>850 <small> <a href="https://www.forbes.com/sites/amyfeldman/2020/05/28/biotech-rd-software-startup-benchling-started-by-mit-undergrads-scores-850-million-valuation-amid-coronavirus-pandemic/#5de0e0c61dcd">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/445">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://meesho.com/">Meesho</a>: <br>Social commerce platform</td>
<td>700 <small> <a href="https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/meesho-raised-125-mn-from-naspers-and-others/articleshow/70641492.cms">source</a> </small></td>
<td>Java <small> <a href="https://angel.co/company/meesho/jobs/596045-software-development-engineer-iii">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://optimizely.com/">Optimizely</a>: <br>Digital experience optimization / testing</td>
<td>600 <small> <a href="https://pitchbook.com/newsletter/optimizely-brings-in-50m#:~:text=Optimizely%2C%20which%20operates%20an%20optimization,with%20participation%20from%20Accenture%20Ventures">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=2647003">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://algolia.com/">Algolia</a>: <br>Search service</td>
<td>578 <small> <a href="https://www.bizjournals.com/sanfrancisco/news/2019/10/15/fast-growing-san-francisco-search-company-scores.html">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://www.algolia.com/doc/faq/why/what-architecture-does-algolia-use-to-provide-an-high-performance-search-engine/">source</a>, <a href="https://stackshare.io/posts/how-algolia-built-their-realtime-search-as-a-service-product">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://goat.com/">Goat</a>: <br>Sneaker marketplace</td>
<td>550 <small> <a href="https://www.forbes.com/sites/kurtbadenhausen/2019/02/07/foot-locker-invests-100-million-in-secondary-sneaker-firm-goat/#3b07b65e568d">source</a> </small></td>
<td>Ruby <small> <a href="https://www.workatastartup.com/jobs/20990">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://standard.ai/">StandardCognition</a>: <br>Autonomous checkout</td>
<td>535 <small> <a href="https://techcrunch.com/2019/07/25/standard-cognition-lands-35m-at-535m-valuation-to-battle-amazon-go/">source</a> </small></td>
<td>Python <small> <a href="https://jobs.lever.co/standard/9b874041-7cfe-4e0a-a459-fcd66451ee75">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://people.ai/">People.ai</a>: <br>Intelligent CRM</td>
<td>500 <small> <a href="https://techcrunch.com/2019/05/21/people-ai-the-predictive-sales-startup-raises-60m-at-around-500m-valuation/#:~:text=People.ai%2C%20the%20predictive%20sales,around%20%24500M%20valuation%20%7C%20TechCrunch">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/1299">source</a>, <a href="https://news.ycombinator.com/item?id=16974829">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://razorpay.com/">Razorpay</a>: <br>Digital payments</td>
<td>450 <small> <a href="https://www.pymnts.com/news/investment-tracker/2019/razorpay-sequoia-india-ribbit-capital/#:~:text=With%20the%20funding%2C%20Razorpay%20is,Razorpay%20X%20neo%2Dbanking%20platform.">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=12407955">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://equipmentshare.com/">EquipmentShare</a>: <br>Equipment rentals</td>
<td>400 est. <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/11/18/softbank-looks-to-invest-equipmentshare-unicorn/#48a6b2d779b8">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=16492994&amp;p=2">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://weebly.com/">Weebly</a>: <br>Website builder</td>
<td>365 <small> <a href="https://techcrunch.com/2018/04/26/square-acquires-weebly/">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=2839742">source</a>, <a href="https://news.ycombinator.com/item?id=5729035">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://webflow.com/">Webflow</a>: <br>Website builder</td>
<td>350 <small> <a href="https://growthhackers.com/articles/how-webflow-quietly-grew-without-vc-money?r=latest">source</a> </small></td>
<td>JS <small> <a href="https://boards.greenhouse.io/webflow/jobs/1838218">source</a>, <a href="https://www.workatastartup.com/companies/566">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://matterport.com/">Matterport</a>: <br>3D technology platform</td>
<td>325 <small> <a href="https://techcrunch.com/2019/03/05/matterport-2/#:~:text=Matterport%20had%20raised%20just%20under,DCM%2C%20Qualcomm%20Ventures%20and%20more.">source</a> </small></td>
<td>C++ <small> <a href="https://news.ycombinator.com/item?id=3300290">source</a>, <a href="https://news.ycombinator.com/item?id=5186626">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://influxdata.com/">InfluxData</a>: <br>InfluxDB creator</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/influxdb/company_financials">source</a> </small></td>
<td>Go <small> <a href="https://github.com/influxdata/influxdb">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://embarktrucks.com/">Embark</a>: <br>Self-driving trucks</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/embark-trucks/company_financials">source</a> </small></td>
<td>Python, C++ <small> <a href="https://jobs.lever.co/embark/25999d12-5d82-45fc-b3e4-0ebc335f6f59">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://sendbird.com/">SendBird</a>: <br>Chat / calls as a service</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sendbird/company_financials">source</a> </small></td>
<td>Python <small> <a href="https://sendbird.com/careers/4317963002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rescale.com/">Rescale</a>: <br>Cloud simulation platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rescale/company_financials">source</a> </small></td>
<td>Java, Python <small> <a href="https://news.ycombinator.com/item?id=5828217">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://gocardless.com/">GoCardless</a>: <br>Direct debit payments</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/gocardless/company_financials">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=14978103">source</a>, <a href="https://news.ycombinator.com/item?id=16283469">source</a>, <a href="https://news.ycombinator.com/item?id=4596703">source</a>, <a href="https://boards.greenhouse.io/gocardless/jobs/2282283">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rigetti.com/">Rigetti Computing</a>: <br>Quantum computing</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rigetti-computing/company_financials">source</a> </small></td>
<td>Python, Lisp, C <small> <a href="https://news.ycombinator.com/item?id=16968407">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://messagebird.com/">MessageBird</a>: <br>Omnichannel customer communication</td>
<td>300 <small> <a href="https://www.fool.com/investing/2020/03/13/twilio-investors-keep-tabs-on-startup-messagebird.aspx">source</a> </small></td>
<td>Go, PHP, Python, Java <small> <a href="https://careers.sh/uk/kompaniya/messagebird/robochi-mistsya/71009">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://ironcladapp.com/">Ironclad</a>: <br>Digital contracting platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/ironclad/company_financials">source</a> </small></td>
<td>JS, Java <small> <a href="https://jobs.lever.co/ironcladapp/2d6616e3-27b8-4138-a6fc-238e46757822">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://sift.com/">Sift</a>: <br>Digital safety and fraud detection</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sift-science/company_financials">source</a> </small></td>
<td>Java, Ruby <small> <a href="https://news.ycombinator.com/item?id=6657091">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://mattermost.com/">Mattermost</a>: <br>Open source Slack alternative</td>
<td>250 est. <small> <a href="https://app.dealroom.co/companies/mattermost">source</a> </small></td>
<td>Go <small> <a href="https://github.com/mattermost/mattermost-server">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://xendit.co/">Xendit</a>: <br>Digital payments</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS <small> <a href="https://www.workatastartup.com/companies/938">source</a>, <a href="https://www.xendit.co/en/careers/job-application/?gh_jid=4114942003">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://easypost.com/">EasyPost</a>: <br>Logistics software</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=6231587">source</a>, <a href="https://news.ycombinator.com/item?id=13542390">source</a>, <a href="https://www.linkedin.com/jobs/view/senior-software-engineer-at-easypost-1669977835/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://newfrontinsurance.com/">Newfront</a>: <br>Insurance platform</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS, Go <small> <a href="https://www.keyvalues.com/newfront">source</a>, <a href="https://news.ycombinator.com/item?id=21683554">source</a> </small></td>
<td>N / N</td>
</tr>
</tbody>
</table>
<p><small>
<p>Note: Ginkgo Bioworks, Boom Supersonic, Grin, Memebox, Helion Energy, North, RelativitySpace, and The Athletic were excluded from the below list; I didn't feel they were primarily software businesses. Feel free to disagree with my judgement.</p>
<p>Note: values current as of August 15, 2020.</p>
<p>Note: if one language was the primary language used to build the initial product, one language is listed above. If it was not clear which language was primary, multiple languages are listed above.</p>
<p>Note: if I couldn't find which language was used to build the startup initially, I referenced the oldest job posting I could find.</p>
<p>Note: valuations are approximate and predominantly sourced from recent articles online. Where I couldn't find an indication of value, ~$150M is assumed; startups listed above were all worth +$150M as of October 2019, as per the <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page.</p>
<p>Note: "Y" and "N" values in the "DataSci / LowLv" column describe a startup's primary product (i.e. ML startups would have a "Y" for DataSci). It was included to provide additional colour on why initial back-end language(s) may have been used / selected. The values in this column are based entirely on my own judgement. Feel free to disagree with them or ignore them.</p>
<p>Note: Ruby and ruby on rails was a popular choice for YC startups around 2010 - 2012. Anecdotally, ~40% of YC startups used ruby during its peak popularity.</p>
</small></p>

<h3 id="stats">2. Aggregated Stats:</h3>

<p><strong>Startups with one (initial) primary back-end language:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>35 (70%)</td>
<td>132.1 (75%)</td>
</tr>
<tr>
<td>Ruby</td>
<td>13 (26%)</td>
<td>92.4 (52%)</td>
</tr>
<tr>
<td>Python</td>
<td>11 (22%)</td>
<td>29.9 (17%)</td>
</tr>
<tr>
<td>Lisp</td>
<td>1 (2%)</td>
<td>3.0 (2%)</td>
</tr>
<tr>
<td>Elixir</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>Java</td>
<td>2 (4%)</td>
<td>1.7 (1%)</td>
</tr>
<tr>
<td>Go</td>
<td>3 (6%)</td>
<td>1.6 (1%)</td>
</tr>
<tr>
<td>PHP</td>
<td>2 (4%)</td>
<td>0.8 (0%)</td>
</tr>
<tr>
<td>JS</td>
<td>2 (4%)</td>
<td>0.5 (0%)</td>
</tr>
<tr>
<td>C++</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>

<p><strong>Startups with multiple (initial) primary back-end languages:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>15 (30%)</td>
<td>44.4 (25%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>4 (8%)</td>
<td>34.9 (20%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>8 (16%)</td>
<td>25.7 (15%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>3 (6%)</td>
<td>15.9 (9%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>5 (10%)</td>
<td>6.5 (4%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>6 (12%)</td>
<td>5.7 (3%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>4 (8%)</td>
<td>5.5 (3%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "Startups with multiple (initial) primary back-end languages" table doesn't add to 100% because multiple languages were used for startups.</small></p>

<p><strong>All startups:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>50 (100%)</td>
<td>176.5 (100%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>16 (32%)</td>
<td>108.3 (61%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>19 (38%)</td>
<td>55.6 (32%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>5 (10%)</td>
<td>35.2 (20%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>8 (16%)</td>
<td>7.4 (4%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>2 (4%)</td>
<td>3.3 (2%)</td>
</tr>
<tr>
<td>Elixir is one</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>3 (6%)</td>
<td>1.1 (1%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "All startups" table doesn't add to 100% because multiple languages were used for some startups.</small></p>
				
			</div>

		</article></div>]]>
            </description>
            <link>https://charliereese.ca/article/top-50-y-combinator-tech-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279611</guid>
            <pubDate>Wed, 26 Aug 2020 06:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCI Express Retimers vs. Redrivers: An Eye-Popping Difference (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24278760">thread link</a>) | @tragiclos
<br/>
August 25, 2020 | https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/ | <a href="https://web.archive.org/web/*/https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Retimers and redrivers have enabled longer physical channels in servers and storage systems since Peripheral Component Interface Express (PCIe) 3.0 was first introduced almost 10 years ago. Now that PCIe 4.0 is ramping up and PCIe 5.0 is just around the corner, how do these reach extension tools stack up in the face of new challenges in high-speed connectivity?</p>
<p>A redriver is a mostly analog reach extension device designed to boost the high-frequency portions of a signal to counteract the frequency-dependent attenuation caused by the interconnect: the central processing unit (CPU) package, system board, connectors and so on. A redriver’s data path typically includes a continuous time linear equalizer (CTLE), a wideband gain stage and a linear driver. In addition, redrivers often have input loss-of-signal threshold and output receiver (Rx) detection capability. Figure 1 illustrates a typical redriver block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg" alt="" width="731" height="419" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg 731w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-300x172.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-260x150.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-523x300.jpg 523w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-200x115.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-564x323.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-600x344.jpg 600w" sizes="(max-width: 731px) 100vw, 731px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 1: Redriver block diagram [1]</a></p>
<p>A retimer is a mixed signal analog/digital device that is protocol-aware and has the ability to fully recover the data, extract the embedded clock and retransmit a fresh copy of the data using a clean clock. In addition to the CTLE and wideband gain stages also found in a redriver, retimers contain a clock and data recovery (CDR) circuit, a decision feedback equalizer (DFE) and a transmit (Tx) finite impulse response (FIR) driver. Finite state machines (FSMs) and/or a microcontroller typically manage the automatic adaptation of the CTLE, wideband gain, DFE and FIR driver, and implement the PCIe link training and status state machine (LTSSM). Figure 2 illustrates a typical retimer block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg" alt="retimer-block" width="787" height="440" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg 787w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-300x168.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-768x429.jpg 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-260x145.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-537x300.jpg 537w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-200x112.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-564x315.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-600x335.jpg 600w" sizes="(max-width: 787px) 100vw, 787px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 2: Retimer block diagram [1]</a></p>
<p>In simple terms, a redriver amplifies a signal, whereas a retimer retransmits a fresh copy of the signal. Figure 3 illustrates this and shows how an attenuated eye opening is boosted by a redriver and completely regenerated by a retimer.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png" alt="eye-attenuated" width="1024" height="238" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-300x70.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-768x178.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1536x357.png 1536w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-260x60.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-800x186.png 800w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-200x46.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-564x131.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-600x139.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated.png 1658w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>Figure 3: Example of an eye attenuated by a channel (left), the eye after a redriver (middle) and the eye after a retimer (right)</p>
<p>The PCIe 4.0 specification took the unprecedented step of formally defining the terms “retimer,” “redriver” and the superset term “repeater,” all of which are types of extension devices or components whose purpose is to extend the physical length of a link. The definitions are:</p>
<ul>
<li><strong>Repeater</strong>: An imprecise term for an extension device [2]. (This term causes confusion … please don’t use it!)</li>
<li><strong>Redriver</strong>: A non-protocol-aware software-transparent extension device [2].</li>
<li><strong>Retimer</strong>: A physical layer protocol-aware, software-transparent extension device that forms two separate electrical link segments [2].</li>
</ul>
<h3>Use Cases for Retimers and Redrivers</h3>
<p>Reach extension devices are necessary whenever the channel – the electrical path between the root complex (RC) and endpoint (EP) – is longer than the PCIe specification allows. The specification defines the maximum channel length in terms of insertion loss at the Nyquist frequency (an informative specification, but easy to validate) and in terms of a reference receiver’s ability to sufficiently equalize and recover the data assuming a worst-case link partner transmitter (a normative specification, but time-consuming to validate).</p>
<p>Suffice it to say, at PCIe 4.0 speeds, reach extension devices are necessary for:</p>
<ul>
<li>Multiconnector topologies.</li>
<li>Cabled topologies.</li>
<li>Single-connector add-in card (AIC) topologies with baseboard channels longer than 9.5 inches.</li>
</ul>
<p>Figure 4 shows an example of a two-connector “riser card” topology, which ordinarily would exceed the PCIe 4.0 loss budget of 28 dB. A redriver or retimer will enable reliable, error-free communication between the RC and EP. But how do you choose which one is the right tool for the job? Well, it helps to know more about the fundamental differences in their capabilities.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png" alt="redriver" width="1024" height="391" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-300x115.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-768x293.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-260x99.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-785x300.png 785w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-200x76.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-564x216.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-600x229.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver.png 1120w" sizes="(max-width: 1024px) 100vw, 1024px"><br>
Figure 4: Example of redriver (top) and retimer (bottom) used in a two-connector topology</p>
<h3>Comparing Retimer and Redriver Capabilities</h3>
<p>Not all redrivers and retimers are the same. There are many distinctions between the two, which are universally true for all PCIe reach extension devices. For example:</p>
<p><strong>Retimers actively participate in the PCIe protocol; redrivers do not.</strong> The PCIe base specification spells out how and to what extent retimers participate in the protocol during Detect, Recovery, L0 and other LTSSM states. Equalization to the L0 and L1 link states requires value-added functionality from the retimer (handshakes, timeouts, bit manipulation, etc.). Redrivers are unaware of and unparticipating in the protocol. If the link works reliably the first time, that’s great! But if the link experiences marginality of any sort, it becomes exceedingly difficult to pinpoint whether the problem is physically before the redriver or after it, since the redriver’s role in link formation is undefined and unknown to its link partners.</p>
<p><strong>Retimers reset the jitter and insertion loss budgets; redrivers do not.</strong> A retimer’s CDR fully recovers the data stream and retransmits it on a clean clock. Starting with a fresh copy of the data enables the extension of the channel to twice the original specification. Without a CDR, the best a redriver can do is attenuate (not reset) the data-dependent jitter (DDJ) caused by intersymbol interference (ISI). A redriver cannot attenuate uncorrelated or random jitter (RJ). In fact, a redriver will always add to RJ due to its own device thermal noise in a root-mean-square (RMS) manner <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>.</p>
<p><strong>Retimers have a DFE; redrivers do not.</strong> A DFE compensates for reflections in the channel response caused by impedance discontinuities in board vias, connectors and package socket-board interfaces. The nice thing about a DFE is that it is unaffected by crosstalk. The DFE equalizes just as well in the presence of crosstalk, and once the data is sampled by the retimer’s CDR, crosstalk is eliminated for good. Redrivers use a CTLE that boosts both the signal and the noise <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. Crosstalk is not eliminated or even attenuated through a redriver; in fact, it gets amplified.</p>
<p><strong>Retimers automatically adapt their receive and transmit equalizers to match the characteristics of the channel and the link partner’s needs; redrivers do not.</strong> A retimer will examine the signal it receives and adjust the CTLE and DFE to minimize its own bit error rate (BER). Likewise, the retimer’s transmitter will adjust its de-emphasis and pre-shoot equalization to minimize the link partner’s BER according to PCIe equalization protocol. A redriver, conversely, operates with a static equalizer setting. The optimal setting (which can be different for every channel in the system) is often painstakingly selected following an exhaustive search in Input/Output Buffer Information Specification (IBIS) algorithmic modeling interface (AMI) simulations and again in lab testing – a process fondly referred to as “tuning.”</p>
<p><strong>Retimers have built-in features to help diagnose link issues (both electrical and protocol); redrivers do not.</strong> Retimers have tools for assessing the electrical performance (internal eye monitors, pattern generators, pattern checkers) and protocol performance (link state history monitors, timeout adjustments). Redrivers cannot offer such diagnostic features because they are neither protocol-aware nor aware of the actual data passing through. Redrivers do not know what state the link is in.</p>
<p><strong>Retimers correct for lane-to-lane skew; redrivers do not.</strong> PCIe has a tight requirement on the physical skew between lanes on a board (1.6 ns for PCIe 4.0), typically caused by mismatches in channel routing length [3]. Retimers are required to compensate and reset any lane-to-lane skew, effectively doubling the specification budget. Redrivers cannot compensate for lane-to-lane skew, and what’s worse is that they may degrade the skew depending on how symmetric the redriver package is across all lanes.</p>
<p><strong>Retimers can be placed anywhere between two PCIe-compliant channels; redrivers cannot.</strong> By definition, retimers extend the total PCIe channel reach by two times the specification. A redriver’s reach extension, however, depends on where it is placed in the channel – how much loss is before the redriver versus how much is after <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. The specific placement of a redriver must be carefully determined by IBIS-AMI simulation and experimentation. Too close to the root complex transmitter, and the redriver’s CTLE will enter nonlinear operation and will have limited benefit. Placed too far from the transmitter, the redriver’s device noise may significantly degrade the signal-to-noise ratio (SNR) of the data signal.</p>
<p>It’s not all bad news for redrivers. They do have lower power consumption and lower input-to-output latency compared to retimers. But if the link does not form in the first place or if the BER is too high, none of that matters!</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png" alt="comparision" width="809" height="527" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png 809w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-300x195.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-768x500.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-230x150.png 230w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-461x300.png 461w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-200x130.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-564x367.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-600x391.png 600w" sizes="(max-width: 809px) 100vw, 809px"></p>
<p>Table 1: Comparison of retimer and redriver capabilities and usage</p>
<h3>Outlook for PCIe 4.0 Systems</h3>
<p>Looking ahead to the upcoming PCIe 4.0 systems, all signs are pointing to an increased need for reach extension devices – and retimers in particular – due to several trends and challenges:</p>
<ul>
<li>CPUs have more PCIe lanes per socket (&gt;100 in some cases [4]) compared to PCIe 3.0. This leads to a greater number of PCIe slots and riser cards, denser routing, and an increased use of multiconnector topologies.</li>
<li>PCIe is shifting from an I/O bus to a multipurpose system interconnect. This means that more servers will be designed to be modular, allowing an array of compute, storage and networking resources to plug in to an increasing number of PCIe slots. This type of open, “plug anything in and it will work” server architecture requires a reach extension solution that is PCIe compliant with plug-and-play interoperability.</li>
<li>The disaggregation of resources such as modular servers, storage trays and accelerator trays is pushing endpoints physically away from CPUs, requiring cables or carrier cards to connect everything together. These longer physical topologies will increasingly need reach …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</a></em></p>]]>
            </description>
            <link>https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278760</guid>
            <pubDate>Wed, 26 Aug 2020 03:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Embrace Beginner's Mind; Avoid the Wrong Way to Be an Expert]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24277832">thread link</a>) | @7d7n
<br/>
August 25, 2020 | https://eugeneyan.com/writing/beginners-mind/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/beginners-mind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>When we learn something new, such as a programming language, we start as beginners. We can learn and follow the rules and apply them in a narrow context. However, we don’t understand the bigger picture and get lost outside of that specific context.</p>

<p>Imagine that I enroll in a <a href="https://en.wikipedia.org/wiki/Massive_open_online_course" target="_blank">MOOC</a> on <code>R</code> and learn about statistical analysis, machine learning, and <a href="https://rstudio.github.io/shinydashboard/" target="_blank"><code>Shiny</code></a> dashboards. As part of machine learning, I learn that I should <a href="https://www.rdocumentation.org/packages/caret/versions/6.0-86/topics/createDataPartition" target="_blank">split the data into train and test</a> sets. I apply this in assignments and Kaggle and everything works fine—this is the <em>narrow</em> context.</p>

<p>Then, perhaps I get the opportunity to apply my new skills in a <em>wider</em> context—I build a model, validate it (via random train-test split), and deploy it. However, the offline and online (i.e., A/B test) metrics don’t match up. Eventually, I figure out that I should use a <a href="https://www.fast.ai/2017/11/13/validation-sets/" target="_blank">time-based split</a> so future data doesn’t <em>leak</em> into the training set.</p>

<p>With the benefit of the wider context, I encountered challenges and failures (read: lessons) that were not part of the MOOC assignments. As a result, I got to see the bigger picture; I know there’s still lots to learn. Thus, I continue to learn and progress through the stages of beginner, intermediate, and so on.</p>

<blockquote>
  <p>The more I learn, the more I realise how much I don’t know. – Albert Einstein</p>
</blockquote>

<h2 id="from-beginner-to--expert-beginner">From beginner to … expert beginner</h2>

<p>But what happens if I <em>don’t</em> see the bigger picture?</p>

<p>Let’s assume I work in the HR department of a widget manufacturer. Everything—from headcount to payroll to vacation balance—is run in Excel. I apply my newfound <code>R</code> skills to automate my work via one-off scripts. This involves calculating statistics on factory sites and displaying it via a <code>Shiny</code> dashboard on the department desktop. In the eyes of my manager and team, I’m an absolute rockstar ninja wizard. I get showered with praise and am promoted to manager of HR data science.</p>

<p>I might not know about proper ML validation, deployment, unit tests, or even version control. I certainly haven’t done any of that. But who cares? We don’t need it. I’m now the manager of HR data science. I’m now… an “expert”.</p>

<p>To those in the know, I’m clearly still a beginner. But my context is narrow and I don’t see the bigger picture. Thus, I don’t know that there’s still lots to learn, lots to do. However, because I’ve achieved a modicum of success (through <em>narrow</em> applications of what I learned) and others call me an expert, I now view myself as an expert. As a result, I stop learning. I’m now stuck at a local optima. <strong>I’ve become an <a href="https://daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/" target="_blank">expert beginner</a></strong>.</p>

<p>Suppose I stay in that same role, within HR, for 10 years. At the end of it, do I have 10 years of experience, or one year of experience repeated 10 times?</p>

<details><summary>An army of expert beginners led by an expert beginner</summary>
<div>

<p>As head of HR data science, I hire a team of data scientists. Eventually, some team members will suggest new technology (e.g., Python, Docker) or practices (e.g., version control, unit testing).</p>

<p>However, I’m the most experienced (read: longest tenure) and the expert-est expert. I dismiss ideas and technology that I’m unfamiliar with. “Oh, I see you’re new here. Yes, Python sounds like a good idea but the Chief HR Officer really likes the <code><span>Shiny</span></code> dashboard that I built.” “Haha, we don’t need unit tests! I live and breathe this code every day—there’s no need to test it”.</p>

<p>Team members who can see the bigger picture are disappointed by the outdated technology and incorrect practices. They see no room for learning and growth. As a result, <strong>the most talented and ambitious leave</strong> (if they know what’s best for them). For those who stay—hurray! There’s less competition. They’ll toe the line and one day, they’ll be a <em>senior</em> expert beginner and teach new joiners their “expert” ways.</p>

<p>This leads to the <a href="http://brucefwebster.com/2008/04/11/the-wetware-crisis-the-dead-sea-effect/" target="_blank">Dead Sea effect</a> where you’re <strong>left with your least talented and effective</strong> people. They’re grateful to have a job and settle in for a couple of years (or decades). Now, the team has (d)evolved into an army of expert beginners who follow the directions of the top expert beginner.</p>

<p><img src="https://eugeneyan.com/assets/dead-sea.jpg" title="The expert beginners are entrenched and can’t be replace" alt="The expert beginners are entrenched and can’t be replace"></p>
<p>The expert beginners are entrenched and can’t be replaced (source: <a href="https://eugeneyan.com/writing/beginners-mind/(https://dilbert.com/strip/2010-12-02)">Scott Adams</a>)</p>

<p>Because expert beginners have learned “everything” there is to learn, tried “everything” there is to try, and done “everything” there is to do, there’s nothing new to learn, try, and do. The team stops trying new ideas—“Oh we don’t use Docker here. We have VMs!”—and the organization stops innovating.</p>

<p>This partly explains some industries getting disrupted. The iPhone disrupting Nokias and Blackberrys, AWS disrupting on-premise hardware, Stripe disrupting payment processing, Tesla disrupting… you get the idea.</p>

</div>
</details>

<p><img src="https://eugeneyan.com/assets/climbed-it-all.jpg" title="The expert beginner doesn't see the bigger picture and is thus stuck" alt="The expert beginner doesn't see the bigger picture and is thus stuck"></p>
<p>The expert beginner doesn't see the bigger picture; thus, he is stuck.</p>

<h2 id="the-beginners-mind-is-always-a-student">The beginner’s mind is always a student</h2>

<p>How do we prevent stagnation (and possibly becoming an expert beginner)? How do we stay open-minded and constantly learning and experimenting?</p>

<p><strong>One way is <a href="https://en.wikipedia.org/wiki/Shoshin" target="_blank">Shoshin</a> (beginner’s mind)</strong>. It’s a concept from Zen Buddhism on having an attitude of openness, eagerness, and no preconceptions, even when our knowledge of the subject is advanced. In other words, to think <em>just</em> like a beginner.</p>

<blockquote>
  <p>In the beginner’s mind there are many possibilities, but in the expert’s there are few. – Shunryu Suzuki</p>
</blockquote>

<p>With beginner’s mind, regardless of your experience and expertise, you <strong>stay curious and approach new ideas and experiences as a student</strong>. Even when new technology or methods don’t fit your paradigm, you’re open to learning and trying it. Students don’t say “That’s not how we do things here”.</p>

<p>Sometimes, when others view us as experts, we let it get to us. We stay within our narrow subject matter expertise and stop exploring new ideas and possibilities. We avoid newer, bigger challenges so we don’t make mistakes; we stick to what has worked in the past. This helps preserve our expert identity.</p>

<blockquote>
  <p>The most dangerous phrase in the language is, “We’ve always done it this way.” – Grace Hopper</p>
</blockquote>

<p>But this doesn’t make sense. In my field of data science, new tools (e.g., Spark, Docker, Airflow) and methods (e.g., embeddings, attention, pre-training) constantly improve on the state of the art (SOTA)—it’s useful, if not essential, to keep up to date. (That said, fundamental techniques like regression and decision trees are often a solid baseline.)</p>

<h2 id="the-beginners-mind-keeps-on-pedalling">The beginner’s mind keeps on pedalling</h2>

<p>Learning is like cycling. When we start pedalling (from a standstill), it takes effort and time to gain momentum. Nonetheless, we’ll pick up speed and begin gaining distance.</p>

<p>We might look back at where we started and think “Wow, I’ve come a long way. Perhaps I don’t have to pedal as hard; perhaps I don’t have to pedal at all.” If we stop pedalling, the initial momentum might carry us slightly further, but eventually, we’ll come to a standstill. While we don’t lose the distance covered, we’re not gaining distance either. (Though in fast-paced fields like tech, if you don’t move forward, <em>you begin to move backward</em>.)</p>

<p>Here, distance is knowledge (and achievements); momentum is learning. While distance is correlated with expertise, the relationship is not as strong as we think (e.g., one year of experience repeated 10 times). I think momentum (the ability to learn and adapt quickly) is part of expertise as well. The experts I know are often reading or hacking. At work, they can synthesize their mental prototypes and tailor solutions based on context.</p>

<p>To maintain momentum, <strong>the beginner’s mind continues to pedal regardless of the distance they’ve covered</strong>. It’s not surprising that many successful people are—and continue to be—voracious readers and learners. Warren Buffet, Bill Gates, Elon Musk, just to name a few. Do you know any successful person that doesn’t read or learn?</p>

<blockquote>
  <p>The illiterate of the 21st century will not be those who cannot read and write, but those who cannot learn, unlearn, and relearn. – Alvin Toffler</p>
</blockquote>

<details><summary>Note: Not all knowledge is the same</summary>
<div>

<p>There’s knowledge that we gain from books and courses—we’re tested on this in exams. Then, there’s <a href="https://commoncog.com/blog/the-tacit-knowledge-series/" target="_blank">(tacit) knowledge</a> that we gain from practice—we’re tested on this in life.</p>

<div>

<blockquote><div lang="en" dir="ltr"><p>You cannot get educated by this self-propagating system in which people study to pass exams, and teach others to pass exams, but nobody knows anything.</p><p>You learn something by doing it yourself, by asking questions, by thinking, and by experimenting. 🧠</p></div>— Richard Feynman (@ProfFeynman) <a href="https://twitter.com/ProfFeynman/status/1295411496407556096?ref_src=twsrc%5Etfw">August 17, 2020</a></blockquote>

</div>

<p>For example, learning to ride a bicycle. We can’t learn to ride a bike by reading a textbook. The <strong>only way to learn is by actually doing it</strong>. We’re going to lose balance and fall, but eventually, we’ll figure it out. Also, our ability to ride a bike is <strong>transferable</strong> to other two-wheeled transport. Once we learn how to ride a regular bike, we’ll have a gentler learning curve on mountains bikes, tandem bikes, and even e-scooters.</p>

<p>Similarly, some skills and knowledge <strong>can only be gained through practice</strong>. They’re usually <strong>transferable</strong> across multiple domains too. For example, what’s the most suitable way to <a href="https://bugra.github.io/posts/2020/5/25/how-to-serve-model/" target="_blank">serve models in production</a>? There are some common patterns: compute offline and cache, serve via microservice, embed in the main app. Do these patterns differ across domains? Not much. Which is the best approach for our use case? Well, it depends—knowing the answer is tacit knowledge.</p>



<p>Often, such skills and knowledge are <strong>fundamental</strong> and can be thought of as building blocks (or <a href="https://jamesclear.com/first-principles" target="_blank">first principles</a>). For example, in programming, we learn about conditionals, iteration, and data structures. In distributed data processing, we learn about map, reduce, and shuffle. Once we understand these fundamentals, it’s easier to pick up another programming language or distributed processing framework. It also helps us write more effective software and <a href="https://en.wikipedia.org/wiki/Extract,_transform,_load" target="_blank">ETL</a> jobs.</p>

<p>Mastering the fundamentals also helps with the <a href="https://commoncog.com/blog/to-get-good-go-after-the-metagame/" target="_blank">metagame</a>. The meta (i.e., higher-order factors) changes constantly. For example, <a href="https://eugeneyan.com/writing/nlp-supervised-learning-survey/" target="_blank">natural language processing</a> has evolved rapidly from recurrent models to embeddings to attention to …</p></div></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/beginners-mind/">https://eugeneyan.com/writing/beginners-mind/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/beginners-mind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277832</guid>
            <pubDate>Wed, 26 Aug 2020 00:28:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's it like as a Senior Engineer?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24277414">thread link</a>) | @benkwokcy
<br/>
August 25, 2020 | https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>When I started working at Microsoft, fresh out of college, coding was my life. Writing code was the easiest way to build any cool thing that my brain could imagine. &nbsp;When I thought about what I’d want to do for the rest of my life I thought that I just wanted to keep coding. </p><p>During the next 11 years I became a Senior Engineer at Microsoft and moved on to work at Google and later Stripe. At these higher levels I still get to build, but I use a very different set of tools to do it. There’s a huge mindset shift needed when you go from junior to senior. Writing code becomes a minor part of the job. </p><p>Ever built a tool no one used? I have. It sucked. At the senior levels most of your time goes into identifying <strong>what </strong>needs to be built and <strong>how </strong>to build it. You have to research what the problem looks like. You talk to others and get everyone to agree on what needs to be done. </p><p>These are your new tools:</p><ul><li>Research the problem</li><li>Design the solution</li><li>Build consensus</li></ul><h2 id="research-like-a-detective">Research like a Detective</h2><p>Fresh out of college you get handed tasks where the right answer is pretty straightforward. There isn’t much disagreement on what to do other than the occasional feedback in code reviews.</p><p>As you get more experienced your problems become more ambiguous. The path looks hazy. There are multiple routes you could take, but each one hides its own dragons. It’s not about coding anymore. Most of your work goes into research, and you can’t google the answer.</p><p>Research can take many forms. It usually involves a combination of reading code, reading documentation, and talking to people. Yes, actual human beings. In fact, that’s where most of the information you’ll need is locked away. Did you ever see Sherlock Holmes using search engines? </p><figure><img src="https://lh3.googleusercontent.com/8zyhAq2HSKAYAzysnJfbR_m6ZCBloCL5jbUmlwLEnJnmErsiHzd6gOEPtMpJZIp961AlNxUrdloY4B3cFFpVca5iH7Xb3wJgj0rFG7TLO60IGey4TaOJGZITimTXGv7U9hXqh-Pp" alt=""></figure><p>There often is no single person who knows the answer you need. Five different people might hold five different pieces of the puzzle you’re assembling. And you don’t know who those five people are. And they don’t know which pieces you need.</p><p><em>You </em>have to find them. Find them and ask the right questions to sift through their brains, uncovering the nuggets you need.</p><h6 id="sifting-for-nuggets">Sifting for nuggets</h6><p>At Google Cloud Platform, customers would often contact the Technical Solutions Engineers for help when they ran into issues. Those TSEs dug into the problems and fixed them. </p><p>My manager had an idea: “Wouldn’t it be great if we could use AI to automate that process?” We had no clue how to do it. Didn’t even know if it was possible. Heck, we weren’t even sure what kind of problems customers were asking for help with. But that was the challenge my manager offered.</p><p>I accepted.</p><p>Now any AI solution for this kind of a problem requires lots of data. The AI needs to see many broken environments to understand what they look like. And as I searched around I realized we didn’t have that data, it was all locked away in the brains of those TSEs. You can’t train AI with that. </p><p>I had to find the patterns. Maybe chatting with the TSEs would reveal something...</p><p>Me: “So, what type of problem do you usually face?”</p><p>TSE: “Eh, it’s something different every time”</p><p>Darn it, The AI future was looking bleak. </p><p>Me: “Well, what do you do to solve it?”</p><p>TSE: “It depends. Based on the problem, we’ll query one database or another. Then that’ll point us somewhere else, and we keep digging until we find what’s wrong. Then we fix it.”</p><p>No solid data on what problems they solve. No repeatable way to fix them. I was ready to give up.</p><p>Wait a second.</p><p>“Tell me more about these queries you run?”</p><p>What if I changed the problem? Maybe I didn’t have to fix those customer issues right off the bat. What if I helped TSEs debug the problems faster? I could automatically run the hundreds of queries they might run and suggest “Hey, this one had a suspicious result. Maybe dig a bit deeper there?” That’s a lot of debugging the TSEs could avoid.</p><p>I could even extend this to collect the data needed for an actual an AI system. This had potential! The TSEs were excited. My team was excited. My manager was excited. We began coding.</p><h2 id="design-the-art-of-balance">Design: The Art of Balance</h2><p>With ambiguous problems there is no single right answer anymore. There might not be any answer. What you have is a pain point. It could be your customers’s pains, your team’s pains, or even your own pain. The existence of that pain is the problem. Your job is to remove that pain without introducing even greater pains.</p><p>There’s a funny thing about ambiguous problems: they don’t have a clear right answer. Every solution offers certain benefits and has certain downsides. The more of those you discover, the better you’ll be at balancing the tradeoffs you have to make. Some common trade offs to consider:</p><ul><li>How long will it take to develop the solution?</li><li>What’s the opportunity cost?</li><li>How risky is it? What happens if that thing fails?</li><li>How much work will it be to maintain this going forwards?</li><li>How far will it scale? How far does it need to?</li></ul><p>With these ambiguous problems, sometimes the best answer can be “keep doing the thing we’ve been doing.” That was a tough lesson to learn. </p><h6 id="young-and-naive">Young and Naive</h6><p>When I was a wee lad four years out of college, I had been asked to come up with a way to make our database upgrades less risky. The team would manually review all the planned changes to make sure they were safe, but once in a while a bug would slip though and the sound of pagers going off would fill the room as everyone frantically tried to fix it.</p><p>“Can we build a tool to catch those risky changes?” my manager asked me. Woah, this was a super open ended problem. Sweet! I was determined to not let him down. This required digging deep into database upgrade best practices (I even read a whole <a href="https://martinfowler.com/books/refactoringDatabases.html">book on it</a> cover to cover). I spent the winter holidays toiling away developing a prototype that could do upgrades safely. And it worked! Kinda.</p><p>When I showed my creation to my manager he was worried: “You know what, let’s just stick with doing things the way we do right now.” </p><p>Ouch. </p><p>It was a tough lesson on risk management, but he made the right call. A bug in my tool could have brought our entire service down. It wasn’t worth the risk.</p><figure><img src="https://lh6.googleusercontent.com/-SpPwF1sWOPZD0HnYx0IqqluusAVritix1g7_NToe3s93jEmkPTsYhCTHJdPh7axMdLIN6gZ0fJ1_01AiPDputH2wPnMBXTDmgfxYIFAicsQeyAlq8Y9fRTxBFljmx9FZYi1Pdcy" alt=""></figure><p>There were multiple lessons I learned that day:</p><ul><li>Consider how much risk any new project might add to the system</li><li>It’s okay to fail. If you never fail then you’re not stretching yourself</li><li>Get feedback early! </li></ul><p>To get that feedback communication is crucial. Tell people what you’re going to build before you build it and let them warn you about any pitfalls before you step into one. If I had shared that design with my manager before building it we would have cancelled the project weeks earlier. And I would have had a relaxing winter break.</p><p>But collecting feedback requires a soft skill: empathy.<strong> </strong>Can you understand why people disagree with you? What are they valuing differently?</p><p>You may not always agree with the feedback, but you have to understand it. Only then can you move forward with a new vision that everyone can get behind.</p><h2 id="build-consensus">Build Consensus</h2><p>Getting that feedback and agreeing on the plan grows more important as your projects get bigger.</p><p>You may start off just having to get your manager to agree (he’s the one who gave you that ambiguous task). But you’ll need to build consensus with the rest of your team and even people outside your team who have a stake in your work. </p><p>This requires communication skills, both to understand and be understood.</p><p>Once I was tasked with creating the next generation of our internal database management system. This was something many teams depended on, and our current solution would stop scaling a year or two down the line. My team had seven different people with eight different opinions about what the system should look like. That included my manager and skip level. Oy vey. </p><p>First step was talking to them all to really understand their concerns and priorities. But there was another voice I wanted to hear from: our customers! This was meant to be a system for other engineering teams, how could I build a solution for them without understanding their problems? &nbsp;It took a bit of digging to even figure out who those users were. This required another soft skill: The art of finding the person you need to talk to.</p><p>Eventually I got into a room with them. There they dropped the bombshell “We can’t really justify the work to migrate to any new system. The current one works well enough for us right now and we have more urgent problems to fix.” I talked to three different teams and got the same answer each time. Damn, what’s the point of building a solution if no one will use it?</p><p>A migration had to happen, soon the current system would stop meeting our reliability standards. There were a couple routes forwards:</p><ul><li><em>Politics</em>: Get my management chain to convince their management chain to force the teams to migrate. Yuck</li><li><em>Persuasion</em>: Teach those teams why this pain that they won’t feel for a few years is more important to fix than the pains they’re facing today. That’s a hard thing to prove, and we’d have to make this case to many, many teams. That doesn’t scale well</li></ul><p>There was a third option: change the constraints. What if I said ‘no’ to some of the features I’d been asked to add? Removing that let me design the system in a way that we could migrate all our customers automatically. There would be zero work required from them to migrate. We’d swap the engine with the car still zooming down the highway.</p><p>This was much more palatable. And by highlighting our user’s push back I convinced the other stakeholders to change drop those constraints as well.</p><figure><img src="https://lh5.googleusercontent.com/uQ8pUq_dwFP6BBDO1d66HKZNGs5DrxtbLCoKc0NxnrsvpHOlh_C_Pi9yUcoU7XLi9TiYkRKy_4QItN3s3pWBVlNCfm2MZYyECTrdEHaJsQVTVxqmV4GPVzEFXJaRxpS5wqloltjj" alt=""></figure><p>That’s the general flow of any project you work on at the senior levels: You research the problem, gather the pieces, understand the world better. You design a solution, collect feedback and adjust course as needed. Then the implementation begins.</p><p>So how do you learn all these skills? Experience. Jump out of the nest and flap your wings. If an opportunity shows up, take it. You won’t feel ready, no one does, but that’s what makes it a learning experience.</p><p>Ask for help. Listen to the answers you get. Keep trying. At the end of the project ask for …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/">https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</a></em></p>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/whats-it-like-as-a-senior-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277414</guid>
            <pubDate>Tue, 25 Aug 2020 23:20:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You want people to do the right thing? Save them the guilt trip]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24277190">thread link</a>) | @canada_random1
<br/>
August 25, 2020 | https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Major global problems </strong>such as racial injustice or climate change often seem insurmountable. Itâ€™s hard to believe that our individual actions can make any real difference. Yet we know that many social dilemmas are overcome only through collective action. They call for people to make behavioural changes without any direct personal benefits â€“ in fact, these changes often come at a personal cost. So what might motivate people to adopt such a â€˜prosocialâ€™ mindset?</p>
<p>Researchers have explored a range of answers to this puzzle. A central line of enquiry relates to emotions and self-perception. Thereâ€™s a close link between emotions and behaviour: feelings motivate us to pursue goals, seek positive reinforcement and avoid punishment. But which emotional route is the most promising â€“ to make people feel bad about their shortcomings, or to encourage them to have a positive self-image because theyâ€™ve done â€˜the right thingâ€™?</p>
<p>There are good arguments both ways. Guilt can be a powerful motivator for action; the feeling of wanting to â€˜make upâ€™ for something can lead to reparative action. On the other hand, feeling good about our actions and what they reflect about who we are can elicit positive emotions. These feelings can then provide us with the energy and mental resources to engage in difficult problems, or to â€˜give to othersâ€™.</p>
<p>Itâ€™s important to distinguish here between guilt that arises internally, and guilt thatâ€™s externally induced. If we feel guilty about failing to recycle our plastics or adopt a vegetarian diet, we might be motivated to engage in reparative action. But if someone buttonholes us over dinner and tries to make us feel bad about our lifestyle choices, the picture might look very different; we might become defensive and try to justify our actions, which drives us further away from changing the way we behave. These scenarios then raise doubts about whether negative self-directed emotional appeals will be effective at promoting prosociality.</p>
<p>In a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188781">study</a> that my colleagues and I conducted at Columbia University in New York, we set out to test the consequences of positive versus negative self-directed emotions. Participants were prompted to think about either how guilty they felt about non-environmentally friendly behaviour, or how proud they might be for acting to preserve the environment. They were then asked a range of questions, such as whether they would pay increased rent to have more energy-efficient appliances, how likely they were to take public transport, and whether theyâ€™d be willing to use reusable shopping bags and mugs. Those participants who had been thinking of how proud they would feel about themselves chose to have a higher number of energy-efficient appliances compared with those participants who had been asked to think about personal guilt. Furthermore, participants in the pride group expressed higher intentions to engage in green behaviours compared with those in the guilt group. These findings suggest that inducing people to consider positive rather than negative self-directed emotions might recruit more people to a climate-change mitigation agenda, and to prosocial behaviour more broadly.</p>
<p>This potential advantage â€“ of appealing to positive emotions over negative ones â€“ links up with what we know about human self-perception. Having a positive self-image about who we are and what we do is a fundamental human need. When weâ€™re balanced and on good terms with ourselves, we are more energetic and have greater cognitive and emotional resources. By contrast, when we feel bad about ourselves, itâ€™s much more difficult to be prosocial â€“ especially if those feelings and actions arenâ€™t geared towards friends and family, but a removed, impersonal â€˜greater goodâ€™. Satisfying our important internal needs as emotional creatures can help us free up prosocial resources for others.</p>
<p>Research on self-affirmation supports this picture. In one <a href="https://academiccommons.columbia.edu/doi/10.7916/D84J1XJH">study</a>, we prompted one set of participants to engage in a self-affirming exercise. This involved reflecting on the values and behaviours that were important to them, and that they appreciated in themselves. Another group completed an unrelated exercise, describing the layout of the store at which they shop most frequently. This second â€˜controlâ€™ group allowed us to quantify the effect of the self-affirmation exercise.</p>
<p>Feeling good about ourselves can translate into acts of kindness towards others, for the benefit of society at large</p>
<p>Both groups were entered into a raffle to win a $10 bonus, and were given the option to either keep the money for themselves or to donate all or a portion to a selection of charities with varying missions and beneficiaries. The â€˜affirmationâ€™ group reported feeling more positively about themselves and more at peace with themselves â€“ and whatâ€™s more, these positive self-directed emotions translated into increased levels of charitable giving compared with those participants who had engaged in the unrelated exercise.</p>
<p><strong>My colleagues and</strong> I were curious about whether the effects of a positive self-image would extend to more challenging contexts, such as when the beneficiaries of prosociality were members of a marginalised group. In a field <a href="https://spssi.onlinelibrary.wiley.com/doi/full/10.1111/josi.12374">study</a> in Nigeria, we investigated how the public felt about enhanced social support for ex-prisoners. Like many other nations, Nigeria has high rates of recidivism. Social stigma means that those released from prison often struggle to secure jobs or have a supportive social network, which feeds into a cycle of reoffending. Interventions that reduce stigma and enhance social support can help ex-offenders to successfully reintegrate into society.</p>
<p>For the study, members of the general public in Nigeria were asked to engage in the self-affirming exercise prior to answering a range of survey questions. The results were striking. The self-affirmed participants showed more prosocial intentions and decreased discriminatory tendencies, compared with participants in the control group. They were more comfortable with having an ex-prisoner as their neighbour, for instance, and indicated stronger intentions to help an ex-prisoner whose employer was discriminating against them. They also expressed more willingness to invest personal time and effort to provide social support, such as participating in a tutoring programme for ex-prisoners.</p>
<p>Follow-up research in the United States replicated these results. Obtaining these findings in two studies and two different countries suggests that these effects can be generalised. The fact that a positive self-image can enhance prosociality doesnâ€™t seem to depend on a particular culture but could be an intrinsic part of human behaviour more generally. Feeling good about ourselves doesnâ€™t just enhance individual wellbeing by fulfilling a fundamental human psychological need; it can also translate into acts of kindness towards others, for the benefit of society at large.</p>
<p>A positive self-image can create a flywheel effect, in which the resulting prosocial behaviour sends a social signal to others. If others discriminate less, we are less likely to do so; if people in our social groups recycle more and watch their carbon footprint, we are more likely to do so. Getting a critical mass to â€˜join inâ€™ and acknowledging problems can, over time, help to shift norms â€“ which are drivers, not just inhibitors, of human behaviour.</p>
<p>The potential of positive self-directed emotions has largely not been embraced by activists. The worry could be that it might make those engaging in the cause appear self-satisfied or selfish. But these studies suggest that, instead of focusing on â€˜doom and gloomâ€™ messaging that zooms in on peopleâ€™s shortcomings and risks alienating them, policymakers and strategists might find that positive messaging, speaking to peopleâ€™s positive sense of self, might be a more powerful lever of behavioural change.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277190</guid>
            <pubDate>Tue, 25 Aug 2020 22:50:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak Smalltalk on a PostmarketOS Cellphone]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24276883">thread link</a>) | @tonyg
<br/>
August 25, 2020 | https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Back in 2007, when <a href="https://en.wikipedia.org/wiki/Openmoko">Openmoko</a>
was first a thing, I
<a href="https://leastfixedpoint.com/tonyg/kcbbs/openmoko-info.html">wrote an Erlang-based userland</a>
that got to the point of being able to take and make calls and receive
and send SMS. The project stalled: the Openmoko GTA01 was too slow,
its power-management too primitive, and Erlang’s GUI facilities too
rudimentary to make further work worthwhile.</p>

<p>Modern cellphone hardware is <em>much</em> more capable. Is it time to have
another run at the idea of a mobile personal computer?</p>

<figure>
<p><a href="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png"><img src="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png" alt="Erlang OpenMoko userland (2008)"></a>
Erlang OpenMoko userland (2008)</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg" alt="PostmarketOS on my cellphone"></a>
PostmarketOS on my cellphone</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg" alt="PostmarketOS Weston demo"></a>
PostmarketOS <a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo</p>

</figure>

<h3 id="postmarketos-is-awesome">PostmarketOS is awesome</h3>

<p>Last week, I installed <a href="http://postmarketos.org/">PostmarketOS</a> on my
previous cellphone, a Samsung Galaxy S7 (using PostmarketOS’s
<a href="https://wiki.postmarketos.org/wiki/Samsung_Galaxy_S7_(samsung-herolte)">samsung-herolte</a>
configuration).</p>

<p>PostmarketOS turns out to be a beautifully engineered system that’s
easy to understand and modify. The basics of kernel and Alpine Linux
userland installed cleanly and easily on the phone, and it’s running
well as a development platform. I’m looking forward to getting into
PostmarketOS more deeply.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/pm-htop-20200825.png"><img src="https://eighty-twenty.org/images/pm-htop-20200825.png" alt="htop running on my cellphone"></a>
<code>htop</code> running on my cellphone. Six cores!</p>
</figure>

<p>Running <code>htop</code> on the phone shows what an <em>amazing</em> little machine it
is! So much power. Loads of cores, lots of RAM. Plenty of space to
explore alternative visions of mobile personal computing.</p>

<p>However, the built-in demos, such as the
<a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo (shown above
at right), currently leave quite a bit to be desired. Perhaps some of
the other
<a href="https://wiki.postmarketos.org/wiki/User-Interfaces">user interface options</a>
included with PostmarketOS could get me closer to a day-to-day usable
cellphone - but I’m interested in running my own software! Let’s get
hacking.</p>

<h3 id="running-my-own-programs">Running my own programs</h3>

<p>PostmarketOS is a plain, clean Alpine Linux distribution. You can SSH
into it initially
<a href="https://wiki.postmarketos.org/wiki/USB_Network">via USB networking</a>.
From there, you can
<a href="https://wiki.postmarketos.org/wiki/WiFi#Using_NetworkManager">configure wifi using nmcli</a>,
set up SSH keys, and then access it directly using SSH over wifi.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg" alt="lflow: Framebuffer demo"></a>
<code>lflow</code>: Framebuffer demo</p>
</figure>

<p>Building software is just as simple:</p>

<figure><pre><code data-lang="shell"><span></span>apk add alpine-sdk</code></pre></figure>

<p>To experiment with drawing to the framebuffer and reading touchscreen
input via <code>/dev/input</code>, I compiled and ran an old
<a href="https://github.com/tonyg/mac-display-hacks/blob/a1fde2054f00588076218b76d7ecf34764e5f99e/lflow.c">quick and dirty framebuffer hack</a>
I wrote years ago. The results (shown at left) were encouraging: the
program effortlessly animates tens of thousands of points at 30 frames
per second, responding to touch inputs. Display is via brute-force
pixel output to the <code>mmap</code>‘d frame buffer. It doesn’t even use a full
core.</p>

<p>PostmarketOS turns a phone into a fully capable Linux machine, with
total control over the attached hardware, and with everything
accessible to the developer in the usual places using the usual tools.</p>

<p>But Unix tools are inappropriate for a mobile personal computing
platform. We’ll need something else.</p>

<h3 id="a-smalltalk-phone">A Smalltalk phone</h3>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg" alt="Squeak Smalltalk on PostmarketOS"></a>
Squeak Smalltalk
<a href="http://files.squeak.org/6.0alpha/Squeak6.0alpha-19812-64bit/">6.0-alpha</a>
on PostmarketOS</p>
</figure>

<p>Smalltalk could make an ideal basis for a mobile personal computing
platform.</p>

<p>I’ve <a href="https://eighty-twenty.org/tag/smalltalk">enjoyed</a> using,
developing with, and contributing to the
<a href="https://squeak.org/">Squeak Smalltalk</a> implementation since the mid
’00s.</p>

<p>So I compiled the
<a href="https://github.com/OpenSmalltalk/opensmalltalk-vm">Cog Smalltalk VM</a>
on the phone itself, making use of the 64-bit ARM support code that
landed extremely recently.</p>

<p>And lo and behold, it runs! Shown to the right is a bleeding-edge,
fully up-to-date Squeak 6.0-alpha image running on the phone itself.
(<a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg">Click here or on the image to embiggen.</a>)</p>

<p>From here, I can experiment with new ideas using the full power of a
modern Smalltalk environment.</p>

<h3 id="what-next">What next?</h3>

<p>My previous Openmoko experiments foundered, in part, on the GUI aspect
of the system; GTK+ via Erlang was fine for quick prototyping but
wasn’t really up to the task for a day-to-day usable machine.</p>

<p>I recall getting Squeak running on my GTA01, in order to see if it
could provide a viable UI. However, I remember being stymied by the
mismatch between the expectations of the Smalltalk environment and the
realities of the phone.</p>

<p>Squeak wants a mouse and keyboard. It assumes a monitor-sized display,
in everything from widget and font sizes to window management. To work
well on a phone, it needs a touchscreen-based, high-DPI UI in addition
to its existing toolset.</p>

<p>Smalltalk, in both its language aspect and its system design aspect,
also <a href="https://eighty-twenty.org/2011/05/08/weaknesses-of-smalltalk-strengths-of-erlang">suffers from some weaknesses in areas where Erlang shines</a>.</p>

<p>However, in the years since the GTA01:</p>

<ul>
  <li>
    <p>the hardware is much better,</p>
  </li>
  <li>
    <p>the Squeak VM and image are better,</p>
  </li>
  <li>
    <p>I’ve learned a heck of a lot about
<a href="https://syndicate-lang.org/tonyg-dissertation/html/">some good ways to design interactive systems</a>,
and</p>
  </li>
  <li>
    <p>I’ve recently
<a href="https://tonyg.github.io/squeak-actors/">built some tools that help bring Erlang- and Syndicate-style architectural patterns for concurrency to Smalltalk</a>.</p>
  </li>
</ul>

<p>So I think using Erlang/Syndicate-style
<a href="https://tonyg.github.io/squeak-actors/">Actors</a> to structure a
Smalltalk-based phone userland, perhaps with <code>cgroups</code>-based
sub-virtual-machines and images, could work well.</p>

<p>My initial experiments have concentrated on</p>

<ul>
  <li>
    <p>fixing the tiny fonts (the DPI-change support code in the image
needs work, and the support in the VM seems to be absent (?)),</p>
  </li>
  <li>
    <p>reading from the touchscreen (probably
<a href="http://lists.squeakfoundation.org/pipermail/squeak-dev/2016-June/190051.html">like this</a>),</p>
  </li>
  <li>
    <p>thinking about how to structure Actor supervision hierarchies and
<a href="https://syndicate-lang.org/tonyg-dissertation/html/#sec:Syndicate's-approach-to-concurrency">Dataspaces</a>
for a mobile phone (probably borrowing some design elements from my
earlier
<a href="https://github.com/tonyg/erlang-openmoko">Openmoko Erlang-based userland</a>),
and</p>
  </li>
  <li>
    <p>thinking about how to layer a touchscreen (panel-based?) GUI atop
Squeak’s <a href="http://wiki.squeak.org/squeak/morphic">Morphic</a> UI.</p>
  </li>
</ul>

<p>I’ll write more on this blog as things develop.</p>

<hr>

<p><strong>Update:</strong> <a href="https://eighty-twenty.org/2020/08/27/squeak-postmarketos-update">Some progress on the font front!</a></p>

  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276883</guid>
            <pubDate>Tue, 25 Aug 2020 22:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tipe raises $2.1M seed round to build a customizable CMS for developers]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24275948">thread link</a>) | @tmvnty
<br/>
August 25, 2020 | https://tipe.io/blog/tipe-raises-seed | <a href="https://web.archive.org/web/*/https://tipe.io/blog/tipe-raises-seed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Today we're excited to announce that tipe has raised $2.1m in seed funding led by CRV and joined by investors YC, M Ventures, and Precursor Ventures. This investment will help tipe deliver an excellent experience for developers and teams who need a better workflow for managing content. Since graduating from YC's Winter 18 batch, we've been building prototypes, talking with users, and learning from the community. We're finally ready to show everyone what we've learned.  </p><p>Teams are shifting away from legacy site builders to more sophisticated builds with frameworks like Next.js and Gatsby. Cloud computing, crawlers, and JavaScript have all approved and come together to enable this shift. Jamstack offers so many benefits for low effort but also introduces more decision making. Teams must now decide on a content workflow, and developers are on the hook to figure it out.</p><p>We want to make this decision easy for developers. </p><h2>Make it your own, together</h2><p>They always say, "...never build a CMS". We know every team has different needs and use cases when it comes to content workflows. Customization and extendability are at the core of tipe's design.  That's why tipe is open-source and has a simple plugin features that make it easy for you to create your own CMS.</p><p>We invest in the open-source community and all the efforts to create and maintain the fantastic projects leading the Jamstack wave. We encourage developers to use plugins and extensions for tipe created by the community. One of our goals is to make sure we're not another app devs have to maintain, so we'll be working with developers to make sure working with tipe stays lean and fast. </p><p>We can't do this alone, so today we're launching the <a href="https://join.slack.com/t/tipe-hq/shared_invite/zt-gfesfzxf-9KHj1Q3GPhUbUOa6PjNpTA">tipe community slack</a>ðŸŽ‰. You can interact with the tipe team more closely, see what the community is cooking up, or even get help for anything that comes up. </p><h2>Roadmap to the best experience</h2><p>Developer and user experience are our main focuses here at tipe. As we grow, we want to move towards a minimal and straightforward product to use but powerful when combined with plugins and extensions. To achieve this goal, we plan on maintaining transparency about the direction of tipe and what's coming next. We'll also be leaning on our users and the community to help us build something that they would love. </p><p>To start, we have support for Jamstack frameworks like Next.js and Gatsby, a CLI to get started without ever visiting our web app, and SDKs to query content. As the community grows and improves tooling, we'll support all that comes from it. Open-source is are core, well before tipe, and will remain that way as we grow. </p><h2>Perfect timing</h2><p>The web is transitioning into another era with all the moving pieces seeing significant enhancements. Now is the time to build a fast experience for your users. You can't do that if your team is slow, because of content changes or any reason.</p><p>We look forward to helping teams stay fast as they deliver amazing journeys for their users. Also, <a href="https://tipe.io/jobs">we're hiring</a>! If anything you read here resonates with you, we'd love to hear from you. </p></div></div></div>]]>
            </description>
            <link>https://tipe.io/blog/tipe-raises-seed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275948</guid>
            <pubDate>Tue, 25 Aug 2020 20:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DevOps, DataOps, and MLOps: the three waves of operationalization]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24275856">thread link</a>) | @mvartak
<br/>
August 25, 2020 | https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops | <a href="https://web.archive.org/web/*/https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Using machine learning models in products is hard. Most companies fail at extracting value from them because they can't operationalize models properly.</p>
<!--more-->
<p>We have gotten good at creating models and iterating on them, but <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/"><span>most companies still don't use them well</span></a>. A model with acceptable performance that you can use is better than a great model that you can't. Then why are companies having so many issues leveraging them?</p>
<p>In this blog post, we show that some challenges are analogous to those before DevOps. We’ll also show that others introduce a new level in the development and operation process that requires a new stack.</p>
<p>The lessons here come from building ML products and platforms at companies like Twitter, NVIDIA, Cloudera, Google, and others. These companies have invested heavily in building their in-house ML platforms or external products for a variety of scenarios.</p>

<h2><span>Moving development closer to operations</span></h2>
<p>Two decades ago, software development was painful. Developers and operators were silos, and making any changes was an adventure. DevOps helped us fix that with a simple shift in mindset: developers should own their software end-to-end, and operators should support them. Operators could focus on building robust IT infrastructure instead of handling each application individually. Meanwhile, developers could speed their development practices by using the tools as their product demanded. This change was the first wave of operationalization, and it changed how we do software.</p>
<p><img src="https://lh5.googleusercontent.com/AzBl9kIU1PCLQLTZQ91tKPpn7bAmjghns_vNHPdloZ-V3XytDuyTemoZn96xA_QEgwuxrVG5vxqSBFixSx2hEtOhiawWdwQ_Ix7TYS_sQ1A5pxbrFhGtT4cWw7rewEymlJqtQ1ya" width="453" height="283"></p>
<p><span>Around the same time, data started to become more relevant via analytics. The goal was to understand the data companies had available. Seeing the success of DevOps, analytics professionals partnered with their operators to create DataOps. In this case, analysts could focus on their business use case while operators made their use reliable.</span></p>
<p><span>Today, machine learning faces a similar challenge. The goal of ML is to help products make decisions on the spot. For example, which messages to show from a search query. These applications focus on actively improving the business instead of just providing insights. However, these more complex applications also have requirements we had never seen, and the operations world is just starting to adjust.</span></p>
<p><span>We now face a similar challenge for model developers that we have encountered before in software development:</span></p>
<ul>
<li><span>Data scientists don't own their work end-to-end. Instead, they send their models to a software developer and data engineer to build the machinery on a case by case basis.</span></li>
<li><span>Data scientists are frequently blocked, waiting for other developers to help them.</span></li>
<li><span>Data scientists are blind to the processes required to satisfy operations until it's too late. In which case, the work is dropped or re-done.</span></li>
</ul>
<h2><span>Why MLOps is so hard</span></h2>
<p><span>Using ML models in products is a quantum leap in their value, and every such significant change comes with paradigm shifts. Not only MLOps is hard on itself, but most companies are not prepared to practice it today if done naively. The challenges of adopting MLOps boils down to:</span></p>
<ul>
<li><span>You have to support multiple pre-existing tools in two isolated ecosystems;</span></li>
<li><span>Models have more dimensions in their requirements, and operate on a broader range of each trade-off;</span></li>
<li><span>You need to provide a self-service ecosystem for data scientists that currently don't have the operations skills that developers do;</span></li>
<li><span>Companies' processes on using ML must start where they're at today and adapt as their use advances;</span></li>
<li><span>ML adds an entirely new layer to the operations stack.</span></li>
</ul>

<h4><span>MLOps challenge 1: pre-existing ecosystems</span></h4>
<p>Software development and model development have pretty mature ecosystems today, with constant and fast improvements. However, these ecosystems are mostly isolated. Consider a core piece of infrastructure: the workflow system. Software engineers will most likely use Jenkins, GitLab, CircleCI, or any similar tools. However, data scientists use Airflow, Kubeflow, and other ML-targeted workflow systems. These two ecosystems might eventually combine, but this can take years and a lot of effort. Instead, we need to meet them where they are today.</p>

<p><img src="https://lh4.googleusercontent.com/GV0KR8tRUGnuk80NmXXCdUuZPwkoupXwKLisbeq2e8-wpmyqjKY0CMMmx6QwafOC61QboUsIC58ZegUYS4hSrfM8VO1Gbv7fgULTyuFPcH14hM_uQGgp1kFchIqQFEfJsAapbInQ" width="277" height="305"></p>
<p>From the data scientist's perspective, they need the infrastructure to be reliable. It should work in the way that they want almost always and provide all the functionality they want to use but not develop. The researcher isn't concerned with which tools achieve this goal, as long as it works with their current solutions.</p>
<p>On the other hand, IT provides a vibrant ecosystem of productivity tools, but they require applications to behave in a particular way. The challenge operators face with data science today is that adapting all those practices to the ML ecosystem is difficult and time-consuming. So they need the ML applications to look like applications they already support.</p>
<p>This golden standard is hard to achieve. Therefore most companies end up with multi-year migration projects that change how everyone does their job simultaneously. As you can imagine, these projects fail most of the time. Instead, we need to figure out how to get these two personas to collaborate first and get value from each other.</p>

<h4><span>MLOps challenge 2: dimensions of model requirements</span></h4>
<p>In modern software development, the system's requirements are usually pretty narrow, so tools can be more focused. Models not only have more dimensions, but the placement of a solution is also fuzzier.</p>
<p><img src="https://lh6.googleusercontent.com/6emah1WRzYxr97IHXpSJzKyeweuXtc3weSwUWtwBrXYJpVhg3keKrtaH_OszAh_Y6UYcaTXYX_OuqPw8DpncM_VmISOvpy58jzleK1VWUoMWV0nezh2doT64UeF0B-gvBwS_UhWX" width="487" height="426"></p>
<p>These are just a few examples of standard dimensions considered and it’s by no means an exhaustive list. Note how software usually lies on clear points in the spectrum. For instance, you know if the application provides an HTTP endpoint or runs in the user's device. Unsurprisingly, that is generally not the case for models. During the lifecycle of the model, from conception to use in a product, the same model might be at different places in the requirements balance. Using the same example, we might not use the end device for computing our test metrics due to speed concerns, but use the model as a library instead.</p>
<p>Most companies start to deploy models by building a solution for a particular case and ignoring others. Then they patch it a little bit to adapt to another model or another use case of the same model. And again, until they end up with a system that is hard to use, change, and maintain.</p>
<p>In which case, new users might consider it's easier to build their own from scratch for their use case. That's how many companies, including big tech ones, end up with multiple internal ML platforms if they're not careful. Keeping in mind the diversity of requirements, even within a single project, is an essential but challenging effort.</p>

<h4><span>MLOps challenge 3: self-service operations for data scientists</span></h4>
<p>One of the core tenets of DevOps is that developers should own their applications end-to-end. To do this properly, operators needed to provide mechanisms for their users to self-service. It allows IT to scale to multiple customers and removes delays waiting on someone else to provide some tooling.</p>

<p><img src="https://lh6.googleusercontent.com/hcT3ffqnaPw9OltYcczXKEgqjt2IHm1xB0O6vuPt2THWRmkHK62dKJ3dwdlm2UajB3mdtN4RskM3CbCJ_L9nh0cU-1pA56x9PtBziPQitU28STuw5NQMpJXaBXOxZFlQmfHLEr1i" width="499" height="326"></p>
<p>The image above covers a few of the functionalities most companies will have in their self-service platform. IT provides tools and processes for core functionalities, focusing on providing a solid foundation. Meanwhile, developers define customizations on top of the platform or perform integration for their particular application. Companies have been reducing the distance between developers and operators for many years now, which allowed lower-level constructs to be used. However, that is not enough for researchers.</p>
<p><img src="https://lh6.googleusercontent.com/4zjcm39V61mB1y4PWkJvzrrkHAVzBG6R9KKwChTHJUe81tr87ppMc2aq1DrppBgbnUXdkbJWVQUvQP0PdMlk5xpMZommxEkhKsSxmWoaZLoQ_lrv4yE2a3dFGnv79oguFTUL4yqD" width="499" height="326"></p>

<p>As we have argued before, data scientists' current skill set is very distinct from bringing up and operating one of their models in production. Hence the platform provided for researchers needs to be at a higher level than for software developers. For example, developers know how to define their systems' behavior to ensure it meets a particular SLA. But data scientists want to specify what those SLAs are and rely on a platform to handle the complexities to achieve that.</p>
<p>Thankfully the industry started to make higher-level constructs available for software engineers too. As anybody would suspect, operating low-level definitions is a considerable overhead. However, the further away you get from the specifics, the more domain knowledge you need to embed in the platform. Unfortunately, not every operations team has this knowledge at hand to support ML applications.</p>

<h4><span>MLOps challenge 4: adapt to existing processes and grow with the company</span></h4>
<p>Every big software company has a set of processes in place for software development. These processes took years and many iterations to develop correctly, potentially including expensive mistakes. When thinking about using models in production, teams frequently face the challenge of building these processes from scratch.</p>

<p><img src="https://lh5.googleusercontent.com/755p1w0mxyZwNwQFrwm_C2OLPIfMS-OAoOrRN5DjfAx2Z_70kHhNRvDRQk4L-Ygu3bnZRBkweEyRrtr8AlGKKQVQFFES7-yXnceVLGkI8VkBLNVh5yhrn5eyNDjmNTcrUvw_Yky9" width="452" height="285"></p>

<p>However, at the start of the ML journey, most operations constraints will look similar to doing software engineering. Operationalizing ML has higher success at places that first adapt their current processes the best they can. Once they have that initial version, the team iterates on the process as they identify improvements related to the new application domain or new product requirements.</p>
<p>This evolution of processes means that platforms and infrastructure must be able to adapt along with their teams. As new regulations and customer requests evolve, so will the requirements and limitations on model development and execution. Switching to a new system every time that happens is expensive. But relying on external enforcement is prone to misalignment failures. Hence production ML needs to meet users where they are today to bring immediate value while supporting the evolution of their ML methodologies.</p>

<h4><span>MLOps challenge 5: new layer at the operations stack</span></h4>
<p>This challenge is potentially the most undervalued one for MLOps: adding models creates an entirely new layer to the operations stack. In a simplified way, each level of the operation stack covers the unit of computation, how …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops">https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</a></em></p>]]>
            </description>
            <link>https://blog.verta.ai/blog/the-third-wave-of-operationalization-is-here-mlops</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275856</guid>
            <pubDate>Tue, 25 Aug 2020 20:43:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open source platform for making synthetic data, sharing it]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24274535">thread link</a>) | @watson1008
<br/>
August 25, 2020 | https://gretel.ai/blog/readme-v2 | <a href="https://web.archive.org/web/*/https://gretel.ai/blog/readme-v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div><h2>We founded Gretel based on our beliefs that data shouldn’t be scary.</h2><figure><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png" alt="" sizes="(max-width: 767px) 100vw, 586.95654296875px" srcset="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f45361b7ebe7f6e8e7ed9cd_Readmev2.png 1440w"></figure><div><p><strong>It’s way too hard- sometimes seemingly impossible- to safely share and collaborate with sensitive data.</strong> We have a solution to this problem that we and every developer faces each day. We founded Gretel based on our beliefs that data shouldn’t be scary, and for you to compete in today’s world, you need to be able to use and learn from your data. </p><p>Companies like Amazon, Google, and Apple have the resources to give the developers the best of both worlds- data privacy and streamlined access to data. We’re here to make that possible for any developer.</p><p>In February we published our first <a href="https://gretel.ai/blog/gretel-readme">README</a> and started laying out our goal of enabling developers to safely share and collaborate with sensitive data, and our vision of democratizing building with data so everyone can use it. We asked for your feedback and ideas, and promised to share research, open source code, and provide examples. </p><p>In the 6 months since then, we have had conversations with nearly 100 developers and companies to understand the barriers to working with sensitive data and how we can apply privacy-enhancing technology to break down those barriers. Here is what we learned:</p><ul role="list"><li><strong>It can take developers months to get access to sensitive data to test an idea</strong>. Often this requires PM and legal approvals, snap-shots of production databases, and manual anonymization of sensitive fields. </li><li><strong>Privacy is an engineering problem, not a policy problem</strong>. Policies are open to interpretation, lack enforceability at different stages of a workflow, and eventually get abused. </li><li><strong>Fairness and ethics in AI is incredibly important. Datasets used to power AI in our lives are often limited and imbalanced, leading to bias against users and groups. &nbsp;</strong>‍</li></ul><p>In the past year, we have built a set of open-source SDKs that enable developers to label and share access to data, composable APIs to enable transformations to streaming data, and an &nbsp;open-source AI-based synthetic data library that can generate artificial datasets from sensitive data with <a href="https://gretel.ai/blog/using-generative-differentially-private-models-to-build-privacy-enhancing-synthetic-datasets-from-real-data">provable privacy guarantees</a>, and automatically boost minority classes in datasets to <a href="https://gretel.ai/blog/reducing-ai-bias-with-synthetic-data">reduce AI bias</a>.</p><p>Today, we are thrilled to release <a href="https://console.gretel.cloud/login">Gretel’s public beta to any developer</a>. It’s free, and you can get started in minutes with one of our guides for <a href="https://gretel.ai/gretel-cloud-faqs/how-do-i-get-started">labeling and sharing a dataset in 2 minutes</a>, or even generating <a href="https://www.youtube.com/watch?v=gS7kpR-LJTs&amp;t=144s">your first synthetic dataset</a> with differential privacy guarantees.</p><p>We are building Gretel for developers like you, so don’t be shy. Please follow us here, <a href="https://twitter.com/gretel_ai">Twitter</a>, and <a href="https://github.com/gretelai/gretel-synthetics">Github</a>. Want to see for yourself? <a href="https://console.gretel.cloud/login">Get started now!</a> We’re <a href="https://gretel.ai/cdn-cgi/l/email-protection#aac2c3eacdd8cfdecfc684cbc3"><span data-cfemail="8ee6e7cee9fcebfaebe2a0efe7">[email&nbsp;protected]</span></a>.<br></p></div><a href="https://gretel.ai/blog"><p>View all posts</p></a></div></div></div></div>]]>
            </description>
            <link>https://gretel.ai/blog/readme-v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24274535</guid>
            <pubDate>Tue, 25 Aug 2020 18:40:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimal Peanut Butter and Banana Sandwiches]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24272814">thread link</a>) | @ethanahte
<br/>
August 25, 2020 | https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/ | <a href="https://web.archive.org/web/*/https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
          <section>
              

              
              
              
              
              


              <article>
                  <div>
<video autoplay="" muted="" loop="loop">
    <source src="https://www.ethanrosenthal.com/videos/optimal-peanut-butter-and-banana/banana_small.mp4" type="video/mp4">
</video>

<p>I was personally useless for most of the Spring of 2020. There was a period of time, though, after the peak in coronavirus cases here in NYC and before the onslaught of police violence here in NYC that I managed to scrounge up the motivation to do something other than drink and maniacally refresh my Twitter feed. I set out to work on something completely meaningless. It was almost therapeutic to work on a project with no value of any kind (<em>insert PhD joke here</em>).</p>
<p>A side effect of having spent 10 years with limited income in college and grad school, 6 of those here in expensive ass NYC, is that I eat of lot of cheap sandwiches, even though I now have a nice Tech™ job. While my sandwich consumption was quite formidable pre-covid, sheltering in place cemented this staple in my diet. I am particularly fond of peanut butter and banana sandwiches, having been introduced to them as a child by my maternal grandfather who ate them regularly.</p>
<p>I start a peanut butter and banana sandwich by spreading peanut butter on two slices of bread. I then slice circular slices of the banana, starting at the end of the banana, and place each slice on one of the pieces of bread until I have a single layer of banana slices. Every time I do this, the former condensed matter physicist in me starts to twitch his eye. You see, I have this urge, this desire, this <em>need</em> to maximize the <a href="https://en.wikipedia.org/wiki/Atomic_packing_factor">packing fraction</a> of the banana slices. That is, I want to maximize the coverage of the banana slices on the bread. Just as bowl-form food is perfect because you get every ingredient in every bite, each bite of my sandwich should yield the same golden ratio of bread, peanut butter, and banana.</p>
<p>If you were a machine learning model (or my wife), then you would tell me to just cut long rectangular strips along the long axis of the banana, but I’m not a sociopath. If life were simple, then the banana slices would be perfect circles of equal diameter, and we could coast along looking up optimal configurations on <a href="http://packomania.com/">packomania</a>. But alas, life is not simple. We’re in the middle of a global pandemic, and banana slices are elliptical with varying size.</p>
<p>So, how do we make optimal peanut butter and banana sandwiches? It’s really quite simple. You take a picture of your banana and bread, pass the image through a deep learning model to locate said items, do some nonlinear curve fitting to the banana, transform to polar coordinates and “slice” the banana along the fitted curve, turn those slices into elliptical polygons, and feed the polygons and bread “box” into a 2D nesting algorithm.</p>
<p>You may have noticed that I supposedly started this project in the Spring, and it’s now August. Like most idiot engineers, I had no idea how complicated this stupid project was going to be, but time’s meaningless in quarantine, so here we are. And here you are! Because I made a pip installable python package <a href="https://github.com/EthanRosenthal/nannernest">nannernest</a> if you want to optimize your own sandwiches, and I’m going to spend the rest of this post describing how this whole godforsaken thing works.</p>
</div>
<div>
<h2 id="sandwich-segmentation">Sandwich Segmentation</h2>
<p>I know that deep learning has been properly commoditized when the easiest part of this project was identifying every pixel that belongs to a banana or slice of bread in an image. Seriously, this step was super easy. I used a pretrained Mask-RCNN torchvision <a href="https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.detection.maskrcnn_resnet50_fpn">model</a> with a Resnet backbone. The model was pretrained on the COCO <a href="https://cocodataset.org/">dataset</a>, and thankfully the dataset has “banana” as segmentation category, along with “sandwich” and “cake” which were close enough categories for suitable detection of most slices of bread.</p>
<p>Passing an image through the model outputs a bunch of detected objects, where each detected object has an associated <code>label</code>, <code>score</code>, <code>bounding box</code>, and <code>mask</code>, where the mask identifies the pixels that correspond to the object with a weight at each pixel corresponding to the model’s confidence in that pixel’s label.</p>
<p>Because there could be multiple bananas and slices of bread in the image, I pick out the banana and slice of bread with the highest score. Below, you can see the model is clearly able to identify the banana and bread, with the mask overlaid in a semi-transparent, radioactive green.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>%</span><span>config</span> <span>InlineBackend</span><span>.</span><span>figure_format</span> <span>=</span> <span></span><span>'</span><span>retina</span><span>'</span>

<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>nannernest</span>

<span>_RC_PARAMS</span> <span>=</span> <span>{</span>
    <span></span><span>"</span><span>figure.figsize</span><span>"</span><span>:</span> <span>(</span><span>8</span><span>,</span> <span>4</span><span>)</span><span>,</span>
    <span></span><span>"</span><span>axes.labelsize</span><span>"</span><span>:</span> <span>16</span><span>,</span>
    <span></span><span>"</span><span>axes.titlesize</span><span>"</span><span>:</span> <span>18</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.right</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.top</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>font.size</span><span>"</span><span>:</span> <span>14</span><span>,</span>
    <span></span><span>"</span><span>lines.linewidth</span><span>"</span><span>:</span> <span>2</span><span>,</span>
    <span></span><span>"</span><span>lines.markersize</span><span>"</span><span>:</span> <span>6</span><span>,</span>
    <span></span><span>"</span><span>legend.fontsize</span><span>"</span><span>:</span> <span>14</span><span>,</span>
<span>}</span>
<span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>_RC_PARAMS</span><span>.</span><span>items</span><span>(</span><span>)</span><span>:</span>
    <span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>v</span>

<span>DPI</span> <span>=</span> <span>160</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>image</span><span>,</span> <span>banana</span><span>,</span> <span>bread</span> <span>=</span> <span>nannernest</span><span>.</span><span>segmentation</span><span>.</span><span>run</span><span>(</span><span>Path</span><span>(</span><span></span><span>"</span><span>pre_sandwich.jpg</span><span>"</span><span>)</span><span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana</span><span>=</span><span>banana</span><span>,</span> <span>bread</span><span>=</span><span>bread</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_4_0.png"> </figure>

</div>
<div>
<h2 id="what-shape-does-a-banana-makehttpswwwyoutubecomwatchv3o1ad4lzygk"><a href="https://www.youtube.com/watch?v=3O1ad4lZYGk">What shape does a banana make?</a></h2>
<p>Now that we have identified the banana in the image, we need to virtually “slice” it. This is where we are first introduced to the universal pain of computer vision:</p>
<p><em>By eye, I can see exactly what I want to do; by code, it’s so damn difficult.</em></p>
<p>I could ask you to draw lines on the banana identifying where you would slice it, and you could easily draw well-spaced, somewhat parallel slices. It’s not so easy to do this with code. However, I would also argue that this is the fun part of the problem. There are many ways to solve this, and it feels creative, as opposed to using a pre-trained deep learning model. On the other hand, “creatively” solving these problems likely leads to more brittle solutions compared to deep learning models trained on millions of examples. There’s a tradeoff here.</p>
<p>I tried a bunch of analytical solutions based on ellipses, but nothing seemed to work quite right. I ended up landing on a somewhat simpler solution that may not be robust to straight bananas, but who cares – this is a silly project anyway. Using the wonderful <a href="https://scikit-image.org/">scikit-image</a> library, I first calculate the <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html">skeleton</a> of the banana segmentation mask. This reduces the mask to a one pixel wide representation which effectively creates a curve that runs along the long axis of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>slices</span><span>,</span> <span>banana_circle</span><span>,</span> <span>banana_centroid</span><span>,</span> <span>banana_skeleton</span> <span>=</span> <span>nannernest</span><span>.</span><span>slicing</span><span>.</span><span>run</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_7_0.png"> </figure>

</div>
<p>I then fit a circle to the banana skeleton using a nice scipy-based least squares optimization I found <a href="https://scipy-cookbook.readthedocs.io/items/Least_Squares_Circle.html#Using-scipy.optimize.leastsq">here</a>. I actually originally tried to fit this with PyTorch and totally failed, likely due to the fact that this is actually a nonlinear optimization problem.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>show</span><span>=</span><span>True</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_9_0.png"> </figure>

</div>
<div>
<h2 id="rad-coordinate-transformations">Rad Coordinate Transformations</h2>
<p>With the circle fit to the banana, the goal is to now draw radial lines out from the center of the circle to the banana and have each radial line correspond to the slice of a knife. Again, while it’s easy to visualize this, it’s much harder in practice. For example, we need to start slicing at one end of the banana, but how do we find an end of the banana? Also, there are two ends, and we have to differentiate between them. Contrary to the behavior of <a href="https://www.thekitchn.com/why-you-should-peel-your-banana-like-a-monkey-206322">monkeys</a>, I start slicing my bananas at the stem end, and that’s what we’re going to do here.</p>
<p>Crucially, because we now have this circle and want to cut radial slices, we must transform from cartesian to polar coordinates and orient ourselves both radially and angularly with respect to the banana. As a start for orienting ourselves angularly, we calculate the <em>centroid</em> of the banana mask, which corresponds to the center of mass of the banana mask if the banana mask were a 2D object. The centroid is shown below as a red dot.</p>
<p>We now draw a radial line originating from the banana circle and passing through the centroid, shown as the dashed white line below. We will consider that line to mark our <em>reference</em> angle which orients us to the center of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>ax</span> <span>=</span> <span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>banana_centroid</span><span>=</span><span>banana_centroid</span><span>,</span>
    <span>show</span><span>=</span><span>False</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>

<span>dy</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>yc</span>
<span>dx</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>xc</span>
<span>reference_angle</span> <span>=</span> <span>np</span><span>.</span><span>arctan2</span><span>(</span><span>dy</span><span>,</span> <span>dx</span><span>)</span>
<span>radius</span> <span>=</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>dx</span> <span>*</span><span>*</span> <span>2</span> <span>+</span> <span>dy</span> <span>*</span><span>*</span> <span>2</span><span>)</span>

<span>radial_end_point</span> <span>=</span> <span>(</span>
    <span>banana_circle</span><span>.</span><span>xc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
    <span>banana_circle</span><span>.</span><span>yc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
<span>)</span>

<span>ax</span><span>.</span><span>plot</span><span>(</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>xc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>0</span><span>]</span><span>)</span><span>,</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>yc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>1</span><span>]</span><span>)</span><span>,</span>
    <span>color</span><span>=</span><span></span><span>"</span><span>white</span><span>"</span><span>,</span>
    <span>linestyle</span><span>=</span><span></span><span>"</span><span>--</span><span>"</span><span>,</span>
    <span>linewidth</span><span>=</span><span>1</span><span>,</span>
<span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_11_0.png"> </figure>

</div>
<p>Using <code>scikit-image</code>, we calculate the segmentation <code>mask</code> intensity along this radial line using the <code>profile_line</code> function. Because our line is passing at an angle along discrete <code>mask</code> pixels (aka matrix entries), we take an average of neighboring points along the radial line cut using the <code>linewidth</code> arguments. As you can see, the banana mask pops out a little over 100 points from the banana circle center.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>from</span> <span>skimage</span> <span>import</span> <span>measure</span>

<span>profile_line</span> <span>=</span> <span>measure</span><span>.</span><span>profile_line</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span><span>.</span><span>T</span><span>,</span> <span>banana_circle</span><span>.</span><span>center</span><span>,</span> <span>radial_end_point</span><span>,</span> <span>linewidth</span><span>=</span><span>2</span><span>,</span> <span>mode</span><span>=</span><span></span><span>"</span><span>constant</span><span>"</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>)</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>profile_line</span><span>)</span>
<span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span></span><span>"</span><span>Distance from banana circle center</span><span>"</span><span>)</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span></span><span>"</span><span>Mask Intensity</span><span>"</span><span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_14_0.png"> </figure>

</div>
<p>This profile line is what allows us to orient ourselves radially. You can clearly see where the banana starts and ends, in the radial direction. As always, just seeing it is not good enough. We need code to define the start and end of the banana in this direction. The <code>mask</code> tends to be monotonically increasing and then monotonically decreasing along the start and end, respectively. Using this information, there are a couple ways …</p></article></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</a></em></p>]]>
            </description>
            <link>https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272814</guid>
            <pubDate>Tue, 25 Aug 2020 16:10:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unpopular Opinion – Data Scientists Should Be More End-to-End]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24272617">thread link</a>) | @importantbrian
<br/>
August 25, 2020 | https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently, I came across a <a href="https://www.reddit.com/r/datascience/comments/i48b5q/for_those_that_work_for_a_team_that_has_both_data/" target="_blank">Reddit thread</a> on the different roles in data science and machine learning: data scientist, decision scientist, product data scientist, data engineer, machine learning engineer, machine learning tooling engineer, AI architect, etc.</p>

<p>I found this <em>worrying</em>. It’s difficult to be effective when the data science process (problem framing, data engineering, ML, deployment/maintenance) is split across different people. It leads to coordination overhead, diffusion of responsibility, and lack of a big picture view.</p>

<p>IMHO, <strong>I believe data scientists can be more effective by being end-to-end</strong>. Here, I’ll discuss the <a href="#from-start-identify-the-problem-to-finish-solve-it">benefits</a> and <a href="#but-we-need-specialist-experts-too">counter-arguments</a>, <a href="#the-best-way-to-pick-it-up-is-via-learning-by-doing">how to</a> become end-to-end, and the experiences of <a href="#end-to-end-in-stitch-fix-and-netflix">Stitch Fix and Netflix</a>.</p>

<h2 id="from-start-identify-the-problem-to-finish-solve-it">From start (identify the problem) to finish (solve it)</h2>

<p>You may have come across similar <em>labels</em> and definitions, such as:</p>
<ul>
  <li><a href="https://towardsdatascience.com/why-you-shouldnt-be-a-data-science-generalist-f69ea37cdd2c" target="_blank">Generalist</a>: Focused on roles (<a href="https://en.wikipedia.org/wiki/Product_manager" target="_blank">PM</a>, <a href="https://en.wikipedia.org/wiki/Business_analyst" target="_blank">BA</a>, <a href="https://www.oreilly.com/content/data-engineering-a-quick-and-simple-definition/" target="_blank">DE</a>, <a href="https://en.wikipedia.org/wiki/Category:Data_scientists" target="_blank">DS</a>, <a href="https://www.quora.com/What-exactly-does-a-machine-learning-engineer-do" target="_blank">MLE</a>); some negative connotation</li>
  <li><a href="https://skillcrush.com/blog/front-end-back-end-full-stack/" target="_blank">Full-stack</a>: Focused on tech (Spark, Torch, Docker); popularized by full-stack devs</li>
  <li><a href="https://www.infoworld.com/article/3429185/stop-searching-for-that-data-science-unicorn.html" target="_blank">Unicorn</a>: Focused on mythology; believed not to exist</li>
</ul>

<p>I find these definitions to be more prescriptive than I prefer. Instead, I have a simple (and pragmatic) definition: An end-to-end data scientist can <strong>identify and solve problems with data, to deliver value</strong>. To achieve the goal, they’ll wear as many (or as little) hats as required. They’ll also learn and apply whatever tech, methodology, and process that works. Throughout the process, they ask questions such as:</p>
<ul>
  <li>What is the problem? Why is it important?</li>
  <li>Can we solve it? How should we solve it?</li>
  <li>What is the estimated value? What was the actual value?</li>
</ul>

<details><summary>Data Science Processes</summary>
<div>
<p>Another way of defining end-to-end data science is via processes. These processes are usually complex and I’ve left them out of the main discussion. Nonetheless, here are a few in case you’re curious:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank">CRISP-DM</a>: Cross-Industry Standard Process for Data Mining (1997).</li>
  <li><a href="https://en.wikipedia.org/wiki/Data_mining#Process" target="_blank">KDD</a>: Knowledge Discovery in Databases.</li>
  <li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview" target="_blank">TDSP</a>: Team Data Science Process, proposed by Microsoft in 2018.</li>
  <li><a href="https://github.com/dslp/dslp" target="_blank">DSLP</a>: Data Science Lifecycle Process.</li>
</ul>

<p>Don’t worry if these processes seem heavy and overwhelming. You don’t have to adopt them wholesale—start bit by bit, keep what works and adapt the rest.</p>
</div>

</details>

<h2 id="more-context-faster-iteration-greater-satisfaction">More context, faster iteration, greater satisfaction</h2>

<p>For most data science roles, being more end-to-end improves your ability to make meaningful impact. (Nonetheless, there are <a href="https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Senior-Deep-Learning-Data-Scientist--RAPIDS---AI_JR1929838" target="_blank">roles</a> that focus on machine learning.)</p>

<p><strong>Working end-to-end provides increased context.</strong> While specialized roles can increase efficiency, it reduces context (for the data scientist) and leads to suboptimal solutions.</p>

<blockquote>
  <p>The trick to forgetting the big picture is to look at everything close-up. – Chuck Palahniuk</p>
</blockquote>

<p>It’s hard to design a holistic solution without full context of the upstream problem. Let’s say conversion has decreased and a PM raises a request to improve our search algorithm. However, what’s causing the decrease in the first place? There could be various causes:</p>
<ul>
  <li>Product: Is fraudulent/poor quality product reducing customer trust?</li>
  <li>Data pipelines: Has data quality been compromised or are there delays/outages?</li>
  <li>Model refresh: Is the model not refreshing regularly/correctly?</li>
</ul>

<p>More often than not, the problem—and solution—lies <em>outside</em> of machine learning. A solution to <em>improve the algorithm</em> would miss the root cause.</p>

<p>Similarly, it’s risky to develop a solution without awareness of downstream engineering and product constraints. There’s no point:</p>
<ul>
  <li>Building a near-real time recommender if infra and engineer cannot support it</li>
  <li>Building an infinite scroll recommender if it doesn’t fit in our product and app</li>
</ul>

<p>By working end-to-end, data scientists will have the full context to identify the right problems and develop usable solutions. It can also lead to innovative ideas that specialists, with their narrow context, might miss. Overall, it increases the ability to deliver value.</p>

<p><strong>Communication and coordination overhead is reduced.</strong> With multiple roles comes additional overhead. Let’s look at an example of a data engineer (DE) cleaning the data and creating features, a data scientist (DS) analysing the data and training the model, and a machine learning engineer (MLE) deploying and maintaining it.</p>

<blockquote>
  <p>What one programmer can do in one month, two programmers can do in two months. – Frederick P. Brooks</p>
</blockquote>

<p>The DE and DS need to <em>communicate</em> on what data is (and is not) available, how it should be cleaned (e.g., outliers, normalisation), and which features should be created. Similarly, the DS and MLE have to discuss how to deploy, monitor, and maintain the model, as well as how often it should be refreshed. When issues occur, we’ll need three people in the room (likely with a PM) to triage the root cause and next steps to fix it.</p>

<p>It also leads to additional coordination, where schedules need to be aligned as work is executed and passed along in a sequential approach. If the DS wants to experiment with additional data and features, we’ll need to wait for the DE to ingest the data and create the features. If a new model is ready for A/B testing, we’ll need to wait for the MLE to (convert it to production code) and deploy it.</p>

<p>While the actual development work may take days, the communication back-and-forth and coordination can take weeks, if not longer. With end-to-end data scientists, we can minimize this overhead as well as prevent technical details from being lost in translation.</p>

<p>(But, can an end-to-end DS really do all that? I think so. While the DS might not be as proficient in some tasks as a DE or MLE, they will be able to perform most tasks effectively. If they need help with scaling or hardening, they can always get help from specialist DEs and MLEs.)</p>

<details><summary>The Cost of Communication and Coordination</summary>
<div>
<p>Richard Hackman, a Harvard psychologist, showed that the number of relationships in a team is <code><span>N</span><span>(</span><span>N</span><span>-</span><span>1</span><span>)</span> <span>/</span> <span>2</span></code>, where <code><span>N</span></code> is the number of people. This leads to exponential growth in links, where:</p>

<ul>
  <li>A start-up team of 7 has 21 links to maintain</li>
  <li>A group of 21 (i.e., three start-up teams) has 210 links</li>
  <li>A group of 63 has almost 2,000 links.</li>
</ul>

<p>In our simple example, we only had three roles (i.e., six links). But as a PM, BA, and additional members are included, this leads to greater than linear growth in communication and coordination costs. Thus, while each additional member increases total team productivity, the increased overhead means productivity grows at a decreasing rate. (Amazon’s <a href="https://buffer.com/resources/small-teams-why-startups-often-win-against-google-and-facebook-the-science-behind-why-smaller-teams-get-more-done/" target="_blank">two-pizza teams</a> are a possible solution to this.)</p>
</div>
</details>

<p><strong>Iteration and learning rate is increased.</strong> With greater context and lesser overhead, we can now iterate, fail (read: learn), and deliver value faster.</p>

<p>This is especially important for developing data and algorithmic products. Unlike software engineering (a far more mature craft), we can’t do all the learning and design before we start building—our blueprints, architectures, and design patterns are not as developed. Thus, rapid iteration is essential for the design-build-learn cycle.</p>

<p><strong>There’s greater ownership and accountability.</strong> Having the data science process split across multiple people can lead to diffusion of responsibility, and worse, social loafing.</p>

<p>A common anti-pattern observed is “<a href="https://wiki.c2.com/?ThrownOverTheWall" target="_blank">throw over the wall</a>”. For example, the DE creates features and throws a database table to the DS, the DS trains a model and throws <code>R</code> code over to the MLE, and the MLE translates it to <code>Java</code> to production.</p>

<p>If things get lost-in-translation or if results are unexpected, who is responsible? With a strong culture of ownership, everyone steps up to contribute in their respective roles. But without it, work can degenerate into ass-covering and finger-pointing while the issue persists and customers and the business suffers.</p>

<p>Having the end-to-end data scientist take ownership and responsibility for the entire process can mitigate this. They should be empowered to take action from start to finish, from the customer problem and input (i.e., raw data) to the output (i.e., deployed model) and measurable outcomes.</p>

<details><summary>Diffusion of Responsibilty &amp; Social Loafing</summary>
<div>

<p><a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility" target="_blank">Diffusion of responsibility</a>: We are less likely to take responsibility and act when there are others present. Individuals feel less responsibility and urgency to help if we know that there are others also watching the situation. </p>

<p>One form of this is the <a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility#Bystander_effect" target="_blank">Bystander effect</a>, where <a href="https://en.wikipedia.org/wiki/Murder_of_Kitty_Genovese" target="_blank">Kitty Genovese</a> was stabbed outside the apartment building across the street from where she lived. While there were 38 witnesses who saw or heard the attack, none called the police or helped her.</p>

<p><a href="https://en.wikipedia.org/wiki/Social_loafing" target="_blank">Social loafing</a>: We exert less effort when we work in a group vs. working alone. In the 1890s, Ringelmann made people pull on ropes both separately and in groups. He measured how hard they pulled and found that members of a group tended to exert less effort in pulling a rope than did individuals alone.</p>

</div>
</details>

<p><strong>For (some) data scientists, it can lead to increased motivation and job satisfaction</strong>, which is <a href="https://www.clearpointstrategy.com/how-employees-are-motivated-autonomy-mastery-purpose/" target="_blank">closely tied</a> to autonomy, mastery, and purpose.</p>
<ul>
  <li><strong>Autonomy:</strong> By being able to solve problems independently. Instead of waiting and depending on others, end-to-end data scientists are able to identify and define the problem, build their own data pipelines, and deploy and validate a solution.</li>
  <li><strong>Mastery:</strong> In the problem, solution, outcome from end-to-end. They can also pick up the domain and tech as required.</li>
  <li><strong>Purpose</strong>: By being deeply involved in the entire process, they have a more direct connection with the work and outcomes, leading to an increased sense of <em>purpose</em>.</li>
</ul>

<h2 id="but-we-need-specialist-experts-too">But, we need specialist experts too</h2>

<p>Being end-to-end is not for everyone (and every team) though, for reasons such as:</p>

<p><strong>Wanting to specialize</strong> in machine learning, or perhaps a specific niche in machine learning such as neural text generation (read: <a href="https://mc.ai/the-subtle-art-of-priming-gpt-3/" target="_blank">GPT-3 primer</a>). While being end-to-end is valuable, we also need such world-class experts in research and industry who push the envelope. Much of what we have in ML came from academia and pure research efforts.</p>

<blockquote>
  <p>No one achieves greatness by …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272617</guid>
            <pubDate>Tue, 25 Aug 2020 15:54:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Mass Surveillance – The Fourteen Eyes]]>
            </title>
            <description>
<![CDATA[
Score 316 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24272244">thread link</a>) | @latexr
<br/>
August 25, 2020 | https://www.privacytools.io/providers/#ukusa | <a href="https://web.archive.org/web/*/https://www.privacytools.io/providers/#ukusa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <nav id="breadcrumb" aria-label="breadcrumb">
  
  <ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
    <li>
      <a href="https://www.privacytools.io/"> <span>Home</span></a>
    </li>
    
    
    <li aria-current="page" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      
      <span itemprop="name">Providers 
      </span>
      <meta itemprop="position" content="1">
    </li>
    
    
  </ol>
</nav>


<div>
  
  <p>There's a ton of people providing services online. Discover which ones you should avoid and our recommendations for a variety of services.</p>
</div>



<p>Click on whatever service you need to view our recommendations.</p>





<img src="https://www.privacytools.io/assets/img/svg/layout/ukusa.svg" width="260" height="115" alt="UKUSA Agreement">

<p>The UKUSA Agreement is an agreement between the United Kingdom, United States, Australia, Canada, and New Zealand to cooperatively collect, analyze, and share intelligence. Members of this group, known as the <a href="https://www.giswatch.org/en/communications-surveillance/unmasking-five-eyes-global-surveillance-practices">Five Eyes</a>, focus on gathering and analyzing intelligence from different parts of the world. While Five Eyes countries have agreed to <a href="https://www.pbs.org/newshour/world/an-exclusive-club-the-five-countries-that-dont-spy-on-each-other">not spy on each other</a> as adversaries, leaks by Snowden have revealed that some Five Eyes members monitor each other's citizens and <a href="https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa">share intelligence</a> to <a href="https://www.theguardian.com/politics/2013/jun/10/nsa-offers-intelligence-british-counterparts-blunkett">avoid breaking domestic laws</a> that prohibit them from spying on their own citizens. The Five Eyes alliance also cooperates with groups of third-party countries to share intelligence (forming the Nine Eyes and Fourteen Eyes); however, Five Eyes and third-party countries can and do spy on each other.</p>

<div>
  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Australia </li>
    <li>Canada </li>
    <li>New Zealand </li>
    <li>United Kingdom </li>
    <li>United States of America </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Denmark </li>
    <li>France </li>
    <li>Netherlands </li>
    <li>Norway </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Belgium </li>
    <li>Germany </li>
    <li>Italy </li>
    <li>Spain </li>
    <li>Sweden </li>
  </ol>
  
        </div>
    </div>
</div>

</div>




<h3>Who is required to hand over the encryption keys to authorities?</h3>

<p>Mandatory <a href="https://en.wikipedia.org/wiki/Key_disclosure_law">key disclosure laws</a> require individuals to turn over encryption keys to law enforcement conducting a criminal investigation. How these laws are implemented (who may be legally compelled to assist) vary from nation to nation, but a warrant is generally required. Defenses against key disclosure laws include steganography and encrypting data in a way that provides plausible deniability.</p>  <p><a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> involves hiding sensitive information (which may be encrypted) inside of ordinary data (for example, encrypting an image file and then hiding it in an audio file). With plausible deniability, data is encrypted in a way that prevents an adversary from being able to prove that the information they are after exists (for example, one password may decrypt benign data and another password, used on the same file, could decrypt sensitive data).</p>



<p> * (people who know how to access a system may be ordered to share their knowledge, <strong>however, this doesn't apply to the suspect itself or family members.</strong>)</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Wikipedia page on key disclosure law</a></li>
  <li><a href="https://law.stackexchange.com/questions/1523/can-a-us-citizen-be-required-to-provide-the-authentication-key-for-encrypted-dat">law.stackexchange.com question about key disclosure law in US</a></li>
  <li><a href="https://peertube.mastodon.host/videos/watch/e09915eb-5962-4830-a02f-8da5c2b59e71">DEFCON 20: Crypto and the Cops: the Law of Key Disclosure and Forced Decryption</a></li>
</ul>

<h3 id="usa">Why is it not recommended to choose a US-based service?</h3>

<img src="https://www.privacytools.io/assets/img/svg/layout/great_seal_of_the_united_states_obverse.svg" width="200" height="200" alt="USA">

<p>Services based in the United States are not recommended because of the country's surveillance programs and use of <a href="https://www.eff.org/issues/national-security-letters/faq">National Security Letters</a> (NSLs) with accompanying gag orders, which forbid the recipient from talking about the request. This combination allows the government to <a href="https://www.schneier.com/blog/archives/2013/08/more_on_the_nsa.html">secretly force</a> companies to grant complete access to customer data and transform the service into a tool of mass surveillance.</p>

<p>An example of this is <a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit</a> – a secure email service created by Ladar Levison. The FBI <a href="https://www.vice.com/en_us/article/nzz888/lavabit-founder-ladar-levison-discusses-his-federal-battle-for-privacy">requested</a> Snowden's records after finding out that he used the service. Since Lavabit did not keep logs and email content was stored encrypted, the FBI served a subpoena (with a gag order) for the service's SSL keys. Having the SSL keys would allow them to access
communications (both metadata and unencrypted content) in real time for all of Lavabit's customers, not just Snowden's.</p>

<p>Ultimately, Levison turned over the SSL keys and <a href="https://www.theguardian.com/commentisfree/2014/may/20/why-did-lavabit-shut-down-snowden-email">shut down</a> the service at the same time. The US government then <a href="https://www.cnbc.com/id/100962389">threatened Levison with arrest</a>, saying that shutting down the service was a violation of the court order.</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://www.bestvpn.com/the-ultimate-privacy-guide/#avoidus">Avoid all US and UK based services</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Surespot#History">Proof that warrant canaries work based on the surespot example.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/UKUSA_Agreement">The United Kingdom – United States of America Agreement (UKUSA)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit: Suspension and gag order</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Key disclosure law</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Portal:Mass_surveillance">Wikipedia Portal: Mass_surveillance</a></li>
</ul>




<img src="https://www.privacytools.io/assets/img/svg/layout/warrant_canary_example.svg" width="450px" alt="Warrant Canary Example">

<p>A warrant canary is a posted document stating that an organization has not received any secret subpoenas during a specific period of time. If this document fails to be updated during the specified time then the user is to assume that the service has received such a subpoena and should stop using the service.</p>

<h4>Warrant Canary Examples:</h4>

<ol>
  <li><a href="https://proxy.sh/canary">https://proxy.sh/canary</a></li>
  <li><a href="https://www.ivpn.net/resources/canary.txt">https://www.ivpn.net/resources/canary.txt</a></li>
  <li><a href="https://www.bolehvpn.net/canary.txt">https://www.bolehvpn.net/canary.txt</a></li>
  <li><a href="https://www.ipredator.se/static/downloads/canary.txt">https://www.ipredator.se/static/downloads/canary.txt</a></li>
</ol>

<h4>Related Warrant Canary Information</h4>

<ul>
  <li><a href="https://www.eff.org/deeplinks/2014/04/warrant-canary-faq">Warrant Canary Frequently Asked Questions</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Warrant_canary#Companies_and_organizations_with_warrant_canaries">Companies and organizations with warrant canaries</a></li>
  <li><a href="https://www.schneier.com/blog/archives/2015/03/australia_outla.html">Warrant canary criticism by Bruce Schneier and an example of a law against warrant canaries.</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://www.privacytools.io/providers/#ukusa</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272244</guid>
            <pubDate>Tue, 25 Aug 2020 15:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitpod is now Open Source]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24271090">thread link</a>) | @henningcash
<br/>
August 25, 2020 | https://www.gitpod.io/blog/opensource/ | <a href="https://web.archive.org/web/*/https://www.gitpod.io/blog/opensource/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As of today Gitpod is open source under the AGPL license at <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">github.com/gitpod-io/gitpod</a>. This allows the community to participate in the development of Gitpod, provides more transparency and makes it even easier for developers to use and integrate Gitpod in their workflows.</p>
<p>For those of you who know us, this probably does not come as a big surprise. Working in open source is in our DNA and everything we’ve created over the past 10 years, including <a href="https://github.com/eclipse-theia/theia" target="_blank" rel="nofollow noopener noreferrer">Theia</a>, <a href="https://github.com/eclipse/xtext" target="_blank" rel="nofollow noopener noreferrer">Xtext</a>, <a href="https://github.com/eclipse/openvsx" target="_blank" rel="nofollow noopener noreferrer">Open VSX</a> and many other projects have been open source. In fact, Gitpod was our only closed-source project and it is a relief to change that going forward.</p>

<p>Contributing to Gitpod should be easy and accessible for everyone. All contributions are welcome, including pull requests, issues, documentation as well as updates and tweaks, blog posts, tutoials, and more. Please head over to <a href="https://github.com/gitpod-io/gitpod" target="_blank" rel="nofollow noopener noreferrer">Github</a> to find out about the various ways you can contribute and join our <a href="https://community.gitpod.io/" target="_blank" rel="nofollow noopener noreferrer">Gitpod Community</a>.</p>
<p>Over the past year, Gitpod has simplified contributions to many open source projects (see <a href="https://contribute.dev/" target="_blank" rel="nofollow noopener noreferrer">contribute.dev</a> for examples). Today, everyone in our team is excited to share our own streamlined development pipeline including Kubernetes preview deployments, an aggressively cached build system, our own slim and fast CI system and of course Gitpod, which continuously beams us into ready-to-code (and debug) dev environments. <a href="https://github.com/csweichel" target="_blank" rel="nofollow noopener noreferrer">Chris</a> gave a great talk about this setup earlier this year 👇</p>
<div> <p> <iframe title="" src="https://www.youtube.com/embed/dFMpXUsJcGM?rel=0" allowfullscreen=""></iframe> </p> </div>
<p>Naturally, we develop Gitpod in Gitpod. This allows the  whole team  to spin up fully initialized, remote dev environments on any branch at any time. </p>
<p>In line with the <a href="http://cloudscaling.com/blog/cloud-computing/the-history-of-pets-vs-cattle/?utm_source=thenewstack&amp;utm_medium=website&amp;utm_campaign=platform" target="_blank" rel="nofollow noopener noreferrer">pets vs. cattle</a> analogy of the cloud-native world, we treat dev environments as automated (yet customizable) resources you can spin up when you need them and close down (and forget about) when you are done with your task. Once you experience the peace of mind of automated, ephemeral dev environments you never want to go back.</p>
<p>Sven will run a webinar next week on Thursday, where we will showcase how we use Gitpod internally at Gitpod and how much it improves our workflow. Hope to see you there! </p>



<p>The <a href="https://www.gitpod.io/pricing/#" target="_blank" rel="nofollow noopener noreferrer">SaaS offering of gitpod.io</a> remains the easiest way to streamline your development workflows with continuously prebuilt dev environments. </p>
<p>In case you want to host Gitpod on your own infrastructure or private cloud, starting today, Gitpod Self-Hosted is free for unlimited users. Organizations using Gitpod Self-Hosted can purchase an enterprise license in order to get additional features like:</p>
<ul>
<li><a href="https://www.gitpod.io/features/#snapshot" target="_blank" rel="nofollow noopener noreferrer">Snapshots</a> (share a reproducible workspace with your team)</li>
<li><a href="https://www.gitpod.io/features/#share" target="_blank" rel="nofollow noopener noreferrer">Live Share</a> (invite others into your running workspace)</li>
<li><a href="https://www.gitpod.io/features/#prebuilt" target="_blank" rel="nofollow noopener noreferrer">Unlimited Prebuilds</a> (making ephemeral dev environments possible)</li>
<li>Admin Dashboard</li>
</ul>
<p>Offering a paid plan for enterprises makes it possible for us to keep working towards building a new category in developer tooling, which completes modern DevOps pipelines. In the future we will add additional functionality to both the open source code as well our paid offering.</p>
</div></div></div>]]>
            </description>
            <link>https://www.gitpod.io/blog/opensource/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24271090</guid>
            <pubDate>Tue, 25 Aug 2020 13:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mathematical Structure of Particle Collisions Comes into View]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24270579">thread link</a>) | @rbanffy
<br/>
August 25, 2020 | http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span><br></span><span>W</span>hen particle physicists try to model experiments, they confront an impossible calculation—an infinitely long equation that lies beyond the reach of modern mathematics.&nbsp;<br></p>

<p>Fortunately, they can generate largely accurate predictions without seeing this arcane math all the way through. By cutting the calculation short, scientists at CERNâ€™s Large Hadron Collider in Europe make forecasts that match events they actually observe when they send subatomic particles barreling toward each other around a nearly 17-mile track.</p>
<p>Unfortunately, the era of agreement between forecast and observation may be ending. As measurements grow more precise, the approximation schemes theorists use to make predictions may not be able to keep up.</p>
<p>â€œWeâ€™re getting close to exhausting what can be done,â€� said&nbsp;<a href="https://theory.cern/roster/duhr-claude" target="_blank">Claude Duhr</a>, a particle physicist at CERN.&nbsp;</p>
<p>But&nbsp;<a href="https://link.springer.com/article/10.1007/JHEP02(2019)139" target="_blank">three</a>&nbsp;<a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.201602" target="_blank">papers</a>&nbsp;from a group of physicists led by&nbsp;<a href="https://amplitudesatpadova.wixsite.com/amplitudes-at-padova" target="_blank">Pierpaolo Mastrolia</a>&nbsp;of the University of Padua in Italy and&nbsp;<a href="https://www.ias.edu/scholars/sebastian-mizera" target="_blank">Sebastian Mizera</a>&nbsp;of the Institute for Advanced Study in Princeton, New Jersey, have revealed an underlying mathematical structure in the equations. The structure provides a new way of collapsing interminable terms into just dozens of essential components. Their method may help bring about new levels of predictive accuracy, which theorists desperately need if they are to move beyond the leading but incomplete model of particle physics.</p>
<p>â€œThey have delivered lots of proof-of-concept results which show that this is a very promising technique,â€� Duhr said.</p>
<p>There could be a bigger payoff than improved predictions.&nbsp;</p>
<p>The new method skirts the traditional mathematical slog by directly computing â€œintersection numbers,â€� which some hope could eventually lead to a more elegant description of the subatomic world.&nbsp;</p>
<p>â€œThis is something thatâ€™s not just mathematics,â€� said&nbsp;<a href="https://www.physics.mcgill.ca/~schuot/" target="_blank">Simon Caron-Huot</a>&nbsp;of McGill University, a quantum theorist who is studying the implications of Mastrolia and Mizeraâ€™s work.&nbsp;â€œItâ€™s something thatâ€™s deeply baked into quantum field theory.â€�&nbsp;</p>
<p><strong>An Infinite Loop</strong></p>
<p>When physicists model particle collisions they use a tool called a Feynman diagram, a simple schematic invented by Richard Feynman in the 1940s.</p>
<p>To get a feel for these diagrams, consider a simple particle event: Two quarks streak in, exchange a single gluon as they â€œcollide,â€� then bounce away on their separate trajectories.</p>
<p>In a Feynman diagram the quarksâ€™ paths are represented by â€œlegs,â€� which join to form â€œverticesâ€� when particles interact. Feynman developed rules for turning this cartoon into an equation which calculates the probability that the event actually takes place: You write a specific function for each leg and vertex—generally a fraction involving the particleâ€™s mass and momentum—and multiply everything together. For straightforward scenarios like this one, the calculation might fit on a cocktail napkin.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_5242dbae24adf53fee012a27d96504f9.jpg" alt="nautilus gluon"><figcaption><br><span>Samuel Velasco/Quanta Magazine</span></figcaption></figure>
<p>But the golden rule of quantum theory is to consider all possibilities, and exchanging a simple gluon represents just one among a vast landscape of scenarios that could unfold when two quarks collide. The exchanged gluon might momentarily split into a â€œvirtualâ€� quark pair, for instance, before reconstituting itself in a flash. Two quarks enter and two quarks leave, but a lot can happen in the middle. A full accounting, implying a perfect prediction, would demand an infinite number of diagrams. No one expects perfection, but the key to improving a calculationâ€™s precision is getting further along in the infinite line of events.<strong>&nbsp;</strong><br></p>
<p>And thatâ€™s where physicists are getting stuck.&nbsp;</p>
<p>Zooming in to that hidden center involves virtual particles—quantum fluctuations that subtly influence each interactionâ€™s outcome. The fleeting existence of the quark pair above, like many virtual events, is represented by a Feynman diagram with a closed â€œloop.â€� Loops confound physicists—theyâ€™re black boxes that introduce additional layers of infinite scenarios. To tally the possibilities implied by a loop, theorists must turn to a summing operation known as an integral. These integrals take on monstrous proportions in multi-loop Feynman diagrams, which come into play as researchers march down the line and fold in more complicated virtual interactions.&nbsp;</p>
<p>Physicists have algorithms to compute the probabilities of no-loop and one-loop scenarios, but many two-loop collisions bring computers to their knees. This imposes a ceiling on predictive precision—and on how well physicists can understand what quantum theory says.&nbsp;</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qe7atm1x6Mg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe>
</center>
<p>But there is one small mercy: Physicists donâ€™t need to calculate every last integral in a complicated Feynman diagram because the vast majority can be lumped together.<br></p>
<p>Thousands of integrals can be reduced to just dozens of â€œmaster integrals,â€� which are weighted and added together. But exactly which integrals can be subsumed under which master integrals is itself a hard computational question. Researchers use computers to essentially guess at millions of relationships and laboriously extract the combinations of integrals that matter.</p>
<p>But with intersection numbers, physicists may have found a way of elegantly plucking out the essential information from a sprawling calculation of Feynman integrals.</p>
<p><strong>A Geometric Fingerprint&nbsp;</strong></p>
<p>Mastrolia and Mizeraâ€™s work is rooted in a branch of pure math called algebraic topology, which classifies shapes and spaces. Mathematicians pursue this classification with â€œcohomologyâ€� theories, which allow them to extract algebraic fingerprints from complicated geometric spaces.</p>
<p>â€œItâ€™s kind of a summary, an algebraic gadget that incorporates the essence of the space you want to study,â€� said&nbsp;<a href="https://imag.umontpellier.fr/~dupont/" target="_blank">ClÃ©ment Dupont</a>, a mathematician at the University of Montpellier in France.</p>
<p>Feynman diagrams can be translated into geometric spaces that are amenable to analysis by cohomology. Each point within these spaces might represent one of a multitude of scenarios that could play out when two particles collide.</p>
<p>You might hope, naively, that by taking the cohomology of this space—finding its algebraic structure—you could calculate the weights for the master integrals that support it. But the type of geometric space that characterizes most Feynman diagrams is warped in a way that resists many cohomology calculations.</p>
<p>In 2017, Mizera was struggling to analyze how objects in string theory collide when he stumbled upon tools pioneered by Israel Gelfand and Kazuhiko Aomoto in the 1970s and 1980s as they worked with a type of cohomology called â€œtwisted cohomology.â€� Later that year Mizera met Mastrolia, who realized that these techniques could work for Feynman diagrams too. In 2019,&nbsp;they published three papers that used this cohomology theory to streamline calculations involving simple particle collisions.</p>
<p>Their method takes a family of related physical scenarios, represents it as a geometric space, and calculates the twisted cohomology of that space. â€œThis twisted cohomology has everything to say about the integrals we are interested in,â€� Mizera said.</p>
<p>In particular, the twisted cohomology tells them how many master integrals to expect and what their weights should be. The weights emerge as values they call â€œintersection numbers.â€� In the end, thousands of integrals shrink to a weighted sum of dozens of master integrals.</p>
<p>The cohomology theories that produce these intersection numbers may do more than just ease a computational burden—they could also point to the physical significance of the most important quantities in the calculation.</p>
<p>For example, when a virtual gluon splits into two virtual quarks, the quarksâ€™ possible lifetimes can vary. In the associated geometric space, each point can stand for a different quark lifetime. When researchers compute the weights, they see that scenarios with the longest-lasting virtual particles—that is, cases in which the particles become essentially real—shape the outcome the most.</p>
<p>â€œThatâ€™s the amazing thing about this method,â€� said Caron-Huot. â€œIt reconstructs everything starting from just these rare, special events.â€�</p>
<p>In August 2020,&nbsp;Mizera, Mastrolia and colleagues published&nbsp;<a href="https://arxiv.org/abs/2008.04823" target="_blank">another preprint</a>&nbsp;showing that the technique has matured enough to handle real-world two-loop diagrams. A forthcoming paper by Caron-Huot will push the method further, perhaps bringing three-loop diagrams to heel.</p>
<p>If successful, the technique could help usher in the next generation of theoretical predictions. And, a few researchers suspect, it may even foreshadow a new perspective on reality.</p>

<ul><li> is a journalist covering developments in the physical sciences both on and off the planet. His work has appeared in <span>Scientific American, The Christian Science Monitor</span> and <span>LiveScience</span>, among other publications. Previously, he taught physics and English in Mozambique and Japan, and he has a bachelorâ€™s in physics from Brown University.</li></ul>
<p>Lead image:&nbsp;<a href="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198" target="_blank" rel="noreferrer nofollow" data-is-link="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198">vchal</a></p>
<p>Video: The brilliant physicist Richard Feynman devised a system of line drawings that simplified calculations of particle interactions and helped rescue the field of quantum electrodynamics.&nbsp;Directed by&nbsp;<a href="http://www.bonscifilms.com/" target="_blank">Emily Driscoll</a>&nbsp;and animated by&nbsp;<a href="http://metteilene.com/" target="_blank">Mette Ilene Holmriis&nbsp;</a>for Quanta Magazine.<br></p>





                    <p>Reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>'s <a href="https://www.quantamagazine.org/category/abstractions/">Abstractions blog</a>.</p>
            </article></div>]]>
            </description>
            <link>http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270579</guid>
            <pubDate>Tue, 25 Aug 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical tips for better microcopy]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24270552">thread link</a>) | @jrdnbwmn
<br/>
August 25, 2020 | https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/ | <a href="https://web.archive.org/web/*/https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        
        <p>Good microcopy is one of the fastest ways to improve an interface. Try doing an audit on your UI with these tips to see how it stands up.</p>

<h2 id="1-use-personal-pronouns">1) Use personal pronouns</h2>

<p>Address the reader instead of just talking out loud. Use the word <em>you</em>. People pay more attention when you talk directly to them.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post1.png">
</figure>

<h2 id="2-start-with-a-verb">2) Start with a verb</h2>

<p>Names for interactive elements should begin with an action verb. The same goes for important copy. Starting with a verb is more direct and engaging.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post2.png">
</figure>

<h2 id="3-prevent-concerns">3) Prevent concerns</h2>

<p>Point out concerning actions before your user can worry about your motives. Be transparent<span>—</span>make sure they understand what they’re doing and why.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post3.png">
</figure>

<h2 id="4-use-natural-language">4) Use natural language</h2>

<p>Write conversationally, like you’re one-on-one. Be professional but get rid of jargon. Use familiar, simple words with a friendly, relaxed tone.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post4.png">
</figure>

<h2 id="5-default-to-active-voice">5) Default to active voice</h2>

<p>Most of the time, active voice is the way to go. It’s easier to understand than passive voice, feels more personal, and is often shorter and stronger.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post5.png">
</figure>

<h2 id="6-show-useful-error-messages">6) Show useful error messages</h2>

<p>Avoid negative, threatening, or overly technical words. Be friendly, show empathy, take the time to explain what’s going on, and be helpful.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post6.png">
</figure>

<h2 id="7-write-iteratively">7) Write iteratively</h2>

<p>We write code iteratively, so why everything else? Things probably won’t be perfect the first time around. Test, refine, ship again. It adds up.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post7.png">
</figure>

<p>Thanks for reading. If you enjoyed the article, sharing on Twitter is really appreciated:</p>

<div>
    <div>
        <blockquote><div lang="en" dir="ltr"><p>Good microcopy is one of the fastest ways to improve an interface. </p><p>Try doing an audit on your UI with these tips to see how it stands up. 👇 <a href="https://t.co/DqRSmVTIvt">pic.twitter.com/DqRSmVTIvt</a></p></div>— Learn UXD (@learn_uxd) <a href="https://twitter.com/learn_uxd/status/1298228761771552773?ref_src=twsrc%5Etfw">August 25, 2020</a></blockquote> 
    </div>
</div>


    </article></div>]]>
            </description>
            <link>https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270552</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24270538">thread link</a>) | @doener
<br/>
August 25, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270538</guid>
            <pubDate>Tue, 25 Aug 2020 12:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure Modular Runtimes]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24270195">thread link</a>) | @ispivey
<br/>
August 25, 2020 | https://guybedford.com/secure-modular-runtimes.html | <a href="https://web.archive.org/web/*/https://guybedford.com/secure-modular-runtimes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I recently posted the following Tweet with regards to the current state of the third-party security problem in the JavaScript ecosystem:

</p><blockquote><div lang="en" dir="ltr"><p>Having worked on and followed modules standards from TC39 and WhatWG to Node.js, it's so so clear that security was, is, and always will be an afterthought.</p><p>Where are the secure-by-default open platform developments? Crypto is the only community I see doing it.</p></div>— Guy Bedford (@guybedford) <a href="https://twitter.com/guybedford/status/1296935308445900801?ref_src=twsrc%5Etfw">August 21, 2020</a></blockquote> 

<p>I wanted to fill in some of the background to this from my own work on Node.js modules and security concepts, following the Agoric SES and compartment models, and from a growing feeling of the inadequacy of the Node.js, Deno and browser runtimes for supporting the third-party security needs of the ecosystem.

</p><p><em>TLDR; I think we need to think about new more secure runtimes for JS, and it should be a collaborative effort, with the components being modules, adding isolated scopes to import maps, and a careful security model plus compatibility with the existing ecosystem. <a href="#secure-modular-runtime-proposal">Skip ahead to the proposal here.</a></em>

</p><p><em>Update: Since posting this, I see that <a rel="noopener" target="_blank" href="https://github.com/Agoric/SES-shim/tree/master/packages/endo">Endo</a> and <a rel="noopener" target="_blank" href="https://github.com/LavaMoat/LavaMoat">LavaMoat</a> provide techniques very close to these directions, although neither has quite yet taken the leap that I argue is necessary that such a security system should be integrated into the primary runtime itself.</em></p>

<h2><a href="#third-party-security-problem">#</a>The Third-Party Security Problem</h2>

<p>The underlying issue is the <code>npm install</code> one. As the registry and our dependence on it continues to expand, the security gap here continues to grow in terms of the amount of untrusted code we are running on a daily basis.

</p><p>Maintainers giving up their time freely now find themselves obliged to respond to regular security issues or risk having unpatchable advisories released for their packages, which may or may not even be genuine escalations of privilege.
  We engage in security theatre to create the illusion of safety, and yet all the while everything remains highly unsecure.

</p><p>Rather than simply accepting the status quo, many companies are actively working on mitigating these security properties. The problem is that they end up creating side ecosystems or patches to the existing ecosystem, security measures that are never fundamentally designed into the ecosystem itself. Third-party security remains a huge if not impossible effort, that only dedicated teams can afford to tackle, as we see for example with these intiatives by <a rel="noopener" target="_blank" href="https://www.figma.com/blog/how-we-built-the-figma-plugin-system/">Figma</a> or <a rel="noopener" target="_blank" href="https://developer.salesforce.com/blogs/developer-relations/2017/02/lockerservice-lightning-container-third-party-libraries-lightning-components.html">Salesforce</a>.

</p><p>The <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms proposal</a> may give us the tools for constructing a secure runtime, but the JavaScript ecosystem conventions themselves work against supporting security restrictions.

</p><p>The general view from Chrome/v8, is that this type of third-party per-package security within the same process isn't possible:

</p><blockquote><p lang="en" dir="ltr">how is this possible post spectre</p>— Sathya Gunasekaran (@_gsathya) <a href="https://twitter.com/_gsathya/status/1297121933004353536?ref_src=twsrc%5Etfw">August 22, 2020</a></blockquote> 

<p>Now I admit I have fully bought in to the elegance of the the OCAP, SES and compartment models, the ideas shared by those at Agoric (who are long-time members of TC39). I gave a session on these concepts at the Node.js Collaboration summit.

</p><p>For all the tremendous benefits of the concept of modular security, there are certainly important questions, but I believe we should actively tackle this work and these questions, and not abandon the same-process modular security models unless they can be fully disproved.

<a name="compartment-model"></a>
</p><h2><a href="#compartment-model">#</a>The Compartment Model</h2>

<p>The gist of the compartment model builds on top of SES (<a rel="noopener" target="_blank" href="https://github.com/Agoric/ses-shim">Secure ECMAScript</a>), as proposed by Agoric, something like the following:

</p><ol>
  <li>All capabilities are imported through the module system (<code>import fetch from 'fetch'</code> kind of thing) - <em>the module resolver acts as the capability system, enforcing permissions</em>.</li>
  <li>The consequence of (1) is that <em>all global capabilities should be disabled / carefully controlled.</em></li>
  <li>JavaScript needs a whole bunch of patching to prevent prototype mutations and unintentional side channels such as <code>return { toString() {} }</code> object hooks. You have to manage package interfaces very carefully and freeze the entire global object from prototype mutation.</li>
</ol>

<p>See the talk by Mark Miller on <a rel="noopener" target="_blank" href="https://www.youtube.com/watch?v=9WdbTucMaRo">Extremely Modular Distributed JavaScript</a>, or my presentation from the Node.js Collaboration Summit,
<a rel="noopener" target="_blank" href="https://docs.google.com/presentation/d/1VUpxoxitZCINJI7jXec4i87YiYZsXr8pCSHdHY5pW30/edit?usp=sharing">Security, Modules and Node.js</a>, for a more in-depth coverage of the full model.

</p><p>The result of this model is, in theory, the ability to restrict destructive code. The date time library you npm install cannot install a trojan horse on your computer, which seems a pretty useful property to have.

</p><p>Towards (3) we already <a rel="noopener" href="https://nodejs.org/dist/latest-v14.x/docs/api/cli.html#cli_frozen_intrinsics">shipped the `--frozen-intrinsics` flag in Node.js</a>. (1) and (2) clearly require breaking changes to what we have in any existing runtimes today.</p>

<h2><a href="#criticisms">#</a>Criticisms</h2>

<p>The criticisms of this model include the Spectre class of vulnerabilities, the difficulty in providing secure cross-package interfaces, and that these ideas might sound good in theory but are impractical in real JS environments.

<a name="spectre"></a>
</p><h3><a href="#spectre">#</a>Spectre</h3>

<p>The Spectre class of attacks means that code running on the same process can use CPU reverse engineering and timing information to read secret information
used by other separate code in the same process. Think - passwords, secure tokens, etc.

</p><p>The first thing to note is that Spectre is the ability to steal secrets and not the ability to install a trojan horse on your computer. Even if we can't fully mitigate Spectre (and we can certainly try), we are still limiting destructive capabilities such as giving full disk and network access
  to random people on the internet, which is a huge win. What we are comparing this model against, is having no separate security for third-party libraries at all, which is the case in Node.js, Deno and browsers today. <em>In the case of an attack, it is better to just lose a credit card, than to lose a credit card AND have your house burnt down.</em>

</p><p>The second thing to note here is that if you have a true capability system and can carefully control network access, then the capability to exfiltrate (basically to use <code>fetch</code>), can itself be treated as a critical permission. Secrets might be discovered but not as easily shared.

</p><p>The counterargument to controlling the capability to exfiltrate is that there are always side channels to be found - the blinking of a light through whatever complex window to share the information of the secret token. It's a complex boundary to mitigate.

</p><p>Finally, in terms of genuine Spectre mitigations, Cloudflare have this same problem for their same-process deployment of Cloudflare Workers, which they recently discussed here - <a rel="noopener" target="_blank" href="https://blog.cloudflare.com/mitigating-spectre-and-other-security-threats-the-cloudflare-workers-security-model/">Mitigating Spectre and Other Security Threats: The Cloudflare Workers Security Model</a>.

</p><p>Their mitigations are summarized at the end, and roughly involve:

</p><ul>
<li>Restricting Date.now() and multi-threading via new Worker (which allows custom timer creation) to attempt to disable the time measurements necessary to initiate the attack.
</li><li>Proactively detecting the attack behaviour based on monitoring and initiating full isolation.
</li><li>Exploring memory shuffling techniques so that secret information does not remain static.
</li></ul>

<p>As Cloudflare mention, this is an active mitigation space that can continue to be developed. In theory, these similar mitigations could apply to new runtime development as well.

</p><p>The important thing to note is that these mitigation techniques do not apply to the Web platform at all as they are simply not possible (at least not without <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms</a>). The Google / v8 position completely makes sense, given this angle,
  but the focus I want to make is on <strong>new JavaScript runtimes</strong>, like successors to Node.js such as Deno and others, <em>which should really be exploring these security properties today</em>.

<a name="insecure-module-interfaces"></a>
</p><h3><a href="#insecure-module-interfaces">#</a>Insecure Module Interfaces</h3>

<p>The next major problem comes down to the complex interface boundary between third-party packages. For example, consider the following code:

</p><pre><code>
import { renderer } from 'renderer';
import { renderGraph } from 'graph';
import { renderTitle } from 'title';

renderer.render([renderGraph, renderTitle]);
</code></pre>

<p>In theory, <code>renderGraph</code> doesn't need any other capabilities other than the ability to call into the renderer so it can be treated as low-trust code.

</p><p>But now consider a malicious implementation of <code>renderGraph</code>:

</p><pre><code>
export function renderGraph () {
  this[1].setTitle('Changed the title');
}
</code></pre>

<p><code>renderGraph</code> knows the renderer will call it via <code>renderArray[i]()</code>, which in JavaScript will set the <code>this</code> binding to the array itself, thus giving access to the title component from the graph component.

</p><p>Yes, it's a contrived example, but it demonstrates how easily you can get capability spillage in JavaScript, and that's before we even get to information spillage eg via <code>toString()</code>.

</p><p>Locking down these sorts of inadvertant side channels means making all package interfaces out of <code>SafeFunction</code> and <code>SafeObject</code> objects that don't have these sorts of awful flaws, and it's not an easy problem to solve - this is where the bulk of the effort needs to be made.

</p><p>The other side of this to consider is that Web Assembly module interfaces don't have these same sorts of capability and information spillage that we have in JavaScript, which certainly gives hope for future ecosystems dealing with these problems.

<a name="impractical-constraints"></a>
</p><h3><a href="#impractical-constraints">#</a>Impractical Constraints</h3>

<p>The third argument is that the security requirements are simply too much of a constraint on JavaScript and its ecosystems. That there exists no path from the ecosystems today to this kind of secure ecosystem. As a result, secure runtimes will always be a fringe effort
  adopted by the few who can invest in the time and effort to support them.

</p><p>This, I believe, is the most crucial problem to solve. The ability to run third-party libraries with less risk should be fully democratized.

<a name="secure-modular-runtime-proposal"></a>
</p><h2><a href="#secure-modular-runtime-proposal">#</a>Secure Modular Runtime Proposal</h2>

<p>I'd like to propose a hypothetical runtime for JavaScript, as a strawman, and to invite scrutiny as to whether this solves the following problems:

</p><ol>
<li>That this runtime can fully restrict high-level capability access from packages for third-party code running in the same process than we have in Node.js, Deno and browsers today.
</li><li>That this runtime can support …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://guybedford.com/secure-modular-runtimes.html">https://guybedford.com/secure-modular-runtimes.html</a></em></p>]]>
            </description>
            <link>https://guybedford.com/secure-modular-runtimes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270195</guid>
            <pubDate>Tue, 25 Aug 2020 11:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Seamless head tracking for games using the TrueDepth camera (iOS)]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24269925">thread link</a>) | @epaga
<br/>
August 25, 2020 | http://www.inflightassistant.com/smoothtrack/index.html | <a href="https://web.archive.org/web/*/http://www.inflightassistant.com/smoothtrack/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <h2>
          <p><a href="https://apps.apple.com/de/app/smoothtrack/id1528839485?l=en"><img src="http://www.inflightassistant.com/img/appstore.svg" height="45/"></a></p>
            
            <p><b><a href="https://testflight.apple.com/join/ytc1tAdA">Click here to join a free public beta</a> which runs on ANY iOS 13 device, not only ones with TrueDepth!</b></p>
            
          <p>SmoothTrack is the best input source for the free OpenTrack software which enables you to use head tracking in your Mac or PC games.</p>
<br>
<div>
  <div>
    <div>
      <p>
        <h6>
          "Just flew a few patterns with this - it genuinely works better for me than TrackIR ever did, at a fraction of the cost." - /u/yawnyprawny
        </h6>
      </p>
    </div>
  </div>
</div>

          <p>SmoothTrack provides you with 6 degrees-of-freedom head tracking for beautiful head tracking for your games.</p>
          

            <p>No headset or extra equipment of any kind is required! Simply set up your device so that it can see your face. Using the on-screen controls, you can shift your perspective in-game.</p>
            

              <p>It's an amazing experience to seamlessly move your head and have your game perspective play along.</p>
              <br>
              <div>
                <div>
                  <div>
                    <p>
                      <h6>
                        "This worked perfectly and way better than expected! Totally enhanced my experience with MFS 2020!" - /u/lexpert1
                      </h6>
                    </p>
                  </div>
                </div>
              </div>
              
              
                <p>Any game that supports the FreeTrack or TrackIR protocol will work with this, including Flight Simulator, Elite: Dangerous, FSX, IL2: Sturmovik, and many, many others!</p>
                

                  <p>INSTRUCTIONS (included in the app):</p>
                  <br>

                    <ol><li>On your computer, install and run the free program "OpenTrack".</li>
                      <li>In OpenTrack, as Input source, choose "UDP over network". As Output, choose "freetrack 2.0 Enhanced".</li>
                        <li>Make sure the UDP port OpenTrack is using is open both on your firewall and router.</li>
                          <li>Find the IP address of your PC</li>
                            <li>Now, in SmoothTrack, set up your IP address and port in the settings</li>
                              <li>Tap Play and you should see the OpenTrack octopus move around, which means any game that supports TrackIR will now be supporting your head tracking!</li>
</ol>
<p>Email support is provided if there are any issues.</p>

    
  
</h2></div></div></div>]]>
            </description>
            <link>http://www.inflightassistant.com/smoothtrack/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269925</guid>
            <pubDate>Tue, 25 Aug 2020 10:43:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incident updates, interruptions and the 30 minute window]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24269804">thread link</a>) | @vinnyglennon
<br/>
August 25, 2020 | https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/ | <a href="https://web.archive.org/web/*/https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>For most companies Incident Commander or Incident Manager is not a
specific job, it’s a role you may take on when something has gone, often
horribly, wrong and you need to quickly unite an adhoc group into a team
to resolve it. The incident commander should be the point of contact,
and source of truth, about your incident and to do that successfully
they’ll need to be updated and kept informed about what’s happening.
Depending on how experienced they are in the role this can be a very
light touch experience or it can feel like being constantly nagged to
put the washing away while someone burns money nearby.</p>
<p>I’ve been involved in a fair few incidents over the years and one of the
best approaches I’ve seen to handling updates and interruptions was from
someone who had an amazing internal clock; or a watch we never noticed.
When handling an incident he’d essentially give himself a 30 minute,
reset-able, window of time. Once he’d been given the initial
introduction to the incident he’d step back, handle the communication
and anything else the incident responders has asked for and wait for
about 30 minutes.</p>
<p>If no one gave him any new information or status updates he’d consider
it an invitation to interrupt and ask what was going on. Once he’d been
updated he’d move back and let the team run with the problem. If someone
gave him an update before the 30ish minutes were up he’d reset his
timer, leave you alone and try to get whatever you’d asked for. I don’t
know if it was just a well chosen period based on experience or the
limit of his patience but 30 minutes was often enough to stop people
rabbit holing while the fires were raging.</p>
<p>Once I’d left the team he often managed incidents for and became one of
his internal customers I began to notice that everyone in his area
developed the subconscious habit of delivering their status updates
every 25 minutes or so, even when he wasn’t the incident manager for
a specific incident. I never discovered if this was all a deliberate
attempt to set the culture he wanted or he was just being himself but as
someone handling an incident I always appreciated the time and
predictability of his involement. Thanks to LinkedIn and Twitter I could
probably track him down and ask but I’ve always liked the idea it was
just him being himself.</p>
</div></div>]]>
            </description>
            <link>https://www.unixdaemon.net/sysadmin/incident-updates-and-interruptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269804</guid>
            <pubDate>Tue, 25 Aug 2020 10:18:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AI Timelines Have Sped Up]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24269316">thread link</a>) | @T-A
<br/>
August 25, 2020 | https://www.alexirpan.com/2020/08/18/ai-timelines.html | <a href="https://web.archive.org/web/*/https://www.alexirpan.com/2020/08/18/ai-timelines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>For this post, I’m going to take artificial general intelligence (AGI) to mean
an AI system that matches or exceeds humans at almost all (95%+)
economically valuable work. I prefer this definition because it focuses on what
causes the most societal change, rather than how we get there.</p>

<p>In 2015, I made the following forecasts about when AGI could happen.</p>

<ul>
  <li>10% chance by 2045</li>
  <li>50% chance by 2050</li>
  <li>90% chance by 2070</li>
</ul>

<p>Now that it’s 2020, I’m updating my forecast to:</p>

<ul>
  <li>10% chance by 2035</li>
  <li>50% chance by 2045</li>
  <li>90% chance by 2070</li>
</ul>

<p>I’m keeping the 90% line the same, but shifting everything else to
be faster. Now, if you’re looking for an argument of why I picked these particular
years, and why I shifted by 10 years instead of 5 or 15, you’re going to be
disappointed. Both are driven by a gut feeling.
What’s important is why parts of my thinking have changed - you can choose
your own timeline adjustment based on that.</p>

<p>Let’s start with the easy part first.</p>

<h2 id="i-should-have-been-more-uncertain">I Should Have Been More Uncertain</h2>

<p>It would be incredibly weird if I was never surprised by machine learning (ML)
research.
Historically, it’s very hard to predict the trajectory a research field will
take, and if I were never surprised, I’d take that as a personal failing to
not consider large enough ideas.</p>

<p>At the same time, when I think back on the past 5 years, I believe I was
surprised more often than average. It wasn’t all in a positive direction.
Unsupervised learning got better way faster than I expected. Deep reinforcement
learning got better
a little faster than I expected. Transfer learning has been slower than
expected. Combined, I’ve decided I should widen the distribution of outcomes,
so now I’m allocating 35 years to the 10%-90% interval instead of 25 years.</p>

<p>I also noticed that my 2015 prediction placed 10% to 50% in a 5 year range,
and 50% to 90% in a 20 year range. AGI is a long-tailed event, and there’s
a real possibility it’s never viable, but a 5-20 split is absurdly skewed.
I’m adjusting accordingly.</p>

<p>Now we’re at the hard part. Why did I choose to shift the 10% and 50% lines
closer to present day?</p>



<p>Three years ago, I was talking to someone who mentioned
that <a href="https://intelligence.org/2017/10/13/fire-alarm/">there was no fire alarm for AGI</a>.
I told them I knew Eliezer Yudkowsky had written another post about AGI, and
I’d seen it shared among Facebook friends, but I hadn’t gotten around to reading it.
They summarized it as, “It will never be obvious when AGI is going to occur.
Even a few years before it happens, it will be possible to argue AGI is far
away. By the time it’s common knowledge that AI safety is the most
important problem in the world, it’ll be too late.”</p>

<p>And my reaction was, “Okay, that matches what I’ve gotten from my Facebook
timeline. I already know the story of
Fermi predicting <a href="https://books.google.com/books?id=aSgFMMNQ6G4C&amp;pg=PA813&amp;lpg=PA813&amp;dq=weart+fermi&amp;source=bl&amp;ots=Jy1pBOUL10&amp;sig=c9wK_yLHbXZS_GFIv0K3bgpmE58&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjNofKsisnWAhXGlFQKHbOSB1QQ6AEIKTAA#v=onepage&amp;q=%22ten%20per%20cent%22&amp;f=false">a nuclear chain reaction was very likely
to be impossible</a>, only a few years before he worked on the
Manhattan Project. More recently, we had
<a href="https://www.wired.com/2014/05/the-world-of-computer-go/">Rémi Coulom state that superhuman Go was about 10 years away</a>,
one year before <a href="https://arxiv.org/abs/1412.6564">the first signs it could happen</a>,
and two years before <a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol">AlphaGo</a> made it official.
I <em>also</em> already know the <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a>
arguments for AI safety.”
I decided it wasn’t worth my time to read it.</p>

<p>(If you haven’t heard the common knowledge arguments, here’s the quick
version: it’s possible for the majority to believe AI safety is
worthwhile, even if no one says so publicly, because each individual could be
afraid everyone else will call them crazy if they argue for drastic action. This can happen
even if literally everyone agrees, because they don’t know that everyone agrees.)</p>

<p>I read the post several years later out of boredom, and
I now need to retroactively complain to all my Facebook friends who only
shared the historical events and common knowledge arguments. Although
that post summary is <em>correct</em>, the ideas I found useful were all
<em>outside that summary</em>. I trusted you, filter bubble! How could you let me
down like this?</p>

<p>Part of the fire alarm post proposes hypotheses for why people claim AGI is
impossible. One of the hypotheses is that researchers pay too much attention
to the difficulty of getting something working with their current tools,
extrapolate that difficulty to the future, and conclude we could never create
AGI because the available tools aren’t good enough.
This is a bad argument, because your extrapolation needs to account for
research tools also improving over time.</p>

<p>What “tool” means is a bit fuzzy. One clear example is our coding libraries.
People used to write neural nets in Caffe, MATLAB, and Theano. Now it’s mostly
TensorFlow and PyTorch. A less obvious example is
feature engineering for computer vision. When was the
last time anyone talked about <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT features</a> for computer vision? Ages ago,
they’re obsolete. But feature engineering didn’t disappear, it just turned into
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural net</a> architecture tuning instead.
For a computer vision researcher, SIFT features were the old tool,
convolutional neural nets are the new tool, and computer vision is the application
that’s been supercharged by the better tool.</p>

<p>Whereas for me, I’m not a computer vision person. I think ML for control is a much
more interesting problem. However, you have to do computer vision to do control
in image-based environments, and if you want to handle the real world, image-based
inputs are the way to go. So for me, computer vision is the tool, robotics
is the application, and the improvements in computer vision have driven many
promising robot learning results.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/filters.png" alt="AlexNet conv filters"></p>

<p>(Filters automatically learned by <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>, which has
itself been obsoleted by the better tool, <a href="https://en.wikipedia.org/wiki/Residual_neural_network">ResNets</a>.)</p>

<p>I’m a big advocate for research tools. I think on average, people underestimate
their impact. So after reading the hypothesis that people don’t forecast
tool improvement properly, I thought for a bit, and decided I hadn’t properly
accounted for it either. That deserved shaving off a few years.</p>

<p>In the more empirical sides of ML, the obvious components of progress are your
ideas and computational budget, but there are less obvious ones too, like
your coding and debugging skills, and your ability to utilize your compute.
It doesn’t matter how many processors you have per machine, if your code doesn’t
use all the processors available.
There are a surprising number of ML applications where the main value-add
comes from better data management and data summarizing,
because those tools free up decision making time for everything else.</p>

<p>In general, everyone’s research tools are deficient in some way.
Research is
about doing something new, which naturally leads to discovering new problems,
and it’s highly unlikely someone’s already made the perfect tool for a problem
that didn’t exist three months ago. So, your current
research tools will <em>always</em> feel janky, and you shouldn’t be using that to
argue anything about timelines.</p>

<p>The research stack has lots of parts, improvements continually happen across that
entire stack, and most of
these improvements have multiplicative benefits. Multiplicative factors
can be very powerful.
One simple example is that to get 10x better results, you can either make one
thing 10x better with a paradigm shift, or you can make ten different
things
<a href="https://www.google.com/search?&amp;q=1.26^10">1.26x better</a>, and they’ll combine
to a 10x total improvement.
The latter is just as transformative, but can be much easier,
especially if you get 10 experts with different skill sets
to work together on a common goal. This is how corporations become a thing.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/tiny-gains-graph.jpg" alt="Tiny gains graph"></p>

<p>(From <a href="https://jamesclear.com/marginal-gains">JamesClear.com</a>)</p>

<h2 id="semi-supervised-and-unsupervised-learning-are-getting-better">Semi-Supervised and Unsupervised Learning are Getting Better</h2>

<p>Historically, unsupervised learning has been in this weird position where it is
obviously the right way to do learning, and also a complete waste of time if
you want something to work ASAP.</p>

<p>On the one hand, humans don’t have labels for most things they learn,
so ML systems shouldn’t need labels either. On the other hand, the
deep learning boom of 2015 was mostly powered by supervised learning on
large, labeled datasets.
Richard Socher made a notable tweet at the time:</p>

<div>
<blockquote><p lang="en" dir="ltr">Rather than spending a month figuring out an unsupervised machine learning problem, just label some data for a week and train a classifier.</p>— Richard Socher (@RichardSocher) <a href="https://twitter.com/RichardSocher/status/840333380130553856?ref_src=twsrc%5Etfw">March 10, 2017</a></blockquote> 
</div>

<p>I wouldn’t say unsupervised learning has always been useless. In 2010, it was
common wisdom that deep networks should go through an unsupervised pre-training
step before starting supervised learning. See <a href="https://jmlr.csail.mit.edu/papers/volume11/erhan10a/erhan10a.pdf">(Erhan et al, JMLR 2010)</a>.
In 2015, self-supervised word vectors like <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>
and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> were automatically
learning interesting relationships between words.
As someone who started ML around 2015,
these unsupervised successes felt like exceptions to the rule. Most other
applications relied on labels. Pretrained ImageNet features
were the closest thing to general behavior, and those features were learned
from scratch through only supervised learning.</p>

<p>I’ve long agreed that unsupervised learning is the future, and the right way
to do things, as soon as we figure out how to do so.
But man, we have spent a long time trying to do so.
That’s made me
pretty impressed with the semi-supervised and unsupervised learning papers from
the past few months.
Momentum Contrast from <a href="https://arxiv.org/abs/1911.05722">(He et al, CVPR 2020)</a>
was quite nice, SimCLR from <a href="https://arxiv.org/abs/2002.05709">(Chen et al, ICML 2020)</a> improved
on that, and Bootstrap Your Own Latent <a href="https://arxiv.org/abs/2006.07733">(Grill, Strub, Altché, Tallec, Richemond et al, 2020)</a>
has improved on that. And then there’s <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>,
but I’ll get to that later.</p>

<p>When I was thinking through what made ML hard, the trend lines were pointing to larger
models and larger labeled datasets. They’re still pointing that way now.
I concluded that future ML progress would be bottlenecked by labeling requirements.
Defining a 10x bigger model is easy. <em>Training</em> a 10x bigger model is harder, but
it doesn’t need 10x as many people to work on it. Getting 10x as many labels
does. Yes, data labeling tools are getting better, <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a> is very popular, and there are even
startups whose missions are to provide fast data labeling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexirpan.com/2020/08/18/ai-timelines.html">https://www.alexirpan.com/2020/08/18/ai-timelines.html</a></em></p>]]>
            </description>
            <link>https://www.alexirpan.com/2020/08/18/ai-timelines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269316</guid>
            <pubDate>Tue, 25 Aug 2020 08:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animal behavior during a solar eclipse]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24268252">thread link</a>) | @everbody
<br/>
August 24, 2020 | https://readwildness.com/23/poli-eclipse | <a href="https://web.archive.org/web/*/https://readwildness.com/23/poli-eclipse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://readwildness.com/23/poli-eclipse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268252</guid>
            <pubDate>Tue, 25 Aug 2020 05:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust-Style Futures in C]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24264841">thread link</a>) | @axelf4
<br/>
August 24, 2020 | https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html | <a href="https://web.archive.org/web/*/https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>All networking applications essentially boil down to stringing together
multiple asynchronous calls in the <em>right</em> way.
Traditionally for programs written in C this would be done through
registering callbacks where the callee either handles the event itself
or dispatches through a state machine.
In such implementations however reasoning about memory safety
can be treacherous, with it sometimes requiring full-program knowledge.
Futures, or promises, as they are also referred to,
ease in that regard by allowing asynchronous programs
to be written in direct style, keeping the control flow linear.</p>

<p>All things considered, I do think that futures can be a good fit
for C programming under the right circumstances.
I also hope this article can serve to help one understand Rust futures,
by being a separate reference that only touches the fundamentals.</p>

<p>The Rust futures story is especially interesting because it is
fundamentally different from the usual workings of futures
in functional languages or, say, JavaScript.
Whereas other implementations are <em>push</em>-based -
meaning you give a function to be pushed to with
the resolved result of the future -
Rust futures are <em>poll</em>-based.
Let us see how this looks in C with the simplification
that we limit ourselves to a single task,
i.e. one top-level future running on one thread.
This is common in embedded programming, and still <em>fairly</em> manageable
without the security guarantees given by Rust.
<a href="https://libuv.org/">libuv</a> is used for the event loop.
No heap allocations will be required - it is all downhill from here
(Get it? Because the stack grows down.) -
other than those imposed by the libuv interface.</p>

<p>The main <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>std::future::Future</code></a> trait
translated into C as a virtual method table becomes</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>{</span> <span>POLL_PENDING</span><span>,</span> <span>POLL_READY</span> <span>};</span>

<span>struct</span> <span>Future</span> <span>{</span>
	<span>enum</span> <span>Poll</span> <span>(</span><span>*</span><span>poll</span><span>)(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>);</span>

	<span>// For now let's skip this method</span>
	<span>// void (*drop)(struct Future *self, struct Context *ctx);</span>
<span>};</span>
</code></pre></div></div>
<p>As an example, let us consider the simplest case:
A future that immediately resolves with the number <code>4</code>,</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>simpleFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>SimpleFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>SimpleFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>self</span><span>-&gt;</span><span>result</span> <span>=</span> <span>4</span><span>;</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>SimpleFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>int</span> <span>result</span><span>;</span>
<span>}</span> <span>simpleFuture</span> <span>=</span> <span>{</span> <span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>simpleFuturePoll</span><span>,</span> <span>}</span> <span>};</span>

<span>// ... and in the event loop</span>
<span>simpleFuture</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>simpleFuture</span><span>,</span> <span>ctx</span><span>);</span> <span>// =&gt; POLL_READY</span>
<span>// Here we can now use the result</span>
<span>simpleFuture</span><span>.</span><span>result</span> <span>// =&gt; 4</span>
</code></pre></div></div>
<p>To <em>attempt</em> to resolve the future, we poll it;
it returns <code>POLL_READY</code> and as such we are done.
And for futures that instead return <code>POLL_PENDING</code> when polled,
we just make sure to poll them again later -
futures are lazy and do not make progress unless actively told to do so.
No one knows better than the future itself when it should
be polled again - <em>awoken</em> -
so the context given to all futures allows them to awake their own task.
With many parallel tasks the additional complexity would make itself apparent here,
but in our case something like</p>
<div><div><pre><code><span>struct</span> <span>Context</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>*</span><span>mainFuture</span><span>;</span>
	<span>uv_loop_t</span> <span>loop</span><span>;</span>
<span>};</span>

<span>void</span> <span>wakeTask</span><span>(</span><span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>if</span> <span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>-&gt;</span><span>poll</span><span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_READY</span><span>)</span> <span>{</span>
		<span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span> <span>// Finished!</span>
	<span>}</span>
<span>}</span>
</code></pre></div></div>
<p>will suffice.
Polling the future once at startup will then kick off the machinery.</p>

<p>For a libuv timer future, we would want to write something like</p>
<div><div><pre><code><span>enum</span> <span>TimerStatus</span> <span>{</span> <span>TIMER_NOT_STARTED</span><span>,</span> <span>TIMER_WAITING</span><span>,</span> <span>TIMER_FINISHED</span> <span>};</span>

<span>struct</span> <span>TimerFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>enum</span> <span>TimerStatus</span> <span>status</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>uint64_t</span> <span>timeout</span><span>;</span>
		<span>uv_timer_t</span> <span>*</span><span>handle</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>static</span> <span>void</span> <span>uvCloseFree</span><span>(</span><span>uv_handle_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>free</span><span>(</span><span>handle</span><span>);</span>
<span>}</span>

<span>static</span> <span>void</span> <span>timerCb</span><span>(</span><span>uv_timer_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>data</span><span>;</span>
	<span>struct</span> <span>Context</span> <span>*</span><span>ctx</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>loop</span><span>.</span><span>data</span><span>;</span>
	<span>uv_close</span><span>((</span><span>uv_handle_t</span> <span>*</span><span>)</span> <span>handle</span><span>,</span> <span>uvCloseFree</span><span>);</span>
	<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_FINISHED</span><span>;</span>
	<span>wakeTask</span><span>(</span><span>ctx</span><span>);</span>
<span>}</span>

<span>static</span> <span>enum</span> <span>Poll</span> <span>timerFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TimerFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>status</span><span>)</span> <span>{</span>
		<span>case</span> <span>TIMER_NOT_STARTED</span><span>:</span>
			<span>uint64_t</span> <span>timeout</span> <span>=</span> <span>state</span><span>-&gt;</span><span>timeout</span><span>;</span>
			<span>state</span><span>-&gt;</span><span>handle</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span> <span>*</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>uv_timer_init</span><span>(</span><span>ctx</span><span>.</span><span>loop</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>handle</span><span>-&gt;</span><span>data</span> <span>=</span> <span>state</span><span>;</span>
			<span>uv_timer_start</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>,</span> <span>timerCb</span><span>,</span> <span>timeout</span><span>,</span> <span>/* no repeat */</span> <span>0</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_WAITING</span><span>;</span>
			<span>/* fallthrough */</span>
		<span>case</span> <span>TIMER_WAITING</span><span>:</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
		<span>case</span> <span>TIMER_FINISHED</span><span>:</span>
			<span>return</span> <span>POLL_READY</span><span>;</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>TimerFuture</span> <span>timerFutureNew</span><span>(</span><span>uint64_t</span> <span>timeout</span><span>)</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TimerFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>timerFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>status</span> <span>=</span> <span>TIMER_NOT_STARTED</span><span>,</span>
		<span>.</span><span>timeout</span> <span>=</span> <span>timeout</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>
<p>The timer handle is made to hold a reference to the future in
its user data field,
so that the callback knows which future to toggle the status on.
However this requires the future object to be pinned in memory,
moving it would make the reference dangling.
Rust deals with this unsafety using the <a href="https://doc.rust-lang.org/std/pin/index.html">Pin construct</a>,
that wraps a pointer type, <code>P</code>,
and only permits operations that cannot move the pointee
(for cases where it may not always be safe to do so, i.e. <code>P: !Unpin</code>)
and ensures its memory remains valid until it gets dropped,
or helps make manually vetted code <em>nonleaky</em>.
In C there is no such thing;
the closest you will get is with a red paragraph buried in the documentation.
This means treading with care,
allocating storage for the main future once and never copying it, and
only referring to futures with pointers to their static place in memory.</p>

<p>Note that it is possible to get by with just one global <code>uv_timer_t</code>
by recognizing that whenever the main future is awoken either:
(I) A timer, necessarily the one with smallest timeout, fired;
or (II) All timers need be dropped and reset, since the futures form a tree,
as we will see.</p>

<h2 id="after-you">After you</h2>

<p>Running multiple futures sequentially is just a matter of
constructing a new future that polls each future to completion,
one after the other.
The poll method of the outer future will have to return <code>POLL_PENDING</code>
after each intermediate step,
before continuing where it left off - like a coroutine.
Rust turns each future into a state machine,
and doing the same in C means playing the part of the Rust compiler.
An adaptation of <a href="https://en.wikipedia.org/wiki/Duff%27s_device">Duff’s device</a>,
as <a href="https://www.chiark.greenend.org.uk/~sgtatham/coroutines.html">described by Simon Tatham</a>,
can help cut down on the boilerplate.
The idea is that with a <code>switch</code> statement enveloping the whole function-body,
you can yield by creating a unique label using the <code>__LINE__</code> macro
where execution will begin upon reentry,
setting the switch-expression as such, and returning.
The following macros do just that</p>
<div><div><pre><code><span>typedef</span> <span>unsigned</span> <span>Coroutine</span><span>;</span>

<span>#define COR_START(s) switch (*(s)) { case 0:;
#define COR_YIELD(s, r) do {*(s) = __LINE__; return (r); case __LINE__:;} while(0)
#define COR_END }
</span></code></pre></div></div>
<p>where <code>s</code> is a pointer to the coroutine state.
Great care has to be taken because when returning all locals are invalidated -
if only there was a language that could statically check for such mistakes.
Awaiting then becomes</p>
<div><div><pre><code><span>#define AWAIT(s, ctx, fut) while ((fut)-&gt;poll((fut), (ctx)) == POLL_PENDING) \
	COR_YIELD((s), POLL_PENDING)
</span></code></pre></div></div>
<p>that is, yielding until the given future is resolved.</p>

<p>To illustrate, here is a future that prints four times to standard output,
first thrice at one second intervals, and then again after two more seconds:</p>
<div><div><pre><code><span>struct</span> <span>TestFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>Coroutine</span> <span>c</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>struct</span> <span>{</span>
			<span>int</span> <span>i</span><span>;</span>
			<span>struct</span> <span>TimerFuture</span> <span>timerA</span><span>;</span>
		<span>};</span>
		<span>struct</span> <span>TimerFuture</span> <span>timerB</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>struct</span> <span>TestFuture</span> <span>testFutureNew</span><span>()</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TestFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>testFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>c</span> <span>=</span> <span>0</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>

<div><table>
<thead><tr><th>With macros</th><th>Desugared</th></tr></thead>
<tbody><tr>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>COR_START</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span>

	<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
		<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
		<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>);</span>
		<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
	<span>}</span>

	<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
	<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>);</span>
	<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>

	<span>COR_END</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span> <span>{</span>
		<span>case</span> <span>0</span><span>:</span> <span>;</span>
		<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
			<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
				<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>1</span><span>;</span>
				<span>return</span> <span>POLL_PENDING</span><span>;</span>
				<span>case</span> <span>1</span><span>:</span> <span>;</span>
			<span>}</span>
			<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
		<span>}</span>

		<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
		<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>2</span><span>;</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
			<span>case</span> <span>2</span><span>:</span> <span>;</span>
		<span>}</span>
		<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
</tr>
</tbody></table></div>
<p>Note that the local <code>i</code> had to be spilled to the future struct
in order to persist across yield points,
and that unions are used to show what variables are active at each step,
and squeeze out that last driblet of performance even in the face of
uncompromising undefined behaviour threats from all directions.</p>

<h2 id="off-to-the-races">Off to the races</h2>

<p>In a similar vein, multiple futures can be made to run in parallel
using a future combinator whose poll method polls all of its children
and either waits for all to complete - <em>joins</em> them,
or selects the first to become ready.
The latter is a tad more difficult, so let us focus on that.
The reason is that after the first future has resolved,
the rest may still be running, their memory possibly referenced elsewhere.
This is where the <code>drop()</code> method that we have skimmed over comes in.
Dropping a pinned object should relax the constraint
that its memory remains valid.
The drop implementation of <code>TimerFuture</code> above could for example
call <code>uv_timer_stop()</code> so the callback never fires
or overwrite the dangling reference to the future with <code>NULL</code>.
For other types, since their drop implementations are …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</a></em></p>]]>
            </description>
            <link>https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264841</guid>
            <pubDate>Mon, 24 Aug 2020 20:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jensen Huang’s vision for data center dominance may destroy the Arm ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 114 (<a href="https://news.ycombinator.com/item?id=24264288">thread link</a>) | @kasabali
<br/>
August 24, 2020 | https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="552" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="680b3ce0" data-element_type="section">
						<div>
							<div>
					<div data-id="c620d2" data-element_type="column">
			<div>
							<div>
						<div data-id="6eb11d27" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>As the weeks pass by, the rumors keep spinning, the likelihood of an Nvidia Arm acquisition increases. On first glance, the two businesses look completely incompatible. A highly vertically integrated graphics and AI company with very high margins buying a low margin IP licensor doesn’t make sense. Nvidia can already build any product they wish as an Arm licensee. Purchasing the whole cow doesn’t yield additional milk or synergies from the current business model. Furthermore, given Nvidia’s reputation as a partner, it would likely even cause customers to start looking for contingencies and accelerate RISC-V adoption. Jensen Huang, in his quest for data center dominance, may destroy the Arm ecosystem for everyone else.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/1.jpg?resize=1140%2C606&amp;ssl=1" alt="1" width="1140" height="606" data-recalc-dims="1"></p><p>The rational for purchasing Arm seems ridiculous to many, but Jensen’s vision is for the datacenter being a computer and Nvidia being the one to build it. They need to be to be completely vertically integrated and control every aspect of this computer. Currently they have the accelerator market on lock-down with their impressive hardware and vast software moat of CUDA/various SDKs which was built by thousands of Nvidia engineers over the last decade. With the acquisition of Mellanox, they bring the “Data Processing Unit (DPU)” of the data center in house as well. They have also continued to expand their vertically integrated software stack to networking with acquisitions of SwiftStack and Cumulus Networks.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/2.jpg?resize=1140%2C575&amp;ssl=1" alt="2" width="1140" height="575" data-recalc-dims="1"></p><p>The datacenter is a 3 legged stool, and the remaining missing piece is a CPU. AMD, Intel, and various hyperscalers are also working to build out their own 3-legged stool. The largest threat to Nvidia is Intel/AMD finally having competent GPUs and software stacks to accompany them. With the US Department of Energy dumping money into SYCL and many in the industry congregating around it, the software front is accelerating rapidly. Furthermore, various hyperscalers are rapidly building out their own CPUs with Arm Neoverse IP to hook in with their accelerators such as the Google TPU and Amazon Inferentia for AI workloads. Lastly, these hyperscalers also already have their own custom network stacks. Nvidia is currently in very strong position, but it is very precarious as their moats may all be eroded simultaneously.</p><p>In any business, in order to maintain a high margin over a long period of time, one must create barriers of entry so high, that no one can break in and disrupt. Even though Intel has stopped executing for essentially 5 years, they are still raking in the dough with &gt;55% gross margins. Jensen Huang’s vision, if fully realized, would see Nvidia building a nearly impenetrable moat that commands high margins and locks customers in. This may sound nefarious, but Nvidia’s solution will be plug and play. The vast majority of companies do not have the resources required to build out the entire software stack to match specialized hardware. Nvidia would offer the best solution, which would eventually become an expensive deal imprisoning you in the Devil’s ecosystem.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/3.png?resize=1140%2C587&amp;ssl=1" alt="3" width="1140" height="587" data-recalc-dims="1"></p><p>This is where acquiring Arm rather than licensing her technology comes into play. Nvidia needs to build the moat, and the only way to do this is to effectively hijack the entire open Arm ecosystem. Developing your own CPU ISA is far too large of an investment and there would be no adoption. Even the opening up of Power and MIPS have failed to stop their slow declines to irrelevancy. RISC-V is also still in its infancy and will take many years to move into any verticals besides embedded.</p><p>Jensen can only realize the of the vision of data center dominance by becoming the only company with the trifecta of CPU, GPU, and DPU. Nvidia can only achieve this by acquiring Arm at an unreasonable price. An independent Arm is simply not worth the $35B-$50B which SoftBank wants. Even a $20B valuation would be high valuation for Arm.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/4.jpg?resize=1140%2C641&amp;ssl=1" alt="4" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia can justify this price if they are willing to flip the semiconductor IP world on its head. The ultimate path to ROI means upending the current Arm business model. Given Nvidia’s over $300B valuation, the deal wouldn’t have to be very dilutive to current shareholders. They would start by purchasing the business in a cash/stock deal and obtaining regulatory approval. Regulatory approval initially seems like a large hurdle, but we believe it will not be. The UK will gladly approve if Nvidia makes commitments for large investments. China would be willing to look the other way if the current Arm China JV drama is swept under the rug. The EU would likely need concessions, but because Nvidia does not compete in most of Arm’s verticals, it shouldn’t be too difficult to obtain approval here either. The US regulators would be foaming at the thought of US control of Arm.</p><p>The next step would involve assuring the clients that the businesses would operate separately. Jensen has already begun telegraphing this according to the <a href="https://www.ft.com/content/b4649576-9541-4857-b3a4-5b4ccb847642">Financial Times</a>.</p><blockquote><p>As the company extends its reach to supply a complete data centre computing platform, it would sell parts of the technology as separate “layers”, Mr Huang said. Other companies would also be able to license its intellectual property for use in their own chips, rather than needing to buy silicon from Nvidia, he added.</p></blockquote><p>As part of the integration of the two companies, Nvidia would cut or sell the Arm Mali GPU and Ethos NPU business. These would be redundant and can be supplemented with Nvidia’s own expertise. This would be quite the shock as Nvidia’s previous attempts to license their GPU architecture have completely failed. If Nvidia is successful in the renewed licensing efforts, we could live in a world where their CUDA architecture with accompanying software stack (read lock-in) is proliferated across phones, embedded, and the upcoming augmented reality segment. There would be some attrition as companies like Samsung have turned to licensing AMD’s RDNA graphics. In general, it would also accelerate the move out of the Arm ecosystem to RISC-V, but this will be a painful and slow move for most.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/5.png?resize=1024%2C395&amp;ssl=1" alt="5" width="1024" height="395" data-recalc-dims="1"></p><p>The key for Nvidia here is creating captive, dependant customers by rocking the boat, but not too violently. If the NvidiArm solution is convenient and cheap, most of the ecosystem will not attempt to rush out. Nvidia likely does not increase prices for a while in order to give their licensees an illusion of a happy status quo. Eventually, these price increases will come. The attrition will be the worst in the embedded market where RISC-V is mostly already here and players like <a href="https://twitter.com/dylan522p/status/1295500585123188737?s=20">Alibaba</a> and Si-Five have the IP nearly ready to go.</p><p>The mobile SOC market is captive to Arm roadmaps for years to come, and this is one of the sectors Nvidia can start aggressively extracting ROI. Apple has a perpetual license and so they won’t be affected, but Qualcomm, Samsung, and Mediatek would start to sweat bullets as their licensing costs soar and they have no alternatives without their own custom core teams which have been disbanded. Mediatek specifically is highly dependent on not only ARM CPUs, but also GPUs and interconnects for many of their SOCs.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/6.png?resize=1140%2C641&amp;ssl=1" alt="6" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia’s largest avenue for ROI comes the data center. x86 is long overdue for some disruption. Even with AMD innovating rapidly, the world wants more options. Arm server development is being done by multiple hyperscalers and independent fabless vendors. Arm is going to break the x86 monopoly with a combination of licensed Neoverse designs and in-house designs from the likes of Nuvia or Marvell. Once the x86 duopoly is broken, Nvidia can also raise prices rapidly here. &nbsp;The hyperscalers in-house Arm Neoverse designs will still have better TCO than any merchant silicon, but the savings will begin to wane.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/7.png?resize=1140%2C641&amp;ssl=1" alt="7" width="1140" height="641" data-recalc-dims="1"></p><p>Another adjacent market where Nvidia can begin to pressure their competition is automotive. While Intel’s Mobileye currently uses MIPS and is transitioning to x86, Tesla and Qualcomm use Arm Cores. If licensing fees ratchet up here significantly, Nvidia can begin to extract margin out of their competitors’ sales. Ultimately, the CPU isn’t a competitive advantage in automotive, but just the cheapest and most convenient option.</p><p>As the Arm ecosystem matures, it will stop being the cheapest option, but only remain the convenient one. Embedded markets have already seen the light of RISC-V and the adoption can only accelerate from here. Other markets have been hooked to the drug of cheap, licensed, Arm IP. With aggressive Nvidia ownership, the junkies will have no choice but to pay up and give in to demands for the short run. They will search for alternative supplies, but this move will take a long time.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/8.jpg?resize=1140%2C642&amp;ssl=1" alt="8" width="1140" height="642" data-recalc-dims="1"></p><p>Nvidia’s endgame isn’t more revenue from licensing costs. Their endgame is a fully vertically integrated data center provider. They will want to make and control every part of the three legged stool. This means they slowly destroy the idea of Neoverse. Whether through making that IP extremely costly, or having their own in house designs be a generation ahead, Nvidia will build a moat around Arm server CPUs. Over time, Jensen Huang will muscle out other Arm vendors supplementing them with Nvidia’s in-house designs. The open Arm ecosystem will be hijacked, and be replaced with a closed off ecosystem rivaling or exceeding that of Intel and AMD.</p><p><span>If Nvidia can quickly seize the worlds most important IP, the most commonly used CPU ISA and designs, they will control the destiny of mobile and data center. This is Jensen Huang’s “Trojan Horse” for a Machiavellian takeover of the future of computing.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264288</guid>
            <pubDate>Mon, 24 Aug 2020 19:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Test Case Generator for a Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24263117">thread link</a>) | @azhenley
<br/>
August 24, 2020 | http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html | <a href="https://web.archive.org/web/*/http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Maxime Chevalier-Boisvert requested resources for learning about fuzzing
programming language implementations on Twitter:</p>

<blockquote>
  <p>I’d like to learn about fuzzing, specifically fuzzing programming language
implementations. Do you have reading materials you would recommend, blog
posts, papers, books or even recorded talks?</p>
</blockquote>

<p><cite><a href="https://twitter.com/Love2Code">@Love2Code</a> · <a href="https://twitter.com/Love2Code/status/1290363848885776385">August 3,
2020</a></cite></p>

<p>Maxime received many replies linking to informative papers, blog posts, and
lectures. <a href="https://twitter.com/johnregehr/status/1290368969199636480">John Regehr suggested writing a simple generative fuzzer for the
programming
language.</a></p>

<p>A generative fuzzer combines a test case generator with the system under test
(e.g. your compiler), generating new test cases and feeding them into the
system:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>generative_fuzzer</span><span>()</span> <span>{</span>
    <span>loop</span> <span>{</span>
        <span>// Use the test case generator to create a new</span>
        <span>// input.</span>
        <span>let</span> <span>input</span> <span>=</span> <span>generate_test_case</span><span>();</span>

        <span>// Feed that input into the system under test.</span>
        <span>let</span> <span>result</span> <span>=</span> <span>run_system_under_test</span><span>(</span><span>input</span><span>);</span>

        <span>// Finally, if the system under test crashed,</span>
        <span>// failed an assertion, etc... then report</span>
        <span>// that!</span>
        <span>if</span> <span>result</span><span>.is_interesting</span><span>()</span> <span>{</span>
            <span>report</span><span>(</span><span>input</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>I realized that many people might not know what it takes to write their own
generative fuzzer, so this blog post shows one aspect of it: implementing a test
case generator.</p>

<p>Our test case generator will generate <a href="https://webassembly.org/">WebAssembly</a> programs. While
WebAssembly has its own quirks — it’s a binary format and is generally a
compilation target rather than a source language — it is a small and
simple language. The techniques we use when generating WebAssembly should
transfer to generating the programming language of your choice.</p>

<p>If you want to skip the exposition and jump head first into the code, <a href="https://github.com/fitzgen/wasm-smith">here is
the repository for our final test case generator</a>.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#what-is-a-test-case-generator">What is a Test Case Generator?</a></li>
  <li><a href="#getting-set-up">Getting Set Up</a></li>
  <li><a href="#translating-grammars-into-generators">Translating Grammars into Generators</a></li>
  <li><a href="#generating-the-type-section">Generating the Type Section</a></li>
  <li><a href="#generating-the-import-section">Generating the Import Section</a></li>
  <li><a href="#generating-the-code-section">Generating the Code Section</a></li>
  <li><a href="#using-the-test-case-generator">Using the Test Case Generator</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="what-is-a-test-case-generator">What is a Test Case Generator?</h2>

<p>Test case generators generate test cases. These test cases are always within the
test domain: no cycles are wasted on invalid inputs, such as source text that
fails to parse. Compare this to <a href="https://www.fuzzingbook.org/beta/html/MutationFuzzer.html">mutation-based fuzzing</a>, where existing seed
inputs are mutated to produce new inputs. In general, nothing guarantees that
the new, mutated input is still within the test domain: the mutation may have
introduced a syntax error. This property, that generated inputs are always
within the test domain, is generative fuzzing’s main advantage and the test case
generator’s main responsibility.</p>

<p>A test case generator should, additionally, support every feature of its target
programming language. You won’t discover a bug in your compiler’s handling of
<code>switch</code> statements if the test case generator doesn’t support generating
<code>switch</code> statements. Pushing this idea even further, the test case generator
should <em>uniformly sample</em> from the test domain. If the test case generator can
technically generate <code>switch</code> statements but the probability of doing so is
nearly zero, then you likely still won’t find that bug. However, uniformly
sampling from the infinite set of all programs that can be written in a
particular programming language is
<a href="https://blog.regehr.org/archives/1700">nontrivial</a> and an area of
<a href="https://arxiv.org/pdf/0807.0992v1.pdf">active</a>
<a href="https://havrikov.github.io/publications/ase19-preprint.pdf">research</a>.</p>

<p>A test case generator should, finally, be fast. The faster we can generate test
cases, the faster we will discover bugs. If the generator is too slow, we can
blow our time budget, failing to find those bugs at all.</p>

<h2 id="getting-set-up">Getting Set Up</h2>

<p>First, we create a new crate with <code>cargo</code>. We’ll name this crate <code>wasm-smith</code>,
giving a little nod to <a href="https://embed.cs.utah.edu/csmith/">Csmith</a>, the popular C program generator.</p>

<figure><pre><code data-lang="shell"><span>$ </span>cargo new <span>--lib</span> wasm-smith</code></pre></figure>

<p>Second, we add <a href="https://github.com/rust-fuzz/arbitrary">the <code>arbitrary</code> crate</a> as a dependency:</p>

<figure><pre><code data-lang="toml"><span># wasm-smith/Cargo.toml</span>

<span>[dependencies]</span>
<span>arbitrary</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.4.6"</span><span>,</span> <span>features</span> <span>=</span> <span>["derive"]</span> <span>}</span></code></pre></figure>

<p>The <code>arbitrary</code> crate helps us generate structured data from arbitrary bytes. It
is typically used in combination with <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> to translate the raw bytes
given to use by libFuzzer into something that the system you’re testing can
process. For example, a color conversion library might use <code>arbitrary</code> to turn
the raw fuzzer-provided bytes into <code>Rgb</code> or <code>Hsl</code> color types. We will use it in
a similar way for this project, translating raw bytes given to us by libFuzzer
into semantically valid WebAssembly modules.</p>

<p>The <code>arbitrary</code> crate’s main export is <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/trait.Arbitrary.html">the <code>Arbitrary</code> trait</a>:</p>

<figure><pre><code data-lang="rust"><span>pub</span> <span>trait</span> <span>Arbitrary</span><span>:</span> <span>Sized</span> <span>+</span> <span>'static</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>;</span>

    <span>// Provided methods hidden...</span>
<span>}</span></code></pre></figure>

<p>It takes an <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/struct.Unstructured.html"><code>Unstructured</code></a>, which is a helpful wrapper around a byte slice, and
returns an instance of the type for which it is implemented.</p>

<p>For our <code>wasm-smith</code> crate, we define a <code>Module</code> type that represents our
pseudo-random WebAssembly modules, and then we implement the <code>Arbitrary</code> trait
for it:</p>

<figure><pre><code data-lang="rust"><span>use</span> <span>arbitrary</span><span>::{</span><span>Arbitrary</span><span>,</span> <span>Result</span><span>,</span> <span>Unstructured</span><span>};</span>

<span>/// A pseudo-random WebAssembly module.</span>
<span>pub</span> <span>struct</span> <span>Module</span> <span>{</span>
    <span>// ...</span>
<span>}</span>

<span>impl</span> <span>Arbitrary</span> <span>for</span> <span>Module</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>todo!</span><span>()</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Before we fill in that <code>todo!()</code> lets take a moment to settle on a design for
what the implementation will look like.</p>

<h2 id="translating-grammars-into-generators">Translating Grammars into Generators</h2>

<p>Writing a generator is remarkably similar to hand-writing a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent
parser</a>, so if you’ve done that before, then you should feel right at home. For
example, given this grammar production (borrowed and lightly edited from <a href="https://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangling">the
C++ name mangling</a> grammar):</p>

<pre><code>&lt;class-enum-type&gt; ::= Ts &lt;name&gt;
                    | Tu &lt;name&gt;
                    | Te &lt;name&gt;
</code></pre>

<p>A recursive descent parser will, almost mechanically, translate the production
into something like this:</p>

<figure><pre><code data-lang="rust"><span>impl</span> <span>Parse</span> <span>for</span> <span>ClassEnumType</span> <span>{</span>
    <span>fn</span> <span>parse</span><span>(</span><span>p</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Parser</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Ts"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Ts"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Ts</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Tu &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Tu"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Tu"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Tu</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Te &lt;name&gt;</span>
        <span>p</span><span>.consume</span><span>(</span><span>"Te"</span><span>)</span><span>?</span><span>;</span>
        <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
        <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Te</span><span>(</span><span>name</span><span>))</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Our generator will do something similar, except instead of peeking at the input
string to decide which right-hand side of the production to parse, we will make
a pseudo-random choice to generate one of those potential right hand sides.</p>

<p>We could use a random number generator directly to make these choices, but this
has two problems:</p>

<ol>
  <li>
    <p>We give up determinism unless we are careful to control the RNG’s seed and
reuse the same RNG everywhere, threading it through all of our functions as a
parameter. Determinism is extremely important for reproducing test failures!
It’s definitely possible to do these things, but can occasionally be a little
annoying.</p>
  </li>
  <li>
    <p>More importantly, using an RNG precludes a mature fuzzing engine, like
libFuzzer, from guiding our test case generation based on code coverage and
other insights.</p>
  </li>
</ol>

<p>Instead, we use a raw input byte slice given to us by libFuzzer or AFL as a
sequence of predetermined choices.<sup id="back-dont-require-libfuzzer"><a href="#foot-dont-require-libfuzzer">0</a></sup> This <a href="https://arxiv.org/pdf/1812.00078v1.pdf">lets the fuzzer guide our
test case generation</a>, and <a href="https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf">gives us test case reduction “for
free”</a> since we can ask the fuzzer to reduce the raw input
sequence, rather than write a domain-specific test case reducer. This comes as a
relief because writing a reducer that understands WebAssembly is easily as much
effort as writing the generator itself.</p>

<p>Here is the same C++ mangling example from above, but translated from a parser
into a generator, using <code>Unstructured</code>:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_class_enum_type</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>output</span><span>:</span> <span>&amp;</span><span>mut</span> <span>String</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
    <span>match</span> <span>u</span><span>.int_in_range</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>(</span><span>0</span><span>..=</span><span>2</span><span>)</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>0</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Ts"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Tu &lt;name&gt;</span>
        <span>1</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Tu"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Te &lt;name&gt;</span>
        <span>2</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Te"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>_</span> <span>=&gt;</span> <span>unreachable!</span><span>(),</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Once again, this is mostly mechanical.</p>

<p>This pattern will generate <em>syntactically</em> correct test cases that can be parsed
successfully but which likely contain a plethora of type errors, calls to
undefined functions, etc. We’ve set out to generate <em>semantically</em> correct test
cases that pass type checking and will exercise more than just the language
implementation’s frontend.</p>

<p>Our final pattern maintains some extra information about the program we’ve
generated thus far, so that we can consult that information when generating new
forms. This extra information might include which names are in scope, the types
of each variable, etc. We consult that information while dynamically building up
thunks for every valid option we could generate. Once we have enumerated every
option, we ask the <code>Unstructured</code> to choose one of them, and finally we call the
chosen thunk to generate the form.</p>

<p>Here is an example of using this pattern for generating integer expressions,
where an integer expression is either a constant integer, an arithmetic
operation, a use of an integer variable, or a call of a function that returns an
integer:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_int_expr</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>scope</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
    <span>// We will dynamically build up all of the valid</span>
    <span>// options of what we can generate.</span>
    <span>let</span> <span>mut</span> <span>options</span><span>:</span> <span>Vec</span><span>&lt;</span><span>fn</span> <span>(</span>
        <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
        <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
    <span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;&gt;</span> <span>=</span> <span>vec!</span><span>[];</span>

    <span>// It is always valid to generate a constant.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>_</span><span>|</span> <span>{</span>
        <span>Ok</span><span>(</span><span>Expr</span><span>::</span><span>Constant</span><span>(</span><span>u</span><span>.arbitrary</span><span>::</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>()</span><span>?</span><span>))</span>
    <span>});</span>

    <span>// It is always valid to generate an addition.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>scope</span><span>|</span> <span>{</span>
        <span>let</span> <span>lhs</span> <span>=</span> <span>arbitrary_int_expr</span><span>(</span><span>u</span><span>,</span> …</code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</a></em></p>]]>
            </description>
            <link>http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263117</guid>
            <pubDate>Mon, 24 Aug 2020 17:36:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking Resilience with Roy Bahat of Bloomberg Beta]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24263090">thread link</a>) | @RoboCornell88
<br/>
August 24, 2020 | https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta | <a href="https://web.archive.org/web/*/https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p>Our <strong>12 Questions</strong> series takes you into the minds of influential leaders to discuss today’s hot topics. Read their fresh views on leadership, managing through change, and the ins and outs of modern work. Think of it as your office hours with some of the most innovative people in business.</p><p>We continue this series on resilience with <a href="https://www.linkedin.com/in/roybahat/" rel="noopener" target="_self">Roy Bahat</a>. Roy is the head of Bloomberg Beta, a venture fund backed by Bloomberg L.P. that invests in companies that make business work better. Roy has been an entrepreneur (started a venture-backed video game console), a public company executive (at News Corporation), a board member for companies and nonprofits, and in government (in his hometown of New York). When he’s not teaching media at U.C. Berkeley’s Haas School of Business or investing in the future of work, he’s also not sharing advice on <a href="https://twitter.com/roybahat" rel="noopener" target="_self">Twitter</a>.</p><hr><p><strong>Thanks for joining us for 12 Questions, Roy. Can you describe your career in twelve words or less</strong></p><p>A determined random walk that only became clear in retrospect.<br></p><p><strong>That's very meta. Do you want to expand on that mental image?</strong></p><p>Sure. I was always jealous of the people who knew what they wanted to do. I had to work in a bunch of settings to figure out where my home was: from nonprofit, academia, and government to professional services, startups, and big corporations. And I think my "home" is in supporting people who are building new organizations. At the moment, that's venture-backed startups.<br></p><p><strong>Let's dive into a topic that is top of mind for most people, given the state of the world right now. What does resilience mean to you?</strong></p><p>I think we often treat resilience as an innate characteristic of people. But I believe that it's a skill that we use to recover from hardship through repeated attempts and self-management to keep ourselves going.<br></p><p><strong>So, how has your thinking about resilience changed in 2020?</strong></p><p>I've come to a realization this year that in the startup world, we love the myth of the heroic individual—and resilience is a part of that myth. It's something I've thought about a lot, but the current situation has confirmed it for me. While I believe in an individual creators' power, we often take the focus off the system that enables them to be resilient. And it takes the focus off the differences that make one person's resilience easier to practice than another.</p><p>There are many psychological reasons why that happens, including the fact that all successful people had to overcome some hardship. But that doesn't make their hardship equivalent to somebody else's. So in the aftermath of the protest surrounding George Floyd's murder and the changed circumstances with the pandemic, it reminded me that resilience is something that stems from having the opportunity to show you can be resilient.</p><p><strong>Resilience as a proxy for opportunity. Curious: when was the last time you checked-in with yourself?</strong></p><p>This morning. I try to have a scientist's attitude about it, which is to say hypotheses that you falsify.</p><p>If you're confident you're going in the right direction regardless of what the evidence says, you're probably not paying attention to the world. So I ask myself a lot, "how do I know if I'd be wrong?" And one of the places <a href="https://www.linkedin.com/in/roybahat/detail/recent-activity/posts/" rel="noopener" target="_self">I've written about that is on LinkedIn</a>. I try to write an <a href="https://also.roybahat.com/your-career-is-a-mess-a8a58acd18fa" rel="noopener" target="_self">honest accounting</a> of what I was thinking and what was right or wrong about different choices. Unless I can learn from them, I don't know where I'm going.</p><p><strong>Is there a time when you wish you were more resilient?</strong></p><p>It might just be because of this present moment, but I think I'm one of these people who tries to think of myself as a good person and do the right thing. And so I can be fragile when critiqued around bias, whether that's sexism or racism because it doesn't align with how I think about what I try to do. And so, I wish that I could've been more resilient in not dismissing that the first few times it came up in my life and try to learn from it.</p><p><strong>Related, what's one big mistake you made, and how did you bounce back from that?</strong></p><p>I should have proposed to my wife years before I did.</p><p>I used to think relationships should all be easy. I was mistaken. Any relationship worth having is one you should take seriously and keep working on it. I wrote a <a href="https://also.roybahat.com/what-our-kids-see-7dc650be8a90" rel="noopener" target="_self">blog post</a> a few years ago now about my son asking me to get off my phone. It stung. But my relationship with my son matters more to me than my ego, and when something I do hurts him, I want to pay attention and grow from it.<br></p><p><strong>In your view, how can people be more resilient in their work-life?</strong></p><p>We should think of resilience as a skill or a muscle. You see something you want to achieve and the obstacle to it and then get resourceful. I think the mistake is being in a situation where you weren't resilient, which leads to some inherent judgment about you as a person versus "you know I didn't hit that basket, I've got to try again."<br></p><p><strong>How does being vulnerable help in building a resilient team?</strong></p><p>The more I see the humanity in the people with whom I am working, the better I can work with them. I know where they're coming from, and I have empathy for them because of that. Somewhat connected to the hero myth—being resilient and being cold is not the same thing.</p><p><strong>Who is the most resilient person that you know, and why?</strong></p><p>Honestly, there are probably many I don't realize are resilient because they keep their struggles private. <a href="https://adeolonoh.com/page/2/" rel="noopener" target="_self">Ade Olonoh</a> wrote a recent <a href="https://www.formstack.com/blog/2020/why-we-should-talk-about-race-ade-olonoh/" rel="noopener" target="_self">piece about race issues</a> and how he struggled to talk about it. I've known the guy for years, and I didn't realize this was something he was going through. So, that makes me think about all the other people who are there who have a sort of silent resilience.</p><p>In terms of people I know, I'd say my wife. She had a much more difficult upbringing that I did economically, and the fact that she's the amazing person that she is, I think, is a sign of resilience. And my mom. My dad passed away when I was 12, and my mom persevered. My brother and I were never worried about things falling apart because she handled it. But again, are they the most resilient people I know? Maybe not. They're the people I know the most about their resilience.</p><p><strong>If you could give people one piece of advice about what's going on in the world right now, what would it be?</strong></p><p>Well, first, I have to say that I'm allergic to the idea of giving advice.</p><p>Someone once told me that all advice is autobiographical. Whether it's one person trying to get you to justify what they do to feel better about themselves or, worse, they're trying to live vicariously through you as an experiment for themselves. Either way, it's not in your interest. I do this <a href="https://twitter.com/search?q=%23thisisnotadvice&amp;src=typed_query&amp;f=live" rel="noopener" target="_self">daily series of tips about work on Twitter</a>, where I go deeper into this concept.</p><p>From my experience, I would say to look at what's happening in the world as a project. And not like a side project. You have to put it front and center for yourself and amp up your experimentation on what's working for you. If that means limiting the amount of news you consume to a few hours a day or eating healthier, taking a long bath, calling someone you love every day, fighting for social justice, etc. Treat yourself as the subject of your experiments. I made a list of 14 things that might work to help myself get through this time, and I think I had to do 12 of the 14 before I felt much better. And now I'm in a much clearer place, but it's still a work in progress.<br></p><p><strong>What are some books or resources you'd recommend on resilience, or that help with getting through tough times?</strong></p><p>Read more fiction. I think we tend to read these abstract advice books about grit and related topics, but for me, what keeps me going are the stories I experience in my own life and the stories I read. Of course, you should listen to the Brene Brown TED talk on vulnerability and shame—it's really good. But I would read stories written by authors who had to go through tough times to get to where they are.</p><p>The new one I've started is <a href="https://www.wsj.com/articles/nk-jemisin-city-became-book-coronavirus-11597764521" rel="noopener" target="_self">N. K. Jeminsin</a>, because I've never read any of her stuff before, and I've gotten a lot out of <a href="https://en.wikipedia.org/wiki/John_Irving" rel="noopener" target="_self">John Irving's books</a>—A Prayer for Owen Meany is one of my favorite novels. The sustenance for progress is examples, and we get those examples from a specific technology: stories.</p><p><a href="https://twitter.com/roybahat?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" rel="noopener" target="_self"><img src="https://cdn.sanity.io/images/e422uarq/production/96577fbf0ed9b0619149cc5f5d8dc663554a299d-2316x2316.jpg?fm=jpg&amp;w=330&amp;dpr=2&amp;q=40" alt="Roy Bahat and family"></a></p><hr></div></div></section></div>]]>
            </description>
            <link>https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263090</guid>
            <pubDate>Mon, 24 Aug 2020 17:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24262336">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262336</guid>
            <pubDate>Mon, 24 Aug 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I helped fix Canadaʼs Covid Alert app]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24262236">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app | <a href="https://web.archive.org/web/*/https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="https://pm.gc.ca/en/news/news-releases/2020/07/31/new-mobile-app-help-notify-canadians-potential-covid-19-exposure-now">On July 31st</a>, Canada's <a href="https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covid-alert.html">COVID Alert</a> app was made available for general use, though it does not have support for actually <em>reporting</em> a diagnosis in most provinces, yet.</p>
<p>In Quebec, we can run the tracing part of the app, and if diagnosis codes become available here, the app can retroactively report contact. It uses the tracing mechanism that <a href="https://covid19.apple.com/contacttracing">Google and Apple created together</a>, and in my opinion—at least for now—Canadians should be running this thing to help us all deal with COVID-19. I won't run it forever, but for now, it seems to me that the benefits outweigh the "government can track me" fear (it's not actually tracking you; it doesn't even know who you are), and it's enabled on my phone.</p>
<p>But, before I decided to take this position and offer up my own movement data, I wanted to be sure the app is doing what it says it's doing—at least to the extent of my abilities to be duly diligent. (Note: it's not purely <em>movement</em> data that's shared—at least without more context—but it's actual physical interactions with other people whose phones are available within the radio range of Bluetooth LE.)</p>
<p>Before installing the app on my real daily-carry phone, I decided to put it on an old phone I still have, and to do some analysis on the most basic level of communication: who is it contacting?</p>
<p>In 2015, I gave a <a href="https://prezi.com/iqwzy66rn3uo/inspect-https-with-your-own-man-in-the-middle-non-attacks/">talk</a> at <a href="https://confoo.ca/en">ConFoo</a> entitled "<em>Inspect HTTP(S) with Your Own Man-in-the-Middle Non-Attacks</em>", and this is exactly what I wanted to do here. The tooling has improved in the past 5 years, and firing up <em>mitmproxy</em>, even without ever having used it on this relatively new laptop, was a one-liner, thanks to <a href="https://nixos.org/learn.html">Nix</a>:</p>
<pre><span>nix-shell -p mitmproxy --run mitmproxy</span>
</pre>

<p>This gave me a terminal-based UI and proxy server that I pointed my old phone at (via the Wifi Network settings, under HTTP proxy, pointed to my laptop's local IP address). I needed to have mitmproxy create a Certificate Authority that it could use to generate and sign "trusted" certificates, and then have my phone trust that authority, by visiting <code>http://mitm.it/</code> in mobile Safari, and doing the certificate acceptance dance (this is even more complicated on the latest versions of iOS). Worth noting also, is that certain endpoints such as the Apple App Store appear to use <a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">Certificate Pinning</a>, so you'll want to do things like install the COVID Alert app from the App Store before turning on the proxy.</p>
<p>Once I was all set up to intercept my own traffic, I visited some <code>https://</code> URLs and saw the request flows in mitmproxy.</p>
<p>I fired up the COVID Alert app again, and noticed something strange… something disturbing:</p>
<p><img src="https://files.scoat.es/covid-tracker-traffic.png" title="COVID Alert app traffic in mitmproxy" alt="shows that the app is accessing clients.google.com"></p>
<p>In addition to the expected traffic to <code>canada.ca</code> (I noticed it's using <code>.alpha.canada.ca</code>, but I suspect that's due to the often-reported unbearably-long bureaucratic hassle in getting a <code>.canada.ca</code> TLS certificate, but that's another story), my phone, when running COVID Alert, was contacting Google.</p>
<pre><span>HEAD https://clients4.google.com/generate_204</span>
</pre>

<p>A little web searching helped me discover that this is a commonly-used endpoint that helps developers determine if the device is behind a "captive portal" (an interaction that requires log-in or payment, or at least acceptance of terms before granting wider access to the Web). I decided that this was <em>probably</em> unintended by the developers of COVID Alert, but it still bothered me that an app, designed for <em>tracking interactions between people['s devices]</em>, that the <em>government</em> wants us to run is telling Google that I'm running it, and disclosing my IP address in doing so:</p>
<p><img src="https://files.scoat.es/covid-alert-google.png" title="A request to clients.google.com, from the COVID Alert app" alt="shows that the User Agent header identifies the app as " covid="" alert="" version=""></p>
<p>(Note that the app clearly identifies itself in the <code>User-Agent</code> header.) </p>
<p>A bit more quick research turned up a <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/pipeda-compliance-help/pipeda-interpretation-bulletins/interpretations_02/#fn50-rf">statement by Canada's Privacy Commissioner</a>:</p>
<blockquote><p>An Internet Protocol (IP) address can be considered personal information if it can be associated with an identifiable individual. For example, in one complaint finding, we determined that some of the IP addresses that an internet service provider (ISP) was collecting were personal information because the ISP had the ability to link the IP addresses to its customers through their subscriber IDs.</p></blockquote>

<p>It's not too difficult to imagine that Google <em>probably</em> has enough data on Canadians for this to be a real problem.</p>
<p>I discovered that this app is maintained by the <a href="https://digital.canada.ca/">Canadian Digital Service</a>, and that the <a href="https://github.com/cds-snc/covid-alert-app">source code is on GitHub</a>, but that the <a href="https://github.com/cds-snc/covid-alert-app/search?q=clients3.google.com&amp;unscoped_q=clients3.google.com&amp;type=Code">code itself didn't directly contain any references to <code>clients3.google.com</code></a>.</p>
<p>It's a <a href="https://reactnative.dev/">React Native</a> app, and I figured that the call out to Google must be in one of the <a href="https://github.com/cds-snc/covid-alert-app/blob/master/package.json">dependencies</a>, which—considering the norm with JavaScript apps—are pleasantly restrained mostly to React itself. I had no idea which of these libraries was calling out to Google.</p>
<p>Now, I could have run this app on the iOS Simulator (which did I end up doing to test my patches, below), but I thought "let's see what my <em>actual</em> phone is doing." I threw caution to the wind, and I ran <a href="https://checkra.in/">checkra1n</a> on my <em>old</em> phone, which gave me ssh access, which in turn allowed me to copy the app's application bundle to my laptop, where I could do a little more analysis (note the app is bundled as <em>CovidShield</em> because it was previously <a href="https://www.covidshield.app/">developed by volunteers at Shopify</a> and was then renamed by CDS (or so I gather, anyway)).</p>
<pre><span>~/De/C/iphone/CovidShield.app ▶ grep -r 'clients3.google.com' *</span>
<span>main.jsbundle:__d(function(g,r,i,a,m,e,d){Object.defineProperty(e,"__esModule",{value:!0}),</span>
<span>e.default=void 0;var t={reachabilityUrl:'https://clients3.google.com/generate_204',</span>
<span>reachabilityTest:function(t){return Promise.resolve(204===t.status)},reachabilityShortTimeout:5e3,</span>
<span>reachabilityLongTimeout:6e4,reachabilityRequestTimeout:15e3};e.default=t},708,[]);</span>
</pre>

<p>(Line breaks added for legibility.) Note <code>reachabilityUrl:'https://clients3.google.com/generate_204</code>. Found it! A bit more searching led me to a package called <code>react-native-netinfo</code> (which was directly in the above-linked <code>package.json</code>), and its <a href="https://github.com/react-native-community/react-native-netinfo/blob/4e3e9813fbae89013bbeee6470b005b6d923e022/src/internal/defaultConfiguration.ts#L2">default configuration</a> that sets the <code>reachabilityUrl</code> to Google.</p>
<p>Now that I knew where it was happening, I could fix it.</p>
<p>To make this work the same way, we needed a reliable <code>204</code> endpoint that the app could hit, and to keep with the expectation that this app should not "leak" data outside of <code>canada.ca</code>, I ended up <a href="https://github.com/cds-snc/covid-alert-server/pull/241">submitting a patch</a> for the <a href="https://github.com/cds-snc/covid-alert-server">server side code</a> that the app calls. (It turns out that this was not necessary after all, but I'm still glad I added this to my report.)</p>
<p>I also <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">patched</a>, and tested the app code itself via the iOS Simulator.</p>
<p>I then submitted a write-up of what was going wrong and why it's bad, to the main app repository, as <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">cds-snc/covid-alert-app issue 1003</a>, and felt pretty good about my COVID Civic Duty of the day.</p>
<p>The fine folks at the Canadian Digital Service seemed to recognize the problem and agree that it was something that needed to be addressed. A few very professional back-and-forths later (I'll be honest: I barely knew anything about the CDS and I expected some runaround from a government agency like this, and I was pleasantly surprised), we landed on a solution that simply didn't call the reachability URL at all, and they <a href="https://github.com/cds-snc/covid-alert-app/releases">released a version of the app</a> that fixed my issue!</p>
<p><img src="https://files.scoat.es/covid-alert-release.jpg" title="COVID Alert release notes showing my fix" alt=""></p>
<p>With the new version loaded, I once again checked the traffic and can confirm that the new version of the app does not reach out to anywhere but <code>.canada.ca</code>.</p>
<p><img src="https://files.scoat.es/covid-alert-no-google.png" alt="A mitmproxy flow showing traffic to canada.ca and not google.com"></p>
</div>
    </div></div>]]>
            </description>
            <link>https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262236</guid>
            <pubDate>Mon, 24 Aug 2020 16:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 2: Shannon's story]]>
            </title>
            <description>
<![CDATA[
Score 408 | Comments 297 (<a href="https://news.ycombinator.com/item?id=24261948">thread link</a>) | @usefulcat
<br/>
August 24, 2020 | https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-clbfl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_900,h_450,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-7adfi">How much Vitamin D should I take? This is still the looming question, and it’s time to address it. </h3><p id="viewer-9k73p">First, though, imagine that someone in a public forum online asked me, “How much metoprolol (a common blood pressure medication) should I take?” It would be clear that I could not give a real answer. I could give a heavily qualified blanket statement that covered indications and common starting doses, and then recommended speaking with a doctor regarding a personalized dosage. I wouldn’t give a specific dose. But no one would expect me to.  Metoprolol is a medication, and medications are usually prescribed by a physician.</p><p id="viewer-7tpp4">We think of vitamins and supplements differently. A few readers have made comments like this: “I understand that the evidence for Vitamin D in healthy adults doesn’t really show a benefit, but I take Vitamin D because it probably won’t hurt me, and it might help.” This is a common sentiment regarding supplements, but not a statement that most people would make about metoprolol, or any prescribed medication.  Medications are generally understood to be substances taken in response to a specific disease or condition, and we hope that research has shown that they work. Supplements are given a pass; we take them if they might help, even though they may not be needed. </p><p id="viewer-2fbtq"><strong>But Vitamin D should be thought of as a medication</strong>, despite being sold over-the-counter in the supplements aisle. </p><p id="viewer-5549c">To illustrate this, let me introduce Shannon. </p><p id="viewer-518ch">In the fall of 2018, Shannon R. was the special education director for a large Arizona school district. Normally energetic and expressive, the otherwise healthy 38-year-old began having an odd and disturbing symptom: difficulty speaking. Her husband and two boys would ask her questions, and though understanding the question, she was unable to formulate the words to respond. </p><p id="viewer-e7f4v">Milder problems had started over the summer, when she felt more tired than usual. As the months passed, new symptoms appeared: palpitations, insomnia, anxiety, along with cognitive deficits – “like my brain wouldn’t function,” she recalled. Her heart rate, normally in the 60s, now often stayed in the 90s, even while in bed. She barely slept at night and lost nearly 50 pounds. By mid-semester, she was often unable to work. At around 1 AM one October morning, she was taken to the emergency room for a racing heart. When there, she had difficulty responding to the doctors’ and nurses’ questions. After a full workup, the doctors had no explanation, so they resorted to what doctors often reach for when confronted with mystery ailments: psychiatric illness. </p><p id="viewer-fu7id">Shannon would be hospitalized several times for “catatonia,” a general symptom describing difficulty with speaking or moving that is caused by certain psychiatric conditions like depression and schizophrenia. Though she had never exhibited mental illness before, doctors assumed that Shannon had developed a severe psychiatric disorder. </p><p id="viewer-4pb27">Shannon’s husband, as well as her new psychiatrist, doubted this diagnosis, and sought second and third opinions. By the time she contacted me four months later, they had consulted multiple specialists at three different hospitals around the state, but still did not have an explanation for her physical and mental decline. There was something that all of the doctors had noticed, though. Her blood calcium levels were often mildly to moderately elevated above normal, up to 11.1 mg/dl (normal for her age would be up to 10.2 mg/dl). The cause of this was unclear, but her doctors did not believe that this incidental finding was relevant to her current issues, and did not pursue it. <strong>Shannon was not taking calcium supplements at all throughout this time, but her levels were still high.</strong> When she emailed me in February 2019, she was desperate for answers and thought the calcium levels might be a clue. </p><p id="viewer-1miap">My specialty is parathyroid disease, which is the most common cause of high calcium. Based on her parathyroid hormone tests, it did not appear that Shannon had parathyroid disease. But she had high calcium levels, and the rise in those levels correlated with the onset of her symptoms. High calcium levels might initially appear to be a good thing, since we need calcium for our bones. But they are not. High blood calcium levels usually indicate a serious illness.</p><div id="viewer-ep36c"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_900,h_434,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-5d4om"><em>Calcium is known for its role in bone health, but its role in the brain and nervous system is just as important. Calcium levels need to be within a small range; anything too high or too low can cause problems.  Image by </em><a href="https://www.bigstockphoto.com/search/?contributor=madrock24" target="_blank" rel="noopener">madrock24</a> on <a href="http://bigstockphoto.com/" target="_blank" rel="noopener"><u>bigstockphoto.com</u></a></p><p id="viewer-115r5">Most patients with high calcium develop fatigue and body aches, and just generally feel bad. They may develop insomnia and palpitations, a feeling like the heart is racing. Some have more severe neurologic symptoms like muscle weakness and problems with balance, and some have psychiatric symptoms like depression and anxiety. Untreated high calcium can also lead to kidney stones, kidney failure, cardiac arrhythmias, headaches, and gastrointestinal problems. Shannon had some of the classic symptoms, as well as what appeared to be more severe “psychiatric” symptoms. I suspected they were all related to her calcium levels. </p><p id="viewer-bac7q">But why was her calcium high? The parathyroid glands exist to regulate calcium, and they do a very good job at it, keeping blood calcium within a tight range. Usually, a problem with calcium indicates a problem with the parathyroids. But over the last few years I have had more patients coming to me with high calcium related to something else: Vitamin D. </p><p id="viewer-6d1js"><strong>Vitamin D is a steroid hormone</strong>, in the same category as sex hormones like estrogen and testosterone, and glucocorticoids like the stress hormone cortisol. Steroid hormones are all made from cholesterol, and looking at their molecular structures, you can see the similarities. </p><div id="viewer-6s0p9"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_1586,h_972,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-3upia">Like the other steroid hormones, Vitamin D acts on multiple organs and only tiny amounts of the molecule are required to have substantial effects. Anyone who has gone through puberty understands the impressive physiologic changes brought about by relatively small shifts in hormone levels. Not surprisingly, most steroid hormones are considered medications that require a physician's order. Vitamin D is an exception. In the U.S., high dose Vitamin D can be purchased by anyone, without a prescription, in most drugstores and grocery stores. It is called a dietary supplement, which sounds safer than a medication, but this is misleading. Due to its role in calcium absorption, high dose Vitamin D can cause serious problems. </p><p id="viewer-21t00">Eventually we worked out what happened with Shannon: In 2013 she was diagnosed with mild osteopenia, a thinning of the bones that can be a precursor to osteoporosis. Her Vitamin D was low at the time, so her physician started her on over-the-counter Vitamin D supplementation at 5000 international units (IUs) daily. Five years later, she was still on this dose, and her blood Vitamin D level had risen to 79 ng/ml. This level is within what many labs call the normal range, between 30 and 100 ng/ml, but levels above 70 are almost always a result of high dose supplementation, and I have seen toxicity with levels between 70 and 100 ng/ml. (A better “normal range” based on what I have seen would probably be between 30 and 60.) Vitamin D builds up over time, so the longer someone is on a high dose, the more likely she is to develop toxicity. Shannon’s calcium levels began rising in the fall of 2018, when her severe symptoms developed. </p><p id="viewer-c0tav">Ironically, Shannon started to recover because she became too sick to worry about taking her vitamins, and stopped taking Vitamin D in October. It often takes many months for high Vitamin D levels to drop, and it took six months for Shannon’s level to fall into the 50s. As it fell, her calcium level gradually started to normalize, and her symptoms slowly resolved. By May, she was starting to feel like herself again. </p><p id="viewer-208hf">I spoke with Shannon recently. All of the symptoms that characterized her frightening and rapid decline in health had resolved completely. Listening to this animated woman, it was difficult to imagine her unable to talk. The only lingering effects appeared to be a wariness of physicians and distrust of vitamins, both understandable. Shannon agrees that Vitamin D should be treated like a medication. “It’s a hormone!” she exclaimed. “If I had to take ‘Hormone D’, I would have questioned my doctor about why I needed it.” Shannon is now committed to educating others about Vitamin D. </p><p id="viewer-16oc8">Of course, there is a selection bias in who comes to me. There are people out there doing just fine on 5000 units of Vitamin D daily. I only see the ones who develop high calcium levels. But I see enough of them to know that this is not an exceptionally rare occurrence. I have been to lectures in which physicians have claimed that Vitamin D toxicity almost never occurs. In my experience, this is false. I have seen many cases of Vitamin D toxicity in people who were taking the recommended dose from an over-the-counter bottle.</p><p id="viewer-8pgar">Unfortunately, none of those patients were warned about the potential for Vitamin D to cause high calcium. They all believed that they were taking a supplement to improve health and that there was very little risk. Supplements don’t require prescriptions, and most do not have the warning labels that accompany medications. For Vitamin D, a steroid hormone, that may need to change. </p><p id="viewer-4ie1g"><strong>So, how much Vitamin D should you take? </strong></p><p id="viewer-9iecb">Vitamin D should be approached like a medication that is used to treat low calcium levels and low levels of the hormone called Vitamin D. The dose depends on your calcium and current Vitamin D levels, and needs to be adjusted appropriately in response to those levels. For my patients, I can and do give very specific recommendations on Vitamin D doses. In future posts, I can go through how I decide that. I will not give any recommendation without first knowing Vitamin D and calcium levels. </p><p id="viewer-ecd8g"><strong>Edited to add: This post should not be taken as a …</strong></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261948</guid>
            <pubDate>Mon, 24 Aug 2020 16:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Mechanist's Guide to the Coronavirus Genome]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261853">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome | <a href="https://web.archive.org/web/*/https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to my Coronavirus Genome Walkthrough.</p>

<p>(Hoping someone comes out with that Vaccine Speedrun soon. This boss battle is really shaping up to be an intense one and we’ll need all the artifacts we can get.)</p>

<p>Here, I aim to provide a <em>mechanistic explanation</em> of the SARS-CoV-2 genome’s syntax and semantics. Let’s investigate what the SARS-CoV-2 viral genome actually does as if reading through code like a compiler, from nucleotides to amino acids all the way to proteins. From the four base pairs all the way up to the completed protein-coated virus, what is a virus like this is actually made of on the concrete, physical level?</p>

<h3 id="understanding-a-full-system">Understanding a Full System</h3>

<p>The underlying purpose of this essay is less about the coronavirus <em>per se</em> and more about how having a small—but functionally complete—piece of viral RNA to analyze gives me a unique opportunity to try to understand a complete self-replicating machine from scratch. This is not a feat that I would have the fortitude to manually replicate with the full human genome, for example—but the coronavirus genome, like the <a href="http://openworm.org/">nematode genome</a>, is small enough that we stand a chance at building a complete understanding. The task is perhaps akin to <a href="https://distill.pub/2018/building-blocks/">interpretability</a>, but for biological systems instead of artificial neural networks.</p>

<p>As a consequence, this essay is not intended to produce epidemiological conclusions; there are plenty of other sources for that! This essay is about fully understanding a biological system at the chemical and physical level.</p>

<h3 id="play-curiosity-and-mechanical-understanding">Play, Curiosity, and Mechanical Understanding</h3>

<p>Throughout this essay, I follow my curiosity in the style of <a href="https://en.wikipedia.org/wiki/Serious_play">serious play</a>: if I <a href="https://www.readthesequences.com/Noticing-Confusion-Sequence">notice I’m confused</a> about something, I look into it and explore it until I’m satisfied that I now understand, and that my understanding is <em>a <a href="https://plato.stanford.edu/entries/science-mechanisms/#ConMec">mechanical</a> understanding</em>. Things are made of stuff! It turns out that we can understand that stuff!</p>

<p>I may skip over some details that were not confusing to me during my own research, but your journey need not be the same as mine. If you’re confused about something while reading this essay, I encourage you to go and look it up! <a href="http://agentyduck.blogspot.com/2015/06/the-art-of-noticing.html">Notice</a> when your curiosity arises; that’s the meditation. It’s always possible to discover the <a href="http://samoburja.com/how-to-find-the-frontier-of-knowledge/">frontier of your own knowledge</a> and to expand it.</p>

<p>This all, at least, has been my intention as I set out to create this piece! As Ken Liu said of his philosophy while translating The Three-Body Problem, “I may not have succeeded, but these were the standards I had in mind as I set about my task.”</p>

<p>Part 1, here, covers just the genome and its translation to proteins. I hope to also write a Part 2 which would cover the structure and function of those proteins, their protein-protein interactions, and the full viral life cycle.</p>

<!--Finally, as you may already be able to tell, this essay also serves as a philosophical manifesto-by-example of how to think concretely about problems in biology. Along the way, I give some of my thoughts about the role of thermodynamics in molecular biology, legibility in complex systems, pedagogy, and the future of computational modeling.-->

<p>Let’s get started.</p>



<p>As a reminder, SARS-CoV-2 is a <em>positive-sense single-stranded RNA virus</em>.</p>



<p>What does this mean we can expect?</p>

<ol>
  <li><em>Single-stranded</em>: Its genome is a single strand of <a href="https://en.wikipedia.org/wiki/RNA">RNA</a> (ssRNA).</li>
  <li><em>Positive-sense</em>: That single strand of RNA can be immediately translated into protein by the ribosomes of the cell it infects.</li>
</ol>

<p>From this we can also infer that one of the proteins the virus encodes for must be <em>RNA-dependent RNA polymerase</em> (RdRP), a protein which synthesizes new RNA given an RNA template. That’s right: RNA → RNA. However, according to the <a href="https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology">central dogma of molecular biology</a>, isn’t RNA → RNA an unconscionable heresy? Correspondingly, RdRP is not naturally found in cells! All known positive-sense ssRNA viruses therefore <em>must encode</em> RdRP in order to successfully commit this heresy.</p>



<p>…Wait a minute, the phrase “positive-sense ssRNA virus” implies the existence of <em>negative-sense</em> viruses. If those don’t encode their proteins directly, how can they possibly work?</p>

<h2 id="positive-sense-and-negative-sense">Positive sense and negative sense</h2>

<p>Negative-sense ssRNA viruses also exist! Influenza, Ebola, and measles are examples.</p>



<p>The inner contents of <em>negative-sense</em> ssRNA viruses consist not of an RNA genome but of a <em>ribonucleoprotein</em>, which incorporates both an RNA genome as well as a cohort of viral proteins capable of replicating RNA. Unlike positive-sense ssRNA viruses, negative-sense ssRNA viruses must travel with a working copy of their RNA-replicating proteins. This ribonucleoprotein has enzymatic activity!</p>

<h2 id="rdrp-as-drug-target">RdRP as drug target</h2>

<p>Since RdRP has (as far as I know) no legitimate purpose in human cells and is not naturally coded by them, might it offer a potential target for novel antiviral drugs?</p>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">Velkov et al. 2014</a> explores RdRP as a drug target for antivirals against the <a href="https://en.wikipedia.org/wiki/Henipavirus">Hendra virus</a>, a negative-sense ssRNA virus, though I am unable to find the full text.</p>

<!-- <div class="unfurl-embed-info-media-default gallery-item-selectable"><img class="unfurl-embed-card-feature-image" src="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image.png"><div class="unfurl-embed-card-title unfurl-embed-card-title-default notranslate"><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">The RNA-dependent-RNA Polymerase, an Emerging Antiviral Drug Target for the Hendra Virus - PubMed</a></div><div class="unfurl-embed-card-description unfurl-embed-card-description-default notranslate"><div style="overflow: hidden; text-overflow: ellipsis; -webkit-box-orient: vertical; display: -webkit-box; -webkit-line-clamp: 2;">Australia is facing a major national medical challenge with the emergence of the Hendra virus (HeV) as a medically and economically important pathogen of humans and animals. Clinical symptoms of human HeV infection can include fever, hypotension, dizziness, encephalitis, respiratory haemorrhage and …</div></div><div class="unfurl-embed-card-url notranslate">pubmed.ncbi.nlm.nih.gov</div></div> -->

<blockquote>
  <p>This review examines the current knowledge based on the multi-domain architecture of the Hendra RdRP and highlights which essential domain functions represent tangible targets for drug development against this deadly disease.</p>
</blockquote>

<p>There must be some reason that developing antivirals against this protein is technically (or socially) complicated, or I’d have expected us to do it by now – there are a lot of RNA viruses that this drug target could theoretically hit. Flagging this discrepancy for further research.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">1</a></sup></p>



<p>Back to SARS-CoV-2! First, let’s get us a genome. Obviously this virus has seen some mutations as it’s spread around, as you can explore at <a href="https://nextstrain.org/ncov/global">NextStrain</a>, so we’ve technically got choices as to which one to analyze. For this thread I’ll just stick to analyzing <em>one</em> version of the genome: Wuhan-Hu-1.</p>

<p>As a reminder, each <code>A</code>, <code>G</code>, <code>C</code>, and <code>T</code> in a genome is one of the four <a href="https://en.wikipedia.org/wiki/Nucleotide">nucleotides</a>: <a href="https://en.wikipedia.org/wiki/Adenine">adenine</a>, <a href="https://en.wikipedia.org/wiki/Guanine">guanine</a>, <a href="https://en.wikipedia.org/wiki/Cytosine">cytosine</a>, and <a href="https://en.wikipedia.org/wiki/Thymine">thymine</a>. There are actually <a href="https://www.scripps.edu/romesberg/publications.html">plenty of ways to engineer</a> different <a href="https://pubmed.ncbi.nlm.nih.gov/22850726/">unnatural base pair systems</a> by adding <a href="https://science.sciencemag.org/content/363/6429/884">artificial nucleotides</a>, and these can even be integrated into <a href="https://www.pnas.org/content/98/9/4922">transcription</a> and <a href="https://www.nature.com/articles/nature24659">translation</a>, but <a href="https://carlbrannen.wordpress.com/2007/06/13/why-does-dna-only-use-4-nucleotides/">for</a> <a href="https://dreamerbiologist.wordpress.com/2013/02/16/why-did-nature-settle-on-just-four-nucleotides/">whatever</a> <a href="https://www.pnas.org/content/114/32/E6476">reason</a>, these four <a href="https://www.nature.com/articles/s41467-018-07389-2">and not others</a> are <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3331698/">what life ultimately ended up with</a>.</p>

<p><img src="https://csvoss.com/images/nucleotides.png"></p>
<p><small>The four nucleotides in DNA.</small></p>

<p>The genome of Wuhan-Hu-1 is available from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>. Since SARS-CoV-2 is an RNA virus, each <code>T</code> in this string technically represents a <code>U</code>, for <a href="https://en.wikipedia.org/wiki/Uracil">uracil</a>, RNA’s information-equivalent of thymine. The genome sequence is therefore:</p>

<div><div><pre><code>1     AUUAAAGGUU UAUACCUUCC CAGGUAACAA ACCAACCAAC UUUCGAUCUC UUGUAGAUCU
61    GUUCUCUAAA CGAACUUUAA AAUCUGUGUG GCUGUCACUC GGCUGCAUGC UUAGUGCACU
121   CACGCAGUAU AAUUAAUAAC UAAUUACUGU CGUUGACAGG ACACGAGUAA CUCGUCUAUC

...

29761 ACAGUGAACA AUGCUAGGGA GAGCUGCCUA UAUGGAAGAG CCCUAAUGUG UAAAAUUAAU
29821 UUUAGUAGUG CUAUCCCCAU GUGAUUUUAA UAGCUUCUUA GGAGAAUGAC AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>

<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>That’s 29,903 nucleotides. Since there are only four possible nucleotides, we can estimate the information compression value of each nucleotide at approximately 2 bits; the virus’s genome therefore requires only 7.5 kilobytes to store. That’s roughly as much data, byte for byte, as there are characters in this essay up to this point!</p>

<!-- <img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/110/2016/05/02212445/Figure_03_05_03.png"> -->

<p>Lay out those 29,903 nucleobases along a ribose-phosphate backbone, reading them left to right <a href="https://en.wikipedia.org/wiki/Directionality_(molecular_biology)">from the 5’ end to the 3’ end</a>, and bam – if that single molecule* were teleported into a cell, that’s 100% chemically sufficient** to infect a person with the plague du jour.</p>

<p>*plus the 5’ cap, discussed below</p>

<p>**modulo viral load effects??</p>

<p><img src="https://csvoss.com/images/polynucleotide.png"></p>
<p><small>How to interpret the Wuhan-Hu-1 genome as a complete molecule.</small></p>

<h2 id="poly-a-tail">Poly-A tail</h2>

<p>First question, and perhaps the most obvious one to the naked eye – what’s with all the <code>AAAAA</code> at the end of the viral genome?</p>

<div><div><pre><code>29821 ...                                                ... AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>
<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>It’s… yelling at us? Is it… suffering? Should we <a href="https://reducing-suffering.org/is-there-suffering-in-fundamental-physics/">help</a>?</p>

<p>Simple: It’s a <a href="https://bioinformatics.stackexchange.com/questions/11227/why-does-the-sars-cov2-coronavirus-genome-end-in-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa">3’ poly-A tail</a>! This <a href="https://en.wikipedia.org/wiki/Polyadenylation">long tail of adenosine monomers</a> is extremely common in both our own cells and in RNA viruses.</p>

<p>Our own messenger RNA (mRNA) has a poly-A tail when it’s freshly produced in the nucleus so as to slow its degradation by the cell, allowing it to last long enough to be transcribed into protein. Naturally, if you’re a positive-strand RNA virus, you’re also going to want to last long enough to be transcribed into protein – so, you need the same feature, yourself.</p>

<p>Genome 0.11% explained. So far so good!</p>

<h2 id="5-cap">5’ cap</h2>

<p>While we’re discussing chemical features of mRNA, note that the viral genome presumably must also have a <a href="https://en.wikipedia.org/wiki/Five-prime_cap">5’ cap</a> – an extra <a href="https://en.wikipedia.org/wiki/7-Methylguanosine">7-methylguanosine</a> at the 5’ end of its RNA strand – just like mRNAs do.</p>

<p><img src="https://csvoss.com/images/5primecap.png"></p>
<p><small>A 5' cap, consisting of a 7-methylguanosine as well as methylation of the first two ribose sugars.</small></p>

<p>The cap is not directly shown in the viral genome sequence or mentioned in NCBI GenBank, but it is referenced in multiple papers discussing coronaviral genomes:</p>

<blockquote>
  <p>Since 2003, the outbreak of severe acute respiratory syndrome coronavirus has drawn increased attention and stimulated numerous studies on the molecular virology of coronaviruses. Here, we review the current understanding of the mechanisms adopted by coronaviruses to produce the 5′-cap structure and methylation modification of viral genomic RNAs.</p>
</blockquote>



<blockquote>
  <p>Coronaviruses possess a cap structure at the 5′ ends of viral genomic RNA and subgenomic RNAs, which is generated through consecutive methylations by virally encoded guanine-N7-methyltransferase (N7-MTase) and 2′-O-methyltransferase (2′-O-MTase). The coronaviral N7-MTase is unique for its physical linkage with an exoribonuclease (ExoN) harbored in nonstructural protein 14 (nsp14) of coronaviruses.</p>
</blockquote>



<blockquote>
  <p>Here, we have reconstituted complete SARS-CoV mRNA cap methylation <em>in vitro</em>.</p>
</blockquote>



<p>Like the poly-A tail, the 5’ cap helps the genome to be recognized and translated by ribosomes rather than destroyed by the cell’s immune response.</p>

<p>How does the virus even ensure that it receives a 5’ cap and a poly-A tail, not to mention its outer coat? Hopefully these questions will be resolved by our review of its genes… let’s move on to look at those!</p>



<p>Per the “Features” section of the genome, again from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>, here are the identifiable genes in this genome, in order:</p>

<ol>
  <li><code>Orf1ab</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269089">orf1ab polyprotein</a>)</li>
  <li><code>S</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269090">surface glycoprotein</a>)</li>
  <li><code>Orf3…</code></li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</a></em></p>]]>
            </description>
            <link>https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261853</guid>
            <pubDate>Mon, 24 Aug 2020 15:55:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being OK with not being extraordinary]]>
            </title>
            <description>
<![CDATA[
Score 799 | Comments 371 (<a href="https://news.ycombinator.com/item?id=24261826">thread link</a>) | @tmatthe
<br/>
August 24, 2020 | https://www.tiffanymatthe.com/not-extraordinary | <a href="https://web.archive.org/web/*/https://www.tiffanymatthe.com/not-extraordinary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>23.08.2020</time> — <a href="https://www.tiffanymatthe.com/tags/mindset">Mindset</a> — <span>2<!-- --> min read</span></p><section><img src="https://www.tiffanymatthe.com/static/c239dad4f9476bf8d02961e957aa71cf/a6c62/rock-climbing.jpg"><p>The internet always highlights the first place winners, the billionaires, the award-winning artists, the best-selling authors, the largest philanthropists, the extraordinary. Their stories are ones of success, of inspiration. They show us what is possible, and push us to achieve more.</p><p>But I don't feel inspired when I see extraordinary. I feel disappointed, jealous. My constant exposure to these amazing stories of success has normalized the extraordinary. I started comparing myself to these "normal" extraordinary people, and wondered why I was not them. This disappointment would incite me to take action, but after a few days of hard work, I would just quit. Quitting was easier; it helped me avoid thinking about the extraordinary and the negative dark clouds that I had shrouded it with.</p><p>This mentality was self-defeating. No one starts off as extraordinary, so that meant I quit a lot in the past. Over time, I came to realize two things:</p><ol><li>extraordinary as I perceived it was one-dimensional and unrealistic,</li><li>to improve, extraordinary could not be my end goal.</li></ol><p><strong>We need to redefine extraordinary.</strong> Extraordinary is often defined by the internet as a permanent trait someone has. They seemed to have been born with it, and extraordinary permeates their every pore. </p><p>But real extraordinary is nothing like this. Yes, it's exciting, but it also comes with sacrifices, limitations, and constraints. And it's not permanent. Extraordinary can disappear over time, just like you can achieve it over time.</p><p>Extraordinary also comes in many forms, and its value does not have to be measured in terms of money. You can be a tech giant who built their entire empire from scratch, just as you can be an amazing organizer who rallies entire communities together for a single cause. You can be a top-notch violinist player, or a inspiring storyteller. Extraordinary can be anything. Sometimes, when you realize what extraordinary really entails, you might not even want it. That's okay.</p><p><strong>Extraordinary should not be the end goal.</strong> I like to envision the extraordinary space in society as a small ledge at the top of a cliff. It gives you a beautiful view and a sense of accomplishment, but is also tight and oppressing. The sheer physical constraints means that not everyone will reach it. But that shouldn't stop you from putting a hand on the cliff and lifting yourself towards that ledge.</p><p>Why? Because the ledge is not the only thing that exists. There is a vast amount of space under it, other ledges, crooks, and crannies, that most people forget about. That space is just as valuable.</p><p>For example, someone starting out on Youtube might be disappointed that they don't have millions of subscribers. They don't think they have what it takes, so they quit. But most people don't only look at the channels with millions of subscribers. Smaller ones are as valuable for viewers, and the creators can get just as much value out of creating their original content and connecting with like-minded people.</p><p>So instead of searching for an extraordinary that is distorted and unrealistic, search to climb up to some space beneath the top ledge. You will be less disappointed and jealous, and you will still maintain some velocity in the right direction. Climbing to a higher vantage point can also unlock new forms of extraordinary that you might have never noticed before.</p><p>By consistently climbing and reassessing which direction to take, you might just reach your own extraordinary as a bonus.</p></section></div></div>]]>
            </description>
            <link>https://www.tiffanymatthe.com/not-extraordinary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261826</guid>
            <pubDate>Mon, 24 Aug 2020 15:53:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remains of 17th century bishop support Neolithic emergence of tuberculosis]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24261768">thread link</a>) | @benbreen
<br/>
August 24, 2020 | https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis | <a href="https://web.archive.org/web/*/https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>Bishop Peder Winstrup of Lund, Sweden passed away in the winter of 1679 at the age of 74 and was interred in a crypt at Lund Cathedral. Three centuries later, his astonishingly well-preserved remains provide insights to the origins of tuberculosis.</p>
  

  

  <p>In a recent study published in <em>Genome Biology</em>, researchers from the Max Planck Institute for the Science of Human History, Lund University and the Swedish Natural Historical Museum present analysis of the highest quality ancient Mycobacterium tuberculosis genome to date, suggesting the pathogen is much younger than previously believed.</p>
  
  
<figure data-description="Portrait of Bishop Peder Jensen Winstrup" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Portrait of Bishop Peder Jensen Winstrup
        </p>
        <p>
           © Orf3us / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)
        </p>
    </figcaption>
</figure>


<p>When Anthropologist Caroline Arcini and her colleagues at the Swedish Natural Historical Museum discovered small calcifications in the extremely well preserved lungs of Bishop Peder Winstrup, they knew more investigation was needed. “We suspected these were remnants of a past lung infection,” says Arcini, “and tuberculosis was at the top of our list of candidates. DNA analysis was the best way to prove it.”</p>
<p>Up to one quarter of the world’s population is suspected to have been exposed to bacteria of the <i>Mycobacterium tuberculosis</i> complex, which cause tuberculosis (TB). Bishop Winstrup would have been one of many to fall ill during the onset of the so-called “White Plague” TB pandemic that ravaged post-medieval Europe. Today, TB is among the most prevalent diseases, accounting for the highest worldwide mortality from a bacterial infection.</p>
<p>The global distribution of TB has led to the prevailing assumption that the pathogen evolved early in human history and reached its global distribution via the hallmark Out of Africa human migrations tens of thousands of years ago, but recent work on ancient TB genomes has stirred up controversy over when this host-pathogen relationship began. In 2014, a team led by scientists from the University of Tübingen and Arizona State University reconstructed three ancient TB genomes from pre-contact South America – not only were the ancient strains unexpectedly related to those circulating in present-day seals, but comparison against a large number of human strains suggested that TB emerged within the last 6000 years. Understandably, skepticism surrounded this new estimate since it was based entirely on ancient genomes that are not representative of the TB strains associated with humans today.</p>
<p>“Discovery of the Bishop’s lung calcification gave us the opportunity to revisit the question of tuberculosis emergence with data from an ancient European,” comments Kirsten Bos, group leader for Molecular Paleopathology at the Max Planck Institute for the Science of Human History (MPI-SHH), who co-led the study. “If we could reconstruct a TB genome from Bishop Winstrup, where we know his date of death to the day, it would give a secure and independent calibration for our estimates of how old TB, as we know it, actually is.”</p>
<p><b>The highest quality ancient TB genome to date&nbsp; </b></p>
<p>In a new study published this week in Genome Biology, Susanna Sabin of MPI-SHH and colleagues reconstruct a tuberculosis genome from the calcified nodule discovered in Bishop Winstrup's remains.</p>
<p>“The genome is of incredible quality – preservation on this scale is extremely rare in ancient DNA,” comments Bos.</p>

<figure data-description="Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB
        </p>
        <p>
           © NIAID
        </p>
    </figcaption>
</figure>


<p>Together with a handful of tuberculosis genomes from other work, the researchers revisit the question of the age of the Mycobacterium tuberculosis complex, with the year of the Bishop’s death as a fine-tuned calibration point. Using multiple molecular dating models, all angles indeed point to a relatively young age of the <i>Mycobacterium tuberculosis</i> complex.</p>
<p>“A more recent emergence of the tuberculosis pathogen complex is now supported by genetic evidence from multiple geographic regions and time periods,” comments Sabin, first author of the study. “It’s the strongest evidence available to date for this emergence having been a Neolithic phenomenon.”</p>
<p>This most recent shift in the narrative for when bacteria in the <i>Mycobacterium tuberculosis </i>complex became highly infectious to humans raises further questions about the context of its emergence, as it appears to have coincided with the rise of pastoralism and sedentary lifestyles.</p>
<p>“The Neolithic transition seems to have played an important role for the emergence of a number of human pathogens,” comments Denise Kühnert, group leader for disease transmission research at MPI-SHH who co-led the investigation.&nbsp;</p>
<p>“For TB in particular, stronger evidence could only come from an older genome, though these deeper time periods are unlikely to yield preservation on the scale of what we’ve seen for Bishop Winstrup,” adds Bos.</p>
<p>“Moving forward,” Sabin further comments, “the hope is we will find adequately preserved DNA from time periods close to the emergence of the complex, or perhaps from its ancestor.”</p>
  
</div></div>]]>
            </description>
            <link>https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261768</guid>
            <pubDate>Mon, 24 Aug 2020 15:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making money building Shopify micro-SaaS apps]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24261192">thread link</a>) | @gk1
<br/>
August 24, 2020 | https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Starting your first business can be a daunting task. There’s so many variables involved - which ones to solve for, which ones to figure out?</p><p>Typically as software engineers and product people, building the product and writing code is not where we falter. </p><p>Where we get stuck is with existential questions like:</p><ul role="list"><li>Does anybody want this app?</li><li>How will I get users?</li></ul><p>And from my little experience in entrepreneurship, I find these questions to be more important than actually designing and building the app. Trust me when I say this.</p><p>Since I’ve been answering questions on email and Twitter DMs around these topics already, writing a guide came as the natural next step.</p><h3>Who this guide is for</h3><ul role="list"><li>You are starting your first micro-SaaS business</li><li>You want to earn extra outside your job, or you want to eventually replace your job income with a business</li><li>You can design apps with a baseline level of UX, and you can write code. Or, you have a business partner who can do these</li><li>You have 10+ hours to allocate every week (initially, more is better) and are in it for the long haul (say 3-6 months before you start seeing significant income from the business)</li><li>You want to serve customer’s needs</li></ul><h3>Who this guide is NOT for</h3><ul role="list"><li>You want to become a millionaire quickly</li><li>You are in it for the short term gain but you don’t see building businesses as your long-term path</li><li>You don’t know the A of design or coding, and neither have a business partner who does</li><li>You don’t have the patience to struggle for 3-6 months when the results might be 0, before things suddenly start to work in your favour</li></ul><p>If this guide is for you, read on. I’ve laid out the index of topics covered in the post. </p><p>Depending on the stage of your journey, feel free to skip to the sections that are most relevant to you.<br></p><h3><strong>Topics covered in this post</strong></h3><ol role="list"><li>Make money building Shopify apps</li><li>Discover problems, niches, and Shopify app ideas</li><li>Standing out from competition</li><li>Shopify App Store optimisation basics</li><li>Find your #1 keyword</li><li>How to build a Shopify app</li><li>Getting customers to review your Shopify app (by delivering great customer support)</li><li>Getting the first customers for your Shopify app</li><li>Finding early users and beta testers for your Shopify app outside the App Store</li><li>Getting listed under the right categories &amp; collections, and getting featured on the Shopify App Store</li><li>The right pricing model for your Shopify app</li><li>Optimising for trials</li><li>Long term game plan in the Shopify App Store</li></ol><p>‍<br></p><h2><strong>Make money building Shopify apps</strong></h2><p>Shopify isn’t the only choice when it comes to picking an apps marketplace. There’s </p><ul role="list"><li><a href="https://slack.com/apps" target="_blank">Slack</a></li><li><a href="https://marketplace.atlassian.com/" target="_blank">Atlassian</a></li><li><a href="https://appexchange.salesforce.com/" target="_blank">Salesforce</a></li><li><a href="https://gsuite.google.com/marketplace" target="_blank">GSuite Marketplace</a></li><li><a href="https://chrome.google.com/webstore/category/extensions" target="_blank">Chrome Web Store</a></li><li><a href="https://play.google.com/store/apps" target="_blank">Google Play Store</a></li><li><a href="https://www.apple.com/in/ios/app-store/" target="_blank">Apple iOS App Store</a></li><li><a href="https://apps.apple.com/us/genre/mac/id39?mt=12" target="_blank">Mac App Store</a></li></ul><p>All these marketplaces are valid options for you to start. I would lean on a marketplace where there’s a combination of 2 factors</p><ol role="list"><li><strong>Familiarity with problems</strong> - You know what the core product is about, you understand or can empathise with its users maybe from using the tool at your previous workplace, you have an idea on the different kind of problems that exist in the ecosystem and don’t find it too boring to solve them</li><li><strong>Skillset to execute</strong> - If you don’t know how to build Android, iOS, or Mac apps, perhaps steer clear of it. Your goal is not to take on a hard challenge, it’s to take on a challenge where you have some advantage from skill and insight. The goal is to win.<br></li></ol><h3>Why you should pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Huge distribution:</strong> Marketing is often a big reason for a business’s failure, the App Store takes care of it. Shopify has 1mn+ merchants and tons of new signups every month who go to the app store browsing for solutions. <br>Shopify promotes apps within its product and has made it an integral part of its user journey. A new app is able to gain traction fairly easily in the app marketplace, which makes it friendly to newcomers. <br>Marketing is often a big reason for a business’s failure, the App Store takes care of it.</li><li><strong>Tons of app opportunities:</strong> E-commerce store owners have 101+ problems to be taken care of, and you can address any one and do a great job at it to build a sustainable business. It’s not hard (relative standards) to gain 200 paying customers paying you $10/mo to earn $2000/mo ($1600 after Shopify’s 20%)</li><li><strong>Ease of development:</strong> Shopify’s documentation and APIs are first-class, they get out of the way allowing you to build fast. Additionally, Shopify’s <a href="https://polaris.shopify.com/" target="_blank">Polaris UI framework</a> makes building app interfaces a piece of cake. It’s based on React and comes with a Sketch/Figma file to help you design and prototype solutions fast.</li><li><strong>Billing taken care of:</strong> Heads up, Shopify takes a 20% commission on all earnings. So if your app’s monthly subscription fees is $10, you get $8. In return, Shopify takes care of billing end to end.<br>You can charge monthly, annually, charge per activity, provide app credit, and issue refunds with very little effort. You don’t need to worry about failed payments, Shopify takes care of it. You don’t even need to generate an invoice, app bills are included in the merchant’s monthly Shopify invoice.</li><li><strong>Familiarity with ecommerce:</strong> If you’re someone who can jump into an industry and learn all about it, great. If not, you would want some familiarity with how an ecommerce store works, what are the typical problems faced by a merchant.<br>You can do this by creating a Shopify store and trying to sell your own products. Or you could have conversations with 10 different store owners and absorb from their experience. You could also find someone who works at an e-commerce agency for valuable insights. It’s not that hard.<br></li></ul><h3>Why you shouldn’t pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Copycat galore:</strong> You’re likely to copy an existing app and make a slight improvement in terms of product, pricing, or both. Guess what, the next smart person with the same idea can do the same to you. If you’re dependent on getting all or majority of your customers from the app store, be ready for stiff competition from copycats. <br>This doesn’t mean you cannot grow your app to $1k or $10k MRR. SaaS is not a winner take all market. It just means that it gets harder to grow as you grow. If this is something you are not mentally prepared for, steer clear. <br>There’s ways you can grow out of this by taking a long term strategy, either by taking a brand-centric approach (brand is not your name, but the experience that customers remember you by for which they’ll choose you over a copycat). <br>Or you can go upmarket and target large volume and Plus merchants, where ticket sizes are $200/mo or higher and switching does not happen often. </li><li><strong>Low-end, high-maintenance customers:</strong> Majority of Shopify merchants are people who don’t want to pay beyond $10-$15/mo and yet they expect world-class customer service. Some will ask for phone support or to jump on a video call. <br>You can tackle this by solving problems where the ticket sizes are higher, in the range of $50-$100/mo, but also expect it to be significantly harder to rank and fight existing competitors in such problem spaces. Example - <a href="https://apps.shopify.com/search?q=page+builder" target="_blank">page builders</a>, <a href="https://apps.shopify.com/search?q=product+reviews" target="_blank">product review</a> apps. <br>You can mitigate this by going in with the mindset that you’ll be serving $15/mo customers, so your app better be self-serve ready, have a dead simple UX and sufficient documentation or walkthrough videos. You can also aim to be the cost-leader of a segment, example - <a href="https://apps.shopify.com/judgeme" target="_blank">Judge.me</a> </li></ul><p>‍<br></p><h2><strong>Discover problems, niches, and Shopify app ideas</strong></h2><p>I’ve previously written about <a href="https://www.preetamnath.com/blog/shopify-micro-saas-growth" target="_blank">uncovering opportunities on Shopify</a> and I also shared all my research in my big <a href="https://docs.google.com/spreadsheets/d/1Hnpcl1VAlPC9MuFvvsl2UsU0yu1iM6aKR-iK30VtbwA/edit?usp=sharing" target="_blank">Shopify app ideas spreadsheet</a>. Let me reiterate on the advice shared there in a more structured manner that will hopefully better answer questions like:</p><ul role="list"><li>“How do you find niches in the app store in the first place?”</li><li>“How to find a problem worth solving within shopify? (worth solving=stressful enough for merchants &amp; competition not too tough)”<br></li></ul><p>There have been people who have asked me what kind of problems to solve, or what are the underserved niches. The thing is - if there's an obviously underserved niche and people have taken the time to research about it, they are probably busy solving it. If it's being posted in any blog post, know that it's no longer an underserved or hidden niche, because clearly anyone could find it.</p><p>Ultimately, only you can find an idea that you find worthy enough to pursue, whose various pros and cons are justified in your mind. And therefore, I can only provide a directional framework towards evaluating ideas. I can't list out ideas.</p><p>The best use of a directional framework is to</p><ol start="" role="list"><li><strong>First</strong> - cast a wide net, get to know what's out there</li><li><strong>Second</strong> - narrow down your search based on parameters you have decided</li></ol><p>This first section of the article will help you with casting a wide net. </p><p>As you go further along the article, I've shared ideas and techniques which you can use to narrow down your search.<br></p><h3>1- Browse the entire App Store</h3><p>I recommend this as the starting point for anyone new to the Shopify ecosystem. Start by browsing all the categories &amp; sub-categories of apps on the app store. You can do the same on <a href="https://sasi.unionworks.co.uk/categories" target="_blank">SASI</a>. </p><p>The purpose of browsing this way is to familiarise yourself with the different types of problems faced by merchants and being solved by apps. Ideally, you want to note down some interesting apps that you come across during your browsing adventure to investigate later on.</p><figure id="w-node-892fc283544a-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f1c114edd643e073591f8cc_browse%20categories%20shopify%20app%20store.png" alt=""></p></figure><h3>2- Go through every letter in search autocomplete</h3><p>Okay, this is a step I took when&nbsp;I was browsing the app store. I would type in "aa", "ab", "ac"... ... ... "zz" on the search bar, note the autocomplete terms and check the results of ones I found to be interesting.</p><p>Turns out, Shopify has since updated their algorithm. Autocomplete suggestions only show up after you type 3 letters now. So you can't recreate what I did with autocomplete and go through every letter. It's not feasible anymore.</p><p>Not to worry, it's still useful.</p><h4>Plug in keywords of shortlisted apps into the search bar</h4><p>From step 1, all the apps (hopefully at least a dozen) that you shortlisted for being interesting, extract the keywords used in the app's title or description. </p><p>Now, enter those keywords in search to find whether they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261192</guid>
            <pubDate>Mon, 24 Aug 2020 14:47:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Year of Nushell]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24259914">thread link</a>) | @rainworld
<br/>
August 24, 2020 | https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html | <a href="https://web.archive.org/web/*/https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <section>
      

      <p>Hard to imagine that it’s already been a year since Nu first went public. At the time, it was largely a demo of what could be possible, but still needed quite a bit of work to make it ready for everyday use. A year later and we’ve learned a lot, and made a few mistakes along the way. In this post, we look back over the year and see how we did and where we might be going in the future.</p>



<p>When Nu first started, it started with a simple idea: the output of <code>ls</code>, <code>ps</code>, and <code>sysinfo</code> should all output the same thing. Taking a page from PowerShell, we explored outputting structured data and quickly settled on a table design that would support the output of each of the three commands, with the added ability of streaming the output as it became available.</p>

<p>Around this idea, we then built a set of “filters”, like the <code>where</code> clause, borrowed from SQL, and a growing set of data types we would support natively.  Soon, we were able to write more complex statements like <code>ls | where size &gt; 10kb</code>. This became the crux of the idea - commands that output values from a core set of data types into a stream, composed together with the traditional UNIX pipe (<code>|</code>), so that you could build up a complex set of commands that work over the data as it streams through.</p>



<h2 id="contributors">Contributors</h2>

<p>Before we got started talking about Nushell today, we wanted to give a <em>big</em> “thank you!” to everyone who has contributed to Nu to get us to this point. Nu is what it is because of your help.</p>

<p>1ntEgr8, AaronC81, AdminXVII, aeosynth, aeshirey, aidanharris, almindor, Aloso, Amanita-muscaria, amousa11, andrasio, Andrew-Webb, arashout, arnaldo2792, avandesa, avranju, bailey-layzer, BatmanAoD, bndbsh, Bocom, boisgera, Borimino, BradyBromley, BurNiinTRee, Byron, candostdagdeviren, casidiablo, charlespierce, chhetripradeep, cjpearce, coolshaurya, cristicismas, DangerFunPants, daschl, daveremy, davidrobertmason, Delapouite, dependabot[bot], Detegr, devnought, Dimagog, djc, drmason13, DrSensor, elichai, eltonlaw, EmNudge, eoinkelly, equal-l2, est31, fdncred, filalex77, Flare576, gilesv, gorogoroumaru, GuillaumeGomez, hdhoang, he4d, hilias, HiranmayaGundu, hirschenberger, homburg, iamcodemaker, incrop, ineol, Jacobious52, jankoprowski, JCavallo, jdvr, jerodsanto, JesterOrNot, johnae, johnterickson, jonathandturner, JonnyWalker81, jonstodle, JosephTLyons, jzaefferer, k-brk, Kelli314, klnusbaum, kloun, kornelski, kubouch, kvrhdn, landaire, lesichkovm, LhKipp, lightclient, lincis, lord, luccasmmg, marcelocg, matsuu, mattclarke, mattyhall, max-sixty, mfarberbrodsky, mhmdanas, mike-morr, miller-time, mistydemeo, mlbright, mlh758, morrme, nalshihabi, naufraghi, nespera, neuronull, nickgerace, nmandery, notryanb, oknozor, orf, orientnab, oskarskog, oylenshpeegul, pag4k, Paradiesstaub, philip-peterson, piotrek-szczygiel, pizzafox, pka, pmeredit, pontaoski, Porges, pulpdrew, q-b, quebin31, rabisg0, ramonsnir, rimathia, ritobanrc, rnxpyke, romanlevin, routrohan, rrichardson, rtlechow, rutrum, ryuichi1208, Samboy218, samhedin, sandorex, sdfnz, sebastian-xyz, shaaraddalvi, shiena, siedentop, Sosthene-Guedon, Southclaws, svartalf, taiki-e, Tauheed-Elahee, tchak, thegedge, tim77, Tiwalun, twe4ked, twitu, u5surf, UltraWelfare, uma0317, utam0k, vsoch, vthriller, waldyrious, warrenseine, wycats, yaahc, yahsinhuangtw, yanganto, ymgyt, zombie110year</p>



<p>Nushell is an interactive programming language for working with your files, your system, and your data as a shell, a notebook, and more.</p>

<h2 id="nu-is-more-than-a-shell">Nu is more than a shell</h2>

<p>It’s easy to think of Nushell as just a shell. It’s even got ‘shell’ in the name. It’s the first and probably main way you’ll interact with it. So why say it’s “more than a shell”?</p>

<p>In truth, Nushell is actually two things at once: Nu and Nushell. Nu is an interactive language for processing streams of structured data, data that you’re probably getting from files, your system, a web address, etc.</p>

<p>So what’s Nushell?</p>

<p>Nushell is taking the Nu language and putting it into a shell, and building around it a set of shell features to make it feel comfortable to use as a login shell. Completions, pretty error messages, and the like.</p>

<p>When we say that “Nu is more than a shell”, does that imply that Nu can be used in other places, too? Absolutely. We’ve got two more hosts that let you run Nu, a <a href="https://github.com/nushell/nu_jupyter">jupyter-based</a> host that lets you run Nu in jupyter notebooks, and a <a href="https://github.com/nushell/demo">WebAssembly-based</a> host that we use to create the <a href="https://www.nushell.sh/demo/">Nu playground</a></p>

<p>The idea of Nu runs deeper than just the shell, to being a language that’s relatively easy to learn, yet powerful enough to do real work with your system, to process large amounts of data, to interactively let you iterate quickly on an idea, to invite exploration by building up a pipeline one piece at a time. There’s really no shortage of ambition for where we hope to go.</p>



<p>Nu’s original design has proven surprisingly robust thus far. Some of its core ideas are continuing to pay dividends a year later. Let’s look at the designs that still feel right.</p>

<h2 id="pipelines-are-infinite">Pipelines are infinite</h2>

<p>When we first started writing Nu, we took a few shortcuts that had us processing all the data in a pipeline at once. Very quickly, we realize this wasn’t going to work. External commands (think <code>cat /dev/random</code>) can output an infinite stream of data, and the system needs to be able to handle it. Understanding this, we transitioned to a different model: data flows between command as infinite streams of structured data. As the data is processed, we avoid collecting the data whenever possible to allow this streaming to happen.</p>

<p>Because the streams can be infinite, even the printing out of tables is done a batch at a time.</p>

<h2 id="separating-viewing-data-from-the-data-itself">Separating viewing data from the data itself</h2>

<p>Coming from other shells, the idea of running <code>echo</code> or <code>ls</code> goes hand-in-hand with printing something to the terminal. It’s difficult to see that there two steps going on behind the scenes: creating the information and then displaying it to the screen.</p>

<p>In Nu, these two steps are distinct. The <code>echo</code> command gets data ready to output into stream, but doesn’t do any work to print it to the screen. Likewise, <code>ls</code> gets ready to output a stream of file and directory entries, but doesn’t actually display this information.</p>

<p>That’s because both <code>echo</code> and <code>ls</code> are lazy commands. They’ll only do the work if the data is pulled from the stream. As a result, the step of viewing the data is separate from the step of creating it.</p>

<p>Behind the scenes, Nu converts a standalone <code>ls</code> to be the pipeline <code>ls | autoview</code>. The work of viewing comes from <code>autoview</code> and it handles working with the data and calling the proper viewer. In this way, we’re able to keep things as structured data for as long as possible, and only convert it to be displayed as the final step before being shown to the user. (note: the wasm-based demo and jupyter do a similar step, but instead of adding <code>autoview</code>, they add <code>to html</code>)</p>

<h2 id="rich-data-types">Rich data types</h2>

<p>In a similar way to working with structured data, rather than only plain text, Nu takes a different approach to data types as well. Nu takes the traditional set of basic types, like strings and numbers, and extends them into a richer set of basic data primitives.</p>

<p>Numbers are represented internally as big numbers and big decimals, rather than integers and floating point machine-based representations. This gives us more flexibility to do math more accurately, and generally removes the worry of whether the number you want to work with will fit in the integer or float size you have available.</p>

<p>We carry this further, by also representing values common in modern computer usage: URLs, file paths, file sizes, durations, and dates are all examples of built-in data types. By building them in, Nu can have better syntax and type checking with their use.</p>

<p>For example, in Nu it’s possible to write <code>= 1min + 1sec</code> to create a duration that is one minute one second long. You can also use the file sizes, like being able to filter a directory list by the size of the file <code>ls | where size &gt; 10kb</code>.</p>

<p>Nu also can help if you try to mix types that shouldn’t. For example, if you had written: <code>= 1min + 1kb</code> it seems you didn’t mean to add time and file sizes together, and Nu gives you an error if you do:</p>

<div><div><pre><code>error: Coercion error
  ┌─ shell:1:3
  │
1 │ = 1min + 1kb
  │   ^^^^   --- filesize(in bytes)
  │   │       
  │   duration
</code></pre></div></div>

<p><em>note: we’ll be making this error better in the future</em></p>

<p>Data in Nu also isn’t just the value, but it’s also a set of metadata that comes with the value. For example, if you load data from a file using the <code>open</code> command, we track the place that it’s loaded along with the data that’s loaded. We can see this metadata using the <code>tags</code> command:</p>

<div><div><pre><code>open package.json | tags
───┬─────────────────┬──────────────────────────────────────────────────────────────────────────────
 # │      span       │                                    anchor                                    
───┼─────────────────┼──────────────────────────────────────────────────────────────────────────────
 0 │ [row end start] │ /home/jonathan/Source/servo/tests/wpt/web-platform-tests/webrtc/tools/packag 
   │                 │ e.json                                                                       
───┴─────────────────┴──────────────────────────────────────────────────────────────────────────────
</code></pre></div></div>

<p>This extra information allows us to know how to view the contents, and even save you time when you use the <code>save</code> command, as it will use the original location by default.</p>

<h2 id="keeping-it-fun">Keeping it fun</h2>

<p>Something we attached to early on was the idea that Nu should be fun. It should be fun to work on, it should be fun to contribute to, and it should be fun to use.</p>

<p>Nu is really about play. You play with your data, you play with the structures that make up your files and filesystem, you play with what web services give back to you. Everything about Nu is made to invite you to explore how things work and how data is put together. As you play, you learn more about Nu works and how to better use it. We firmly believe …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</a></em></p>]]>
            </description>
            <link>https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259914</guid>
            <pubDate>Mon, 24 Aug 2020 12:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why People Become Internet Trolls]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24259728">thread link</a>) | @Gedxx
<br/>
August 24, 2020 | https://dradambell.com/why-people-become-internet-trolls/ | <a href="https://web.archive.org/web/*/https://dradambell.com/why-people-become-internet-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1c056633" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<p><span>When I was 10 years old and first introduced to the miracle of the World Wide Web, chat rooms were by far my favorite thing. Talking to random people from all over the world about anything you want — what more could a bored kid ask for?</span></p>

<p><span>I’d spend hours in these chat rooms, asking my new friends how old they were, what they had for breakfast, and how much pocket money their parents gave them. I shared this experience with a friend who didn’t own a computer and had never used the internet.</span></p>

<p><span>He asked if he could have a go. “Sure!” I said, excited for him to experience the wonder of the internet. Without hesitation, he began typing the worst insults and swear words he could think of. Horrified I had awoken a dark and malevolent force, and fearing he had forever ruined my friendship with strawberry88, I shut down my computer and didn’t invite him to play on the internet again.</span></p>

<p><span>To this day, I remain baffled by this behavior. When faced with the endless possibility of the internet, my childhood friend’s first impulse was to verbally abuse strangers. This innocent 10-year-old had become a troll.</span></p>

<h4 id="02ff"><span>Wretched impulses</span></h4>

<p><span>John Oliver once described the internet as a “dark carnival of humanity’s most wretched impulses.” Was it these wretched impulses that had consumed my childhood friend?</span></p>

<p><span>The act of trolling is best described from where its name&nbsp;<a href="https://www.etymonline.com/word/troll" target="_blank" rel="noreferrer noopener">may have come from</a>&nbsp;— the form of fishing where a lure is dangled off a moving boat.</span></p>

<figure><span><img src="https://miro.medium.com/max/3200/0*f3HYZpvSGgrg1vHC" alt=""></span></figure>

<p><span>The troll casts his bait (the offensive comment) into the water of the internet. An unsuspecting fish (the targeted user) sees the bait and feels compelled to go for it (the defensive comment). Soon they are hooked and reeled in without mercy. But unlike trolling for fish, which delivers a clear and edible reward, the troll’s reward isn’t entirely clear.</span></p>

<p><span>Trolling is a hard concept to define because there are various methods of trolling and differing degrees of depravity. Some are abhorrent, like “suicide baiting,” where trolls encourage vulnerable users to kill themselves, or “RIP trolls” who vandalize Facebook memorial sites of the recently deceased. But others, like “griefers” who play online games in a manner that purposely disrupts other players, are more of a nuisance.</span></p>

<p><span>Who are these trolls, and what drives them?</span></p>

<h4 id="4d5f"><span>The dark tetrad</span></h4>

<p><span>Psychologists have found&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886914000324" target="_blank" rel="noreferrer noopener">a link between trollish behavior</a>&nbsp;and a set of personality traits called “the dark tetrad.”</span></p>

<figure><span><img src="https://miro.medium.com/max/2974/0*sAMy6kU4hSsBKYQy" alt=""></span></figure>

<p><span>The dark tetrad comprises:</span></p>

<ul>
<li><span>Sadism — deriving pleasure from another’s pain</span></li>
<li><span>Psychopathy — impairment of empathy and remorse</span></li>
<li><span>Machiavellianism — manipulative and emotionally “cold” behavior</span></li>
<li><span>Narcissism — self-involvement and a need for admiration</span></li>
</ul>

<p><span><a href="https://www.academia.edu/41115419/Loneliness_moderates_the_relationship_between_Dark_Tetrad_personality_traits_and_internet_trolling" target="_blank" rel="noreferrer noopener">In a recent study</a>, trolls were positively correlated with three of the four dark tetrad traits, with narcissism being the odd one out. They found trolls were manipulative, lacked empathy, and enjoyed hurting others. Men exhibited these traits more commonly than women and were more likely to troll. Loneliness was also a significant predictor of trolling when in the presence of Machiavellianism or psychopathy.</span></p>

<p><span>Most studies on trolls use internet surveys to collect data, which is questionable: Can we really trust trolls to complete surveys accurately? This method may also not account for those who don’t consider their behavior to be trollish or those unaware of their trollish behavior.</span></p>

<p><span>In the book&nbsp;<a href="https://www.hardiegrant.com/au/publishing/bookfinder/book/troll-hunting-by-ginger-gorman/9781743794357" target="_blank" rel="noreferrer noopener"><em>Troll Hunting</em></a>, journalist Ginger Gorman spends years building relationships with the worst trolls she can find in an attempt to understand what drives them. To her surprise, trolls were not uneducated lost souls who lacked social skills and lived in their mother’s basement. These trolls had partners, children, and full-time jobs. They showed leadership skills as commanders of&nbsp;<a href="https://www.theguardian.com/books/2019/jan/28/it-was-like-being-skinned-alive-ginger-gorman-goes-hunting-for-trolls" target="_blank" rel="noreferrer noopener">large trolling syndicates</a>. They were socially intelligent and able to pinpoint users’ weaknesses with vicious precision. But what was driving them?</span></p>

<p><span>Many saw trolling as a hobby — something that entertained or amused. Some were ideologically driven, attacking anybody opposing their belief system. But both types of troll tended to engage users that threatened their beliefs or sense of self.</span></p>

<p><span>Some of the trolls exhibited dark tetrad traits. In these trolls, she saw a common pattern — excessive internet use with little to no parental supervision between the ages of 11 and 16. But some trolls didn’t fit the dark tetrad personality type. These trolls were pleasant, friendly, and compassionate when she engaged them directly. How could these trolls behave so antisocially online yet appear to function as typical members of society offline?</span></p>

<h4 id="7160"><span>Empathy deficit</span></h4>

<p><span>The human brain was primarily designed for face-to-face interaction. It hasn’t had time to adapt to communication over the internet.</span></p>

<p><span>Nonverbal communication — facial expressions, gestures, and voice qualities — provides the precise social context of an interaction. While the claim that 93% of communication being nonverbal is&nbsp;<a href="https://cornerstone.lib.mnsu.edu/cgi/viewcontent.cgi?article=1000&amp;context=ctamj" target="_blank" rel="noreferrer noopener">inaccurate</a>, it is a crucial part of how we communicate. Words alone can only go so far. Even if we used the full&nbsp;<a href="https://englishlive.ef.com/blog/language-lab/many-words-english-language/" target="_blank" rel="noreferrer noopener">170,000 words</a>&nbsp;currently in use in the English language, we still couldn’t convey what an expressive face or a suggestive voice could.</span></p>

<p><span>Most internet discussions only allow words. Well, words and emojis and GIFs and stickers and all the other substitutes created to replace nonverbal cues.</span></p>

<p><span>If you say something mean to my face and make me cry, you will probably start to feel uncomfortable. Unless you’re especially mean or psychopathic, my distress will trigger an empathic response and lead you to have mercy. If you tweet something mean and make me cry, no amount of emojis can convey what the sight of a grown man weeping can. If there is no social cue to elicit an empathic response, you might continue your tirade of meanness.</span></p>

<p><span>The absence of nonverbal feedback leads to an “empathy deficit,” and this is what sociopaths suffer from.</span></p>

<h4 id="53a2"><span>Toxic disinhibition</span></h4>

<p><span>When you combine an empathy deficit with the anonymity of online interactions, you get “<a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect" target="_blank" rel="noreferrer noopener">toxic disinhibition</a>,” which is more than just the phenomenon of being rude to bar staff after that fifth shot of tequila.</span></p>

<p><span>Anonymity can lead to “<a href="https://en.wikipedia.org/wiki/Deindividuation" target="_blank" rel="noreferrer noopener">deindividuation</a>” — a temporary loss of one’s identity leading to behavior incongruent with one’s character. It explains why groups of civilized people can engage in riots. It also explains trolling. If a lack of nonverbal cues is what makes us detached from the other person’s suffering, deindividuation is what makes us detached from the awareness of our misconduct.</span></p>

<p><span>True anonymity offers protection from real-world social repercussions, and this has profound effects on human behavior. The image-based bulletin board 4chan, where registration isn’t possible and users remain anonymous, has been&nbsp;<a href="https://theconversation.com/4chan-raids-how-one-dark-corner-of-the-internet-is-spreading-its-shadows-68394" target="_blank" rel="noreferrer noopener">infamous as a troll incubator</a>&nbsp;for this reason. When there are no real-world consequences to your actions, it liberates you from a lifetime of societally inhibited behaviors. Society discourages antisocial behavior and encourages prosocial behavior, so it is antisocial behavior that seeks liberation.</span></p>

<p><span>We are a delicate balance between prosocial humans and antisocial primates. When society cannot enforce prosocial human behavior, the antisocial primate may come back into power. And thus the troll is created.</span></p>

<h4 id="f597"><span>Troll begets troll</span></h4>

<p><span>Researchers at Stanford and Cornell universities performed a large-scale data analysis on&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5791909/" target="_blank" rel="noreferrer noopener">over 16 million comments</a>&nbsp;from December 2012 to August 2013 on CNN.com and found 1 in 4 posts flagged as abusive were from users with no prior record of trollish behavior. This suggests trolling isn’t always a full-time occupation and that one may indulge sporadically.</span></p>

<p><span>The researchers could predict the likelihood of trolling based on the nature of other comments in the discussion and the user’s mood. If earlier comments were negative, the propensity to troll was greater. Like a bad mood, trolling is contagious. All it takes is another user’s trollish comment and a bad mood to create an environment in which our inner troll can blossom.</span></p>

<h4 id="b294"><span>The inner troll</span></h4>

<p><span>It is easier to view trolls as bad apples than see them as something inside all of us, waiting for the right environment to let loose. But when we condemn trolls as inherently malicious individuals, we limit our understanding of what may drive these behaviors.</span></p>

<p><span>While RIP trolls or suicide baiters are likely to be dark tetrad personality types who use the internet as an outlet to indulge their darkest impulses, lesser trolls may be part-time participants who will engage with the right combination of a bad day and a noxious environment. We have only begun to scratch the surface in our understanding of trolls, but the evidence we have suggests we may all be vulnerable.</span></p>

<p><span>Is anyone exempt from toxic disinhibition? Few respond to a tweet that offends them with “Excuse me, I really don’t want to be rude, but if I may could I please respectfully disagree with your opinion for these reasons …” While an offhand remark may appear harmless, the less empathic our online interactions collectively become, the greater risk we all stand of becoming trolls. The gentle ripples of impolite tweets may become crashing toxic waves of disinhibited hatred.</span></p>

<p><span>Trolling isn’t black and white, it is somewhere in the grey between prosocial human and antisocial primate. Ultimately, our propensity for antisocial behavior in the physical world is likely to predict similar online behavior.</span></p>

<h4 id="9272"><span>How can we manage our inner trolls?</span></h4>

<p><span>The more accountable we are for our behavior, the less potential we have of becoming trolls. Employing&nbsp;<a href="https://scholarspace.manoa.hawaii.edu/bitstream/10125/41373/1/paper0224.pdf" target="_blank" rel="noreferrer noopener">less anonymity may help</a>, but this raises privacy concerns for many. Anonymity can also be a good thing. Benign disinhibition — the friendly sibling of toxic disinhibition — is where users freely discuss their deepest insecurities and concerns with other users. This can be very therapeutic and shouldn’t be discouraged. But by using anonymity only where it is necessary, we reduce the likelihood of toxic disinhibition.</span></p>

<p><span>Empathy doesn’t come …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dradambell.com/why-people-become-internet-trolls/">https://dradambell.com/why-people-become-internet-trolls/</a></em></p>]]>
            </description>
            <link>https://dradambell.com/why-people-become-internet-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259728</guid>
            <pubDate>Mon, 24 Aug 2020 11:50:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Generators, Meet XPath]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24259688">thread link</a>) | @fanf2
<br/>
August 24, 2020 | https://jack.wrenn.fyi/blog/xpath-for-2020/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/xpath-for-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
<article>
    <header>
      
      <span>2020-08-22&nbsp;</span>
    </header>

    <p>Using Generators to Modernize a Geriatric Javascript API for <code>$CURRENT_YEAR</code></p>
<span id="continue-reading"></span>
<hr>
<p>How do you find-and-replace text on an HTML page?</p>
<pre><code><span>&lt;div&gt;</span><span>Hello, </span><span>&lt;span&gt;</span><span>human</span><span>&lt;/span&gt;</span><span>!</span><span>&lt;/div&gt;
</span></code></pre>
<p>If the text is neatly neatly isolated inside an HTML element, it's easy; this will do:</p>
<pre><code><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"span"</span><span>)</span><span>.textContent </span><span>= </span><span>"evolved ape"</span><span>;
</span></code></pre>
<p><strong>But here's a puzzle</strong>: how do you you change text that <em>isn't</em> neatly isolated in an HTML element?</p>
<p>You <em>could</em> use <code>innerHTML</code>:</p>
<pre><code><span>let </span><span>elt </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>;
</span><span>elt</span><span>.innerHTML </span><span>= </span><span>elt</span><span>.innerHTML.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>...but this will hose any event listeners registered on <code>elt</code>'s children.</p>
<p>You <em>could</em> grapple onto the nearest selectable element:</p>
<pre><code><span>let </span><span>node </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>.childNodes[</span><span>0</span><span>];
</span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>Yuck; this sort of child-node indexing feels <em>really</em> brittle.</p>
<p><strong>Why can't we just <em>directly</em> select the text nodes containing <code>Hello</code>?</strong></p>
<h2 id="xpath">XPath</h2>
<p><strong>We can!</strong> Enter: <a href="https://en.wikipedia.org/wiki/XPath">XPath</a>, the <em>excessively</em> powerful language for querying XML documents. It's usable in web-browsers with the, uh, <em>descriptively</em>-named method <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/evaluate"><code>document.evaluate</code></a>.</p>
<p>It's a <em>bit</em> of a production to use:</p>
<pre><code><span>let </span><span>xpath </span><span>= </span><span>"//text()[contains(., 'Hello')]"</span><span>; </span><span>// find text nodes containing 'Hello'
</span><span>let </span><span>context </span><span>= </span><span>document</span><span>.body; </span><span>// look in the body element
</span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>; </span><span>// some sorta xml voodoo
</span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE; </span><span>// DEFINITELY MAKE SURE YOU USE THIS

</span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

</span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>) {
  </span><span>let </span><span>node </span><span>= </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
}
</span></code></pre>
<p>Yes, you really need to write <em>all</em> of that. The <code>result_type</code> argument is technically optional, but omit it at your own peril: without it, you must instead stream results via <code>iterateNext</code>, and this will crash with an exception if you dare <em>modify</em> the queried elements!</p>
<p>It's no wonder <code>document.evaluate</code> is seldom used. <strong>Can we improve on it?</strong></p>
<h2 id="iterizing-xpath-queries">Iterizing XPath Queries</h2>
<p>Yes, with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators"><strong>generators</strong></a>! We can exploit the implicit iterability of generators to modernize this unwieldy API:</p>
<pre><code><span>Document</span><span>.</span><span>prototype</span><span>.xpath </span><span>= </span><span>Element</span><span>.</span><span>prototype</span><span>.</span><span>xpath </span><span>=
  </span><span>function* </span><span>xpath</span><span>(</span><span>xpath</span><span>) {
    </span><span>let </span><span>context </span><span>= </span><span>this </span><span>instanceof </span><span>Document </span><span>? </span><span>document</span><span>.documentElement </span><span>: </span><span>this</span><span>;
    </span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>;
    </span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE;
    </span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

    </span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>)
      </span><span>yield </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  };
</span></code></pre>
<p>And because the result of this function is iterable, we can use it with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax">spread syntax</a>:</p>
<pre><code><span>[</span><span>...</span><span>document</span><span>.</span><span>xpath</span><span>(</span><span>"//text()[contains(., 'Hello')]"</span><span>)</span><span>].
  </span><span>forEach</span><span>(</span><span>node </span><span>=&gt; </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>))</span><span>;
</span></code></pre>
</article>

        </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/xpath-for-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259688</guid>
            <pubDate>Mon, 24 Aug 2020 11:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of Venmo (2014)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24259509">thread link</a>) | @saadalem
<br/>
August 24, 2020 | https://kortina.nyc/essays/origins-of-venmo/ | <a href="https://web.archive.org/web/*/https://kortina.nyc/essays/origins-of-venmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I often speak about the origins of Venmo in person and finally wrote down the story here to share with our latest intern class that started this week. (You can also watch an excellent video of Iqram speaking about even more of the history of Venmo <a href="https://www.youtube.com/watch?v=aX7JCCCmLJw">here</a>. It’s a good place to pickup the story where this post leaves off.)</p>

<p>My friend Iqram and I started Venmo to solve a very simple problem for ourselves and for our friends: we noticed that we were still using cash and checks to pay each other back and thought this was silly. Everyone should be using PayPal to pay each other back, but no one we knew was. We thought something must be not quite right about the PayPal experience for casual use, and we decided to design something that felt “right,” something that felt consistent with all of the other mobile tools we used to interact with our friends, like SMS, Gmail, Facebook, etc. This is the story of how we got to Venmo.</p>

<h2 id="penn">Penn</h2>

<p>Iqram and I met as randomly paired freshman year roommates at the University of Pennsylvania in 2001. We’ve been great friends ever since.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iqram-kortina-college.png">
<figcaption>Oldest pic I could find of me and Iqram.</figcaption>
</figure>

<p>Iqram studied computer science at Penn. I started in computer science, but found that much of the learning I was doing happened while I was doing homework exercises, and I was getting no additional value out of the University. I couldn’t justify tuition costs when I was only learning by spending time doing programming exercises, and I developed a hypothesis that I would maximize the value of tuition costs by studying the least practical subjects possible, the things I would not get to do after graduation / outside of University, like reading and discussing great books with a group of incredibly smart students and professors (this backfired, btw–liberal arts is very practical stuff!). I eschewed big lectures and things like On Campus Recruiting, and tried to spend as much time possible in seminars and writing workshops. I ended up with majors in Philosophy and Creative Writing and minors in Computer Science and Logic.</p>

<p>I remained interested in building things during this time, however, and always took the opportunity to build websites for various clubs I was in or for friends with bands, etc.</p>

<p>During our senior year, Iqram and I built our first real project together, a college classifieds site called My Campus Post. It was our first taste of all night coding sessions to get a product to market, and we learned a bunch about grassroots marketing and retention challenges that arise from products with seasonal usage.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/mycampuspost.png">
<figcaption>My Campus Post marketing paraphernalia.</figcaption>
</figure>

<p>I loved spending all of my time reading philosophy, working on fun side projects, and actively ignoring practical things like interviewing for jobs, but I clearly remember the day when my Mom was in town for graduation and she asked, “What are you doing after you graduate?” I was sitting on the floor of my dorm room, and I remember being very scared about the question, thinking, “I have no idea what I want to do with my life,” but also feeling OK about the short term, eventually answering, “I don’t have to move out of my dorm until 2 weeks after graduation. I’ll figure something out.”</p>

<h2 id="post-grad-door-to-door-sales">Post Grad Door to Door Sales</h2>

<p>Iqram ended up finding a cheap sublet in West Philly, and we spent the summer building websites for restaurants, salons, bars, etc. We went door to door selling, “Hey, you need a website. We’ll build it for $500…. $100? OK, deal.” We learned a lot as we tried to abstract the sites we were building into something modular, and we got a lot of experience pitching and hearing “no.” One “no” that I still regret more than most of the others I have subsequently heard (for much bigger deals) was for this amazing Pakistani restaurant, Kabobeesh, that served a chicken kabob sandwich on fresh naan bread for $3.50: we tried to sell them a site for 100 chicken rolls, but failed to close them.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/kabobeesh.png">
<figcaption>Kabobeesh: I recommend the chicken rolls and chicken karahi.</figcaption>
</figure>

<p>Once, we were chatting at a bar about how we might pad our sporadic income with some part time jobs. We noticed the bar was hiring, got two applications, and started filling them out. We spent a few minutes getting through all the basic background stuff, education, personal info, and got to the references section. We didn’t really have past employers to list at the time, so I put Iqram as a reference, and he put me. We were still rooming together at the time, so we had the same street address. We did not get a call back.</p>

<h2 id="swooge-and-philafunk">Swooge and Philafunk</h2>

<p>During this period, we were always also working on startup-y things, like a realtime website analytics tool called Swooge (which now reminds me of Chartbeat + Google Analytics) and a web based music selling platform, Philafunk (it was like iTunes + MySpace).</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/philafunk.jpg">
<figcaption>Philafunk site and flyer.</figcaption>
</figure>

<p>After working on a few of these, we realized we had a lot to learn about building a successful startup, so we decided to go find one and work there. Many of these projects we worked on were still in my opinion great ideas and solid evidence that execution matters much more than the idea.</p>

<h2 id="iminlikewithyou">iminlikewithyou</h2>

<p>So we found this NYC company, iminlikewithyou.com, that was just getting started out of Y Combinator, and we joined as 2 of the first 3 employees, all engineers starting together the day we moved to NYC. We had a talented team, built a really innovative, immersive web experience, and learned a bunch about doing startups for real. Eventually, the company pivoted from the original flirting-site idea into a casual games company (OMGPOP), and we both left because we weren’t interested in building games.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iminlikewithyou.png">
<figcaption>iminlikewithyou site.</figcaption>
</figure>

<h2 id="ticketleap-and-bitly">Ticketleap and Bit.ly</h2>

<p>Iqram worked at Ticketleap as the VP of Engineering for a few years, and I bounced around and ended up spending a bunch of time working at Betaworks, on Bit.ly.</p>

<p>We both learned a lot during this period, but I looked forward to the time when we would work on a new project together, with more knowledge and experience this time. Over the years, I often brought up this idea, but the timing was never quite right.</p>

<h2 id="exploring-new-product-ideas">Exploring New Product Ideas</h2>

<p>In early 2009, Iqram chatted me mentioning that he was feeling ready to move on from Ticketleap, and I remember thinking, “Great let’s do this.” We began getting together on weekends (he was in Philly and I was in NYC) to hack on different ideas.</p>

<h2 id="yogorino">Yogorino</h2>

<p>We had a friend in Philadelphia who was opening a yogurt shop, and while helping her get up and running technically, we realized how horrible traditional point of sales software was. We prototyped a web based point of sales software that would turn any laptop into a cash register with a $50 USB magtek swiper. As we thought about it more, it seemed like this would present a really challenging distribution problem (we remembered our days of door to door restaurant sales…). Plus, although this was designed to solve a problem for one of our friends, it wasn’t software that we would be using ourselves daily.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/cardswiper.png">
<figcaption>Web POS prototype.</figcaption>
</figure>

<h2 id="back-to-music">Back to Music</h2>

<p>Another idea we explored came to us at a local jazz show: we thought, “It would be awesome to be able to download this show by sending a text message to this band right now, and then have an mp3 show up in our email.” This was getting closer to the Venmo concept we ultimately arrived at, and the detailed wireframes we constructed for this definitely informed a lot of the original Venmo service.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/rootsbuy.png">
<figcaption>Wireframe for selling music downloads via SMS.</figcaption>
</figure>

<p>This concept even bore the Venmo name. Lots of people ask about the origin of the name. The brainstorming process was one of many we tried and was not important as the requirements. We were exploring the Latin root vendere “sell” and mo for mobile, but purely as a means to get to a name that (1) was short, 5-6 letters, (2) could be a verb, (3) didn’t have a unintuitive spelling, and (4) was cheap. Venmo was available on GoDaddy and met the important criteria, so we grabbed it.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/visionslide.png">
<figcaption>A slide from our deck for an SMS music service.</figcaption>
</figure>

<h2 id="discovering-venmo">Discovering Venmo</h2>

<p>One of the weekends we were getting together to work on this idea, Iqram was visiting me in NYC and left his wallet in Philly. I covered him for the whole weekend, and he ended up writing me a check to pay me back. It was annoying for him to have to find a checkbook to do this, and annoying for me to have to go to the bank if I wanted to cash it (I never did). We thought, “Why are we still doing this? We do everything else with our phones. We should definitely be using PayPal to pay each other back. But we don’t, and none of our friends do.”</p>

<p>So we decided, let’s just try to solve this problem, and build a way to pay each other back that feels consistent with all of the other experiences we have in apps we use with our friends.</p>

<p>We got pretty excited about this idea, and thought, “Surely someone else must be doing this.” We found a laptop and started googling, and soon came across Obopay: a way to send money to anyone directly from your cell phone. They had recently raised $70M from Nokia, and we thought, “Uh-oh.” But then we poked around the website and the product and found that there was no feel and it seemed a little clunky and not like something anyone we knew would ever use.</p>

<h2 id="evolution-of-the-note">Evolution of the Note</h2>

<p>We got a prototype working pretty quickly. It worked over SMS, and was dead simple. To send iqram $20, text “iqram 20” to our number (a hacked Google Voice account, because the alternative, Textmarks, required that you prefix every text message with a keyword–this was back in the days before Twilio…). The recipient saw “kortina paid you $20.”</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/gvhack.png">
<figcaption>Google Voice SMS hack.</figcaption>
</figure>

<p>Right after we got this working we decided we needed to have a note with each payment so we could keep track of what all of these random amounts were for: “iqram 20 for thai lunch at Nooch.”</p>

<p>The interface was SMS, so we immediately thought, of course it would only be natural for the person on the other end to see the message, so we updated …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kortina.nyc/essays/origins-of-venmo/">https://kortina.nyc/essays/origins-of-venmo/</a></em></p>]]>
            </description>
            <link>https://kortina.nyc/essays/origins-of-venmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259509</guid>
            <pubDate>Mon, 24 Aug 2020 11:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BPF Portability and CO-Re (Compile Once Run Everywhere)]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24259499">thread link</a>) | @nyellin
<br/>
August 24, 2020 | https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html | <a href="https://web.archive.org/web/*/https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>What does portability mean in BPF context? What are the challenges of writing portable BPF programs that developers need to deal with? This post will describe BPF portability problem and how BPF CO-RE (Compile Once – Run Everywhere) is helping to address this problem.</p>
<!--truncate-->

<h2>BPF: state of the art</h2>
<p>Since the inception of (e)BPF, it’s been a constant priority for the BPF community to simplify BPF application development as much as possible, make it as straightforward and familiar of an experience as it would be for a user-space application. And with the steady progress around BPF programmability, writing BPF programs has never been easier.</p>
<p>Despite these usability improvements, though, one aspect of BPF application development has been neglected (mostly for technical reasons): portability. What does "BPF portability" mean, though? We define <strong>BPF portability</strong> as the ability to write a BPF program that will successfully compile and pass kernel verification, and will work <strong>correctly</strong> across <em>different kernel versions</em> without the need to recompile it for each particular kernel.</p>
<p>This note describes the BPF portability problem and our solution to it: BPF CO-RE (Compile Once – Run Everywhere). First, we’ll look at the BPF portability problem itself, describing why it is a problem and why it’s important to solve it. Then, we will outline high-level components of our solution, BPF CO-RE, and will give a glimpse into the pieces of the puzzle that needed to be put together to make it happen. We’ll conclude with a tutorial of sorts, describing the user-visible API of the BPF CO-RE approach and demonstrating its application with examples.</p>
<h2>The problem of BPF portability</h2>
<p>A BPF program is a piece of user-provided code which is injected straight into a kernel. Once loaded and verified, BPF programs execute in kernel context. These programs operate inside kernel memory space with access to all the internal kernel state available to it. This is extremely powerful and is one of the reasons why BPF technology is successfully used in so many varied applications. However, this powerful capability also creates the BPF portability pains we have today: BPF programs do not control memory layout of a surrounding kernel environment. They have to work with what they get from independently developed, compiled, and deployed kernels.</p>
<p>Additionally, kernel types and data structures are in constant flux. Different kernel versions will have struct fields shuffled around inside a struct, or even moved into a new inner struct. Fields can be renamed or removed, their types changed, either into some trivially-compatible ones or completely different ones. Structs and other types can get renamed, or they can be conditionally compiled out (depending on kernel configuration), or just plain removed between kernel versions.</p>
<p>In other words, things change all the time between kernel releases and yet BPF application developers are expected to cope with this problem somehow. How is it even possible to do anything useful with BPF today considering this ever-changing kernel environment? There are a few reasons for this.</p>
<p>First, not all BPF programs need to look into internal kernel data structures. One example is <code>opensnoop</code> tool, which relies on kprobes/tracepoints to track which processes open which files, and just needs to capture a few syscall arguments to work. As syscall parameters offer a stable ABI, these don’t change between kernel versions and as such portability is not a concern to begin with. Unfortunately, applications like this are quite rare. These types of applications are also typically quite limited in what they can do.</p>
<p>So, additionally, BPF machinery inside kernel provides a limited set of "stable interfaces" that BPF programs can rely on to be stable between kernels. In reality, underlying structures and mechanisms do change, but these BPF-provided stable interfaces abstract such details from user programs.</p>
<p>As one example, for networking applications it is usually enough to look at a limited set of <code>sk_buff</code>'s attributes (and packet data, of course) to be extremely useful and versatile. To that end, BPF verifier provides a stable <strong><code>__sk_buff</code></strong> "view" (notice underscores in front), which shields BPF programs from changing <code>struct sk_buff</code> layout. All the <code>__sk_buff</code> field accesses are transparently rewritten into an actual <code>sk_buff</code> accesses (sometimes quite elaborate ones – doing a bunch of internal pointer chasing before finally fetching requested field). Similar mechanisms are available to a bunch of different BPF program types. They are done as program type-specific BPF contexts understood by BPF verifier. So, if you are developing a BPF program with such context, consider yourself lucky, you can blissfully live in a nice illusion of stability.</p>
<p>But as soon as you need to get a glimpse at any raw internal kernel data (e.g., very commonly a <code>struct task_struct</code> which represents a process/thread and contains a treasure trove of process information), you are on your own. It is commonly the case for tracing, monitoring, and profiling applications, which are a huge class of extremely useful BPF programs.</p>
<p>In such cases, how do you make sure you are not reading garbage data when some kernel added an extra field before the field you thought is, say, at offset 16 from the start of <code>struct task_struct</code>? Suddenly, for that kernel, you'll need to read data from, e.g., offset 24. And the problems don't end there: what if a field got renamed, as was the case with <code>thread_struct</code>'s <code>fs</code> field (useful for accessing thread-local storage), which got renamed to <code>fsbase</code> between 4.6 and 4.7 kernels. Or what if you have to run on two different configurations of a kernel, one of which disabled some specific feature and completely compiled out parts of the struct (a common case for additional accounting fields, which are optional, but extremely useful if present)? All this means that you can no longer compile your BPF program locally using kernel headers of your dev server and distribute it in compiled form to other systems, while expecting it to work and produce correct results. This is because kernel headers for different kernel versions will specify a different memory layout of data your program relies on.</p>
<p>So far, people have been dealing with this problem by relying on <a href="https://github.com/iovisor/bcc/">BCC</a> (BPF Compiler Collection). With BCC, you embed your BPF program C source code into your user-space program (control application) <em>as a plain string</em>. When control application is eventually deployed and executed on target host, BCC invokes its embedded Clang/LLVM, pulls in local kernel headers (which you have to make sure are installed on the system from correct <code>kernel-devel</code> package), and performs compilation on the fly. This will make sure that memory layout that BPF program expects is exactly the same as in the target host's running kernel. If you have to deal with some optional and potentially compiled-out stuff in kernel, you'll just do <code>#ifdef</code>/<code>#else</code> guarding in your source code to accommodate such hazards as renamed fields, different semantics of values, or any optional stuff not available on current configuration. Embedded Clang will happily remove irrelevant parts of your code and will tailor BPF program code to specific kernel.</p>
<p>This sounds great, doesn't it? Not quite so, unfortunately. While this workflow works, it's not without major drawbacks.</p>
<ul>
<li><p>Clang/LLVM combo is a big library, resulting in big fat binaries that need to be distributed with your application.</p></li>
<li><p>Clang/LLVM combo is resource-heavy, so when you are compiling BPF code at start up, you'll use a significant amount of resources, potentially tipping over a carefully balanced production workfload. And vice versa, on a busy host, compiling a small BPF program might take minutes in some cases.</p></li>
<li><p>You are making a big bet that the target system will have kernel headers present, which most of the time is not a problem, but sometimes can cause a lot of headaches. This is also an especially annoying requirement for kernel developers, because they often have to build and deploy custom one-off kernels as part of their development process. And without a custom-built kernel header package, no BCC-based application will work on such kernels, stripping developers of a useful set of tools for debugging and monitoring.</p></li>
<li><p>BPF program testing and development iteration is quite painful as well, as you are going to get even most trivial compilation errors only in runtime, once you recompile and restart your user-space control application. This certainly increases friction and is not helping to iterate fast.</p></li>
</ul>
<p>Overall, while BCC is a great tool, especially for quick prototyping, experimentation, and small tools, it certainly has lots of disadvantages when used for widely deployed production BPF applications.</p>
<p>We are stepping up the game of BPF portability with BPF CO-RE and believe this is a future of BPF program development, especially for complex real-world BPF applications.</p>
<h2>High-level BPF CO-RE mechanics</h2>
<p>BPF CO-RE brings together necessary pieces of functionality and data at all levels of the software stack: kernel, user-space BPF loader library (libbpf), and compiler (Clang) – to make it possible and easy to write BPF programs in a portable manner, handling discrepancies between different kernels within the same pre-compiled BPF program. BPF CO-RE requires a careful integration and cooperation of the following components:</p>
<ul>
<li><p>BTF type information, which allows to capture crucial pieces of information about kernel and BPF program types and code, enabling all the other parts of BPF CO-RE puzzle;</p></li>
<li><p>compiler (Clang) provides means for BPF program C code to express the intent and record relocation information;</p></li>
<li><p>BPF loader (<a href="https://github.com/libbpf/libbpf">libbpf</a>) ties BTFs from kernel and BPF program together to adjust compiled BPF code to specific kernel on target hosts;</p></li>
<li><p>kernel, while staying completely BPF CO-RE-agnostic, provides advanced BPF features to enable some of the more advanced scenarios.</p></li>
</ul>
<p>Working in ensemble, these components …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</a></em></p>]]>
            </description>
            <link>https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259499</guid>
            <pubDate>Mon, 24 Aug 2020 11:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My startup validation process]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24259246">thread link</a>) | @NeilRamp
<br/>
August 24, 2020 | https://neilcocker.com/2020/08/22/my-startup-validation-process/ | <a href="https://web.archive.org/web/*/https://neilcocker.com/2020/08/22/my-startup-validation-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

		<!-- #masthead -->

			<!-- .image-header -->
	
	

<section id="content">
	<div>
		<div>
						<div id="primary">
							<main id="main" role="main">

					
						
<article id="post-2340">
	<!-- .entry-header -->

	<div>
		
<p>I’m very interested in how startups validate their ideas. I’m finding that actually a staggering amount of them barely do. Or just do it very badly.</p>



<p>There’s no one right way to validate a startup idea. And, even if you do it perfectly, it doesn’t guarantee success. But it does hugely reduce the risk of failure.</p>



<p>What I outline below is the method I’ve been using for a while. It’s <strong>not comprehensive</strong>, and each of the steps can be done in a much more detailed way. But it’s <strong>quick</strong>, captures good data, and gives you a very strong footing to start your journey.</p>



<p>TL;DR</p>



<ul><li>Define your customer – 1 hour</li><li>Read a book – 3 hours</li><li>Write your hypothesis – 1 hour</li><li>Create and distribute a survey – 4 hours</li><li>Speak to people (properly!) – 10+ hours</li></ul>



<figure><img data-attachment-id="2355" data-permalink="https://neilcocker.com/william-iven-gcsnospexfs-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg" data-orig-size="4193,2785" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="william-iven-gcsnospexfs-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=750" src="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@firmbee?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">William Iven</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>Here’s a quick breakdown of each one of these. </p>



<p>1 – Define your potential market, and your potential customer. You may already have a typical customer in mind, but try to drill down into something specific. It’s not enough to just say “This is for entrepreneurs”. Or “It’s for single mums”. You need to define them more clearly by their behaviours, as well as their primary characteristics. Try something like “Time-rich, cash-poor,&nbsp; freelancers who need extra sources of income”. Or “High net worth individuals who take more than ten flights for business a year”. </p>



<p>2 (Optional, but VERY strongly recommended) – Read <a href="http://momtestbook.com/">The Mom Test</a>. I think it’s the most important business book I’ve ever read, and it fundamentally changed how I talk to (potential) customers. It stopped me being obsessed with my product, and fall in love with the problem. I should get commission for how often I recommend it! If you have already read it, and are confident that you don’t need to refresh your memory, then move on to stage 3.</p>



<p>The Mom Test is a book that helps you speak to your customers in a way in which they can’t lie to you, subconsciously or otherwise. By talking about their life, and the problems they face around your area of interest, INSTEAD of your solution, you get an unfiltered, unbiased set of feedback about what they REALLY want to have solved. And not just feedback to the idea you have presented to them, which is probably a very different thing. This is a VERY important thing to understand, especially as “no market need” is the most often cited reason for startups failing.</p>



<p>Don’t let your ego get in the way of having a successful business. <strong>Your solution isn’t more important than their problem.</strong></p>



<p>If you don’t want to spend 3 hours reading the book, spend an hour<a href="https://www.youtube.com/watch?v=FG1Fa-t4AEQ&amp;t=0s"> watching the author talk about it</a>. If you don’t want to spend an hour watching that, spend three minutes watching<a href="https://www.youtube.com/watch?v=Hla1jzhan78"> this video</a>, or reading<a href="https://medium.com/@nataliekorotaeva/how-to-talk-with-your-users-3-takeaways-from-the-mom-test-by-rob-fitzpatrick-bbeb4a93ba07"> this blogpost</a>. Ideally you’ll do all of the above, just so you fully embrace the idea.</p>



<figure><img data-attachment-id="2359" data-permalink="https://neilcocker.com/nesa-by-makers-igur1ix0mqm-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg" data-orig-size="6720,4480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nesa-by-makers-igur1ix0mqm-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=750" src="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@nesabymakers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">NESA by Makers</a> on <a href="https://unsplash.com/s/photos/startup?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>3 – Write your hypothesis. I won’t write too much here, as there are lots of great blogposts out there that do a great job of explaining good ways of nailing this. In short, you’re looking to find a hypothesis that you can test with your customer conversations. There are several different templates for this, but this is a simple one to start with. </p>



<p><em>I believe [target market] will [engage in this behaviour / use this solution] for [this reason].</em></p>



<p>You can refine this as you go along, and as you speak to customers. After all, there’s a very good chance that your research will show you that your hypothesis is wrong – and therefore you’ve just saved yourself thousands of Pounds, Dollars, or Euros, and 2 years of your life. Yay!</p>



<p>If your hypothesis is proven wrong, you can come up with a new one, and start again. </p>



<p>4 – Design a survey that is easy to distribute, and easy to fill in (multiple choice here). The idea is to capture some rough data, but mainly it’s the top of a funnel for getting people on the phone to the real interviews. </p>



<p>Here’s <a href="https://docs.google.com/forms/d/e/1FAIpQLSdSwINF3uDxeD2fx0Y5sWaX9esyrG39HzCzeXSPMcwMRo5wnw/viewform?usp=sf_link">an example of a real, live survey</a> that I’m currently using to capture data from potential customers. Feel free to steal the format, and also <strong>feel free to fill it in if you’re an early stage founder, too</strong>.</p>



<p>I’ve used Google Forms in this example, but I also heartily recommend the services of <a href="https://doopoll.co/">Doopoll</a>.</p>



<p>Make it mainly multi-choice, to make it a low barrier to people filling t in, but if you feel like you want to devote one question to free-entry, then go ahead. It can sometimes be a simple “Is there anything else you would like to tell us?” thing at the end.</p>



<p>Distribute via the usual channels, and call in favours from people who can help you reach your target market.</p>



<p>Hint – <strong>Twitter is a search engine for human beings</strong>. Want to find people interested in, for example, medtech? There’s a ton of hashtags these people will use, and that info may also be in their bio. It wouldn’t take too long to tweet a few hundred of them with a polite message, asking them to give you 2 mins of their time to fill in the survey, as they’re interested in your area of research.</p>



<p>Bonus – it’s an email list for you to approach to be your beta users once you have an MVP up and running. But, be respectful. These people gave you their time for free, so don’t just add them to a never-ending drip campaign.</p>



<figure><img data-attachment-id="2357" data-permalink="https://neilcocker.com/daria-nepriakhina-zocdwpuirua-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg" data-orig-size="4032,2688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="daria-nepriakhina-zocdwpuirua-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=750" src="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@epicantus?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Daria Nepriakhina</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>4 – Speak to the ones you have chosen. Read The Mom Test *before* you speak to them. It’ll allow you to ask questions that get to the root of the real problems they face in this area, and not just answer questions that are limited to the scope of your proposed product. In an ideal world, they’ll end the session not having a clue what your product is. It’s all about them, NOT your product.</p>



<p>I’d strongly recommend speaking to at least 25 people. Preferably more like 50. If you have chosen a well-enough defined target (and not just something vague like “car owners” or “entrepreneurs”), and you listen carefully, clear trends will start to emerge. And these may well be problems that you can solve!</p>



<p>Hint – I strongly recommend Calendly (or similar) to provide a 15 or 20-min link to your interviewees, allowing them to book the relevant slot in your calendar. This will give them confidence that you intend to honour your 15 min promise. It also keeps you concise in your questioning, and get to the point. If they’re happy to keep talking, that’s great. But don’t abuse their goodwill.</p>



<p>Finally – Fall in love with the problem, not your product. The market, in a true economic sense, doesn’t care about your product. It only cares about you being able to solve a problem. Don’t succumb to Ugly Baby Syndrome, where you have come up with an idea that you LOVE, and you’re deaf to any market signals that tell you that it’s no good.</p>



<p>I know that I’ve made this mistake in the past. To be enthusiastic, and in love with your idea is a very normal thing. And it’s particularly typical of entrepreneurs, as we’re all out trying to change the world. But we’ve been mis-sold the concept that the moment of genius, and the idea itself, is sacrosanct. But successful entrepreneurship is about a disciplined process. And validation is an absolutely vital part of it.</p>



<p>I once had the “product-first instead of problem-first” way of doing things described to me as “<strong>designing a key (product) and running around trying to find a lock (problem) that it will open</strong>“. Surely it’s much better to find a lock, study it, understand it, then design a key to open it. </p>



<p>If you’ve done all the steps above, you now understand the lock MUCH better. Go make a key to open it.</p>



<p>Update – I’ve had a few people ask for my input on their ideas. If you’d like a free mentoring session, you can <a href="https://neilcocker.com/toughquestions/">book in here</a>.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
						
	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
						
<!-- #comments -->

					
				</main><!-- #main -->
			</div><!-- #primary -->
			
<!-- #secondary -->
		</div><!-- .row -->
	</div><!-- .container -->
</section><!-- #main -->



		<!-- #colophon -->
	</div></div>]]>
            </description>
            <link>https://neilcocker.com/2020/08/22/my-startup-validation-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259246</guid>
            <pubDate>Mon, 24 Aug 2020 10:30:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pieter Levels Makes $600k a Year from Nomad List and Remote OK]]>
            </title>
            <description>
<![CDATA[
Score 284 | Comments 139 (<a href="https://news.ycombinator.com/item?id=24259201">thread link</a>) | @Pete-Codes
<br/>
August 24, 2020 | https://www.nocsdegree.com/pieter-levels-learn-coding/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/pieter-levels-learn-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p><a href="https://twitter.com/levelsio">Pieter Levels </a>makes about $600,000 a year. He taught himself to code and has an unconventional philosophy. This is not an interview but an analysis piece. Pieter defied the critics and built Nomad List and Remote OK into successful businesses without cutting edge tools like React or other modern frameworks. If you would like to learn more about the business side of things, check out my new product, <a href="https://gum.co/hCrax">How Does This Make Revenue?</a></p><h2 id="who-is-pieter-levels">Who is Pieter Levels</h2><p>Pieter is a self-taught developer from The Netherlands. He has an MBA but no coding qualifications. As we will see in today's article he has a rough and ready approach to coding but it pays off handsomely. </p><p>His <a href="https://www.nomadlist.com/">Nomad List</a> directory and community for digital nomads draws in over $300k a year and that's despite a recent fall in revenue due to people not travelling during the Corona virus crisis. </p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.30.06.png" alt=""></figure><p>His Remote Ok job board for remote workers made <a href="https://remoteok.io/open">$300,000 over the last 12 months</a></p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.23.51.png" alt="Revenue chart for Remote OK job board"></figure><p>So that's a total of $600,00 from the last 12 months! Not bad for a self-taught developer! Pieter is active on Twitter and has a very stong following there. </p><p>As he works for himself he is able to travel extensively and live where he choses. Although, rather than the common misconception of digital nomads being constantly on the move, Pieter recommends spending a few months in each place. This way you avoid travel burnout. </p><h2 id="how-did-pieter-levels-learn-to-code">How did Pieter Levels learn to code?</h2><p>Not a lot is known about his very earlies forays into coding apart from the fact that as a teenager he played around programming. His first attempt at a web business was an analytics service for Youtube which would let you see how all your videos/channels were performing in one place. Unfortunately, he worked on it for a year without making any money from it. </p><p>From that point Pieter adopted his now familar approach to coding and business - build websites quickly and monetize from the beginning. He only adds more features if there is money coming in and the idea is validated by the market.</p><p>Pieter takes the "search on Google" approach to Google. So when he wanted to connect a database to a website or make a button do something on his website he would just search the terms on Google and find solutions in places like Stackoverflow. Pieter is a strong critic of the approach of doing courses as he believes people learn best by doing and building. </p><p>One analogy would be different approaches to learning Spanish. One person might study a course, learn the correct grammar and then go to Spain. Whereas Pieter would go to Spain, ask for the words he needs to use and go from there. </p><p>When asked in the past why he didn't use modern frameworks like React he made the point that as he was a solo founder he couldn't afford to spend time re-building his websites as this would mean his project would stall. </p><!--kg-card-begin: markdown--><p><a href="https://gum.co/GGofo"><img src="https://www.nocsdegree.com/content/images/2020/08/monetize.png" alt="monetize"></a></p>
<!--kg-card-end: markdown--><h2 id="what-technologies-does-pieter-levels-use">What technologies does Pieter Levels use?</h2><p>Pieter is famous (or infamous) for having a rather eccentric choice of stack by modern standards. It's essentially the easiest, least glamorous tools you could imagine. But that's ok because Pieter makes $600k a year! </p><p>Here is his stack:</p><ul><li>HTML (hand coded so no template to make life easier)</li><li>CSS (He has used pre-processors like LESS and SASS in the past)</li><li>Javascript (No frameworks - this is sometimes referred to jokingly as Vanilla Javascript. There is no such thing as Vanilla JS though. It's just plain-old Javascript without a framework such as React, Vue or Angular) </li><li>jQuery (An unfashionable choice nowadays but it does the job)</li><li>PHP (He doesn't use any frameworks like Laravel)</li><li>SQLite - Pieter says it's super quick and swears by it. SQLite is a database written in a single file so Pieter doesn't need to set up a server for it. &nbsp;</li><li>his sites are hosted on a single VPS running Ubuntu with NGINX.</li></ul><p>Here are some modern options Pieter doesn't use </p><ul><li>React - he jokes a lot about how he never wants to learn it due to it's (perceived) complexity. </li><li>Node - for a time he considered using it but he's never used it in production</li><li>Angular/ Vue - he doesn't use any Javascript frameworks </li><li>SQL/ Postgres - he doesn't use any of the conventional databases </li></ul><h2 id="get-a-job-without-a-cs-degree-">Get a job without a CS degree 👇</h2><!--kg-card-begin: markdown--><p><a href="http://nocsok.com/"><img src="https://www.nocsdegree.com/content/images/2020/08/Screenshot-2020-08-07-at-17.35.28-2.png" alt="No-CS-OK-screenshot-1"></a></p>
<!--kg-card-end: markdown--><h2 id="what-results-has-pieter-had-with-this-approach-to-coding">What results has Pieter had with this approach to coding?</h2><p>Despite the technical critics, Pieter has been consistently making six figures since 2014. He currently makes approximately $600,000 a year which is far more than most developers. He has been able to live in countries with a low cost of living so he will likely be able to have financial independence and not need to work relatively soon. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">📈 Record sales yesterday of $2,342.04 on <a href="https://t.co/S9Qv34rpbP">https://t.co/S9Qv34rpbP</a> for no apparent reason (maybe companies are spending their EOY HR budgets?). Normal sales is like $299 or 1 post per day. <a href="https://t.co/8HukglDuiv">pic.twitter.com/8HukglDuiv</a></p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938699122445451265?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr"><a href="https://t.co/rORz8xdCQp">https://t.co/rORz8xdCQp</a> is a single PHP file called "index.php" generating $2,342.04 in a day. No frameworks. No libraries. 💖</p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938707166508154880?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><h2 id="what-is-pieter-levels-working-on-now">What is Pieter Levels working on now?</h2><p>He just released a new project, <a href="https://remoteworkers.dev/">Remote Workers</a>, where people can post their resumé. He "built in public" - that is to say he gave daily updates of his code on Twitter. This is also a great way for developers to build an audience! You can check out what people are saying about Remote Workers on <a href="https://www.producthunt.com/posts/remote-workers">Product Hunt</a>. </p><h2 id="conclusion">Conclusion</h2><p>Pieter is like a bare knuckle boxer so don't compare him to a Judo practioner going to the Olympics. One is going to win no matter what and one is going to follow the rules they have trained under and have finer technique. Neither is better or worse. It depends on the situation. </p><p>Pieter's approach would not be good if you were trying to get a job in a lot of companies. But Pieter isn't looking for a job and the proof for him is in his bank balance. So Pieter's scrappy technique is better suited if you are attracted to coding for entrepreneurship and being a solo founder who doesn't have to share their code with others to work on. He doesn't use Github to save his code, for instance and this is an industry standard that most employers expect. If you want to be an indie hacker/entrepreneur though then Pieter is a fine act to follow. </p><h3 id="if-you-enjoyed-this-article-please-send-it-to-a-friend">If you enjoyed this article please send it to a friend </h3><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="and-you-should-totally-sign-up-for-the-newsletter">And you should totally <a href="https://nocsdegree.carrd.co/">sign up for the newsletter</a> </h3>
                    </div>
                </section></div>]]>
            </description>
            <link>https://www.nocsdegree.com/pieter-levels-learn-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259201</guid>
            <pubDate>Mon, 24 Aug 2020 10:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of webpage speed, or throwing away React]]>
            </title>
            <description>
<![CDATA[
Score 351 | Comments 294 (<a href="https://news.ycombinator.com/item?id=24258855">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
  <p>Back in 2011, I happened to get a job writing <a href="https://backbonejs.org/">Backbone.js</a> app. If you never did that, don’t. I was complaining about difficulties with composition left and right to whoever would listen. As I started digging into alternatives for the front-end, I discovered <a href="https://en.wikipedia.org/wiki/Functional_reactive_programming">FRP</a> and <a href="https://www.flapjax-lang.org/">Flapjax</a>, and <a href="https://clojurescript.org/">ClojureScript</a>. The last one got me hooked on <a href="https://clojure.org/">Clojure</a>. I even did a <a href="https://fwdays.com/event/js-frameworks-day-2013/review/Functional-Reactive-Programming-&amp;-ClojureScript">successful talk</a> on FRP and ClojureScript (and precursor to <a href="https://hoplon.io/">Hoplon</a>, called hlisp).</p>
<h2 id="react">React</h2>
<p>Then in May 2013 React was released. I championed it on my new job and discovered during Clojure-themed hackaton (<a href="https://solovyov.net/blog/2013/clojurecup/">Clojure Cup 2013</a>) that CLJS and React are a great match. What’s so good about React though? To me, the main selling point is that it composes well.</p>
<p>When you use predecessors like jQuery or Backbone or Angular or whatever after just a year of development your code is a mess of event listeners and triggers. Don’t get me started on unobtrusive JS, code locality is non-existent with jQuery. Which handler is bound where and what it does? It’s too hard to discover to be a good base for a good codebase!</p>
<p>Then I started working at <a href="https://kasta.ua/">Kasta</a>, where web frontend was exactly that jQuery-ish mess. Nobody ever wanted to touch checkout, since you could spend hours, if not days, making the smallest change. Then QA would find more invalid states than you can dream of. And then users would report more bugs to our call center. It was just as awful as you can imagine.</p>
<p>So after some experiments, tests, and checks, I decided that we’re going React + ClojureScript way with server-side rendering done in Clojure.</p>
<h2 id="demise">Demise</h2>
<p>And for a while, things were looking good. We had this <a href="https://solovyov.net/blog/2017/server-side-rendering/">architecture</a> where our components are executed as Clojure on the backend, so no Node.js on the server, hurray! And developer UX is through the roof with the excellent live reload (thanks CLJS), ability to connect from your editor to browser REPL, and experiment there. It is just great!</p>
<p>To make a long story short, our frontend grew bigger and bigger. Incremental compilation started to become slower — it now routinely takes more than a second or two. And while there were few attempts on keeping the whole app performant, ultimately we failed. It’s a death by a thousand cuts. The application became too big and its boot time became too long. Server side rendering helps partially, but then hydration freezes the browser. On the older hardware or Androids it became unacceptable!</p>
<p>One of the main reasonings back in 2016 was that we take a hit on startup time, but in turn, get no page loads and have a rich web application with a lot of interactions. And for a while that worked! But startup time became longer and longer, leading to a shameful rating of 5/100 from Google’s PageSpeed (okay, it was sometimes up to ~25/100, whatever).</p>
<p>More than that, while doing what is described below, we’ve discovered that React also leads to some questionable practices. Like hovers in JS (rather than in CSS), drop-down menus in JS, not rendering hidden (under a hover) text (Google won’t be happy), weird complex logic (since it’s possible!), etc. You can have a React app without those problems, but apparently, you have to have better self-control than we had (nobody’s perfect!).</p>
<p>Also since then, the vast majority of our users switched to mobile apps. This made the web app the main entry point for new users. This means its main goal is rendering fast for a newcomer, because old-timers, which want more functionality, are on mobile app now. And <a href="https://web.dev/tti/">TTI</a> (time to interactive) is so much more important here.</p>
<h2 id="time-for-a-change">Time For A Change</h2>
<p>So given that circumstances have changed, what do we do? I read articles “how I survive on vanilla JS” since before React appeared and they usually don’t make sense — it’s either a pink-glassed rant about how great it is, disregarding all the problems (separation of concerns, cohesion, composability, code locality) or a project by one (or few) persons, who just keep everything in their head.</p>
<p>Somewhere back in February I stumbled upon <a href="https://intercoolerjs.org/">Intercooler.js</a>. I’m not sure if I ever saw it before — maybe I did but skimmed over — it does not matter. This time it captured my attention.</p>
<p>The idea is that all HTML is rendered on the server. And client updates parts of HTML, controlled by element’s attributes. Basically like HTML+XHR on steroids. You can’t do anything you want, but that’s partially the point: some limits are good so you won’t do crazy stuff. And you need some support from the server, so you can render partial results — just an optimization, but quite an important one.</p>
<p>There is an alternative library — <a href="https://unpoly.com/">Unpoly</a>. It has more features around layout and styling but has a little bit less thought out XHR stuff (hard to do a POST request with parameters without having a form, for example). And the library size is much bigger. And it’s written in CoffeeScript with lots of classes, <a href="https://solovyov.net/blog/2020/inheritance/">ugh</a>.</p>
<p>So I made a proof-of-concept implementation of our catalogue page in Intercooler and it worked! Except there was a dependency on jQuery and some other irritating stuff… As I was struggling to make a batch request for HTML fragments I understood one thing: when I wrote down a roadmap for catalogue the last point was “small intercooler-like thing for analytics”.</p>
<p>So why wait?</p>
<h2 id="twinspark">TwinSpark</h2>
<p>I liked Intercooler’s coherent approach to working around AJAX, so I decided to name the library after some automotive stuff as well, and TwinSpark seems like an appropriate name. So what’s the deal?</p>
<p><a href="https://github.com/kasta-ua/twinspark-js">TwinSpark</a> is a framework for declarative HTML enhancement: you put additional attributes on your element and TwinSpark does something with them. Like makes an AJAX call and replaces target with a response, or adds a class, or… well, see <a href="https://kasta-ua.github.io/twinspark-js/">examples</a>, shall you?</p>
<p>There are some differences with Intercooler, of course, because why would it exist? The most noticeable one is that there is no dependency on jQuery. It supports only modern browsers (not IE or Opera Mini) but drops that 88kb monster.</p>
<p>It also has:</p>
<ul>
<li>no inheritance — can’t stress that enough!</li>
<li>clear extension points for your directives</li>
<li>support for batching requests to a server</li>
<li>tighter attribute name convention (my own opinion, but <code>ic-get</code> and <code>ic-post</code> irritate me: do not make me change keys!)</li>
<li>much smaller payload (thanks to no jQuery!)</li>
<li>should be faster (thanks to no jQuery again)</li>
</ul>
<p>Honestly speaking, the main reasons are <a href="https://kasta-ua.github.io/twinspark-js/#batch">batching</a> and <a href="https://solovyov.net/blog/2020/inheritance/">no inheritance</a>. Inheritance is particularly painful here. In Intercooler, if you declared <code>ic-target</code> on the body, all tags inside will think it’s their target too. So you include a component somewhere in HTML tree and an attribute higher on tree changes this component behavior. I mean this is a freaking dynamic scope, I want none of that! :)</p>
<p>Funnily enough, after about a month of dabbling with TwinSpark, Intercooler’s author announced that he’s doing a jQuery-less modern version: <a href="https://htmx.org/">htmx</a>. :) It has really good extensions points, so maybe it’s possible to add batching… but inheritance is still there. :-(</p>
<h2 id="why-is-that-a-good-idea">Why is that a good idea</h2>
<p>We need to look at it from two sides: if it’s good for developers and if it’s good for users. React was great at former and terrible at later.</p>
<p>TwinSpark approach is much better in most cases for the user: less JavaScript, less jitter, more common HTML-like behavior. In the worst case, we would serve you 2.5MB of minified (non-gzipped) JS and 700KB of HTML (half of it were initial data for React) for catalogue. JS bundle is not that big because of embedded images or css or some other obscure stuff, it’s big because it’s the whole app, with a lot of views and logic.</p>
<p>Now it’s 40KB of minified non-gzipped JS (TwinSpark, analytics, some behavior, IntersectionObserver polyfill) and 350KB of HTML. Two orders of magnitude difference and even HTML is smaller! This is just like Christmas in childhood!</p>
<p>On the developer side, I think React is better still, but code locality is great, composability is much better (since you are forced in a limited world of working in a simplistic model) than with jQuery. Plus there are a lot of ways to improve it.</p>
<p>The good news is that the development process did not change that much! We’re still writing components that query necessary data from site-wide memory store (and make a call to API when needed), but they are executed only on the server. We effectively piggy-backend on our previous architecture, and this gives us the perfect ability to render “partial” HTML - since components do not wait for some “controller” to give them all necessary data. This is what allowed us to have both React and non-React versions to co-exist and make an A/B test without writing the markup twice.</p>
<h2 id="results">Results</h2>
<p>It took us four months since the first experiments to release. Not exactly the amount of time I imagined when we started (“should take two to three weeks at most!"), heh, but we were not exclusively doing that. It still took a lot of time and energy to remove React-isms from the code and wrangle our app to be a server-side citizen. It still could use some polishing, but we decided to release it despite that just to cut it short. And A/B test showed that we were right — especially for Android phones.</p>
<p>Google gives our catalogue 75/100 now instead of 5/100. Hurray, I guess? :)</p>

  </section></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258855</guid>
            <pubDate>Mon, 24 Aug 2020 09:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The GemRB project celebrates 20 year anniversary with a new release]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24258780">thread link</a>) | @Lightkey
<br/>
August 24, 2020 | https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html | <a href="https://web.archive.org/web/*/https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p>The GemRB team announces the availability of GemRB 0.8.7, a new minor release to kick off
a week of celebrations of the project’s founding anniversary. 20 years ago, on the 21st of
August, the project initiator Daniele Colantoni registered it on SourceForge to try to make
it a team effort. Many things have happened since, the path was convoluted and bumpy, but
GemRB has continued to grow throughout the years.</p>

<p>GemRB is a portable free/libre open-source implementation of Bioware’s Infinity Engine, which
powered classic CRPGs like Baldur’s Gate, Icewind Dale and Planescape: Torment. The goal of
the project is to make these games available on a wide range of platforms forever, fix or avoid
old bugs, add new features and provide a superb platform for mod (and eventually game) development.</p>

<p>It was started 20 years ago by a student fresh out of town, Daniele Colantoni:
<em>“I missed playing D&amp;D with my friends so much /…/ I wanted to create my game to play
via internet. So I started my personal reverse engineering process on the base files
from Baldur’s Gate.”</em></p>

<p>Predictably it turned out to be much more complicated and time consuming than first
imagined, but the effort continued. From its Windows-only 32-bit beginnings GemRB was
made to run on all common and many niche platforms (from AmigaOS to IRIX and Symbian;
x86 to PPC, ARM, MIPS and WebAssembly). This was largely made possible through use
of open source libraries that are themselves very portable (SDL, OpenAL, libpython, zlib).
Without an open development model and supporting infrastructure, the project would have
never succeeded.</p>

<figure>
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2-kuldahar-gem.jpg" title="IWD2 remains to be fully understood">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2-kuldahar-gem.jpg" alt="IWD2 GemRB battle screenshot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/10pp6.jpg" title="Larger player parties is one of the most popular features">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/10pp6.jpg" alt="10pp6.jpg">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2stylecombat2.jpg" title="IWD2-style combat output">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2stylecombat2.jpg" alt="IWD2-style combat output">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/goi.jpg" title="Glory of Istar game shot">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/goi.jpg" alt="Glory of Istar game shot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/sorcerer_monk.jpg" title="Sorcerer/monk multiclass">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/sorcerer_monk.jpg" alt="Sorcerer/monk multiclass">
      </a>
    
  
    
      <a href="https://lynxlynx.info/bugs/mushroom.madness.jpg" title="Sometimes things go hilariously wrong ...">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/fonts.png" alt="Sometimes things just go wrong ...">
      </a>
    
  
  
    <figcaption>Various screenshots.
</figcaption>
  
</figure>

<p>The engine can be used to play the full Baldur’s Gate saga, the first Icewind Dale and
Planescape: Torment. The latter requires more reverse engineering and polishing, but
one can finish the game already. Icewind Dale 2 is a different matter — while it
appears more polished than Torment, only the first two chapters of the game are
playable.</p>

<p>As GemRB marks its 20th anniversary, Jaka Kranjc, the current maintainer, is optimistic about
the project’s future. <em>“Our work is not finished, but this sort of thing is like an
ultramarathon — for most of the run the goal is not within reach. Companies come and go, but
FLOSS persists!”</em></p>

<p>The <a href="https://gemrb.org/2020/08/24/gemrb-0-8-7-released.html">new release</a>
brings over 500 changes manifested as bugfixes, smaller features, cleanups
and an improved setup experience. More than that, it introduces a new <a href="https://gemrb.org/2020/07/16/new-pathfinder-smarter-movement.html">smarter
pathfinder</a> with
bumping support and other movement related improvements. At the same time work continued
on the drawing and GUI handling rewrite — stay tuned for a deeper dive later this week.
With this anniversary release out of the way, finishing that rewrite is again the team’s
main priority.</p>

<p>Overall it’s clear that after all this time the GemRB effort is still active, slowly building
missing pieces of the Infinity Engine mosaic, revitalising older code, extending features and
working throughout the project to keep the effort vibrant for years to come. The team is
looking for <a href="https://github.com/gemrb/gemrb/blob/master/CONTRIBUTING.md">new contributors</a>,
especially programmers with OpenGL experience, who could help them finish a drawing backend
refactoring — for better performance and to remain available on a wide berth of platforms.</p>

<p>A pearl to you!</p>

<p><em>PS: check our news section in the following days for a daily retrospective with past maintainers and a look into the project’s future.</em></p>

<hr>
<p>Project links:</p>
<ul>
  <li>Web site: <a href="https://gemrb.org/">https://gemrb.org</a></li>
  <li>Downloads: <a href="https://gemrb.org/Install">https://gemrb.org/Install</a></li>
  <li>News: <a href="https://gemrb.org/News">https://gemrb.org/News</a> (RSS available)</li>
  <li>Screenshots: <a href="https://gemrb.org/Media">https://gemrb.org/Media</a></li>
</ul>

<p>If you want to be notified of further releases, subscribe to
<a href="https://sourceforge.net/projects/gemrb/lists/gemrb-release">gemrb-release</a> (low volume).</p>

<p>If you <em>need</em> to get in touch via email, write to &lt;registracije+gemrb20@lynxlynx.info&gt;.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258780</guid>
            <pubDate>Mon, 24 Aug 2020 09:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing Teams Through Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24258519">thread link</a>) | @jstanier
<br/>
August 24, 2020 | https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/ | <a href="https://web.archive.org/web/*/https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary" role="main">
		
<article id="post-1410">

			<!-- end .entry-header -->

		<div>
		
		<div>
			
<p><em>This article is part of a </em><a href="https://www.theengineeringmanager.com/managing-managers/"><em>series on managing managers</em></a><em>.</em></p>



<p>Making the switch to managing managers, and hence managing many teams, can be taxing on the brain. If you’ve not done it before, then you may look at others in more senior roles, potentially running organizations of hundreds of people, and wonder to yourself how they ever find any clock time or mental time for getting anything done.</p>



<p>If you’re used to running one team, that’s a reasonable thought to have. After all, running a team is a tough job. It involves balancing your time between managing others and making your own contributions, working with people outside of your team, deeply understanding the personalities and desires of your staff, and, of course, let’s not forget the most important thing: shipping software.</p>



<p>When viewed through this lens, the thought of having multiple teams may seem quite overwhelming. How are you meant to carry everything in your head that you did before, but at many times the scale? Well, the answer is that you <em>shouldn’t have to</em>. That’s exactly why you have managers reporting to you, which allows you to work at a higher level of abstraction.</p>



<p>Working at this higher level of abstraction allows you to focus your efforts on what’s important; whether that importance manifests in the <a href="https://www.theengineeringmanager.com/managing-managers/vp-director-what/">operational running of work streams or strategic planning for the future</a>. It allows you to step back and to focus your energy where it pays the greatest dividends: the outputs of tens, if not hundreds, of people.</p>



<p>Since those that read this website typically have a background in writing software, I’ll lean on a software engineering analogy in order to explain how you use your managers to work at this higher level of abstraction. We’re going to be looking at the interface between yourself and your managers by looking at, erm, <strong>interfaces</strong>. How handy.</p>



<h2>Interfaces</h2>



<p>The programming language that I have the most experience in is Java, so I’m going to lean on it for this particular analogy. An interface in Java, like in other languages, is a type that allows you to define abstract methods that other classes must have if they implement that interface.&nbsp;</p>



<p>So, for example, you may define an interface for a CurseGenerator:</p>



<pre><code>interface CurseGenerator {
  public String curse();
}</code></pre>



<p>Of which we could then implement a British version:</p>



<pre><code>public class BritishCurseGenerator implements CurseGenerator {
  public String curse() {
    return “Oh, bloody hell!”;
  }
}</code></pre>



<p>An interface allows extensibility in software systems because a particular piece of code can work with any class that implements a given interface, since the interface’s methods are checked to be present in the implementing class at compilation time.&nbsp;</p>



<p>Most importantly,&nbsp;the code that works with an interface <em>does not need to know the details of the implementation</em>.<em> </em>The implementing class can do whatever it wants as long as it abides by the contract of the method signatures. The interface <em>delegates </em>the implementation to the implementing class. </p>



<p>Do you see where this is going? I’m sure you do. Back to the management analogy:</p>



<ul><li><strong>As a manager of managers, you define what the interface that represents each of your teams looks like.</strong> For example, you may define particular measurements that are important, such as KPIs like application uptime, daily active users, and so on. You may also require that your managers hold weekly one to ones with each of their staff, write a report on progress to the rest of the company every two weeks, or to fix critical priority bugs in one business day.</li><li><strong>Each of your managers has the flexibility of deciding exactly how those teams are run, as long as they follow the interface contract.</strong> So the way in which they decide to tackle improving the uptime percentage or the number of daily active users is entirely up to them. Which member staff works on which part of the codebase is down to them and the team. How and when they schedule their one-to-ones and the content that they discuss is for them to decide. But fundamentally, they should be done to abide by the contract of the interface.</li></ul>



<p>Clear interfaces allow you to not have to worry about the exact implementation details of how each of your managers run their teams, but they allow you to make it clear <em>exactly what you expect of each of them in doing so, and therefore how you define success</em>. OK, I’ll stop the programming analogy now.</p>



<h2>Defining the interface</h2>



<p>So you start by defining that interface with each of your managers. There’s a neat exercise for your first one-to-one meetings (although you can do it at any time) called <a href="https://www.theengineeringmanager.com/management-101/contracting/">Contracting, that I’ve written about before</a>. You can expand on that Contracting exercise by having you both think about the answers to the following questions, which make up the interface:</p>



<ul><li><strong>What success looks like for the team.</strong> What measurements are being used to prove that the team is being successful? Is it working towards an outcome, or some KPI, or shipping particular projects on time? Does it also take into account the happiness, productiveness and psychological security of their staff? How will this information be gathered and made accessible to you?</li><li><strong>Which processes will be used to run the team.</strong> In order to be successful, how are they going to compose themselves? Will they use scrum, kanban, just get on with it, or something else? How do they intend to ship to production regularly? How will they prioritize and execute on their work? Each team of yours may operate differently depending on the skills and seniority of the people on each.</li><li><strong>How the manager interfaces with each of their own staff.</strong> They’ll need to think about the different personalities, skills and career development trajectories for each of their staff and consider what that means for how each of them can operate with autonomy, mastery and purpose. What is an acceptable cadence for one-to-ones? Do they prefer synchronous or asynchronous communication?&nbsp;</li><li><strong>How will you know if something is going wrong? </strong>Code throws errors or performs slowly, bringing problems to your attention. How will issues with the team be made visible so you can work on them together?</li><li><strong>Whether you’d occasionally like to inspect the implementation yourself.</strong> Although defining an interface is meant to hide the complexity from you, occasionally it’s interesting to look under the hood and see what’s going on there. You might have some suggestions to make it better, or you may even learn something new. You can arrange a cadence for skip-level meetings, occasionally pop-up in their group meetings to listen, and get feedback from the individuals and the team as a whole.</li></ul>



<p>With a little work up front on the interface, you can make it absolutely clear at what level of involvement you both feel comfortable with having in your relationship. This allows you to abstract away from issues you don’t need to know about as a manager of managers, and gives your direct report the freedom to run the team how they want, as long as the fundamentals that you expect are being implemented. And that’s great, because you can build a great coaching relationship from that foundation, rather than being at risk of micromanaging or firing and forgetting.</p>



<h2>Debugging problems</h2>



<p>Occasionally things will go wrong, as they do in code. You may need to get the debugger out to see what’s going on. But that’s OK, since you’ve already discussed the interface between you, your direct report, and their team. That interface gives you a number of methods to attach your debugger to.</p>



<p>Perhaps if the team’s cadence is slowing down, you can dig deeper into the processes that are being used to run the team. How often are they shipping? If that’s not very often, why is that? How does code get written, reviewed and deployed? You can keep <a href="https://www.theengineeringmanager.com/growth/first-principles-and-asking-why/">asking why</a> in order to get to the bottom of quirks that might be bugs. And then you can fix them together.</p>



<p>Sometimes it’s interesting to attach the debugger out of pure curiosity. You can do this in your one-to-ones with your direct report. Focus on one area of your interface and go deep into the implementation by asking questions. You’ll always find something worth discussing, and often there’s some neat performance optimizations to try out.</p>



<h2>Beginning with the end in mind</h2>



<p>So why have interfaces?&nbsp;</p>



<p>The ideal end state is that you have clear expectations and boundaries between yourself and the managers that are reporting into you. When you’ve made it clear which high-level functions that each of your managers should be performing, you can delegate the implementation to them so they can do so in whichever way they feel is best for them and their team.</p>



<p>This allows you to move away from details that you don’t need to spend your time focussing on, enabling you to work at a higher level of abstraction. If you were programming, this abstraction would allow you to concentrate on making the system surrounding the interface more efficient, extensible, performant and elegant. That’s exactly what you’ll be wanting to do with the organization, structure and strategic direction of teams as well.</p>



<p><a href="http://eepurl.com/cSMExr">You can sign up to my mailing list to hear when new posts are published.</a></p>
					</div><!-- end .entry-content -->

			</div><!-- end .entry-wrap -->

</article><!-- end .post-1410 -->
	<!-- #comments .comments-area -->
	</div></div>]]>
            </description>
            <link>https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258519</guid>
            <pubDate>Mon, 24 Aug 2020 08:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apparatus with Magnets]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24258396">thread link</a>) | @jiriro
<br/>
August 24, 2020 | https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e | <a href="https://web.archive.org/web/*/https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258396</guid>
            <pubDate>Mon, 24 Aug 2020 07:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM 5160]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24258010">thread link</a>) | @hwdegroot
<br/>
August 23, 2020 | https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/ | <a href="https://web.archive.org/web/*/https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <div>
            <blockquote>
<p>640 Kilobytes!!!!1!!1 I shit you not. That is like 10 times the size of Donald Trump’s brain.</p>
</blockquote>
<p>Recently I was trying to get my son enthousiastic for programming. He is currently 7 years old and getting interested in all kinds of electronics,
so I thought that getting acquainted with programming would not hurt him. And I like to think of myself as a parent that stimulates his kids, so I used that
as an excuse to look into older computers, because <em>nostalgics</em>.</p>
<p><a href="#show-me-the-pics">Show me them footage</a></p>
<p>My kids grew up with LED monitors and TV’s and never really saw a real cathode tube, except on the episodes of <a href="https://en.wikipedia.org/wiki/Pat_%26_Mat">Pat &amp; Mat</a>.
I still remember the soft fading sound of of the tv turning off and the graphics vanishing into this thin line.</p>



<figure id="6fe72747c83aa07dbdebd9927f00a3d7">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/mesmerizing-shutdown.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Mesmerizing shutdown. The terminal vanishes into a line.

        </small>
    </figcaption>
    
    </p>
</figure>


<p>Besides that, I am a fan of clicky keyboards. I have a <a href="https://www.daskeyboard.com/daskeyboard-4C-ultimate/">DasKeyboard 4C ultimate</a> tenkeyless with Cherry Blue switches and a <a href="https://www.daskeyboard.com/daskeyboard-4C-tenkeyless-professional/">4C Profressional</a> with brown switches. Sitting at home during the
corona period, made me google old skool stuff a lot.</p>
<p>So first I laid my eyes on a <a href="https://clickykeyboards.com/product/ibm-model-m2-1395300-made-by-ibm-06-30-1993/">IBM Model M2</a> and got this pretty cheap on
the dutch eBay. Getting this to work on my modern laptop was not rocket science, but not straight forward either. I warned my collegues
that the quiet days at the office were over. But this also opened up a window into vintage computers and computing. What if I could get a vintage computer, I thought. How awesome would that be?</p>
<p>How cool would it be to program a vintage computer with my collegues, or my kids. With all the speed we get nowadays, who still thinks about the limits of computing power. This will be totally different if you have just a fraction of the memory and chip available.</p>
<h2 id="ibm-5160">IBM 5160</h2>
<p>I am from 1983. So I was looking for a computer from that year. IBM was <em>the company</em> in those days for personal computing and when it came to makeing PC’s (I am NOT an apple fan). So I found that IBM produced the <a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer_XT"><strong>IBM PC XT</strong></a> in that year. I also found out that you could still get them online for a reasonable price.
Luckliy I was able to lay my hands on one, in a pretty good state. It came with an <a href="https://clickykeyboards.com/product-category/1986-1989-ibm-model-m-silver-label/">IBM Model M</a> keyboard with the silver label (the PC is from 1986). The sound of that is even better than than the <code>Model M2</code>.</p>


<figure id="c1eacc927bc26694d18237b77c9b6c5e">
    <p><audio controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/audio/IBM-model-m-oh-that-clicky-sound.mp3" type="audio/mpeg">
            Your browser does not support the audio tag.
        </audio>
    </p>
    
    <figcaption>
        <small>
            
Need I say more...

        </small>
    </figcaption>
    
</figure>


<p>After introducing my kids to th <code>DIR</code> command (it was the only one I was pretty sure about it would work), they wanted to type “words” on the old computer (first success).</p>
<h2 id="exiting-vim-is-hard">Exiting Vim is hard?</h2>
<p>So, I know the <code>DIR</code> command. But now what. Let’s see what commands are available.</p>
<ul>
<li>No tab completion. <code>TAB</code> just places the cursor somewhere down the line</li>
<li>No <code>HISTORY</code>. You can repeat the last command by pressing the right-arrow.</li>
</ul>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>This is incorrect. You say that you have IBM PC DOS 5. If so, this includes the DOSKEY command. This will give you a command-line history with editing. Just type <code>dos\doskey</code> to load it.</p>
</blockquote>
<p>For a starters, on <code>IBM DOS</code> (version 5.0) there is no <code>$PATH</code>. The executables are located in <code>C:\DOS</code> (or <code>c:\dos</code>, because <code>DOS</code> don’t care about casing). the most executables are located. After a day or two I figured this out, so I finally managed to open my first <code>BASIC</code> program. All fine, until I wanted to quit the program. It’s not that easy as <a href="https://stackoverflow.com/questions/11828270/how-do-i-exit-the-vim-editor">exiting <code>Vim</code></a>. It took me quite some time googling, until I finally found this <a href="https://stackoverflow.com/questions/44253055/how-can-i-exit-microsoft-gw-basic-ibm-basica-or-other-similar-old-dialects-of">lifesaver</a>.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>There certainly should be! DOS has 2 configuration files, which live in the root directory of the boot drive (A: or C:). They are called [1] CONFIG.SYS and [2] AUTOEXEC.BAT. In the 2nd, there should be a line:
<code>PATH=C:\DOS; C:\</code></p>
</blockquote>








<figure id="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen_hu03af1e9e4264eec2575cd1ba06f1e20e_255454_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Entering BASIC is peanuts

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><span id="close-1fadd62c83243e573af5941d4eb32c02">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic_hu7173749eb1353b22f37803cfee1222d6_251610_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Stuck in BASIC

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><span id="close-0e171f24d2705fcfc1f3dddef5ea66e3">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic.jpg" width="4032" height="3024"></p>
    </div>
</div>





<figure id="34bf581ec5de30d29fb4a52465d157a0">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/trying-stuff-in-qbasic.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    
    
    <figcaption>
        <small>
            
Trying to exit QBASIC. Epic fail

        </small>
    </figcaption>
    
    </p>
</figure>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>That is <em>not</em> <code>QBASIC</code>; <code>QBASIC</code> has a GUI. You were in either <code>BASICA</code> or <code>GWBASIC</code>. The command to quit is <code>syst em</code>, if I remember correctly after 30 years.</p>
</blockquote>
<p>So, now I can start a few commands, but getting all available commands is not that straight forward. There is a lot in the <code>DOS</code> directory, but there is no scrolling, and the monitor only is 25 lines.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>Yes there is [scrolling]. Type <code>dir /p</code> for page-by-page. <code>dir /w</code> gives a wide listing. You can combine these: <code>dir /w /p</code>. You can also do <code>dir | more</code></p>
</blockquote>
<blockquote>
<p>[the monitor is only 25 lines] This depends on the graphics card. If you have an MDA card, no, 25 lines is all. Try <code>mode con: lines=43</code> or <code>mode con: lines=50</code>. This will only work on a VGA-compatible card, though, and you will need ANSI.SYS installed, I think.</p>
</blockquote>
<p>So figuring out the available commands is using a lot of <code>DIR *.EXE</code>'s and <code>DIR *.COM</code>'s.</p>
<p>First class fun.</p>
<h2 id="show-me-the-pics">Show me the pics</h2>
<p>Not so long ago I was explaining my collegue (who is using a screensaver), <a href="https://en.wikipedia.org/wiki/Screensaver">where a screensaver got its name from</a>. Back in the days, when we were all running the <a href="https://www.youtube.com/watch?v=Uzx9ArZ7MUU">pipes</a> so the screen would not <span>fuck up</span>
.</p>
<p>But now, sit back and relax…</p>



<figure id="f3b027a374567777bfd8178001360334">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/insane-refresh-rate-oldskool-monitor.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Check this insane refresh rate of the cathode tube. The color of the terminal is magnificent! 😍

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="4cdf95e55b8fbd6e1c5e3ea1f0bd43bf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/more-refresh-rate.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
And more refresh rate. The mesmerizing fading away of the fonts into the background. Beautiful, just beautiful

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="6f82255ebe285b0963065fc046514bcf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 The startup is amazing as well. The sound of the fan, and the nostalgic beep.

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="43c3937b62bdb5325a2b1a8a57bc530d">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos-again.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 One more time. I could loop this forever.

        </small>
    </figcaption>
    
    </p>
</figure>










<figure id="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch_hu3a6de3285dc77b6df0e675474f4c7576_447189_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
un DOS tres. The fluorescence is soooo pretty.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><span id="close-01da5907dc0ec7a58dc42ca82d974286">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file_hu5af41f7c240e39ab901ff694320d0a39_288464_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
wppreview, I totally miss the point of this program. But, hey, it's there.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><span id="close-69f512f8bcce7a3b38b62b31e321231a">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file.jpg" width="4032" height="3024"></p>
    </div>
</div>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It [wppreview] is not part of DOS. Sounds like a WordPerfect preview program for use with mailmerge.</p>
</blockquote>
<h2 id="what-next">What next?</h2>
<p>So far I had to explain to my son what a <code>file(name)</code> and a <code>command</code> is (when they were typing “words” the IBM kept returning</p>
<p>So the experience is already educational :)</p>
<p>To be honest, I do not have a clear idea what I am going to do with it next. I will be playing with it for a while like an 8 year old with his trains.
After the <a href="https://twitter.com/hashtag/stayathome"><code>#stayathome</code></a> is over, hopefully I can take it to the office, so we can start doing real cool things with it.</p>
<p>I will definitely have to up my <a href="https://www.qb64.org/wiki/GOTO"><code>GOTO</code></a> skills :)</p>
<p>I will start using my Model M2 for work (sorry collegues), for sure. I will have to remap my function key in <a href="https://i3wm.org/"><code>i3</code></a>, because I am currently using the
windows key for this. But the Model M2 does not have one. But I will overcome.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It is easy to remap CapsLock to be a “Windows” (Super) key. This is how I use my IBM Model M in Linux. I suggest <code>xmodmap</code>.</p>
</blockquote>
<p>Besides that, I found this great archive with <a href="ihttps://archive.org/search.php?query=dos%20ibm">manuals</a> and <a href="http://www.retroarchive.org/dos/disks/">bootdisks</a> and even <a href="https://winworldpc.com/download/40c2a543-4218-c39a-11c3-a4e284a2c3a5">PC DOS 5.02</a>. Currently I am trying to get a VM up running PC DOS 5.0 (yes, that is possible in <a href="https://www.youtube.com/watch?v=xfjUkJMe_kw">virtualbox</a>)</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>If you are willing to change the DOS version, I suggest DR DOS 3.41. The reason is this: MS/PC DOS 5, 6 &amp; later are designed for 386 memory management. This is impossible on an 8088 chip, and as a result, you will have very little free memory. Many DOS programs won’t work.</p>
</blockquote>
<blockquote>
<p>DR-DOS is a better 3rd party clone of DOS, by the company that wrote the original OS (CP/M) that MS-DOS was ripped-off from. The first version is 3.41 (before that it had different names) and it is far more memory-efficient. <a href="https://winworldpc.com/product/dr-dos/3x">https://winworldpc.com/product/dr-dos/3x</a></p>
</blockquote>
<blockquote>
<p>But if you want to stay with an IBM original DOS, then IBM developed PC DOS all the way to version 7.1, which supports EIDE hard disks over 8GB, FAT32 and some other nice features. It is a free download.</p>
</blockquote>
<blockquote>
<p>I have described how to get it here: <a href="https://liam-on-linux.livejournal.com/59703.html">https://liam-on-linux.livejournal.com/59703.html</a></p>
</blockquote>
<blockquote>
<p>PC DOS 7 is a bit strange; IBM removed Microsoft’s GUI editor and replaced it with an OS/2-derived one called E, which has a weird UI. IBM also removed GWBASIC and replaced it with the Rexx scripting language.</p>
</blockquote>
<blockquote>
<p>Personally, I combine bits of PC-DOS 7.1 with Microsoft’s editor, Microsoft’s diagnostics, Scandisk disk-repair tool and some other bits, but that is more than I can cover in a comment!</p>
</blockquote>
<blockquote>
<p>There is a lot you can do to upgrade a 5160 if you wish. Here is a crazy example: <a href="https://sites.google.com/site/misterzeropage/">https://sites.google.com/site/misterzeropage/</a></p>
</blockquote>
<blockquote>
<p>I would not go that far, but a VGA card, VGA CRT, a serial mouse and an XTIDE card with a CF card in it, and it would be a lot easier to use…</p>
</blockquote>
<p>The downside, my Cherry MX blue switches feel like second class now.</p>
<h2 id="update">UPDATE</h2>
<p>When I was installing my VM with <code>PC DOS</code>, at the end of the installation I was aske if I wanted to start in <code>shell</code> mode. It turns out there is a command <code>DOSSHELL</code> (needs to be executed fron <code>C:\DOS</code>) which gives you a very fancy
gui.</p>








<figure id="8a76cf6b5c012a99a1bf166c516671c4">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/dosshell_hu8b1374a2b83ba8d4970af29e66446ddf_361223_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
😱 It …</small></figcaption></div></figure></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</a></em></p>]]>
            </description>
            <link>https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258010</guid>
            <pubDate>Mon, 24 Aug 2020 06:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GCD and the magic of subtraction]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24257871">thread link</a>) | @plumsempy
<br/>
August 23, 2020 | https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/ | <a href="https://web.archive.org/web/*/https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1295">

	

	
			<figure>
				<img width="1229" height="727" src="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1229" alt="" loading="lazy" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png 1229w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1024 1024w" sizes="(max-width: 1229px) 100vw, 1229px" data-attachment-id="1315" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-4/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png" data-orig-size="1229,727" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 4" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>The greatest common divisor is something I learned in school but it was one of those “so what?” subjects. But recently I revisited it and it is very interesting.</p>



<p><strong>Why is gcd cool?</strong></p>



<p>Every number, can be expressed as the product of prime numbers. This product for every number is unique; sort of like saying, every number has a fingerprint. This is called the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">fundamental theorem of arithmetic</a>. 36 is <code>4x9</code>, and 45 is <code>5x9</code>. This means that some numbers will have common parts with each other.</p>



<p>These common parts can divide both numbers, and thus they are common divisors. In the example above, 36 is <code>4x9</code> or <code>2x2x3x3</code>, while 45 is <code>5x3x3</code>; 3 is a common divisor of both, so is <code>3x3</code>, which is 9; but 9 is the greatest divisor of both 36 and 45.</p>



<p>One question I had when I was younger, was why we are talking about the “greatest” and not the smallest common divisor. We could, but soon, this gets boring: there is 1, the smallest common divisor of every number, then there are some common divisors in between 1 and the gcd. But what the gcd does so uniquely, is that it takes two numbers and gives us <em>all</em> the common parts of two numbers. </p>



<figure><img data-attachment-id="1328" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-1-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png" data-orig-size="1150,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 1" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png 1150w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>common and uncommon parts of 36(4×9) and 45(5×9). The gcd of 36 and 45 is 9.</figcaption></figure>



<p>This is cool! The uncommon parts are relatively prime! — meaning, they have nothing in common but the number 1. </p>



<p>So to find the gcd, then, we need to find all the common parts of the two numbers when written in terms of their prime factors. </p>



<p><code>36=3x3x2x2</code> and <code>45=3x3x5</code>, thus the gcd of 36 and 45 is <code>3x3</code>, which is 9. So 36 is 9(4) and 45 is 9(5). It is very interesting to look at numbers as multiples of gcds. Moreover, notice that these multipliers, 4 and 5 in the example above, are relatively prime. </p>



<p><strong>The magic of subtraction</strong></p>



<p>Subtracting two relatively prime numbers, will produce another number that, while not necessarily prime itself, will be relatively prime to both the previous numbers. As an example, <code>13-7=6</code>. 6 is not prime, but it is relatively prime to both 7 and 13. If we subtract 6 from 13 we will get 7 again which is not very interesting. But if we subtract 6 from 7, the smaller one, since 6 and 7 are relatively prime we should get another number that is relatively prime to them both; <code>7-6=1</code>, which is relatively prime to every other number, if keep doing this:</p>


<pre title="">13 -  7 = 6
7  -  6 = 1
6  -  1 = 5
5  -  1 = 4
4  -  1 = 3
3  -  1 = 2
2  -  1 = 1
1  -  1 = 0

(1, 0)
</pre>


<p>The final two numbers are 0 and 1. So whenever we start with two relatively prime numbers and do this on them, it will always end with 0 and 1. This is pretty strange and magical. I am still perplexed by it, but the way I convinced myself, is to think about it bottom up: if we start with the number 1, and try to build our way to any other number by addition, there are finite number of ways. So when we start subtracting, what we are doing is walking that path backwards towards 1. </p>



<figure><img data-attachment-id="1319" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png" data-orig-size="1226,634" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 3" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>There is a limited set of paths from any two numbers back to 1 by successive subtractions.</figcaption></figure>



<p>Now why do these two numbers need to be relatively prime? because if they are not relatively prime, that means that they have some parts in common, like 36 and 45 above, remember? they are 9(4) and 9(5). If we do the subtracting trick on them:</p>


<pre title="">9(5) - 9(4) = 9(1)
9(4) - 9(1) = 9(3)
9(3) - 9(1) = 9(2)
9(2) - 9(1) = 9(1)
9(1) - 9(1) = 9(0)

(9(1), 0)
</pre>


<p>So you see, the common part survives the subtractions, while the uncommon parts converge to 1. But 9 is <em>all</em> the common parts of 36 and 45, in other words the gcd of 36 and 45! </p>



<p>Can we keep subtracting any two numbers until we reach (X, 0) and then proclaim X is the greatest common divisor? yes, we can, and it is called the <em><a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclidean Algorithm</a></em>.</p>



<p>Here is a silly experiment, what if we subtract the partially common parts? for 36 and 45, what if we wrote them as 3(12) and 3(15)?</p>


<pre title="">3(15) -  3(12) = 3(3)
3(12) -  3(3)  = 3(9)
3(9)  -  3(3)  = 3(6)
3(6)  -  3(3)  = 3(3)
3(3)  -  3(3)  = 3(0)

(3(3), 0)
</pre>


<p>This is really funny. The algorithm basically told us that the gcd of 12 and 15 is 3. Now if we choose to multiply the other 3 that we have factored out before we started our subtraction, it will yield the same result: the gcd of 36 and 45 is 9.</p>



<p><strong>What just happened?</strong></p>



<p>We started by finding the gcd of two numbers, then subtracting the uncommon, relatively prime parts to realize we always reach 1, so if we always subtract any two numbers from each other repeatedly, since the gcd is a common factor of both, it will remain constant until the end, when the uncommon parts have reduced down to 1 and 0; and then what we are left with is the gcd. </p>



<p>Here is a recursive implementation of it in Python:</p>


<pre title="">def gcd(a,b):
    if a == 0: return b
    if b == 0: return a

    return gcd(abs(a-b), min(a,b))
</pre>


<p>If someone has a better explanation of why subtracting relatively prime numbers repeatedly will always result in one, please leave a comment or reach out and help me understand better.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257871</guid>
            <pubDate>Mon, 24 Aug 2020 05:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Tcl 8.7 Part 11: The ZIP virtual file system]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24257855">thread link</a>) | @systems
<br/>
August 23, 2020 | https://www.magicsplat.com/blog/tcl87-zipfs/ | <a href="https://web.archive.org/web/*/https://www.magicsplat.com/blog/tcl87-zipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <header>
                        
                        <p>
                            Published <time datetime="2020-08-23+0000">2020-08-23</time>
                        </p>
                    </header>
                    <p>
                        This is the eleventh in a series of <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">posts</a> about new features in the upcoming version 8.7 of Tcl. It is the first of a pair of posts describing core support for treating ZIP archives as virtual file systems within Tcl. This post focuses on base operations dealing with existing ZIP archives. The next describes the creation of ZIP archives and their use for building <em>zipkits</em> and single file executables.
                    </p><!-- more -->
                    <blockquote>
                        <p>
                            To take Tcl 8.7 for a spin, you can download the <a href="https://sourceforge.net/projects/tcl/files/Tcl/8.7a3/">source</a> distribution. Binary distributions for Windows are available from <a href="https://sourceforge.net/projects/magicsplat/files/barebones-tcl/">magicsplat</a> and <a href="http://www.bawt.tcl3d.org/download.html#tclbi">BAWT</a>.
                        </p>
                    </blockquote>
                    <p>
                        With Tcl 8.6, access to files in ZIP archives was already possible. Tcl itself offered the ability to compress and decompress data with the <code>zlib</code> command. The <code>zipfile</code> module in <code>tcllib</code> then made use of these to permit access to files within an archive.
                    </p>
                    <p>
                        Tcl 8.7 goes beyond these capabilities by treating ZIP archives as mountable <em>virtual file systems</em> (VFS). This makes access to the files within the archive much simpler through the standard Tcl channel commands <code>open</code>, <code>gets</code> etc.
                    </p>
                    <h2>
                        Mounting ZIP archives
                    </h2>
                    <p>
                        The first step to accessing ZIP archives is to mount them as a Tcl VFS. This is done with the <code>zipfs mount</code> command.
                    </p>
                    <pre><code>% zipfs mount mnt demo.zip</code></pre>
                    <p>
                        This results in the archive <code>demo.zip</code> being mounted as a VFS under the path <code>zipfs:/mnt</code>.
                    </p>
                    <p>
                        The root of all ZIP file systems is given by the <code>zipfs root</code> command.
                    </p>
                    <pre><code>% zipfs root
zipfs:/</code></pre>
                    <p>
                        This root is platform-specific, <code>zipfs:/</code> on Windows and <code>//zipfs:/</code> on Unix(y) systems.
                    </p>
                    <p>
                        Naturally, you can mount multiple archives or even the same archive multiple times. The mount points of course have to be different but one can be nested inside another. For example,
                    </p>
                    <pre><code>% zipfs mount mnt2 demo.zip
% zipfs mount mnt/nested demo2.zip</code></pre>
                    <p>
                        Invoking <code>zipfs mount</code> without any arguments will return the currently mounted ZIP archives as a flat list of mount points and the archive file path.
                    </p>
                    <pre><code>% zipfs mount
zipfs:/mnt demo.zip zipfs:/mnt/nested demo2.zip zipfs:/mnt2 demo.zip</code></pre>
                    <p>
                        ZIP archives may be protected with a password. In that case the password must be supplied as the last argument to the command.
                    </p>
                    <p>
                        When no longer needed the each VFS should be unmounted with <code>zipfs unmount</code>.
                    </p>
                    <pre><code>% zipfs unmount mnt2
% zipfs unmount mnt/nested
% zipfs mount
zipfs:/mnt demo.zip</code></pre>
                    <h2>
                        Introspecting archives
                    </h2>
                    <p>
                        Once mounted, the archives can be introspected.
                    </p>
                    <p>
                        The <code>zipfs list</code> command returns a list of the files in the ZIP file system. Optionally, regular expression or glob wildcard patterns may be specified to filter the returned paths.
                    </p>
                    <pre><code>% zipfs list
zipfs:/mnt/demo zipfs:/mnt zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/subdir zipfs:/mnt/demo/demo.txt
% zipfs list *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -glob *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -regexp {\.txt$}
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt</code></pre>
                    <p>
                        Notice there is no mount point specified above. The command lists all files and directories under the ZIP VFS root. To restrict to a specific archive, specify it as a pattern.
                    </p>
                    <p>
                        A similar command returns a list of all file paths under a specific directory.
                    </p>
                    <pre><code>% zipfs find zipfs:/mnt/demo/subdir
zipfs:/mnt/demo/subdir/file.txt</code></pre>
                    <p>
                        <strong>TIP:</strong> The <code>zipfs find</code> command will work with any file system, not just ZIP VFS'es.
                    </p>
                    <p>
                        Since the ZIP archive is mounted as a Tcl VFS, standard Tcl commands for retrieving generic file information can be used. For example,
                    </p>
                    <pre><code>% file size zipfs:/mnt/demo/demo.txt
12
% clock format [file atime zipfs:/mnt/demo/demo.txt]
Sun Aug 23 12:33:24 IST 2020</code></pre>
                    <p>
                        The <code>zipfs info</code> command returns additional information that is specific to the ZIP archive format.
                    </p>
                    <pre><code>% zipfs info zipfs:/mnt/demo/demo.txt
demo.zip 12 14 50</code></pre>
                    <p>
                        The returned list contains the name of the ZIP archive (as originally passed), the original file size, the compressed file size and the offset of the file's compressed data within the ZIP archive. (As an aside, note in our example that the "compressed" size is greater than the actual size as often happens for small files.)
                    </p>
                    
                    <p>
                        Data transfer from compressed files in the archive is achieved through the standard Tcl channel I/O commands.
                    </p>
                    <pre><code>% set chan [open zipfs:/mnt/demo/demo.txt]
zipfs_32_1
% gets $chan
Demo file 
% close $chan</code></pre>
                    <p>
                        You can also open the file for writing. However, the ZIP VFS does not support the append mode.
                    </p>
                    <h2>
                        Coming up
                    </h2>
                    <p>
                        Having described the basics of access to ZIP archives, in the next post I will illustrate the use of the new features for creating ZIP archives, zipkits and single-file executables.
                    </p>
                    <h2>
                        References
                    </h2>
                    <ol>
                        <li>
                            <p>
                                <a href="https://core.tcl-lang.org/tips/doc/trunk/tip/430.md">TIP 430: Add basic ZIP archive support to Tcl</a>
                            </p>
                        </li>
                        <li>
                            <p>
                                <a href="http://www.tcl-lang.org/man/tcl8.7/TclCmd/zipfs.htm">zipfs man page</a>
                            </p>
                        </li>
                    </ol>
                    <nav>
                        Tagged:
                        <ul>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl/">Tcl</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">Tcl 8.7</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tutorial/">tutorial</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/zip/">zip</a>
                            </li>
                        </ul>
                    </nav><!-- tags -->
                </section></div>]]>
            </description>
            <link>https://www.magicsplat.com/blog/tcl87-zipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257855</guid>
            <pubDate>Mon, 24 Aug 2020 05:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principal Component Analysis]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24257468">thread link</a>) | @keyboardman
<br/>
August 23, 2020 | https://leimao.github.io/article/Principal-Component-Analysis/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Principal-Component-Analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Principal components analysis (PCA) is one of a family of techniques for taking high-dimensional data, and using the dependencies between the variables to represent it in a more tractable, lower-dimensional form, without losing too much information. It has been widely used for data compression and de-noising. However, its entire mathematical process is sometimes ambiguous to the user.</p>



<p>In this article, I would like to discuss the entire process of PCA mathematically, including PCA projection and reconstruction, with most of the derivations and proofs provided. At the end of the article, I implemented PCA projection and reconstruction from scratch. After reading this article, there should be no more black box in PCA anymore.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="orthogonal-matrix">Orthogonal Matrix</h4>

<p>In linear algebra, an orthogonal matrix is a real square matrix whose columns and rows are orthogonal unit vectors (orthonormal vectors).</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\top}A = AA^{\top} = I
\end{align}\]

</p><p>By <a href="https://en.wikipedia.org/wiki/Invertible_matrix">the definition of invertible matrix</a>, this means matrix $A$ is invertible and $A^{-1} = A^{\top}$.</p>



<p>We could also view this from the perspective of determinant.</p>



<p>Because $A$ and $A^{\top}$ are square matrices and using <a href="https://en.wikipedia.org/wiki/Determinant#Properties_of_the_determinant">the properties of determinant</a></p><p>

\[\begin{align}
\det(I) &amp;= \det(A^{\top}A) \\
&amp;= \det(AA^{\top}) \\
&amp;= \det(A) \det(A^{\top}) \\
&amp;= \det(A) \det(A) \\
&amp;= \det(A)^2 \\
&amp;= \det(A^{\top})^2 \\
&amp;= 1 \\
\end{align}\]

</p><p>Since $\det(A) \neq 0$, matrix $A$ is invertible. We multiply $A^{-1}$ on both side of the orthogonal matrix definition.</p><p>

\[\begin{align}
A^{\top}A A^{-1} &amp;= I A^{-1}\\
A^{\top} I &amp;= A^{-1} \\
A^{\top} &amp;= A^{-1} \\
\end{align}\]

</p><p>We have also derived the conclusion that $A^{-1} = A^{\top}$.</p>



<p>Similarly, a complex square matrix $A$ is unitary if its transpose conjugate $A^{\dagger}$ is also its inverse.</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\dagger}A = AA^{\dagger} = I
\end{align}\]

</p><h4 id="symmetric-matrix">Symmetric Matrix</h4>

<p>Real symmetric matrix has the following useful properties:</p>



<p>If $A$ is a real symmetric matrix, all of its eigenvalues are real numbers.</p>



<p>Because of <a href="https://en.wikipedia.org/wiki/Complex_conjugate#Generalizations">the conjugate properties</a> and $\overline{A} = A$ since $A$ is a real value matrix,</p><p>

\[\begin{align}
\overline{Av} &amp;= \overline{\lambda v} \\
&amp;= \overline{A} \overline{v} \\
&amp;= A \overline{v} \\
&amp;= \overline{\lambda} \overline{v} \\
\end{align}\]

</p><p>We got $A \overline{v} = \overline{\lambda} \overline{v}$.</p>



<p>Let $\lambda \in \mathbb{C}$ be an eigenvalue of the symmetric matrix $A$. $Av = \lambda v$ and $v \neq 0$. We multiply $v^{\dagger}$ ($v^{\dagger} = \overline{v}^{\top}$) to the both sides, and because of $A^{\top} = A$ and the property we have just derived $A \overline{v} = \overline{\lambda} \overline{v}$,</p><p>

\[\begin{align}
v^{\dagger} A v &amp;= \lambda v^{\dagger} v \\
&amp;= v^{\dagger} A^{\top} v \\
&amp;= \overline{v}^{\top} A^{\top} v \\
&amp;= (A\overline{v})^{\top} v \\
&amp;= (\overline{\lambda} \overline{v})^{\top} v \\
&amp;= \overline{\lambda}^{\top} \overline{v}^{\top} v \\
&amp;= \overline{\lambda} v^{\dagger} v \\
\end{align}\]

</p><p>We have $\lambda v^{\dagger} v = \overline{\lambda} v^{\dagger} v$, thus $\lambda$ is real.</p>



<p>This concludes the proof.</p>

<h4 id="positive-semi-definite-matrix">Positive Semi-Definite Matrix</h4>

<p>The $n \times n$ symmetric matrix $A$ is defined to be positive semi-definite, if $x^{\dagger} A x \geq 0$ for $x \in \mathbb{C}^n$.</p>



<p>The positive semi-definite matrix has the following important property:</p>



<p>The eigenvalues of positive semi-definite matrix are non-negative.</p>



<p>Because $x^{\dagger} A x \geq$ for $x \in \mathbb{C}^n$, suppose $x$ is an eigenvector of $A$ and $Ax = \lambda x$ where $x \neq 0$,</p><p>

\[\begin{align}
x^{\dagger} A x &amp;= x^{\dagger} \lambda x \\
&amp;= \lambda x^{\dagger} x \\
&amp;\geq 0 \\
\end{align}\]

</p><p>Because $x^{\dagger} x$ must be real number and $x^{\dagger} x &gt; 0$, we have $\lambda \geq 0$.</p>



<p>This concludes the proof.</p>

<h4 id="covariance-matrix">Covariance Matrix</h4>

<p>The covariance matrix has the following important property:</p>



<p>Covariance matrix is positive semi-definite. This means that the eigenvalues of covariance matrix is non-negative.</p>



<p>The proof of that covariance must be positive semi-definite could be found in my previous post on <a href="https://leimao.github.io/blog/Multivariate-Gaussian-Covariance-Matrix/">Multivariate Gaussian and Covariance Matrix</a>.</p>

<h4 id="singular-values">Singular Values</h4>

<p>The singular values, $\sigma_1$, $\sigma_2$, $\cdots$, $\sigma_r$, of an $m \times n$ matrix $A$ are the square roots, $\sigma_i = \sqrt{\lambda_i}$, of non-negative eigenvalues of the associated Gram matrix $K = A^{\dagger}A$. The corresponding eigenvectors of $K$ are known as singular vectors of $A$.</p>



<p>Note that the associated Gram matrix $K = A^{\dagger}A$ is real and symmetric, so the eigenvalues of $K$ are all real.</p>



<p>$K = A^{\dagger}A$ is also positive semi-definite.</p>



<p>For any vector $x$</p><p>

\[x^{\dagger} (A^{\dagger} A) x = (Ax)^{\dagger} Ax\]

</p><p>Because $Ax$ is also a vector,</p><p>

\[\begin{align}
x^{\dagger} (A^{\dagger} A) x \geq 0
\end{align}\]

</p><p>Therefore, all the eigenvalues of $K = A^{\dagger}A$ are non-negative and they all have a corresponded singular value of $A$.</p>

<h4 id="singular-value-decomposition">Singular Value Decomposition</h4>

<p>In linear algebra, the singular value decomposition (SVD) is a factorization of a real or complex matrix that generalizes the eigendecomposition of a square normal matrix to any $ m\times n$ matrix via an extension of the polar decomposition.</p>



<p>Specifically, the singular value decomposition of an $m \times n$ real or complex matrix $M$ is a factorization of the form $U \Sigma V^{\dagger}$, where $U$ is an $m \times m$ real or complex unitary matrix, $\Sigma$ is a $m \times n$ rectangular diagonal matrix with non-negative real numbers on the diagonal, and $V$ is an $n \times n$ real or complex unitary matrix.</p>



<p>The diagonal entries $\sigma_{i}=\Sigma_{ii}$ of $\Sigma$ are known as the singular values of $M$. The number of non-zero singular values is equal to the rank of $M$.</p>



<p>In particular, for any matrix $A \in \mathbb{C}$,</p><p>

\[A_{m \times n} = U_{m\times m} \Sigma_{m \times n} V_{n \times n}^{\dagger}\]

</p><p>We will skip the proof for why every matrix has SVD and the algorithm for SVD.</p>

<h4 id="singular-value-decomposition-for-norm-matrix">Singular Value Decomposition for Norm Matrix</h4>

<p>For any matrix $A \in \mathbb{C}$, $A^{\dagger} A$ could be expressed as</p><p>

\[\begin{align}
A^{\dagger} A &amp;= (U \Sigma V^{\dagger})^{\dagger} U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} U^{\dagger}  U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} I \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} \Sigma V^{\dagger}
\end{align}\]

</p><p>We multiply $V$ at both side of the equation.</p><p>

\[\begin{align}
A^{\dagger} A V &amp;= V \Sigma^{\dagger} \Sigma V^{\dagger} V \\
&amp;=  V \Sigma^{\dagger} \Sigma I \\
&amp;=  V \Sigma^{\dagger} \Sigma \\
&amp;= \Sigma^{\dagger} \Sigma V \\
\end{align}\]

</p><p>Note that $\Sigma^{\dagger} \Sigma$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma^{\dagger} \Sigma$, including the zeros, are the eigenvalues of $A^{\dagger} A$. All the columns of $V$ are the corresponding eigenvectors of $A^{\dagger} A$.</p>



<p>Similarly, $A A^{\dagger}$ could be expressed as</p><p>

\[\begin{align}
A A^{\dagger} U &amp;= \Sigma \Sigma^{\dagger} U \\
\end{align}\]

</p><p>Note that $\Sigma \Sigma^{\dagger}$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma \Sigma^{\dagger}$, including the zeros, are the eigenvalues of $A A^{\dagger}$. All the columns of $U$ are the corresponding eigenvectors of $A A^{\dagger}$.</p>

<h3 id="mathematics-of-principal-components-analysis">Mathematics of Principal Components Analysis</h3>

<p>We start with $p$-dimensional vectors, and want to summarize them by projecting down into a $q$-dimensional subspace, where $q \leq p$. Our summary will be the projection of the original vectors on to $q$ directions, the principal axes, which span the subspace.</p>

<h4 id="minimizing-projection-residuals">Minimizing Projection Residuals</h4>

<p>Given a dataset $X \in \mathbb{R}^{n \times p}$ whose row is the centered data vectors $x_i \in \mathbb{R}^p$ for $0 \leq i \leq n-1$ ($\sum_{i=0}^{n-1} x_{i} = 0$), if we have a unit vector $w \in \mathbb{R}^p$ ($|w| = 1$) and we project the all the data vectors to this unit vector $w$.</p>



<p>The length of projection for data vector $x_i$ on $w$, by definition, is</p><p>

\[\begin{align}
|x_i| \cos \theta &amp;= \frac{\langle x_i, w \rangle}{|w|} \\
&amp;= \langle x_i, w \rangle \\
\end{align}\]

</p><p>where $\langle x_i, w \rangle$ is the inner product of $x_i$ and $w$.</p>



<p>The projection vector for data vector $x_i$ on $w$ is $\langle x_i, w \rangle w$.</p>



<p>The residual, which is the distance from data vector $x_i$ to $w$, is the length of vector $x_i - \langle x_i, w \rangle w$.</p>



<p>Let’s check what the residual square $| x_i - \langle x_i, w \rangle w | ^2$ is.</p><p>

\[\begin{align}
| x_i - \langle x_i, w \rangle w |^2 &amp;= \langle x_i - \langle x_i, w \rangle w, x_i - \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, \langle x_i, w \rangle w \rangle - \langle \langle x_i, w \rangle w, x_i \rangle + \langle \langle x_i, w \rangle w, \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, w \rangle \langle x_i, w \rangle - \langle x_i, w \rangle \langle w, x_i \rangle + \langle x_i, w \rangle ^2 \langle w,  w \rangle \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 |w| ^2 \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 \\
&amp;= \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \\
\end{align}\]

</p><p>The optimization goal of projection is to minimize mean squared error $\text{MSE}(w)$, which is the mean of the residual sum of squares.</p><p>

\[\begin{align}
\text{MSE}(w) &amp;= \frac{1}{n} \sum_{i=0}^{n-1} | x_i - \langle x_i, w \rangle w |^2 \\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \big( \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \big)\\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \langle x_i, x_i \rangle - \frac{1}{n} \sum_{i=0}^{n-1}  \langle x_i, w \rangle ^2\\
\end{align}\]

</p><p>Remember the relationship between variance and expected value, $\mathbb{V}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2$, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Principal-Component-Analysis/">https://leimao.github.io/article/Principal-Component-Analysis/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Principal-Component-Analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257468</guid>
            <pubDate>Mon, 24 Aug 2020 04:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standard Space Habitats]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24257132">thread link</a>) | @luu
<br/>
August 23, 2020 | https://halcanary.org/vv/2020/07/14/3017/ | <a href="https://web.archive.org/web/*/https://halcanary.org/vv/2020/07/14/3017/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A refinement of O'Neill's colonies.</p><div>

<!-- BEGIN CONTENT -->
<p><a href="https://settlement.arc.nasa.gov/70sArtHiRes/70sArt/art.html"><img src="https://halcanary.org/images/Spacecolony1.jpg" alt="[A pair of O'Neill cylinders. https://settlement.arc.nasa.gov/70sArtHiRes/70sArt/art.html Interior view looking out through large windows. Art work: Rick Guidice.  NASA ID Number AC75-1086]" width="1920" height="1512"></a></p>
<p>Start with the idea of an <a href="https://en.wikipedia.org/wiki/O%27Neill_cylinder">O'Neill cylinder</a>: a spinning cylindrical space habitat 8 km in diameter and 32 km long.  The frequency of revolution is about two minutes.  This is a good diameter for a space habitat: if it is an order of magnitude larger, the structure won't hold together when it spins; an order of magnitude smaller, the Coriolis force is more noticeable.</p>
<p>The giant windows are a huge hazard for both radiation and meteor impacts.  Instead, make the cylinder a solid steel vessel, thick enough to block most radiation.  Make it out of many layers of steel sheeting, with a thick layer of ablative insulation on the outside that can absorb and redirect the kinetic energy of a meteor impact.  Construct it as several independent 8 km long segments, each with its own shielded endcaps, all sharing a common axis.  Each hab segment has airlocks at the axis, leading to rotating joints that connect the segment to two small non-rotating modules at the axis, where there are ports for visiting spacecraft to dock.  This is also where arrays of directional communication antennas are located.</p>
<p>At one end of the axis, there is a massive array of solar panels (not rotating with the hab), at the other, there is an array of radiators.  If the hab is too far from a star for solar power, a nuclear power plant is located outside of the hab, along the axis, in its own shielded module, as far away as needed to minimize radiation hazards to humans entering and exiting the habitat at the docking port module.</p>
<p>The ecology and economy of the hab is 99.9% closed - with energy as an input and heat as an output.  Occasionally, robots are sent out to mine asteroids or comets for material to replace material losses.  I expect that the solar power and radiator arrays will need constant maintenance and replacement to keep working at 100% capacity.  All of the habs in a star system exchange information, allowing the occupants of the habs to share and trade art, science, and culture.</p>
<p>The inside of the hab segment is either completely open or is segmented into many smaller "cells" big enough to feel open but small enough to give the human population more room.  A cell might have a ceiling 100 meters tall that looks like Earth's sky and provides similar light.  Some of the interior volume is taken up by light industry and vertical-farm-based agriculture.</p>
<p>This design is meant to be very robust and adaptable.  It doesn't matter if the hab is located in orbit around a red dwarf or a blue giant, as long as the solar panels work.  The hab can be sent on a thousand-year interstellar voyage as long as enough spare energy and material is taken along.  The occupants of the hab can remotely supervise robots to build new habs.</p>
<p>This is the future for humanity if we don't become post-human.  There aren't any planets out there that we can walk around in shirtsleeves on.  Terraforming projects would take many thousands of years at best, and might fall afoul of the law of unintended consequences.  Even Mars, one of the best possible places for humans to live outside of Earth, might not have enough gravity for standard humans to thrive.</p>
<p>I'm not saying rocky planets and moons aren't useful.  After all, that's where a lot of the useable material is.  But if you need that material, why not supervise robot miners from orbit?  Especially if the planet has a surface gravity of 1.5g or a surface temperature of 700 K.</p>
<hr>
<p>Discuss: <a href="https://twitter.com/halcanary/status/1283090742852886528">twitter</a>, <a href="https://www.reddit.com/user/hwc/comments/hrmyxc/standard_space_habitats/">reddit</a>.</p>

<!-- END CONTENT -->

      </div></div>]]>
            </description>
            <link>https://halcanary.org/vv/2020/07/14/3017/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257132</guid>
            <pubDate>Mon, 24 Aug 2020 02:42:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an SSDP Directory in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24256984">thread link</a>) | @luu
<br/>
August 23, 2020 | https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir | <a href="https://web.archive.org/web/*/https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a href="https://netscape-browser.en.softonic.com/" target="_blank">
        <img src="https://quinnwilton.com/images/netscape_now.gif">
      </a>
    </header>
<a href="https://quinnwilton.com/blog"><img src="https://quinnwilton.com/images/back.png"></a>

<section>
  
  <h2>2020-02-26</h2>

<p>I used to spend all of my free time programming random toy projects. Over time, likely after spending a few years in industry, I started to spend so much time thinking about how to write maintainable code that I think I started to lose out on what makes programming fun: exploring new ideas and learning how to do things I’ve never done before. I’d like to rediscover that joy, and to do that, I need to stop being so much of a perfectionist.</p>
<p>I think that in an office setting, deadlines force me to move on and call things done, but in my personal life, lack of that kind of pressure means that I can spend literally forever architecting and rearchitecting the same piece of code until it’s perfect (it never is).</p>
<p>To fix this, I’m going to try blogging! If I can make myself excited to share my code with other people, imperfect and unfinished as it is, then maybe I can start to unlearn the paralysis that’s been plaguing me for the past few years.</p>
<p>To start, I just want to walk through a small program I wrote a few months ago. I wanted to learn how <a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol">SSDP</a> works, so I implemented an SSDP Directory! For those of you who aren’t aware, SSDP is a fairly simple protocol from the 90s that’s used to facilitate the discovery of network services. Nowadays, it’s also used by everything from smart TVs to Hue lights.</p>
<p>My implementation can be found <a href="https://github.com/QuinnWilton/ssdp_directory">here</a>, and the (very readable!) RFC is <a href="https://tools.ietf.org/html/draft-cai-ssdp-v1-03">here</a>.</p>
<p>If I run the application, it discovers all of the devices on my network:</p>
<pre><code>iex(1)&gt; SSDPDirectory.list_services
%{
  "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice" =&gt; %SSDPDirectory.Service{
    location: "http://192.168.0.150:60000/upnp/dev/b236f169-9c9d-db64-ffff-ffffcff91970/desc",
    type: "upnp:rootdevice",
    usn: "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice"
  },
  ...
}</code></pre>
<p>The key to SSDP is what’s called <a href="https://en.wikipedia.org/wiki/Multicast">multicast addressing</a>. Essentially, services broadcast their presence to a specially designated multicast address, and then anyone else on the network is able to listen for those presence notifications in order to track the appearance and disappearance of new services.</p>
<p>Fortunately, Elixir, my language of choice, makes subscribing to these notifications <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/multicast_channel.ex">easy</a>!</p>
<pre><code>defmodule SSDPDirectory.MulticastChannel do
  use GenServer

  alias __MODULE__

  alias SSDPDirectory.{
    Discovery,
    Presence
  }

  @multicast_group {239, 255, 255, 250}
  @multicast_port 1900

  def start_link(opts \\ []) do
    GenServer.start_link(__MODULE__, :ok, opts)
  end

  @spec broadcast(GenServer.name(), iodata) :: :ok
  def broadcast(channel \\ MulticastChannel, packet) do
    GenServer.cast(channel, {:broadcast, packet})
  end

  @spec init(:ok) :: {:ok, %{socket: port}}
  def init(:ok) do
    udp_options = [
      :binary,
      active: true,
      add_membership: {@multicast_group, {0, 0, 0, 0}},
      multicast_if: {0, 0, 0, 0},
      multicast_loop: false,
      reuseaddr: true
    ]

    {:ok, socket} = :gen_udp.open(@multicast_port, udp_options)

    {:ok, %{socket: socket}}
  end

  def handle_cast({:broadcast, packet}, state) do
    :ok = :gen_udp.send(state.socket, @multicast_group, @multicast_port, packet)

    {:noreply, state}
  end

  def handle_info({:udp, _socket, _ip, _port, data}, state) do
    Task.Supervisor.start_child(SSDPDirectory.DecodingSupervisor, fn -&gt;
      with {:ok, packet, rest} &lt;- :erlang.decode_packet(:http_bin, data, []),
           {:ok, handler} &lt;- packet_handler(packet),
           {:ok, decoded} &lt;- handler.decode(rest) do
        :ok = handler.handle(decoded)
      end
    end)

    {:noreply, state}
  end

  defp packet_handler({:http_request, "NOTIFY", _target, _version}),
    do: {:ok, Presence}

  defp packet_handler({:http_response, _version, 200, "OK"}),
    do: {:ok, Discovery.Response}

  defp packet_handler(_packet), do: :error
end</code></pre>
<p>Most of the magic happens in the <code>init/1</code> function. By opening a UDP socket and joining it to the protocol’s multicast group, our process is now able to receive packets that are broadcast to that group. That receiving logic is located in the <code>handle_info/2</code> function within the same file.</p>
<p>When receiving a packet, we spawn another process that is responsible for handling that packet. This process runs under a <code>Task.Supervisor</code> in order to isolate crashes of that process from the <code>MulticastChannel</code>. Also interesting, is that we’re able to decode the incoming packets using <a href="http://erlang.org/doc/man/erlang.html#decode_packet-3">:erlang.decode_packet/3</a>. This is a builtin function that allows us to decode a variety of packet formats, piece-by-piece. In this case, we’re using it to parse the packet as an HTTP packet. This is the same way that Elixir’s <a href="https://github.com/elixir-mint/mint/blob/master/lib/mint/http1/response.ex#L7">Mint</a> decodes HTTP responses too!</p>
<p>Based on the type of packet decoded, <code>packet_handler/1</code> then delegates the handling of that packet to another module. Either we’ve received an HTTP NOTIFY request, and we’re dealing with a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence.ex">presence notification</a>, or we’ve received a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/discovery/response.ex">response to a discovery request</a>.</p>
<p>Let’s take a look at the presence case. In case you’re curious, here’s an example presence notification:</p>
<pre><code>NOTIFY * HTTP/1.1
Host: 239.255.255.250:reservedSSDPport
NT: blenderassociation:blender
NTS: ssdp:alive
USN: someunique:idscheme3
AL: &lt;blender:ixl&gt;&lt;http://foo/bar&gt;
Cache-Control: max-age = 7393</code></pre>
<p>And here’s where we handle it:</p>
<pre><code>defmodule SSDPDirectory.Presence do
  require Logger

  alias __MODULE__
  alias SSDPDirectory.HTTP

  @type command :: Presence.Alive.t() | Presence.ByeBye.t()

  @spec decode(binary) ::
          :error
          | {:ok, command}
  def decode(data) do
    case HTTP.decode_headers(data, []) do
      {:ok, headers, _rest} -&gt;
        process_headers(headers)

      :error -&gt;
        _ = Logger.debug(fn -&gt; "Failed to decode NOTIFY request: " &lt;&gt; inspect(data) end)

        :error
    end
  end

  @spec handle(command) :: :ok
  def handle(%Presence.Alive{} = command) do
    Presence.Alive.handle(command)
  end

  def handle(%Presence.ByeBye{} = command) do
    Presence.ByeBye.handle(command)
  end

  defp process_headers(headers) do
    do_process_headers(headers, %{})
  end

  defp do_process_headers([], args) do
    case args do
      %{command: "ssdp:alive", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.Alive{
           usn: usn,
           type: type,
           location: Map.get(args, :location)
         }}

      %{command: "ssdp:byebye", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.ByeBye{
           usn: usn,
           type: type
         }}

      _ -&gt;
        :error
    end
  end

  defp do_process_headers([{"nts", command} | rest], args) do
    args = Map.put(args, :command, command)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"nt", type} | rest], args) do
    args = Map.put(args, :type, type)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"usn", usn} | rest], args) do
    args = Map.put(args, :usn, usn)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"al", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"location", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([_ | rest], args) do
    do_process_headers(rest, args)
  end
end</code></pre>
<p>It looks like there’s a lot going on here, but it’s actually pretty simple. Starting in <code>decode/1</code>, we continue decoding the packet from <code>MulticastChannel</code>. This time it’s the headers we’re interested in, so we decode those, and then process them in order to determine what kind of command we’re dealing with.</p>
<p>The processing step simply involves recursing over the list of headers, and accumulating the relevant ones in a map . Once we’ve done that, we just construct the corresponding command!</p>
<p>Lastly, the command handler delegates to a third module based on the type of command being processed. For example, in the case of an <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence/alive.ex">ssdp:alive</a> command:</p>
<pre><code>defmodule SSDPDirectory.Presence.Alive do
  require Logger

  alias __MODULE__

  alias SSDPDirectory.{
    Cache,
    Service
  }

  @enforce_keys [:usn, :type]
  defstruct [:location] ++ @enforce_keys

  @type t :: %Alive{}

  @spec handle(Alive.t()) :: :ok
  def handle(%Alive{} = command) do
    _ = Logger.debug(fn -&gt; "Handling ssdp:alive request: " &lt;&gt; inspect(command) end)

    service = %Service{
      usn: command.usn,
      type: command.type,
      location: command.location
    }

    :ok = Cache.insert(service)
  end
end</code></pre>
<p>Here we just construct a service using the parameters in the command, and then store it in our <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/cache.ex">cache</a>:</p>
<pre><code>defmodule SSDPDirectory.Cache do
  use GenServer

  require Logger

  alias __MODULE__
  alias SSDPDirectory.Service

  def start_link(opts \\ []) do
    GenServer.start_link(Cache, :ok, opts)
  end

  def contents(cache \\ Cache) do
    :ets.tab2list(cache)
    |&gt; Enum.into(%{})
  end

  def insert(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:insert, service})
  end

  def delete(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:delete, service})
  end

  def flush(cache \\ Cache) do
    GenServer.call(cache, :flush)
  end

  def init(:ok) do
    table = :ets.new(Cache, [:named_table, read_concurrency: true])

    {:ok, %{table: table}}
  end

  def handle_call({:insert, %Service{usn: usn} = service}, _from, data) when not is_nil(usn) do
    :ets.insert(data.table, {usn, service})

    _ = Logger.debug(fn -&gt; "Cached service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call({:delete, %Service{usn: usn}}, _from, data) when not is_nil(usn) do
    :ets.delete(data.table, usn)

    _ = Logger.debug(fn -&gt; "Evicted service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call(:flush, _from, data) do
    :ets.delete_all_objects(data.table)

    _ = Logger.debug(fn -&gt; …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</a></em></p>]]>
            </description>
            <link>https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-24256984</guid>
            <pubDate>Mon, 24 Aug 2020 02:09:41 GMT</pubDate>
        </item>
    </channel>
</rss>
