<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 23 Dec 2020 17:04:40 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 23 Dec 2020 17:04:40 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[This Community is Available in the App]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25502828">thread link</a>) | @rukshn
<br/>
December 21, 2020 | https://ruky.me/2020/12/22/this-community-is-available-in-the-app/ | <a href="https://web.archive.org/web/*/https://ruky.me/2020/12/22/this-community-is-available-in-the-app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Yesterday’s <a href="https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/">post</a> was an awesome one, I learned a lot in JavaScript and and I was happy to see people doing what I thought impossible. Writing a simple todo app within 280 chars, in plain js.</p>
<p>After I finished writing the post, I wanted to share it on Reddit JavaScript community, r/javascript at the same time I shared it on HackerNews.</p>
<p>I have seen lot of comments on HackerNews criticizing the new Reddit design, using JavaScript and breaking in their mobile website, and constant nags pushing the users to their mobile app.</p>
<p>I was one of those few who liked their new design on desktop, no page loads between posting something, lot of white spaces, I feel most of the average users would be feeling the same, except for the tech community. But as a service Reddit should be looking at the common denominator, not the outliers.</p>
<p>I’m annoyed with the mobile app nag, when I visit the mobile website, Reddit is always asking me to download the mobile app. But I just cancel it and move along in the mobile browser.</p>
<p>But what happened yesterday just took me off the ledge. When I visited the r/javascript community on my iPad, I was greeted with this screen.</p>
<figure><img data-attachment-id="73" data-permalink="https://ruky.me/2020/12/22/this-community-is-available-in-the-app/img_0041/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=1536%2C2048&amp;ssl=1" data-orig-size="1536,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_0041" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=768%2C1024&amp;ssl=1" loading="lazy" width="768" height="1024" src="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?w=1536&amp;ssl=1 1536w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?w=1536&amp;ssl=1 1536w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>This community is only available in the app.</figcaption></figure>
<p>Why do you block me from from visiting the community from my mobile device?</p>
<p>Will the whole mobile website is scrapped and you end up with a landing page to download the mobile app?</p>
<p><strong>If you want to visit a popular subreddit</strong>, <strong>install our up and use it, or else login. </strong></p>
<p>I’ve managed to see the subreddit by requesting the desktop website, but I’m sure they will figure out a way, by checking the screen size to block this as well.</p>
<p>I understand that, as a company, you need to push to gain as much users as possible on their mobile devices, that’s the best way to track, to send notifications and keep you hooked and keep coming back. If I had a company like Reddit I might have done the same.</p>
<p>But for blocking users from their mobile devices, a service they once offered is a very dark pattern, instead what they should do is introduce some awesome features that will make the users download the app by themselves so they can enjoy those features. Not forcing the app though their throats.</p>
<p>Anyone else experienced a similar experience on Reddit mobile?</p>
<p><em>Only after writing the and checking the screenshot again made me see that they allow you to see the subreddit by logging in. But that is obscured and they intend to push users to download the app.</em></p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2020/12/22/this-community-is-available-in-the-app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502828</guid>
            <pubDate>Tue, 22 Dec 2020 04:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Blind Passwords a.k.a. Horcruxing]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25502703">thread link</a>) | @phantom_rehan
<br/>
December 21, 2020 | https://kaizoku.dev/double-blind-passwords-aka-horcruxing | <a href="https://web.archive.org/web/*/https://kaizoku.dev/double-blind-passwords-aka-horcruxing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1607775961422/elXIChWIZ.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Before we get into Horcruxing, here's a quick prologue on online security hygiene. You can skip to the  <a href="#double-blind-passwords-aka-horcruxing">Horcruxing section</a>  if it seems redundant.</p>
<h3 id="rules-for-strong-online-security">Rules for Strong Online Security</h3>
<p>1.
<strong>Longer passwords (atleast 16 characters) are better than shorter ones</strong></p>
<pre><code>=&gt; cutesamantha15101995 &gt; cutesamantha
</code></pre><p>2.
<strong>Randomized passwords are better than personally identifiable passwords</strong></p>
<pre><code>=&gt; process-cancel-stingy-garnet &gt; cutesamantha15101995
</code></pre><p><strong>NOTE: </strong> <code>process-cancel-stingy-garnet</code> is technically a passphrase - basically an easy-to-remember password in comparison to randomized strings like <code>B6fSpxMj&amp;f6DU@5^k</code></p>
<p>3.
<strong>Have a <em>significantly</em> different password for each account</strong></p>
<p>Having the same password for different accounts is like using the same key for different locks. It beats the whole point of having multiple locks! Also, having different passwords but with only one easily guessable word different (like the ones below) still poses the same risk. The passwords should be <strong><em>significantly</em></strong> different.</p>
<pre><code>bounce-unfold-stunning-chute        process-cancel-stingy-facebook
symptom-untouched-unpaid-arena  &gt;   process-cancel-stingy-twitter
sediment-tweak-annually-koala       process-cancel-stingy-gmail
</code></pre><p>4.
<strong>Use 2FA/MFA wherever possible</strong></p>
<p>Both Google and Facebook offer a 2FA feature where you need the second factor only when you login from a new device or a new location, instead of needing 2FA every time. That's a rare combination of convenience &amp; security right there! 
Most other sites also offer some variation of 2FA.</p>
<p><strong>NOTE</strong>: Use the  <a target="_blank" href="https://play.google.com/store/apps/details?id=org.shadowice.flocke.andotp">andOTP</a>  (or any other) app's TOTP as the second factor since it cannot be spoofed or spied on lock-screen like the SMS OTP and does not require a mobile network or internet connection. You can also use Biometrics (finger print or face recognition)</p>
<blockquote>
<p>Woah! How do I create a long password for each of the bazillion websites out there, <em>and</em> have them significantly different <em>and</em> remember them? Security seems like such a pain in the ass!</p>
</blockquote>
<h3 id="enter-password-manager">[enter] <strong>PASSWORD MANAGER</strong></h3>
<p>A password manager helps you manage all your passwords in one place, either in the form of a browser extension, mobile app, or website. Good password managers will offer a browser extension and a mobile app with one-click auto-fill-login-page feature by removing the hassle of copy pasting or typing your login details. A few smart ones even detect phishing pages and warn you indirectly, by not showing the login details for such web pages.</p>
<p>They enable all the above measures for strong online security with ease. While I agree it takes some effort to set it up for the very first time. But, after that, it just flows like butter. </p>
<p><br>
For example, password generator in <a target="_blank" href="https://bitwarden.com/">BitWarden</a> lets you custom design your random password in different flavours.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1607770748804/m93T3kqUH.png?auto=compress" alt="BitWarden's password generator"></p>
<h3 id="yay-im-secure">YAY! I'm Secure!</h3>
<p>You meticulously move all your passwords and secrets to a trusted password manager. Finally, you can rest easy knowing that your digital life is truly secure. Or, is it?  <br></p>
<p><strong>What if </strong></p><ul>
<li>your master password (the password to your password manager) is compromised due to a security breach or you left it in plaintext on a post-it/ email/ notes app</li>
<li>someone gained temporary access to your unlocked system (computer or phone) when you stepped away to get that last coffee for the day and your password manager is still logged in for everyone to see</li>
</ul>
<p>The answer: you're <strong><em>screwed</em></strong>. The cost of putting all your eggs in one basket is that it could all go into oblivion in one fell swoop. How do you overcome this challenge now? </p>
<h3 id="double-blind-passwords-aka-horcruxing">Double Blind Passwords (aka Horcruxing)</h3>
<p>For all his faults, Voldemort did one good thing for us muggles. He gave us the concept of a horcrux. For the uninitiated, a horcrux is any object in which you store a piece of your soul, putting the proverbial eggs of your soul into different baskets, to gain quasi-immortality. </p>
<p><strong>The basic idea</strong>: You split your password into 2 parts - one which is stored in the password manager, and the other which is stored in your head (aka horcrux).</p>
<p>Basically, at any given point in time, you and your password manager know only a piece of the password. It's double-blind. In effect, just like You-Know-Who, you're splitting your password (soul) into pieces and storing them in different places.</p>
<h4 id="before">BEFORE</h4>
<pre><code>
<span>username: rick</span>
<span>password: rollthepeople1732</span>


<span>username: rick</span>
<span>password: rollthepeople1732</span>
</code></pre><h4 id="after">AFTER</h4>
<pre><code>
<span>username: rick</span>
<span>password: roll-the-people-venus</span>


<span>horcrux: papel</span>


<span>username: rick</span>
<span>password: roll-the-people-venuspapel</span>
</code></pre><p>The horcrux adds an additional layer of security that only you can unlock. It's a kind of 2FA. Again, the longer the horcrux the better. But, a simple word should also be fine as long as only you know the horcrux.</p>
<p>If it feels like too much effort, use a horcrux only for the most important logins - your social media, bank accounts etc. </p>
<h3 id="one-last-thing">One Last Thing</h3>
<p>Security is never absolute. One can try to secure a system as tightly as possible, but never really say that it is fully secure (if you see someone claiming otherwise, it's mostly marketing bullshit). If we cannot make systems completely secure, the next best thing to do is to make them as secure as possible and a good way to do it is <a target="_blank" href="https://en.wikipedia.org/wiki/Defense_in_depth_(computing">Defense In Depth</a> - basically make sure that even if one layer of security is breached, there exist other layers to mitigate further damage - which is what we've tried to achieve all along.</p>
<h3 id="summary">Summary</h3>
<p>1.
Use a good password manager </p>
<blockquote>
<p>I use BitWarden (since it is open source and costs just $10 a year for the PRO features)</p>
</blockquote>
<p>2.
Use TOTP/ biometrics instead of SMS-based OTP</p>
<blockquote>
<p>I use andOTP (since it is open source)</p>
</blockquote>
<p>3.
Use a horcrux (a double-blind password) for the most important logins</p>

<p>P.S. Keep in mind that horcruxing only works fine until you connect your brain to NeuraLink and accidentally upload your thoughts online for everyone to see. :P</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://kaizoku.dev/double-blind-passwords-aka-horcruxing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502703</guid>
            <pubDate>Tue, 22 Dec 2020 03:58:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconventional Warfare in Mexico: The US Trained Some of Its Most Brutal Cartels]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25502435">thread link</a>) | @AndrewBissell
<br/>
December 21, 2020 | https://narco.news/unconventional-warfare-in-mexico | <a href="https://web.archive.org/web/*/https://narco.news/unconventional-warfare-in-mexico">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-120a3898=""><div data-v-120a3898=""><p><a href="https://fas.org/irp/doddir/dod/jp1_02.pdf">Unconventional Warfare</a> (UW): Activities conducted to enable a resistance movement or insurgency to coerce, disrupt, or overthrow a government or occupying power by operating through or with an underground, auxiliary, and guerrilla force in a denied area.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-20-at-5.49.19-PM.png" width="1000" height="888"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-20-at-5.49.29-PM.png" width="1000" height="888"></p></div></div><figcaption>Unconventional Warfare associated terminology <a href="https://www.soc.mil/ARIS/books/pdf/Unconventional%20Warfare%20Pocket%20Guide_v1%200_Final_6%20April%202016.pdf">Special Operations Command</a></figcaption></figure><hr><p><em>Los Zetas</em> were the highly-trained enforcers of the Gulf cartel made up of supposed deserters from the Mexican special forces known as the <em>Grupo AeromÃ³vil de Fuerzas Especiales </em>(GAFE). The GAFES<em> </em>were formed in 1986 as an elite quick reaction force specializing in counterinsurgency and unconventional warfare. When the North American Free Trade Agreement went into effect in 1994, the GAFES received combat experience in the brutal fight with the leftist <em>EjÃ©rcito Zapatista de LiberaciÃ³n Nacional</em> (EZLN) in Chiapas. According to <a href="http://historic.edualter.org/material/ddhh/proc1.htm">reporting by Carlos Marin</a>, the army sent the GAFES to Chiapas to <strong>create paramilitary forces and displace the population</strong> in order to break the support of the people for the EZLN, an approach which would be used against organized crime years later. In Ioan Grillo's book <em>El Narco</em>, he describes how the mutilated bodies of rebels captured by the GAFES were dumped along a riverbank in the Las Margaritas municipality with their ears and noses sliced off, the sort of spectacular violence that <em>Los Zetas</em> would later standardize in the Drug War.</p><figure><img src="https://publish.narco.news/content/images/2020/10/Screen-Shot-2020-10-26-at-5.09.07-PM-1.png"><figcaption>2005 FBI memo about <em>Los Zetas</em></figcaption></figure><p>Some of the original members of <em>Los Zetas</em> are said to have been <a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB499/DOCUMENT01-20050422.PDF">trained by the U.S.</a> at the notorious School of the Americas, although accounts vary about exactly who, where and when. Some say it was at <a href="https://www.kold.com/story/3394374/los-zetas-draw-concern-of-us-government/">Ft. Benning</a> in Georgia, others at <a href="https://www.aljazeera.com/features/2010/11/03/us-trained-cartel-terrorises-mexico/">Ft. Bragg</a> in North Carolina, while other rumors suggest it was at <a href="https://www.army.mil/article/63245/army_north_hosts_mexican_army_leaders_to_strengthen_relationships">Ft. Hood</a> in Texas. According to Lt. Col. Craig Deare (retired), the former Academic Dean of the Center for Hemispheric Defense Studies and a former Special Forces Commander, it's likely that more than 500 Mexican GAFES received training from U.S. special operations forces (SOF).</p><p>According to <a href="https://www.aljazeera.com/features/2010/11/03/us-trained-cartel-terrorises-mexico/">reporting</a> in Al Jazeera:</p><p><em>Some of the cartelâ€™s initial members were elite Mexican troops, trained in the early 1990s by Americaâ€™s 7th Special Forces Group or â€œsnake eatersâ€� at Ft. Bragg, North Carolina, a former US special operations commander has told Al Jazeera.</em></p><p><em>â€œThey were given map reading courses, communications, standard special forces training, light to heavy weapons, machine guns and automatic weapons,â€� says Craig Deare, the former special forces commander who is now a professor at the US National Defence University.</em></p><p><em>â€œI had some visibility on what was happening, because this [issue] was related to things I was doing in the Pentagon in the 1990s,â€� Deare, who also served as [Mexico] director in the office of the US Secretary of Defence, says.</em></p><p>The <a href="https://en.wikipedia.org/wiki/7th_Special_Forces_Group_(United_States)">7th Special Forces Group</a> (SFG) of the U.S. Army specializes in unconventional warfare, foreign internal defense, direct action, counterinsurgency, special reconnaissance, counterterrorism, information operations, and security force assistance, among other things. In the 1980s during the Reagan administration, they fought with and trained special operations forces and paramilitaries in El Salvador, Guatemala, Honduras, Panama, Colombia, Peru, Bolivia and Venezuela.</p><figure><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.45.27-PM.png"><figcaption>A U.S. special forces Soldier assigned to 7th SF Group, oversees a group of Guatemalan Special Forces "Kaibils" conduct pistol marksmanship training Jan. 28 in Poptun, Guatemala. <a href="https://www.dvidshub.net/image/1749645/kaibil-us-special-forces-promote-security-through-partnership">DVIDS</a></figcaption></figure><p>Between 1996 and 1999, <a href="https://www.jornada.com.mx/1998/08/16/mexico.html">3,200 soldiers</a>, including at least 500 GAFES, were reportedly trained by the 7th SFG in the U.S. to create elite "counternarcotics" forces.</p><p>In 1997, Arturo GuzmÃ¡n Decena, also known as <a href="https://en.wikipedia.org/wiki/Arturo_Guzm%C3%A1n_Decena">El Zeta-uno (Z-1)</a> supposedly defected along with other GAFE soldiers to work as enforcers for the Gulf cartel in Tamaulipas. They came to be known as Los Zetas.</p><p><em><a href="https://narco.news/los-zetas">Los Zetas</a></em> changed the way that organized crime operates in Mexico. The military tactics which they standardized and their supposed fights over territory were used to justify President Felipe CalderÃ³n's decision to <a href="https://www.chicagotribune.com/hoy/ct-hoy-8766718-la-guerra-contra-el-narco-en-mexico-costosa-cara-y-mortal-story.html">deploy the military</a> to prosecute <em>La Guerra contra el NarcotrÃ¡fico</em> in December 2006 and its associated consequences. </p><figure><img src="https://publish.narco.news/content/images/2020/10/Screen-Shot-2020-10-19-at-2.08.25-PM-5.png"><figcaption>Homicides were trending downwards until Felipe CalderÃ³n unleashed the military</figcaption></figure><p>Los Zetas also supposedly recruited from other U.S.-trained SOF, like the Guatemalan Kaibiles. According to a <a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB445/docs/20090700ca.PDF">DEA memo</a> from July 2009, Los Zetas were allegedly recruiting Kaibiles since at least 2005.</p><figure><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-20-at-5.28.11-PM.png"><figcaption><a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB445/docs/20090700ca.PDF">National Security Archive</a></figcaption></figure><p>The Kaibiles have been trained by U.S. since the 1970s. Created as an elite counterinsurgency force during the Cold War, the U.S. Army's 7th SFG has trained an unknown number of Kaibiles. Between 1999 and 2010, <a href="http://www.ghrc-usa.org/Publications/factsheet_kaibiles.pdf">3,555 Guatemalan soldiers</a>, many of them Kaibiles, were trained by the US through the School of the Americas (later renamed the Western Hemisphere Institute for Security Cooperation, or WHINSEC), and other U.S. training programs. </p><p>The methods of the Kaibiles are notoriously barbaric. In training, they're given a puppy to look after and bond with for several weeks. At the end of training, the recruits are required to kill the animal using their bare hands, drink the blood and eat the flesh, a method which <a href="https://www.voltairenet.org/Los-Kaibiles-mexicanos">reportedly</a> has diffused to the Mexican GAFES and other security forces throughout the world who train with the Kaibiles. They are taught to kill without mercy or thought. Their motto is: "<em>Si avanzo, sÃ­gueme. Si me detengo, aprÃ©miame. Si retrocedo, mÃ¡tame!</em> / <em>If I advance, follow me. If I stop, urge me on. If I retreat, kill me!"</em></p><p>In 1982, the Kaibiles massacred 226 people in the Dos Erres village in Guatemala. According to the <a href="https://www.aaas.org/sites/default/files/s3fs-public/mos_en.pdf">United Nations Truth Commission Clarification</a>, the Kaibiles arrived in the middle of the night and accused the residents of being guerrilla sympathizers. The smallest children were killed by smashing their heads against various hard surfaces, while older children were killed with hammers. Adults were interrogated and tortured, one by one, and the women were raped. Fetuses were cut out of pregnant women. After the interrogation, the adults were also killed with hammers and the corpses were dumped in a well.</p><figure><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.58.27-PM.png"><figcaption><a href="https://www.nytimes.com/1999/02/26/world/guatemalan-army-waged-genocide-new-report-finds.html">New York Times</a></figcaption></figure><p>A few years later, one of the officers who had supervised the massacre at Dos Erres, Pedro Pimental Rios, became an instructor at the School of the Americas. He was extradited from the U.S. in 2012 and sentenced to 6,060 years in prison for his involvement in the massacre. Jose Mardoqueo Ortiz Morales, another former Kaibil involved in the Dos Erres massacre, <a href="https://www.ice.gov/news/releases/ice-arrests-former-guatemalan-special-forces-member-linked-1980s-massacre">was arrested</a> in Maryland in 2017. Many other School of the Americas alumni were eventually charged with crimes against humanity years after the fact. The United Nations Truth Commission Clarification later determined that <a href="https://www.aaas.org/sites/default/files/s3fs-public/mos_en.pdf">93% of the violence</a> during the 36-year conflict in Guatemala was perpetrated by the U.S.-supported security forces.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-10.11.53-AM.png" width="1462" height="944"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-10.11.36-AM.png" width="1462" height="944"></p></div></div><figcaption><a href="https://www.aaas.org/sites/default/files/s3fs-public/mos_en.pdf">CEH</a></figcaption></figure><p>According to a declassified <a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB32/docs/doc42.pdf">Defense Intelligence Agency (DIA) memo</a> from 1994, intelligence sources described clandestine graves outside of a Guatemalan military facility. The memo reported how Guatemalan soldiers would fly captives over the ocean before pushing them out of helicopters to their deaths. </p><figure><div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.09.33-PM.png" width="1100" height="1436"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.10.15-PM.png" width="1100" height="1436"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.10.38-PM.png" width="1100" height="1436"></p></div></div><figcaption><a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB32/docs/doc42.pdf">National Security Archive</a></figcaption></figure><p>After the end of the Cold War, rather than disbanding the Kaibiles, they were <a href="https://www.aljazeera.com/features/2011/8/15/guatemalas-feared-special-forces">repurposed</a> to fight the United States' new greatest threat to national security: drugs. According to a story from 2015 on the U.S. Special Operations Command (SOCOM) website, the 7th SFG continues training the Kaibiles.</p><figure><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-12.07.11-PM.png"><figcaption><a href="https://www.socom.mil/Pages/KaibilUSSpecialForcespromotesecuritythroughpartnership.aspx">U.S. SOCOM</a></figcaption></figure><p>According to <a href="https://web.archive.org/web/20201028120501/http://securityassistance.org/content/report-training-special-operations-forces">documents</a> obtained through Freedom of Information Act requests, from 2007 to 2014, U.S. SOF training <a href="https://www.wola.org/analysis/u-s-special-operations-latin-america-parallel-diplomacy/">tripled</a> in Latin America, mostly in the area of responsibility of U.S. SOUTHCOM (i.e. the Caribbean, Central and South America). The U.S. continues training with the Kaibiles to this day.</p><figure><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-1.03.23-PM.png"><figcaption>U.S. soldiers training with the Kaibiles <a href="https://www.dvidshub.net/image/5602004/us-soldiers-trek-through-jungles-with-guatemalan-special-forces">DVIDS</a></figcaption></figure><hr><p>In a <a href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a475840.pdf">2007 academic paper</a> on a model for command and control (C2) by the Special Operations Command - South (SOCSOUTH), the authors outlined a new distributed model for conducting the global war on terror in the area of responsibility (AOR) of the U.S. Southern Command (SOUTHCOM). The AOR of U.S. SOUTHCOM includes all of Central and South America and the Caribbean. According to the paper:</p><p><em>Conducting command and control in combat environments is very different from performing it in non-combat environments. One of the major differences between the two environments is the issue of â€œthe objective.â€� The mission objective will determine many aspects of the C2 structure. The [conventional] definition of C2 is well suited for the combat environment where objectives are clear and the USMC definition is better suited for counterinsurgency and non-combat environments, where the objectives are more ambivalent.</em></p><p><em>In standard military maneuver operations where missions such as â€œattack that position,â€� are clearly defined, the [conventional] definition of C2 is sufficient. However, in an ambiguous environment where SOF often operates, the mission (e.g., plan and execute UW [Unconventional Warfare]) is not as clearly defined. As a result, a special operator in the field must be able to operate with maximum authority, flexibility, and agility to respond to immediate changes emerging from dynamic situations. The USMC definition reflects precisely how SOCSOUTHâ€™s staff currently approaches C2 in its theater of operations.</em></p><p>â€¦</p><p><em>The leadership of Special Operations Command-South (SOCSOUTH) recently initiated a new concept for the command and control (C2) of its operations. This new concept, called distributive C2, seeks to improve speed, increase flexibility, facilitate interagency integration, and achieve innovation in a military staff bureaucracy.</em></p><hr><p>In a <a href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a491149.pdf">2008 academic paper</a> from the United State Marine Corps Command and Staff College at the Marine Corps University in Quantico, Virginia, Major Juan C. Arango described modern warfare from the perspective of the Colombian military. According to the Major:</p><p><em>The enemy's ability to disperse in small …</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://narco.news/unconventional-warfare-in-mexico">https://narco.news/unconventional-warfare-in-mexico</a></em></p>]]>
            </description>
            <link>https://narco.news/unconventional-warfare-in-mexico</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502435</guid>
            <pubDate>Tue, 22 Dec 2020 03:11:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Engineering Axioms]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25500815">thread link</a>) | @mnouquet
<br/>
December 21, 2020 | https://martinrue.com/my-engineering-axioms/ | <a href="https://web.archive.org/web/*/https://martinrue.com/my-engineering-axioms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <h3>My Engineering Axioms</h3>

            <p>A few months back I gave a talk in which I shared a list of my personal engineering axioms – things that, over the years, I've come to think of as generally true and useful to have in mind when writing code, building things, and working with others.</p>

            <p>Axiom is a fancy word, but popping a few layers off the etymology stack we arrive neatly at the ancient Greek word <a href="https://en.wiktionary.org/wiki/%E1%BC%80%CE%BE%CE%AF%CF%89%CE%BC%CE%B1">ἀξίωμα</a>, or "that which is thought fit or worthy". I like that, and consider each item on the list at least worthy of consideration.</p>

            <p>Of course they're <b>my</b> engineering axioms – things I believe to be useful based on my own experience. Your experience may well differ. Maybe you already knew about <a href="https://martinrue.com/zzuy-a-lesson-in-perseverance/">zero termination</a>, or have better tools than <a href="https://martinrue.com/give-yourself-more-playtime/">scissors to remove bugs</a> from your programs.</p>

            <p>In any case, I thought it would be fun to share the list here, with a few brief clarifications. Some things are pretty unsurprising, but hopefully others will generate some provocative thoughts and/or interesting disagreements.</p>

            <h4>1. Change is constant.</h4>

            <p>This one shouldn't be too controversial. Almost everything is always changing, including the rate of change itself. We need to acknowledge not only that our ability to respond to change is crucial, but that how well we do it (time, cost, quality, reliability) is often a dimension of our competitiveness.</p>

            <h4>2. Your product is an asset, but code is a liability.</h4>

            <p>Your product solves your customer's problem(s), and therefore is your asset. The code itself is the cost of creating the asset. The more code you have, the more it needs to be read, tested, changed, and understood. This is especially relevant when you consider axiom 1. Accept new code (and dependency on external code) conservatively. The best code is code you don't have to write.</p>

            <h4>3. Duplication is less costly than premature abstraction.</h4>

            <p>Until you have a high degree of confidence that your abstraction is going to pay for itself because it solves a real, abstract problem you really do have, don't do it. Wait and learn more. Until then, repeating code can help avoid dependency, which itself makes the code easier to change independently or delete. A premature abstraction creates complexity through dependency and indirection, and can become a bottleneck to your ability to respond to change.</p>

            <h4>4. Code should be easy to delete.</h4>

            <p>Write code to be removable, which in large part is the same as saying "decoupled". For sure not all code needs to be similarly removable, but minimising dependencies, having clear boundaries via well-defined interfaces, and having a thoughtful overall system design allows parts to be removed/changed more easily. I once heard someone use the expression "code spent", as an alternative to "code written" and I love that. I like the implication that removing code is reducing future cost.</p>

            <h4>5. Existing code exerts a powerful influence.</h4>

            <p>The very fact it's there suggests it's correct and necessary. Hopefully it is, but not always. We need to maintain both the confidence to change it, and the ability to reason about whether we should. Don't let the existence of code itself create doubt that it can't be removed. As per axiom 4, it should be easy to remove, and the system design should be good enough to enable us to understand whether we still need it.</p>

            <h4>6. Accidental complexity is one of the biggest risks.</h4>

            <p>Accidental complexity is complexity that can be avoided, and occurs due to things like poor design, bad decisions, and not prioritising an appropriate level of simplicity within a system. If simplicity is not a goal, accidental complexity is more likely to occur as a system grows, and will gradually negatively affect almost everything from changing the system to even being able to understand it. The 2006 paper <a href="http://curtclifton.net/papers/MoseleyMarks06a.pdf">Out of the Tar Pit</a> is a worthwhile read on this subject.</p>

            <h4>7. Technical excellence can be shadowed by bad personal skills.</h4>

            <p>Unless you're working completely alone, it's not just your ability to solve technical problems, to write good code, etc, that matters. To the contrary, they matter even less if you make the people around you unhappy and less productive. Just like learning to write good code, you have to learn "to people" good as well. Empathy is a big part of this, as is recognising that people are different – be caring, be understanding, help others and ask for help yourself, be nice. Be an engineer others want to work with.</p>

            <h4>8. You are not your code. Be kind to the coder, not to the code.</h4>

            <p>Code is merely a moment in time that captured what we thought we knew about something. It's not you. You may have wrote it, but since that moment (even if it was 3 minutes ago) you've grown, but the code has not. A conversation about code, good or bad, should never be personal. Keep it professional. Talk about the code, or about the problem, but don't make it about the person who wrote it. Use "we" instead of "you". Sometimes I try to pretend I wrote the code someone else wrote, which helps me avoid accidentally sounding personal.</p>

            <h4>9. Treat people who know less than you with respect and patience.</h4>

            <p>We all start somewhere, and the journey is a lot more joyful when you're surrounded by patient people who want you to succeed, rather than those who make you feel like you don't belong. If you struggle with this, it may be helpful to remember that the newbie programmer almost certainly does something better than you do – perhaps they're fluent in another language, or cook amazingly, or play a sport. Just imagine yourself in the reverse role. How would you like them to treat you, the total newbie? Again: be an engineer others want to work with.</p>

            <h4>10. The only true authority stems from knowledge, not from position.</h4>

            <p>Knowledge and understanding of the problem, the domain, the customer, are all far more important than whatever the first 3 letters on your business card are. <a href="https://youtu.be/cISYzA36-ZY?t=85">Even if it does have a watermark</a>. Understand how something works from first principles, build a solid understanding, and authority will follow.</p>

            <h4>11. Teaching is a form of learning in disguise.</h4>

            <p>If you think you know something, try teaching it. Often the very act of trying to explain what you know to someone else forces you to formalise your own thoughts much more clearly. Writing things down seems to have a similar effect. I've lost count of the number of times I've begun explaining something only to find I don't quite understand it as well as I thought.</p>

            <h4>12. Lift the skills of people around you, not just yourself.</h4>

            <p>A great team is never a great because of one amazing person. It's a great team because everyone challenges each other and everybody grows together. When you learn something cool, share it – help the people around you get better. As they do the same, everybody benefits and nobody gets left behind. It's also far more fun. Secondary benefit: axiom 11.</p>

            <h4>13. The longer you wait the more you'll know.</h4>

            <p>I'm still learning this and trying hard to avoid my almost default desire to decide quickly. The truth is, the longer you delay non-essential decisions the more information you'll have to lean on when the time comes to make it. Of course you can't always procrastinate a decision, but often you can, and as a minimum you should at least consider whether not knowing the answer right now is actually OK.</p>

            <h4>14. A good type system is worth its weight plus some.</h4>

            <p>Having gone backwards and forwards through various static and dynamic languages over my career, I'm currently of the opinion that a good type system is worth its overhead. A good type system shouldn't carry all that much overhead. If the type system is designed well, it can almost feel like a dynamic language (via features like inference and flow analysis) while removing a whole class of issues that the compiler can handle far better and quicker than you can. Developments like ownership in Rust are a nice example of how this has gone even further than people would have imagined years back.</p>

            <h4>15. The right team of people trumps everything else.</h4>

            <p>Having a team of people who just want to work together and build great things makes a lot of other problems easier to deal with. The word "right" here is highly subjective and contextual, but at least anecdotally, empathy, respect, and friendship have been recurring elements of great teams I've been part of.</p>

            <h4>16. Stick to boring technology, unless there's a good reason not to.</h4>

            <p>Boring tech is often older and better understood. There's battle-hardened experience of how to use it effectively, better understanding of its failure modes, and it's easier to find people and resources on how to best apply it. I really like Dan McKinley's idea of <a href="https://mcfunley.com/choose-boring-technology">innovation tokens</a>. You only get 3. Use them to adopt or build brand new stuff – ideally stuff that will make you better at your core competency – but any more than 3 and the risk of never reaching stability/maturity starts to grow.</p>

            <h4>17. Have the smallest team possible, but no smaller. Grow it carefully.</h4>

            <p>A play on a well-known quote, and your mileage may vary on this one. In my career so far, I've reliably seen smaller teams be more effective than larger ones. There's a balance to be found, for sure, which depends on the magnitude and complexity of the problem you're solving. That said, smaller teams benefit from less communication overhead, less room for miscommunication, and more space for everyone's voice to be heard. In a smaller team, it also feels more personal, and I feel more responsible, and I like that.</p>

            <h4>18. Rest.</h4>

            <p>I'm happy to see the gradual de-sexification of …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://martinrue.com/my-engineering-axioms/">https://martinrue.com/my-engineering-axioms/</a></em></p>]]>
            </description>
            <link>https://martinrue.com/my-engineering-axioms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500815</guid>
            <pubDate>Mon, 21 Dec 2020 23:08:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write code. Not too much. Mostly functions.]]>
            </title>
            <description>
<![CDATA[
Score 619 | Comments 260 (<a href="https://news.ycombinator.com/item?id=25500671">thread link</a>) | @brundolf
<br/>
December 21, 2020 | https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>There's a well-known quote by author <a href="https://en.wikipedia.org/wiki/Michael_Pollan">Michael Pollan</a>:
        "Eat food. Not too much. Mostly plants." I like it because it doesn't
        attempt to be dogmatic: it encapsulates some basic guiding principles that get
        you 90% of the way there 90% of the time. Wikipedia describes the book the quote
        is from (emphasis mine):</p>
      <blockquote>
        <p>He explains...the notion that nutritionism and, therefore, the whole Western
          framework through which we intellectualize the value of food <strong>is more a religious
and faddish devotion to the mythology of simple solutions than a convincing and
reliable conclusion of incontrovertible scientific research</strong>.</p>
      </blockquote>
      <p>That...sounds familiar.</p>
      <h2 id="write-code">Write code </h2>
      <p>Code, like food, has value. I think those of us who write it can (hopefully)
        agree on that. Some, though, are so afraid of writing/eating
        <em>too much</em> that they avoid writing/eating what they should.</p>
      <p>In the context of programming, I think this translates to an unhealthy fear
        (again, for some) of duplication. A little bit of duplication - writing
        something in a way that doesn't completely maximize conciseness - isn't the end
        of the world. Sometimes it's the best path forward. Sometimes it's okay to
        copy-and-modify here and there, especially when you're still figuring out what
        your application will end up being.</p>
      <h2 id="not-too-much">Not too much </h2>
      <p>Of course too much code, like too much food, can also be a bad thing. This is
        a well-trodden topic so I don't feel the need to go too far into it here.</p>
      <p>Just be aware of your project's "appetite": write what needs to be written,
        and then try not to over-indulge.</p>
      <h2 id="mostly-functions">Mostly functions </h2>
      <p>By "functions" here I mean "pure functions". You could make a case that pure
        functions aren't the "plants" of code, though I feel
        that they are. In my experience most codebases have a pure functional
        subset, and I believe writing that subset in a pure-functional style is nearly
        always a win for the long-term health of the project.</p>
      <p>Of course the qualifier is "mostly": this isn't a dogma. Writing a 100%
        functional system ("going vegan", if you will) often requires you to jump
        through a bunch of extra hoops to get all the functionality you need. Looking
        at it solely from the perspective of health, those extra complications may not
        be worth it.</p>
      <p>And then different projects have different needs: just as an athlete may need
        a larger percentage of protein, or individuals may have certain nutrient
        deficiencies, a project may only have a very small functional subset, or may not
        be able to afford to return new values each time due to data size or
        performance-sensitivity. There's nothing wrong with that.</p>
      <h2 id="%22real-code%22">"Real code" </h2>
      <p>Pollan later qualifies his snappy statement a bit further:</p>
      <blockquote>
        <p>He contends that most of what Americans now buy in supermarkets, fast food
          stores, and restaurants is not in fact food, and that a practical tip is to eat
          only those things that people of his grandmother's generation would have
          recognized as food.</p>
      </blockquote>
      <p>At the risk of stretching the analogy, maybe the equivalent is
        "code only those things that people at a junior level would recognize for what
        they do". Code in simple, straightforward terms. Don't get too clever,
        "manufacturing artificial ingredients". Use the primitives that are there, when
        possible. Write what is simple, and natural, and human.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500671</guid>
            <pubDate>Mon, 21 Dec 2020 22:53:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuck Amazon Vine]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25500255">thread link</a>) | @fivedogit
<br/>
December 21, 2020 | https://thingamagig.com/vine/WhyAmazonVineSucks.html?x=3 | <a href="https://web.archive.org/web/*/https://thingamagig.com/vine/WhyAmazonVineSucks.html?x=3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thingamagig.com/vine/WhyAmazonVineSucks.html?x=3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500255</guid>
            <pubDate>Mon, 21 Dec 2020 22:13:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Be a 10x Developer]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25498696">thread link</a>) | @mooreds
<br/>
December 21, 2020 | https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/ | <a href="https://web.archive.org/web/*/https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><span><span>Reading Time: </span> <span>13</span> <span>minutes</span></span></p><p>It’s not a clickbait title, but I understand why it looks that way.</p>



<p>I’ve made my thoughts about the 10x developer trope <a href="https://chelseatroy.com/2019/12/06/listening-7-deliberate-appreciation/">extremely clear</a>. I think that someone who produces 10x as much code as someone else has left a wake of destruction that will slow down other developers. I don’t think 10x counts if you achieve it by slowing down everyone else. I think 10x has to take into account how you impact other people.</p>



<p>And <em>that,</em> paradoxically, suggests a path for how to become a 10x developer: empower and enable other people such that nine additional developers’ worth of work gets done. You can do that by making nine other developers’ workflows 2x smoother. You can also do that by making 18 other developers’ workflows 50% smoother, or 90 other developers’ workflows 10% smoother.</p>



<div><figure><a href="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?ssl=1"><img data-attachment-id="8295" data-permalink="https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/screen-shot-2020-12-18-at-12-53-49-am/" data-orig-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?fit=1200%2C1202&amp;ssl=1" data-orig-size="1200,1202" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-12-18 at 12.53.49 AM" data-image-description="" data-medium-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?fit=723%2C724&amp;ssl=1" loading="lazy" src="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=310%2C310&amp;ssl=1" alt="owl holding a red leaf in its beak" width="310" height="310" srcset="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?w=1200&amp;ssl=1 1200w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=1022%2C1024&amp;ssl=1 1022w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=768%2C769&amp;ssl=1 768w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=450%2C450&amp;ssl=1 450w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=60%2C60&amp;ssl=1 60w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=550%2C550&amp;ssl=1 550w" sizes="(max-width: 310px) 100vw, 310px" data-recalc-dims="1"></a><figcaption>PC @templephotobetsy on Instagram</figcaption></figure></div>



<p>At some point, your biggest gains in your X are gonna be in improving the ecosystem for other developers. On occasions when I have succeeded at that, from <a href="https://chelseatroy.com/2018/02/25/how-to-socialize-big-changes-at-work-part-1-start-at-the-grassroots-level/">driving workplace changes</a> to <a href="https://chelseatroy.com/category/teaching/">teaching computer science classes</a>, I have noticed that I’m using one or more of three techniques. So I thought I’d list them here.</p>



<h3>First, establish the motivation.</h3>



<p>Learning is work. Sometimes, it’s boring or difficult work. Folks don’t undertake that kind of work unless they understand why they should. That’s not as simple as <em>telling</em> them why. Understanding comes from engaging with the material.</p>



<p>Suppose you want to make a major code change that affects your team’s workflow. If you blaze forward and do that without buy-in, the team will resent it (<a href="https://chelseatroy.com/2018/02/25/how-to-socialize-big-changes-at-work-part-1-start-at-the-grassroots-level/">as we’ve discussed in more detail here</a>). So I recommend starting with individual conversations about the reasons for the change:</p>



<blockquote><p><span>What is bothering you about your team’s current workflow that motivates you to push your solution? Are you annoyed at having to write the same code over and over in different places? Are you tired of trying to poke your way around an opaque tool? Are you losing track of things that cost you time and money? Before you&nbsp;</span><em>push</em><span>&nbsp;your solution,&nbsp;</span><em>pull</em><span>&nbsp;your coworkers to it by making sure they feel the pain that you feel.</span></p><p>Before I do a major refactor, I’ll deliberately pair program with key people on my team on the kind of problems that my refactor would solve. I want them to experience the pain firsthand; I want to hear them say ‘oh my&nbsp;<em>god&nbsp;</em>this is annoying.’ After I have that admission of pain from a critical mass of people on my team, I’ll propose my solution, and I’ll offer to spearhead the refactor. I will craft a concise explanation of how our workflow changes after the refactor, and I’ll point out why I think the new way is nicer for us than the way we’re doing it now.&nbsp;&nbsp;I have ‘negative testimonials’ about the old way, which I can whip out to capture the attention and agreement of others on my team. This approach allows me to muster support for my refactor and then, in spearheading the refactor, look like I’m taking one for the team.</p><p>Imagine the same scenario, same refactor, but instead of socializing my solution, I go off on my own, do the refactor, and push. My team didn’t understand the pain that the refactor solved, so all they’re seeing is the pain of learning the&nbsp;<em>new</em>&nbsp;way to do things. To them, it looks like I made a unilateral decision that screwed them over—the&nbsp;<em>opposite</em>&nbsp;of what a team player would do. Keep in mind, in both circumstances, I wrote the&nbsp;<em>same code</em>. The only difference is how I introduced it.</p></blockquote>



<p>In effect, even the right code changes need to be <em>sold</em>. </p>



<p>How do we know what the right code changes are? This one is tricky, but one guiding principle has helped me out a lot:</p>



<h3>Look for bonehead solutions to convoluted technical issues.</h3>



<p>Michael Feathers talks a great deal about technical simplification options in his various discussions on edge-free programming (<a href="https://chelseatroy.com/2020/05/28/lessons-from-space-edge-free-programming/">here’s a more detailed look at some of those principles)</a>. But for exemplary purposes, here are a few simple solutions to complex problems that I’m especially proud of:</p>



<ul><li>I solved a thorny issue with a sometimes camouflaged, sometimes unreliable delete button by ripping it out (<a href="https://github.com/zooniverse/mobile/pull/345">Here’s the PR if you want more details</a>)</li><li>I resolved the issue of a laggy metronome in React-Native, where computationally expensive operations can result in delays for scheduled tasks. The app happened to also need to play back tracks at various multiples of their original speed. So I recorded a sound file of a metronome at 120 BPM, calculated what speed to play it by dividing the BPM the musician requested by 120, and wrote one method that shelled out to <code>expo-av</code> to play accurate-to-tempo sound files for both the metronome and the backtracks.</li><li>I resolved an issue of regulating how often a person should be allowed to log their mood by realizing the issue was fake (assumed foil to “let’s make sure they log it at least this often”) and letting them log as often as they want (<a href="https://chelseatroy.com/2020/05/28/lessons-from-space-edge-free-programming/">more details here</a>).</li></ul>



<p>Each of these solutions made the code cleaner and eliminated<em> </em>multiple problems with the product. But they were not genius solutions. In fact, they were easy to miss precisely because complex problems don’t scream “I have a bonehead solution.”</p>


	
	


<p><strong>One drawback: </strong>the tech industry generally rewards churning out tons of code <em>over</em> elegant solutions. Chen Lin recently <a href="https://twitter.com/votecapgood/status/1337920511095918592">tweeted about</a> his experience with this at Uber. Chen is responding to <a href="https://twitter.com/mountain_ghosts/status/1337552024821510144">this commentary</a>, which starts out salty but goes on to articulate a rarely-discussed element of how the tech industry functions: tech executives <em>have</em> to make their work appear innovative in order to secure VC funding. So they’re forced to artificially “make it innovative” by filing patents or hopping on the latest trends. In the case of Uber and iOS development, that imperative <a href="https://twitter.com/StanTwinB/status/1336890442768547845">burned them badly</a>.</p>



<p>Academia is similar: <a href="https://www.mccormick.northwestern.edu/research-faculty/directory/affiliated/watt-jeremy.html">Dr. Jeremy Watt</a>, author of <em><a href="https://github.com/jermwatt/machine_learning_refined">Machine Learning Refined</a></em>, articulates how academics <em>have</em> to make their work appear novel in order to get published, and they have to get published to keep their jobs, so they’re forced to artificially differentiate similar concepts—to convolute rather than simplify.</p>



<p>There’s a great <a href="https://twitter.com/mekkaokereke/status/1027552576454021120">explanation from Mekka Okereke</a> about how to counteract some of this as an engineer. It shares a lot with our “first establish the motivation” approach—namely, by starting from the <em>problem</em>, not the solution.</p>



<p><strong>Also, a giant caveat: </strong>This solution is not always there. Sometimes the solution just has to be clever, or complicated, or messy. Sadly I can’t give you an ironclad heuristic for how to find them or how to confirm their existence. I can tell you this: in most cases where I have found them, I have found them by popping <em>up</em> a level from the implementation level to the design level. </p>



<p>Also, this recommendation applies specifically to technical solutions: it does not apply, for example, to racism or fascism. The problems we’re talking about here are de facto circumscribed by the scope of an application. When we’re talking about a generational cultural, political, and structural phenomenon, “just rip out X” doesn’t work.</p>


	<div>
		<figure>
							
										<figcaption>Nor does one simply solve [insert insidious social issue here].</figcaption>
					</figure>
	</div>
	


<p>White supremacy culture in tech alone is so insidious and multifaceted that I’ve got <a href="https://chelseatroy.com/2020/02/07/the-price-of-whiteness-in-tech/">an ongoing series</a> about reimagining different parts of tech through a not-white-supremacist lens. But also, listen to <a href="https://twitter.com/polotek/status/1249908489826099201">Marco Rogers about this caveat</a>. He knows more things than I do.</p>



<p>ANYWAY, anyway, anyway. </p>



<p>So we’ve talked about selling our changes, and we’ve talked about making changes that reduce the scope of complexity. Naturally, the third thing I find myself doing, is selling new knowledge <em>by</em> reducing the scope of complexity. Here we go:</p>



<h3>Try to spread intuition with as few prerequisites as possible.</h3>



<p>One of my Mobile Software Development students asked me what frameworks he should consider for testing a Python app he’s working on. Here’s what I said:</p>



<blockquote><div><p>In Python there are two leading options: unittest and pytest. Both work fine. When I’m working on teams, I tend to go with pytest because the output is a little nicer.&nbsp;</p><p>But…when I’m&nbsp;<em>teaching</em>&nbsp;Python, I don’t use a testing framework at all. I write methods that call the method I’m testing, and then I use Python’s&nbsp;<a rel="noreferrer noopener" href="https://www.w3schools.com/python/ref_keyword_assert.asp" target="_blank">built in assert keyword</a>&nbsp;to check the state of the modified objects or return values. Reason being, I don’t want to jump into the complexity of all the different stuff you can use to test until students understand&nbsp;<em>why</em>&nbsp;we test. I try to use the minimum toolset that gets the point across.</p></div></blockquote>



<p><br>One of the big things that educational approaches manage to screw up, in my view, is to introduce prerequisites that make the topic in question <em>harder</em> instead of <em>easier</em>. Fluent Forever founder Gabriel Wyner <a href="https://youtu.be/bPVeIHcgfTs?t=74">articulates how language learning often depends on translation</a>—which is a whole, separate, <em>difficult</em> skill. So when I’m trying to help someone build intuition, I’ll try to eliminate as many dependencies as possible. </p>



<p>I’ll show you an example for teaching testing in Python. I pulled this example out of a notebook that I share with my <a href="https://www.emergentworks.org/">Emergent Works</a> and <a href="https://centerforjustice.columbia.edu/justicethroughcode">Justice Through Code</a> mentee. She was working on writing a Sudoku solver. Of course, to solve a Sudoku, it helps to know when a Sudoku is solved. </p>



<p>Suppose we start with a similar but simpler puzzle; each row and each column must each possess one copy of each number, like this:</p>



<pre><code>puzzle = [
    [1, 2, 3, 4],
    [2, 1, 4, 3],
    [3, 4, 1, 2],
    [4, 3, 2, 1],
]</code></pre>



<p>This is a valid puzzle, albeit smaller than your typical 9 x 9. </p>



<p>It shows a way of <em>representing</em> our problem space—a list of lists. We could make a <code>Puzzle </code>class for this, with all kinds of methods on it. I’m not doing that yet. I’m doing the <em>minimum thing</em> that gets the point across: we need a way to represent our data. Here is a way to represent our data with minimal dependencies and indirection. </p>



<p>We’re gonna do the same thing for the test, no test framework involved (yet!):</p>



<pre><code>def valid_puzzle(puzzle):
    try: 
        # Python is duck-typed, so …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/">https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/</a></em></p>]]>
            </description>
            <link>https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25498696</guid>
            <pubDate>Mon, 21 Dec 2020 19:49:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing JSON at the CLI: A Practical Introduction to jq and more]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25498364">thread link</a>) | @sequoia
<br/>
December 21, 2020 | https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/ | <a href="https://web.archive.org/web/*/https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><p><code>jq</code> is a command line tool for parsing and modifying JSON. It is useful for extracting relevant bits of information from tools that output JSON, or REST APIs that return JSON. Mac users can install <code>jq</code> using homebrew (<code>brew install jq</code>); see <a href="https://stedolan.github.io/jq/download/">here</a> for more install options.</p>
<p>In this post we'll examine a couple "real world" examples of using <code>jq</code>, but let's start with...</p>
<h2 id="-code-jq-code-basics">
    <a href="#-code-jq-code-basics">
      
    </a>
    <code>jq</code> Basics</h2><p>The most basic use is just tidying &amp; pretty-printing your JSON:</p>
<pre><code>$ USERX=<span>'{"name":"duchess","city":"Toronto","orders":[{"id":"x","qty":10},{"id":"y","qty":15}]}'</span>
$ <span>echo</span> <span>$USERX</span> | jq <span>'.'</span>
</code></pre>
<p>outputs</p>
<pre><code>{
  <span>"name"</span>: <span>"duchess"</span>,
  <span>"city"</span>: <span>"Toronto"</span>,
  <span>"orders"</span>: [
    {
      <span>"id"</span>: <span>"x"</span>,
      <span>"qty"</span>: <span>10</span>
    },
    {
      <span>"id"</span>: <span>"y"</span>,
      <span>"qty"</span>: <span>15</span>
    }
  ]
}
</code></pre>
<p>I like this pretty-printing/formatting capability so much, I have an alias that formats JSON I've copied (in my OS "clipboard") &amp; puts it back in my clipboard:</p>
<pre><code><span>alias</span> jsontidy=<span>"pbpaste | jq '.' | pbcopy"</span>
</code></pre>
<p>The <code>'.'</code> in the <code>jq '.'</code> command above is the simplest jq "filter." The dot takes the input JSON and outputs it as is. You can read more about filters <a href="https://stedolan.github.io/jq/manual/#Basicfilters">here</a>, but the bare minimum to know is that <code>.keyname</code> will filter the result to a property matching that key, and <code>[index]</code> will match an array value at that index:</p>
<pre><code>$ <span>echo</span> <span>$USERX</span> | jq <span>'.name'</span>
<span>"duchess"</span>
$ <span>echo</span> <span>$USERX</span> | jq <span>'.orders[0]'</span>
{
  <span>"id"</span>: <span>"x"</span>,
  <span>"qty"</span>: 10
}
</code></pre>
<p>And <code>[]</code> will match <em>each</em> item in an array:</p>
<pre><code><span>echo</span> <span>$USERX</span> | jq <span>'.orders[].id'</span>
<span>"x"</span>
<span>"y"</span>
</code></pre>
<p>Filtering output by value is also handy! Here we use <code>|</code> to output the result of one filter into the input of another filter and <code>select(.qty&gt;10)</code> to select only orders with <code>qty</code> value greater than 10:</p>
<pre><code><span>echo</span> <span>$USERX</span> | jq <span>'.orders[]|select(.qty&gt;10)'</span>
{
  <span>"id"</span>: <span>"y"</span>,
  <span>"qty"</span>: 15
}
</code></pre>
<p>One more trick: filtering by <strong>key</strong> name rather than value:</p>
<pre><code>$ ORDER=<span>'{"user_id":123,"user_name":"duchess","order_id":456,"order_status":"sent","vendor_id":789,"vendor_name":"Abe Books"}'</span>
$ <span>echo</span> <span>$ORDER</span> | jq <span>'.'</span>
{
  <span>"user_id"</span>: 123,
  <span>"user_name"</span>: <span>"duchess"</span>,
  <span>"order_id"</span>: 456,
  <span>"order_status"</span>: <span>"sent"</span>,
  <span>"vendor_id"</span>: 789,
  <span>"vendor_name"</span>: <span>"Abe Books"</span>
}
$ <span>echo</span> <span>$ORDER</span> | jq <span>'with_entries(select(.key|match("order_")))'</span>
{
  <span>"order_id"</span>: 456,
  <span>"order_status"</span>: <span>"sent"</span>
}
</code></pre>
<p>(cheat sheet version: <code>with_entries(select(.key|match("KEY FILTER VALUE")))</code>)</p>
<p>Check out <a href="#more-resources">more resources</a> below to learn about other stuff jq can do!</p>
<h2 id="a-usecase-debugging-some-prometheus-metrics">
    <a href="#a-usecase-debugging-some-prometheus-metrics">
      
    </a>
    A Usecase: Debugging Some Prometheus Metrics</h2><p>I have a prometheus metric showing up locally that doesn't look quite right:</p>
<pre><code>async_task_total{task_name="/Users/duchess/charmoffensive/toodle-app/pkg/web/page/globals.go(189):(*GlobalsPopulator).Populate"} 6
</code></pre>
<p>The fact that the <code>task_name</code> value is a <em>filename</em> is a red flag–<a href="https://prometheus.io/docs/practices/naming/#labels">it's bad to have labels with high cardinality</a> and I'm not sure how many of these there are. I want to find out:</p>
<ol>
<li>What do these <code>task_name</code> labels look like in production?</li>
<li>How many unique values are there for these labels?</li>
</ol>
<h3 id="1-getting-the-label-values-in-production">
    <a href="#1-getting-the-label-values-in-production">
      
    </a>
    1. Getting the label values in production</h3><p>At my company there is a <abbr title="Command Line Interface">CLI</abbr> tool we'll call <code>pquery</code> that allows prometheus metrics to be queried from the command line, and it outputs JSON–how conventient! I use this tool in the following examples. You don't have this tool, but fear not: <a href="https://learndevops.substack.com/p/hitting-prometheus-api-with-curl">this wonderful post</a> explains how to query prometheus using <a href="https://curl.se/">curl</a> which is essentially what <code>pquery</code> does.</p>
<p>Using <code>pquery</code> we can view prometheus metrics from our various clusters. But even if we filter for this exact metric name, it's more data than we can easily look at. We'll use <code>wc -l</code> (wordcount: count lines) to get a rough idea of how much data we're working with:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | wc <span>-l</span>
316117
</code></pre>
<p>316,117 lines of JSON! Oof! We want to iterate over the metrics. But what jq filter do we need to access the array of metrics? I find <code>head</code> useful for figuring out what the top level keys are for a large json structure:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | head -n 20
{
    <span>"data"</span>: {
        <span>"result"</span>: [
            {
                <span>"metric"</span>: {
                    <span>"__name__"</span>: <span>"async_task_total"</span>,
                    <span>"app"</span>: <span>"toodle-app-alpha"</span>,
                    <span>"instance"</span>: <span>"10.55.55.55:9393"</span>,
                    <span>"job"</span>: <span>"toodle-app-alpha"</span>,
                    <span>"kubernetes_pod_name"</span>: <span>"toodle-app-b446b7ccd-6mls6"</span>,
                    <span>"namespace"</span>: <span>"noweb"</span>,
                    <span>"netpol"</span>: <span>"toodle-app"</span>,
                    <span>"node_name"</span>: <span>"gke-production-04-3455c6df-j526"</span>,
                    <span>"release"</span>: <span>"toodle-app"</span>,
                    <span>"task_name"</span>: <span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
                },
                <span>"value"</span>: [
                    1600981630.344,
                    <span>"2"</span>
</code></pre>
<p>You can also use <code>jq 'keys'</code> if you just want the key names:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | jq <span>'keys'</span>
[
  <span>"data"</span>,
  <span>"status"</span>
]
</code></pre>
<p>Anyway we can see from above that <code>.data.result</code> is the "filter" path for the metrics themselves. Let's get the <strong>first result</strong> (<code>[0]</code>) of this array so we can see what one metric looks like:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | jq <span>'.data.result[0]'</span>
{
  <span>"metric"</span>: {
    <span>"__name__"</span>: <span>"async_task_total"</span>,
    <span>"app"</span>: <span>"toodle-app-alpha"</span>,
    <span>"instance"</span>: <span>"10.55.55.55:9393"</span>,
    <span>"job"</span>: <span>"toodle-app-alpha"</span>,
    <span>"kubernetes_pod_name"</span>: <span>"toodle-app-b446b7ccd-6mls6"</span>,
    <span>"namespace"</span>: <span>"noweb"</span>,
    <span>"netpol"</span>: <span>"toodle-app"</span>,
    <span>"node_name"</span>: <span>"gke-production-04-3455c6df-j526"</span>,
    <span>"release"</span>: <span>"toodle-app"</span>,
    <span>"task_name"</span>: <span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
  },
  <span>"value"</span>: [
    1600981906.069,
    <span>"2"</span>
  ]
}
</code></pre>
<p>Oops! That <code>app</code> value (<code>toodle-app-alpha</code>) indicates a mistake: I'm only interested in results from the <code>toodle-app</code> app, <em>not</em> from other apps that may also emit this metric (such as the <code>alpha</code> deployment we see here). We could <code>select</code> for this using jq, but <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/"><code>promql</code> already lets us filter by metric names</a> so we'll do that instead: <code>pquery 'async_task_total{app="toodle-app"}'</code>.</p>
<p>We're interested in the <code>task_name</code> value in the <code>metric</code> object, so let's pluck that from <strong>each</strong> item in the array above:</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(122):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(132):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(73):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(160):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(166):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(172):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(140):(*areaCategoryView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(146):(*areaCategoryView).fetchData"</span>
{... + 18009 more lines}
</code></pre>
<blockquote>
<p>📝 Update: It was pointed out to me that as this is a post about <code>jq</code>, not about <code>promql</code>, a <code>jq</code> solution is more appropriate here. I'd originally used promql because it's more efficient to filter on the server when possible. Here's the <code>jq</code> version which uses the <a href="https://stedolan.github.io/jq/manual/#select(boolean_expression)"><code>select</code> filter</a>:</p>
<pre><code>$ pquery <span>'async_task_total'</span> \
| jq <span>'.data.result[].metric | select(.app == "toodle-app").task_name'</span>
</code></pre>
<p>Back to the post...</p>
</blockquote>
<p>Eighteen thousand values for that label!? That's bad!! But wait a tic–if other labels are varying, some of these may actually be duplicates. Let's sort them and see:</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | head -n10
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
</code></pre>
<p>Yep: most of these are actually not unique names. <code>uniq</code> to the rescue!</p>
<pre><code>$  pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | uniq
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(122):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(132):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(73):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(160):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(166):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(172):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(140):(*areaCategoryView).fetchData"</span>
{... more}
</code></pre>
<p>Now I've got a full list of all the <em>distinct</em> values for this label, which answers my first question.</p>
<h3 id="how-many-unique-values-are-there-for-these-labels-">
    <a href="#how-many-unique-values-are-there-for-these-labels-">
      
    </a>
    How many unique values are there for these labels?</h3><p>Well that's pretty easy at this point...</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | uniq | wc <span>-l</span>
92
</code></pre>
<p>Ninety-two! Not so bad. Mystery solved, and I can say with reasonable confidence "the cardinality of these labels isn't terribly high, I'm …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/">https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/</a></em></p>]]>
            </description>
            <link>https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25498364</guid>
            <pubDate>Mon, 21 Dec 2020 19:22:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I rewrote a Clojure tool in Rust]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25497050">thread link</a>) | @praveenperera
<br/>
December 21, 2020 | https://timofreiberg.github.io/clojure-vs-rust/ | <a href="https://web.archive.org/web/*/https://timofreiberg.github.io/clojure-vs-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            
<p>2020-12-20</p>


<p>About two years ago, I wrote a quite complicated diff tool in Clojure.<br>
It was complicated enough that I struggled to fit the algorithm in my head and the inputs were large enough that I had to make some efforts to improve performance.</p>
<p>About half a year later, I started learning Rust, ported the current state of the Clojure program into Rust, was very happy with the change<sup><a href="#hooked-on-rust">1</a></sup> and continued exclusively with Rust.<br>
While working on that project, I've developed some opinions about the two languages, especially about error handling and performance:</p>
<p>I think that these are areas where Rust excels, while they are among the weaker spots of Clojure<sup><a href="#not-hating-on-clojure">2</a></sup>.</p>
<p>To put my experience in context:
I had a bit more than one year of experience in Clojure when I moved to Rust.
The diff tool was by far the largest Clojure program I've ever written, and it was only about 3000 lines.<br>
When I started writing Rust, reimplementing the existing Clojure code was among my first Rust code.
I've continued learning Rust since then and have mostly stopped writing Clojure.<br>
If things have changed in Clojure recently, please let me know and I'll update the article.</p>
<h2 id="error-handling"><a href="#error-handling" aria-label="Anchor link for: error-handling">🔗</a>Error Handling</h2>
<p>The error handling requirements in this project were not very complicated.
All errors just needed to be logged and returned to the user.<br>
The only slightly unusual requirement was that parsing and validation logic should show all errors for each row in both uploaded excel files
(instead of just the first error) so I had to accumulate errors.</p>
<h3 id="error-handling-in-clojure"><a href="#error-handling-in-clojure" aria-label="Anchor link for: error-handling-in-clojure">🔗</a>Error Handling in Clojure</h3>
<p>Error handling in Clojure is not opinionated.<br>
<a href="https://lispcast.com/clojure-error-messages-accidental/">Similar to error messages</a>
, what error handling idioms exist in Clojure seem to me to be largely accidental or inherited from Java.</p>
<p>The standard library mostly supports <a href="https://clojuredocs.org/clojure.core/ex-info">exceptions</a>.<br>
There are some libraries that support returning error values instead of throwing exceptions like the error handling library <a href="https://github.com/adambard/failjure"><code>failjure</code></a>.<br>
Others, like the parsing library <a href="https://github.com/Engelberg/instaparse"><code>instaparse</code></a>, return their own custom error values<sup><a href="#insta-result">3</a></sup>.</p>
<p>I used failjure to help accumulate errors in a nicer way (and because it appealed to my Haskell-influenced taste).</p>
<p>Let's look at a Clojure function from my diff tool that uses <a href="https://github.com/adambard/failjure#attempt-all">attempt-all</a> to parse and validate the input data.
If any errors occur, all errors are aggregated into a string:</p>
<pre><code><span>(</span><span>defn </span><span>parse
  </span><span>[country-mapping data]
  #_"</span><span>   👇 the attempt-all function exits early 
           if any binding returned a failure</span><span>"
  (</span><span>fail/attempt-all
   </span><span>[headers (</span><span>header-row</span><span> data)
    parsed (</span><span>map
             </span><span>#(</span><span>parse-rule</span><span> headers country-mapping %)
             (</span><span>content-rows</span><span> data))
    #_"</span><span>           👇 list of failures is aggregated here</span><span>"
    failed-parses (</span><span>-&gt;&gt;</span><span> parsed
                    (</span><span>filter</span><span> fail/failed?)
                    (</span><span>map</span><span> fail/message))
    #_"</span><span>          👇 this can return a failure,
                    triggering an early exit</span><span>"
    parse-result (</span><span>if </span><span>(</span><span>empty?</span><span> failed-parses)
                   parsed
                   #_"</span><span>👇 a single failure value containing the
                         list of failures concatenated into a string</span><span>"
                   (</span><span>fail/fail
                    </span><span>(</span><span>let </span><span>[msg (</span><span>str
                               </span><span>"</span><span>Failed to parse </span><span>"
                               (</span><span>count</span><span> failed-parses)
                               "</span><span> rules:</span><span>")]
                      (</span><span>str</span><span> msg "</span><span>\n</span><span>" failed-parses))))
    #_"</span><span>          👇 This can also return a failure</span><span>"
    spec-result (</span><span>util/check-specs </span><span>"</span><span>Rules</span><span>"
                                  </span><span>:rule/id
                                  ::spec/rule</span><span>
                                  parse-result)]
   #_"</span><span>👇 if everything was successful, this is returned</span><span>"
   spec-result
   #_"</span><span>👇 if any failure occurred, this is returned</span><span>"
   (</span><span>fail/when-failed </span><span>[failure]
                       (</span><span>do
                         </span><span>(</span><span>log/warn
                           </span><span>(</span><span>str </span><span>"</span><span>Failed to parse data </span><span>"
                             data "</span><span>:</span><span>\n</span><span>" (</span><span>fail/message</span><span> failure)))
                         failure))))
</span></code></pre>
<p>Nice things about this:</p>
<ul>
<li>The identifier-expression pairs in the square brackets use the same syntax as Clojure's <a href="https://clojuredocs.org/clojure.core/let"><code>let</code>-form</a>
which makes it look familiar.</li>
<li>I can optionally add an error handling function to the very end, which is helpful to, e.g., log the argument of the function, as I did here.</li>
</ul>
<p>Not so nice things about this:</p>
<ul>
<li>I can't see which functions can actually fail. I have to read them to find out.</li>
<li>Since the Clojure ecosystem doesn't have a uniform error handling style, I have to manually convert exceptions or other errors like <code>instaparse</code> error values to <code>failjure</code> errors.</li>
</ul>
<p>My verdict is:<br>
Since Clojure is a Lisp, it's possible to use most kinds of error handling and make it look fine, if you really want to.
The most pragmatic solution in most cases will be to use exceptions.</p>
<p>I found that readability could suffer when using less explicit error handling, especially in a dynamic language.</p>
<p>Due to the freedom of choice in error handling approacher, I was tempted to experiment more than with a more opinionated language.</p>
<h3 id="error-handling-in-rust"><a href="#error-handling-in-rust" aria-label="Anchor link for: error-handling-in-rust">🔗</a>Error handling in Rust</h3>
<p>Rust is quite opinionated about error handling.
The Rust community has worked on developing and improving common idioms, some of which were incorporated into the standard library, thereby improving the baseline error handling.</p>
<p>There's no improvement without change though, and the frequent changes have been a source of complaints.
While backwards compatibility was never broken, people that wanted their code to be idiomatic had to update it anyway.
Old tutorials and guides have therefore also become outdated.</p>
<p>There are lots of good, up-to-date articles about error handling in Rust<sup><a href="#rust-error-handling-links">4</a></sup>, which help learn the current idioms.</p>
<p>In Rust, functions that can error return the <a href="https://doc.rust-lang.org/std/result/index.html"><code>Result</code></a> type<sup><a href="#panic-ref">5</a></sup>.<br>
There are several libraries that make creating your own errors or handling errors from libraries easier, but they (mostly) just use the types from the standard library instead of introducing new stuff that's incompatible with the rest of the ecosystem.</p>
<p>Let's look at the same function as before, but this time in Rust:</p>
<pre><code><span>pub fn </span><span>parse</span><span>(
    </span><span>workbook</span><span>: &amp;</span><span>mut</span><span> Workbook,
    </span><span>country_mapping</span><span>: CountryMapping,
) -&gt; Result&lt;Vec&lt;Rule&gt;&gt; {
    </span><span>let</span><span> range = workbook
        .</span><span>worksheet_range</span><span>("</span><span>Rules</span><span>")
        </span><span>// this question mark triggers an early exit
        // there are two because we have an Option
        // containing a Result                    👇
        </span><span>.</span><span>ok_or</span><span>(format_err!("</span><span>Missing Rules sheet</span><span>"))??;
        </span><span>//                               👇
    </span><span>let</span><span> range = </span><span>skip_to_header_row</span><span>(range)?;
    </span><span>let</span><span> parsed = RangeDeserializerBuilder::new()
        .</span><span>has_headers</span><span>(</span><span>true</span><span>)
        .</span><span>from_range</span><span>(&amp;range)
        </span><span>//                                    👇
        </span><span>.</span><span>context</span><span>("</span><span>Failed to read Rules sheet</span><span>")?;
    </span><span>let</span><span> rules = </span><span>collect_errs</span><span>(parsed.</span><span>map</span><span>(|</span><span>parse_result</span><span>| {
        parse_result
            </span><span>// 👇 mapping a lambda over the error value
            </span><span>.</span><span>map_err</span><span>(|</span><span>e</span><span>| e.</span><span>into</span><span>())
            </span><span>// 👇 this would be called flatMap in some other languages
            </span><span>.</span><span>and_then</span><span>(|</span><span>row</span><span>| row.</span><span>parse</span><span>(&amp;country_mapping))
    }))
    </span><span>// 👇 this converts a list of errors into a single error
    //    containing a string
    </span><span>.</span><span>map_err</span><span>(|</span><span>es</span><span>| {
        format_err!(
            "</span><span>Failed to parse {} rules:</span><span>\n</span><span>{}</span><span>",
            es.</span><span>len</span><span>(),
            </span><span>// 👇 very elegant...
            //    this would just be one .joinToString call in Kotlin
</span><span>            es.</span><span>into_iter</span><span>()
                .</span><span>map</span><span>(|</span><span>e</span><span>| e.</span><span>to_string</span><span>())
                .collect::&lt;Vec&lt;_&gt;&gt;()
                .</span><span>join</span><span>("</span><span>\n</span><span>")
        )
   </span><span>// 👇
    </span><span>})?;
    Ok(rules)
}
</span></code></pre>
<p>Nice things about this:</p>
<ul>
<li>The standard library, every Rust library I've ever seen and my own application code is always using the same <a href="https://doc.rust-lang.org/std/result/enum.Result.html"><code>Result</code></a> type, which keeps things pretty compatible.</li>
<li><a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">The <code>?</code> operator</a> makes fallible functions visible but keeps it succinct.<br>
It also automatically converts error types where possible, which reduces the need for manual type conversion.</li>
<li>The error type I'm using here from the library <a href="https://docs.rs/anyhow/*/anyhow/index.html"><code>anyhow</code></a> supports a <a href="https://docs.rs/anyhow/*/anyhow/trait.Context.html"><code>.context</code></a> method, which gives otherwise unhelpful low-level errors the necessary context.<br>
This is usually done in exception-based languages by catching, wrapping and rethrowing, but this looks a lot more pleasant.</li>
</ul>
<p>Not so nice things about this:</p>
<ul>
<li>I have to keep the error types compatible, which I accomplish in this case by not distinguishing between different error types at all<sup><a href="#anyhow-usecase">6</a></sup>.<br>
I still have to return a single error value, which means I have to manually and verbosely convert the list of errors into a single one - in this case a newline-delimited string.</li>
<li>If I want to log something when this entire function returns an error or add some <code>.context</code> to it, I would like to have the equivalent of a <code>try/catch</code>-block around the entire function body.<br>
This doesn't exist yet<sup><a href="#try-blocks">7</a></sup>, the current best practice seems to be do move the entire body into an inner function or lambda.</li>
</ul>
<p>My verdict is:<br>
In Rust, you will use the <code>Result</code> type and you will like it<sup><a href="#and-you'll-like-it">8</a></sup>.<br>
The main design decisions are whether you use some of the helper libraries and how you design your error types.</p>
<p>Designing the error types can be a challenge though, especially because it's a bit different than designing e.g. Java exception hierarchies.<br>
I was lucky that keeping up to date with the evolving error handling idioms wasn't too hard for me as I was not under time pressure and often worked in my spare time with learning as my primary objective.
It might have been painful for teams maintaining bigger production systems.<br>
The large number of error handling tutorials and articles should hopefully make it easier to learn now than it was a few years ago.</p>
<p>The learning curve aside:
To me, Rust's error handling feels like part of the secret sauce that makes it the most promising language for correctness that I know of.</p>
<h2 id="performance"><a href="#performance" aria-label="Anchor link for: performance">🔗</a>Performance</h2>
<p>The part of the program that caused performance issues was the diff algorithm and, to a slightly lesser extent, a data normalization step before that.<br>
The type of performance problems I had were mostly being CPU bound, having to generate and compare a lot of temporary data.
The large amount of data also often caused memory issues in both languages.</p>
<h3 id="clojure-performance"><a href="#clojure-performance" aria-label="Anchor link for: clojure-performance">🔗</a>Clojure Performance</h3>
<p>In …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://timofreiberg.github.io/clojure-vs-rust/">https://timofreiberg.github.io/clojure-vs-rust/</a></em></p>]]>
            </description>
            <link>https://timofreiberg.github.io/clojure-vs-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25497050</guid>
            <pubDate>Mon, 21 Dec 2020 17:23:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix's Metaflow: Reproducible machine learning pipelines]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 97 (<a href="https://news.ycombinator.com/item?id=25497008">thread link</a>) | @ChefboyOG
<br/>
December 21, 2020 | https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex | <a href="https://web.archive.org/web/*/https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><h4>From training to deployment with Metaflow and Cortex</h4></p><div content-type="article"><p>If we were to design an optimal machine learning pipeline, it would be:</p><ul role="list"><li><strong>Scalable</strong>. As workloads increased, it would scale up without issue.</li><li><strong>Reproducible</strong>. We would be able to draw a line from any model to its data.</li><li><strong>Configurable</strong>. It wouldn’t lock us into particular frameworks or tools.</li></ul><p>Typically, pipelines will tradeoff in at least one of these areas. A pipeline might be scalable, but will rely on a platform that puts limits on data scientists. Or, a pipeline will be completely configurable, but will also be glued together by a mess of ad hoc code and will be impossible to reproduce.</p><p>In this piece, I want to introduce a way to build this kind of ideal pipeline without any tradeoffs. To do this, we’ll be using <a href="https://metaflow.org/" target="_blank">Metaflow, the open source data science framework from Netflix</a>, and <a href="https://github.com/cortexlabs/cortex" target="_blank">Cortex, our open source deployment platform for machine learning</a>. </p><p>Let’s start by defining our pipeline.</p><h3>Defining a pipeline in Metaflow</h3><p>Metaflow is a data science framework that provides a single API for managing different pieces of the infrastructure stack. It places an emphasis on scalability, reproducibility, and usability.</p><div><p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/XV5VGddmP24" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></div><p>At a high level, Metaflow allows us to define pipelines as DAGs, called “flows,” in which data undergoes a sequence of transformations called ”steps.” These steps persist transformed data as “data artifacts,” which are accessible by subsequent steps throughout the flow. </p><p>For example, say we had a training flow that loaded data (probably produced by another flow), trained multiple models with different strategies, evaluated the different models, and saved the top performer:</p><p>This is just a snapshot of our full pipeline, which I’ll be adding to in the next section, but even with just this snippet we have a repeatable training pipeline that can scale to run on many machines. We also have, thanks to Metaflow’s Client API, a way to version, audit, and reproduce these training runs.</p><p>For example, to instantiate a given step from a previous flow, we can simply pass in the flow name, run id, and step name to the Metaflow Client:</p><p>To access an artifact from a particular run, the logic is very similar:</p><p>This means that every time a flow is executed, Metaflow automatically versions and records it using a standard taxonomy. As a result, we can trace any given model’s lineage from raw data to final export. </p><p>There is much more to Metaflow, and I’d encourage you to check out their <a href="https://docs.metaflow.org/" target="_blank">documentation</a> to learn more, but as an introduction, this should serve to get us started. </p><p>Now, let’s talk a bit about triggering deployments in Metaflow.</p><h3>Deploying models with Cortex</h3><p>In this section, I’m going to take our training flow from before and add a step for deploying our model as a production API on AWS. To do this, we’re going to use Cortex.</p><p>Cortex is a deployment platform for machine learning. On the surface, it provides simple interfaces for building prediction services, deploying them to production, and managing an inference cluster. </p><p>Under the hood, Cortex automates all of the cloud infrastructure needed for inference—autoscaling, GPU/ASIC support, load balancing, prediction tracking, etc—and implements a automated deployment process in which model serving code is packaged, versioned, and deployed to the cluster.</p><p>We can trigger a deployment using Cortex’s Python client within our training flow like this:</p><p>You’ll notice the client includes a deploy() method, which takes a configuration object for defining our API. This configuration works with the Metaflow client to extract the location of the model, and the metadata of the flow for logging purposes. Now, when we audit our deployments, we can connect it all the way back to the run that produced it, extending our lineage from data to deployment.</p><p>The configuration object also references a predict.py script, which is where the actual prediction service is defined. A Cortex predictor looks like this:</p><p>The structure is very simple. We initialize our model in the init() function, which runs on initial deployment, and we generate predictions in the predict() function. Similar to steps in Metaflow, these Python methods can contain whatever logic you want to implement.</p><p>Now, when we run the flow, the model will be trained, evaluated, and deployed to production with zero downtime or extra configuration needed. </p><p>Because Cortex provides native support for A/B testing and traffic splitting, we can even run complex deployment strategies without breaking Metaflow’s lineage.</p><p>For example, if after selecting a best model, we wanted to test how the model performed in different formats—say ONNX vs TensorFlow—we could export two versions of the model, deploy them both in an A/B test, and log their performance. Because our training flow is connected to our deployment, we can then pass this information back and forth between Cortex and Metaflow without issue.</p><h3>An easier path to production machine learning</h3><p>Over the years, a number of end-to-end data science platforms have been released, and most of them fall into the same traps:</p><ul role="list"><li>Providing a smooth interface, with zero transparency into what’s happening under the hood, killing reproducibility and auditing.</li><li>Solving one part of the stack well, like training, but “bolting on” under-developed solutions for other parts, like deployment.</li><li>Locking data scientists and machine learning engineers into a narrow stack by only supporting specific frameworks and integrations.</li></ul><p>The result is a platform that makes production machine learning easy—if you stay strictly within the confines of the system. When you have a diverse set of problems to solve, however, this is difficult to do.</p><p>Metaflow and Cortex represent a fundamentally different, human-centric approach. The emphasis is not on providing a magic solution to a narrow set of problems, but on providing an easy interface for building solutions to any problem.</p><p>If you’re interested in digging into either platform, check out the links below:</p><ul role="list"><li><strong>Metaflow documentation: </strong> <a href="https://docs.metaflow.org/" target="_blank">https://docs.metaflow.org/</a></li><li><strong>Metaflow GitHub: </strong><a href="https://github.com/Netflix/metaflow" target="_blank">https://github.com/Netflix/metaflow</a></li><li><strong>Cortex documentation: </strong><a href="https://docs.cortex.dev/" target="_blank">https://docs.cortex.dev/</a></li><li><strong>Cortex GitHub: </strong><a href="https://github.com/cortexlabs/cortex" target="_blank">https://github.com/cortexlabs/cortex</a></li></ul><p>‍</p></div></div>]]>
            </description>
            <link>https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex</link>
            <guid isPermaLink="false">hacker-news-small-sites-25497008</guid>
            <pubDate>Mon, 21 Dec 2020 17:20:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[eBPF Updates 2nd issue. Collection of news and links about eBPF]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25496621">thread link</a>) | @genbit
<br/>
December 21, 2020 | https://ebpf.io/news/ebpf-updates-2020-12 | <a href="https://web.archive.org/web/*/https://ebpf.io/news/ebpf-updates-2020-12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div>
<h2 id="foreword"><a href="#foreword" aria-label="foreword permalink"></a>Foreword</h2>
<p>Welcome to the second issue of the <em>eBPF Updates</em>! This time we have
interesting resources about how to write eBPF programs with Zig, or with Rust,
or on how to manage them with libbpf. On the kernel side, modules now support
BTF, and improvements to memory accounting for eBPF should help to solve the
limitations of rlimit. Did this just sound incomprehensible to you? Do not
fear, we also have some gentle introductions to eBPF in the list. This issue
also introduces a “Did You Know” section, and this time the focus is on CO-RE.
Read, learn, trace, and filter!</p>
<h2 id="important-news"><a href="#important-news" aria-label="important news permalink"></a>Important News</h2>
<p>The calls for participation (CFPs) for the devrooms for
<a href="https://fosdem.org/2021/">FOSDEM 2021</a> (online event) are open. Some of the
devrooms have hosted multiple talks about eBPF over the last year. In
particular:</p>
<ul>
<li>The SDN devroom (<a href="https://mdr78.github.io/2020/12/01/fosdem-cfp.html">CFP</a>)
accepts submissions until the 20th of December 2020.</li>
<li>The Containers devroom
(<a href="https://discuss.linuxcontainers.org/t/fosdem-2021-containers-devroom-call-for-papers/9625">CFP</a>)
accepts submissions until the 22th of December 2020.</li>
</ul>
<p>Recent start-up acquisitions highlight the growing adoption and the maturity of
eBPF:</p>
<ul>
<li><a href="https://www.flowmill.com/">Flowmill</a>, offering a solution for network
observability relying on eBPF,
<a href="https://techcrunch.com/2020/11/24/splunk-acquires-network-observability-service-flowmill/">has been acquired</a>
by <a href="https://www.splunk.com/en_us/newsroom/press-releases/2020/splunk-to-acquire-network-performance-monitoring-leader-flowmill.html">Splunk</a>.</li>
<li><a href="https://pixielabs.ai/">Pixie Labs</a>, which uses eBPF for visibility in
Kubernetes,
<a href="https://techcrunch.com/2020/12/10/new-relic-acquires-kubernetes-observability-platform-pixie-labs/">has been acquired</a>
by <a href="https://blog.newrelic.com/product-news/pixie-developer-first-observability/">New Relic</a>.</li>
</ul>
<p>Readers from Brazil may be interested in the <a href="https://ebpfbr.org/">eBPF Brasil</a>
website, which aims at gathering, translating, and sharing knowledge about
eBPF.</p>

<p>eBPF was named as one of the 5 technologies to watch in 2021 by CNCF TOC chair
<a href="https://twitter.com/lizrice">Liz Rice</a>, and the eBPF community just keeps on
growing every day.</p>
<p><span>
      <a href="https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/91608/community.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="community" title="community" src="https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/8c557/community.png" srcset="https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/4edbd/community.png 175w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/13ae7/community.png 350w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/8c557/community.png 700w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/e996b/community.png 1050w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/91608/community.png 1251w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span></p>
<h2 id="new-resources"><a href="#new-resources" aria-label="new resources permalink"></a>New Resources</h2>
<h3 id="blog-posts-presentations"><a href="#blog-posts-presentations" aria-label="blog posts presentations permalink"></a>Blog Posts, Presentations</h3>
<ul>
<li><a href="https://blog.container-solutions.com/the-top-reasons-why-you-should-give-ebpf-a-chance"><em>The Top Reasons Why You Should Give eBPF a Chance</em></a>,
from Lucas Severo Alves.<br>
Several factors are responsible for eBPF's success and should make readers
consider learning about, or using, this technology. This post cites its
powerful tracing capabilities, with the ability to attach to nearly any
function in the kernel with little impact on performance. Another reason is
that more and more companies, including large ones, are adopting eBPF; a
detailed list follows. At last, eBPF makes it possible to quickly develop
tools to instrument new parts of the kernel, without the need to go through a
longer process to upstream new attach points.</li>
<li><a href="https://cmd.com/blog/making-bpf-easy-with-libbpf-and-zig/"><em>Making BPF easy with libbpf and Zig</em></a>,
from Matt Knight.<br>
The <a href="https://ziglang.org/">Zig</a> programming language is used to create and
handle a simple eBPF program in this tutorial, both for the user space loader
and the eBPF program itself. The objective is mostly to understand how libbpf
manipulates the ELF object containing a program in order to load it, but
compiling from Zig, which aims at competing with C while offering some newer
features, may open new perspectives. The code is available
<a href="https://github.com/mattnite/zig-bpf-intro">on GitHub</a>.</li>
<li><a href="https://github.com/cilium/cilium/pull/13943">Weight support for Cilium's eBPF-based Maglev load balancer implementation</a>,
from Fankaixi Li.<br>
A new pull request by a software engineer at ByteDance (TikTok) popped up,
adding weight support to the eBPF-based
<a href="https://cilium.io/blog/2020/11/10/cilium-19#maglev">Maglev implementation in Cilium</a>.
Maglev provides consistent hashing for high-availability scenarios, and
balance packets to the same backends even if they arrive at different load
balancing nodes. The feature adds the possibility to assign weights to favor
some backends. It is still being discussed, but should land soon.</li>
<li><a href="https://kccncna20.sched.com/event/ekDR/beyond-the-buzzword-bpfs-unexpected-role-in-kubernetes-andrew-randall-alban-crequy-kinvolk"><em>Beyond the Buzzword: BPF’s Unexpected Role in Kubernetes</em></a>,
from Andrew Randall and Alban Crequy.<br>
After a high-level overview of eBPF, this presentation depicts the landscape
of the projects gravitating around this technology. The authors explain that
there are many powerful tools based on eBPF, although none of them would
cover Kubernetes clusters. As an answer to fill the gap, they introduce
Inspektor Gadget, which reuses some elements from the bcc tools to provide a
new set of monitoring gadgets for examining Pods. Note that the wording in
the slides might be misleading: If there was no equivalent to bcc for tracing
containers before Inspektor Gadget, there <em>are</em> other tools targeting the
platform, such as Cilium/Hubble for network and observability or BPFd for
running bcc scripts in containers.</li>
<li><a href="https://filipnikolovski.com/posts/ebpf/"><em>TIL: eBPF is awesome</em></a>,
from Filip Nikolovski.<br>
We all agree on this! This post is a gentle introduction to eBPF. A bit of
history, some details on the core infrastructure and its components, and a
simple “Hello, World!” example extracted from
<a href="https://github.com/iovisor/bcc/blob/34cada17f798b8e00268d1ba4a4a8d765b948532/examples/tracing/hello_fields.py">the bcc tools</a>.
A nice read if you just got started with eBPF.</li>
<li><a href="https://suchakra.wordpress.com/2020/11/20/building-an-esoteric-filesystem-tracing-tool-with-ebpf/"><em>Building an Esoteric Filesystem Tracing Tool with eBPF</em></a>,
from Suchakra Sharma.<br>
This post has a focus on the read-ahead mechanism in the Linux kernel. After
providing a refresher on how read-ahead works, Suchakra explains in details
how eBPF can monitor the hit rate and efficiency of this mechanism. It turns
out that the program used to do that already exists in two versions, one with
a mix of C and Python proper to the bcc tools, and another one based on
libbpf and the newer features brought by the library, like CO-RE (Compile
Once, Run Everywhere). The last section details the benefits of the latter
version and the motivations to port tools to libbpf.</li>
<li><a href="https://lac2020.sciencesconf.org/data/proceedings.pdf#section*.12"><em>eXpress Data Path Kernel Objects for Real-Time Audio Streaming Optimization</em></a> (PDF),
from Christoph Kuhr and Alexander Carôt.<br>
Focusing on audio packet processing, this work aims at facilitating the set
up of a rehearsal environment for conducted orchestras via the Internet with
up to sixty musicians. The system may be susceptible to latency issues when
the different UDP streams must be processed and combined. The authors
investigated the use of XDP for processing these UDP streams, aggregating
them in the kernel and reporting only the final audio sample to the user
application. The authors found that XDP was not ideal, because of its lack of
floating-point operations and because it does not permit to retrieve hardware
timestamps. They were also limited by the incompatibility between LLVM, used
to compile the eBPF programs, and their build system, and could not
experiment on one part of their frontend. And although XDP increased the
performance, they realized that they could obtain similar speeds for their
use case with an optimized handling of a generic raw socket. Still, the use
case and experiment remain an interesting read.<br>
Video of the presentation may be available in the future from
<a href="https://lac2020.sciencesconf.org/">the page of the conference</a>, if it gets
uploaded.</li>
<li><a href="https://thenewstack.io/primer-how-xdp-and-ebpf-speed-network-traffic-via-the-linux-kernel/"><em>Primer: How XDP and eBPF Speed Network Traffic via the Linux Kernel</em></a>,
from Jack Wallen.<br>
There is a resolute focus on XDP in this article which describes how this
eBPF hook can speed up network traffic on Linux. This is followed by a simple
tutorial, where bcc is used to attach a XDP program and to track UDP packets
sent to a given port.</li>
<li><a href="https://nakryiko.com/posts/libbpf-bootstrap/"><em>Building BPF applications with libbpf-boostrap</em></a>,
from Andrii Nakryiko.<br>
You want to start developing an eBPF application, but you feel intimidated by
libbpf's complexity or lack of documentation? You <em>must</em> have a look at
libbpf-bootstrap. This project builds simple application templates, on which
you can directly build your software. Of the two available templates, the
simplest one (<code>minimal</code>) manipulates an eBPF program that simply logs the PID
of the process that calls it. The more advanced template (<code>bootstrap</code>) sets
up an application with more advanced features like eBPF maps, read-only
configuration variables, eBPF ring buffer, or CO-RE which needs a BTF (BPF
Type Format) description of the kernel's internals. This means that using
these features gets simple and immediate, all is set up for you in the
template. This article goes into a thorough description of the mechanisms
involved. This is a long read, but well worth it if you want to program
applications working with eBPF.</li>
<li><a href="https://pluginized-protocols.org/xbgp/2020/11/29/xbgp-hello.html"><em>A first xBGP plugin</em></a>,
from Thomas Wirtgen.<br>
As a follow-up from the link to the paper for xBGP in the previous issue of
these <em>eBPF Updates</em>, this is the introduction of a first eBPF-based xBGP
plugin. The idea is that, quoting the post, “<em>a network operator would like
to ignore the BGP UPDATE messages that contain an unknown attribute. A
practical example of this usage is when problems with the processing of BGP
Path attribute 128 caused the failure of BGP sessions</em>”. All steps required
for running this example are provided. The code is hosted on
<a href="https://github.com/pluginized-protocols/xbgp_plugins.git">GitHub</a>, but there
is also a
<a href="https://github.com/pluginized-protocols/libxbgp/blob/master/misc/Dockerfile_xbgp">Dockerfile</a>
packaging all the required elements.</li>
<li><a href="https://docs.google.com/presentation/d/1cB4rJcdxTolIIUy5IEcb9iiUJHlMNmyT7c5eYY9D5LU/edit?usp=sharing"><em>Cilium &amp; eBPF - From Device to Service-Centric Networking</em></a>,
from Thomas Graf.<br>
In this presentation at the NAG (Network Architecture Geeks) Cafe in
December, Thomas outlines how eBPF allows to build powerful service-centric
networking models and how to evolve away from the old device-centric
networking architecture to meet requirements of containers and cloud-native
environments.</li>
<li><a href="https://medium.com/simplestaking/integrating-an-ebpf-based-firewall-into-the-tezedge-node-with-multipass-validations-769d4c6ccd93"><em>Integrating an eBPF-based firewall into the TezEdge node with multipass validations</em></a>,
from Juraj Selep.<br>
TezEdge peer-to-peer nodes validate blocks for the decentralized
<a href="https://en.wikipedia.org/wiki/Tezos">Tezos</a> blockchain, providing smart
contracts. Blockchain networks are subject to DDoS (Distributed Denial of
Service) attacks, generally mitigated with a firewall. In the current case,
XDP is used to implement it. The eBPF program checks that each connection
starts with a valid and unique proof of work, making it expensive for an
adversary to start many connections. This is further integrated with the
“multipass validation” scheme that aims at detecting erroneous blocks as soon
as possible. Note that the eBPF programs are written in Rust.</li>
<li><a href="https://en.pingcap.com/blog/why-we-switched-from-bcc-tools-to-libbpf-tools-for-bpf-performance-analysis"><em>Why We Switched from bcc-tools to libbpf-tools for BPF Performance Analysis</em></a>,
from Wenbo Zhang.<br>
Another article on the benefits brought by CO-RE, for which libbpf provides
good support. After comparing bcc-based and libbpf-based tracing tools in
terms of features and memory footprint, the author provide a list of tools
and invocation patterns they use to analyze I/O performance.</li>
<li><a href="https://cilium.io/blog/2020/12/11/kube-proxy-free-cve-mitigation"><em>How to mitigate Kubernetes CVE-2020-8554 with eBPF</em></a>
from Jed Salazar.<br>
<a href="https://github.com/kubernetes/kubernetes/issues/97076">CVE-2020-8554</a>
represents a MITM (Man-in-the-middle) attack in Kubernetes where the
ExternalIP service feature can be used to attack a workload and redirect
egress network traffic from a unsuspecting Pod to another destination. In
this blog, Jed describes how Cilium is able to …</li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ebpf.io/news/ebpf-updates-2020-12">https://ebpf.io/news/ebpf-updates-2020-12</a></em></p>]]>
            </description>
            <link>https://ebpf.io/news/ebpf-updates-2020-12</link>
            <guid isPermaLink="false">hacker-news-small-sites-25496621</guid>
            <pubDate>Mon, 21 Dec 2020 16:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chef cofounder on CentOS: It’s time to open source everything]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25493606">thread link</a>) | @ashitlerferad
<br/>
December 21, 2020 | https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/ | <a href="https://web.archive.org/web/*/https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Commentary: Red Hat has been in hot water about changing the way CentOS operates, but that model looks like the exact right way for open source entrepreneurs to operate.</p><div data-component="lazyloadImages">
<figure><span></span><figcaption></figcaption></figure>
<p>Red Hat switched up CentOS to make it less of a Red Hat Enterprise Linux (RHEL) clone and more of a feeder project into RHEL (as Fedora was always supposed to be, yet wasn’t). Some people are mad, as <a href="https://www.zdnet.com/article/red-hat-resets-centos-linux-and-users-are-angry/" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Steven J. Vaughan-Nichols has written</a> on sister site ZDNet. Some people, like former Disney employee Justin Garrison, <a href="https://twitter.com/rothgar/status/1337818039799070722" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">think</a> it sounds perfect (the hipper, slightly edgier version of RHEL). If you’re a billion-dollar company upset that Red Hat appears to be trying to charge for something you value, the <a href="https://www.zdnet.com/article/goodbye-centos-hello-rocky-linux/" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">founder of CentOS has a new way for you to get something for nothing</a>: Rocky Linux.</p>

<p>But if you’re an open source entrepreneur wondering what this means for you, well, Chef cofounder and System Initiative CEO <a href="https://twitter.com/adamhjk/status/1337062314357514251" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Adam Jacob has you covered</a>. In a series of tweets, he walks through how Red Hat’s CentOS strategy can play out for you. (He should know, as the company he co-founded, Chef, <a href="https://www.techrepublic.com/article/why-chefs-100-open-source-move-is-smart-business/" data-absolute="true">last year open sourced everything</a>.)</p>
<p>Let’s observe.</p>
<h2>Open source all the things</h2>
<p><a href="https://twitter.com/adamhjk/status/1337062314357514251" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Jacob’s first rule</a>? Open it up. Completely. “If I do an open source strategy for a company ever again, I will own the upstream, it will be fully open source, and I’ll happily collaborate with anyone downstream.” But not just an open upstream–it’s also important to, “Produce a commercial distribution [and c]ollaborate on downstream non-commercial ones, in the open,” he <a href="https://twitter.com/adamhjk/status/1337062321982758912" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">argued</a>.</p>
<p>What does he mean by “upstream” and “downstream”? In open source, think of the <a href="https://opensource.stackexchange.com/questions/993/what-does-upstream-mean" target="_blank" rel="noopener noreferrer nofollow" data-absolute="true" data-component="externalLink">upstream</a> as the parent, the head, the initial open source project. Downstream might be forks or distributions (packaging up of a particular build of the upstream code) of the upstream.</p>
<p>What Red Hat announced was basically that CentOS would move from being downstream to upstream. It becomes a place, as <a href="https://twitter.com/adamhjk/status/1337062318451068929" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Jacob noted</a>, that others <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux" target="_blank" rel="noopener noreferrer nofollow" data-absolute="true" data-component="externalLink">like Facebook</a> can collaborate with Red Hat in a way they simply couldn’t before (as Fedora wasn’t closely enough aligned with RHEL). CentOS as a downstream RHEL community was mostly one of users, of consumers, not of collaborators. It was somewhere to get RHEL, but rebranded CentOS, for free.</p>
<p>As such, Jacob pointed out, “They weren’t invested in it beyond using it.” And when someone removes the downstream they get mad “because it’s like someone threatened the water supply,” <a href="https://twitter.com/adamhjk/status/1337062319558434822" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">he argued</a>. It’s therefore far better to condition people to participate as collaborators with an open source project, and through the commercial distribution to also condition users to become customers, if they want the certified distribution.</p>
<h2>Open source + cloud</h2>
<p>One way that open source companies are doing this model to fantastic effect is by open sourcing their upstream and creating a cloud distribution (read: managed service). A variety of companies have embraced this model to greater or lesser extents.</p>
<p>Yugabyte, for example, ditched its Open Core model a year ago and open sourced 100% of its database code. A year later, CTO Karthik Ranganathan told me in an interview, “It increased our adoption like crazy,” growing the number of Yugabyte clusters 10x, but it also has dramatically accelerated their business without them losing any known pipeline. Could someone take that upstream and create a competitive downstream competitor? Of course. But no one should be able to out-Yugabyte on their home turf.</p>
<p>Or take Redis Labs. The company has fiddled with licensing over the last few years, but has kept core Redis completely open while encouraging a growing community (which includes downstream competitors) to lend a hand to improving the code. While Redis Labs doesn’t publish results, its business is booming, even as 10 or so other companies have created competitive downstream managed service offerings.</p>
<p>Which brings us back to Jacob: “Run an open upstream from the jump. Produce a commercial distribution. Collaborate on downstream non-commercial ones, in the open.”</p>
<p>That’s the strategy. That’s the magic. You don’t need to go Open Core or any other permutation of kind-of, sort-of open source. You can open source everything and just ensure you have a rock-solid managed cloud service. This reliance on cloud is what’s driving MongoDB, Confluent, DataStax, Redis Labs, and others to great success. It can be your model, too.</p>
</div></div>]]>
            </description>
            <link>https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493606</guid>
            <pubDate>Mon, 21 Dec 2020 10:22:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul: Commutation and Scalability]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25493577">thread link</a>) | @Ygg2
<br/>
December 21, 2020 | https://pijul.org/posts/2020-12-19-partials/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2020-12-19-partials/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Sunday, December 20, 2020</p>
<p>I just finished the implementation of an important feature of Pijul: clones, pushes and pulls on partial repositories. In this post, I explain why this matters.</p>
<h2 id="change-commutation">Change commutation</h2>
<p>Pijul is based on <em>changes</em>, also called <em>patches</em> or <em>diffs</em>.
This doesn’t mean that its only internal datastructure is patches, quite to the contrary: it was only by departing from a patch-only internal representation that we were able to solve the algorithmic challenges inherent to patch-based systems.</p>
<p>However, being change-based does mean that the core operations of Pijul are defined on changes, and that Pijul is designed in such a way that changes satisfy basic intuitive properties, similar to algebraic operations. One basic thing is that applying a change is an <em>associative</em> operation, like matrix multiplication: applying $A$ and $B$ at once, and then later $C$, is the same as applying $A$, and then $B$ and $C$ at once. In matrix multiplication, $(AB)C = A(BC)$. Moreover, in Pijul, all changes are invertible (whereas only some matrices are): for any change $A$, there is an “inverse change” $A^{-1}$ such that applying $A^{-1}$ after $A$ is the same as applying neither. Of course, both $A$ and $A^{-1}$ will appear in the log, but the contents of the repository will be the same as applying neither $A$ nor $A^{-1}$.</p>
<p>There is another property that users want from version control systems, and that is <strong>commutation</strong>.
Matrix multiplication rarely commutes<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
In Git, commutation is usually <em>simulated</em> using branches and rebase: indeed, rebasing a branch A on top of another branch B really means commuting the commits of A since the divergence between A and B, and the commits of B since the divergence. However, that commutation isn’t perfect, since the commits must change their hash when rebased.</p>
<p>Things are simpler in Pijul, because any two changes that <em>could have been written independently</em> always commute, meaning that if the two changes could be written without knowledge of each other, they can be applied in any order.</p>
<p>This of course raises a potential concern:</p>
<blockquote>
<p>If I can apply $A$ and $B$ in any order, how do I know which order is the <strong>right</strong> one?</p>
</blockquote>
<p>In Pijul, this question <strong>does not matter</strong>: both orders will yield <strong>the exact same result</strong>, the only difference is that the log will list the changes in the order in which they were applied. And I’m not saying that it doesn’t matter because I’m careless, but because it truly is the same thing.</p>
<blockquote>
<p>I disagree: it does matter, I still prefer to have a “<em>linear</em>” order for my changes/commits.</p>
</blockquote>
<p>Indeed, everybody wants to see the order of operations in a repository, for many reasons. For example:</p>
<ul>
<li>We want to keep a record of the operations performed on our repository.</li>
<li>We want to go back in time.</li>
</ul>
<p>And in fact, Pijul allows you to do exactly that, but in a more rigorous way than Git. Indeed, take the scenario where Alice and Bob work together, Alice makes a change $A$ while Bob makes $B$. When they put their work together, Alice applies Bob’s change, resulting in the log $AB$, while Bob applies Alice’s change, resulting in the log $BA$. In this case, there is no “true” linear history, since they worked on different things, and took different steps at different times. However, both of them want to be able to go back in time, step-by-step, and not just “<em>step-by-step-according-to-Bob’s-order</em>”.</p>
<h2 id="commutation-and-massive-repositories">Commutation and massive repositories</h2>
<p>One of the biggest challenge for Pijul up to the recent releases was scalability: even modestly-sized repositories like Pijul’s source code would use a lot of disk space. This was even more disappointing since, as I’m about to explain, commutation was suposed to allow it to scale to gigantic repository sizes… in theory. The same problem also made massive tests impossible, meaning that getting past the “0.x releases” seemed more and more impossible as time passed.</p>
<p>Now that this phase is mostly behind us, the cool bits of the theory finally become practical.</p>
<p>In particular, in Pijul, each change contains a reference to the files it modifies. Note that, because we want operations on repositories (such as renaming files) to commute with edits inside files, we don’t identify files and directories by name, but by a unique identifier made from the hash of the change that introduced that file or directory.</p>
<p>For repositories with multiple projects, this makes it possible to clone and pull just parts of a repository, and work on that part as if we had the entire thing. Indeed, imagine we have a repository with the following log:</p>
<ol>
<li>A, adding file <em>x</em></li>
<li>B, editing <em>x</em></li>
<li>C, adding file <em>y</em></li>
<li>D, adding file <em>z</em></li>
<li>E, renaming <em>x</em> to <em>w</em></li>
<li>F, editing <em>y</em> and <em>z</em></li>
</ol>
<p>All these changes do not necessarily commute; however, since B and C touch completely different files (namely, <em>x</em> and <em>y</em>), they could be produced in parallel, and hence they commute. This means that we can pull only the changes related to a specific file, say <em>x</em>, and make the following history: A, B, E<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p>Moreover, any change made on top of that sequence will commute with C, D and F: indeed, if we edit file <em>x</em> again, producing a change G, then since G can be made in parallel to C, D and F, we can push G after any patch that comes after B in that history, for example getting history “ABCDEFG”.</p>
<p>Note that this is done without changing the changes nor their hash.</p>
<h2 id="another-trick-for-large-files">Another trick for large files</h2>
<p>As explained in previous posts on this blog, Pijul changes have a bit more information than diffs, and operate on graphs rather than files. This means that changes can be split into two parts, a short-ish one with a binary specification of the graph operations, and then the new content inserted by the change.</p>
<p>The change format is designed to be downloadable in two stages: one can download the operations without downloading the contents. One issue with this is security: if we don’t download the contents, how can we make sure that the hash is right? This is done by including a hash of the change in the “operations” section of the change, and letting the hash of a change be the hash of the “operations” section.</p>
<p>This makes it possible for someone to make five versions of a large binary file in a day, where each change deletes the entire file, and adds it again, the operation sections only contain the length of the different versions, not the actual bytes. In order to get the latest version of the file, a client will therefore only have to download the latest change completely, and only the operations section of the previous ones.</p>
<p>Note that this makes the following “attack” possible: a server might trick a client into believing that the server has a change with hash $A$, which inserts $n$ bytes into a file, and then another change with hash $B$, deleting all these bytes. When the client downloads $A$ and $B$, it doesn’t need to download the contents. However, if the client later decides to unrecord $B$, the contents of $A$ will have to be downloaded, and the client will be able to tell that the hash of $A$ was incorrect. This should make it impossible to unrecord $B$ without also unrecording $A$. However, if $A$ made other edits, and other changes depend on $A$, this could be problematic.</p>
<h2 id="what-is-next">What is next?</h2>
<p>There is one remaining painpoint for very large repositories, and this is the fact that in order to clone a repository with a very large history, one must download and apply all the changes, one by one. Even though our apply function is quite fast<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, this can still be problematic for dozens or hundreds of thousands of changes.</p>
<p>In my next post, I will talk about a solution to this problem, which I have started to implement.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Matrices that are simultaneously diagonalizable do, for example, but for two arbitrary matrices $A$ and $B$, $AB$ is often different from $BA$. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Note that in this case, we could also pull A, E, B, since renaming a file commutes with editing it. However, we must start with A, since adding a file could not be possibly done in parallel to editing or renaming it. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The complexity of apply is in $O(|p| |c| \log |H|)$, where $|p|$ is the size of the change, $|c|$ is the size of the largest conflict in which $p$ is involved, and $|H|$ is the number of edits made since the start of the repository. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://pijul.org/posts/2020-12-19-partials/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493577</guid>
            <pubDate>Mon, 21 Dec 2020 10:14:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for on Call Engineers During the Holidays]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25493498">thread link</a>) | @kiyanwang
<br/>
December 21, 2020 | https://www.transposit.com/blog/2019.12.23-tips-for-on-call-engineers-during-the-holidays/ | <a href="https://web.archive.org/web/*/https://www.transposit.com/blog/2019.12.23-tips-for-on-call-engineers-during-the-holidays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://transposit.imgix.net/img/2019.12.23a.jpg?auto=format&amp;ch=Width,DPR&amp;q=95&amp;w=800" alt="Picture of fire burning in a fireplace"></p><p>Are you sitting by the fire sipping cocoa, worrying secretly about whether you’ll have to put out an engineering fire any minute?</p><p>If only everyone could enjoy a well-earned break from on call life, the week would be more relaxing, but there is no rest for the technology that keeps our world running. This week certain industries are reaching a holiday high, and DevOps, SREs, and on call engineers everywhere will have to don their invisible superhero capes and keep us humans and our devices connected, just like they always do.</p><p>At Transposit, we know the pain of on call ourselves, and so we’ve banded together to come up with some of our top tips for making holiday on call shifts as painless as possible.</p><h2 id="on-call-tip-number-one%3A">On Call Tip Number One: <a href="#on-call-tip-number-one%3A">#</a></h2><p>Whether on-callers are planning on having a Rockwellian Christmas, lighting the menorah with Bubbe, visiting family abroad, or taking a tropical trip with the two federal holidays padding their vacation request, there is one consistent truth about the holiday week between Christmas and New Years: Mass exodus from the office. So, before we even get into the challenges of answering a page when no one is around to help you, how can you avoid that conundrum in the first place?</p><p>On call engineering managers should be careful to adjust on call schedules so that the same people are not on call during multiple peak times. Which times are most painful are up to the individual, so giving each person the opportunity to sign up for what works for them first is always a best practice. Perhaps someone doesn’t mind being on call Christmas morning, but absolutely can’t do it on New Years Eve. Start by letting people pick what is ideal for them, and then fill in the remaining gaps, being sure not to unduly burden any one member of the team.</p><p>When making the on call schedule, make sure that there are primaries and secondaries who are committed to each shift, since they will likely be working together without quick access to the rest of the team when something goes wrong.</p><p>To reduce the pain further, consider upping on call bonuses for the entire week as an incentive for taking on undesirable shifts, and once everyone is back in the office in January, be sure to acknowledge the on-callers who responded quickly to keep the business running while everyone else was enjoying their time away from work.</p><h2 id="on-call-tip-number-two%3A">On Call Tip Number Two: <a href="#on-call-tip-number-two%3A">#</a></h2><h3 id="communicate-early-and-often%2C-with-and-without-runbooks.">Communicate early and often, with and without runbooks. <a href="#communicate-early-and-often%2C-with-and-without-runbooks.">#</a></h3><p>Without easy access to the rest of the team, good playbook/runbook documentation during this period is even more important than it is the rest of the year. If your typical on call process involves opening up a collaborative team Slack thread or Jira ticket and then letting various experts or senior SREs weigh in, you might face a rude awakening when your reliable experts are MIA during the holiday week.</p><p>Make sure your runbooks are updated and everyone has easy access to the DevOps systems they need before everyone leaves on vacation, because if on-callers are left to search half-empty wikis by themselves, the speed to resolution is going to be stressful for everyone - engineers, managers, and executives alike.</p><p>Additionally, make sure that primary and secondary on-callers know exactly who they are paired with for a particular shift. Make sure that both are committed to being fully available and sober during their shifts, so that in the absence of the whole team, they are secure in having at least one problem-solving partner.</p><h2 id="on-call-tip-number-three%3A">On Call Tip Number Three: <a href="#on-call-tip-number-three%3A">#</a></h2><h3 id="plan-around-potential-travel-problems">Plan around potential travel problems <a href="#plan-around-potential-travel-problems">#</a></h3><p>While it may seem obvious to plan your travel around your on call shifts so that you aren’t in the air while you’re supposed to be available, these days, we sometimes have too much faith in our connectivity during travel. Airports and even some planes have wifi, many airplane seats have built-in electricity and jacks, what could possibly go wrong?</p><p>Remember, this week is one of the busiest travel weeks of the year in the US, so our already strained infrastructure will be at the edge of capacity in the best of circumstances. You won’t be very effective at troubleshooting an outage if you are standing in a 2-hour long airport security line or sitting in a traffic jam on the way up to the mountains. Add unpredictable winter weather to the mix, and we have on call disasters in the making. So, what should on-callers do?</p><p>First, you should plan wider time-frames for travel around your on call shifts to avoid accidentally being unavailable. You also shouldn’t count on access to wifi on your flights (only some planes are equipped, and airlines often shift which plane is flying a certain route based on weather and mechanical issues). Don’t expect access to electricity in the airport to charge your computer or phone, as the high number of travelers may easily keep the charging stations fully occupied, and make sure you have your computer and charger easily accessible, so that if you are forced to gate-check a bag on your crowded flight, you will be sure to keep these precious items on your person.</p><p>Traveling on-callers should also remember that time zones are a thing - your on call planning will need to be adjusted accordingly. If you are the secondary, your primary may be in a different time zone (or vice versa), and you should discuss your plans with them beforehand so that you are prepared for them to be asleep at different hours.</p><p>Finally, if you are traveling anywhere that has inclement weather or otherwise unreliable access to internet, you should have a back-up plan, such as tethering your computer to your phone’s data service to get around unreliable wifi. If you arrive at your destination and realize that you have bad data service, finicky wifi, or (gasp) the possibility of power outages, you should admit your defeat early and find an understanding colleague to take your shift, rather than hoping for the best and leaving any alerts to your back-ups.</p><h2 id="on-call-tip-number-four%3A">On Call Tip Number Four: <a href="#on-call-tip-number-four%3A">#</a></h2><p>We’ve already talked about the importance of secondaries as problem-solving partners, but what about the other, more social challenges of being on call during this time? Let’s say you’re sitting down to a nice family dinner, and, just like you were dreading, there goes your phone dinging with an urgent alert. How are you going to explain this situation to your relatives, who in many cases, don’t really understand what you do?</p><p>This is where a friendly ally can help serve as your secondary within your social situation. If you arm a sibling or supportive partner with talking points to explain why you have to get up from the festive table to crouch frantically over your laptop in the back room, you will be able to focus on troubleshooting without worrying about the familial fallout.</p><h2 id="on-call-tip-number-five%3A">On Call Tip Number Five: <a href="#on-call-tip-number-five%3A">#</a></h2><h3 id="pat-yourself-and-your-team-on-the-back">Pat yourself and your team on the back <a href="#pat-yourself-and-your-team-on-the-back">#</a></h3><p>It should go without saying, and so often it does, that there is a reason the world functions so smoothly during this week, despite its unique circumstances. While a lot of the credit is due to excellent engineering and team planning throughout the rest of the year, there are always unanticipated incidents that simply can’t be avoided. That’s why on call shifts, DevOps, and SREs exist in the first place! And so, as we look back on the year, and the incidents resolved during this special last week of 2019, let’s remember to give a shout out to all the engineering heroes who stepped forward to make it happen. Cheers to you!</p></div></div>]]>
            </description>
            <link>https://www.transposit.com/blog/2019.12.23-tips-for-on-call-engineers-during-the-holidays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493498</guid>
            <pubDate>Mon, 21 Dec 2020 09:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Lisp (2019)]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25493495">thread link</a>) | @wheresvic4
<br/>
December 21, 2020 | https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019 | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  It's 2019 and Lisp stories are on fire at HackerNews. While there exist multiple Lisp dialects, Common Lisp is the
  oldest and most mentioned. Thus, if you're looking to get started with programming in Common Lisp, then there are 2
  options:
</p>

<ul>
  <li>Use <a href="https://portacle.github.io/">portacle</a> to get up and running with SBCL + Emacs.</li>
  <li>
    Use
    <a href="https://github.com/roswell/roswell">roswell</a> to install multiple Lisp implementations + build and bundle
    lisp applications. Roswell installs SBCL by default.
  </li>
</ul>

<p>
  As for me, I did not feel like learning a brand new text editor just to get started with Lisp so I went with Roswell.
  Follow the instructions on installing Roswell for your platform. In my case, I decided to install it under
  <code>$HOME/bin</code> on my linux machine via:
</p>

<pre>$ sudo apt install rlwrap
$ mkdir $HOME/bin
$ git clone -b release https://github.com/roswell/roswell.git
$ cd roswell/
$ sh bootstrap
$ ./configure --prefix=$HOME/bin
$ make
$ make install</pre>

<p>
  Make sure to add the roswell path to your <code>~/.bashrc</code> (note that roswell installed itself under
  <code>~/bin/bin</code> and if this looks odd to you, install it under <code>$HOME/apps</code> or something of the
  sort):
</p>

<pre>if [ -d "$HOME/bin/bin" ] ; then
  PATH="$HOME/bin/bin:$PATH"
fi</pre>

<p>
  Open a new terminal and setup roswell:
</p>

<pre>$ which ros
/home/xxx/bin/bin/ros
$ ros --version
roswell 19.06.10.100
$ ros setup </pre>

<p>
  We will now setup VSCode to run lisp. First install the
  <a href="https://marketplace.visualstudio.com/items?itemName=mattn.Lisp">vscode-lisp</a> extension. Open a new file
  and type the following in:
</p>

<pre>(defun main ()
  (format t "Hello world"))
</pre>

<p>
  Then <a href="https://code.visualstudio.com/docs/editor/integrated-terminal">launch a terminal</a> inside VSCode. In
  the terminal run <code>rlwrap ros run</code> to start the REPL (Read/Eval/Print Loop). Select the above defined
  function and use the "Run Selected Text in Active Terminal" from the Command Palette (F1) to run your code!
  Note that you can exit the REPL via: <code>(SB-EXT:EXIT)</code>. The <code>rlwrap</code> utility remembers previously
  typed commands which makes for a much nicer REPL experience.
</p>

<p>
  What is amazing about Roswell is that is comes with a scripting / build ability that allows you to easily distribute
  your application. To see this in action first create a roswell script via <code>ros init hello-world</code>. Then add
  in the following code so that your script looks like the following:
</p>

<pre>#!/bin/sh
#|-*- mode:lisp -*-|#
#|
exec ros -Q -- $0 "$@"
|#
(progn ;;init forms
  (ros:ensure-asdf)
  ;;#+quicklisp(ql:quickload '() :silent t)
  )

(defpackage :ros.script.hello-world.3774807541
  (:use :cl))
(in-package :ros.script.hello-world.3774807541)

(defun helloWorld
  ()
  (format t "Hello world")
)

(defun main (&amp;rest argv)
  (declare (ignorable argv))
  (helloWorld))
;;; vim: set ft=lisp lisp:
</pre>

<p>
  We can now simply run this script via <code>ros hello-world.ros</code> but more interestingly, we can actually compile
  a binary via <code>ros build hello-world.ros &amp;&amp; ./hello-world</code>.
</p>

<p>
  Interestingly enough, I am not a complete noob to Common Lisp, I actually programmed it 15 years ago during my
  undergrad years. A colleague and I
  <a href="https://smalldata.tech/api/to/847c726edff337b818ba86914d9e71b6">compared an experimental genetic algorithm against an ant colony optimization algoritm on a path-finding problem</a>. Once I had lisp running I opened up the project and basically executed <code>ants.lisp</code> in the REPL, ran
  <code>(INITIALIZE-ANT-WORLD)</code> followed by <code>(DISPATCH-ANTS)</code> and voila, my ants were able to find
  their food!
</p>

<p>
  No guide to getting started with Lisp would be complete without a list of further reading that will keep you busy for
  the next 100 years so here we go:
</p>

<ul>
  <li>
    A very basic Lisp <a href="https://lisp-lang.org/learn/first-steps">tutorial</a> which also features an excellent
    <a href="https://lisp-lang.org/books/">list</a> of Lisp books
  </li>
  <li>
    <a href="https://smalldata.tech/api/to/3c02f249908494a961ac4b28e33f1ec5">A road to common lisp</a> - Steve Losh's excellent guide to
    getting into Lisp programming. The following is a small snippet of useful information from the post:
    <ul>
      <li>
        Files are files on your hard drive.
      </li>
      <li>Packages are containers of symbols. They are orthogonal to files.</li>
      <li>
        Systems are collections of code, instructions on how to load that code, dependency lists, and metadata. They are
        orthogonal to packages.
      </li>
      <li>
        Projects are high-level collections of "stuff" such as code, documentation, maybe some image assets,
        etc. They are (mostly) orthogonal to systems.
      </li>
      <li>Common Lisp itself knows about files and packages.</li>
      <li>ASDF adds systems.</li>
      <li>Quicklisp adds the internet.</li>
    </ul>

    This guide also provides a very nice review of libraries and is definitey worth a read.
  </li>
  <li>
    Another <a href="https://smalldata.tech/api/to/cb5d30e9026cba3d1d0b838611d1624c">article</a> that recommends roswell and provides
    instructions for Atom integration along with project and library management.
  </li>
</ul>

<p>
  Well, that's about it - Lisp is beautiful and I'm off to wrap my head around some 15 year old code that doesn't look
  too bad, go functional programming!
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2019%2F08%2F16%2Fgetting-started-with-lisp-in-2019&amp;t=Getting%20started%20with%20Lisp%20in%202019">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493495</guid>
            <pubDate>Mon, 21 Dec 2020 09:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Office Hours” Meetup (2014)]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25492576">thread link</a>) | @luu
<br/>
December 20, 2020 | https://ideolalia.com/essays/the-office-hours-meetup.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/the-office-hours-meetup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>Consider the meetup speaker.  She’s had a topic in mind for while, and so when the request went out for speakers, she volunteered.  But that was three months ago, and now the meetup’s only a few weeks away, and she hasn’t even begun.  She starts to outline the talk, but can’t quite figure out where to start.  She can explain all the details easily, but the order in which they should be introduced, the organizing structure of the talk, remains elusive.  Giving a talk about a subject, it turns out, is not the same as having a conversation about it.</p>

<p>Consider the first-time meetup attendee.  He’s been interested in the technology for a few months, but there doesn’t seem to be any guides that help him progress from the ubiquitous “hello world” or “distributed word count” examples to actual, effective production usage.  Maybe, he thinks, there will be some people at the meetup who can guide him through this awkward adolescence.  So after a long day at work, he wanders over to the meetup space, where everyone’s hanging around the open pizza boxes.  A few are eyeing the kegerator in the corner, wondering if it’s off-limits.  He stands next to them and eats his pizza, listening to their conversation, wondering if he should introduce himself or just wait for the talk to begin.</p>

<p>Consider the long-time meetup attendee.  He’s been using the technology for a few years, and wants its adoption to grow, so every month he comes to the meetup, eats the pizza, makes small talk with the other regular attendees, and dutifully listens to the talk.  The talk, unfortunately, is usually either too remedial or focused on something not very relevant to his day-to-day usage.  Also, the talks tend to be scattered, introducing concepts out of order, with lots of mental throat-clearing as the speaker tries to remember what was going through their head when they made the slide.  Usually within ten minutes half the audience is looking at their laptops, with only the occasional glance up to confirm that the talk is, in fact, still going on.  He attends almost every month, and often leaves wondering why he bothers.</p>

<p>In this based-on-a-true-story scenario, everyone’s motivations are good: they want to educate and to learn, to nurture and grow the community, to meet people who share their enthusiasm.  And yet, a typical meetup is at best weakly successful in all of these dimensions.  This is for a variety of reasons:</p>

<ul>
  <li><strong>Any growing community is at least half-filled with novices.</strong>  Very few assumptions can be made about what vocabulary and concepts are universally understood.  The speaker needs to make a conscious choice to either build up from first principles, greatly delaying the time it takes to get to the actual topic at hand, or leave a significant part of the audience behind.</li>
  <li><strong>Understanding something well enough to use it doesn’t mean you can explain it well.</strong>  We should all aspire to a clarity of understanding that lets us easily explain an idea to people from a variety of backgrounds, but that doesn’t come for free.  Details need to be synthesized into broader concepts, without losing sight of the practical knowledge necessary to apply those concepts.  Unsurprisingly, speakers are often still ascending that learning curve.</li>
  <li><strong>The standard lecture format expects and enforces passive participation.</strong> Ostensibly the attendees are making an active choice to learn and grow by attending a meetup, but upon arriving all that’s expected of them is to eat and listen.  Each attendee likely has interests and projects of their own, but unless the talk directly addresses them, any discussion must be crammed into the margins of the meetup - either before, when people are eating and the speaker is fussing with the projector, or after, when the hosts are tidying up and giving not-so-subtle looks to everyone who’s lingering.</li>
</ul>

<p>The lecture format still has value, of course, but much less so than its widespread usage would suggest.</p>

<p>In <a href="http://en.wikipedia.org/wiki/Seeing_Like_a_State">Seeing Like a State</a>, James Scott contrasts two Ancient Greek words for knowledge, <em>techne</em> and <em>metis</em>.  <em>Techne</em> is universal and timeless: the Pythagorean theorem and the <a href="http://en.wikipedia.org/wiki/Musica_universalis">harmony of the spheres</a>.  <em>Metis</em> is local and contextual: Odysseus infiltrating Troy and escaping the Cyclops.  Our educations are anchored in <em>techne</em> - data structures, algorithms, and exams with objectively correct answers - but upon entering the real world, we find the <em>techne</em> only takes us so far.  The problems we solve are not universal, they’re bounded by the context of our particular domains.  This is fortunate, because needing to solve the general form of every problem we come across would slow our work to a standstill.  However, this means our <em>metis</em> is unavoidably tangled up in the context in which we developed it.</p>

<p>Looking back, leaving the <em>techne</em> of school for the <em>metis</em> of our jobs can feel like a fall from grace.  What was once clear is now hopelessly muddled, littered with a thousand half-remembered details.  The promise of the lecture format is a return to that higher plane, an escape from the endless minutiae that awaits below.  And yet, most of what we’ve learned in our careers is within that minutiae.  There is enormous practical knowledge available at every meetup, and the lecture format uses almost none of it.</p>

<p>And so, at Factual we’ve been experimenting with <a href="http://www.meetup.com/The-Bay-Area-Clojure-User-Group/events/181057342/">a Clojure meetup</a> modeled on a different academic tradition: office hours.  At a university, students who have questions about the lecture content or coursework can visit the professor, and have a one-on-one conversation.  This can be enormously freeing for both parties: the student can ask questions without fear of looking stupid or holding up the rest of the class, and the professor can focus on giving an explanation that makes sense to this particular student, rather than the entire class.</p>

<p>At the beginning of every meetup, we give everyone a name tag, and provide a whiteboard with two columns, “teachers” and “students”.  Attendees are encouraged to put their name and interests in both columns.  From there, everyone can eat their food and read the whiteboard, and go in search of someone from the opposite column who shares their interests.  Typically they form groups of two or three, sometimes with a few more people listening in.</p>

<p>We’ve only had three meetups so far, each time with around twenty attendees, but the results have been promising.  It has been especially encouraging seeing novice Clojure users bring in their first project to get a critique of their approaches, and discuss how they can better use Clojure’s core abstractions.  These are precisely the sorts of conversations that create a healthy, growing community.</p>

<p>It’s unclear what the maximum practical size for this sort of meetup is.  Given the small size of each group it may scale fairly well, but at some point it becomes impossible for people to find each other.  Some sort of pre-event registration where people list their interests, and popular topics are assigned a physical location, may offset this.  However, for the vast majority of tech meetups, where the attendees number in the dozens rather than hundreds, this can be an enormously useful and engaging alternative to the lecture format.  We encourage everyone to give it a try.  And if you find yourself in San Francisco and have even a passing interest in Clojure, <a href="http://www.meetup.com/The-Bay-Area-Clojure-User-Group/events/181057342/">give us a visit</a>.</p>

<hr>

<p>This post was originally on the Factual blog, which has since been taken down post-acquisition.</p>


		</article>
	</div>

</div></div>]]>
            </description>
            <link>https://ideolalia.com/essays/the-office-hours-meetup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492576</guid>
            <pubDate>Mon, 21 Dec 2020 06:24:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Herald – Bluetooth contact tracing protocol]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25492423">thread link</a>) | @npad
<br/>
December 20, 2020 | https://vmware.github.io/herald/ | <a href="https://web.archive.org/web/*/https://vmware.github.io/herald/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div>
  <div>
    <div>
      <div>
        
        <p>Herald provides reliable Bluetooth communication and range finding across a wide range of mobile devices, allowing Contact Tracing and other applications to have regular and accurate information to make them highly effective.</p>        
      </div>
      
    </div>
  </div>
</div> <!-- /home-hero -->



<!--
<div class="section pb-0">
    <div class="section-content">
      <div class="row">
        <div class="col">
          <h2 class="text-center"></h2>
          <p></p>
  
          <ul>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
--> 

<div>
  <div>
    <div>
      <p>
        <h2>Herald solves risk estimation problems</h2>
      </p>          
    </div>
    <p><img src="https://vmware.github.io/herald/images/EstimationBenefits.png" alt="Herald estimation benefits">
  </p></div>
</div>

<div>
  <div>
    
    
    
<div>
  
    <div>
      
      <div>
        <div>
          
          <h5>Detect nearby phones</h5>
          
          
<p>100% detection of phones in the foreground and background across iOS and Android devices. <a href="https://vmware.github.io/herald/efficacy/herald">Herald supports</a>) 100% of the phones in the UK that support advertising, as well as the 35% of Android phones (<a href="https://vmware.github.io/herald/efficacy/statistics">~14% of all phones overall</a>) that cannot act as ‘advertisers’ and so remain unseen by advertising-only based protocols.</p>

          
        </div>
      </div>
    </div>
    
  
    <div>
      
      <div>
        <div>
          
          <h5>Provide regular distance readings</h5>
          
          
<p>Herald performs distance estimations every few seconds, with higher frequency on modern phones. This allows for a more accurate data and risk picture over time. Maximum frequency can be configured to optimise battery use. At <a href="https://vmware.github.io/herald/efficacy/herald">~4s per reading battery use is 6-11% over 8 hours</a>), depending on the age of the phone and its battery capacity.</p>

          
        </div>
      </div>
    </div>
    
  
    <div>
      
      <div>
        <div>
          
          <h5>Interoperate internationally</h5>
          
          
<p>By providing a common packet header we allow for <a href="https://vmware.github.io/herald/payload/interop">international interoperability</a> amongst all contact tracing applications, whether designed for centralised or decentralised contact matching and risk scoring.</p>

          
        </div>
      </div>
    </div>
    
        
</div>

  </div>
</div>

<div>
  <div>
    
    
    <div>

    
        
        


    <div>
    <div>
        <div>
            <p><img src="https://vmware.github.io/herald/img/herald.png" alt="New guides added to website">
                
            </p>
            <article>
                <h5>
                    <a href="https://vmware.github.io/herald/blog/guides">New guides added to website</a>
                </h5>
                <p>
                    We’ve been busy getting ready for the upcoming V1.1 release. For this release we’ve dramatically changed
our documentation on this website.


                </p>
            </article>
        </div>
    </div>
</div>
        
        


    <div>
    <div>
        <div>
            <p><img src="https://vmware.github.io/herald/img/herald.png" alt="New logo and website">
                
            </p>
            <article>
                <h5>
                    <a href="https://vmware.github.io/herald/blog/website">New logo and website</a>
                </h5>
                <p>
                    Quite a few things have happened in the first month since Herald was published as Open Source Software
under the MIT license. [29 Nov 2020 NOTE: Code now under the Apache-2.0 license]


                </p>
            </article>
        </div>
    </div>
</div>
        
         
</div>
    
  </div>
</div>


<div>
  <div>
    
<p>
A lot of work has gone in to mobile app based contact tracing protocol 
research, design, testing and collaboration worldwide. We'd like to thank 
all of those in VMware Pivotal Labs and elsewhere worldwide that have 
assisted with various national and state governments to use mobile contact 
tracing to help save lives. ❤️
</p>
  </div>
</div>

<div>
  <div>
    
<p>

All Herald works are Copyright 2020 Herald Authors.
</p>
<p>
The code for Herald (Android, iOS, Analysis Scripts, Calibration tool) are Apache-2.0 licensed. The documentation for Herald, including this website, are under the Creative Commons Attribution 4.0 International Public License.
</p>
<p>
See LICENSE.txt and NOTICE.txt for details.
</p>
  </div>
</div>


<div>
  <div>
    
<div>
  <div>
    <p>Herald Project is released as open source software and provides community support through our GitHub project page.
        If you encounter an issue or have a question, feel free to reach out on the <strong><a href="https://vmware.github.io/herald/issues">GitHub issues page for Herald Project</a></strong>.</p>
    <p>The Herald project team welcomes contributions from the community — please see our <strong><a href="https://github.com/vmware/herald/blob/master/contributing.md">contributing documentation</a></strong>.</p>
  </div>
</div>



  </div>
</div>
      <div>
    <div>
        <div>
            <div>
                <h5>Getting Started</h5>
                <p>To help you get started, see the documentation.</p>
            </div>
            
        </div>
    </div>
</div>




<!-- JS -->







    </div>
  </div></div>]]>
            </description>
            <link>https://vmware.github.io/herald/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492423</guid>
            <pubDate>Mon, 21 Dec 2020 05:44:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A TO-DO app that fits inside a single tweet]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25492302">thread link</a>) | @rukshn
<br/>
December 20, 2020 | https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/ | <a href="https://web.archive.org/web/*/https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Sunday morning while I was scrolling through my Twitter feed one tweet caught my eye,</p>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p><a href="https://twitter.com/hashtag/JavaScript?src=hash&amp;ref_src=twsrc%5Etfw">#JavaScript</a> Challenge:</p><p>Can you make a TO-DO app within a single Tweet? (280 chars)</p><p>The app should be able to add tasks, strike-through finished tasks &amp; clear all tasks.</p><p>Any general-purpose library is allowed.<br>Starting HTML body should be empty except the &lt;script&gt;.<a href="https://twitter.com/hashtag/JS?src=hash&amp;ref_src=twsrc%5Etfw">#JS</a> <a href="https://twitter.com/hashtag/code?src=hash&amp;ref_src=twsrc%5Etfw">#code</a></p></div>— Dumi (@dumindaxsb) <a href="https://twitter.com/dumindaxsb/status/1340539549890404354?ref_src=twsrc%5Etfw">December 20, 2020</a></blockquote>
<p>The challenge was to make a todo app that fits in a single tweet, just like any other todo app, you should be able to add or remove tasks and clear the task list. I thought how hard this can get, I thought to myself this is doable just by using plain JavaScript.</p>
<p>So since I don’t have a laptop, what resulted was a whole day of torture having to code though my iPad on codepen.</p>
<h2><strong>Plain JavaScript</strong> </h2>
<p>Soon after I started using plain JavaScript it became obvious that I was not able to make it within one tweet, the DOM manipulation was taking too much characters<em>, document.createElements, document.getElements. </em></p>
<p>It was obvious that was not the right approach.</p>
<h2>Using vue</h2>
<p>Vue framework won’t require any build tools, so I don’t have to go through setting up Webpack,</p>
<p>Also I can easily create the DOM within the script tag using simple HTML. So that will save some characters for me in DOM manipulation.</p>
<p>The first version I made use the <em>method</em> option in Vue app to handle button clicks, the button click event will call the function in methods to add new tasks and clear the task list.</p>
<p>However, I was unable to reduce it to one tweet. Then I went back to in-line functions, the same methods were added to button click events inline and not within the <em>methods</em> section.</p>
<p>Also I had to change buttons to anchor tags, in order to save some characters, and I had to use emojis instead of button text to save some more characters.</p>
<p>I also had to drop few buttons like a button to add a task, and instead I had to go with pressing enter key to add a task instead.</p>
<p>So I made the final version, the JavaScript code looked like this, </p>
<p data-height="300" data-theme-id="dark" data-default-tab="js" data-user="rukshn" data-slug-hash="qBaXmpE" data-pen-title="qBaXmpE">
<span>See the Pen <a href="https://codepen.io/rukshn/pen/qBaXmpE">
qBaXmpE</a> by Rukshan Ranatunge (<a href="https://codepen.io/rukshn">@rukshn</a>)
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>Then I ran the code through an online JavaScript minifier and then the whole HTML though an HTML minifier, and ended up with this piece of code,</p>
<pre><code>&lt;body&gt;&lt;script src=https://unpkg.com/<a href="https://ruky.me/cdn-cgi/l/email-protection" data-cfemail="81f7f4e4c1efe4f9f5">[email&nbsp;protected]</a>&gt;&lt;/script&gt;&lt;script&gt;var x={data:()=&gt;({t:[],k:""}),template:'&lt;input @keyup.enter="t.push(k)" v-model="k"&gt;&lt;a @click="t=[]"&gt;❎&lt;/a&gt;&lt;p v-for="(v,i) in t"&gt;&lt;a @click="t.splice(i,1)"&gt;🅾️&lt;/a&gt;{{v}}&lt;/p&gt;'};Vue.createApp(x).mount("body")&lt;/script&gt;</code></pre>
<p>With my fingers crossed, I copied the code on to Twitter, and guess what it fits perfectly inside a single Tweet.</p>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">&lt;body&gt;&lt;script src=<a href="https://t.co/FY9eWOxLgZ">https://t.co/FY9eWOxLgZ</a>&gt;&lt;/script&gt;&lt;script&gt;var x={data:()=&gt;({t:[],k:""}),template:'&lt;input <a href="https://twitter.com/keyup?ref_src=twsrc%5Etfw">@keyup</a>.enter="t.push(k)" v-model="k"&gt;&lt;a <a href="https://twitter.com/Click?ref_src=twsrc%5Etfw">@click</a>="t=[]"&gt;❎&lt;/a&gt;&lt;p v-for="(v,i) in t"&gt;&lt;a <a href="https://twitter.com/Click?ref_src=twsrc%5Etfw">@click</a>="t.splice(i,1)"&gt;🅾️&lt;/a&gt;{{v}}&lt;/p&gt;'};Vue.createApp(x).mount("body")&lt;/script&gt;</p>— Rukshan (@JustRuky) <a href="https://twitter.com/JustRuky/status/1340862545322762240?ref_src=twsrc%5Etfw">December 21, 2020</a></blockquote>
<p>And here is the code in action, <a href="https://jsbin.com/venihiliha/1/edit?html,output">link</a> </p>
<p data-height="265" data-theme-id="dark" data-default-tab="result" data-user="rukshn" data-slug-hash="qBaXmpE" data-pen-title="qBaXmpE">
<span>See the Pen <a href="https://codepen.io/rukshn/pen/qBaXmpE">
qBaXmpE</a> by Rukshan Ranatunge (<a href="https://codepen.io/rukshn">@rukshn</a>)
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<h2>What I failed to achieve </h2>
<p>The original Tweet says, that the completed tasks should have a strike through.</p>
<p>But because css was costing me too much characters I had to fall back to remove completed tasks instead, but I’m sure someone will figure a solution for that as well.</p>
<p>At the same time, I think you can save even more characters by using <a href="https://mithril.js.org/">mithril</a>, because you have short-codes for DOM elements as well, but I haven’t tried mithril in awhile.</p>
<h4>One last thing</h4>
<p>No I didn’t waste my whole Sunday on this problem, but I had to spend few hours, thinking and trying different versions. </p>
<p>I would have cut back some more time if I had a laptop. Somerimes I feel like buying an old laptop and refurbishing it and installing Ubuntu on it.</p>
<p>Sunday well spent? Absolutely yes.</p>
<h2>Best answer?</h2>
<p>One thing I love about HN is the fact that there are lot of bright minds out there. Since I posted this on HN I knew it was just a matter of time since someone figures this out.</p>
<p>I guess this is the best answer and also ticks all the boxes, well done.</p>
<pre><code> &lt;script&gt;document.write(`&lt;style&gt;:checked+*{text-decoration:line-through}#t{display:none}&lt;/style&gt;&lt;p id="t"&gt;&lt;input type="checkbox"&gt;&lt;input&gt;&lt;div id="f"&gt;&lt;/div&gt;&lt;p&gt;&lt;button onclick="f.appendChild(t.cloneNode(true)).id=''"&gt;+&lt;/button&gt;&lt;button onclick="f.innerHTML=''"&gt;×&lt;/button&gt;`)&lt;/script&gt;</code></pre>
<p><strong>HN link to this answer</strong>: https://news.ycombinator.com/item?id=25493533</p>
<p><strong>Original thread on HN</strong>: https://news.ycombinator.com/item?id=25492302</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492302</guid>
            <pubDate>Mon, 21 Dec 2020 05:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modeling TLA+ in Z3Py (2020)]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25492150">thread link</a>) | @philzook
<br/>
December 20, 2020 | https://www.philipzucker.com/Modelling_TLA_in_z3py/ | <a href="https://web.archive.org/web/*/https://www.philipzucker.com/Modelling_TLA_in_z3py/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It’s that time of year again where I’m fiddling around with Z3Py. I’m booting it back up because I’m scheduled to do a <a href="https://fmie2021.github.io/agenda.html">tutorial on Z3</a> on Feb 3. It’s kind of silly because I probably already have too much content, and the tutorial is aimed at newbies, but there are some fun new things that I’ve learned in the last year I can do in Z3. As one example, it’s not so hard to build a pretty reasonable simulacrum of TLA+ in Z3.</p>

<p><a href="https://lamport.azurewebsites.net/tla/tla.html">TLA+</a> is a modelling/specification language for computational processes. It is particularly useful for modeling concurrency, where our intuitions fail us <a href="http://deadlockempire.github.io/">http://deadlockempire.github.io/</a>. It’s the mind child of Leslie Lamport, the same guy behind <a href="https://en.wikipedia.org/wiki/LaTeX">LaTex</a> and <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>. The language doesn’t aim for deep verification of your actual code as is sometimes the goal with tools like Coq, but because of that it is significantly more lightweight and easy to use. 
The <a href="https://lamport.azurewebsites.net/tla/toolbox.html">TLA+ Toolbox</a> is a freely available IDE and checker to TLA+, but I think it is kind of a neat idea to replicate something in the flavor of TLA+ in all too familiar python. By leveraging Z3, we can get a lot of logical mileage and solver power for free.</p>

<p><a href="https://rise4fun.com/z3/tutorial">Z3</a> is an SMT solver. Its input language <a href="http://smtlib.cs.uiowa.edu/examples.shtml">smtlib2</a> is a kind of typed first order logic with special support for things like booleans, integers, reals, bitvectors, and algebraic datatypes. You can ask Z3 if propositions are valid, or if not it can provide a counterexample. It works pretty crazy good, especially if you work around its weaknesses (mostly quantifiers and nasty nonlinear stuff). Z3 has top class performance and its <a href="https://z3prover.github.io/api/html/namespacez3py.html">python bindings</a> are widely regarded as very good.</p>

<p>The main unusual things TLA brings into play compared to bog standard logics is the primed variables \(x'\), representing the values of variables at the next time step, and some temporal operators like always \(\Box\) and eventually \(\Diamond\).</p>

<p>We could mark primes by creating variables in pairs</p>
<div><div><pre><code><span>from</span> <span>z3</span> <span>import</span> <span>*</span>
<span>x</span><span>,</span> <span>xnxt</span> <span>=</span> <span>Ints</span><span>(</span><span>"x x'"</span><span>)</span>
</code></pre></div></div>

<p>But I’ve chosen to mark the prime variables using a special uninterpreted function, which we strip out later.</p>

<div><div><pre><code><span>def</span> <span>nxt</span><span>(</span><span>x</span><span>):</span> <span># next is a special function for generators in python, so we shouldn't use that name
</span>    <span>assert</span> <span>is_const</span><span>(</span><span>x</span><span>)</span>
    <span>assert</span> <span>f</span><span>.</span><span>decl</span><span>().</span><span>kind</span><span>()</span> <span>==</span> <span>Z3_OP_UNINTERPRETED</span><span>:</span>
    <span>s</span> <span>=</span> <span>x</span><span>.</span><span>sort</span><span>()</span>
    <span>return</span> <span>Function</span><span>(</span><span>"nxt"</span><span>,</span> <span>s</span><span>,</span> <span>s</span><span>)(</span><span>x</span><span>)</span>
</code></pre></div></div>

<p>One breakage here as compared to with TLA+ is the use of types. TLA+ curiously insists on a lack of intrinsic types and argues against them as a foundational feature. Types are instead propositions that are proved in the system. This just is really not convenient for using with Z3, so from the get-go I’m going to take liberties.</p>

<p>We can implement an <code>always</code> operator via a fairly simple procedure, we just roll out the execution of any formula for <code>n</code> time steps. This is the trick of bounded model checking. This rollout can be achieved by using the Z3 <code>substitute</code> function, a surprisingly useful little fellow.</p>

<div><div><pre><code><span># collects up all the variable from a formula
# https://stackoverflow.com/questions/14080398/z3py-how-to-get-the-list-of-variables-from-a-formula
</span><span>def</span> <span>get_vars</span><span>(</span><span>f</span><span>):</span>
    <span>r</span> <span>=</span> <span>set</span><span>()</span>
    <span>def</span> <span>collect</span><span>(</span><span>f</span><span>):</span>
      <span>if</span> <span>is_const</span><span>(</span><span>f</span><span>):</span> 
          <span>if</span> <span>f</span><span>.</span><span>decl</span><span>().</span><span>kind</span><span>()</span> <span>==</span> <span>Z3_OP_UNINTERPRETED</span><span>:</span>
              <span>r</span><span>.</span><span>add</span><span>(</span><span>f</span><span>)</span>
      <span>else</span><span>:</span>
          <span>for</span> <span>c</span> <span>in</span> <span>f</span><span>.</span><span>children</span><span>():</span>
              <span>collect</span><span>(</span><span>c</span><span>)</span>
    <span>collect</span><span>(</span><span>f</span><span>)</span>
    <span>return</span> <span>r</span>


<span>#https://theory.stanford.edu/~nikolaj/programmingz3.html#sec-bounded-model-checking
# rolls out the transition relation for n steps
# it replaces x with x_i and prime(x) with x_(i+1)
</span><span>def</span> <span>always</span><span>(</span><span>p</span><span>,</span><span>n</span><span>=</span><span>20</span><span>):</span>
    <span>orig_vs</span> <span>=</span> <span>get_vars</span><span>(</span><span>p</span><span>)</span>
    <span>nextvs</span> <span>=</span> <span>orig_vs</span>
    <span>t</span> <span>=</span> <span>True</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span><span>n</span><span>):</span>
        <span>vs</span> <span>=</span> <span>nextvs</span>
        <span>nextvs</span> <span>=</span>  <span>[</span> <span>Const</span><span>(</span> <span>f"</span><span>{</span><span>str</span><span>(</span><span>v</span><span>)</span><span>}</span><span>_</span><span>{</span><span>i</span><span>}</span><span>"</span><span>,</span> <span>v</span><span>.</span><span>sort</span><span>())</span> <span>for</span> <span>v</span> <span>in</span> <span>orig_vs</span>  <span>]</span>
        <span>p1</span> <span>=</span> <span>substitute</span><span>(</span><span>p</span><span>,</span> <span>[</span> <span>(</span><span>nxt</span><span>(</span><span>v</span><span>),</span> <span>nextv</span><span>)</span> <span>for</span> <span>v</span><span>,</span> <span>nextv</span> <span>in</span> <span>zip</span><span>(</span><span>orig_vs</span><span>,</span><span>nextvs</span><span>)</span>  <span>])</span> 
        <span>p2</span> <span>=</span> <span>substitute</span><span>(</span><span>p1</span><span>,</span> <span>[</span> <span>(</span><span>orig_v</span><span>,</span> <span>v</span><span>)</span> <span>for</span> <span>orig_v</span><span>,</span> <span>v</span> <span>in</span> <span>zip</span><span>(</span><span>orig_vs</span><span>,</span><span>vs</span><span>)</span>  <span>])</span>
        <span>t</span> <span>=</span> <span>And</span><span>(</span><span>t</span><span>,</span><span>p2</span><span>)</span>
    <span>return</span> <span>t</span>
</code></pre></div></div>

<p>Here for example is the specification of a clock from the <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/05/book-02-08-08.pdf">Specifying Systems</a> book. The clock starts with an hour between 0 and 12, and at each time step increases unless it’s wrapped around 12.</p>

<div><div><pre><code><span>hr</span> <span>=</span> <span>Int</span><span>(</span><span>"hr"</span><span>)</span>
<span>HCini</span> <span>=</span> <span>And</span><span>(</span><span>1</span> <span>&lt;=</span> <span>hr</span><span>,</span> <span>hr</span> <span>&lt;=</span> <span>12</span><span>)</span>
<span>HCnxt</span> <span>=</span> <span>nxt</span><span>(</span><span>hr</span><span>)</span> <span>==</span> <span>If</span><span>(</span><span>hr</span> <span>!=</span> <span>12</span><span>,</span> <span>hr</span> <span>+</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
<span>HC</span> <span>=</span> <span>And</span><span>(</span><span>HCini</span><span>,</span> <span>always</span><span>(</span><span>HCnxt</span><span>))</span> 
<span>prove</span><span>(</span><span>Implies</span><span>(</span><span>HC</span><span>,</span>  <span>always</span><span>(</span><span>HCini</span><span>)))</span> <span># prove clock always stays between 0 and 12 (for 20 times steps)
</span></code></pre></div></div>

<p>You do have to be careful with using always. Arbitrarily nesting it’s usage may give unexpected results. Lamport makes an argument that specs very rarely do or should make sophisticated use of the temporal operators. Maybe this is good enough or maybe there is a way to patch this up.</p>

<p>Here are some other useful TLA+ like features and functions transcoded.</p>

<div><div><pre><code><span>def</span> <span>elem</span><span>(</span><span>x</span><span>,</span><span>S</span><span>):</span>
    <span>return</span> <span>Or</span><span>([</span><span>x</span> <span>==</span> <span>s</span> <span>for</span> <span>s</span> <span>in</span> <span>S</span><span>])</span>

<span>def</span> <span>unchanged</span><span>(</span><span>*</span><span>args</span><span>):</span>
    <span>return</span> <span>And</span><span>([</span><span>prime</span><span>(</span><span>x</span><span>)</span> <span>==</span> <span>x</span> <span>for</span> <span>x</span> <span>in</span> <span>args</span><span>])</span>

<span>def</span> <span>eventually</span><span>(</span><span>p</span><span>,</span> <span>n</span><span>=</span><span>20</span><span>):</span>
    <span>return</span> <span>Not</span><span>(</span><span>always</span><span>(</span><span>Not</span><span>(</span><span>p</span><span>),</span><span>n</span><span>=</span><span>n</span><span>))</span>

<span>def</span> <span>stutter</span><span>(</span><span>p</span><span>,</span> <span>vars</span><span>=</span><span>None</span><span>):</span>
    <span>if</span> <span>vars</span> <span>==</span> <span>None</span><span>:</span>
        <span>vars</span> <span>=</span> <span>get_vars</span><span>(</span><span>p</span><span>)</span>
    <span>return</span> <span>Or</span><span>(</span><span>p</span><span>,</span> <span>unchanged</span><span>(</span><span>*</span><span>vars</span><span>))</span>

<span>def</span> <span>enabled</span><span>(</span><span>A</span><span>):</span>
    <span>vs</span> <span>=</span> <span>get_vars</span><span>(</span><span>A</span><span>)</span>
    <span>nxtvs</span> <span>=</span>  <span>[</span> <span>FreshConst</span><span>(</span>  <span>v</span><span>.</span><span>sort</span><span>(),</span> <span>prefix</span><span>=</span><span>str</span><span>(</span><span>v</span><span>)</span> <span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vs</span><span>]</span>
    <span>p1</span> <span>=</span> <span>substitute</span><span>(</span><span>A</span><span>,</span> <span>[</span> <span>(</span><span>nxt</span><span>(</span><span>v</span><span>),</span> <span>nextv</span><span>)</span> <span>for</span> <span>v</span><span>,</span> <span>nextv</span> <span>in</span> <span>zip</span><span>(</span><span>vs</span><span>,</span><span>nxtvs</span><span>)</span>  <span>])</span> 
    <span>return</span> <span>Exists</span><span>(</span><span>nxtvs</span><span>,</span> <span>p1</span><span>)</span>

<span># backports useful logical operator notation for z3 that it does not have by default
</span><span>BoolRef</span><span>.</span><span>__and__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>And</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__or__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>Or</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__xor__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>Xor</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__invert__</span> <span>=</span> <span>lambda</span> <span>self</span><span>:</span> <span>Not</span><span>(</span><span>self</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__rshift__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>Implies</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
</code></pre></div></div>

<p>Here as another example is the <a href="http://lamport.azurewebsites.net/video/video4.html">Die Hard puzzle</a></p>

<div><div><pre><code><span>small</span><span>,</span> <span>big</span> <span>=</span> <span>Ints</span><span>(</span><span>"small big"</span><span>)</span>

<span>TypeOk</span> <span>=</span> <span>And</span><span>(</span>
   <span>elem</span><span>(</span><span>small</span><span>,</span> <span>range</span><span>(</span><span>4</span><span>)),</span>
   <span>elem</span><span>(</span><span>big</span><span>,</span> <span>range</span><span>(</span><span>6</span><span>))</span>
<span>)</span>
<span>Init</span> <span>=</span> <span>And</span><span>(</span>
   <span>big</span> <span>==</span> <span>0</span><span>,</span>
   <span>small</span> <span>==</span> <span>0</span>
<span>)</span>

<span>FillSmall</span> <span>=</span> <span>And</span><span>(</span><span>prime</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>3</span><span>,</span> <span>unchanged</span><span>(</span><span>big</span><span>))</span>
<span>FillBig</span> <span>=</span> <span>And</span><span>(</span><span>prime</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>5</span><span>,</span> <span>unchanged</span><span>(</span><span>small</span><span>))</span>
<span>Goal</span> <span>=</span> <span>big</span> <span>!=</span> <span>4</span>
<span>SmallToBig</span> <span>=</span> <span>If</span><span>(</span><span>big</span> <span>+</span> <span>small</span> <span>&lt;=</span> <span>5</span><span>,</span>   
                 <span>And</span><span>(</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>big</span> <span>+</span> <span>small</span><span>,</span> <span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>0</span> <span>)</span> <span>,</span> 
                 <span>And</span><span>(</span><span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>small</span> <span>-</span> <span>(</span><span>5</span> <span>-</span> <span>big</span><span>),</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>5</span><span>)</span>
               <span>)</span>

<span>BigToSmall</span> <span>=</span> <span>If</span><span>(</span> <span>big</span> <span>+</span> <span>small</span> <span>&lt;=</span> <span>3</span><span>,</span>
                 <span>And</span><span>(</span> <span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>big</span> <span>+</span> <span>small</span><span>,</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>0</span><span>),</span>
                 <span>And</span><span>(</span> <span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>3</span><span>,</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>big</span> <span>-</span> <span>(</span><span>3</span> <span>-</span> <span>small</span><span>)</span> <span>)</span>
                <span>)</span>

<span>EmptyBig</span> <span>=</span> <span>And</span><span>(</span><span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>0</span><span>,</span>  <span>unchanged</span><span>(</span><span>small</span><span>))</span> 
<span>EmptySmall</span> <span>=</span> <span>And</span><span>(</span><span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>0</span><span>,</span>  <span>unchanged</span><span>(</span><span>big</span><span>))</span> 
<span>Next</span> <span>=</span> <span>Or</span><span>(</span><span>FillSmall</span><span>,</span> <span>FillBig</span><span>,</span> <span>EmptySmall</span><span>,</span> <span>EmptyBig</span><span>,</span> <span>SmallToBig</span><span>,</span> <span>BigToSmall</span><span>)</span>

<span>Spec</span> <span>=</span> <span>Init</span> <span>&amp;</span> <span>always</span><span>(</span><span>Next</span><span>,</span> <span>n</span><span>=</span><span>8</span><span>)</span>
<span>prove</span><span>(</span> <span>Implies</span><span>(</span><span>Spec</span>  <span>,</span> <span>always</span><span>(</span><span>Goal</span><span>,</span> <span>n</span> <span>=</span> <span>8</span><span>)))</span>
</code></pre></div></div>

<p>Z3 does in fact return a counter model that fills the buckets up as desired.</p>

<p>TLA+ has a tendency to use functions/records which are not so obvious how to encode. There are different ways of going about this. One aspect of playing around with Z3py is that it makes extremely clear the existence of the logic language and a metalanguage. The logic is Z3 expressions, but the metalanguage is python and they are obviously very different. But there is often a choice of whether to encode things in the logic vs the metalanguage. It is usually better I think to encode as much in python as possible if you can get away with it. Z3 likes piles of simple constraints more than it likes complicated quantifiers and things.</p>

<p>For example, we can want to encode an Enum type in python or in Z3.</p>

<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span><span>,</span> <span>auto</span>
<span>#python enum
</span><span>class</span> <span>RMState</span><span>(</span><span>Enum</span><span>):</span>
     <span>WORKING</span> <span>=</span> <span>auto</span><span>()</span>
     <span>PREPARED</span> <span>=</span> <span>auto</span><span>()</span>
     <span>COMMITTED</span> <span>=</span> <span>auto</span><span>()</span>
     <span>ABORTED</span> <span>=</span> <span>auto</span><span>()</span>

<span># z3 enum
</span><span>RMState</span> <span>=</span> <span>Datatype</span><span>(</span><span>"RMState"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"working"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"prepared"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"committed"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"aborted"</span><span>)</span>
<span>RMState</span> <span>=</span> <span>RMState</span><span>.</span><span>create</span><span>()</span>
</code></pre></div></div>

<p>Or we can choose to encode records in Z3 vs python.</p>

<div><div><pre><code><span>#python record of z3 values
</span><span>val</span> <span>=</span> <span>Int</span><span>(</span><span>"val"</span><span>)</span>
<span>rdy</span><span>,</span> <span>ack</span> <span>=</span> <span>Bools</span><span>(</span><span>"rdy ack"</span><span>)</span>
<span>chan</span> <span>=</span> <span>{</span><span>val</span> <span>:</span> <span>val</span><span>,</span> <span>rdy</span> <span>:</span> <span>rdy</span><span>,</span> <span>ack</span> <span>:</span> <span>ack</span><span>}</span>

<span># Z3 record of Z3 values
</span><span>Chan</span> <span>=</span> <span>Datatype</span><span>(</span><span>"Chan"</span><span>)</span>
<span>ChanCon</span> <span>=</span> <span>Chan</span><span>.</span><span>declare</span><span>(</span><span>"constr"</span><span>,</span> <span>(</span><span>"val"</span><span>,</span> <span>IntSort</span><span>())</span> <span>,</span> <span>(</span><span>"rdy"</span><span>,</span> <span>BoolSort</span><span>()),</span>  <span>(</span><span>"ack"</span><span>,</span> <span>BoolSort</span><span>())</span> <span>)</span>
<span>Chan</span> <span>=</span> <span>Chan</span><span>.</span><span>create</span><span>()</span>
<span>record</span> <span>=</span> <span>Chan</span><span>.</span><span>constr</span><span>(</span><span>val</span><span>,</span><span>rdy</span><span>,</span><span>ack</span><span>)</span>
<span>chan</span> <span>=</span> <span>Const</span><span>(</span><span>"chan"</span><span>,</span> <span>Chan</span><span>)</span>
</code></pre></div></div>

<p>Or we can choose to encode functions in z3 or python</p>

<div><div><pre><code><span># python square. Works of Z3 values too
</span><span>def</span> <span>square</span><span>(</span><span>x</span><span>):</span>
    <span>return</span> <span>x</span><span>*</span><span>x</span>

<span># Internalized Z3 square function
</span><span>square</span> <span>=</span> <span>Function</span><span>(</span><span>"square"</span><span>,</span> <span>IntSort</span><span>(),</span><span>IntSort</span><span>())</span>
<span>x</span> <span>=</span> <span>Int</span><span>(</span><span>"x"</span><span>)</span>
<span>square_axiom</span> <span>=</span> <span>ForAll</span><span>([</span><span>x</span><span>],</span> <span>square</span><span>(</span><span>x</span><span>)</span> <span>==</span> <span>x</span> <span>*</span> <span>x</span><span>)</span>
</code></pre></div></div>

<h3 id="bits-and-bobbles">Bits and Bobbles</h3>

<p>Downsides:</p>

<ul>
  <li>Very ad hoc. The use of special autogenerated names is a great way to inadvertently smash things together</li>
  <li>TLA syntax is designed to be readable. The python adds a lot of noise</li>
  <li>TLA toolbox can format specs nicely using latex.</li>
  <li>TLA has a lot of thought gone into it. Making changes to it in an afternoon of thought is probably not to be trusted</li>
</ul>

<p>Upsides:</p>
<ul>
  <li>Better fits Z3, so we get good automation from the get go</li>
  <li>python is lingua franca of computing. It is comforting compared to TLA+, even if Z3py might be discomfiting.</li>
  <li>Having to download the toolbox and figure out how to use it is always going to be a slight speedbump. There is a TLA+ vscode extension now though. That might help</li>
</ul>

<p>Using Python ast parsing <a href="https://greentreesnakes.readthedocs.io/en/latest/index.html">https://greentreesnakes.readthedocs.io/en/latest/index.html</a>, we could probably use regular simple python syntax as a PlusCal like DSL and compile it into the above Z3-TLA+ hybrid.</p>

<p>I’m not sure if the CHOOSE operator of TLA+ will be easy to implement. It kind of seems like it requires nested solves? Can it be encoded using</p>

<p>I don’t particularly understand the TLA+ module system yet and I’m not so sure how to emulate it. Python modules might be one way, or perhaps classes.</p>

<p>Although I tried to copy exactly, perhaps one shouldn’t spec in precisely the style of standard TLA+.</p>

<h3 id="links">Links</h3>

<ul>
  <li><a href="https://www.learntla.com/introduction/">https://www.learntla.com/introduction/</a> Hillel Wayne’s tutorial</li>
  <li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/05/book-02-08-08.pdf">https://www.microsoft.com/en-us/research/uploads/prod/2018/05/book-02-08-08.pdf</a> Specifying Systems</li>
  <li><a href="https://pron.github.io/tlaplus">https://pron.github.io/tlaplus</a>  Very impressive essays by Ron Pressler</li>
  <li><a href="https://github.com/cobusve/TLAPLUS_DeadlockEmpire">https://github.com/cobusve/TLAPLUS_DeadlockEmpire</a> Very neat way to learn TLA+</li>
  <li><a href="https://github.com/tlaplus/Examples">https://github.com/tlaplus/Examples</a></li>
  <li>Apalache is a Z3 backed model checker for TLA+ <a href="https://github.com/informalsystems/apalache">https://github.com/informalsy…</a></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.philipzucker.com/Modelling_TLA_in_z3py/">https://www.philipzucker.com/Modelling_TLA_in_z3py/</a></em></p>]]>
            </description>
            <link>https://www.philipzucker.com/Modelling_TLA_in_z3py/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492150</guid>
            <pubDate>Mon, 21 Dec 2020 04:31:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix Recovery Legend (1986)]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25491790">thread link</a>) | @signa11
<br/>
December 20, 2020 | https://www.ee.ryerson.ca/~elf/hack/recovery.html | <a href="https://web.archive.org/web/*/https://www.ee.ryerson.ca/~elf/hack/recovery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h4>This classic article from Mario Wolczko first
appeared on Usenet in 1986.  </h4>

Have you ever left your terminal logged in, only to find when you
came back to it that a (supposed) friend had typed "<kbd>rm -rf
~/*</kbd>" and was hovering over the keyboard with threats along the
lines of "<em>lend me a fiver 'til Thursday, or I hit return</em>"?
Undoubtedly the person in question would not have had the nerve to
inflict such a trauma upon you, and was doing it in jest.  So you've
probably never experienced the worst of such disasters....<p>


It was a quiet Wednesday afternoon.  Wednesday, 1st October, 15:15
BST, to be precise, when Peter, an office-mate of mine, leaned away
from his terminal and said to me, "<em>Mario, I'm having a little
trouble sending mail.</em>" Knowing that msg was capable of confusing
even the most capable of people, I sauntered over to his terminal to
see what was wrong.  A strange error message of the form (I forget
the exact details) "<kbd>cannot access /foo/bar for userid 147</kbd>"
had been issued by msg.  My first thought was "<em>Who's userid 147?;
the sender of the message, the destination, or what?</em>" So I leant
over to another terminal, already logged in, and typed</p><blockquote>        <kbd>grep 147 /etc/passwd</kbd></blockquote>

<p>only to receive the response</p><blockquote>        <kbd>/etc/passwd: No such file or directory.</kbd></blockquote>

Instantly, I guessed that something was amiss.  This was confirmed
when in response to<blockquote>        <kbd>ls /etc</kbd></blockquote>

<p>I got</p><blockquote>        <kbd>ls: not found.</kbd></blockquote>

I suggested to Peter that it would be a good idea not to try anything
for a while, and went off to find our system manager.<p>

When I arrived at his office, his door was ajar, and within ten
seconds I realised what the problem was.  James, our manager, was
sat down, head in hands, hands between knees, as one whose world has
just come to an end.  Our newly-appointed system programmer, Neil, was
beside him, gazing listlessly at the screen of his terminal.  And at
the top of the screen I spied the following lines:</p><blockquote>
        <kbd># cd <br>
        # rm -rf *</kbd>
</blockquote>

<p>Oh, shit, I thought.  That would just about explain it.</p><p>


I can't remember what happened in the succeeding minutes; my memory
is just a blur.  I do remember trying <kbd>ls</kbd> (again),
<kbd>ps</kbd>, <kbd>who</kbd> and maybe a few other commands beside,
all to no avail.  The next thing I remember was being at my terminal
again (a multi-window graphics terminal), and typing</p><blockquote>
        <kbd>cd /<br>
        echo *</kbd>
</blockquote>
<p>I owe a debt of thanks to David Korn for making <kbd>echo</kbd> a
built-in of his shell; needless to say, <kbd>/bin</kbd>, together
with <kbd>/bin/echo</kbd>, had been deleted.  What transpired in the
next few minutes was that <kbd>/dev</kbd>, <kbd>/etc</kbd> and
<kbd>/lib</kbd> had also gone in their entirety; fortunately Neil had
interrupted <kbd>rm</kbd> while it was somewhere down below
<kbd>/news</kbd>, and <kbd>/tmp</kbd>, <kbd>/usr</kbd> and
<kbd>/users</kbd> were all untouched.</p><p>


Meanwhile James had made for our tape cupboard and had retrieved what
claimed to be a dump tape of the root filesystem, taken four weeks
earlier.  The pressing question was, "<em>How do we recover the
contents of the tape?</em>".  Not only had we lost
<kbd>/etc/restore</kbd>, but all of the device entries for the tape
deck had vanished.  And where does <kbd>mknod</kbd> live?  You
guessed it, <kbd>/etc</kbd>.  How about recovery across Ethernet of
any of this from another VAX?  Well, <kbd>/bin/tar</kbd> had gone,
and thoughtfully the Berkeley people had put <kbd>rcp</kbd> in
<kbd>/bin</kbd> in the 4.3 distribution.  What's more, none of the
Ether stuff wanted to know without <kbd>/etc/hosts</kbd> at least.
We found a version of <kbd>cpio</kbd> in <kbd>/usr/local</kbd>, but
that was unlikely to do us any good without a tape deck.</p><p>


Alternatively, we could get the boot tape out and rebuild the root
filesystem, but neither James nor Neil had done that before, and we
weren't sure that the first thing to happen would be that the whole
disk would be re-formatted, losing all our user files.  (We take dumps
of the user files every Thursday; by Murphy's Law this had to happen
on a Wednesday).  Another solution might be to borrow a disk from
another VAX, boot off that, and tidy up later, but that would have
entailed calling the DEC engineer out, at the very least.  We had a
number of users in the final throes of writing up PhD theses and the
loss of a maybe a weeks' work (not to mention the machine down time)
was unthinkable.</p><p>


So, what to do?  The next idea was to write a program to make a
device descriptor for the tape deck, but we all know where
<kbd>cc</kbd>, <kbd>as</kbd> and <kbd>ld</kbd> live.  Or maybe make
skeletal entries for <kbd>/etc/passwd</kbd>, <kbd>/etc/hosts</kbd>
and so on, so that <kbd>/usr/bin/ftp</kbd> would work.  By sheer
luck, I had a <kbd>gnuemacs</kbd> still running in one of my windows,
which we could use to create <kbd>passwd</kbd>, etc., but the first
step was to create a directory to put them in.  Of course
<kbd>/bin/mkdir</kbd> had gone, and so had <kbd>/bin/mv</kbd>, so we
couldn't rename <kbd>/tmp</kbd> to <kbd>/etc</kbd>.  However, this
looked like a reasonable line of attack.</p><p>


By now we had been joined by Alasdair, our resident UNIX guru, and as
luck would have it, someone who knows VAX assembler.  So our plan
became this: write a program in assembler which would either rename
<kbd>/tmp</kbd> to <kbd>/etc</kbd>, or make <kbd>/etc</kbd>, assemble
it on another VAX, <kbd>uuencode</kbd> it, type in the uuencoded file
using my gnu, <kbd>uudecode</kbd> it (some bright spark had thought
to put <kbd>uudecode</kbd> in <kbd>/usr/bin</kbd>), run it, and hey
presto, it would all be plain sailing from there.  By yet another
miracle of good fortune, the terminal from which the damage had been
done was still <kbd>su</kbd>'d to root (<kbd>su</kbd> is in
<kbd>/bin</kbd>, remember?), so at least we stood a chance of all
this working.</p><p>


Off we set on our merry way, and within only an hour we had managed
to concoct the dozen or so lines of assembler to create
<kbd>/etc</kbd>.  The stripped binary was only 76 bytes long, so we
converted it to hex (slightly more readable than the output of
<kbd>uuencode</kbd>), and typed it in using my editor.  If any of you
ever have the same problem, here's the hex for future reference:</p><blockquote>
   <kbd>070100002c000000000000000000000000000000000000000000000000000000<br>
        0000dd8fff010000dd8f27000000fb02ef07000000fb01ef070000000000bc8f<br>
		8800040000bc012f65746300</kbd>
</blockquote>

<p>

I had a handy program around (doesn't everybody?) for converting
ASCII hex to binary, and the output of <kbd>/usr/bin/sum</kbd>
tallied with our original binary.  But hang on---how do you set
execute permission without <kbd>/bin/chmod</kbd>?  A few seconds
thought (which as usual, lasted a couple of minutes) suggested that
we write the binary on top of an already existing binary, owned by
me...problem solved.

So along we trotted to the terminal with the root login, carefully
remembered to set the umask to 0 (so that I could create files in it
using my gnu), and ran the binary.  So now we had a <kbd>/etc</kbd>,
writable by all.  From there it was but a few easy steps to creating
<kbd>passwd</kbd>, <kbd>hosts</kbd>, <kbd>services</kbd>,
<kbd>protocols</kbd>, (etc), and then <kbd>ftp</kbd> was willing to
play ball.  Then we recovered the contents of <kbd>/bin</kbd> across
the ether (it's amazing how much you come to miss <kbd>ls</kbd> after
just a few, short hours), and selected files from <kbd>/etc</kbd>.
The key file was <kbd>/etc/rrestore</kbd>, with which we recovered
<kbd>/dev</kbd> from the dump tape, and the rest is history.</p><p>


Now, you're asking yourself (as I am), what's the moral of this
story?  Well, for one thing, you must always remember the immortal
words, <strong>DON'T PANIC</strong>.  Our initial reaction was to
reboot the machine and try everything as single user, but it's
unlikely it would have come up without <kbd>/etc/init</kbd> and
<kbd>/bin/sh</kbd>.  Rational thought saved us from this one.</p><p>


The next thing to remember is that UNIX tools really can be put to
unusual purposes.  Even without my <kbd>gnuemacs</kbd>, we could have
survived by using, say, <kbd>/usr/bin/grep</kbd> as a substitute for
<kbd>/bin/cat</kbd>.</p><p>


And the final thing is, it's amazing how much of the system you can
delete without it falling apart completely.  Apart from the fact that
nobody could login (<kbd>/bin/login</kbd>?), and most of the useful
commands had gone, everything else seemed normal.  Of course, some
things can't stand life without say <kbd>/etc/termcap</kbd>, or
<kbd>/dev/kmem</kbd>, or <kbd>/etc/utmp</kbd>, but by and large it
all hangs together.</p><p>


I shall leave you with this question: if you were placed in the same
situation, and had the presence of mind that always comes with
hindsight, could you have got out of it in a simpler or easier way?
Answers on a postage stamp to:</p><pre>Mario Wolczko
------------------------------------------------------------------------
Dept. of Computer Science       ARPA:   miw%uk.ac.man.cs.ux@cs.ucl.ac.uk
The University                  USENET: mcvax!ukc!man.cs.ux!miw
Manchester M13 9PL              JANET:  miw@uk.ac.man.cs.ux
U.K.                            061-273 7121 x 5699
------------------------------------------------------------------------
</pre>

<hr>

<address><a href="https://www.ee.ryerson.ca/~elf/hack/index.html">Hacker's Wisdom</a>: Unix Recovery
Legend</address>

<!-- hhmts start -->
Last modified: Thu Mar  7 13:47:40 EST 1996
<!-- hhmts end --></div>]]>
            </description>
            <link>https://www.ee.ryerson.ca/~elf/hack/recovery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491790</guid>
            <pubDate>Mon, 21 Dec 2020 03:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Covid vaccine scientist dead w stab wounds after falling from 14th floor]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25491576">thread link</a>) | @bookofjoe
<br/>
December 20, 2020 | https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/ | <a href="https://web.archive.org/web/*/https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491576</guid>
            <pubDate>Mon, 21 Dec 2020 02:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cakelisp: A Programming Language for Games]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25491568">thread link</a>) | @makuto
<br/>
December 20, 2020 | https://macoy.me/blog/programming/CakelispIntro | <a href="https://web.archive.org/web/*/https://macoy.me/blog/programming/CakelispIntro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><em>Update:</em> See the <a href="https://news.ycombinator.com/item?id=25491568">Hacker News thread</a>, <a href="https://www.reddit.com/r/programming/comments/kh6ox0/cakelisp_a_programming_language_for_games/">/r/programming</a>, <a href="https://www.reddit.com/r/ProgrammingLanguages/comments/kh6gh2/cakelisp_a_programming_language_for_games/">/r/ProgrammingLanguages</a>, and <a href="https://www.reddit.com/r/gamedev/comments/kh1p0a/cakelisp_a_programming_language_for_games/">/r/gamedev</a> posts for discussions on this article and Cakelisp.</p>
<p>I have been working on a new programming language since the end of August 2020. It is hosted on <a href="https://github.com/makuto/cakelisp/">Github</a>, and mirrored on <a href="https://macoy.me/code/macoy/cakelisp/">my site</a>.</p>
<p>If you want to see a working example first, <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame.cake</a> is a simple audio looper with Ogre 3D graphics and SDL for windowing, input, and audio. This demo supports code hot-reloading and doesn't require an external build system, only Cakelisp. You can also check <a href="https://macoy.me/code/macoy/cakelisp/src/branch/master/runtime/Macros.cake">Macros.cake</a>, which demonstrates some use-cases for compile-time code.</p>
<p>I figured showing non-trivial examples would be much more interesting. It also proves that Cakelisp is working.</p>

<p>Cakelisp is built for me first, but it should appeal to fellow programmers who know what they're doing and want to try a more powerful language.</p>
<p>Cakelisp might be for you if you want…</p>
<ul>
<li><strong>Uncompromised performance</strong></li>
<li><strong>Trust in you, the programmer</strong></li>
<li><strong>Powerful code generation</strong></li>
</ul>
<p>If any of the things in that list don't make sense to you, or you think you're already getting them in language <em>X</em>, then Cakelisp isn't for you, and that's okay! We have different domains and different problems, so it makes some sense to use different languages and methodologies.</p>
<p>While many languages have these features, few have the combination of all three. Lisp has extremely powerful code generation, but makes serious performance compromises. C is great for performance but can require extremely repetitive code writing to accomplish tasks a simple code generator could handle. Rust is fast (well, apart from compilation, which is very important for iterative development to be productive), but doesn't trust the programmer.</p>

<p>My goal is to "have my cake and eat it too", meaning all three of these features in one coherent package. Importantly, there isn't one dominating principle in Cakelisp (no <a href="https://www.youtube.com/watch?v=TH9VCN6UkyQ">Big Idea</a>). I've found that the small things like removing the need for header files, no longer dealing with external build systems, or being able to run Cakelisp files like scripts, end up making a big difference when combined in one package.</p>
<p>It is useful to go over the goals in detail so you can understand my decisions.</p>
<h2 id="uncompromised-performance">Uncompromised performance</h2>
<p>This means no garbage collection, no type boxing/unboxing, etc. Fewer abstractions (besides the ones you create) between you and what the computer is actually doing. Idiomatic usage of the language should result in performance comparable with C (in most cases, it should be identical, because it's only a thin layer on C).</p>
<h2 id="trust-in-you-the-programmer">Trust in you, the programmer</h2>
<p>While languages like Rust offer benefits in terms of security and stability, they cost programmers in terms of productivity. It makes sense to value safety so highly if your code is safety-critical (operating systems, aerospace, automotive, etc.), but it's much less valuable when safety isn't as important (e.g. in games).</p>
<p>In a perfect world all programs would be as robust as space flight software, but in reality, that level of robustness is unnecessary for most programs. It's important to realize that the safety focus is just one way of doing things, not the <em>One True Way</em> or anything.</p>
<h2 id="powerful-code-generation">Powerful code generation</h2>
<p>In my opinion, most languages offer far too little opportunity for the programmer to automate the actual writing of code. This power also relates to trusting in the programmer, because gone wild, the code can become incomprehensible.</p>
<p>The company I work for has what I consider to be a state-of-the-art code generator built for the company's use-case: multi-platform MMOs. It's used very effectively on serialization, RPC, automatic commands, monitoring, automatic documentation, and more.</p>
<p>To give more credence to the use of code generation in games, <a href="https://docs.unrealengine.com/en-US/ProgrammingAndScripting/GameplayArchitecture/index.html">Unreal</a> and <a href="https://www.youtube.com/watch?v=wiJqUWfR90I">Naughty Dog</a> also rely on code generation.</p>
<h2 id="simplify-project-setup-and-management">Simplify project setup and management</h2>
<p>I want to dramatically reduce time wasted on C++ project set-up and "code logistics". This includes setting up build systems, creating header files, adding and managing new C/C++ 3rd party libraries, and other things of that ilk.</p>
<h2 id="gain-more-power">Gain more power!</h2>
<p>Every language has limitations. The lack of straightforward, all-powerful code generation was my primary gripe with C++.</p>
<p>For example, automatically creating function and structure bindings using C++ template metaprogramming is very complex. These are two very useful tools in game development: function bindings for commands, scripting languages, and RPC; structure bindings for serialization or game monitors.</p>
<p>I also wanted features like hot-reloading (being able to load new versions of the code without restarting the program/losing runtime state). Cakelisp made it possible to implement hot-reloading entirely in "user-space", thanks to code modification.</p>
<h2 id="have-my-cake-and-eat-it-too.">"Have my cake and eat it too."</h2>
<p>By this I mean lose little-to-nothing on metrics I care about, which include build time, runtime performance, overall complexity, and various other things. I looked into several languages in my <a href="https://macoy.me/code/macoy/LanguageTests">LanguageTests</a> experiment and found they all had major drawbacks I couldn't accept.</p>
<h2 id="unexpected-freedom">Unexpected freedom</h2>
<p>I did not realize when I started Cakelisp how freeing it felt. All of the sudden, I got to decide what made sense to <em>me</em>, not what made sense to previous language designers.</p>
<h3 id="freedom-in-syntax">Freedom in syntax</h3>
<p>A simple example is type declarations. In C:</p>

<p>The same variable, in Cakelisp:</p>

<p>In my opinion C type declarations are much harder to parse than my explicit type declarations. You need to work backwards from the name to properly interpret the type. The parentheses do add more typing, but they're more clear, machine-parseable, and can be read naturally (e.g. read left to right "pointer to constant character" vs. C's "constant character pointer", which seems worse in my mind).</p>
<p>My form also handles arrays as part of the type: <code>(var my-array ([] 5 int))</code> rather than <code>int myArray[5];</code>, another way it is more consistent, readable, and parsable.</p>
<p>I chose to swap the order of name and type because it places more emphasis on the name. A well-written program will convey more useful information in the name than in the type, so it makes sense to me to have it come first for the reader.</p>
<h3 id="freedom-in-process">Freedom in process</h3>
<p>I also found that having an executable which preprocesses my code exactly how I want it opens the door to a huge amount of awesome features:</p>
<ul>
<li>Compile-time code execution. "Macros" and "Generators" are defined in-line with the rest of your code, making them feel like a natural part of your code. Defining them in-line makes it acceptable to add one-off macros, whereas adding such a thing to an external code generator would quickly become unmaintainable</li>
<li>Build optimization. A recent idea I discovered is automatically creating precompiled headers for large batches of 3rd-party headers. This would be a complex task that would need to be integrated in whatever build system you use, whereas Cakelisp can have it built-in</li>
<li>Other data processing. Compile-time code execution means you can do things like prepare assets, download 3rd-party code, run tests, etc. without having to set up all these additional tools</li>
</ul>

<p>I was inspired by Naughty Dog's use of <a href="https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp">Game Oriented Assembly Lisp</a>, GOOL, and <a href="https://www.youtube.com/watch?v=oSmqbnhHp1c">Racket/Scheme</a> (on their modern titles). I've also taken several ideas from Jonathan Blow's <a href="https://www.youtube.com/user/jblow888">talks on Jai</a>.</p>
<p>I'm a software engineer in the game industry. I've been working since July 2015 at a studio that makes cross-platform MMOs. The company has a custom engine written in C (with some C++).</p>
<p>I <a href="https://macoy.me/code/macoy/LanguageTests">experimented</a> with other languages before deciding I needed to write my own.</p>

<p>Now that my goals are clear, I will show you how I approached achieving them.</p>
<h2 id="notation">Notation</h2>
<p>Cakelisp uses an <a href="https://en.wikipedia.org/wiki/S-expression">S-expression</a>-style notation. Here is some Cakelisp code from <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame</a>:</p>

<p>There are a few things you can notice from reading this code:</p>
<ul>
<li>Types. Cakelisp is strongly- and explicitly-typed. I prefer reading code with explicit types because I can better imagine what the computer is actually doing, and what possibilities I have with each variable</li>
<li>Name-type order. I talked about this in a previous section. I wanted to emphasize the name of a variable for conveying meaning, especially when you may have many variables of the same type</li>
<li>Explicit <code>return</code>. I find I prefer code where return points are made explicit. Lisp will implicitly return the result of the last evaluation</li>
<li>Lisp-y style. The parentheses, plus keywords like <code>unless</code>, <code>defun</code>, <code>var</code>, <code>at</code>, and <code>incr</code>. I matched Lisp only when I didn't have strong opinions for a better notation. I am not trying to create something which is compatible with existing Lisps</li>
<li>C types and function calls. Cakelisp has seamless C interop, which means Cakelisp's "standard library" <em>is</em> C's standard library. No bindings had to be written to use the C types or make the function calls</li>
</ul>
<p>You can read more Cakelisp code in <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/src">Gamelib</a>.</p>
<p>You should think of Cakelisp more as "C in S-expressions" rather than "Lisp with C performance". If you know C, you'll have a relatively smooth transition to Cakelisp. If you only know Lisp, you're going to have a rougher time.</p>
<h3 id="why-s-expressions">Why S-expressions?</h3>
<p>When I set out to make Cakelisp, I decided on S-expressions syntax for several reasons:</p>
<ul>
<li>Parsability. S-expressions shift the burden of creating a syntax tree onto the programmer. This does result on more work for the human, but I value its extremely explicit nature. It also facilitates simpler tokenization, domain-specific-language implementation, and external tool support</li>
<li>Consistency. There are only four types of tokens in Cakelisp: open and close parenthesis, symbol, and string. The consistency is admittedly limiting, so things like paths (<code>myThing-&gt;member.member</code>) become much more verbose to type, unfortunately. However, this limitation keeps Cakelisp code parsable, and has an elegant feel that I appreciate</li>
</ul>
<p>I don't believe there is one notation to rule them all, especially after I've encountered the disadvantages of using S-exprs. I'm still happy with the decision though, and it does give Cakelisp a novel and distinguishing characteristic from the many …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macoy.me/blog/programming/CakelispIntro">https://macoy.me/blog/programming/CakelispIntro</a></em></p>]]>
            </description>
            <link>https://macoy.me/blog/programming/CakelispIntro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491568</guid>
            <pubDate>Mon, 21 Dec 2020 02:28:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PicoLisp Chess]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25491356">thread link</a>) | @simonpure
<br/>
December 20, 2020 | https://software-lab.de/chess/README | <a href="https://web.archive.org/web/*/https://software-lab.de/chess/README">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>|<n>|<b>|<q>|<k>|<b>|<n>|<r>|
      +---+---+---+---+---+---+---+---+
    7 |<p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|
      +---+---+---+---+---+---+---+---+
    6 |   | - |   | - |   | - |   | - |
      +---+---+---+---+---+---+---+---+
    5 | - |   | - |   | - |   | - |   |
      +---+---+---+---+---+---+---+---+
    4 |   | - |   | - |   | - |   | - |
      +---+---+---+---+---+---+---+---+
    3 | - |   | - |   | - |   | - |   |
      +---+---+---+---+---+---+---+---+
    2 | P | P | P | P | P | P | P | P |
      +---+---+---+---+---+---+---+---+
    1 | R | N | B | Q | K | B | N | R |
      +---+---+---+---+---+---+---+---+
        a   b   c   d   e   f   g   h

For a local installation, supply instead of "pil" the actual path like "./pil"
or "../pil21/pil".

The pieces are indicated by the letters 'K'ing, 'Q'ueen, 'R'ook, 'B'ishop,
k'N'ight and 'P'awn, with black pieces in angular brackets.

You can enter your moves with the field names (in lower case) for the "from" and
"to" positions:

: (go e2 e4)

Castling may be entered by just specifying the king's move:

: (go e1 g1)

To promote a pawn to some piece other than a queen, you can specify a class:

: (go h7 h8 +Knight)

To undo one or several moves, enter

: (go -)

and to redo them

: (go +)

To switch sides (and have the computer play against itself), call 'go' without
arguments:

: (go)

The initial board position can be restored with

: (main)

The global variable '*Depth' holds the maximal depth of the alpha-beta tree
search. It defaults to 5. You may change it to some smaller value for a faster
response, or to a larger value for a deeper search:

: (setq *Depth 7)

The same effect can be achieved by passing the desired depth as the first
argument to 'main':

: (main 7)

The second (optional) argument to 'main' is your color ('NIL' for white and 'T'
for black).

To setup some given board position, call 'main' with a list of triples, with
each describing:

   1. The field
   2. The piece's classes
   3. An optional flag to indicate that the piece did not move yet

: (main 5 NIL
   (quote
      (a2 (+White +Pawn) T)
      (b1 (+White +King))
      (d4 (+Black +King)) ) )
   +---+---+---+---+---+---+---+---+
 8 |   | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 7 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 6 |   | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 5 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 4 |   | - |   |<k>|   | - |   | - |
   +---+---+---+---+---+---+---+---+
 3 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 2 | P | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 1 | - | K | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
     a   b   c   d   e   f   g   h

At any time, you can print the current board position in the above format to a
file with

: (ppos "file")

which later can be restored with

: (load "file")


   === PilBox and Web App ===

If you have the PilBox App installed on your Android device, just type "chess"
in the settings and press the "Download" button.

To start the Web application, use

   $ pil chess/main.l -chess~main -go +

Alternatively, you can start it with German localization as

   $ pil chess/main.l -'chess~main "DE" "de"' -go +

then point your browser to http://localhost:8080

In both cases you can interact with the chess board in this way:

   â€” To enter a move, drag a piece to the new field.
   â€” A click on the board does an auto-move and then switches sides.
   â€” The search depth can be changed with a drop-down menu.
   â€” The "New" button starts a new game, and the "Undo" and "Redo" buttons
     navigate in the history.
   â€” The text "White" or "Black" indicate who is to move next. It changes to
     "White ..." or "Black ..." while the computer is thinking.
   â€” After a move, the moved piece and the old and new positions are indicated
     above that text.

The "Setup" button switches to edit mode and allows you to change the position
manually:

   â€” A click on a piece removes it from the board.
   â€” Dragging a piece moves it to another field.
   â€” A new piece can be placed on the board by dragging it from the setup area.
   â€” The "Clear" button removes all pieces from the board.
   â€” The "New" button sets up all pieces for a new game.
   â€” The "Game" button switches back to play mode.

As in any PilBox app, you can go to the settings (wheel icon on top right) and

   â€” switch to another language in the "Language" tab or
   â€” view the App's source code by clicking on the app name "chess" in the
     "PILs" tab.


   === Credits and Copying ===

The pieces and board colors are from https://chessboardjs.com

The icon is from
   https://commons.m.wikimedia.org/wiki/File:Chess logo.PNG

(MIT/X11 License)
</k></p></r></n></b></k></q></b></n></div></div>]]>
            </description>
            <link>https://software-lab.de/chess/README</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491356</guid>
            <pubDate>Mon, 21 Dec 2020 01:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First release of quantum operating system, Deltaflow]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 42 (<a href="https://news.ycombinator.com/item?id=25490816">thread link</a>) | @kristianpaul
<br/>
December 20, 2020 | https://www.riverlane.com/news/2020/12/riverlane-release-first-version-of-quantum-operating-system-deltaflow-os/ | <a href="https://web.archive.org/web/*/https://www.riverlane.com/news/2020/12/riverlane-release-first-version-of-quantum-operating-system-deltaflow-os/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <div>
                <article>
                    

                    <div>
                        
                        <div>
                            <p>In May 2020, Riverlane revealed that they will lead a consortium which has been <a href="https://www.riverlane.com/news/2020/05/uk-companies-to-build-radically-new-operating-system-for-quantum-computers/">awarded a £7.6m grant to build a radically new operating system</a> for quantum computers. We marked a ‘hello world’ moment in September, with the first <a href="https://www.riverlane.com/news/2020/09/commercial-breakthrough-following-success-of-deltaflow-os-trials/">successful trials of Deltaflow.OS</a>, using quantum hardware belonging to leading trapped-ion company, <a href="https://www.oxionics.com/">Oxford Ionics</a>.</p>
<p>The latest milestone is the public release of the first version of Deltaflow.OS; ‘Deltaflow-on-ARTIQ’. The product has been built to enable quantum hardware companies as well as algorithm and app developers to accelerate their research by making collaboration easier and reduce down-time in labs. This version uses simulated hardware and <a href="http://m-labs.hk/experiment-control/artiq/">ARTIQ</a> as a backend. ARTIQ is a control system which is widely used in the trapped-ion community.</p>
<p>Deltaflow-on-ARTIQ consists of the Deltaflow language (Deltalanguage), and various hardware models on which the language can be run, including an emulator of the ARTIQ control system. The Deltalanguage lets users define a graph of different hardware nodes corresponding to the type of hardware elements found in labs. After defining a programme, users can test it on increasingly realistic hardware models.</p>
<p>Robert Jördens of M-Labs commented, “My hands are twitching because I really want to see and try that&nbsp;emulator and Deltaflow. There are so many valuable pieces in there.”</p>
<p>A first <a href="https://vimeo.com/480247763/d8fd4a0708">public demonstration of Deltaflow.OS</a> took place at the virtual National Quantum Technologies Showcase on 6 November 2020, where the team demonstrated how a Rabi-Oscillation would be performed.</p>
<p>The release of Deltaflow-on-ARTIQ marks a significant step towards Riverlane’s mission to build a quantum operating system that is high performance, portable across all qubit technologies and scalable to millions of qubits.</p>
<p>Access <a href="https://www.riverlane.com/products/">Deltaflow-on-ARTIQ</a></p>





                        </div>
                    </div>

                </article>
            </div>
        </section></div>]]>
            </description>
            <link>https://www.riverlane.com/news/2020/12/riverlane-release-first-version-of-quantum-operating-system-deltaflow-os/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25490816</guid>
            <pubDate>Mon, 21 Dec 2020 00:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[eBPF Is Awesome]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25490138">thread link</a>) | @filipn
<br/>
December 20, 2020 | https://filipnikolovski.com/posts/ebpf/ | <a href="https://web.archive.org/web/*/https://filipnikolovski.com/posts/ebpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I was doing some research at work for tracing and observability for microservices, when I came across <a href="https://pixielabs.ai/">Pixielabs</a>. This tool advertises that you can instantly troubleshoot applications without any instrumentation or special code inside the apps, which sounded ✨magical✨ to me. So naturally I wanted to know a little more about what enables this technology to work, and after scrolling through the site, under the “No Instrumentation” section was this acronym <strong>eBPF</strong>.</p><p>After some further digging on the internet, reading the <a href="https://www.tcpdump.org/papers/bpf-usenix93.pdf">design papers</a> and watching several videos, it was safe to say this technology caught my attention, so I wanted to write some notes on it and I hope this post will spark some further interest in you as well.</p><h2 id="so-what-is-ebpf-exactly">So what is eBPF exactly?</h2><p>The TL;DR version is that this technology enables sandboxed user space applications to run in the Linux kernel itself. In a way it makes the kernel <em>programmable</em> which unlocks tremendous possibilities.</p><p>You can pick <strong>any function</strong> from the kernel and execute the program every time that function runs. Running a program that “attaches” to network sockets, tracepoints and perf events can be extremely useful. Developers can debug the kernel without having to re-compile it. There are plenty of use cases such as:</p><ul><li>Application performance &amp; troubleshooting</li><li>Networking &amp; security</li><li>Runtime security</li><li>Application tracing</li><li>Observability</li></ul><p>That’s what enables tools like Pixie to do blackbox analysis, without requiring any tinkering inside the applications that we’re trying to debug.</p><p>Originally BPF was <a href="https://www.tcpdump.org/papers/bpf-usenix93.pdf">designed</a> for capturing and filtering network packets that matched specific rules, discarding any unwanted packets. That’s why it was called the “Berkeley Packet Filter”. If you’ve ever used <strong>tcpdump</strong> you’ve probably already used it. Nowadays eBPF can be used for many different things and not just packet filtering but the name stuck for some reason.</p><p>This architecture of network monitoring was vastly superior to the current existing packet capture technologies in terms of performance, mainly because the filtering was done in the kernel instead of copying all of the packets in user space and doing
the calculations there. But with the advancement of processors it didn’t hold up so well with it’s initial design. That’s why the <strong>extended BPF</strong> (eBPF) design was introduced, to take advantage of the modern processing power.</p><p>Initially eBPF was to be also used as a network packet filtering solution, but the ability to run user-space programs inside the kernel proved to be very powerful. The new design extended what the BPF virtual machine could do, which was to allow it to run on all kinds of events, not just packets, and also do certain actions instead of just the ability to filter things.</p><h2 id="how-does-it-work">How does it work?</h2><p>An eBPF program is just a sequence of 64-bit instructions. The virtual machine’s instruction set is fairly limited and it has two goals in mind:</p><ol><li>The code needs to be executed as fast as possible.</li><li>All BPF instructions must be verifiable at load time to ensure the safety of the kernel.</li></ol><p>Okay so, eBPF code is run in a safe virtual machine inside the kernel. Writing these programs is done with the help of some frameworks (like <a href="https://github.com/iovisor/bcc">bcc</a> and <a href="https://github.com/iovisor/bpftrace">bpftrace</a>) and the program bytecode is then loaded via the <a href="https://man7.org/linux/man-pages/man2/bpf.2.html"><code>bpf</code></a> system call.</p><p>To nullify the security and stability risks when running a user space program inside the kernel, several checks are performed
to ensure that the code we run is safe and that it terminates so our computer won’t freeze up.</p><p>Firstly, to even be able to run a user program which loads eBPF code, it needs root privileges to do so, unless unprivileged eBPF is enabled, in which case the process can load a program with a reduced functionality. Secondly, there’s the eBPF verifier which all eBPF programs must go through before they can be executed.</p><p>The verifier runs several checks on the code that safeguards the kernel. The first check ensures that any unbounded
loops which could freeze up the kernel are prohibited. The second check, which is more extensive, simulates the execution of the code making sure that all paths of the code run to completion, no out of bounds memory is accessed and overall the state of the virtual machine is valid.</p><p>The last step of the verification process involves restricting the eBPF program abilities, which kernel functions are callable and which data it can access. The verifier knows how to apply those restrictions because of the <strong>program type</strong>. The program type is determined when we associate the program with a certain event.</p><p>After the verification process is done, the BPF bytecode is then interpreted, or compiled by a JIT compiler, into native instructions that run efficiently whenever an event happens in the kernel.</p><h2 id="kprobes--uprobes">kprobes &amp; uprobes</h2><p>We can create and insert kernel probes or kprobes for short to virtually any function in the kernel, and attach an eBPF program so that it executes each time that function is invoked.</p><p>Here’s a simple hello world example from the <a href="https://github.com/iovisor/bcc/tree/master/examples">bcc</a> repository:</p><div><pre><code data-lang="python"><span>from</span> bcc <span>import</span> BPF
<span>from</span> bcc.utils <span>import</span> printb
<span># define BPF program</span>
prog <span>=</span> <span>"""
</span><span>int hello(void *ctx) {
</span><span>    bpf_trace_printk("Hello, World!</span><span>\\</span><span>n");
</span><span>    return 0;
</span><span>}
</span><span>"""</span>
<span># load BPF program</span>
b <span>=</span> BPF(text<span>=</span>prog)
b<span>.</span>attach_kprobe(event<span>=</span>b<span>.</span>get_syscall_fnname(<span>"clone"</span>), fn_name<span>=</span><span>"hello"</span>)
<span># header</span>
<span>print</span>(<span>"</span><span>%-18s</span><span> </span><span>%-16s</span><span> </span><span>%-6s</span><span> </span><span>%s</span><span>"</span> <span>%</span> (<span>"TIME(s)"</span>, <span>"COMM"</span>, <span>"PID"</span>, <span>"MESSAGE"</span>))
<span># format output</span>
<span>while</span> <span>1</span>:
    <span>try</span>:
        (task, pid, cpu, flags, ts, msg) <span>=</span> b<span>.</span>trace_fields()
    <span>except</span> <span>ValueError</span>:
        <span>continue</span>
    <span>except</span> <span>KeyboardInterrupt</span>:
        exit()
    printb(<span>b</span><span>"</span><span>%-18.9f</span><span> </span><span>%-16s</span><span> </span><span>%-6d</span><span> </span><span>%s</span><span>"</span> <span>%</span> (ts, task, pid, msg))
</code></pre></div><p>The eBPF program is written in a pseudo-C code and it’s placed in the variable <code>prog</code> as a string. The bcc framework does all the heavy lifting of generating the bytecode, loading the programs and all that stuff, which makes writing these programs a bit easier.</p><p>In this example, the hello function invokes a bpf helper function called <code>bpf_trace_printk</code> which outputs a “Hello, World!” trace. Then we load the program and we attach a kernel probe for the <a href="https://man7.org/linux/man-pages/man2/clone.2.html"><code>clone</code></a> event, basically saying that we want to call the <code>hello</code> program each time <code>clone</code> is called.</p><p>After that the script waits for new traces to arrive, fetches the fields and prints the values to the screen.</p><p>Let’s try running it:</p><pre><code>$ sudo python3 hello-ebpf.py
TIME(s)            COMM             PID    MESSAGE
</code></pre><p>The script has successfully loaded the program and now we wait for the traces to arrive. The next thing to do is to try and invoke the <code>clone</code> syscall. We can run any command on the terminal, such as <code>ls</code> and a child process will be created. Since I had firefox running, it created some child processes in the meantime and traces started to show up:</p><pre><code>611.247475000      firefox          5378   Hello, World!
</code></pre><p>As we can see, the message “Hello, World!” is printed on the screen along with the other trace fields. Super cool!</p><p>Besides attaching to kernel functions, we could also observe functions invoked in user space, such as <strong>malloc</strong> or <strong>strlen</strong>. This is possible via another Linux kernel feature - <strong>uprobes</strong>.</p><p>Here’s an interesting script that counts frequencies of strings by tracing strlen() and using a hash map to store the strings along with the count of their recurrence: <a href="https://github.com/iovisor/bcc/blob/master/examples/tracing/strlen_count.py">https://github.com/iovisor/bcc/blob/master/examples/tracing/strlen_count.py</a></p><h2 id="helper-functions">helper functions</h2><p>Since arbitrary kernel functions are prohibited to be called by ebpf programs, there are several helper functions which the kernel provides for us, such as the <code>bpf_trace_printk</code> function. We can use them to:</p><ul><li>Get the current time</li><li>Interact with eBPF maps</li><li>Manipulate network packets</li><li>Print debugging messages</li></ul><p>Note that each program can only use a subset of these helpers because of the different contexts the programs can run in. Here’s the extensive <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html">list</a> of bpf helpers.</p><h2 id="map-storage">map storage</h2><p>To write more complicated programs you’ll need some type of data store, and that is where <strong>maps</strong> come in. They are an important part of the BPF internal system, which allows programs to store information that can be accessed from userspace.</p><p>BPF supports different <a href="https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#maps">types</a> of data stores - you can use a hash map, an array, or even a stack or a queue, depending on the use case of course.</p><h2 id="conclusion">conclusion</h2><p>eBPF opens up all kinds of possibilities for observability. You can treat a system as a blackbox, without really knowing anything about it, and run all kinds of interesting analysis: count the most frequently called functions, trace network packets, do performance tracing and debugging, etc.</p><p>There are a myriad of tools that you can use to observe every component of the system: the CPU, memory, file system, networking, containers, applications…</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/b19abde4b1ccfe4ce140969c8bf44f39d1c2fe70/f9ed3/images/ebpf/bcc_tracing_tools_early2019.png" alt="ebpf-tracing-tools"><figcaption>BCC performance tools (courtesy of Brendan Gregg)</figcaption></figure><p>I’ve only scratched the surface on this subject and I can’t wait to learn more about it, as well as Linux performance in general. There’s tons of great posts and videos on this exciting technology, and I’ve left some links below for you. Cheers!</p><h2 id="references">References</h2><ul><li><a href="https://www.tcpdump.org/papers/bpf-usenix93.pdf">https://www.tcpdump.org/papers/bpf-usenix93.pdf</a> – BPF paper</li><li><a href="https://lwn.net/Articles/740157/">https://lwn.net/Articles/740157/</a> – A thorough introduction to eBPF</li><li><a href="https://www.youtube.com/watch?v=16slh29iN1g">https://www.youtube.com/watch?v=16slh29iN1g</a> – interesting talk by Brendan Gregg on BPF performance analysis at Netflix</li><li><a href="http://www.brendangregg.com/ebpf.html">http://www.brendangregg.com/ebpf.html</a> – eBPF trace tools</li><li><a href="https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md">https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md</a> – BCC reference guide</li></ul></div></div>]]>
            </description>
            <link>https://filipnikolovski.com/posts/ebpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25490138</guid>
            <pubDate>Sun, 20 Dec 2020 22:24:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The U.S. Army Is Creating Robots with Synthetically Grown Muscle]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25489005">thread link</a>) | @bookofjoe
<br/>
December 20, 2020 | https://smosa.com/army-building-robots-with-synthetic-muscle/ | <a href="https://web.archive.org/web/*/https://smosa.com/army-building-robots-with-synthetic-muscle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>According to <a href="https://www.eurekalert.org/pub_releases/2020-12/uarl-asf121720.php">an announcement in EurekAlert</a>!, The U.S. Army has been researching with Duke University a technological approach that uses robotics and "biohybrid" muscle elements.</p><p>Army researchers claim that robotic systems filled with muscle tissue will deliver a new level of agility and flexibility. In order to maximize efficiency, biohybrid robotics incorporates living organisms into mechanical systems. The team's first applications are legged platforms similar to the LLAMA and Marine Corps Legged Squad Support System (LS3), the legged locomotive and movement adaptation device of the Army.</p><p>"Though impressive in their own right, today's robots are deployed to serve a limited purpose then are retrieved some minutes later," said research scientist Dr. Dean Culver, "ARL wants robots to be versatile teammates capable of going anywhere soldiers can and more, adapting to the needs of any given situation." Culver added, "Organisms outperform engineered robots in so many ways. Why not use biological components to achieve those remarkable capabilities?"</p><figure><img src="https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Humanoid robot Robotis Bioloid with the hands in the air, cheering." srcset="https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@anilinverse?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Adam Lukomski</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>In addition, a separate team from Duke University will focus on the characteristics of macroscopic performance of muscles, tendons and ligaments in skiping animals using legged robots.</p><p>The muscle tissue is excellent for generating a certain mechanical strength, and its flexibility is unrivaled in today's robotic service. The research could show the bio-hybrid engineering community how to grow strong muscular tissue instead of extracting it from a trained organism in addition to providing insight into the mesomechanics that control motor protein movement.</p><p>"Muscle tissue is outstanding at producing a specific amount of mechanical power at a given moment," says Culver, "and its versatility is unrivaled in robotic actuation today."</p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/army-building-robots-with-synthetic-muscle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25489005</guid>
            <pubDate>Sun, 20 Dec 2020 19:51:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Graying of Gnome]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 253 (<a href="https://news.ycombinator.com/item?id=25488887">thread link</a>) | @yankcrime
<br/>
December 20, 2020 | https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/ | <a href="https://web.archive.org/web/*/https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><section id="primary"><main id="main" role="main"><article id="post-622"><div><p><a href="https://gnome.org/">The GNOME project</a> turned 23 this year, and despite equally persistent rumors to the contrary, it’s still alive and kicking.</p><p>Just how alive, though? All I know is this: Where the topic of GNOME’s health goes, accurate data rarely follows. Of course, there <em>is</em> data — lots of it in fact, in public source code repositories. Though flawed in many ways, it allows us to make comparisons to the past — and maybe predictions for the future: Are a few organizations carrying most of the workload, making them critical points of failure? Are new contributors able to pick up the slack from those who leave? Is the project graying (i.e. increasingly dominated by veterans)?</p><p>In one of my occasional fits of hubris, I set out to process this data to see if I could shake out anything meaningful. I’m usually fine with just satisfying my own curiosity and leaving it at that, but it’s one of those times where the results seem interesting enough for a blog post. So here we are.</p><p>I’m going to lead with the nice graphs and follow on with a <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#methodology">section on methodology</a>. The latter is long, boring, and mandatory reading.</p><h2 id="contributors">Active contributors</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png" alt="Active GNOME authors per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>The stacked histogram above shows the number of contributors who touched the project on a yearly basis. Each contributor is assigned to a generational cohort based on the year of their first contribution. The cohorts tend to shrink over time as people leave.</p><p>There’s a special “drive-by” cohort (in a fetching shade of off-white) for contributors who were only briefly involved, meaning all their activity fits in a three-month window. It’s a big group. In a typical year, it numbers 200-400 persons who were not seen before or since. Most of them contribute a single commit.</p><p>According to this, GNOME peaked at slightly above 1,400 contributors in 2010 and went into decline with the GNOME 3.0 release the following year. However, 2020 saw the most contributors in a long time, even with preliminary data — there’s still two weeks to go. Who knows if it’s an anomaly or not. It’s been an atypical year across the board.</p><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png" alt="Active GNOME authors per month, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>This is the same histogram, but with per-month bins. There’s a clear periodicity caused by the semiannual release cycle. The peak month was March 2011, right before the <a href="https://www.gnome.org/press/2011/04/gnome-3-0-released-better-for-users-developers-3/">GNOME 3.0 release</a>. About 450 contributors got involved that month.</p><p>The drive-by cohort is relatively smaller on a monthly basis. This makes sense, as it has little overlap from month to month, and the per-year bins tend to add them all up.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png" alt="Active GNOME authors per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Above, the top 15 affiliations of active contributors. I’ve excluded personal accounts. This is pretty flawed (details below), but interesting nonetheless. For what it’s worth, it mostly lines up with my memory of things.</p><p>The pattern tracks well with the total despite only capturing a minority portion of it. I think this means that paid and unpaid contributions are driven by the same underlying trends, or that there’s a lot of the former hiding in the latter.</p><h2 id="commitcount">Commit count</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png" alt="Number of GNOME commits per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Here I’m counting the number of commits per year in the various cohorts.</p><p>At first glance, this looks much less dire. However, note how newcomers are having a smaller impact, especially from 2014 on. And the 2018-2020 bounce is entirely due to a handful of veterans making a comeback.</p><p>Half the commits in 2020 were made by contributors who’ve been with the project for ten years or more. Also noteworthy, drive-by commits are a vanishingly small portion of the total.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png" alt="Number of GNOME commits per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Top 15 affiliations again, but now ordered by commit counts. It’s safe to say that GNOME is dependent on paid developers in a big way. Specifically, and to no one’s surprise, it leans heavily on Red Hat.</p><h2 id="observations">General observations</h2><p>A few observations can be made with confidence:</p><ul><li>By F/OSS standards, the project is not <em>un</em>healthy. It has hundreds of experienced and first-time contributors every year. It is well-organized and arguably well-funded compared to its peers. But:</li><li>Every metric has the project peaking around 2010.</li><li>A diminishing number of veterans is doing an increasing share of the work.</li><li>Although recruitment is stable, newcomers don’t seem to be hitting their stride in terms of commits.</li><li>Corporate sponsorship is probably necessary to keep the project going, but the field of sponsors has kept thinning.</li></ul><p>I think GNOME is addressing the risk factors competently by modernizing infrastructure (<a href="https://gitlab.gnome.org/">GitLab</a>, <a href="https://discourse.gnome.org/">Discourse</a>). This has obvious value even in the absence of quantifiable results, but it’ll be interesting to see if the effect can be measured over the next couple of years.</p><p>Diminished enthusiasm may also be due to there being fewer ways for a new contributor to make their mark or assume a role of responsibility. GNOME has become more conservative, certainly much more so than it was a decade ago in the run-up to GNOME 3. The rationale and phrasing in <a href="https://discourse.gnome.org/t/new-gnome-versioning-scheme/4235">the announcement of the new versioning scheme</a> (e.g. <em>“Radical technological and design changes are too disruptive for maintainers, users, and developers”</em>) seems indicative of this trend<sup>1</sup>.</p><h2 id="methodology">Notes on methodology</h2><p>So what’s wrong with this analysis? If you’re so inclined, you can find the details under the next couple of subheadings and pass harsh, harsh judgement.</p><p>I’ve set the unscientific rigor bar high enough to hopefully yield something useful, but low enough that I could do it in my spare time and not get stuck in the dreaded state commonly known as “90% done”.</p><h3>Module selection</h3><p>I aggregated data from <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-repos">189 Git repositories</a>. The vast majority of these are hosted on <code>gnome.org</code>, with a handful from <code>freedesktop.org</code> and <code>github.com</code>. Commits are uniquely identified by their commit hash, meaning trivial duplicates are counted only once.</p><p>GNOME has always been a decentralized, big-tent project, so it’s not obvious how to delineate it. I’ve tried to be fair by including most of the repositories from a full meta-gnome-desktop jhbuild, including fairly low-level dependencies like Cairo, Pango, and Pipewire, as well as past, present and would-be flagship applications under the GNOME umbrella. Documentation and infrastructure is represented, as are many archived projects (e.g. ORBit2, Bonobo, Sabayon, GAL).</p><p>I was a little uncertain about what to do with X.Org and Wayland. In the end I decided to include the latter, but not the former, since Wayland has close ties to GNOME (it even references GTK+ in its TODO file), while X.Org has its roots in the much older XFree86.</p><p>Mono is another project I resisted including; its development was tangential to GNOME proper, diverging completely in the most recent decade. However, I did include GtkSharp and several GNOME-hosted C# applications common on desktops in the 2005-2010 time frame.</p><p>Since I haven’t established hard criteria for module selection, it’s subject to various biases. Older code is probably underrepresented, since providers of important functionality were more loosely attached to the project early on (e.g. GNOME Online Accounts and Telepathy got pulled in, should I have included Gaim or Pidgin too? How about XChat?).</p><p>Anyway, the list isn’t terrible, but there’s room for improvement.</p><h3>Contributor identities</h3><p>Similar studies often identify contributors by their e-mail addresses. I used full author names instead, since there’s good reason to think they’re more stable over a 20-year time span. We’re fairly consistent in spelling our own names, and we change them rarely (often never). On the other hand, e-mail addresses come and go with different hosting arrangements, employers, etc.</p><p>An added challenge with this approach is that sometimes different people have the exact same name. In practice, I’m not aware of any instances of this happening in GNOME. It seems to be rare enough that I doubt it’d introduce significant error in most projects.</p><p>I should add here that the drive-by cohort depends on a fair amount of hindsight (you never know when someone might come back with more contributions, but the likelihood drops off quickly as time passes). This means the cohorts for 2020 are preliminary. They’ll be a lot more accurate with another run late next year.</p><h3>Domain names</h3><p>I’m using e-mail domain names as a proxy for organizations in some of the graphs. This is a notoriously unreliable approach for at least three reasons:</p><ol><li>Contributors often use personal e-mail addresses for paid work, leading to significant undercounting in general.</li><li>Specific companies may require their employees (or ask them nicely) to use company e-mail for collaboration. Out of the listed companies, I know of at least one that definitely did this. However, there are many that don’t, and these will be comparatively less well represented.</li><li>The mapping between DNS and organizations isn’t one-to-one. A company may operate under multiple names or TLDs (e.g. <code>.co.uk</code> and <code>.com</code>).</li></ol><p>Despite these weaknesses, it’s common to slice the data this way. It’s difficult to do better without access to semi-closed data troves, and depending on your views on privacy and ability to handle <a href="https://en.wikipedia.org/wiki/Personal_data">PII</a> safely, it might not be something you’d want to get into anyway. But I bet you’d be well-positioned for it if you were, say, the corporate owner of both LinkedIn and GitHub.</p><p>When grouping by organization, the goal is to get an idea of which outside entities are sponsoring contributions. Therefore, I’ve filtered out addresses from the biggest mass e-mail providers like <code>@gmail.com</code> and project-centric providers of personal accounts (e.g. <code>@gnome.org</code>, <code>@gtk.org</code>).</p><p>I took the liberty of reassigning the personal domains of a few extra prolific authors who would’ve otherwise showed up as individual organizations. Since there’s no way I’m doing it for everyone, this introduces some bias. The full details are in <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-meta.json">the project’s metadata file</a> (see: <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#code">code</a>).</p><h3>Version control systems</h3><p>Changeovers in version control systems divide GNOME’s VCS history into three eras with noticeable discontinuities between them.</p><h4>Before 1998: Dark ages</h4><p>In the Bad Old Days, Free Software would often use plain <a href="https://en.wikipedia.org/wiki/Revision_Control_System">RCS</a> or no version control at all. I have basically no data for this era: The GIMP, being the ur-project from which …</p></div></article></main></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</a></em></p>]]>
            </description>
            <link>https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25488887</guid>
            <pubDate>Sun, 20 Dec 2020 19:33:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posenet Fruit Ninja in the Browser (Tensorflow.js and Posenet)]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25486322">thread link</a>) | @liuxiaopai
<br/>
December 20, 2020 | https://huhai463127310.github.io/posenet_fruit_ninja/ | <a href="https://web.archive.org/web/*/https://huhai463127310.github.io/posenet_fruit_ninja/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>保证摄像头处于未禁用状态，正对摄像头站立，保证左上角摄像头窗口可看见你的上半身，挥舞手臂，划掉New Game。</p>
        <p>挥舞你的手！挥舞你的手！挥舞你的手！</p>
    </div></div>]]>
            </description>
            <link>https://huhai463127310.github.io/posenet_fruit_ninja/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25486322</guid>
            <pubDate>Sun, 20 Dec 2020 14:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding how AES encryption works]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25486017">thread link</a>) | @nakabonne
<br/>
December 20, 2020 | https://nakabonne.dev/posts/understanding-how-aes-encryption-works/ | <a href="https://web.archive.org/web/*/https://nakabonne.dev/posts/understanding-how-aes-encryption-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I recently had the opportunity to encrypt/decrypt stuff using AES, but I didn’t know it inside out well. I couldn’t help but be curious about how it is working, and I realized my mind could only be satisfied by digging deeper into its implementation.
This post walks you through how AES encryption works by reading core implementation written in Go.</p>
<h2 id="what-is-aes-encryption">What is AES encryption?</h2>
<p>The Advanced Encryption Standard (AES) is a symmetric block cipher, an alternative to the DES. Cryptographers from around the world proposed algorithms, from which the Rijndael algorithm was selected in 2000. Hence we’ll take a look the implementation of this Rijndael.</p>
<h2 id="rijndael">Rijndael</h2>
<p>Rijndael is a block cipher algorithm. A block cipher is a cryptographic algorithm that processes a specific number of bits at a time.
The number of bits (called block length) to be processed at a time depends on the algorithm, AES is 128-bits (16-bytes). Most plaintext we encrypt is longer than this block length, so we typically use this block cipher algorithm repeatedly.
Keep in mind this post goes into some details on only on one block’s process to focus more on the core algorithm.</p>
<h2 id="digging-deeper-into-the-implementation">Digging deeper into the implementation</h2>
<p>The Go language officially provides the <a href="https://golang.org/pkg/crypto/aes/">crypto/aes</a> package, which makes use of Go Assembly to leverage Intel’s hardware support for AES if it’s built for amd64.
It otherwise uses the implementation written in pure Go. Let’s take a look at the pure Go implementation that the human mind relatively can work in.</p>
<p>The public method <code>aesCipher.Encrypt</code> defined in <a href="https://github.com/golang/go/blob/55b58018f41e6de63bdaa8f3d9a284077d4e88c1/src/crypto/aes/cipher.go#L54-L65">aes/cipher.go</a> looks to implement a block cipher:</p>
<div><pre><code data-lang="go"><span>// The AES block size in bytes.
</span><span></span><span>const</span> <span>BlockSize</span> = <span>16</span>

<span>func</span> (<span>c</span> <span>*</span><span>aesCipher</span>) <span>Encrypt</span>(<span>dst</span>, <span>src</span> []<span>byte</span>) {
	<span>if</span> len(<span>src</span>) &lt; <span>BlockSize</span> {
		panic(<span>"crypto/aes: input not full block"</span>)
	}
	<span>if</span> len(<span>dst</span>) &lt; <span>BlockSize</span> {
		panic(<span>"crypto/aes: output not full block"</span>)
	}
	<span>if</span> <span>subtle</span>.<span>InexactOverlap</span>(<span>dst</span>[:<span>BlockSize</span>], <span>src</span>[:<span>BlockSize</span>]) {
		panic(<span>"crypto/aes: invalid buffer overlap"</span>)
	}
	<span>encryptBlockGo</span>(<span>c</span>.<span>enc</span>, <span>dst</span>, <span>src</span>)
}
</code></pre></div><p>This method does the two validations that check if:</p>
<ul>
<li>the given plaintext is equal to 16-bytes, the block length of AES</li>
<li><code>dst</code> and <code>src</code> share memory at any index</li>
</ul>
<p>It seems to leave the core implementation to <code>encryptBlockGo</code> defined in <a href="https://github.com/golang/go/blob/55b58018f41e6de63bdaa8f3d9a284077d4e88c1/src/crypto/aes/block.go#L43-L87">aes/block.go</a>:</p>
<div><pre><code data-lang="go"><span>// Encrypt one block from src into dst, using the expanded key xk.
</span><span></span><span>func</span> <span>encryptBlockGo</span>(<span>xk</span> []<span>uint32</span>, <span>dst</span>, <span>src</span> []<span>byte</span>) {
	<span>_</span> = <span>src</span>[<span>15</span>] <span>// early bounds check
</span><span></span>	<span>s0</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>0</span>:<span>4</span>])
	<span>s1</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>4</span>:<span>8</span>])
	<span>s2</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>8</span>:<span>12</span>])
	<span>s3</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>12</span>:<span>16</span>])

	<span>// First round just XORs input with key.
</span><span></span>	<span>s0</span> ^= <span>xk</span>[<span>0</span>]
	<span>s1</span> ^= <span>xk</span>[<span>1</span>]
	<span>s2</span> ^= <span>xk</span>[<span>2</span>]
	<span>s3</span> ^= <span>xk</span>[<span>3</span>]

	<span>// Middle rounds shuffle using tables.
</span><span></span>	<span>// Number of rounds is set by length of expanded key.
</span><span></span>	<span>nr</span> <span>:=</span> len(<span>xk</span>)<span>/</span><span>4</span> <span>-</span> <span>2</span> <span>// - 2: one above, one more below
</span><span></span>	<span>k</span> <span>:=</span> <span>4</span>
	<span>var</span> <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span> <span>uint32</span>
	<span>for</span> <span>r</span> <span>:=</span> <span>0</span>; <span>r</span> &lt; <span>nr</span>; <span>r</span><span>++</span> {
		<span>t0</span> = <span>xk</span>[<span>k</span><span>+</span><span>0</span>] ^ <span>te0</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s3</span>)]
		<span>t1</span> = <span>xk</span>[<span>k</span><span>+</span><span>1</span>] ^ <span>te0</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s0</span>)]
		<span>t2</span> = <span>xk</span>[<span>k</span><span>+</span><span>2</span>] ^ <span>te0</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s1</span>)]
		<span>t3</span> = <span>xk</span>[<span>k</span><span>+</span><span>3</span>] ^ <span>te0</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s2</span>)]
		<span>k</span> <span>+=</span> <span>4</span>
		<span>s0</span>, <span>s1</span>, <span>s2</span>, <span>s3</span> = <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span>
	}

	<span>// Last round uses s-box directly and XORs to produce output.
</span><span></span>	<span>s0</span> = uint32(<span>sbox0</span>[<span>t0</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t1</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t2</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t3</span><span>&amp;</span><span>0xff</span>])
	<span>s1</span> = uint32(<span>sbox0</span>[<span>t1</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t2</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t3</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t0</span><span>&amp;</span><span>0xff</span>])
	<span>s2</span> = uint32(<span>sbox0</span>[<span>t2</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t3</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t0</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t1</span><span>&amp;</span><span>0xff</span>])
	<span>s3</span> = uint32(<span>sbox0</span>[<span>t3</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t0</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t1</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t2</span><span>&amp;</span><span>0xff</span>])

	<span>s0</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>0</span>]
	<span>s1</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>1</span>]
	<span>s2</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>2</span>]
	<span>s3</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>3</span>]

	<span>_</span> = <span>dst</span>[<span>15</span>] <span>// early bounds check
</span><span></span>	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>0</span>:<span>4</span>], <span>s0</span>)
	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>4</span>:<span>8</span>], <span>s1</span>)
	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>8</span>:<span>12</span>], <span>s2</span>)
	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>12</span>:<span>16</span>], <span>s3</span>)
}
</code></pre></div><p>Don’t be afraid of it. We’ll focus on the significant parts.</p>
<p>The input (means plaintext) to a single block is 16-bytes as we can see above. The input is first divided into four lines, separated by four bytes.</p>
<div><pre><code data-lang="go"><span>s0</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>0</span>:<span>4</span>])
<span>s1</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>4</span>:<span>8</span>])
<span>s2</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>8</span>:<span>12</span>])
<span>s3</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>12</span>:<span>16</span>])
</code></pre></div><p>This illustrates how the input is handled in the AES encryption process. It is definitely the key to understand to keep this format in mind.</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-divided-input.jpg" width="100%" height="auto"> 
</figure>

<p>And the next part which is something iterating, is the most core implementation.</p>
<div><pre><code data-lang="go"><span>// Middle rounds shuffle using tables.
</span><span>// Number of rounds is set by length of expanded key.
</span><span></span><span>nr</span> <span>:=</span> len(<span>xk</span>)<span>/</span><span>4</span> <span>-</span> <span>2</span> <span>// - 2: one above, one more below
</span><span></span><span>k</span> <span>:=</span> <span>4</span>
<span>var</span> <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span> <span>uint32</span>
<span>for</span> <span>r</span> <span>:=</span> <span>0</span>; <span>r</span> &lt; <span>nr</span>; <span>r</span><span>++</span> {
	<span>t0</span> = <span>xk</span>[<span>k</span><span>+</span><span>0</span>] ^ <span>te0</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s3</span>)]
	<span>t1</span> = <span>xk</span>[<span>k</span><span>+</span><span>1</span>] ^ <span>te0</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s0</span>)]
	<span>t2</span> = <span>xk</span>[<span>k</span><span>+</span><span>2</span>] ^ <span>te0</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s1</span>)]
	<span>t3</span> = <span>xk</span>[<span>k</span><span>+</span><span>3</span>] ^ <span>te0</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s2</span>)]
	<span>k</span> <span>+=</span> <span>4</span>
	<span>s0</span>, <span>s1</span>, <span>s2</span>, <span>s3</span> = <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span>
}
</code></pre></div><p>Rijndael encrypts a block by repeating a process called a round.
In a round, there are four processes: SubBytes, ShiftRows, MixColumns, and AddRoundKey. As commented out in the snippet, the number of rounds depends on the key length.</p>
<h3 id="subbytes">SubBytes</h3>
<p>The conversion is done 1-byte at a time based on a conversion table called S-box which has 256 values.
Below illustrates to perform <code>sbox[s0[1]]</code> well:</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-sbox.jpg" width="100%" height="auto"> 
</figure>

<p>Unlike DES, we can see that all bytes have been converted at this point.
This post doesn’t cover AES’s S-Box as it is mentioned in many places and much better than I could do.</p>
<h3 id="shiftrows">ShiftRows</h3>
<p>The next step is to process the rows that are grouped into 4-byte units and shifted regularly to the left.
The number of bytes to be shifted depends on the line, as shown below:</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-shift-rows.jpg" width="100%" height="auto"> 
</figure>

<h3 id="mixcolumns">MixColumns</h3>
<p>In the previous step, it dealt with rows, but the next is to process the bytes in columns.</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-mix-columns.jpg" width="100%" height="auto"> 
</figure>

<p>It involves multiplication operations in a finite field, hence this step is a bit tough to describe. See <a href="https://en.wikipedia.org/wiki/Rijndael_MixColumns">Wikipedia</a> for more details.</p>
<h3 id="addroundkey">AddRoundKey</h3>
<p>Finally, it XORs the output of MixColumns with the round key. The following figure shows the execution of <code>s0[1] ^ xk[4]</code> (the <code>^</code> denotes an XOR operation in Go).</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-add-round-key.jpg" width="100%" height="auto"> 
</figure>

<h2 id="bottom-line">Bottom Line</h2>
<p>While this post has only shown you the encryption process, these processes are fully reversible with an Inverse MixColumns, ShiftRows, SubBytes. How beautiful!
I’ll keep reading the implementation to deepen my understanding of cryptography.</p>

        
    </div></div>]]>
            </description>
            <link>https://nakabonne.dev/posts/understanding-how-aes-encryption-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25486017</guid>
            <pubDate>Sun, 20 Dec 2020 13:17:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we made the PJON network protocol from scratch]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25485943">thread link</a>) | @gioscarab
<br/>
December 20, 2020 | https://www.pjon.org/how.php | <a href="https://web.archive.org/web/*/https://www.pjon.org/how.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <div>
          
          <p>
            <a href="https://github.com/gioblu/PJON" target="_blank" rel="noopener noreferrer">PJON (Padded Jittering Operative Network)</a> is a lightweight, efficient and completely open network protocol. It has revolutionary features such as single wire communication with a range of up to 2 kms, wireless LED-to-LED communication and long range laser communication.
          </p>
        </div>
      </section>
      <section>
        <div>
          <article>
            <h2>2009 - Communication</h2>
            <p>
              Far back in 2009, while following Digital Communication, Advertising and Art Direction at NABA (New Academy of Fine Arts of Milan), I became interested in Professor Massimo Banzi's classes and managed to get an Arduino Diecimila. In just one day my vision of the world had changed and I slowly started to better understand computers and electronics while sharing results with the Arduino community both on my website and on Arduino's forum. I started to build robots and after few years of experiments I launched my first start­up: a webshop of arduino-compatible, CNC machined robot kits, boards and sensors.
            </p>
          </article>
          <br>
          <article>
            <h2>2010 - Let's transmit data</h2>
            <p>
              At the time in my projects I had to connect many microcontrollers on a common bus and I found myself not satisfied by the solutions available, for this reason I started to develop my own data link. I perfectly remember that night back in 2010 when I started bit-banging bits using an Arduino and trying to sample them with another. The first problem I hit were bugs in the implementation that were quickly resolved. Then I unsterstood I did not have any synchronization, depending on when the receiver was powered on bits were shifted. That night, with no experience in electronics or engineering I instinctively defined the synchronization pulse that is still present as the core of <a href="https://github.com/gioblu/PJON/blob/13.0/src/strategies/SoftwareBitBang/specification/PJDL-specification-v5.0.md" target="_blank" rel="noopener noreferrer">PJDL (Padded Jittering Data Link) v5.0</a>. To make sure to synchronize with the start of each byte I have added a 1 longer than data bits followed by a 0 and instructed the receiver to find it and only then start sampling 8 bits. Data was coming in perfectly. That was <a href="https://github.com/gioblu/PJON/blob/master/src/strategies/SoftwareBitBang/specification/obsolete/padded-jittering-protocol-specification-v0.1.md" target="_blank" rel="noopener noreferrer">PJDL (Padded jittering data link) v0.1</a> which was basic and working by mere chance. Then, after debugging it further, experiments proved it was working well not only through wires and the human body, but also wirelessly through radio and infrared light, yet it showed to be robust operating bidirectionally in spite of interference. After I noticed that it was possible to connect more than 2 devices to the same wire, I started to experiment with an initial collision avoidance phase, an 8 bits device id and a synchronous acknowledgement at the end of the packet. It was shocking to see that many devices were able to send and receive data through the same wire. Soon after I released <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v0.1.md" target="_blank" rel="noopener noreferrer">PJON v0.1</a> on the Arduino forum, receiving plenty of "don't ­reinvent ­the ­wheel" and few active contributors.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2014 - Let's network</h2>
            <p>
              In those days I became aware of how quickly the cloud was eating the world and how difficult was to connect stuff directly without relying on a third-party. It seemed like noone could connect computers together anymore without an ever present observing big brother. To be honest, I did not like it: that was the point when I understood how <a href="https://github.com/gioblu/PJON" target="_blank" rel="noopener noreferrer">PJON</a> could have changed the game and what I personally could have done to influence the outcome. I decided to double my efforts on the protocol and try my best to provide humanity with a free and more efficient way to make networks. With a working protocol layer and support from the community, I went further in the address space development adding an optional 32 bits bus id used to identify a group of up to 255 devices, supporting up to 4.294.967.295 buses and a total of 1.090.921.692.930 devices. This addition released in <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v0.2.md" target="_blank" rel="noopener noreferrer">PJON v0.2</a> enabled coexistence and networking for groups of devices. Thanks to Micheal Teeuw's post on his blog, PJON received contributions, testing, debugging and feature requests. Then many talented contributors added support for devices like ESP8266, Teensy 3.2 and Node MCU.
            </p>
          </article>
          <br>
          <article>
            <h2>2015 - Abstracting the data link</h2>
            <p>
              The community wanted to use PJON over different existing protocols and physical layers, to obtain that without making the implementation complex and more difficult to use I have defined the <a href="https://github.com/gioblu/PJON/tree/master/src/strategies" target="_blank" rel="noopener noreferrer">strategy</a> abstraction. The curiously recurring template pattern or CRTP was adopted to abstract the physical layer in separate classes called strategies. Thanks to this change from then it was possible to instantiate a PJON object passing the selected data link. Initially, I developed three strategies, a bit-banged implementation of <a href="https://github.com/gioblu/PJON/blob/13.0/src/strategies/SoftwareBitBang/specification/PJDL-specification-v5.0.md">PJDL</a> called <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/SoftwareBitBang">SoftwareBitBang</a>, <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/OverSampling">OverSampling</a> for radio communication and <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/AnalogSampling">AnalogSampling</a> able to communicate wirelessly or with optical fiber using off-the-shelf LEDs. Later on, I developed together with Fred Larsen <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/ThroughSerial">ThroughSerial</a> able to operate through a serial port.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2016 - It's mainstream</h2>
            <p>
               <a href="http://hackaday.com/2016/03/31/pjon-fancy-one-wire-arduino-communications-protocol-for-home-automation/" target="_blank" rel="noopener noreferrer">Hackaday</a> and the <a href="http://blog.atmel.com/2016/04/09/pjon-is-a-pretty-cool-one-wire-protocol/" target="_blank" rel="noopener noreferrer">Atmel blog</a> wrote about the PJON protocol and from that day an ongoing earthquake began. The initial response, especially in the Hackaday's comments, was quite negative - trolls were raging. Only when I joined the discussion and answered openly and sincerely to all the complaints and questions asked, the tone changed dramatically. Well, so dramatically, that in the next comments I got the most praiseworthy compliments I have ever received, those people for sure helped me not to desist. Since then, the PJON protocol specification has been used in academic researches and PhDs in different parts of the world, and the official PJON implementation has already been applied globally in a wide range of different systems.
            </p>
          </article>
          <br>
          <article>
            <h2>2016 - Let's add a header</h2>
            <p>
              The release of the <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v0.3.md" target="_blank" rel="noopener noreferrer">PJON v0.3</a> was the result of the most interesting proposal I have received so far, by Fred Larsen, who is a great friend already even if we never met personally. He proposed the addition of a 8 bits header containing a map of the fields contained in the packet and the configuration requested by the sender. At this point we left a fixed configuration scenario, where interoperability was impossible, heading towards a dynamic network architecture. An entire new set of possibilities opened up and users started to make use of this new field.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2016 - PJON over the internet</h2>
            <p>
              <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/EthernetTCP">EthernetTCP</a> and <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/LocalUDP">LocalUDP</a> made by Fred Larsen enabled multiple devices with Ethernet ports use PJON to communicate with each other on a LAN, WAN or across the Internet. It became possible to create a PJON network of devices using also an Internet connection. Our constantly growing community has already provided PJON implementations in other programming languages like <a href="https://github.com/Girgitt/PJON-python">PJON-python</a> by Zbigniew Zasieczny and <a href="https://github.com/Matheus-Garbelini/PJON-C">PJON-c</a> by Matheus Garbelini. Thanks to their work, it was for the first time possible to run PJON on a wider range of devices. At the same time the protocol reached its first stable version with the release of the <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v1.0.md" target="_blank" rel="noopener noreferrer">PJON v1.0</a> which added a lot of new features.
            </p>
          </article>
          <br>
          <article>
            <h2>2017 - Let's make it universal</h2>
            <p>
              New features brought new objectives: the community wanted to have <a href="https://github.com/gioblu/PJON">PJON</a> working on many different MCUs and real time operative systems although I wanted to avoid code duplication and maintain only one unified implementation. For this reason I defined the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces">interface</a> abstraction. With interfaces it was for the first time possible to run and cross-compile the same implementation on all supported targets. I developed the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces/RPI">RPI</a> interface to support Raspberry Pi, after few weeks Zbigniew Zasieczny developed the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces/WINX86">WINX86</a> interface enabling PJON communication on Windows computers, and soon after, Fred Larsen developed the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces/LINUX">LINUX</a> interface. In late 2017 I discovered that frame inizialization was missing from both the specification and the implementation and that arbitrary data could have been mistaken for a valid frame. I vividly remember how shocked I was, that was a serious hole, so I quickly found a way to safely identify frames in each strategy. After that was fixed and all seemed perfect I discovered the <a href="https://betterembsw.blogspot.com/2012/02/can-protocol-vulnerabilities.html">length corruption vulnerability</a> that affected PJON and still affects CAN (Controlled Area Network). To close that hole I added an additional CRC8 to protect the header and soon after I released <a href="https://github.com/gioblu/PJON/blob/9.0/specification/PJON-protocol-specification-v2.0.md">PJON v2.0</a>.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2018 - Distributed field test</h2>
            <p>
              Although PJON is licensed "AS IS", the more it was applied in the real world, the more I was feeling the responsibility for possible failures. When in 2018 Fred Larsen used PJON and <a href="https://github.com/fredilarsen/ModuleInterface">ModuleInterface</a> to handle the life support systems of his hens' house in Norway I started to be preoccupied for those animals and be finally aware of the potential consequencies and the risks involved in PJON real world applications, specially if dealing with living beings. If for whatever reason the temperature value transmitted was corrupted by interference or because of a bug, the hens could have ended up frozen or roasted. The conception of this possibility pushed me to study deeper the implementation and make better software.
            </p>
          </article>
          <br>
          <article>
            <h2>2019 - PJON in the top ten</h2>
            <p>
              After the release of <a href="https://github.com/gioblu/PJON/releases/tag/12.0">PJON 12.0</a>, in November 2019, unexpectedly, we experienced a 25% growth of the community in few days. The right <a href="https://news.ycombinator.com/item?id=21427013">HN post</a> and few reddit discussions …</p></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pjon.org/how.php">https://www.pjon.org/how.php</a></em></p>]]>
            </description>
            <link>https://www.pjon.org/how.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485943</guid>
            <pubDate>Sun, 20 Dec 2020 13:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Print() and Beyond]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25485916">thread link</a>) | @josiasaurel
<br/>
December 20, 2020 | https://josiasdev.best/python-print-and-beyond | <a href="https://web.archive.org/web/*/https://josiasdev.best/python-print-and-beyond">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><h2 id="beyond-the-print-function-in-python">Beyond the <code>print()</code> function in <em>Python</em></h2>
<p>Hey guys, today I am going to talk about some features of the <code>print()</code> function in python. You will probably have come across some of these functions while others could seem new.</p>
<p>Let's start by understanding the basics of the print function. 
In python, the built-in print function is used to print all kinds of stuff - text, numbers, objects, dictionaries etc.
But how does this function handle that ?! You might think; it just can do it, it was made for that. But in reality, the print function in python can only handle strings.</p>
<p>Under the hood, anything you pass to the <code>print()</code> function gets converted to a string before being printed to your screen. That mean it will make use of the <code>str()</code> type casting and convert all other data types to strings before displaying them to your console/terminal.
Now that you know how the <code>print()</code> work, let's dive into its features.</p>
<p>Furthermore, print doesn't know how to print text to the screen. I won't go detail into that for now. Later in this post, you will know what happens under it.</p>
<p>Basically, you can print whatever you want . The simplest example you have come across is <code>print("Hello World!")</code>
It take a string enclosed in double quotes or single quotes and prints it.
You can also print multiple stuff by simply separating them with comas as such :</p>
<pre><code>name = <span>"Mike"</span>
age = <span>24</span>
print(<span>"Hello"</span>, name, <span>"Your age is"</span>, age)

</code></pre>
<p>You can as well print text that takes more than a line. In this case, you will be using the newline escape character <code>\n</code>
Example :</p>
<pre><code>print(<span>"Hello \nWorld"</span>)



</code></pre>
<p>You can also format text with it. Making use of <code>f-strings</code></p>
<pre><code>name = <span>"Samson"</span>
print(<span>f"Hello <span>{name}</span>"</span>)

</code></pre>
<p>The example above showcase the basics of the print function. It can take a variable number of values to print. Other than that, there are also some keyword arguments.
Let's dive into them</p>
<h2 id="1-separator">1. Separator</h2>
<p><code>print()</code> allows you to decide what separates text we print with it. By default, all the values you pass to it are separated by empty strings. But we change that. It suffices to include <code>sep=</code> followed by whatever you want to separate your text.
Let's make use of the previous example.</p>
<pre><code>name = <span>"Mike"</span>
age = <span>24</span>
print(<span>"Hello"</span>, name, <span>"Your age is"</span>, age, sep=<span>"-"</span>)

</code></pre>
<p>You notice that all what we passed into it separately are separated by a <code>-</code>. You can modify that however you want. You just need to make sure the separator is a valid string.</p>
<h2 id="2-ending">2. Ending</h2>
<p>You can specify by whatever you want your output to end with. By default, what you print end with a newline escape character <code>\n</code>. Let's change that and see what happens</p>
<pre><code>
print(<span>"Hello James"</span>)
print(<span>"How are you doing"</span>)





print(<span>"Hello James"</span>, end=<span>""</span>)
print(<span>"How are you doing"</span>, end=<span>""</span>)


</code></pre>
<p>If we execute that, we notice the text is no more separated by a new line. Let's try that again! But this time, we want it to end by <code>y</code> and move to a new line.</p>
<pre><code>print(<span>"Hello James"</span>, end=<span>"y\n"</span>)
print(<span>"How are you doing"</span>, end=<span>"\n"</span>)
</code></pre>
<p>We get the following output</p>
<pre><code><span>Hello</span> Jamesy
How are you doingy
</code></pre><p>Yay it worked !</p>
<h2 id="3-writing-to-a-file">3. Writing to a file</h2>
<p>At the beginning of this post, I said python doesn't know how to print stuff to the screen by itself. It rather uses <code>sys.stdout</code> and writes your text to that file. 
Wait what ! Print will write text to a file object which I sent to your screen via <code>sys.stdout</code>. Therefore, you can modify this behaviour too in order to have this printed elsewhere.
Let's give it a try.
Write the following code:</p>
<pre><code><span>with</span> open(<span>"hello.txt"</span>, <span>"w"</span>) <span>as</span> file_object:
        print(<span>"This message is for you"</span>, file=file_object)
</code></pre>
<p>Executing the above will end in a file name <code>hello.text</code> in the same directory with the text <em>This message is for you</em> in it. 
Therefore, we can direct where we want our text to be printed. In this case, we created a file name <code>hello.txt</code> and use the <code>file</code> keyword argument to direct the result to be written to that file rather than our terminal. You can use this to direct any result to wherever you want, even through a socket connection.</p>
<h2 id="4-flushing">4. Flushing</h2>
<p>This one requires an example. Let's have one!</p>
<pre><code><span>import</span> time

names = [<span>"John"</span>, <span>"Sylvia"</span>, <span>"Smith"</span>]

<span>for</span> name <span>in</span> names:
    print(name, end=<span>" "</span>)
    time.sleep(<span>1</span>)
</code></pre>
<p>What this code should do is; print a name after a second. Try and run it and see what happens. 
You notice it unexpectedly waits and print all at once.  This is because since it's on a single line, it is all buffered (packed) before we get it. 
<a target="_blank" href="https://en.m.wikipedia.org/wiki/Data_buffer#:~:text=In%20computer%20science%2C%20a%20data,from%20one%20place%20to%20another.&amp;text=However%2C%20a%20buffer%20may%20be,comparable%20to%20buffers%20in%20telecommunication.">Read more about buffers here</a>
But we could go around that by simply adding the <code>flush=</code> keyword argument to the print function. By default it it set to <code>False</code>. Setting it to true will ensure every print statement is executed and freed from buffer before the next one.
The following code will make it :</p>
<pre><code><span>import</span> time

names = [<span>"John"</span>, <span>"Sylvia"</span>, <span>"Smith"</span>]

<span>for</span> name <span>in</span> names:
    print(name, end=<span>", "</span>, flush=<span>True</span>)
    time.sleep(<span>1</span>)
</code></pre>
<p>If you run it. It will print a name, sleep for a second and print another, all on the same line. 
Yay we did it !</p>
<p>You have reached the end of this post. 
<a target="_blank" href="https://ko-fi.com/S6S01ULOV"><img src="https://www.ko-fi.com/img/githubbutton_sm.svg" alt="ko-fi"></a></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://josiasdev.best/python-print-and-beyond</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485916</guid>
            <pubDate>Sun, 20 Dec 2020 12:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a simple neural net in Java]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25485841">thread link</a>) | @wheresvic4
<br/>
December 20, 2020 | https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

            <p>
            In this post we will tackle Artificial Intelligence with baby steps and try to build a very simple neural net in Java.
            </p>

            <h5 id="what-is-a-neural-net">What is a Neural net?</h5>

            <p>
            A neural net is a software representation of how the brain works. Unfortunately, we do not know as of yet how exactly does the brain really work but we do know a little bit of the biology behind this process: the human brain consists of 100 billion cells called neurons, connected together by synapses. If sufficient synapses connected to a neuron fire, then that neuron will also fire. This process is known as "thinking".
            </p>

            <p>
            We thus try and model the above process using a very simple example that has 3 inputs (synapses) and results in a single output (1 neuron firing).

            <img alt="Neural net example" src="https://smalldata.tech/img/blog/nn-1-simple-problem.png" width="400">
            </p>



            <h5 id="a-simple-problem">A simple problem</h5>

            <p>
            We will train our above neural net to solve the following problem. Can you figure out the pattern and guess what the value of the new input should be? 0 or 1?
            </p>

            <div>
              <table>
              <tbody><tr>
                <th>Examples</th>
                <th colspan="3">Input</th>
                <th>Output</th>
              </tr>
              <tr>
                <td>Example 1</td>
                <td>0</td>
                <td>0</td>
                <td>1</td>
                <td>0</td>
              </tr>

              <tr>
                <td>Example 2</td>
                <td>1</td>
                <td>1</td>
                <td>1</td>
                <td>1</td>
              </tr>

              <tr>
                <td>Example 3</td>
                <td>1</td>
                <td>0</td>
                <td>1</td>
                <td>1</td>
              </tr>

              <tr>
                <td>Example 4</td>
                <td>0</td>
                <td>1</td>
                <td>1</td>
                <td>0</td>
              </tr>

              <tr>
                <td colspan="5">&nbsp;</td>
              </tr>

              <tr>
                <td>New situation</td>
                <td>1</td>
                <td>1</td>
                <td>0</td>
                <td>?</td>
              </tr>

              </tbody></table>
            </div>

            <p>
            The answer is actually very simply the value of the left-most column, i.e. 1!
            </p>


            <h5 id="training-process">The training process</h5>

            <p>
            So now that we have the model of a human brain, we will try and get our neural net to learn what the pattern is given the training set. We will first assign each input a random number to produce an output.
            </p>

            <p><img alt="Neural net example" src="https://smalldata.tech/img/blog/nn-1-simple-problem-neuron-weights.png" width="400"></p><p>
            The formula for calculating the output is given as follows:
            $$\sum weight_i . input_i = weight1 . input1 + weight2 . input2 + weight3 . input3$$
            </p>

            <p>
            As it turns out we would like to normalize this output value to something between 0 and 1 so that the prediction makes sense. After normalization we compare the output with the expected output of our inputs. This gives us the error, or how far off is our prediction. We can then use this error to slightly adjust the weights of our neural net and try our luck on the same input again. This can be summarized in the following image:
            </p>

            <!--
            <div>
                <a class="image-popup-no-margins" href="/img/blog/nn-1-training-process.png">
                    <img class="img-responsive centered img-border" alt="Neural net training process" src="/img/blog/nn-1-training-process.png" />
                </a>
                <div class="img-desc">
                </div>
            </div>
            -->

            <p><img alt="Neural net training process" src="https://smalldata.tech/img/blog/nn-1-training-process.png" width="450"></p><p>
            We repeat this training process for all the inputs <i><b>10,000 times</b></i> to reach a satisfactorily trained neural net. We can then use this neural net to make predictions on new inputs!
            </p>

            <p>
            Before we jump into the implementation however, we still need to clarify how we achieved the normalization and the weight adjustment based on the error (also known as back-propagation).
            </p>

            <h5 id="normalization">Normalization</h5>

            <p>
            In a biologically inspired neural network, the output of a neuron is usually an abstraction representing the rate of action potential firing in the cell. In its simplest form, this is binary value, i.e., either the neuron is firing or not. Hence, the need for normalization of this output value.
            </p>

            <p>
            To achieve this normalization we apply what is known as an activation function to the output of the neuron. If we take the example of a really simple Heaviside step function which assigns a 0 to any negative value and a 1 to any positive value, then a large number of neurons would be required to achieve the required granularity of slowly adjusting the weights to reach an acceptable consensus of the training set.
            </p>

            <p>
            As we will see in the next section on back-propagation, this concept of slowly adjusting the weights can be represented mathematically as the slope of the activation function. In biological terms, it can be thought of as the increase in firing rate that occurs as input current increases. If we were to use a linear function instead of the Heaviside function, then we would find that the resulting network would have an unstable convergence because neuron inputs along favored paths would tend to increase without bound, as a linear function is not normalizable.
            </p>

            <p>
            All problems mentioned above can be handled by using a normalizable sigmoid activation function. One realistic model stays at zero until input current is received, at which point the firing frequency increases quickly at first, but gradually approaches an asymptote at 100% firing rate. Mathematically, this looks like:
            $$ \frac{1}{1 + e^{-x}} $$
            </p>

            <p>
            If plotted on a graph, the Sigmoid function draws an S shaped curve:
            </p>

            <p><img alt="sigmoid plot" src="https://smalldata.tech/img/blog/nn-1-sigmoid-plot.png" width="450"></p><p>
            Thus, the final formula for the output of a neuron now becomes
            $$ Output = \frac{1}{1 + e^{-(\sum weight_i . input_i)}} $$
            </p>

            <p>
            There are other normalization functions that we can use but the sigmoid has the advantage of being fairly simple and also having a simple derivative which will be useful when we look at the back propagation below.
            </p>

            <h5 id="back-propagation">Back-propagation</h5>

            <p>
            During the training cycle, we adjusted the weights depending on the error. To do this, we can use the "Error weighted derivative" formula
            $$ Adjustment = error . input . SigmoidCurveGradient(output) $$
            </p>

            <p>
            The reason we use this formula is that firstly, we want to make the adjustment proportional to the size of the error. Secondly, we multiply by the input, which is either a 0 or a 1. If the input is 0, the weight isn’t adjusted. Finally, we multiply by the gradient of the Sigmoid curve (or the derivative).
            </p>

            <p>
            The reason that we use the gradient is because we are trying to minimize the loss. Specifically, we do this by a <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent method</a>. It basically means that from our current point in the parameter space (determined by the complete set of current weights), we want to go in a direction which will decrease the loss function. Visualize standing on a hillside and walking down the direction where the slope is steepest. The gradient descent method as applied to our neural net is illustrated as follows:
            </p><ol>
                <li>If the output of the neuron is a large positive or negative number, it signifies the neuron was quite confident one way or another.</li>
                <li>From the sigmoid plot, we can see that at large numbers the Sigmoid curve has a shallow gradient.</li>
                <li>Thus, if the neuron is confident that the existing weight is correct, it doesn’t want to adjust it very much and multiplying by the gradient of the sigmoid curve achieves this.</li>
            </ol>
            

            <p>
            The derivative of the sigmoid function is given by the following formula
            $$ SigmoidCurveGradient(output) = output . (1 - output) $$
            Substituting this back into the adjustment formula gives us
            $$ Adjustment = error . input . output . (1 - output) $$
            </p>

            <h5 id="code">Code</h5>

            <p>
            An important but subtle point that was missed out when explaining the mathematics above was that for each training iteration, the mathematical operations are done on the entire training set at the same time. Thus, we will make use of matrices to store the set of input vectors, the weights and the expected outputs.
            </p>

            <p>
            You can grab the entire project source here: <a href="https://github.com/wheresvic/neuralnet">https://github.com/wheresvic/neuralnet</a>. For the sake of learning, we implemented all the math ourselves using only the standard java Math functions :)
            </p>

            <p>
            We will begin with the <code>NeuronLayer</code> class which is just a placeholder for the weights in our neural net implementation. We provide it with the number of inputs per neuron and the number of neurons which it can use to build a table of the weights. In our current example, this is very simply the last output neuron which has the 3 input neurons.
            </p>

<pre>public class NeuronLayer {

    public final Function<double, double=""> activationFunction, activationFunctionDerivative;

    double[][] weights;

    public NeuronLayer(int numberOfNeurons, int numberOfInputsPerNeuron) {
        weights = new double[numberOfInputsPerNeuron][numberOfNeurons];

        for (int i = 0; i &lt; numberOfInputsPerNeuron; ++i) {
            for (int j = 0; j &lt; numberOfNeurons; ++j) {
                weights[i][j] = (2 * Math.random()) - 1; // shift the range from 0-1 to -1 to 1
            }
        }

        activationFunction = NNMath::sigmoid;
        activationFunctionDerivative = NNMath::sigmoidDerivative;
    }

    public void adjustWeights(double[][] adjustment) {
        this.weights = NNMath.matrixAdd(weights, adjustment);
    }
}
</double,></pre>

            <p>
            Our neural net class is where all the action happens. It takes as a constructor the <code>NeuronLayer</code> and has 2 main functions:
            </p><ul>
                <li><code>think</code>: calculates the outputs of a given input set</li>
                <li><code>train</code>: runs the training loop <code>numberOfTrainingIterations</code> times (usually a high number like 10,000). Note that the training itself involves calculating the output and then adjusting the weights accordingly</li>
            </ul>
            

<pre>public class NeuralNetSimple {

    private final NeuronLayer layer1;
    private double[][] outputLayer1;

    public NeuralNetSimple(NeuronLayer layer1) {
        this.layer1 = layer1;
    }

    public void think(double[][] inputs) {
        outputLayer1 = apply(matrixMultiply(inputs, layer1.weights), layer1.activationFunction);
    }

    public void train(double[][] inputs, double[][] outputs, int numberOfTrainingIterations) {
        for (int i = 0; i &lt; numberOfTrainingIterations; ++i) {

            // pass the training set through the network
            think(inputs);

            // adjust weights by error * input * output * (1 - output)

            double[][] errorLayer1 = matrixSubtract(outputs, outputLayer1);
            double[][] deltaLayer1 = …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java">https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java</a></em></p>]]>
            </description>
            <link>https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485841</guid>
            <pubDate>Sun, 20 Dec 2020 12:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meritocracies Are Unfair – and That's the Point]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25485766">thread link</a>) | @whack
<br/>
December 20, 2020 | https://outlookzen.com/2020/12/20/meritocracies-are-unfair-and-thats-the-point/ | <a href="https://web.archive.org/web/*/https://outlookzen.com/2020/12/20/meritocracies-are-unfair-and-thats-the-point/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><a href="https://en.as.com/en/2020/04/13/other_sports/1586800170_771249.html" target="_blank"><img data-attachment-id="1212" data-permalink="https://outlookzen.com/bolt/" data-orig-file="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg" data-orig-size="1242,1114" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bolt" data-image-description="" data-medium-file="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=300" data-large-file="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=1024" src="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=1024" alt="" srcset="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=1024 1024w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=150 150w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=300 300w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=768 768w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg 1242w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>When your father suffers a heart attack and needs emergency surgery, who would you rather have operating on him?</p>



<p>An inspiring doctor who lost an arm in a tragic car accident, and still heroically manages to attain an average level of success as a surgeon?<br>Or the son of a multimillionaire who has breezed through life with minimal setbacks, and boasts one of the best surgical track records?</p>



<hr>



<p>There is a common perception that a meritocracy is the most fair way to run society. That because we are avoiding bias and favoritism and picking candidates purely based on their capabilities and achievements, a meritocratic system is the most fair of all.&nbsp;</p>



<p>Such a belief is hogwash. There’s nothing “fair” about not selecting the surgeon who lost his arm in a car accident, and is now trying desperately to hold on to his career. There’s nothing fair about the fact that some people are born into good circumstances which confer a tremendous headstart in life. There’s nothing fair about the fact that so many of society’s most accomplished individuals grew up in upper-middle-class families that nurtured them, raised them well, and gave them access to highly regarded schools and teachers.</p>



<p>A meritocracy never was, and never will be, “fair”. <strong>And that’s the whole point.</strong></p>



<p>The reason meritocracies work so well, is not because they are fair, but because they produce peak performance.</p>



<p>NFL teams draft the “best” players they can find, because they know that’s how they can win the most games. Universities grant tenure to the most productive professors, because that will best enhance the University’s reputation, and further the frontiers of knowledge. Hospitals hire the best doctors, because they can save the most lives.&nbsp;</p>



<p>Hiring people who are “good enough” is simply not good enough. There has never been, and never will be, a team that won the world cup by selecting players who are “good enough.” And what’s true for a kid’s game, is doubly true for our society. A society should delegate its jobs to those who are smartest, most capable, and most accomplished in that field. Because they are the ones who can best lead society through the worldly challenges we face everyday. Corrupting this process by discriminating on the basis of family ties, personal friendships, wealth, race, or gender, is simply cutting your nose to spite your face.</p>



<p>Which is not to say that “fairness” and Social Justice isn’t important. It is vital. But you don’t get to it by hiring less qualified candidates. By turning down the best possible candidate in favor of someone who is more sympathetic and “good enough”. A meritocracy excels at producing wealth and economic prosperity. Universal basic income, universal healthcare, unemployment insurance, better public schooling and free job trainings… these are the kind of Social Justice programs that can share the resulting prosperity among everyone.</p>



<p>Social justice teaches us how to distribute the pie fairly, so that no one is left behind. This is absolutely essential, and something we should always keep in mind. But social justice doesn’t have all the answers on how to grow the pie in the first place. And unless we harness the power of a meritocracy to keep the pie growing, we will all soon be fighting over scraps.</p>



<hr>



<p><a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=25485766" target="_blank"><em>Discussion thread on HackerNews</em></a></p>



<p><em><strong>Addendum</strong>: This article’s thesis is that we should select/hire candidates who will perform best in the role, regardless of their personal circumstances. Many have mentioned that traditional methods of assessment may be flawed, incomplete, or biased. In accordance with the thesis, we should certainly strive to refine our assessment methods, and continually make them more accurate. This article is certainly not stating that current methods of assessment are perfect.</em></p>



<p><em>Many have also brought up the point that personal circumstances often do impact job performance. For example, <a rel="noreferrer noopener" href="https://www.gsb.stanford.edu/insights/diversity-work-group-performance" target="_blank">some studies have suggested that diverse teams perform better than homogenous teams</a>, especially in certain job roles. If you are an ardent believer in improving team performance, this would mean taking into account any demographic info that would help the organization perform better. This is also a double-edged sword for a couple reasons:<br>1. By legalizing the use of race or gender as a factor in hiring decisions, you would also be enabling prejudiced employers who discriminate against women or minorities, for purely bigoted reasons<br>2. <a rel="noreferrer noopener" href="https://archive.boston.com/news/globe/ideas/articles/2007/08/05/the_downside_of_diversity/" target="_blank">Studies have also found that communities operate better in some ways, when they are more homogenous</a>. If more such studies are unearthed in future, the same reasoning above could be used to justify discriminating against all women and people of color. Something most of us, including myself, would consider to be dystopian.</em></p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-12-20T07:05:42-05:00">December 20, 2020</time><time datetime="2020-12-21T08:16:07-05:00">December 21, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://outlookzen.com/2020/12/20/meritocracies-are-unfair-and-thats-the-point/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485766</guid>
            <pubDate>Sun, 20 Dec 2020 12:19:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Server Mark III]]>
            </title>
            <description>
<![CDATA[
Score 321 | Comments 161 (<a href="https://news.ycombinator.com/item?id=25485428">thread link</a>) | @homarp
<br/>
December 20, 2020 | https://uplab.pro/2020/12/raspberry-pi-server-mark-iii/ | <a href="https://web.archive.org/web/*/https://uplab.pro/2020/12/raspberry-pi-server-mark-iii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-597">
								
				<div>
					
<figure><img loading="lazy" width="1024" height="681" src="https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-1024x681.jpg" alt="" srcset="https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-1024x681.jpg 1024w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-300x200.jpg 300w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-768x511.jpg 768w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-1536x1022.jpg 1536w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0.jpg 1669w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Raspberry Pi Rack Server Mark I и Mark II have been working pretty nice for 6 month already. Both of them are based on a model which I found on <a href="https://thingiverse.com/" data-type="URL" data-id="https://thingiverse.com">thingiverse.com</a> and inherited the basic design idea.</p>



<p>With Mark III, I completely rethought the design, which allowed to:</p>



<ul><li>increase the number of raspberries in 2 rack units</li><li>significantly reduce printing time and plastic consumption</li><li>significantly reduce the time required for assembling and disassembling the server</li><li>reduce the number of parts</li><li>implement a modular design, which means that MARK III will be available in various modifications</li></ul>



<p>I’m glad to present the first basic model, designed for 14x of Raspberry Pi and 14x of a standard 2.5″ SSD.</p>



<p>BTW I will be glad if you subscribe to my instagram <a rel="noreferrer noopener" href="https://www.instagram.com/uptime.lab/" target="_blank">instagram.com/uptime.lab</a> your feedback and likes are very important for me!</p>










<figure><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="179" height="82" src="https://uplab.pro/wp-content/uploads/2020/10/image-1.png" alt=""></a></figure>



<p>Printing recommendations:</p>



<ul><li>layer height 0.15mm</li><li>wall thickness &nbsp;0.6mm</li><li>no supports</li><li>horizontal expansion &nbsp;-0.1mm</li><li>without a skirt&nbsp;&nbsp;</li></ul>



<p>Please print one Tray and one Body part first and have a look at how they fit each other, as well as how it works with Raspberry Pi and your SSD.</p>



<p>Screws and other parts:</p>



<ul id="block-9f0674bd-8795-4e10-ada2-1c682dcbc328"><li>Set of 5 fans <a rel="noreferrer noopener" href="https://www.amazon.de/gp/product/B00NTUJZ36" target="_blank">Arctic F8 Value Pack, ACFAN0 0061 A</a>&nbsp;–&nbsp;<strong>€17.60 incl. VAT</strong></li><li>Power supply for fans&nbsp;<a rel="noreferrer noopener" href="https://www.amazon.de/gp/product/B07MJQ8K4P" target="_blank">12V2A 7Tipps</a>&nbsp;–&nbsp;<strong>EUR 13.99 incl. VAT</strong></li><li>Adapter with 1 to 6 fans. Cutting off the extra one turns out perfect for my purposes&nbsp;<a rel="noreferrer noopener" href="https://www.amazon.de/gp/product/B003UU6EQQ" target="_blank">Lüfter Adapterkabel 3Pin auf 6x 3Pin Molex (6x15cm)</a>&nbsp;–&nbsp;<strong>€4.40 incl. VAT</strong></li><li>Screws for fans M4 12mm 10 pcs. with nuts</li><li>Threaded rod M5 ~452mm &nbsp;2 pcs. and 4pcs nuts M5</li><li>20 screws for fans for plastic (usually come with fans) Like that <a rel="noreferrer noopener" href="https://www.amazon.de/-/en/StarTech-com-Case-Fan-Screws-Pack/dp/B0002AFTD6" target="_blank">StarTech.com PC Case Fan Screws (Pack of 50)</a></li><li>In case you don’t use original PoE hat you additionally need 2x M2.5 with M2.5 nut for each Raspberry</li><li>2pcs. M3 ~5mm for each SSD. Like <a rel="noreferrer noopener" href="https://www.amazon.de/-/en/Poppstar-Hard-Drive-Screws-Drives/dp/B01HBRG3W8/ref=sr_1_7?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;dchild=1&amp;keywords=m3+ssd+schraube&amp;qid=1608385770&amp;sr=8-7" target="_blank">Poppstar Hard Drive Screws for 3.5 Inch or 2.5 Inch Hard Drives Set of 50</a></li><li>SATA Cable Adapter, USB 3.0 to SSD&nbsp;(you don’t need model faster). Like <a href="https://www.amazon.de/-/en/Sabrent-2-5-inch-Optimized-Supports-EC-SSHD/dp/B011M8YACM/" target="_blank" rel="noreferrer noopener">Sabrent SATA Cable Adapter, USB 3.0 to SSD / 2.5-inch SATA Hard Drive Adapter</a></li></ul>




			
				</div><!-- end .entry-content -->
							</article></div>]]>
            </description>
            <link>https://uplab.pro/2020/12/raspberry-pi-server-mark-iii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485428</guid>
            <pubDate>Sun, 20 Dec 2020 11:08:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a custom iterator in modern C++]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25484444">thread link</a>) | @signa11
<br/>
December 19, 2020 | https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp | <a href="https://web.archive.org/web/*/https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>— Written by Triangles on December 13, 2020 
								• updated on December 19, 2020  
								• ID 86 —</p><p>An experimental Forward Iterator written from scratch to boost up hand-made containers.</p><div>
				
<!-- internalpointers responsive -->
<p>An iterator is an object that points to an element inside a container. Like a pointer, an iterator can be used to access the element it points to and can be moved through the content of the container. Each container in the C++ Standard Library provides its own iterator, as well as some methods to retrieve it. Using iterators is quite easy: obtain an instance from a container, move it around where needed and then get the pointed element.</p>
<p>Concretely, an iterator is a simple class that provides a bunch of operators: increment <code>++</code>, dereference <code>*</code> and few others which make it very similar to a pointer and the arithmetic operations you can perform on it. In fact, iterators are a generalization of pointers, which are often used as a foundation when writing the iterator itself.</p>
<p>Iterators are one of the building blocks of the Standard Library containers, but they are also useful when you want to provide the ability to iterate over elements of a custom container that you wrote yourself: this is what I want to investigate in the present article. Adding iterators to your containers will make them compatible with the <a href="https://en.cppreference.com/w/cpp/language/range-for">range-based for loops</a> and the <a href="https://en.cppreference.com/w/cpp/algorithm">C++ Algorithms library</a>: a collection of functions for searching, sorting, counting and manipulating containers, based on iterators.</p>
<h2>A dummy container for our experiments</h2>
<p>Before digging deeper, let's define a silly custom container that we want to spice up with iterators:</p>
<pre><code>class Integers
{
private:
    int m_data[200];
};
</code></pre>
<p>The <code>Integers</code> class is a wrapper around a raw array of <code>int</code>s: we want to be able to access elements of that private array through an iterator, as well as to loop over it or pass it to any of the Standard Library algorithms. Let's start by making some design decisions.</p>
<h2>Choose the nature of our iterator</h2>
<p>The first step is to choose the type of iterator we want to implement. Modern C++ defines six types:</p>
<table>
<thead><tr>
<th>#</th>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/InputIterator">Input Iterator</a></strong></td>
<td>Can scan the container forward only once, can't change the value it points to (read-only);</td>
</tr>
<tr>
<td>2</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/OutputIterator">Output Iterator</a></strong></td>
<td>Can scan the container forward only once, can't read the value it points to (write-only);</td>
</tr>
<tr>
<td>3</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/ForwardIterator">Forward Iterator</a></strong></td>
<td>Can scan the container forward multiple times, can read and write the value it points to;</td>
</tr>
<tr>
<td>4</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/BidirectionalIterator">Bidirectional Iterator</a></strong></td>
<td>Same as previous one but can scan the container back and forth;</td>
</tr>
<tr>
<td>5</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/RandomAccessIterator">Random Access Iterator</a></strong></td>
<td>Same as previous one but can access the container also non-sequentially (i.e. by jumping around);</td>
</tr>
<tr>
<td>6</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/ContiguousIterator">Contiguous Iterator</a></strong></td>
<td>Same as previous one, with the addition that logically adjacent elements are also physically adjacent in memory.</td>
</tr>
</tbody>
</table>
<p>The six categories are hierarchical: a Bidirectional Iterator is also a Forward Iterator and a Random Access Iterator is both a Bidirectional and a Forward Iterator and so on. Normally, all iterators are Input Iterators (1) which makes them read-only, also known as <strong>constant iterators</strong>. Iterators that both support read and write operations are also Output Iterators (2) and are called <strong>mutable iterators</strong>.</p>
<div>
<p><img src="https://raw.githubusercontent.com/monocasual/internalpointers-files/master/2020/12/iterators/iterator-hierarchy.png" alt="Iterators hierarchy"></p><p>1. Iterators hierarchy in C++. All iterators are Input Iterators, Output Iterators or both.</p>
</div><p>Input and Output iterators are often used for low-level components such as input and output streams (the so-called <strong>single-pass algorithms</strong>) and thus have limitations. We want to do more with our custom container, so we will skip those two and jump straight to the mutable Forward Iterator.</p>
<h2>Prepare the custom iterator</h2>
<p>An iterator is usually declared inside the class it belongs to, for example:</p>
<pre><code>class Integers
{
public:
    struct Iterator { /* ... */ };

    // ...
};
</code></pre>
<p>The first thing to do is to assign the iterator some properties. Until C++17 this is done by <em>tagging</em> it with the <a href="https://www.fluentcpp.com/2018/04/27/tag-dispatching/"><strong>tag dispatch</strong></a> mechanism, while C++20 uses <strong>concepts</strong>: in this article I will follow the traditional approach.</p>
<p>C++ expects some properties from an iterator:</p>
<ul>
<li><code>iterator_category</code> — one of the six iterator categories we have seen above. The full list is available <a href="https://en.cppreference.com/w/cpp/iterator/iterator_tags">here</a>. The <code>std::forward_iterator_tag</code> tag is what we need;</li>
<li><code>difference_type</code> — a signed integer type that can be used to identify distance between iterator steps. Our iterator is basically a wrapper around a pointer and leverages pointer arithmetic, so the default <a href="https://en.cppreference.com/w/cpp/types/ptrdiff_t"><code>std::ptrdiff_t</code></a> is a good choice;</li>
<li><code>value_type</code> — the type the iterator iterates over. <code>int</code> in our case;</li>
<li><code>pointer</code> — defines a pointer to the type iterated over. <code>int*</code> in our case;</li>
<li><code>reference</code> — defines a reference to the type iterated over. <code>int&amp;</code> in our case;</li>
</ul>
<p>Translated into code:</p>
<pre><code>#include &lt;iterator&gt; // For std::forward_iterator_tag
#include &lt;cstddef&gt;  // For std::ptrdiff_t

struct Iterator 
{
    using iterator_category = std::forward_iterator_tag;
    using difference_type   = std::ptrdiff_t;
    using value_type        = int;
    using pointer           = int*;  // or also value_type*
    using reference         = int&amp;;  // or also value_type&amp;
};
</code></pre>
<h3>Why are tags useful?</h3>
<p>Some of the tags above might seem useless at first. In fact, you will notice how they will never get mentioned during the definition of our iterator. Tags are used to select the most efficient algorithm if your container is passed to one of the Standard Library functions from the <code>&lt;algorithm&gt;</code> library. Wrong tags mean sub-optimal performance! The iterator category is also used to set algorithm requirements, for example: <a href="https://en.cppreference.com/w/cpp/algorithm/fill"><code>std::fill</code></a> wants a Forward Iterator, while <a href="https://en.cppreference.com/w/cpp/algorithm/reverse"><code>std::reverse</code></a> wants a Bidirectional Iterator. Passing the wrong iterator will result in a compilation error.</p>
<h2>Define the iterator constructors</h2>
<p>All iterators must be <em>constructible</em>, <em>copy-constructible</em>, <em>copy-assignable</em>, <em>destructible</em> and <em>swappable</em>. Let's translate those requirements into code for our iterator:</p>
<pre><code>struct Iterator 
{
    // Iterator tags here...

    Iterator(pointer ptr) : m_ptr(ptr) {}

private:

    pointer m_ptr;
};
</code></pre>
<p>Easy! We just need a custom constructor to initialize the private member variable <code>m_ptr</code>, which points to an element of the <code>Integers</code> container. The custom constructor satisfies the <em>constructible</em> requirement, while all others are covered by the implicitly-declared constructors and operators kindly provided by the compiler.</p>
<h2>Implement operators</h2>
<p>We are building a mutable Forward Iterator, which inherits properties from both Input and Output Iterators. The resulting iterator must support the following operations:</p>
<ul>
<li><code>*iterator</code> and <code>iterator-&gt;x</code> — dereferenceable, to get the value it points to;</li>
<li><code>++iterator</code> and <code>iterator++</code> — incrementable, to move it one step forward, both prefix and postfix versions. The latter must return something dereferenceable;</li>
<li><code>iterator_a == iterator_b</code> and <code>iterator_a != iterator_b</code> — comparable with another iterator;</li>
</ul>
<p>This is done by implementing some custom operators in the <code>Iterator</code> class, like this:</p>
<pre><code>struct Iterator 
{
    // Iterator tags here...

    // Iterator constructors here...

    reference operator*() const { return *m_ptr; }
    pointer operator-&gt;() { return m_ptr; }

    // Prefix increment
    Iterator&amp; operator++() { m_ptr++; return *this; }  

    // Postfix increment
    Iterator operator++(int) { Iterator tmp = *this; ++(*this); return tmp; }

    friend bool operator== (const Iterator&amp; a, const Iterator&amp; b) { return a.m_ptr == b.m_ptr; };
    friend bool operator!= (const Iterator&amp; a, const Iterator&amp; b) { return a.m_ptr != b.m_ptr; };     

private:

    pointer m_ptr;
};
</code></pre>
<p>As you can see every operator involves the usage of the private pointer <code>m_ptr</code>. Also, notice the <code>friend</code> declaration for the two comparison operators: this is handy way to define the operators as non-member functions, yet being able to access private parts of the <code>Iterator</code> class (rationale  <a href="https://stackoverflow.com/questions/4421706/what-are-the-basic-rules-and-idioms-for-operator-overloading/4421729#4421729">here</a>).</p>
<h2>Prepare the container</h2>
<p>Our iterator is good to go. The last step is to give our custom container the ability to create <code>Iterator</code> objects. This is done by adding two public methods <code>begin()</code> and <code>end()</code> that return instances of the <code>Iterator</code> class, representing the first and the last element respectively:</p>
<pre><code>class Integers
{
public:

    // Iterator definition here ...

    Iterator begin() { return Iterator(&amp;m_data[0]); }
    Iterator end()   { return Iterator(&amp;m_data[200]); } // 200 is out of bounds
};
</code></pre>
<p>The <code>end()</code> method returns an iterator that refers to an <em>invalid</em> memory address, past the end of our raw array. Such iterator is just a placeholder used to determine when the boundary has been reached: it should never be accessed directly.</p>

<!-- internalpointers responsive -->
<h2>Time to test our iterator</h2>
<p>Both the custom container and its iterator are now ready. Let's test them with the range-based for loop:</p>
<pre><code>Integers integers;
for (auto i : integers)
    std::cout &lt;&lt; i &lt;&lt; "\n";
</code></pre>
<p>This code will magically print the value of each integer in the container. It works because the range-based for loop is just syntactic sugar created by the compiler for the following:</p>
<pre><code>for (auto it = integers.begin(), end = integers.end(); it != end; ++it) { 
    const auto i = *it; 
    std::cout &lt;&lt; i &lt;&lt; "\n";
}
</code></pre>
<p>In words: two iterators <code>it</code> and <code>end</code> are created. The first one points to the beginning of the container, the other one points to the end. Then, on each loop, the <code>it</code> iterator is incremented until it's equal to <code>end</code>, that is until the end of the container has been reached. The actual value is obtained by dereferencing <code>it</code> in a local variable before being printed.</p>
<p>Notice how the compiler makes use of all the operators and functions we have previously implemented: the <code>begin()</code> and <code>end()</code> methods in the custom container, the ability to compare the two iterators with the <code>!=</code> operator, the ability to increment <code>it</code> with the prefix syntax and finally the ability to dereference it to grab the actual value it points to.</p>
<p>Let's now try a function from the Algorithm library, <a href="https://en.cppreference.com/w/cpp/algorithm/fill"><code>std::fill</code></a> for example:</p>
<pre><code>Integers integers;

std::fill(integers.begin(), integers.end(), 3);
</code></pre>
<p>The function assigns all elements in the container the value <code>3</code>. It works because <code>std::fill</code> is usually implemented like this:</p>
<pre><code>template &lt;typename ForwardIterator, …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp">https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp</a></em></p>]]>
            </description>
            <link>https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25484444</guid>
            <pubDate>Sun, 20 Dec 2020 06:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knotwork Designer]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25484101">thread link</a>) | @blewboarwastake
<br/>
December 19, 2020 | http://birrell.org/andrew/knotwork/ | <a href="https://web.archive.org/web/*/http://birrell.org/andrew/knotwork/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://birrell.org/andrew/knotwork/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25484101</guid>
            <pubDate>Sun, 20 Dec 2020 05:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebooting a 15 year-old game written in D – Part 1 Compiling]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25483693">thread link</a>) | @arunc
<br/>
December 19, 2020 | https://speps.fr/articles/torus-trooper-part1/ | <a href="https://web.archive.org/web/*/https://speps.fr/articles/torus-trooper-part1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-container">
        <div id="main">
            
<div id="content">
	<div id="page">
		
		
		
		
		<p>See also</p>
<ul>
<li><a href="https://speps.fr/articles/torus-trooper-part1">Part 1 - Compiling a new executable</a></li>
<li><a href="https://speps.fr/articles/torus-trooper-part2">Part 2 - Running the game for the first time</a></li>
<li><a href="https://speps.fr/articles/torus-trooper-part3">Part 3 - Porting to WebAssembly</a></li>
<li><a href="https://speps.fr/articles/torus-trooper-part4">Part 4 - Final steps</a></li>
</ul>
<p>While exploring D recently, I remembered a game I played while at university 15 years ago. For a long time, I couldn’t remember the name at all, only that it was from a Japanese developer. After some search wrangling, I finally managed to find the name of the game: <strong>Torus Trooper!</strong></p>
<p>You can find it there: <a href="http://www.asahi-net.or.jp/~cs8k-cyu/windows/tt_e.html">http://www.asahi-net.or.jp/~cs8k-cyu/windows/tt_e.html</a></p>
<p><img src="https://speps.fr/media/articles/tt1.png" alt=""></p>
<p>Here is a copy of the tt0_22.zip file archived: <a href="https://github.com/speps/tt/archive/legacy.zip">https://github.com/speps/tt/archive/legacy.zip</a></p>
<p>What made me remember this game is that :</p>
<ul>
<li>It came with <a href="https://github.com/speps/tt/tree/legacy/src/abagames">source code</a>, quite unusual at the time for me</li>
<li>Written in D, a language I didn’t know at all while I was busy studying C++</li>
<li>It’s awfully addictive!</li>
</ul>
<p>What better project than try to compile a <strong>D v0.110</strong> project in a modern version of D and possibly porting the game to WebAssembly+WebGL! So here we are…</p>
<h2 id="switching-from-ant-to-dub">Switching from Ant to DUB</h2>
<p>The game used Ant and its <code>build.xml</code> file to generate the executable, resources, etc. Since then, D added DUB as a build system / package manager so let’s use that!</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="json"><span>{</span>
	<span>"authors"</span><span>:</span> <span>[</span>
		<span>"Kenta Cho"</span><span>,</span>
		<span>"Remi Gillig"</span>
	<span>],</span>
	<span>"copyright"</span><span>:</span> <span>"Copyright © 2004 - Kenta Cho, 2020 - Remi Gillig"</span><span>,</span>
	<span>"description"</span><span>:</span> <span>"Torus Trooper (Reboot)"</span><span>,</span>
	<span>"license"</span><span>:</span> <span>"BSD 2-clause"</span><span>,</span>
	<span>"name"</span><span>:</span> <span>"tt"</span><span>,</span>
	<span>"targetType"</span><span>:</span> <span>"executable"</span><span>,</span>
	<span>"sourcePaths"</span><span>:</span> <span>[</span>
		<span>"src"</span>
	<span>]</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>With this initial <code>dub.json</code> file, I was set to run the <code>dub</code> command…</p>
<div><pre><code data-lang="plaintext">Performing "debug" build using C:\D\dmd2\windows\bin64\dmd.exe for x86.
tt ~master: building configuration "application"...
src\abagames\tt\barrage.d(95,33): Error: instead of C-style syntax, use D-style BulletMLParserTinyXML*[char[]][char[]] parser
src\abagames\tt\barrage.d(122,28): Error: instead of C-style syntax, use D-style BulletMLParserTinyXML*[] pl
src\abagames\tt\barrage.d(130,14): Error: instead of C-style syntax, use D-style BulletMLParserTinyXML*[char[]] pa
src\abagames\tt\boot.d(51,12): Error: instead of C-style syntax, use D-style char[4096] exe
src\abagames\tt\tunnel.d(300,14): Error: template argument expected following !
src\abagames\tt\tunnel.d(322,14): Error: template argument expected following !
src\abagames\util\rand.d(115,6): Error: instead of C-style syntax, use D-style uint[N] state
src\abagames\util\rand.d(140,20): Error: instead of C-style syntax, use D-style uint[] init_key
src\abagames\util\sdl\luminous.d(21,10): Error: instead of C-style syntax, use D-style GLuint[LUMINOUS_TEXTURE_WIDTH_MAX * LUMINOUS_TEXTURE_HEIGHT_MAX * 4 * (uint).sizeof] td
src\abagames\util\sdl\luminous.d(83,17): Error: instead of C-style syntax, use D-style float[2][2] lmOfs
C:\D\dmd2\windows\bin64\dmd.exe failed with exit code 1.
</code></pre></div><p>Alright let’s start and get this to compile!</p>
<h2 id="c-style-syntax-errors">C-style syntax errors</h2>
<p>This is one is easy to fix, the suggestion from the compiler works, I just replaced every instance of this error with the suggestion.</p>
<p>Here is an example:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -42,7 +43,7 @@ struct SDL_AudioSpec {
</span><span></span>     Once the callback returns, the buffer will no longer be valid.
     Stereo samples are stored in a LRLRLR ordering.
  */
<span>- void (*callback)(void *userdata, Uint8 *stream, int len);
</span><span></span><span>+ void function(void *userdata, Uint8 *stream, int len) callback;
</span><span></span>  void  *userdata;
 }
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="error-template-argument-expected-following-">Error: template argument expected following !</h2>
<p>This is an interesting one, here is one of the files where this error triggers:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span><span>17
</span></span><span>18
</span><span>19
</span><span>20
</span><span>21
</span></code></pre></td>
<td>
<pre><code data-lang="d">  <span>private</span> <span>void</span> <span>calcIndex</span><span>(</span><span>in</span> <span>float</span> <span>z</span><span>,</span> <span>out</span> <span>int</span> <span>idx</span><span>,</span> <span>out</span> <span>float</span> <span>ofs</span><span>)</span> <span>{</span>
    <span>idx</span> <span>=</span> <span>slice</span><span>.</span><span>length</span> <span>+</span> <span>99999</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>slice</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>if</span> <span>(</span><span>z</span> <span>&lt;</span> <span>slice</span><span>[</span><span>i</span><span>].</span><span>depth</span><span>)</span> <span>{</span>
        <span>idx</span> <span>=</span> <span>i</span> <span>-</span> <span>1</span><span>;</span>
        <span>ofs</span> <span>=</span> <span>(</span><span>z</span> <span>-</span> <span>slice</span><span>[</span><span>idx</span><span>].</span><span>depth</span><span>)</span> <span>/</span> <span>(</span><span>slice</span><span>[</span><span>idx</span> <span>+</span> <span>1</span><span>].</span><span>depth</span> <span>-</span> <span>slice</span><span>[</span><span>idx</span><span>].</span><span>depth</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
    <span>}</span>
    <span>if</span> <span>(</span><span>idx</span> <span>&lt;</span> <span>0</span><span>)</span> <span>{</span>
      <span>idx</span> <span>=</span> <span>0</span><span>;</span>
      <span>ofs</span> <span>=</span> <span>0</span><span>;</span>
    <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>idx</span> <span>&gt;=</span> <span>slice</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>)</span> <span>{</span>
      <span>idx</span> <span>=</span> <span>slice</span><span>.</span><span>length</span> <span>-</span> <span>2</span><span>;</span>
      <span>ofs</span> <span>=</span> <span>0.99</span><span>;</span>
    <span>}</span>
<span>    <span>if</span> <span>(</span><span>ofs</span> <span>!&gt;=</span> <span>0</span><span>)</span> <span>// ERROR HERE
</span></span><span></span>      <span>ofs</span> <span>=</span> <span>0</span><span>;</span>
    <span>else</span> <span>if</span> <span>(</span><span>ofs</span> <span>&gt;=</span> <span>1</span><span>)</span>
      <span>ofs</span> <span>=</span> <span>0.99</span><span>;</span>
  <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>I did try a few searches without success so I asked on the D community forums and a few people guessed right, it’s of course a <code>not &gt;=</code>, equivalent to <code>&lt;</code>. However, <a href="https://forum.dlang.org/post/rec3d1$toc$1@digitalmars.com">thanks to Walter Bright</a>, I got a link to the <a href="https://www.digitalmars.com/ctg/ctgNumerics.html#comparisons">original documentation from Digital Mars</a>. The subtle difference with <code>!&gt;=</code> is that it will also return <code>true</code> if any operands are <code>NaN</code>. Suggested fix seems to have worked:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>17
</span><span>18
</span></code></pre></td>
<td>
<pre><code data-lang="d">    <span>if</span> <span>(</span><span>std</span><span>.</span><span>math</span><span>.</span><span>isNaN</span><span>(</span><span>ofs</span><span>)</span> <span>||</span> <span>ofs</span> <span>&lt;</span> <span>0</span><span>)</span>
      <span>ofs</span> <span>=</span> <span>0</span><span>;</span>
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="replacing-char-with-string">Replacing <code>char[]</code> with <code>string</code></h2>
<p>D1 used to have <code>char[]</code> as the string type, and functions in <code>std.string</code> in Phobos to manipulate this type. D2 replaced this with an <code>alias string = immutable(char)[]</code>. As a result, a lot of the code needs updating to deal with this. That includes the code in the custom bindings.</p>
<p>Most of the changes here are similar to this</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -92,24 +91,24 @@ public class Barrage {
</span><span></span>  */
 public class BarrageManager {
  private:
<span>-  static BulletMLParserTinyXML *parser[char[]][char[]];
</span><span>-  static const char[] BARRAGE_DIR_NAME = "barrage";
</span><span></span><span>+  static BulletMLParserTinyXML*[string][string] parser;
</span><span>+  static const string BARRAGE_DIR_NAME = "barrage";
</span><span></span> 
   public static void load() {
<span>-    char[][] dirs = listdir(BARRAGE_DIR_NAME);
</span><span>-    foreach (char[] dirName; dirs) {
</span><span>-      char[][] files = listdir(BARRAGE_DIR_NAME ~ "/" ~ dirName);
</span><span>-      foreach (char[] fileName; files) {
</span><span>-        if (getExt(fileName) != "xml")
</span><span></span><span>+    string[] dirs = listdir(BARRAGE_DIR_NAME);
</span><span>+    foreach (string dirName; dirs) {
</span><span>+      string[] files = listdir(BARRAGE_DIR_NAME ~ "/" ~ dirName);
</span><span>+      foreach (string fileName; files) {
</span><span>+        if (fileName.extension != ".xml")
</span><span></span>           continue;
         parser[dirName][fileName] = getInstance(dirName, fileName);
       }
     }
   }
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="converting-value-to-string">Converting value to string</h2>
<p>D1 used to have <code>std.string.toString</code> to convert a value to a <code>char[]</code> value. This functionality was replaced by <code>std.conv.to!string</code>.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -5,6 +5,7 @@
</span><span></span>  */
 module abagames.tt.shot;
 
<span>+private import std.conv;
</span><span></span> private import std.math;
 private import std.string;
 private import opengl;
<span>@@ -179,7 +180,7 @@ public class Shot: Actor {
</span><span></span>       else if (sc &gt;= 2000)
         size = 0.7;
       size *= (1 + multiplier * 0.01f);
<span>-      fl.set("X" ~ std.string.toString(multiplier), pos, size * pos.y,
</span><span></span><span>+      fl.set("X" ~ to!string(multiplier), pos, size * pos.y,
</span><span></span>              cast(int) (30 + multiplier * 0.3f));
     }
     if (chargeShot) {
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="passing-strings-to-c">Passing strings to C</h2>
<p>The usual way to pass strings to C seems to have been to just to use <code>std.string.toStringz</code>. However, back in D1 it used to return char* :</p>
<pre><code>char* toStringz(char[] s);
</code></pre><p>This worked well for the C bindings but with D2, it now returns:</p>
<pre><code>immutable(char)* toStringz(scope return string s) pure nothrow @trusted;
</code></pre><p>Again, the fix is quite straightforward. For example, the bindings weren’t written with this in mind so they need fixing:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -81,7 +81,7 @@ struct SDL_RWops {
</span><span></span> 
 /* Functions to create SDL_RWops structures from various data sources */
 
<span>-SDL_RWops * SDL_RWFromFile(char *file, char *mode);
</span><span></span><span>+SDL_RWops * SDL_RWFromFile(const char *file, const char *mode);
</span></code></pre></td></tr></tbody></table>
</div>
</div><h2 id="simple-substitution">Simple substitution</h2>
<ul>
<li><code>typedef</code> → <code>alias</code></li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -28,10 +28,10 @@ import SDL_types;
</span><span></span> 
 extern(C):
 
<span>-typedef int (*_seek_func_t)(SDL_RWops *context, int offset, int whence);
</span><span>-typedef int (*_read_func_t)(SDL_RWops *context, void *ptr, int size, int maxnum);
</span><span>-typedef int (*_write_func_t)(SDL_RWops *context, void *ptr, int size, int num);
</span><span>-typedef int (*_close_func_t)(SDL_RWops *context);
</span><span></span><span>+alias int function(SDL_RWops *context, int offset, int whence) _seek_func_t;
</span><span>+alias int function(SDL_RWops *context, void *ptr, int size, int maxnum) _read_func_t;
</span><span>+alias int function(SDL_RWops *context, void *ptr, int size, int num) _write_func_t;
</span><span>+alias int function(SDL_RWops *context) _close_func_t;
</span></code></pre></td></tr></tbody></table>
</div>
</div><ul>
<li><code>inout</code> → <code>ref</code>: this made sense for all instances where <code>inout</code> was used</li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -59,7 +59,7 @@ public class PrefData {
</span><span></span> 
   public this() {
     gradeData = new GradeData[Ship.GRADE_NUM];
<span>-    foreach (inout GradeData gd; gradeData)
</span><span></span><span>+    foreach (ref GradeData gd; gradeData)
</span><span></span>       gd = new GradeData;
   }
</code></pre></td></tr></tbody></table>
</div>
</div><ul>
<li><code>auto T</code> → <code>auto</code>: it seems the original author specified auto along with the type which isn’t allowed anymore</li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -631,9 +631,9 @@ public class BulletShape: Drawable {
</span><span></span>   }
 
   private void createSquareShape(bool wireShape) {
<span>-    auto Vector3 cp = new Vector3;
</span><span>-    auto Vector3[] p = new Vector3[4];
</span><span>-    auto Vector3[] np = new Vector3[4];
</span><span></span><span>+    auto cp = new Vector3;
</span><span>+    auto p = new Vector3[4];
</span><span>+    auto np = new Vector3[4];
</span><span></span>     static const float[][][] POINT_DAT = [
       [[-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1], ],
       [[-1, -1, -1], [1, -1, -1], [1, 1, -1], [-1, 1, -1], ],
<span>@@ -642,9 +642,9 @@ public class BulletShape: Drawable {
</span><span></span>       [[1, -1, -1], [1, -1, 1], [1, 1, 1], [1, 1, -1], ],
       [[-1, -1, -1], [-1, -1, 1], [-1, 1, 1], [-1, 1, -1], ],
     ];
<span>-    foreach (inout Vector3 ip; p)
</span><span></span><span>+    foreach (ref Vector3 ip; p)
</span><span></span>       ip = new Vector3;
<span>-    foreach (inout Vector3 inp; np)
</span><span></span><span>+    foreach (ref Vector3 inp; np)
</span><span></span>       inp = new Vector3;
     for (int i = 0; i &lt; 6; i++) {
       cp.x = cp.y = cp.z = 0;
</code></pre></td></tr></tbody></table>
</div>
</div><ul>
<li><code>getExt</code> → <code>.extension</code>: behaviour is different but it’s easy enough to fix, it now includes the dot</li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -44,10 +45,10 @@ public class SoundManager: abagames.util.sdl.sound.SoundManager {
</span><span></span> 
   private static Music[] loadMusics() {
     Music[] musics;
<span>-    char[][] files = listdir(Music.dir);
</span><span>-    foreach (char[] fileName; files) {
</span><span>-      char[] ext = getExt(fileName);
</span><span>-      if (ext != "ogg" &amp;&amp; ext != "wav")
</span><span></span><span>+    string[] files = listdir(Music.dir);
</span><span>+    foreach (string …</span></code></pre></td></tr></tbody></table></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://speps.fr/articles/torus-trooper-part1/">https://speps.fr/articles/torus-trooper-part1/</a></em></p>]]>
            </description>
            <link>https://speps.fr/articles/torus-trooper-part1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25483693</guid>
            <pubDate>Sun, 20 Dec 2020 03:42:50 GMT</pubDate>
        </item>
    </channel>
</rss>
