<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 08 Oct 2020 04:23:49 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 08 Oct 2020 04:23:49 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: Chat bot powered by GPT-3]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24695710">thread link</a>) | @piotrgrudzien
<br/>
October 6, 2020 | https://blog.quickchat.ai/post/knowledge-base-chat-bot/ | <a href="https://web.archive.org/web/*/https://blog.quickchat.ai/post/knowledge-base-chat-bot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><img src="https://blog.quickchat.ai/images/blog-post-1-bg.png" alt="Knowledge-base chat bot for SaaS product sales"></figure><section><div><p><em>Brief summary of our GPT-3 chat bot for SaaS product sales.</em></p><p>The most natural way for us to communicate is, well, <em>natural language</em>. Chat bots are nothing new but unless they meet a high-enough quality bar, they tend to be a step backwards rather than forward. We believe huge language models such as <a href="https://openai.com/blog/openai-api/">OpenAIâ€™s GPT-3</a> will form a foundation for a truly conversational human-computer interface. It is, however, a foundation rather than a solution in and of itself.</p><p>In this new paradigm, the big challenge becomes to ensure the chat bot strictly sticks to the topic it was designed for and provides accurate information - without depriving it of its creativity.</p><p>I will discuss this briefly in the context of what we refer to as <strong>knowledge-base chat bots</strong>. They are built to answer general questions and hold a conversation about a product, service or a topic delineated by a predetermined unstructured knowledge base.</p><p><img src="https://blog.quickchat.ai/images/zeroth_faster.gif" alt="Start a conversation - image" title="Start a conversation"></p><p>Our chat bot implementation approved by the OpenAI team (try it out live at <a href="https://itemsy.com/">itemsy.com</a>) is an expert on Itemsy - a software product for managing the content you read online. It relies on GPT-3 for its conversational capabilities.</p><p>Thanks to our <a href="https://quickchat.ai/">Quickchat</a> engine (on top of GPT-3), it makes full and accurate use of the Itemsy knowledge base it was provided with, focuses on the topic at hand and cannot be maneuvered away from it:</p><p><img src="https://blog.quickchat.ai/images/first_faster.gif" alt="Avoid off-topic conversations - image" title="Avoid off-topic conversations"></p><p>Ultimately, itâ€™s all about <em>conversation</em>. It requires context, needs to be unscripted, adaptive and creative. Youâ€™re still talking to a machine but this time language feels more like natural language. ğŸ™ƒ</p><p><img src="https://blog.quickchat.ai/images/second_faster.gif" alt="Creative conversation guided by the user - image" title="Creative conversation guided by the user"></p><p>Weâ€™re ready to work with you and launch conversational chat bots for a wide range of use cases. Reach out to us at <a href="https://quickchat.ai/">quickchat.ai</a>!</p><blockquote>â€” Dominik Posmyk (@dominikposmyk) <a href="https://twitter.com/dominikposmyk/status/1309497928810213376?ref_src=twsrc%5Etfw">September 25, 2020</a></blockquote></div></section></article><div><h2>Follow the Quickchat blog for product updates, user stories and technical posts about artificial intelligence.</h2><p>
<span>Please correct your email address</span></p></div></div>]]>
            </description>
            <link>https://blog.quickchat.ai/post/knowledge-base-chat-bot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695710</guid>
            <pubDate>Tue, 06 Oct 2020 08:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fooling Around with Foveated Rendering]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24695275">thread link</a>) | @underanalyzer
<br/>
October 5, 2020 | https://www.peterstefek.me/focused-render.html | <a href="https://web.archive.org/web/*/https://www.peterstefek.me/focused-render.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 <div>
  
  <p><label>Posted on <strong>28 September 2020</strong></label></p>
<p>Shadertoy is a wonderful tool which lets users create and share a type of program called a fragment shader online. The true magic of shadertoy is its community of very talented graphics programmers who build incredible works of art despite having access to only a sliver of the traditional graphics pipeline.  </p>
<p>Some of these shaders are very computationally intensive and even in a small window, they crawl along well below their intended 60 frames per second on my old laptop. Inspired by a technique in the VR community called Foveated Rendering, I decided to try to optimize these shaders by only rendering a fully detailed image within a small focal region. As you move away from the focal point the image quality decreases.   </p>
<p>This rendering scheme is motivated by biology. It turns out your eye notices more detail in the center of your vision than in the periphery. Some VR graphics programmers realized they could take advantage of this phenomenon to increase the effective resolution of images by increasing image quality towards the center of your vision. An in depth discussion of foveated rendering can be found in the â€œprevious work sectionâ€ of this <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a>.  </p>
<p>I did not have the time, equipment or the background necessary to implement a full foveated rendering system but it was fun to fool around with the concept.  </p>
<p>Before diving into the technical details letâ€™s look at a simple shadertoy fragment shader.   </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord)<br>
{
</code></p><p><code>
    // Normalized pixel coordinates (from 0 to 1)<br>
    vec2 uv = fragCoord/iResolution.xy;
<div><pre><span></span><span>//</span> <span>Output</span> <span>the</span> <span>pixel</span> <span>coordinates</span> <span>as</span> <span>a</span> <span>color</span> <span>to</span> <span>screen</span>
<span>//</span> <span>fragColor</span> <span>is</span> <span>a</span> <span>4</span> <span>vector</span> <span>of</span> <span>the</span> <span>form</span>
<span>//</span> <span>(</span><span>red</span><span>,</span> <span>green</span><span>,</span> <span>blue</span><span>,</span> <span>transparency</span><span>)</span>
<span>fragColor</span> <span>=</span> <span>vec4</span><span>(</span><span>uv</span><span>,</span> <span>0</span><span>.</span><span>0</span><span>,</span> <span>1</span><span>.</span><span>0</span><span>);</span>
</pre></div>


</code></p><p><code>
}<br>
</code></p>
<p>This program runs once for each pixel on the screen. Each time it runs, we receive the input variable <code>fragCoord</code>. <code>fragCoord</code> is a 2d vector which contains the x and y coordinates of the pixel being drawn. We normalize those coordinates by dividing by <code>iResolution</code>, another 2d vector, which contains the width and height of the image. Finally we output a color to the screen, whose red and green channels are proportional to the x and y position of the pixel being drawn. The output of this shader looks like this:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/simple-shader-out.png" width="50%"> 
</p>
<p>Side note, why do these shader programs require their own language? Shaders are special because they run on the graphics card instead of the cpu. They are highly parallel. A helpful mental model might be imagining that each pixel is colored simultaneously. Therefore a lot of things that we take for granted in normal program languages such as liberally accessing memory and branching become much more difficult.  </p>
<p>In shadertoy shaders the bottleneck is always in the pixel rendering step. So to speed them up we want to only render a subset of the all the pixels on the screen. It seems like selectively rendering pixels should be as simple as adding a branch to the per pixel shader code that looks like:  </p>
<p><code>
void mainImage(out vec4 fragColor, in vec2 fragCoord) <br>
{<br>
</code></p><p><code>
    if (fragCoord is in the subset of pixels to render) {
      <p>
      ... do computationally intensive work 
      </p> 
    } else {
      <p>
      // return a black pixel<br>
      return vec4(0, 0, 0, 1); 
      </p> 
    } 
</code></p><p><code> 
}
</code></p>
<p>Unfortunately we cannot just use an if statement inside of the shader to save us from rendering all the pixels. Unlike normal programming languages, fragment shaders always execute both parts of each branch due to gpu limitations. So while our above code will still have to spend the sample amount of time evaluating compuationally intensive work.  </p>
<p>Luckily, it turns out that graphics drivers can selectively mark which pixels not to shade by writing their location to a special buffer called the stencil buffer. We can use this stencil buffer to only shade the subset of pixels we are interested in.</p>
<p>Once I could efficiently render a subset of the pixels, I needed to come up with a pre-generated sampling pattern. Most foveated rendering techniques seem to use a grid, but I decided to try a non uniform approach. Searching for some kind of optimal sampling pattern seemed like an interesting problem and if I was going to devote more time to this I'd explore options like <a href="https://blog.demofox.org/2018/01/30/what-the-heck-is-blue-noise/">blue noise</a>. However in the interest of time, I just decided fill in a small circle in the center and then use samples drawn from one low variance and one high variance gaussians centered at the middle of the screen to place the rest of the pixels. The final sampling pattern ended up looking like this:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/final-sample-pattern.png" width="50%"> 
</p>
<p>Next, I needed a way to fill in all the missing pixels in the final image. The approach I took was pretty simple. I started by mapping each pixel in the final screen to its nearest neighbor. Since my sampling pattern was predetermined, I could create this map beforehand and pass it into the shader as a texture. Here's what this mapping looks like:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/nearest-mapping.png" width="50%"> 
</p>
<p>And hereâ€™s a gif of the mapping applied to a <a href="https://www.shadertoy.com/view/3lsSzf">shadertoy</a> created by the extremely talented <a href="https://www.iquilezles.org/">Inigo Quilez</a>:<br>
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1-neighbor.gif"> 
</p>
<p>The above screen is 420x236 pixels and only 1/10th of those pixels are actually rendered. The focal point is directly in the center of the screen. Here's what the full resolution version looks like:</p>
<p>
  <img src="https://www.peterstefek.me/images/focused-render/original.gif"> 
</p>

<p>And here's what it looks like with only our sampling pixels:
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/sample-pixels.gif"> 
</p>
<p>One little improvement I tried was to make 4 different maps. The kth map mapped each pixel in the final image to its kth nearest sampled neighbor. I weighted each of neighbors by the inverse of their distance to the pixel in question. I actually even tried using some gradient descent based optimization to fine tune the weights but ended up seeing little improvement. It also seemed that increasing the number of maps beyond 4 did not improve things much either. Here's what the example from above looks like with weighted interpolation between the four closest neighbors of each pixel (we are still rendering only 1/10th of the total pixels):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/4-neighbors.gif"> 
</p>
<p>Finally, here's the shader with 1/5th of the total pixels rendered (as opposed to 1/10th shown above):
</p><p>
  <img src="https://www.peterstefek.me/images/focused-render/1of5pixels.gif"> 
</p>
<p>Okay that's all cool but does this technique actually increase performance? I did not do a rigerous benchmark, but <a href="https://www.shadertoy.com/view/3l23Rh">this shader</a> goes from around 20-25 fps on my plugged in laptop to 60 fps when reduced to 1/5th of the total pixels. <a href="https://www.shadertoy.com/view/Ms2SD1">Another shader</a> went from around 15 fps to 60 fps.  </p>
<p>One last side note is that this method can be used with any 3d scene and is not exclusive to shader toys. I just chose to use them because they are always bottlenecked by the pixel rendering step and they are really pretty!</p>
<p>Further questions:</p>
<ul>
<li>How do we achive better temporal stability? (the <a href="https://ai.facebook.com/blog/deepfovea-using-deep-learning-for-foveated-reconstruction-in-ar-vr">paper</a> I mentioned earlier talks about this)</li>
<li>Can we dynamically change the sampling pattern to give us better results? For example what if we sampled along edges or areas where large amounts of motion is occuring? Of course to do this we would need to compute our nearest neighbor mappings on the fly (there are actually <a href="https://www.shadertoy.com/view/XtlGDS">some</a> <a href="https://www.shadertoy.com/view/ldl3W8">shadertoys</a> which already demonstrate capability).</li>
<li>How could this scheme improve if we had access to the internals of the 3d scene? For example, could we adjust our sampling pattern based on depth information?  </li>
<li>How does this actually look in VR?  </li>
</ul>
<p>Have questions / comments / corrections?<br>
Get in touch: <a href="mailto:pstefek.dev@gmail.com">pstefek.dev@gmail.com</a>   </p>
<p>Discussion on <a href="https://news.ycombinator.com/item?id=24695275">Hacker News</a></p>
 </div>
</div></div>]]>
            </description>
            <link>https://www.peterstefek.me/focused-render.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24695275</guid>
            <pubDate>Tue, 06 Oct 2020 06:44:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[File Corruption Is Attractive]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24694017">thread link</a>) | @sergioro
<br/>
October 5, 2020 | https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/chaos1.jpg" alt="Chaos, an important theme in hermetism" loading="lazy"></p>

<p>We live in a world that is gradually and incessantly attracted by
over-rationality and order. In this article weâ€™ll burst the enchanted
bubble and embrace corruption and chaos â€” Weâ€™re going to discuss the
topic of image glitch art.</p>

<h2 id="wÌ¸hÌ¸aÌ·tÌ´Ì¶sÌ´-Ì¶aÌ´-Ì·gÌ·lÌ¸iÌ·tÌ´cÌµhÌµ">wÌ¸hÌ¸aÌ·tÌ´â€™Ì¶sÌ´ Ì¶aÌ´ Ì·gÌ·lÌ¸iÌ·tÌ´cÌµhÌµ</h2>

<p>Welcome to the land of creative destruction: image glitch art. Our story
starts with a simple idea: glitching a wallpaper to create a slideshow
of corrupted pictures.<br>
The unfortunate victim of our crime: The world (Right click <strong>&gt;</strong> View
image, while keeping the <strong>Control</strong> key pressed, to admire it in more
details while its still in its pristine form):</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map.jpg" alt="World Map, nominal case" loading="lazy"></p>

<p>Before we begin, letâ€™s attempt to define what weâ€™re trying to do: What
is glitch art?<br>
Like any art movement, words can barely express the essence behind the
meaning, they are but fleeting and nebulous. Regardless, Iâ€™ll be an
infidel and valiantly express what I think glitch art is.</p>

<p>A glitch is a perturbation, a minor malfunction, a spurious signal. In
computers, glitches are predominantly accidental events that are
undesirable and could possibly corrupt data.<br>
Glitch art started as people developed a liking for such unusual events
and the effects glitches had on the media they were perturbing. Some started
to collect these glitches that happened naturally in the wild, and others
started to intentionally appropriate the effects by manually performing them.<br>
In the art scene, some started using image processing to â€œfakeâ€ true
glitching effects.</p>

<p>Glitches happen all the time and everywhere, information is never as
durable and reliable as we might like it to be, and living in a physical
world makes it even less so. Youâ€™ve probably encountered or heard of the
effect of putting a magnet next to anything electronic that hasnâ€™t been
rugged to withstand such scenario.<br>
Thatâ€™s why many techniques have been put in place to avoid glitches,
at all layers, from the hardware storage, to the software reading
and interpreting it. Be it error correcting codes (ECC) or error detection
algorithms, they are all enemies of glitch art and the chaos we like.</p>

<p>However, this niche aesthetic is more than a fun pass-time for computer
aficionado, there is a bigger picture. Similar to painters with
brushes on a canvas, we are offered a material, an object to work with
â€” a material made of bits and formatted in a specific way.<br>
Like any object, our medium has a form and meaning, it can move, it has
a size, it can be transferred, and interpreted â€” information theory
is the field interested in this.<br>
Like any object, our medium can be subject and react to deformations,
forces, and stressors. How it flows is what the field of rheology
is interested in (not to be confused with computational rheology, the
field of fluid simulation.) The medium fluidity can be studied to answer
questions such as: is it elastic, solid, viscous, or oily, how does it
respond, within the bound of information theory, to different types of
applied forces.</p>

<p>Here are some words you may encounter and that you definitely want
to know:</p>

<ul>
  <li>
    <p>Misregistration: Whenever a physical medium misread data because of
damages caused by scratches, dirt, smudges, gamma rays, or any other
treasures the universe throws at us.</p>
  </li>
  <li>
    <p>Datamoshing, Photomosh, Imagemosh: Abusing the format of a medium,
normally compression artefacts, to create glitches. For example, video
compression often use i-frames for fixed images and p-frame for the
movement/transition of pixels on that image. <a href="https://www.reddit.com/r/datamoshing/">Removing i-frames is a
common glitching method</a>.</p>
  </li>
  <li>
    <p>Databending: An idea taken from circuit bending, bending the circuit
board of a toy to generate weird sounds. Databending is about bending
the medium into another unrelated one, reinterpreting it as something
it is not meant to be.</p>
  </li>
</ul>

<p>Let me add that glitch art is vast and fascinating, this article is but a
glimpse into this space. If youâ€™re captivated as much as I am, please take
a look at <a href="http://gli.tc/h/0nline/">gli.tc</a> and <a href="https://beyondresolution.info/">Rosa Menkmanâ€™s Beyond
Resolution</a>. Images can be pleasantly
destroyed in a great number of ways to create masterpieces.</p>

<h2 id="iÌ·mÌ·aÌ·gÌ´eÌ´-Ì¸gÌ¸lÌ´iÌ´tÌ´cÌµhÌ¸-Ì´aÌ¶rÌµtÌµ">IÌ·mÌ·aÌ·gÌ´eÌ´ Ì¸GÌ¸lÌ´iÌ´tÌ´cÌµhÌ¸ Ì´AÌ¶rÌµtÌµ</h2>

<p>Before starting letâ€™s give some advices:</p>

<ul>
  <li>Back up your precious files before corrupting them.</li>
  <li>Any glitching techniques can be combined and/or applied multiple times.</li>
  <li>Sometimes too little has no effect, and sometimes too much can destroy
the file.</li>
  <li>Itâ€™s all about trials and errors, especially errors that result in
glitches.</li>
</ul>

<h3 id="Ì·hÌ·oÌµwÌ¶-ÌµtÌ¸oÌ´-Ì¶iÌ·nÌ¶dÌ¸uÌ·cÌ¶eÌµ-Ì¶aÌ¸-Ì¶gÌ¸lÌµiÌ·tÌ¶cÌ¸hÌ´">Ì·HÌ·oÌµwÌ¶ ÌµTÌ¸oÌ´ Ì¶IÌ·nÌ¶dÌ¸uÌ·cÌ¶eÌµ Ì¶AÌ¸ Ì¶GÌ¸lÌµiÌ·tÌ¶cÌ¸hÌ´</h3>

<p>Now itâ€™s time to think about how we can apply our mischievous little
stimuli, its size, the level or layer at which itâ€™ll be applied, and
the methodological recipe weâ€™ll concoct to poison our images.</p>

<p>Glitch artist Benjamin Berg classifies glitches into 3 categories:</p>

<ul>
  <li>Incorrect Editing: Editing a file using a software that
wasnâ€™t made to edit such file. Like editing an image file as if it
was a text file.</li>
  <li>Reinterpretation aka Databending: Convert or read a file as if it was
another type of medium. Like listening to an image file as if it was
an audio file (aka sonification).</li>
  <li>Forced errors, Datamoshing, and Misregistration: A software or hardware
bug to force specific errors in the file. This can be about the
corruption of specific bytes in the file to induce glitches, or
something happening accidentally like a device turning off when saving
a file.</li>
</ul>

<p>So letâ€™s get to work!</p>

<h3 id="mÌ·aÌµsÌµhÌ¸iÌ¶nÌ¶gÌ·-Ì´tÌ¶hÌ·eÌ·-Ì·dÌ¶aÌ¸tÌµaÌ¸-Ì¸rÌ·aÌ¸nÌ¶dÌ¶oÌ¸mÌ´lÌµyÌ·">MÌ·aÌµsÌµhÌ¸iÌ¶nÌ¶gÌ· Ì´TÌ¶hÌ·eÌ· Ì·DÌ¶aÌ¸tÌµaÌ¸ Ì¸RÌ·aÌ¸nÌ¶dÌ¶oÌ¸mÌ´lÌµyÌ·</h3>

<p>The easiest, but roughest, way to glitch a file is to put on our monkey
suit and overwrite or add random bytes in our image. As you would have
guessed, this isnâ€™t very efficient but half the time it does the trick
and forces errors.</p>

<p>This technique is better suited for stronger materials like images in
raw format â€” without metadata and headers. Weâ€™ll understand why in a bit.<br>
To convert the file to raw format, open it in GIMP, select <strong>Export As</strong>,
select the file by extension, and choose the raw type. For now, it doesnâ€™t
matter if you pick pixel-ordered or planar, but weâ€™ll come back to this
choice later because itâ€™s an important one.</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/gimp_saveas_raw.jpg" alt="GIMP process to save image as raw" loading="lazy"></p>

<figure><pre><code data-lang="shell">file world_map.data
<span># world_map.data: Targa image data - Map (771-3) 771 x 259 x 1 - 1-bit alpha "\003\003\003\003\003\003\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001\001"</span></code></pre></figure>

<p>You should also note the width and height of the image as it now doesnâ€™t
contain this information anymore, and weâ€™ll need those to reopen it in
GIMP. In our case it is <code>2000x1479</code>.</p>

<p>We now proceed to hand over the file to our least favorite
staff and let them have an anger tantrum at it. So what does
it look like, letâ€™s take a look at <a href="https://www.youtube.com/watch?v=oj6NMiuU0ys">the result our monkey
did</a>:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_random_bytes.jpg" alt="World Map, monkey have been randomly mashing the
world" loading="lazy"></p>

<p>Not bad at all for something random, but we can do better.</p>

<h3 id="cÌ¸oÌ¶mÌ¸pÌ·rÌ¶eÌ·sÌ¸sÌµiÌ¸oÌ¶nÌ´-Ì¶dÌµeÌµfÌ¶oÌ¶rÌ´mÌ·aÌ¶tÌ·iÌµoÌ¸nÌ·">CÌ¸oÌ¶mÌ¸pÌ·rÌ¶eÌ·sÌ¸sÌµiÌ¸oÌ¶nÌ´ Ì¶DÌµeÌµfÌ¶oÌ¶rÌ´mÌ·aÌ¶tÌ·iÌµoÌ¸nÌ·</h3>

<p>Some medium are more malleable when squished properly and squished
in different ways. The image sheds a lot of information and only the
essence stays. Thatâ€™s a form of databending.<br>
For example, increasing the compression of JPEG images can open the path
for glitches to happen more frequently. This is a key asset, especially
when trying to create errors related to the compression parameters within
the format of the file.</p>

<figure><pre><code data-lang="shell">convert <span>-quality</span> 2 world_map.jpg world_map_compressed.jpg</code></pre></figure>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_compressed.jpg" alt="World Map, compressed to extract its
essence" loading="lazy"></p>

<p>Keep this in your toolbox to use along with other techniques.</p>

<h3 id="gÌµeÌ´tÌµtÌ¶iÌ¸nÌµgÌ·-Ì´iÌ¸nÌµtÌ·iÌµmÌ·aÌ´tÌ¸eÌ´-Ì¸wÌ¶iÌµtÌ¸hÌ¶-Ì´tÌµhÌ¸eÌ¸-Ì´fÌ·oÌ´rÌ¶mÌ¸aÌ´tÌ·">GÌµeÌ´tÌµtÌ¶iÌ¸nÌµgÌ· Ì´IÌ¸nÌµtÌ·iÌµmÌ·aÌ´tÌ¸eÌ´ Ì¸WÌ¶iÌµtÌ¸hÌ¶ Ì´TÌµhÌ¸eÌ¸ Ì´FÌ·oÌ´rÌ¶mÌ¸aÌ´tÌ·</h3>

<p>We want to corrupt in the most efficient way possible, to create
attractive chaos from the smallest change possible. To do that we have to
get intimate with the medium, to understand its deepest secrets, tickle
the image in the right places. This is what we previously referred to
as imagemoshing.</p>

<p>Thereâ€™s a panoply of image formats, and they all are special in their
own ways. However, thereâ€™s still some commonality:</p>

<ul>
  <li>Header, Footer, and Metadata: If the format contains these extra
information, be it extraneous or essential, what they represent, and
how they affect the rest of the image.</li>
  <li>Compression: The format can either be compressed or not. When it is
compressed, there can be extra bits of information to help other software
uncompress the image data.</li>
  <li>How the data is laid out: Usually, the image color information is
decomposed into its components such as HSL, RGB, or others. These
components then need to be represented in the image data, either in
an interleaved or planar manner. Planar refers to writing components
independently in the data (<em>ex:</em> all R, then all G, then all B),
while interleaved refers to having them joined non-contiguously in an
alternate sequence (<em>ex:</em> RGB, then RGB, then RGB..).</li>
</ul>

<p>Manipulating these to our advantage can lead to wonderful glitches. For
example, in our previous raw image example â€” an image bare of header,
footer, and without compression â€” the pixels were interleaved which
gave rise to the effect weâ€™ve seen, namely shifts and changes in some
colors. Having them in planar form wouldâ€™ve led to different glitches
in separate color channels.</p>

<h3 id="rÌµeÌ·iÌ·nÌ´tÌ¶eÌ·rÌ¶pÌ¸rÌ´eÌ¸tÌ¸aÌ·tÌ¶iÌ·oÌµnÌ´-ÌµaÌ¸sÌµ-ÌµrÌ¸iÌ·cÌµhÌ¸-Ì¸tÌ·eÌµxÌµtÌ´-Ì´aÌ´kÌ·aÌ¸-Ì·wÌ¶oÌ´rÌµdÌ´pÌ´aÌ¸dÌµ-Ì·eÌµfÌ¸fÌ´eÌ¶cÌ¶tÌ¶">RÌµeÌ·iÌ·nÌ´tÌ¶eÌ·rÌ¶pÌ¸rÌ´eÌ¸tÌ¸aÌ·tÌ¶iÌ·oÌµnÌ´ ÌµAÌ¸sÌµ ÌµRÌ¸iÌ·cÌµhÌ¸ Ì¸TÌ·eÌµxÌµtÌ´ Ì´AÌ´KÌ·AÌ¸ Ì·WÌ¶oÌ´rÌµdÌ´PÌ´aÌ¸dÌµ Ì·EÌµfÌ¸fÌ´eÌ¶cÌ¶tÌ¶</h3>

<p>Letâ€™s give this a try with the well-known WordPad effect, which is about
databending an image into rich text: opening the image in WordPad and
saving it.<br>
Keep in mind that this only works with raw images as itâ€™s highly
destructive and otherwise could break fragile key info in the header
and footer. So letâ€™s reuse our interleaved raw image of earlier but also
get a planar one.</p>

<p>This is our results for interleaved:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_wordpad.interleaved.corrupt.jpg" alt="World Map, WordPad effect interleaved" loading="lazy"></p>

<p>And for planar:</p>

<p><img src="https://venam.nixers.net/blog/assets/glitch_art/world_map_wordpad.planar.corrupt.jpg" alt="World Map, WordPad effect planar" loading="lazy"></p>

<p>Technically, what happens is that during the bending and interpretations
as rich text, some bytes are inserted in some â€¦</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html">https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html</a></em></p>]]>
            </description>
            <link>https://venam.nixers.net/blog/programming/2020/10/05/corruption-at-the-core.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24694017</guid>
            <pubDate>Tue, 06 Oct 2020 01:43:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Donâ€™t Find Mentors. Find Your Future Self]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24693763">thread link</a>) | @jdcampolargo
<br/>
October 5, 2020 | https://www.juandavidcampolargo.com/blog/future-self | <a href="https://web.archive.org/web/*/https://www.juandavidcampolargo.com/blog/future-self">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1601739309102" id="item-5f789898afa8642a86474931"><div><div><div data-block-type="2" id="block-ba447757312844ef3468"><div><p>Back in 2018, I was fifteen years old, and I wanted to do something over the summer. I could get a job, work on my businesses, sit around, watch Netflix, or work for free at tech startups.&nbsp;</p><p>I chose the latter.</p><p>Why would I work for free in a startup? It wasnâ€™t for free; I had to pay for the train tickets and food. I didnâ€™t care. I knew that being out there meeting founders and investors would be the best way to learn.&nbsp;</p><p>I wanted to be involved in the startup world by creating, developing, and investing in them. I believe thatâ€™s the way how we can change the world and have a positive impact.&nbsp;</p><p>But how in the world would I find those startups?</p><p>I sent 500+ emails, called companies, asked family friends, and did everything I could, but I got annoyed. So I was like, â€œScrew it, Iâ€™m just going to go and ask them.â€</p><p>I went to this startup incubator called Techstars at 1871 and asked if they were hiring. And that I was willing to work for free or â€œvolunteer.â€</p><p>At first, the founders looked at me like, â€œKid, how old even are you?â€ Most founders looked the other way, but two guys were like, â€œDamn, letâ€™s find something for this kid to do.â€</p><p>And thatâ€™s how one of my best summers started.</p><p>The founders may have thought a fifteen-year-old wonâ€™t be able to do much, but I literally told them, â€œIâ€™m willing to do anything, I just want to learn and spend as much time as possible at the incubator.â€ It felt like I was learning by osmosis.&nbsp;&nbsp;</p><p>I would go with the founders to meetings with investors and mentors and take notes, find venture capitalists interested in investing, work on hardware, and anything they told me to do.&nbsp;</p><p>I worked with three startups that developed an AI fitness assistant, solar drones, and a real estate crowdfunding site.&nbsp;</p><p>That summer showed me the world of startups. I met people like the governor, billionaires, and overall people who were heavily involved in the startup world.&nbsp;</p><p>I also experienced the startup world, which Iâ€™m sure will pay off in the future.&nbsp;</p><p>But most importantly, I met Paul, the founder who gave me the opportunity.&nbsp;</p><p>I always kept him posted on my progress in my projects and would ask how his company was doing. And Thanksgiving, Christmas, and Happy New Year messages as well.&nbsp;</p><p>Well, it turns out that Paul studied in the same college and did the same major. Iâ€™ve talked to him multiple times in the last few weeks and it reminded me of the <strong>importance of having people who were once where you are.</strong></p><p>Some people called people like Paul â€œmentors,â€ but that word is misleading because 1) itâ€™s overused and over-hyped 2) itâ€™s transactional and self-centered.&nbsp;</p><p>How do I call people like Paul? I call them, <strong>â€œMy Future Selves.â€</strong></p><p>They often can give that little push you need. And you get to cheat because you get to talk to your future self. Whatâ€™s even better is that you can always do things differently and learn from their mistakes.&nbsp;</p><p>Studying engineering isnâ€™t the easiest thing in the world and when you bomb a test, you can feel like â€œYou donâ€™t have what it takes.â€ My first chemistry exam? Hmmm. One to forget. I like to do as best as I can and not doing as expected frustrates me, especially when I need to get a good GPA to transfer to the engineering school.&nbsp;</p><p>I felt like I was the only one, but as I talked to â€œMy Future Selfâ€ or Paul, I realized I wasnâ€™t the only one and he too didnâ€™t do great on his first chemistry exam. But he improved and could transfer to the engineering school.&nbsp;</p><p>He advised me on how to approach studying and how to approach the test and my grades have improved.&nbsp;</p><p>Sometimes, you can also lose sight of the big picture of what you want. Future selves remind you to keep focused not by scolding you but by asking you simple questions like, â€œWhat are your future plans after college?â€ or â€œDo you like what youâ€™re studying?â€</p><p>In my case, Paul knows Iâ€™m into startups and <a href="https://www.juandavidcampolargo.com/blog/ambition" target="_blank">eating the world</a>, so he helps me with choosing a path that aligns with my interests and with my goals.&nbsp;</p><p>Looking back, that was not a normal thing for a teen to do. Yes, you can say it, â€œI was weird.â€&nbsp;</p><p>Well, not really. I knew <strong>who</strong> I was and <strong>where</strong> I wanted to go. Thatâ€™s how going up to startup founders asking for a job could become your summer.&nbsp;</p><h2>How To Find Your Future Self</h2><p>If I hadnâ€™t talked to Paul a few times since college started, Iâ€™d honestly be down and not very excited about the possibilities. <strong>Future selves can you show a path that gets you excited to work harder and more ambitiously.&nbsp;</strong></p><p>If youâ€™re interested in finding a possible future self. Iâ€™ve learned a few lessons that can be helpful.&nbsp;</p><p><strong><em>Avoid being artificial. </em></strong>Weâ€™ve all heard the talk, â€œGet a mentor and blah blah blah.â€ Sure, but that canâ€™t the only reason. You should be genuine. And please please, donâ€™t be asking people to be your mentor.&nbsp;</p><p>How can you be more genuine?</p><ul data-rte-list="default"><li><p>Make yourself useful to them</p></li><li><p>Get a job or internship at that personâ€™s company or lab</p></li><li><p>Ask unique and interesting questions</p></li><li><p>Just DM or email them</p></li></ul><p><strong><em>Understand their motivations. </em></strong>Keep this question in mind, â€œWhy would someone want to mentor you?â€</p><p>It usually happens when a high-potential person approaches them, and they can help him/her reach that potential.&nbsp; And if they can see their advice pays off 10x in you. If your future self tells you to walk 5 steps, they want to see you walk 50 steps.&nbsp;&nbsp;</p><p><strong><em>Donâ€™t find mentors. </em></strong>This one will be the hardest to understand, but the most powerful. I donâ€™t ask people, â€œDo you want to be my mentor?â€</p><p>Most people will say â€œNo.â€ Instead, the way you find mentors or future selves is by:</p><p>1) Finding people who are where you want to be.&nbsp;</p><p>2) Asking great questions and becoming genuinely interested in their work, and finally,&nbsp;</p><p>3) Keeping in contact with them and asking questions and/or advice when you need it. Or if you find something useful for them, this is when you help them.</p><p>Iâ€™m grateful to Paul and many of my other future selves because they allow me to learn from their mistakes, pick a unique path for me, and give you the little push and fresh perspective when you most need it.&nbsp;</p><p>Thank you, Paul, and thank you to all my future selves!</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.juandavidcampolargo.com/blog/future-self</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693763</guid>
            <pubDate>Tue, 06 Oct 2020 00:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Oswald Spengler â€“ an intellectual life]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24693655">thread link</a>) | @objections
<br/>
October 5, 2020 | https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/ | <a href="https://web.archive.org/web/*/https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="9549bc7" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:500}" data-widget_type="theme-post-content.default">
				<div>
			
<p>Oswald Spengler was one of the most profound pessimists of modern times but at a glance, his legacy appears to have collected decades of dust since his early death in 1936.&nbsp;Considered unessential by historians and troublesome by philosophers, he nonetheless exerted an extraordinary influence over many powerful figures throughout the twentieth century. Wittgenstein said he was one of his chief inspirations; the Jungian theorist Joseph Campbell claimed Spenglerâ€™s work was his biggest influence; the philosopher Martin Heidegger was profoundly affected by Spenglerâ€™s thinking; and former Secretary of State, Henry Kissinger, wrote favourably about him in his doctoral thesis â€˜The Meaning of Historyâ€™. Kissinger gifted a one-volume edition of Spenglerâ€™s The Decline of the West to President Nixon when he served in his administration to â€˜emphasise the manifestation of eventsâ€™. But who was this man whose thought has shaped modern philosophy and the perception of some of our top policy gurus, and what did he believe?&nbsp;</p>



<p>Oswald Spengler was born in the Duchy of Brunswick in 1880 to Protestant parents. His fatherâ€™s family were traditionally mining engineers and metallurgical inspectors while his mother, Pauline, from whom Spengler received his irascible temperament, hailed from an artistically inclined lineage of ballet dancers and bohemians. Unlike his ancestors, his father worked as a senior postal secretary and severely chastised any hint of intellectualism in his children, a repulsion that must have conditioned the young Spengler to distrust celebrated thinkers later in his life. It was this inherited mixture of two divergent tendencies â€“ engineering and science with bohemianism and the arts â€“ that afforded Spengler a unique intellectual vantage and prepared him to proffer his special perspective to his readers in the future.&nbsp;</p>



<p>After excelling in Greek, Latin, Mathematics and the Sciences at school, he attended the universities of Munich, Berlin and Halle. In 1903, two years after his fatherâ€™s death, he initially failed to obtain his PhD but managed to pass a year later via an oral equivalent of the examination. He then qualified as a schoolmaster and led a relatively uneventful life teaching in Saarbrucken, Dusseldorf and Hamburg. When his mother died in 1910, he returned to Munich where he lived on his modest inheritance as a private scholar. It is said he owned no books and suffered from great loneliness rather like a latter-day Nietzsche. But, like Nietzsche, these years proved to be formative. It was around this time that he conceived of writing a book that would challenge common preconceptions of history and its meaning. He began work on&nbsp;<em>The Decline of the West&nbsp;</em>in 1911 and completed a first draft in 1914, but due to the war, he had to wait until 1918 for it to be published. Burdened with a weak heart, he was exempted from military service yet this didnâ€™t mean he had an easy time. With much of his inheritance invested abroad, he was forced to persist in a state of serious poverty until the publication of his work.&nbsp;</p>



<p>When it came out, its success made him an instant celebrity and he finally gained the respect and reputation his talents deserved. His explanation of the war as a â€˜historical change of phaseâ€™ which was â€˜preordained for Germany hundreds of years agoâ€™ consoled Germans who were being blamed in the European press for gratuitously starting the greatest military catastrophe of their time. In the early days of the Weimar Republic, he called himself a Socialist, but not a socialist of any obvious orthodoxy. He rejected Marx, whom he saw as the chief critic of the English capitalism he  defined as â€˜Get rich, so you donâ€™t have to work anymoreâ€™. He believed that the true source of German socialism was not Marx so much as Frederick William I. To succinctly explicate his brand of Prussian Socialism he used the phrase â€˜Do your duty, workâ€™.&nbsp;</p>



<p>His Prussian subgenre of Socialism naturally appealed to National Socialists and he became an inspirational figure to some early believers of Nazism. His criticism of the Weimar Republic, of Marxism, pacifism and democracy intellectually aided the Nazis in their ideological advancement to the top of German politics, but once they were in power Spengler famously refused to â€˜Heil Hitlerâ€™ and was thereafter shunned. He occupied his concluding years by collecting thousands of books and exotic primitive weapons, by reading the comedies of Moliere and Shakespeare and listening to the haunting quartets of his hero, Beethoven. He died three weeks before his fifty-sixth birthday of a sudden heart attack on 8<sup>th</sup>&nbsp;May, exactly nine years before the bloody fall of the Third Reich.</p>



<p>Like Kant, who rarely left his place of birth and was famously not convivial, Spengler lived an externally anodyne existence while his mental interior shone incandescently with original ideas. He worked in an age of Prussian militarism and German nationalism, of extraordinary revelations and dire events, when the tumultuous tide of uncontrollable circumstances invoked an apocalyptic atmosphere. His thinking therefore can be seen as an illuminating response to the blindness of his time. His magnum opus,&nbsp;<em>The Decline of the West</em>, was a rejection of Eurocentric versions of history and a repudiation of traditional structures of scholarship. He deemed the historical phases of â€˜classical, medieval and modernâ€™ as inaccurate, random and unhelpful, as a cracked encasement of human activity. He did not want to appraise the past chronologically and solely link cause to effect. He wanted to examine what was common and unique to cultures across the world, what the nature of mass existence is, and how humans see themselves through history, if at all. He called this new approach a â€˜Copernican overturningâ€™. For the study of history, it is as seminal a moment as the Newtonâ€™s shift in Physics or Descartesâ€™s dramatic declaration of â€˜Cogito ergo sumâ€™ in Western Philosophy. This drastic development he hoped would forever transform humanityâ€™s elemental understanding of history. However, his obscurity seems to have precluded his influence on the public and his theories remain widely unread outside the insular circles of academia.&nbsp;Perhaps the pessimism he espoused makes him appear intellectually unprofitable and therefore unattractive to the merely curious reader.&nbsp;</p>



<p>In&nbsp;<em>The Decline of the West</em>, Spenglerâ€™s â€˜Copernican overturningâ€™ led him to see past eras as loose biographies of isolated cultures. He applied the seasonal system of spring, summer, autumn and winter to the evolution and undoing of every prosperous society. They rise, flourish, wither and vanish like distinct wild flowers on a windswept heath. Spring naturally represents an awakening when the force of cultural expression is so strong that it sets a precedent for centuries thereafter. Summer signifies a stage of pleasing artistic production and clever imitations when creation becomes a personal activity. Autumn is when the soul of a culture depicts its happiness and attempts to return to nature, and winter means the solidifying of culture into a civilisation, when great art is mostly extinguished and the creative energy that drove a culture on is almost entirely spent.&nbsp;</p>



<p>Although there have been innumerable births of culture, Spengler argued only eight â€˜high culturesâ€™ have existed: the Babylonian, Egyptian, Indian, Sino-Japanese, Mesoamerican, Classical (Greek-Roman), Magian (or Arabian) and our own, the Faustian. Classical man was more concerned by the near and the present, whereas we children of the Faustian age are forever looking into infinity, searching for the ultimate end of our speculative powers. Sadly, he claims that the Faustian age is the most tragic because although we enjoy unprecedented technological discoveries and rapidly strive and create, we know deep down that our goals will always elude us and that our efforts will eventually be proven futile.&nbsp; To add to the dark tone he used to describe our time, he believed our culture was now in its winter phase. Lawrence Durrell opened his Alexandrian Quartet with the beautiful line â€˜in the midst of winter you feel the inventions of springâ€™. In Spengler, this â€˜feelingâ€™ is a remembrance rather than an anticipation. The time of birth and rejuvenation is forever finished, metaphorically speaking. In this present phase, Spenglerâ€™s prophesising limns an authoritative ruler or â€˜new emperorâ€™ who emerges in response to the disintegration of culture. He called this the Caesarian age. Many Spenglerian commentators have identified the advent of Hitler and Nazism as an example of a Caesarian instance in cultural history and it would be an easy feat to find comparisons in politics today who fit the description of attributes Spengler so eerily expatiates.&nbsp;</p>



<p>Spenglerâ€™s approach to the philosophy of history â€“ to how we see history and what meaning we can derive from an appraisal of past events â€“ is informed by a myriad of unorthodox intellectual disciplines. Morphology, the study of the form and structure of organisms and their specific structural features, determines his perception of eras and their attributes. Mathematics is used to reveal the rational divergence of different cultures and to prove the sociocultural relativism of subjects that supposedly seek certainty. Art, economics, politics, literature and architecture are each discussed with a rare authority, but his factual errors and historical inaccuracies have galvanised his critics and stunted his appeal. However, Spenglerâ€™s holistic discernments distinguishes him from other philosophers of history and raises his status to a laudable level of exceptional intellectual skill. His analytical insight penetrates more deeply and disturbingly than Toynbee and his Nietzschean prose and encyclopaedically varied knowledge rewards his readers with a weird and widened perspective. Like most great thinkers, it is not the bleak conclusions he draws which are â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/">https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/</a></em></p>]]>
            </description>
            <link>https://engelsbergideas.com/portraits/oswald-spengler-an-intellectual-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693655</guid>
            <pubDate>Tue, 06 Oct 2020 00:30:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Probability and Statistics with Applications to Computing [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24693589">thread link</a>) | @ArtWomb
<br/>
October 5, 2020 | https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf | <a href="https://web.archive.org/web/*/https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><i d]g(*hÂªÂ®jcÅ¡Â»â€¢ÃŸÃ•]Â¿Â¿}[xÃ¯^Ã®r)Å f3@="Ã¯JÂ§â€œcccâ€“/_^RRbsâ€”Â¬mÃˆ" ;Ã„Ã§ÃeÃ¡Ãš?Â§â€¹â‚¬Ã‘="" p8]xÂ±<Ã…<Â­}ÃŸÃ´â€¡Ã™â€¦â€¹!kim2Å â€¹â€¹m1cÃ†Â¡â€“â€ºÃÂ·yyybÂ¡'ï¿½ï¿½aÃ€â€¡kdÂ¡8Ã»Ã»Â£â€¡="" Ã¶Ã˜Â½+ÃªÃ¦ï¿½dÃ´fÃ”Ã :qÃ euÃŠju;~Ã—Â¨)?l7Â¥="" Ã‚="" Ã–Â®[bcÂ£vciqÃ²ÃŠ!Ã¡2ÃœÃ‘ÃƒrÃ¸="" ÃŒ|Ã±ÃÃª`â€°-Â»ï¿½8&7Å¾Â¢ÃƒÃ½="" Ã½Â­Â¼â€_Ã¶Ã‡Å’)Å Ã‡3â„¢.dÂ¢Ã§lÂ¥&nÅ“xÃ»Ã¶Ã­'oÅ¾Ëœo)Â­ÃŠï¿½â€œ?yÃ‰Å vw-jÃ¾b7rï¿½Ã…Â»s="" â€ ï¿½Ã§h<bÂ¦iÃ¬Â²Ã“â€a-Ã¥pÃ‹mÃ‰Â¬y-g="" "Ã¦Â³gÃ6nÃœhÂ¡ï¿½\]Â°xÃÃ½Ãºzï¿½]gÃ³â€¢â€ ="" mÃŠ`4ÃÃ®â€¡qp;iÃ¬1â„¢Ã¬Ã´Å¸Ã¿|Ã¥Ã¤Ã¤Ã‘Â«wÂ¯#f,yÂ²Ã¤Ã¢Ã…â€¹.mqÃ•Â´Ë†ï¿½Â£`â€¹Ã½ÃƒÅ½Ã°Â¢ÃŸ7aÃ¯Ã‹Ã™)Ã‘sÃ”Å’hÅ½,ÃšxÃ•Ã–Ã²(jÂ®aÂ¬jÃ‹kÂ²yÅ“uÃ«Ã–Ã™bÃÂ¡c-7Å¸oÃ³Ã³Ã³Ã·Ã¬Ã™3yÃ²Ã¤&mÅ¡Ã¸Ã¸xâ€œÃ‰d"Ã‘ï¿½nwâ€¹qÃ©Å’Ã¡ÃƒÂ¼Â²â€“nÃ›~Ã°@ÃŒÃ™Ã“ÃŠâ€¹Ã§Ã•Â¹Ã•9Ã”'ï¿½+Ã¶Ã®Å½=""><b nÂ¸1Â Â±ÃœÂ®3Ã”%Ã•e!ï¿½jÂ¡Â«Å’ÃÂ±ï¿½Ã†cvâ€°ynglbpaï¿½kÂ¯â€Â«cÃ²,Â´Ã¥ï¿½Â£(Å ÃœÃŠ"Ã^Â¯iÃ®2Â¢^?Ã¥â€˜Ã—ueâ€°ï¿½mâ€Ã‰Ã^ÃsÃ?Â¿}Ã‡vÃ¸â€“.Ëœ_`6zÃÃ‘#ÃÂ¶ÃoÂ°Ã®Å½;Ã®pÂ©d^Â¯Ã´Â«eÃ…\Ã‹Â¶Ã£Ã›ÃÅ¸|Ã½Â±uÃ±&Ã—â„¢Ã‹b9%â€¦n)Ã˜Ã¤zÂµ(Â¶Â¼'Â§Â oÃ½ÃšÃ¢Ã­wÂ¬Å¾k="" Ã¼auÂ¸â€°;Ã¯pvâ€â€œï¿½@&Ã«.â€˜tâ€°Âº="" â€¦Â°Ã±ÃÃ¯Â¬xÂ±Ã¢\Ã¥Â¤eÃ­Å’="" nÃ¼ï¿½?Ã¾xeâ€™Ã%buÃ”Â¥Å½Â°j+râ€¦Â¤b_â€ºÃ€ÃœuÃ˜.wÃªâ€°Ë†sÃ¦Ãimzua@jÃ‘ÃˆÅ“Â¡Å½Ãª.c!ËœÃœï¿½Ã›Ã›â€¡Æ’Ãº=""><s â€˜hÂªÃ·*^Ã­Ã•ÂªjÅ¾i[jÂ¯Å¸!Â±Â¼Å¡gyÃ¤1<`Ã€Ã•="" Ãœ8(Â²gp!z$_ÃµÃ´Å’Ã»kÃâ€uqï¿½Ã Ã¢tâ€¡Ã‘h6:p<â€°Ã£Ã—Ã®Å’ï¿½Ã€Ã$bxÃ€%ÂµÂ¨Ëœâ€˜}h="" !="" lâ€˜"â€â€¡b!qÃ‚hË†@b"ï¿½pÂ¼zeâ€šâ€˜Å’â€¦ic"ï¿½(Âµ="â„¢41" Â¡Â¤!Â½Å lÃ€ÃˆÃŒÂ«fip7Ã±Â¼ÃªÃ¾Â¿Ã»Ã‰â€¡Â½sÃ¬Å¾Å¾ï¿½Â kÃ¡uï¿½Â¤Ã‘Â¼j9Ã”3Ã®â€°â€“Ã¯Ã¼Ã¿Â¥="" wÃ¼Â¤Ã°Ãº+nÅ¸fÃ­Ã•cÃ.Ã·Å“Ã·Ã¡Ã’â€¢â€“sâ€šhhÂ¯râ€šÃuiâ€™x5â€“4Â©Â¼ÃŠÂ«ï¿½&{Â¯="" bÃšÃ˜â„¢eÃ¶Â«ï¿½â€“Â®Ã²Â®6<uÂºqÂµÃ½v="" Ã¯â€°oÃˆcoÅ“uoÃ­Â·Ã¨s="" â€°Ã§u&Ã»ï¿½oï¿½Ã´ÃªËœwÅ¡]tc4gËœwiiÂ´â€™gzâ€¢'Ã±ÃªÂ±ï¿½mÃ¯="" â€¹Å¸:fbÂªÃ°*="" ;kÂ¯Ã²Â¬Â½ÃŠË†?Ã@Å¡Â¾vÃ§Ã¹Ã³*d^sÅ½iâ€˜fÃªÃ uÂ¸â„¢ÃÂ«ÃªÃ”Ã•Â«Æ’sxvÂ®x5ï¿½<Ã²ÃˆcÂ¸ÃˆÃ’"Ãâ€¹Ã¼Ãˆâ€Âª\Ã¡Ã¥pÃ½0Ã¦y0Ã£e~Â¤|&Â®]Æ’Å“.ÂªÃ“Ã»Â¤ï¿½Ã¨â€ºa%â€ hÃ°â€°="" Å¡d!Â¨_<â€fÆ’Ã»â„¢="" Ãeâ„¢a`l%Â¤:iÃ‚qÃ¦hâ€™Ã†h\rÃ±â€°Å’bÂ¬Å½&â€Ã‡â€œÃ†hhliÃÂ«Ãâ„¢3Ã¢kÃ»Â¾5<Â½j}ÂºÂ©Ã«ï¿½Â»Ã¤knÃ¹}qÃ¥Ã»i="" Â¯ÃÂµÅ¾uÃ|ÃŸÂ·_Ã¡="" iÆ’Â©Â¡Â¼'ï¿½ï¿½^Ã¥="" Ã¦uâ€ qÂ¤Â©ÃÂ«bÃgÃ¯â€ºÃ–8Ã±Ã…dkÃ¤gÃÃªâ‚¬ï¿½^Â½urÃ¥%ï¿½'[-8t8!="" fâ‚¬,Â¯Â¾Ã¿iÃ¥qï¿½Ã‡oÃ­Â²iÂ¯ÂªÃ¼Ã©hrÃ¤Ã•pÂ¯*Å“dzuÃc%Ã·tÃºï¿½ÃŸÃµk^Â­"ï¿½h0jÃªubÅ¡*Â«Ã Â¾kÅ¸Â¬Â°Ã´Ã®ï¿½Ã…â€â€Ã„Ã³ÂªÅ $sÂ¯â€™â€h7dÃ©Â¿ï¿½â€™x^{dÃ®uÂ±Âºaj^="" Â½Å o2Ã‰#ï¿½<Ã²Ã8Æ’Ã‰Ã›_pj="" n="" â€¹Â¥,jÂªÃ¥Â ="CÃ«Ã¥" Ã…="" â€°Â¨Ã—dq#Ã²Â¹zâ€¡p="Ã•Â«Â¼Dâ€šÃº3#Â¡ÃŠk!â€™HWaÂ²Ã§Ã’Ãâ€&nbsp;Å’Ãº{6!" Â¬yÃŒ.mË†2Â¦Ã©aï¿½?ÂªÃ±*Â«Ã±Â¼j}Â¶Â¥Ã­wÂºgÃ™Â­Â¿ÂºpÂ¾Â¬â‚¬Ã²*=""><i â€¹b#Ã…Ã„(cÅ’##eÆ’*mÃ¼â€œrÅ â€°â€¹txÆ’Æ’Ã @1Â¸Ãœâ€¢bÃ©Ã®Ã‰Ã¥Ã“Ã ÃºÃ Â¸â€¹iÂ§rÅ’Â¤Ã pmÃ†]Å â„¢Ãšx="" â€¡Ã®-&ï¿½Â©="" bâ€19[khyâ€3Æ’Â§Ã‡\â€¹6â€"'?Å’â€œtÃ Â´1%â€¢â€“Ã¼ejq9â€ºkï¿½rÂ¬Æ’#="" Ã…x="" Å½Â¯Â´98Ã—*="" Â¥x="Ã—Ã‚fb&quot;#EÃŸÂ¥" Ã³jÂ¸ÃŸÃ‚@â‚¬Ã20gÃŒ5Å Ã€Ã‚â€¹â€°Â´Ã‡k&â€ [Â¶Ã¢Â§9p="" m8le="v]ÃÂ­â‚¬$=Ë†Ã¶+Â¤" =""><i ÃŠn<yÂ¾"+xÃ’o%bwï¿½oÂ v!Ã¦Ã‡="" <aÃ«Ã‚Ã“jâ€¡ï¿½Â´â€¦'Â `xz(hÅ¾,="" bÃ”a{Ã±Â¬gâ€¡Â¡â€°Â£:="" ovâ€°ÃŒcoÂºÂ´Ã—ofâ€¡!(â€ºÃxzâ‚¬ÂµÂµÃjkkÃ½Ã½Ã½Â±.Ã¬gÂ£iÃ“ffÂ£Ã¡Ã§Å¸opÂ¨ÃšpzÂ¸pÂ¡Ã‰h"Å¸ï¿½`ÃƒÃÃ‘Â±Â Â°Ã Ã¾Æ’Ã»Â¯xï¿½Â²Ã¡="" Â®Ãcï¿½jkÅ¸<~Â¼lÃ®Â¤Ã”0u=""><i Â¼,<-;l]?hï¿½="xÃ™â€°'Â¥`Ãï¿½Â¦Ã½â€ºÃºÆ’vÃ“7Â±TÅ¾?;ÂºMb7wE62" gâ€Ã”j<bâ€”.kwgÂº+ÃšÃºÂ©ÃœcxÃšxÃ§Ã¸0eÃ§="" c@1ÃªËœ4â€¢Ã©oÃŠÃ°3vÃ²Ã•Â·Ã±sÃ…Â´â€Ã·â€˜="" rd&Ë†zhï¿½pf9ï¿½eÃ€5ÃŠâ€œÅ¡&Ã¬)Â¢â‚¬k@yp[qhÂ¤="" Ãœâ€¦â€¹Ã¬ÃÃ‡f4Â°ikahh#&Â¶*Ã„_Ã€$cpÃ¥!Ã•Â®hÃ˜Ã‚}Ë†Ã–="" zÂ¾ÃœsÃ¯Â spd;Â¨Ã‚l=""><i Ã‚'@ÃˆÃ¢Â°jiÃ°$*Ë†_Â³zÃ¡pÃ½Ã›aâ€šÃ¯Ã€â€œj0]Ãâ€œÂ ="" cuwaâ€Â¢Â Â²="" Ã¥r4ujÃŸÂ§ÂªÃ„sjÃ·mÃ°Â¤(Ã˜u<5jâ‚¬Â½ÃÃ´4Ã€ï¿½eÃ¼Ã½fÃ²$="Â¬-Ã±Ã·7" Å¾ÃÂ®ÃÃœÃ¡jÃµÂ»â€¢.Ã†2ÃœÃŒxÃ£uÃ¬|yÂ£Â¦ÃªÂ¹Ã¶Ã£xzÃ³<Ã»Â¡Ã›4Ãˆ;5ÃŠÃ·Å¾fwÃŠâ‚¬gjÃ€,cÃ¢d#â€¡5<â€¡e\Â·Ã¾&.Ã–Ã¼â„¢Â¦z3="" y3eÂ¯Ã±Â§Ã‰&&lÃ¡jojÃ›;Â±mÃ½Â¹Ãƒâ€ hÆ’Ã |Â²=""><i Ã¢Ã¯a5Ãâ€œÂ¢="" ÃÃ™Ã™Ã»Â¡i:aaaÂ¹Â¹Â¹Ã¿f<uÅ’Â¢Ãœ`ÂºË†Â§â€fyaâ€¢xjÂ¦="" â€šÃ(xwwwÃ©Ã’Â¥Ã¥Ã‹â€”c3Â»Ã»Ã»Ã¸Ã¡#Â­â€š]Ã€â€œÂ¨`Ã—Ã±dÃˆxr%Ã¢Å¡Ã…il0Ã¥oâ€”Ã°â€Ã’Ã¡iuï¿½pâ€¦$<Â¿eÃ¼2x=""><s kâ„¢-sÃ²Å¡Ã¦s\Ã¿h%=""><i Æ’Æ’â€¦="" Â¨="" Ë†fÃ„Æ’Ã«Å¡Ã¡Ã¿nÃ«1Å¡$â€¢Ã¡,â€”ÃÃÅ’â€¡Ã€'Å¸ntÃœÃ‹Ã ="" ÃƒÂ´3<Ã¢Ã¹Ë†Â²Ã—ï¿½ï¿½Â¶Ã‚Ë†ÂºÃ—#â‚¬e0â€™â€™ï¿½cp0â€¢Ã±="" ËœÂ¬Â»Ã`="Ã†`+Å’Ã€v3Fï¿½Â«Ã0E|Ã·2Â¸Ã`ÃŒÃ°Ã®Ã”Ã¹HQÃ²98â‚¬â€¦~Ã˜v`Â¦Ã­Ã‚Ã€nÂ³Â­Ã¬Ã›Â¼k4UÃ¼kÂ¤wÃ¡Â³Å’â€¦ï¿½Â·Ã€Ã°Â®Â¹"><i><s Å’Â¦Ãœ7Ã‹Ãˆsï¿½\Â â€“xÅ Âµ(`="" Ãï¿½Ã¿Ã¨zÃ°Ãº~Ã¬Ã¿tz~tÃ™Ã‹cï¿½Â¢Â ÂºÅ“j%ï¿½Ã¹Â¾Ã…â€¦Å’â€¹*ï¿½ÃˆrÃ²â€@Ë†|)pÃ¹Ã€ÃœÃÃ–4Ã­Ãˆâ€˜#.Å“<y2Â¿ÃŒÃˆÃˆ0="" ÃƒwÂ¿ÃÃ½Â­aÂ¢="" Ã˜="" Âª="" 0="" [ï¿½o@vrâ€˜Ã•jÃÂ£ï¿½â€“Â«â€™Ã›Ã¼Å¾Â´Ã±Â³="" Ã‡ï¿½(Â¸ï¿½="" cÃ†Ã¥e{ÂµÃ€dfbÃ¿r="" sË†Â¥Ã¡Ã…="" â€š="" â€”="" .0Ã„rÅ Â°}Â²;â€“Â¬Â¶â€¦a$`Ã˜Â°j="" ÃœÃ‘y{â„¢Âª[zÂ·="" -yqÃ“pË†Ã—Ã‹â€ rcl*ovÅ½Â£Â´;vÂ®hbÂ¨rÂ¹ÃÃÃ‰Ã‰yÂ»vÃ­Ã”Â©sgÃÅ¡ÂµcÃ‡Ã“4ubÂ ÃŠÃ·Ã‚b]2â€°j`Â¢Â¡ro,xpÃ¥â€¢w~Ã¶Ã™gÂ¹Â¹Â¹gâ€¢Ã·Ã²Â§:dÃ¼#ÃšÂ¦mâ€ºÂ¶mÃ›nÃšÂ´Ã©<{Ã»Ã•<Ã˜Ã³Ã¸Ã¿yyyÃ¼Ã·Âª=""><b><b ï¿½bÃ‰Ã¶vï¿½jÂ§Ã…ÂºdÃ€ï¿½8Ã‡gÃ….k\â€ Â¨â€¡Å’="" =""><i Â¬Å½qÃ”Â¥wÂ´Ã©:â€¡Ãµï¿½Æ’Ã³Ã²_fÃ§:Â§uÃ’Â¶Å¡Âª7Â½Â¾Ã¢frÃ¸Â¹Ã—eÃ¸Å Â«Ã¨5Ã±!_Â¢â€˜q<dÃ±Ã¡eÃ…=""><s â€Ã»Â·tb!aÃˆÃ§Ã¹*`lze;â€¹Ã—5Ã‘rÆ’Ã°Â¬ÂºÃÃŒzÃ’Ã Â¸gxlÂ¼Ã€diyÃ»-yÂ­;o="" Ãâ€ iÃ‚+jâ€“Â¶Ã¢o\^Ã¥ÃŠuÃ‚â€œo*1`hÅ¾sÃ›â‚¬="" â€“Â©eÃŠvie;Â¿Â¤Ã·â€Ã¡Â£Â©Ã–hâ„¢c|Ã‰Ã™Â¨bÂ£pâ€¦edï¿½-Ã­Â¨r9Â¹Ãœ=""><i â€™Ã®Ã£qÅ¡Æ’Ã¬}="" Â¯5Ã€7-}Â£Ã°gzfÃ¨Ãµ4nÂ¼Â¦kxËœâ„¢~Å“criÂ³Â¯Ãˆï¿½g@Ã…Â´)Ã®1â€°Ã¾_Â¼alsbÃ·Ë†k=""><b Â­ÃŠÃ«%jtï¿½="" Ã•Ã§Â¬,p1ÃÃ¯Â¾Ã»n]l="" hjâ€šâ€šâ€šÂ Ã›yÃ›Â¶mÂ _Â®Ã¬Â½Ã±Ã‚Â¸="" ="" Â¯ï¿½Ã¶whï¿½Ã†Ã«Â Å“Ã Ã·gÃ‚nj2}Â²?Ã¡Â§](â€pÃ†a`â€ cÂªÃ²Ã°â€ºÃ±Ã¾@Å½d="" tâ€“Ã¸,utyÃŠ="" ÃˆÃºÃ¬izzj)Ã°â€œâ€™Â§iyâ„¢ybâ€“Ã˜luyâ€“Å ="" Å¸=""><b><i o*dÂ´,wÃgÂ·Â®Ã€+Å“Â¶*â€šâ€¹f\yâ€="" Â«'yÃ¨ÃÃ¿Â¥Â¨Â¿Â©Å“Ã¿â€ºÂ´ÃÃ¿roÃ«â€ºÂ®Â·5Â¾wÃ«eqÃÃ½yâ€#ÃŒâ€”Ã¹Ã‚â€¹nÃ§Ã…Â¦pÃ¶Ã£yÃºï¿½Ã›,Ã’ÃœÂ­ÃÃ¼nÂ³yÃ–ÃÂ²Å½Ãœ="" 7ÃsÃ¤="" Â£Ã­bÃ®&2xÂ«Ãâ€°zqÃ¶ÃšÂ¢qÅ’+Â¡:Ã¬â€¦]â€!Ã”â€œÃœ{ÃˆÅ½8^Ã‡=""><s><b Ã7ËœÃ³Â¸Ã£Ã‘Ã‡Ã†a$211yÂ¼hqbbâ€ Ã©pÃ˜1*Å“Ë†â€œg0^3gÃ:tÃ„Â¾Ã½Ã»Â¢Â¢Â¢ÃŠï¿½^ï¿½Â³Â©iâ€œÂ¦Ã¤ÃªccgggËœÃÃ¹â€™Ã¼Ã„Ã„â€Â·xq="" â€Ã…â€°*)â€™Å¡Â·}Ã»Å½vÃŸ?zÃ”Ã¨;w$â€™|xâ€“hpÃk(Ã¿="" 9Ã¹0Å’Ã—Ã¶mÃ›Ã«7hï¿½y="" Ã#Ã€"rÂ©â€Ã£Ã¢zÂ·jmhË†="" Ã†hÃ™Â²Ã¥Â¹sÃ§ï¿½Â¥Â¬Ã¢Ã|Â¦Ã²â€¡ÃŒ,yï¿½Ã¬Å½â€¡gÂ³Ã¦Ã!uâ€¢Âªuâ€”Ã½ÂµÃ¬ÃÂ»w"4Ã©Ã¸@Ã€-Ã»[-Ã¿Ã·?rimÂ¿Ã¾Ã½Ã°Ã="" ÂºtÃ1bÆ’_Â§Ã†Ã¼Ã©uÃ€"â€”â€â€¢â€œ~Ã›?jÃÃ¥â‚¬Ãâ€ºÃœÃºÂ®ÃƒÃ—ÃŸÅ½Ã»Ã›Ã³Ë†kÃ°Ã«Ã¨Ã´\â€°Â¬@Â®Â¬Â°Ã½vÃ€ÃœÃ”cxÃ`j="" Â»Ã‚@Â´5fÂ¨bâ‚¬Å¾a="Ã•â‚¬Ã¾&nbsp;Â¾" Â§h3ËœÃ§â€ºâ‚¬Å Â½lhÃ“="" Ã€o`Ã¢â‚¬s!Â½cqÃ³ËœxÃ`Ã›Ëœ="Ã¯ï¿½Â²ÃŒP'Ë†" Â¡Ã•ngÃ¬kvpÂ±Å¸â€˜Ã·Å¸_Ã”Ã²â€¹ÃÂ ÃŒÂ²Ã…Ã–3Å½=""><s><u><i sÃs[Å½="" Â´â€š="" mpnÂ¬iÂ©Ã¸8Â¦Â¸_ÂªsÃ·w4Â´:Â®Æ’vaÃ¦="" Ã’.vâ€ºbÃ³:!Â®â€ ?jÆ’zÃ˜Ã…yrÃ¬Ã„Ã¡Ã¨Â§Ã£kÃ£Å¾uÃ‹ÃµfÃ‹Â¸Â yzÃ¯Ã¢nÃ‹="" Â«="" nÃ©Ã¬ÃŠÃï¿½Â¢â€¹Â¿Â¿Ã™="" q="" gwhÃšÃ¬Â£Ã¥zâ€¢Ã â€¹â€Â²â€œÂ¹Â­ÃÃ£^yË†="" tÂ­Å½Â»xhu="" Å 5Â¦cÂ·â€º=""><u><i hÃ¦Ã¨Ã™ÃŸ&Å Ãª="" Â¦mÂ¤â€™)â€™ï¿½#cmâ€º5kËœÃ¬Ã‘kldÂºÂ°)u+Â¡btâ€¢ï¿½="" ~ytÂ¨Ã–="Ãâ€°zUiÃ¨%ï¿½Â´ÂºTâ€°â€šÅ¾â€¦" Æ’nÃ´htâ€)wÂ«ÃŒhÃ…ÃÂ»wcÂ·Ã‘%Ã„Ã¥ï¿½Ã€="" Ã•@="" Ã¨ÃbÃ¨Ã¾ÃÃ›jÃ¨Ã¼q4txâ€°ï¿½Ë†Ã¯:%.Â¨Â¬{Ã‹b)Ã†lyjâ€˜Ã£Â wÃ‘:Â¥]uÂº{i9#nÃ¨ÃÂ«bÃ.Ã¨â€™Ãiwa'ÃªuÂ¥Â¡â€”4Ã’Ã¨rÂ¥ÃÅ“xÂ vÃ¯$â€ ^onÃ¼Â»Â·â€¹6'gÂ®â‚¬ÃµdjrwdÅ½lâ‚¬$Ë†Â°cÃ„hÃ‹Â¤ÂµÃ¡*Ã¼Å’Â§dâ€˜jâ€œcÂ¶jÃˆxÂ¥ï¿½Ã°Ã’â€œ|â‚¬â€1â€š$ÃŒ*f4="" |xÃ¡'Ã´#rbÅ½Â¶p#Ã¥Â¡â€¹deÃ+â€ _="" tpâ€â€¦nÃ…%Å’hÂµ*kkË†2wÂ½Ã˜Ë†:Ë†ÃÃÃ¥Ã§"#Â­â€n`Â­Ã¤uqsâ€“Ã¢u@Ã·2Ã¢â€^ÃË†zÅ¾Ã¶tyÂ§Ã¸=""><a Ã¤â€¹Å¸Â­9ï¿½1Ã¯.â€œ}(â€”xâ€™dÅ½|wÃ-Å’ÃŠÃƒâ€œ4Ã¿dÂ¦Â¼[b="" â€ Â©Ã¹o0â€¦Å“lyÂ®hÂ§.Ã£.ÃÃºâ€¹ï¿½!Ã–Â©â‚¬w\Ã€Ã¯ÃvÃ²zvÃ•cÂ¸â€¡,jÃ§Ã¾Â»?ÃœÃ´%]Â£uÃ˜ÃÃ²'v~tÃ˜ÂµËœmÂ¬ÃºÃfÂ¼Ã…="" ÃšÂ¡Â¨y8jÅ½Â§Â¸.=""><u Ã½â€¦ï¿½Ã®Ã˜Â¿?v9Ã¥$;bii"iÃšÃŸÃŸï¿½Ã¬dÂ¹Ã‚e$&&Å Â¤*Â¡Ã—(â€¢j;;;Ã¬bÃŠÃ¨Ã‘lÃšÂ´i$iy?tÃ—Â®]Ã˜yÃ²Ã†Ã™Ã™Ã™Ã‘Ã‘q$u="" Ã½Â¥Â­Â­mdÂ¦ad$v="" Ã¥mxx8$ÃÃœÃœ,â€ ÂªÃ±Ã±Ã±Ã°Ã¦'nÅ“Ã€Ãâ€™7Ã‘Ã‘Ã‘l6ÂºÂªÃºknn.Å’#gÅ½`â€”pÃÂ°Â©Ãœ"uï¿½Â }Ã¨Ã¤Ã¤â€ï¿½"Ã¬quï¿½Ë†1Ã¸Ã¸Ã¸Ëœâ„¢â„¢uuuaâ€”pÃtvvÅ¡Å¡Å¡Å Ã‘ujiia_ï¿½ÃªÃ»|ï¿½]Ã¾â€”Â¶Â²Â²Â¢Â®1Å¡Å¾Å¾Â¨!!!Å“â€¹"Ã˜zjjÅ Â·Â·Ã·ÃšÂµkÂ¿ÃºÃª+Ã¸aÃŸÂ¾}Ã¼Â·eÃ³Ã³Ã³Æ’Ã´Ãpâ€uâ€¢Â­Â¥\wwÃ‡9="" Ã¯â€¹="" Â¾xÃ—]w-[Â¶Å’Ã¿Ã•cccÃ…Ã«ï¿½ÃºÃ«;pÃÃ‘#!!Ã¡â„¢gÅ¾Â¹kÃ°kpÅ¾â€˜Ã¤Ã¤Ã¤@Ãºvu="" Ã„n|wÂ¬yÂ³â€ iÅ Ã¢3lfÃ¥Ã¾Ã½Ã»â€¦uâ€¢Ã_Â Ã“eÂ¢Â£Â£Æ’[!t*â€¢cyÃ´Ã‘g_Ã½ÃµÃ—^{Ã­Â§?Ã½Â©Ã¦â€”<Ã—Â£`Ã·Ã€Ã¡Å j:44â€Ã˜i:{Ã¶Ã¬ÂªuÂ«4bÂ¢Ã¸="" ï¿½="" Ã€-Â Âªâ€Ã¾2<<ÃŒ6Ã¢vÃ¼Ã â€ºnÃ®ÃœÂ¹pÃ¾|Ã°ÃÃ‘â€¹hÃw0â€Ã^â€šï¿½="ÃŠ-$Â¶â€¢H!â€ÂªÃÃ»cS5Â¹Â¥&nbsp;!**jÃâ€šÂ£â€ºË†X">ÃˆOâ€™Ã‘rÃš(ï¿½ÃŒÃ¼IYÃ¦Ã¦tÃ²Ã†tÃšÂ²:Â»Â·ï¿½0Ãˆï¿½Ã¾ÃªÃƒ-â€¢Â£|Ã’+eÂ©â€ºÂ¼9V9-â€šÃsm5â€”'Â«Ã¯Â­SÃ¯oVÂ¿?Ã‡8Ã—^6ÃÃ­Ã›+56Ã©/Ã“Ã¯Â¬06â€¡â„¢Ã§â€¢ÃµhkÃ†â€™â€šuÂ¾Â³Ã¦Ã†RÃ•ÃÂµÃŠÃ§Ë†Â«Æ’â€Â¤TÃ‚Ã£â€šÂª1&gt;Ã´ Usâ€°ÃªfÃ‚\gÃ¾Ã†TÃ²Ã…Ã±Â¤Â¹Â®4
ÃŸQÆ’^Ã¦HÂ©9brvg]Ã¢Lâ€¡Ã¿Lâ€¡ÃÂ¨Ã„â€¡[Å¾Ã”XÅ“â€â€šjm~,=;â€“UÃÃ•`Â­Ã¢Xv7ËœÃ“Â²}Ã‹Æ’Ã±Ã±ÃˆÃ½aÂ¬Â¯6Â©
Ã¯C\^Å¡Â¯ï¿½3kÅ“M}LÂ½OÅ¸
&gt;1rb&amp;Ã¸Ã„lÃ â€°Ã™`#Â¥Â¨ÃµÂ·`Ã•WÂ»&nbsp;Â¬ÂªÃ«ÂºÂµÂ¼Bï¿½QcÂ¥]Â¬
4YÃÂªÂ»kâ‚¬!Â«jÃÂ¼ÃªÂ½Â»w^Ã’Â¯ÃšÃÃ•!Ã¦ËœÂ¶ÃÂ¯ÃºEâ€™Ã©'â€°&amp;Ã½Ã¡Â¿ÃŒÂª0vÅ Ã¶.Ã€Â¼Ã€ÂªÃšÂ¼*5CÃÃ†0bkrÅ¡ÃŠÂ±Â½ÃQ#â€™hvQF+1Â½Â¹4Â«Â¿%uYâ€œry.mu8KÃ½Âºâ€¹vÃ•â€.U&nbsp;yÃ•ksÂ´9%eÅ“OÃ‘Å¡uÅ¸kÃŸÃÂ¨Â®Â©!Â¨p/
6Æ’Ë†Ã¨oÅ¸Å½Ã¾Ã¯Â¯Â¡ÃšÃŸÅ¾N|Ã¿ÃÃ¸Ã¿Ã¾rÃ¾~^Ã½Â¿[Ã¹Ã©Ã£â„¢G3Ã²GsÃ²â€¡Â³Â²{Ã“ÃÃ­Ã–Â¨Ã°Ã†Â¨Ã Æ’UÃ¹Å¸Ã{Ã¾gï¿½:Å¾^â€¢~rSÃ²Ã¹Ã‰gâ€ï¿½Â¯4_â€¡Å½LÃ¼Ãªï¿½Ã‘jpÃ°lAÂ«Â¥11AU_Ã–Ã—Ã½ÂºÂ»Ëœâ€¦Ã Ã€Å Ã‰â€¦Ã›Â¬:3Â¥Å’â€¢Ã’pÃ¬â€™Ã”&amp;pZK Â«Ã¦Ã†CVÃÂ¼*`UrZ(!)Å’â‚¬Æ’Â¬ÂºÃ­Ã—Ã£â€œâ€¦\Ãµ#Â©UÂ´k5Â°ÂªÃ¯Ã³QÃˆÃ.fâ‚¬UÂ¯DÃƒâ€˜7boDÃÅ½2Ëœ/OzÂ³yU"Â²~Â±Ã¸ÃµkÃµuâ‚¬ÂµÂ±â€œÃ®=Â¿Å¾UÃµÃ«ÃŸcÃ­Â©Ã¾rW^ÃµÃ¶Ã­Ã›333Ã»Ã¶Â«baÂ¿ÃªSÂ¤_ÃµÃƒD^ï¿½â€°â€“UuÂ£Ã¬_hÂ¸xï¿½UÆ’VEÃ²Âªâ€UÃ“Ã¢Â¹Po9	Â¼ÃŠÂ¸!Ads,Â§$ï¿½_â€˜ÃRâ€“Â¥Â¦\zÃ¯Å¡Ã³Â¿_|_cdUËœWÂ¥]Å¡Â¬â€ Â¬*&nbsp;"Â¥Â¿Å’EÂ­ÃÃ¶4hÃµÃ¶Ã²`Ã³Â½â€¦Â¶?Ã»ÃoÂ¦Ã¿Ã¾Ã—Â¹Â¿&gt;Ã¿Ã¾Ã±Ã¸ÃŸÂ¿YzÃ»ÃŸ?,Ã¿hÃ¼Ã‘Ã¬Å½Ã"&amp;7G7Ã‡]jÃ¿Ã¡Ã“ï¿½o&gt;Ã¬Ã¹Ã¢AÃ»â€œÃ‹Ã¢OoÂ½v_Ã°pâ€œÂ»Â®fM	h3Ã¢jÃ°Â¯?Â¼Ã´â€“Â¼6VÂ¡Ã¡â€¢Ã·6â€Ãµ6Ã Â»YEpÅ“Â£@L*ÃœfÃ•Qâ€Uâ€œÃ™%)Meâ€°Â¨ÃÃ’sÃ¢Â«â€¹]4Â«â€™Rï¿½Ãâ€ Â¢zâ€¹ÃÃ¡Â½Ãâ€°Ã²Ã’Ã
&amp;Â¿p7Ãµ6ÃœÃ&lt;ÃÃ™,ÃŸÃƒÃ¤Â¢Â·Ã—coÂ½ï¿½4ËœÂ¨.|Â³Â¬Âº_Ãƒâ€¦Â®Ã£ÃºÂ«.tÃµVÃ—q]Â·ÃeU+++Ã€ÂªgÃÅ“Ã‘Â³Âª~Ã½AÃ–/Â²ÃªÂ¥Ã½YuÂ¼,y=Ã¤Ã”â€¦Ã°SÂ«Ã¡Â°Ar&gt;Ã´TÂ´Â½ï¿½ï¿½:GÃ¬9Â®â€šxÃ¸yC\&nbsp;SJÂ°KnÂ´sYâ€™Svâ€gvâ€oIÂ¼g
ÃÃâ€™1ÃŒkÃ²&lt;Ã‹â€œ"HÂ©aÂ¤Ã”Â¨Â¢Gâ€¹=Â³ Â¦&amp;/Å½UÃ—PÅ’m(Nj&amp;$Ã¶Ã³â€šÃ§{Ã¼z4Ã‚()5CLÃiÂ£Ã¦Ã²Ã’ÃÂ«cWGÂ±Ã§Ã•I=ÃµÂ¨VÃƒ)CMâ€Â¡&amp;Ã¢0ï¿½Â¸Ãï¿½_Å¸(iÂ¦N&nbsp;h_Ã”Â®/â€¢Ãœ8ï¿½ÃŸÅ“ Å¾â€¢Bâ‚¬ï¿½Ã•Â®â€œoÅ“/Â¿Â¹RÃ¶Ã¾Ã¹Ã²ÃµÃ’Â¶Ã¥ï¿½Å’&gt;#Â¦ÃÃ‰Â©â€”Â¦KÂ®/Ã¥_Å¡)XÃ¬.mÂ¡Å’Â¶â€™Fxâ€¢Å¡fÂ¢Å¡â€¡Å½Ãµ7.â€œdÅ¸WÃ‡-kÂ¢g:Ã£Ã¤Ã•â€¦rZÃ¸Ã™$â€,!)KPâ„¢ÃQ3Â©Ã°â€”Â¹ÃµrÂ½Ãªâ€¹puâ€¦ÃC&nbsp;6â€“Ã·P3ÃÃ“Q2-ï¿½Ã±ÃŸfâ€,||Pq\Ã€&nbsp;ÂªÃ“â€”ï¿½â€šÃªÃ³dï¿½Â«yËœÂ³iï¿½â€œâ€°ï¿½Â½1Ã‹Ã«Ã”DÃ Ã±Â©Ã€Ã£Ã£`Ã»4TÅ [eoËœUÃ·Ã—Â¸Ã—Â­Ã¥â€šÃ¼RÂ· ÃˆÃ¨pUWWWÃ›Ã˜Ã˜Ã¨Yu7Â«&gt;Ã»Ã²Ã™Â£â€¡Ë†Â·dÃ•â„¢Ã™Ã™{wÃ®,-.Â¾â€UÃ›w|â‚¬Â¡&gt;Ã€XÃ£Å¾Â£YÃ•ÃºÃ¥yÃ•hmMZ@YR`cÂ©Ã§Ã¬WuÃ¨Ã¡@VÂ¥VÃÃ‡Ã”Ã€Ã˜)vH:*ï¿½hÂ£'u5&amp;Â¶Ã—%kâ€Â¸Ã³CÂ¸ÃiAeLÂ´Ã¥*iÂ«Ã–â€“Å¾Ã«+Â»ÂµZÃ±pÂ«ÃªÃªYÃŠYeÃ•Ã»Å¾{Â°TkÂ»Â©Â¼ï¿½=ÃÅ¡ÃŸkÃ½Ã¦ÃƒÃ¾&gt;SÃ¿Ã´lÃ´Ã©ZÃ‡Â£Ã¹WwÃ¿Ã£â€ºÃ‰Å¸Å¾MÃ¼Ã¸Ã¹Ã¸Ã‡ÂºLAÂ´Ã»Sm0vÃ<ziÃ»Ã¶iÃ—Â³gÃŠ Ã‰Å¸="lÃ»Ã¢Â¾Ã¸Ã£Ã›Ã¼â€¡[ÃœKÃµÃ³2Ã†Å’â€">Ã‘JÂ»Â¨Â¦Ãœ]Â¯ÂºÂ·AÃœÅ“$Å’â€¹Ã‹{Â«Â²ÂµÂ¬Å¡/Â©*kKEÃºUÂ£&amp;Ã¤	Ã‡Ã†Â§5â€¢Â¡Â¬ÃÃˆMï¿½Ã—Ã¸#Ã½ÂªÂ²7ÃˆÂªÂ¸Ã§Â¬ÃºBYÃŠÂªÃÃ/eÃ•gÃ“ï¿½Â¨3Â¨PÃÂ«gfJÃ	â€¢Â½QVÃ5X
Â­Ã˜Ã›Â¬ÂºÂ·yjÃ¯Â¤Â¿Ã½KiÃÂ©Ã¶Å¾ÃŸÃÃNÃÂªÃºÃµÂ»^Â»YÃµÃ‹/&gt;GÃ»UÃ»ÃºÃ€Ã™\X\Â¼}Ã³Ã¦Ã™Â³g_ZÃœÃŸÃŒÃ¼4Å¡Â½Ã½$ÃÃ¤AÅ“Qsâ‚¬Ã±Ã®Â¼ÂªÂ®Ãâ€ Â¹iÃµVâ€ºW-Ã‡Ã²*ÃÃ•Â­Â°_UÃ‰Â¬
Â¨-â€ UM&lt;Ã„Ã•1ÃƒÃ¢PÂµ JÃ†HÃªlHÃªÂ¨OÃ£VGqâ€º3)F24â€šÃ¼Å“MÃ¢Å¸UuÃ¹Â½uÃ¢ÃƒKU[â€œâ€iiË†|Ã6UToÂ«Â¢zÂ»}78Ã|gNÃ´Ã­Ã“Ã¾&gt;Ã—Ã¼Ã´Ã•Ã˜Â£%Ã¹â€¹Å Ã¯k~Ã¾jÃ²Ã§gâ€œÃ½pÃ´Ã©rÃ§Æ’Â©6Ã„pÃ‘Ã›QÃ¡Ã1Ã¡â€¡â€ºÃ²o&gt;|Â®Â·Å¸ÃŸ}|â€¹Â½i]SÃ‚Â§i}ZRÂ½1
'Â¡Ã…Ã“hÃ¹6Â«6Ã®ÃŒÃ²c@Â½ï¿½Ã©Ã€Â­Â¨c/G!cwâ€™9Ã¸TÃ6Â«Ã†Ã“sÂ»Â½4"'ÂµÃAPÃ¥	YÃ·"Â«b^dUDoÃ·Â²jÂ®Â»Ã‰fÃ”â„¢â€ºÃ‘â€”Â¢Ã\â€°<s-Ã¼ÃŒ(ÂµpÃ¾Â°Ãª?[oÂ¶Â·yÃµÃµfÂ¨Ã©:Ã[â€umllï¿½Â«â€šÃ«yuÂ¿Ã¾Ã«_fuÂ¹Â¬mÂ¤4y9Ã¨Ã¤r(ÃœkÃ¡Â§Â§â€šodÃ˜Å¾Ã¶Â´>Ã£og&nbsp;â€¹Â«ÃšÃ´
Ãï¿½â€¡Â¤@'BÂ²Â·Ãœ23Ã‚5-Ã„Â»0ÃMÅ Â°ÂªË†jAÃ‰Ã´(â€°â€¡Ã¾Â·Ã‰"Âªï¿½â€šiSï¿½Sï¿½â€¦aÃ¤Ã†â‚¬Ã€Ëœâ„¢ÃŸPÂ¯Â¨
Å¾VÂºOÂ·{â€¹Ã½EUÃ‰Â­Ã„AeV;+eÂº#ri0tÂ±?Â²â€”ï¿½Ã™Ã½RÅ ÂºYÂ°Ã¸PU_6Ã€)ï¿½VÃ¤Å“ÃˆÃ¨k Â©!]V.ÃµlNglÃdÂ®Å½Â¡#ÃƒÃ¸â€â„¢6Ã¢Ã†DÃ®Ã–lÃ–Â¥Â³YGÃ²gdÃ„1u\Ëœâ€2!"^Ã‰ÃœËœJÂ¾0â€™:-/`W6â€¢Ã®gÃƒKBÃ°Â¯Ã­Ã­Â¨)Ã©Ã§fÃtD.Ã¶M)CdÂ´LQUÅ½Ã±fÃ§â€¢gÃ°â€°Â¸Ã¶ÂºÃ Q)P]')ÃÂ§6/Â©6^â€“Â¢ÃÃ¬Ã¤Â´HzN&nbsp;Å“aÃšUoÃ–YgFÃÃ°.Å Ã³/Ã€Ã¸Ã¦Ã‡xÃ¯â‚¬ÃªvFÂ§Ã“Â¦ÂºSUh@5Ã„Ã‰Â±g7bxÅ“Ã¶?:Ã¢lÃˆÃ¯Â¨Ã†Ã§Â¨Ã†ÃŸ@Ã±Ã¦XUÃ·Ã²pÂ¯{Ã€Ãqï¿½{Ã WÂ»Âµhâ€ºUuYÃÃ—Å“<yrÃÂª;yÃ•gh^uzxx,vÂ½{Ã§ÃÃ¢kyÂµÂ£Â«cÃ„Â¿â€œdÃ¿ï¿½â„¢Ã·Ã·0ÃÃ¨^Å“qgÂ°â€˜â€”ÃƒÂ¶Â·ÃštÃÃ™asyâ‚¬#xÂ¯gÂ½>ÃÂ¦rtrQ\`ib`ÃsÃºÃ›uÂ³ï¿½Â¨â„¢Ã°TÃ–Ã¤a9Ã±rÃ´â€&lt;`EÂ°:Â¼&gt;Â¶1Â¹&gt;sa{q,im<eÂº=Â«ï¿½qÃ” n?Ã—ï¿½Ã¿\Ã©Ã5Ã‚Ã¥Ã™ÃŠÂ³jÃ²(ï¿½2-ï¿½Ã½s="" Âªyâ‚¬â€“jÂ¬Ã³;ÃÂªÃ«Â½Å“ï¿½Â¾Â¦Â«#Ã_Ãœw|Ã½aÃ‡Ã—ï¿½;Ã¯ÃiÃ|Â¸Â®Ã¸Ã¶cÃ•wÃ·~Ã·tÃµÃ©â€¢Ã¶â€ºÃƒÃ‚â€ºË†Ã»Ã™ï¿½1ÃšÂ¸zwiÃ°Ã…cÃ©gÃ·doÂ®Ã°="" ï¿½Â²7Ã”ÃµÃ»Ã«â€“â€Âµg%Å’Â³r:Ã•Ã†[Â«â€”hÂ·v="" Â·="" â€“Â®oÃ Ã‡deÂªÂºr;uÃ¯ÃŒaâ€“tÅ’iqâ€¹1Ã§â€¡"f%1b2â€™w-ÃÃ‰Â«Ã¦$ÃˆÂ¾="" â‚¬tÃ¬Ã›Â®Ã¤Ã”]v-|}vu1]ï¿½8u1@[â€¹8Â½vjÅ¸Ã°Ã›Â±Ãª~Â±â€œâ€“uuÃÂº_Ã<Â¥kÃ´Â±â€”uaÃ¬Â¤guÃ½ÃºÂ½Â¯â€”Ã¤u!Â«^Ã®cÂ¼â€¢oÂ½â€uâ€˜Ã¹ÂªÃ½\Ã¦â€œhÂ£Ã»qfwÃ¢Å’="">@Ã¦Â«rÃ¼Å’|_nÃ¢â€˜Ã¼Ã¢tÂ°Ã˜Â¯ÃšBtÃ¤A`EÂ­)5Â°*bï¿½â€ºÃÃ†Ë†ËœÃ©zxa4d}"Ã‘[ÃŒâ€¦Ã‘Ã¸ÂµÃ±Â¤â€¹c)Â£â€™Å“Å½Å¡Â¢.VIO=~Â©Ã»BÃ©Â½ÃµÅ ÃÃ‰ÃŠ))yÂ¼Ã¨-4@ÃµÂµTÃ’Ã•Ã›3Ã¼/(Â¾Ã¹Â°Ã³Ã«Ã‡]Â·&amp;DÃ¯?Â¹ÃšÃ¾Ã­SÂ¨Â·ÃŸ&lt;Ã®Ã¹hSqC#â€Ã€Ë†Ã^Ã“Â´^Ã¦?\Â½Ã½Ã´Å½Ã¨Ã‘&amp;ocÂ°qS]Â¡â€”Âµ ÃŸÃ–[&nbsp;Ã­SbÃª
4Å“Â¼}aÂ¯Ã¦â€¢Æ’xÃÂ«vÃ€â€“UÂ¨Â·Ã“Ã­	Ã§Â£â€”â€¡Ã‚Ã¹Â±Â­â€¢Ã‰Å“XÂ¼ï¿½WÃNÃ¨Â¬Ã·TC`Â»Vâ€™Ã‡/Â³ÃªN^5Ã¶EVÃq7Â¾Ë†Ã¨Ã­Ã…ÃˆÃ“Ã«Ã¡Â§7BO
S~#VÃ•ï¿½Â¶Â·YuoÂ½â„¢nÃ‹KÃµVÂ·ÃLÃÂªÃºÃµâ€¡]Ã»Â°Ãªâ€šB"Ã¾EVUâ€”Ã Ã¦Ã½ï¿½ÃÅ¸{9Ã¬Ã”hÃ€Ã±PÃ«Ã®â€“Â§|lN\
Â´7v4Ã5#ÃÃ‡Ã«Ã«XÅ½Â³Ã¥-3ÃƒÃ½Â½
cï¿½etKÃ›Â¢â€¦hMHÃ¶(Ã„@!Â¸*cËœÃ±Ë†6Â¤Ã”Â¨ÂªÂ´ÃˆÃª,â‚¬rÃ‘Ã´Å“Ã˜ÃšÃ¼8&gt;)dDÃ¬8,vÃ’Ë†Ãœâ€Ã¤Ã˜Ã¦Â²â€Ã¦Â²t!9Â¥Â¿9bÂ®Ã‡Ã·lï¿½Ã¿PkÅ’â€Å¡'Â«ÃSÃ’Ã³@Ã°Â©dÃ€jâ€œ1qÃ²Ã™ÃÃ¸Â®Bo}Â©ÂªÂ¾|Fâ„¢Â¾2Å’]ÃÃuÂ¥
pÆ’MC\ ÃÃ¹Ã°Ã¹â€Ã•QÃ¬Â²:qZÅ¾&gt;3Ã„-Ã«k$Âªâ€ºKÃ»Ã¢â€”5Qâ€¹}ËœQf7Â³Å½vâ€¦u,Eï¿½ÂµÂ°tÂº'U*k2â€ Z#f:=Ã‡eÃÃ²,ï¿½ï¿½Ã…Â«Hm!$Â³KÃ’xDLgÂ½Ã»PÂ«ï¿½Å cÃŸXFÃÅ½Â§eÆ’â‚¬<wÂ¥â€¡sÃ‚Â©Ã™Å Å¡mv%Â¥yÃ¤Ã‡Ã€ï¿½ÂªÂºÂ½o {ï¿½â€Ã¾â€ "Â â€Å½Â½Â¶1Â ÂºÃ¯Ã·92Ã¨sÂ´Ã—Ã»hÅ¸Ã§â€˜="">ÃŸÃ“
Ã‘fÃ•â€”Å½kÃœÃ=Ã 5`Â­ Â£Â¬ÂªÃ•d=Â«Ã‚ÃµKÂ¬zg_VÃ­VÅ Ã¸Ã¯'Ã˜ÃÅ 6Â¸â€ºÃŠoÃ†*
Ã‘
Ã â€”gÂ»JÃŸÃ›:ÃÃ±Ã«FZÂ¨P{%Ã”Â¯â€Oâ€¦Â±Ã¾Ã¸â€â‚¬ÂºbÃ·Ã¾fÃ«ï¿½Ã›Ãz{Ã”â€OÃ´Å“81-|TÃªÂ£Ã²C5Ã¢Ã°IÃ”XfÂ¾Â³Â¢â€°Â½8?Ã›â€¢ÃšQâ€œpÂµï¿½^2)+Â¼:WpsÂ¥hkÂºtFQÂ¡Ã¡â€™'â€U;Â£`Ã—ÃªÂ¼Â¼vâ€#	Ã–Ã•Ã®Ã†ï¿½AÃ¶G7xÅ¸Ã|zWxsâ€ Â·Ã•Ã—|sÅ¡Ã¿Ã‘5Ã‘ï¿½$Å¸Ãz[â€šÂ¥+CÂ¼+C-â€”â€¡ZÂ¶Ãºâ€º7Â¸Ã¯Ãr?ÂºÃ…}zÆ’sÃ¯4@[ï¿½1Ã§eÂµsmHÃ $Â¥MÅ Â©c&lt;ÃŠ|gÃ…ÂµÂ¥â€™Ã·Ã\Ãâ€“tÂ³J{ÃªÂ·â€œÂª
zÅ¾â€Å“7*â€°Å¸Ã¯â€¹XÃ¬V"Ã¹DÃ€ÂªË†Y7Ã¬Å¸Å Ã‡VJÃ·Ã Ã™Ã°lÂ¤Ã•ÃÂ¤Ã”Â¤_AÃ–Ã­WÃÃ?Â¥Ã›Â¯ÃªjÃ¬Yu1Ã´$Ë†Å¡â‚¬l.â€¡Å¾\
99VÃ²Ã¦YuÂ¿Â©Ã´Â¿Â¾YU;Â¡Â¬Âª[â€œÂ¦gUÃ½ÃºÂ½Â¯ï¿½UÂ«ÂªÂ¸ÃŒ{7c&nbsp;ÃÃâ€¹5Â¼mÃÃ kÃ¨Ã£`Â¢Ã›Ã‹ÃŒÂ½M~Ã‰|&nbsp;Â·Â¥â€°Ã¾\â€šÃÃ›Ã¾f[ÃƒÂ¥2%â€“â€“Ã…ÃˆÃ…ÃsÂ°Ãˆï¿½Â·Â¯Z4Ã˜:,Å½â€˜Dï¿½ÂµÃ….
`Vâ€ Ã£.Å½%Å’Â·eÃ€hÃÃ•Ã*nÅ“z[Â¼1Q:!!Â·ï¿½'â€¦U:Â¦Ã«Ã›z{IÂ°Â½Â½2Ã†Ã¹Ã¨&amp;Ã¿Â³Ã»PoÂ¯ï¿½Â¶lÃ¶6ÃŸâ„¢oÃ½Ã¸Â¦Ã¸â€¹â€¡PoÅ¸^]QCÂ±EÃµvÃ¨Ã­ Ã·Ã¶ÃÃ›Â¦'Ã—Ã™Â·ÃÃ•ÃKËœÂ²ÃšyY
Ã[hÃ¥!Â­Å¾R'ZÂ«â€“Tâ€+Ã…Ã¯Å¸Ã‹_Ã•Ã¤5Ã£Â»Ã«Ã°Â¨Â·â„¢Ã¤4Â¨Â·SJÃŒBÃ¸b_poSLÃ‘Ã›â€™mÂ½Â¥eÃ‡Â·Ã—Â¹
Ã²Ã­ZlÃ¸â€¢Ã®â€¢)!HÂ¿ÂªvÃ¨Ã¼s+`8Â¹fGoÂµ7Ã¹HÂ¿Âªyï¿½Â³YÂ¶Â»Ã±RÃ”Ã›Ã³;zÂ«Â¦Â¼yV}Eoâ€nÃ°Ã«4Â«Ã®Â½ÃƒÃ—:oooÂ¯gUÃ½ÃºÂ£Â­ï¿½UÃ¥Â«'MÃ»â€º&lt;6pÃ¼lÃ°â€°AÂ¿Â£AÃ‡ï¿½ÃOxZÅ¾Ã´Â±&gt;Ã¥g{&amp;Ã€Â­ÃÅ¾â€š
B5  1Å¾Â¶Ã¸Ã‘"%Ãˆ&gt;ÃŒÃ™Â»$ÃZYkÂ¡bâ€ºÂ³Å Ã¬
0Å¾Â¹Q@â€šÃ¼Ã‹â€™Ã¼;Ã«,Ã¹ÃÂ¥	aÃ‰Â¡Ã¤Â´Â°ÂªÃ´JF5Ãƒ*Å’Ã¨mÂ²Ã®oï¿½)Å¾VrxCqRc1Å½Æ’Ã‡â€°Â¨Ëœâ€°Ã«Â¸Ãœu\Ã¦!Â¥%Â·Ã³EÂ¤<iuÅ¾Ë†\Â¤`dï¿½hbg$â€˜2*^Ã‰(pÃjâ€ â€¦â€°s=!Ã³Â½!Ã£mÃ±ï¿½ÂµÂ¥ÃÂ´Ã¨'aÃo?Ã›Â±Ã˜Â²Ã:Â¥Ë†Ã«Â©(zÃsw4Â¥,0Ã•Ã’Ã—â€â€š|Å¸<Ã™ÃŠhÂ¹mÃˆdfiuâ€“Ëœâ€%$e*j1â‚¬Â£â€¡eÅ½] Ã¬Ã¢Â¬Ã†â€™Â´â€ Ã¢va*Å¸ÃœÃhÃ•ÃƒÂ¶ï¿½tÃ›uÂ¥Ã‡k)â€¢â€jlÃ…'â€sï¿½Å¾wÃ—â€ºuÃ•â„¢â€¢&zdfÃ¸dflÅ Ã®2sÃ’Ãµ="" u6a^ÃºÃ›Ã¸ÃšÅ“vÂ³:er="">Ã–Ã­uÂ¤Ã‡Ã«Hâ€¡Ã§Ã¡NÃ·CÃÃÂ§eÃ‚VEG'â‚¬â€¢
â€¦JÂ¥Ãºâ€¢Â¬ÂºÅ¸{ÃŠÂªÂ¿8ÃªMÂªÂ¾Ã”Ã©N+Ãˆ(Â«M1Â°6_sÃ¢Ã„â€°Ã¦Ã¦f=Â«Ã®fUÂ¡pÃ¦Ã¬Ã™Â»wÃ¯Â¾â€šU/amÂ¯FÅ¾Â¹Å’4â€¢_â€°2ï¿½Ã¸Å¸Ã±Â°â€¦Â³Ã©uÃ‚Â§=ckÂ®Fx&nbsp;KÃ¹Â¿bÂ¬Â³ÃUÃ…Â¶Ã¨mÂ²T0mIÂ©â€˜â€Å’HdlMt[M`_Â³Â§Ã›XÅ“Ã„-Ãƒ5RZÃŠÃ’â€ Ã¸Â±Â½â€˜+Å¡Ã¨Ã™Â®â€ÃÂºÃ¬6jÂ¡â€šVÂ¤Ã¦Ã¥Â¯Od^YÃˆÃËœÃŒâ€ºVÃ Ã˜Ã„^%Å“Gï¿½z&nbsp;â€°ÂªÃ§dÂ´â€¢^ÃšrcAï¿½Â»W{X7Yï¿½Â¯Ã—?Â¾ÃšpyÂ´qÂµÂ«qÂ½Å¸}kï¿½Ã½Ã¡ï¿½Ã†'Ã—?|Â¿Ã±Ãº4{Â­â€¡Â³Â¦bÂ¯Ãµ6^Ã¨n\Ã­Â®Â¿4Ãztâ€¦Ã±Ã°Ã­Ã¦yÃšÂ¢Â¢v[Â¯Ã·EÃ”	!eÂ¬â€¢Â¬i&amp;MJ[Ã“9â€”Ã§2Vâ€¡3â€ 5%];&amp;Ã€Â²Ãª1)wDsÂ¶;hÂ¶Ã‹Â¿Â·)&lt;#v15VbÃ¦Ã‡Ã’Â²Â°bÂªWoâ€œMoâ€œâ€¢ËœÃ¢Xâ„¢\Å¡RÅ¡&nbsp;[Â¬[Â®Ã¿Â¢/%;Â¹Ëœ;â„¢F9â€ºÃŒâ€ Å“QÃ“&lt;Ã˜Ã'OÃ…Â¿YV}ï¿½i5{â€ºUÃ‘Â£ÃºRÂ³Ã®â€”â€“Ã’Å¾SmÃ¬Â¤gUÃ½ÃºÂ½Â¯_`Ã•Â¥Â¥[Â·nÃ­ÃƒÂªï¿½=MÃŒÃ·ÃƒÃ&nbsp;z{#Ã†p+Ã²Ã“Ã›Ã€Ã‹ÃX'
BÃµVgÃ´|Ã¨Ã¶Ã˜&nbsp;Â·Ã¹&nbsp;Â·Ã¾Ã¸x_Nâ„¢S/Ã‡BÃ…Â±â€™T;UÃ bÂ¨â„¢PoÃ³Â¢Â»Ã½:Ã«Æ’8Ã¸xÃ¶sÂ½Mâ€œÃ†,Ã¶GÂ®GOÃˆâ€œ:Ëœ92*Â´Â¢aP9&nbsp;Â·kÃ£Ã¹cÃ¢Â²!Ã”Ã›Â±Ã§zKâ€ºSÃ/ÃÃu"e-JÃ¦ÃºÃ«Ã¡%DoÂ¯4lÂ²ï¿½Ãâ€šï¿½wWÃ˜@iÅ¸\oÃ¼Ã JÃ£Ã•	Ã¶â€¦NÃZ/{MÃ„Â¶qÂµÂ§Ã¾ÃšÃ³Ã‘eÃºÃ½MhApV@RÃªÂ´Â¸Ã•[&nbsp;Ã­Ãƒ-â€¢3Å Â²+Yâ€”ÃÂ¦Â¯Â¨3Â¸ &nbsp;*Ã‘Å¡Â®Â·QÂ¡ÃN*"Ã¦ÂºÂ¡Ã¡dG}tS)Â¼ï¿½Ã€aË†ï¿½GufÂ¼Â¢Ã–Â¥ï¿½kÃÃ‹Â±lÂ©p%&amp;Â±
FÃµÂ¶pÂ§=jÃ›X{â„¢Ã¯gÂ¯ï¿½â€˜Ã€Â«
Ã´6ÃÃ‰4Ã“Ãh.Ã¤Ã„JÃ¨IÃ°Ã•Ã›rÃ¾dÃ•7Ã’Â¬ÂºkZÃKÃ«ÃÂ´Â¬jiiill|ÃºÃ´i=Â«ÃªÃ—dÃ½Ã«Â¬ÃšÃ–Ã–[â€4ÃªuTÃ£wTÃ£Â«ÃŠÃ·Ë†Â¿Ã™GÃ£Â£nfÃ‡&lt;,NxYï¿½Ã”&amp;XÆ’ï¿½UÂ¶Å tÂ³Ë†pÂµ*Ã‚Zâ€°Â©Â¦Ã¥Ã‰foÂ§FÂ¼iÃ‡RQcFHvLÃµÃŒÅ’Ã°ÃŠÅ½Ã²"Â§;wÃ•[P3ï¿½
cÃ±Ã±ÃÃ¥IAÃ‰!Ã„â€0bJ$=;PQcÃÃ2Ã¯nÂ´hÂ­tcÃ¦GÃ—Ã¦%Â°
â‚¬Â¾IÃ©~ÃƒB[ï¿½Ã^Ã…qS1Â¼Å 4&gt;1Â­ï¿½Ã—ÃŸÃ¬?!wÃ«kÃ…Ã¤&lt;)5Â«Â¿%|\Ã¦5!Ã·RÂ·â€ â€™mÂ£ÃˆÂªÃ³eÃ•ÃŠÅ¡ï¿½ lRÃ¡
Ã¶ËœÃ”_Ã…Ã†J)%â€™Âªâ€™vfÃŠÂ°Ãˆ\Ã¦&gt;,Ã¶ÃªnË†WAï¿½B8ÃTÂ¦Â·Ã“Ã¸0Å¡Ã‚-Kk!$(jÂ¼yÃ–Ã ]Â¦ÂµÃ’â€¹UÂ¢Â±KÃ½Â¤4Ã›Ã®sEï¿½MmÂ¾_e
â€ â€
Å¾K(\â€“TTÅ’
 gÂ¸Ã‹Ã¨Â¦LÃ“vÂ¦)1Ã•&gt;#Ãœ-9Ã˜=%Ã˜eÃ‡Å¾(Ã°Ãm!Ã¢&amp;
@#Ã„Ã™Â¼Â°â‚¬RmÃÃ¸XÅ¸Ã²Â°&lt;Ã©d~Â¢ÃœÃ±Ë†Ã‚Ã£ï¿½Ã’Ã£ï¿½ÃŒÃ½ï¿½Ã‚Ã­&nbsp;ÃœÃ«Â¤BÃ”ÂªÃ¬Ã¬zÆ’Â¬ÃºÃÅ½k|ï¿½XÂ·YÃ•Ã‹Ã‹KÃÂª/Â¬_bÃ•{Ã»Â³jÂ»ËœÂ¿kÂ³~z=Ã²Ã´Â¥Ãˆ3â€˜Â§â€¦Â¾Â§ÃmÅ’Â¶ï¿½Ã¤&gt;Â¸Å¡Â³Â«nYâ€˜nÂ¹QÂ¹Q&gt; 0Â¨Ã‰wÂ¿Ã€Ã ÃIiâ€“Ã‰Ã¤Â´pRj#/LVÃ£Ã•QÃ¯~Ã‰â„¢Ã¹	ÃµEâ€°l|RCaZg}ÃŒtGÃˆÃ’@ÃˆLgTwcÅ ËœW^'+Ã·Ãœ n}wq<urâ€“ÃŸ[_>Ãˆ)Ws+4-0Ë†iÂ©Å¡â€˜â€˜.j*ÃÃ·â€™Â§â€tÃ³,(iÂ·â€“+Ã¯Â®â€œÃ®^$_Â¨YTÂ²â€“â€Â¬ÂµÂ¡ÃšÃ›Â«Ã”Ã»â€ºâ€Ã»â€Ã·Â«Â¡Ãµâ„¢â€™uÂ®ï¿½Â¹Â¨Â»Ã¦Ã¢ÃµÃ¶Ã‚Â­Ã•Â²Ã‹Â³Ã¥Â³R2M
)Ã£Â­U jiï¿½ÃÃ¥Æ’lÃ‚Â·lEâ€œÂº6â€˜p^ï¿½Â¨nÃVÃ’â€¹ÃÃ©	mÃ•Ã™brÂ¶ï¿½â€9,ï¿½Ã©Ã°Ãº&nbsp;dâ€ #â€“n	Â¨Ã‚Å }JFÅ“â‚¬Ã¬ÃÃ•
Ã$Ã»
2_5~gÃÃŸÃÃ€Å¡tÃ­Â¼Â¿Mâ‚¬Â³nÃ“@'â€œH'Ã£â€°&nbsp;Ã£ jÅ¡;Ã¨Ã¸Å’Ã¿Ã±Â¡Bâ€UÃ›ÃŸÂ«Â¾~Â³ÂªÃ®QÃ•Â­ÃmVÃ•ï¿½ï¿½tÃÂºuc'â€UAÃ¬Â¤gUÃ½ÃºÂ½Â¯WÂ±ÂªLXÃµÃÂ­[Â³/eÃ•Ã¶Ã.Ã³rÃˆÃ©ï¿½Ë†Ã“kâ€˜Â§Â¯Dï¿½Â¹qÅ¡Ã¡yÃ†Ã“Ã¨Â­Ã±Nd0
Ã…Ã•Ã»ï¿½)Â«Â®@oÂ³Â¡ÃzÃ¦FÃ¹Ã‡Ã¹Â°Ã±Å½@d@Ã”JÂ²/KË†Â¦dâ€â€˜RÂ£â„¢â€¦!ï¿½
Ã®Rz Ã[Ã³@Â½Ã…Ã•Â¤Ã·5GÃvÅ¸â„¢ï¿½c:Ã«Ã’$dËœÂ²Ã¬iÃˆÂ¹0Å¡â€”Ã†RGEEÂ½
Ã¥Æ’MÃ¥ÃªfToI#ÃUgâ€¢â€¢Ã«câ€â€¦ÃŠÂ´Ë†&gt;+Â¡/Â«ÂªoÂ­@Â½Â½sÂ±jÂ¹Â»ÃªÂ­Â¢nkÂ¬Ã¦ÃÂ¨Â·wÃ—Â¨Ã—ÃV/ÃŠÃ«Ã Ã€Â¾vÃ¦â€šÅ“Â¹Â¨Â¬Ã™Â©Âº}Â¡Ã¼Ã¦rÃ™Ã–$aÂ²â€¢&gt;%FÂ¯Â«FÃÃ·oÂ©Tsâ€°Æ’Ã‚p+~mÂ·6n0Â±Â¯)OI/TÃ’QÃƒÃ‰lÃ”Ã›Å’	YÃÃ›1Â©â€”â€ÃPâ€C3ÂªTï¿½ÃVÂ¥Ã‡IiÅ½Ãï¿½â€“]
Ã¦MÃ¥.Ã¨â€^Ã¬Â¦Ã“eï¿½&amp;UÃ‘ÂªÂ³Gâ€œ4WÃƒÃ‰mÂ½=Ã´vÃ–Ã¯xÃ©ÃÂ³ÃªÃ«4Â«ÃªÃ¶FÃ½Â³ÃƒÂ´Æ’Ã¼Ã´Â¬Âª_Ã€ÃµkXÂµÂ»0qÃ€Ã³HÂ¿Ãâ€˜&gt;ÃŸ#ÃƒÃ¾G;&lt;{Â²58Ã¤l|Ã˜Ã•Ã´Â¨Â»Ã¹1Oâ€¹ÃVÂ§|Qbu@Kâ€šMBÅ“ÃÂ±Â½lâ€¹Å¾F+Ã•â‚¬j_â€œ-Ã—2-Ã”1)Ã5=ÃŒÂ¥"Ã…Â©â€œe3Ã˜bÃ™Ã“`Ã‹%Ã˜â€“&amp;Ã‚*Ã„l@yRÂ«ÃÂ½â€œeÃ—Ã›Â¾Ã–BÂ¿Æ’5ï¿½Ã¨Ã‰Ãˆ
Â§eÃ‡2rbYâ€¦QbÂªKoâ€œÃ¥Ã—Âºâ€¡Ã£Ã˜UÃ¯Ã’ÃÃ¨Ã’Ã‡uÃ¤Ã™Ãµ7;Ji!Å“Ã¢<iuxÃ—k-pÃ’Ë†Ã¬â€¡Ãâ€šÂ¿ÃµÃ¨Â®h%fhÂ­Ã„ÃœvÂ¨zÃ <"â€ â€“Â§jï¿½[g]â‚¬Â²&xï¿½Ã¯Â®8 Â³Â¹Ã­ynâ‚¬â€¦Ã¥t@Â¦Ãœ2\sÅ½sÅ¡Ã„f:,Ãªâ€¹axÃ¾)Â©Â¶Ã«io4Ã–="" â€ Â½Å“Ã®Ã˜ÃÂ²Ã­iÂ°ï¿½Ã‘Â­Ã«Å Ã="" Â¸pâ„¢sâ€˜kyÃ€sÂ£fÂ¹iÂ¨Â¶ÃÃµÂ¶}lâ€¹^Å½eâ€œewï¿½u[Âµ="" !ÃÂ»bÃ½tÂ»sâ€˜Â«bwsÃ°2â€š3ÃÃÃÃÃ¶Å’Â¯ÃµiÃ°"Æ’â€”ÃšÃ•Ã¬ËœÂ½Ã‰Â±bÂ»cbÂ·Æ’rÂ·Æ’bÃ—bÃ§bÃ·="" Â±Ã°ï¿½Â°ÃªÂ«yÂ·yÃµÃµÂ§Ã•Ã¬="" â‚¬qvÅ¡Â¬ï¿½ï¿½ÃµÂ¬Ãºâ€¹Â¬zÃ¿yu19Ã†z5Ã¬Ã”rÃ˜Ã¶Ã”ÃÃ¯sÂ®vvâ€ Â¯Ã‚uÃ„ï¿½Å¡eâ€¹opÃÅ Ã°ÃŠï¿½Ã¶Â¦Ã§:u7Ëœï¿½Ëœï¿½oÂ²(m'Â¦â€â€™Â¢jd5nâ€™j="" jf|m="">Ãµ@cÃ¥'KhÃ‘#bÃ¿Â¹nÃŸ)eï¿½Å Ã‹'Ã¤J)Yâ€™ÂªÃœ)%Ã¶Â¼:fe8vBâ€“Ã–]WÃœSâ€¡Ã¯kÃ„Ã·Â³Ã‹Â´4'$Â¥Ã‹Æ’sÂ¥ÃƒÃU Ã â„¢â€“ï¿½/Å¸-Â¼Â¾TpmÂ¡hÂ±â€¹&lt;#Â¡Mâ€¹Ã©s
ÃªÃº(Ã¡Ã†rÃ‘ÃµÃ…â€™Ã«KÃ…K]U3:Ã²WÃ•Ã“bÃªRÃ¡ÃªBÃâ€¢Â¹Ã¬ÂµÃ‘ÃœÂ±VÃ’pÃ˜Du3qÂ¨â€°Â°Ã]^ï¿½Ã¯fâ€¢Ãv&amp;Å¾Å ZÃ¬ï¿½Ã¤%Ë†F
ÃDÃ¤~Eâ€“â‚¬Å’Ã¸MÃˆ]Ãâ€˜QÃƒËœÃ¹8Å“JÃ¤%â€ â€“ENÃƒÃ°*\:XÃ hâ€ºÃ±+Ã­Kâ€œâ€¹Ã¢Ã€Ã¶ÃUï¿½WÆ’*xÂ©CÅ“LÃ¼Å’ÃƒÅ’â€ Å½M86ÃªlÃœÃ§XVÂ®Ã¸MXÃµï¿½&gt;^ÃÂ¬Ãº
Â£4vÃ’Â³Âª~Ã½â€ºÂ­WÂ³ÃªÃ¢+YÂµÂ»â€°Â¹tÃ•Ã›ÃµË†Ã“Ã§Ã‚NQÃOÂ»[Ã€â€“Â¨Ã­Ã»(wÃÃ¬ÃªÂ®â€ ÂºÃ”Ã¤Ã›Ã„Âºfâ€ {Ã§cÂ¼JÃ¬ï¿½ÃÂ©i*Â·-Å½â€¹"Â¥â€”'F7â€Ã¸(YÅ½<r@ul;Ã–!zÃ‹ÃŒoâ€˜Ã—fÅ’Ã‹Ã¼Ã¦z|Ã‡eÃï¿½Ãµ â€šÅ )%Â»Â­:gÂ®Â³Â¬â€°yÅ½â€¦ï¿½kÂ»ÃµÂ¶rjâ€ _Ã•Ã¤oÂ·fzÂ ÃÃ)â€°wÃ¦Â¶Ãµvnkâ€¦Ãƒ.vrÂ¶&Ã‹Ã?ÃµÃ¶Ãª|Ã‰Â¼â€š:#â€ ÃµÂ½sÂ¢Ãª="" ueÂ ="" Ã¨Ã­Ã¥Â³Ã™Â«Ãªm="" Â°ÃªmÃ…Â¶Ã6â€“ÂªÃªÃ±Â½ï¿½Ã…Â½qÃ‹ÃªÃˆâ€¦Â¾'Ã¨Â­Ã•[r&Â¿"sxâ€¢4*ÃµÅ¡ï¿½Â»Ã´Â·Â¸Ã³*Â£â„¢Ã¹iË†ÃbÃ¨9Â°cÅ â€Å qÃ¬:Ã«`cÂ»ÃŒâ€leq@oÃ·Å½â€ºâ€¡zÃ«oÂ¿k:ÂªÂ·~Ã†)Ã#Ë†ÃÅ½Ã®Ã¨Â­Å â€â€¡Ã´Â¿1vÃ•-ï¿½Ã–mv}ï¿½â€ â€¹Â½ÃÂªhÃƒÃ…Â®fu4.Â¬="" 4vÃÂªÃºÃµg[ÃyÃµoÃ»Ã©Ã«Â¯Ã¿)vÃ­(hÃ¬v;Ã”Ã¥}Â¸Ã‹Ã«Ã°â‚¬Ã¯â„¢Ã‡!Ã·3Ã¯yÅ¾zÃÃÃ Â Â£Ã¡!'Ã£#.ï¿½xï¿½#Ã„Ãº<Ã‡`oÅ“hr_d,Â­6â€¢Ãldsrâ€ yjï¿½="" Ã–Ã‡="">ÃÃÃ¤XgÃ‡)3Ã§â€YÂ´TXÃ–Ã¦[`ÃœsÂ£Â¼Ã³c|Å Ã¢Â¼Â©YÃÃ¼JÂ«â€“
Ã«â€“
â€ºÂ¢M+Ã‰Â¦Â®ÃˆÂ­*=%"EÃ‚Å’Ãœ0Nâ„¢Â§Ëœj'Â¯Â±TÃ–Å¡+j,Ã›hÃ¶Â²'Â·&lt;FÃ‘Â©-AmtWÃƒEÃ†pâ€¢3Ãœ5Â®Å ZW)Ã•â€ºÆ’OÃ¥â€“&amp;qÃ°i<blÃ|rqÃ¾Ã–mlÃ±vÃ¹Ã‹k\dtâ€”6Ã˜Ãm4')ÃÂ©â€¢Ã¤]wËœtwË†ebâ„¢Ãˆ5 Â´Å¡Ã‰ï¿½Â¡Ã§`hÃ™ÃÃ”â€”[Ã”ff7â€”3ÃŒ%Ã•â€“ÃzÅ½wyr`i|piÂ¼1Ã–Â¯0â€ Â¸9q="">â‚¬ÃÃ™xnÂ¹%Ã¸Ã˜Xb6Â§Ã”â€š]bVgâ€¦ÃµÂ±Ã…xmÂ·Â¦Ã®Â¢T[XÃ´^XOÃ‹Ã Ev5=Ãªh|Ã˜Ã†Ã°pÂ¾ÃµÂ¾Ã³{Â­ÃZÅ“ÃŸÃ£9Â¾Ã‡s=Â®Ã,Â«ÃªvdÃ¨vÃ€Ã­Ã§Â°wZ
Â¿Tï¿½QcÂ¥]1Â°Å¾U_Ã‚ÂªÃ“Ã/Â³ÂªË†Â¿iÂµÃ‡ÃÂ©Â»â€¹Â¡'9Å¾'Å“,NÃ»ÃšÅ“	Â°G=Ã`1pÃ„Å½Å Â«	Ã¾Å½INÃâ€¹ÃŠ4Â»Ã´PÃ·Â¬ZÂ®CrÃÃŸË†Â·*Å Æ’MÅ¡Â¥Ã±uEÅ¾Å¡5â€”Ã IJÃ…Ã’â€˜Å½*@Â¬5Â¹â€°Ãâ€Ã¨^Â®ÃÂ¤ÃœmÂ¬ÃSÃ•ÃŠ-ÃTÂ¦Ã±ÃŠsÃºÅ¡Ã£fÂ»BB&amp;dÂ±ÃÃµY
@ÃœÃ…,â€šÂ£Âµe~Ã¾\WÃšâ€4Â¿Â¯ÃeÃ…0Â¿Ã¼Ã¢XÃšÃ†TÃŠÃºdÃšÂ´Â¬Ã¦xd@&nbsp;gÃ›Ã±â€ºÃ“iÃ«â€œÃ©[Â³Â©â€¹ÂªÃ¼1AÃ¥Å¸4ÃŒÂ«{FQÂ¸6â€˜Â¸6Å¾pn yÂ°	Ã€)Ã˜Â¥}HÃˆâ€6Ëœw2Ã¥Ã•%ÃªÃ–Ã¸Ã™Ã®Ã Â³=Ã¾-1
4gï¿½`iDSIÂ¦Ë†5Ã€sÃ™wÃ”Â»sÃŠ"9	5y1Â´Ã¬hÂ´hÅ¸ËœÃ•LpjgÅ¡!Â¬jW
0Ã/	Å“Ã -Ã“Ã®Å’j(Ã’WÃ®kgbgÃÃ¯wtÃ„Ã¯Ã¨Ã˜&gt;GÃ•^GTÃ¹qoâ€“U_gÂ°Ã”Â«cÂ§Ã—,ÂµÃ·Å¾ÃŸÃ–Ã–VÃÂªÃºÃµÂ»^Ã»Â°Ãªâ€¦Ã¡Â¾Ã_`UÃ°FÃ‹Â©=Ã¯b1ÃªÃ­JÃ˜Â©Â¹ï¿½â€œ$Ã—â€œ.â€“Â§}aKâ€Ã€UÂ¤Ã˜lÃ—Ãµ Ã[â‚¬Â«Ã’jÂ³â€™â€¡Â´ÃÅ“(Ã·ÃºbxÃÂ­dZ0Ã­
bÃ‚	Â¸&lt;6Å SÃ®"Â¥Y7â€Ã¸â€œÃ“Ã¢Ã¨9Q5Ë†Ã2râ€œxâ€¢CÂ­Å¾â€œ
7Ã€}uâ€˜ÃebzkEÃ¶ï¿½ f^Ã´vDÃŸÃ‰ÃŒUÃ’ï¿½â€z[S&gt;"ÃŒ[PÂ¥Å½Â´Ã·7â€º*&amp;$Ã¸ÂµÃ±TÂ¨Â·iÃ£Ã‚Å Â½Â­\Ã¬.zÂ»1â€¢&gt;ÃwÅ½Ã°ÂªFÃ¹â€¢Ãƒ-Â¤&gt;qÂ®+Ã¨Ã­Ã…Ã‘Ã„UZ_}%&nbsp;` Â¶ZÂ·IÃ„@Â©HÃ‰(cÃ¦Tï¿½gÂ»Ã½TlÂ¬Â¸*S@ÃŠâ€oâ€4niÅ¡Â¤:\#tz+Â¯Ãµl(â€°aÃ¤Ã„Æ’ 
5Å“Â¬Jï¿½Â¨HÅ½â€™m:XÂ«â€“:ï¿½Â¨Â©Ã£â€”=v'wgTaÂ°Â´m8Ã©Â²m8Ã©cgËœÃ¤xzÃÃ¯Ã¨Â¨Ã¿Ã‘To=ï¿½tUÂ¾IVÃ•-~ï¿½Ã¡{Â§Æ’Ã©Ã–â€ºÂ¡zÂ«Ã›pÂ±kï¿½`U###=Â«ÃªÃ—gÃ­ÃÂªÃxeUÂµZâ€”UÃ¥;Â¬ÂªÃˆKPÂºTxâ€{ÃªÃ¶&gt;,r;Ã¨|Ã²mÃ“co[ï¿½|Ã‡Ã¦4 Ã–ï¿½XÂ»Ëœ&nbsp;UÃÃ‡aUÂ°Ãµ)â€º3ï¿½â€ oÃƒâ€Ã£Å’Ã“â€SÅ’Â§yÂ¤PÃ¨Ã§câ€º`â€”fâ€ºnÅ¸eÅ¸Ã©ï¿½ÃªÅ¡}Ã=â‚¬:Ã¥Ã‡Â¸â€”$Â¸â€¢$Â¸â€”&amp;zâ€%yâ€™Ã½Ã¹â€“%â€“%pAÃ„Ã¤ï¿½Å Ã¤Ã°ÃŠÃ”ÃÃªlÃ¿Å¡|_fÂ¡Â³Ã€Â¯&amp;/Ë†â€“Qï¿½â€°Â¡eÃ…Ã’sQF1Ã‚XÃ¡Â¬â€šË†ÂºBÂ¸Ã«â€¹Ã‚Ã«â€¹"â„¢Ã¹Â°Ã²â€Yx6Â®Â¾(ÂªÂ¡8|Â²Â¾&lt; Å¡USWÃ‰*GÂ¾0Å’YZâ€ºÅ½`)bï¿½Â®FiEÃ»Oâ€˜ÃšÃˆpbrDej05Ã“â€¡â€“Ã£IÃ‹Ã±Â¨ÃŠÃ°,Ã‡Ã¹@Ã·ÃŒswÃŸÃŸ$Ã·ÃŒâ€”Å“(Ã°L3ÃƒÃ­ÃOÂµM
Â±I
Â±Å Ã·â€¦Â¯I$RÃŠâ€š
/tJ=Æ’P*ÃŒÂ¥Âºâ€ºâ€ÃªlrÃ„Ã‘Ã¨ï¿½ï¿½ÃAÃ‹SÂ²-Ãmr|â€”Ã«Ã´.Ã›Ã¡]Â¶Ã½;Â§cÃ²7Ã‡ÂªÂ»`Tï¿½u`ÃÂªÃ‚Wï¿½kÃœoZï¿½â€“UÃ‘Xâ€ºÂ¯Ã‘Â³ÃªV]Å¸Ã–Â¨_ÃÂª2â€UgÃ‚-fï¿½Oï¿½ï¿½Ã“LÃâ€°:Ã·Ã£fÂ°DÃŸwÂ´XÂ»8oGÃ‘â€šâ€fÆ’pMqcÃ¤Ã™ÂªÃ˜Ã¦ï¿½uâ€,Ã»Â¼hhÃƒXÃšPÃ¢*Â¤XÃ•Ã¤{â€™b(aÃ  ÃÂ²ÃÃ§(FQÃ«Kâ€N=N	Å½[Å¡Ã’â€OSâ€ Eï¿½3ï¿½ÃÃ²Ã€NÂ¼ËœÅ“ÃŸFÃâ€œÃ“Ã²Å’|ÃŸÃŸÅ“6)ï¿½UÃ³3:kÃŠ`
â‚¬]Â¼Ã”ï¿½YÃ–DÅ¸Ã‚hZÃºQÃ¶$Â¨y%â€¹Â½â€°0_&nbsp;â€°YÃ¬ÃƒjÃ¸EÃ Ã³Ã oAËœ4*ÃŠ:7~n |Â¶3Â¦Â»Â®Â¤â€¹	Mâ€œ:kÃ›Ã¡Â¤chï¿½$Â§Ã§Å Ã‰J&amp;nDÃ¢BÂ»Ã¾	%ï¿½[Å¡Ã•\Å¾Ã’TÅ¡\_ï¿½ÃFÃ·Ã©kÂ¶Ã«Ã£ZÃˆÃï¿½RÂ³bÂµÂ­Ã¥â€¢Â©aÂ¥â€°MÃ¥Å½(Â«Ã²*lâ€˜Â»&amp;ÃŸÃœÂ´Ã§=ÂªhÃ Ã¤Â³câ‚¬â€ VÃ¬;Æ’Ã³Ã«ogÃ¨ms&amp;ÃˆÃ¦tÂ·74@SyQyÃ®Ãµ8Ãœâ„¢'Â«Â½ÃƒÃ Ã¿Ã±Ã—Â°Ãª~ÃSÂ¿XÂ«Ã¿Ã’Ã¦Â©WÃ—ÃªÃ¯Â½Ã§Ã—Â³Âª~Ã½ÃÃ—Â¾Â¬ÃšÃ»Ã‹Â¬ÃšÃ‰Â©ï¿½Ã·9&gt;t|*Ã¨Ã„BÃˆÃ‰Ã‰&nbsp;Ã§Ã£Å½Ã¦'Â½ï¿½Â³X`fÃ¬dÃ¶\oaÃ˜Ã«cÃ¯Ã«(Â§â€ºâ€”Ã„Ã›&amp;Ã¸Â¹gEÂ¸4Ã¢mâ‚¬ÃÃŠÃ¨â€“Â¤tÂ§ÃœÂ¨`|Â¼_alxKâ€¦C+Ã‰Å¡â€“Ã­Wï¿½â€¹Â¦dâ€#zMÃ‹Ã†Â²
Â£Â»ÃÃ”BÂ¨Â·Ã­Â¬@&gt;Ã¨-Â·4]JÃ‡Å½Ã‹|gÂºÂ¼Ã‡Ãšâ€š:Ã«pÃ¢Âª&lt;&nbsp;Â·
Â¨Â·mâ€R57Â­Ã„Ã´7Ã¥vÃ•â€“vÃ—Ã¡â€¡ZÃ²â€”Â¶Ãµvï¿½[Ã‰ï¿½Fâ€â€¹Ã½Ã±PoÃ•Ëœâ€¦ÃÃ¸ÃÂ¦R&nbsp;Â·Â½
@Å Ã±mÂ©@oÃ»#Â¦Ã˜vÂ¡â€¹Yâ€Ã¨mï¿½VoeÂ´\IU^G]Ã‚Â¸ÃœÃ¨Â­Å $$Ã¡Â¸eÃœÃ²&gt;Â¥Â±8YQÃ«&gt;Ã€Â³Ã©Ã¥ZÂ·TÃ€Â±YËœÃª,Jâ€˜Ã“Ã‚*SÃ‚Ã°	â€˜Â­$ÃˆÂª]uf
%Å½Ã¨Ã&gt;4Â¯Ã“5Ã¾}aÃ–Ã¼vÃ©Â¯Å½ÃxÃ™Å“â€°Â·?Ã•Æ’Ã¨mÂªÂ·Ã®â€¡;Ë†Â¹râ€¦RÂ®Ã¬PÃ¼jVÃo8ÂªÂ·ÂºÅ½Ã«Ã»
GÃ˜Â«Â·ÂºÅ½Ã«ÂºzÂ«:ï¿½Â²ÃªÂ©SÂ§Ã€Ã£ÃµÂ¬Âª_â€Â¥Ã‹Âª?Â¾ÃˆÂªÃ½Ã½Ã½[[[â€”/]Ã’Â¼ËœWâ€¢Ã‰d
â€UÂ¥Â¹Ã±Â§bÂ·Æ’`+&lt;ÂµÂ¸Â°?Ã¶gÂ£Ãƒoâ„¢Ã»Â³Ã…Ã±Â¿XÅ¾|Ã‡ÃºÃ”{vg8t2:xÃŠÃ•Ã´ËœÂ»Ã¹qÃ‹â€œÂ§ÃÃÃxXz[Ã»Ã˜ËœÃšâ€ºâ€šP9ÃœÃ•IÃ®XF{XGÂ¹Ã›E{8`Â¼Ã¢|Q{Ã’Ã¤`g MÂ©Ãn)ÃÅ¾Ã©Â¡^aÃYÃ¡Â¾Ã™â€˜Â¾Â¹Ã‘Â¾Ã¹ÃŸÃ‚XÃŸÂ¢8Â¿Â¬?&gt;&gt;Ã© Æ’nEÂ¥â€°Ã¡Ã¥â€°Ã¡â€Â¤`ÃƒHiÃÂ£â€°â€IJï¿½&amp;Â¥Ã†ï¿½Ã’bÃˆ`Â§cÂªÃ’1â€XpDl&nbsp;Ã¿â€LxÃ‡VeÃ„R2Ã _ï¿½]â€¦&lt;Å’Å’~IZ4Ã²"IKC+SBâ€°)Â¡Ã‰!\p9.Â¨,	Ã¸Ã€'cÆ’
0AÃ¹1ï¿½yÃ‘Â¹QÃ¾9Q~9QÃ9Q Â¬EmBÂ¡iRÂ°3Ã¢\Ã§â€ÃµqÅ ÃµvÅ’Ã±tÅ’Ã¶Â°â€¹tÂ³ï¿½pÂµ	uÂ¶sï¿½N,Ã›â€°TÃ„=Ã‰ÃÃ¦4â‚¬}@â‚¬RÃ¾Â»Ëœu2&gt;Ã¬`tÃˆÃÃ &nbsp;Ã­Ã©Ã·Â¬NÂ½kzÃ¬ï¿½TÂ³Â·Ã«Ã¬ÃŸiÂ°â€¡iÃ·Ã‹Ã¦mâ€“ÃƒQÂ¹Ã¨ÃÂ°ÃªÂ®Ã¸u:Ã ^=Â®q?AF^kc`â€Uï¿½?ÃÃ¥rÃµÂ¬ÃºÃÂ²ÂªBÃ„ÂµÃ·?6pl):Â­q=jkOÂ¢â€”Ã¥	Ã°Ã«Ã¤Â«Ã£ï¿½Â¶Ã£Â¶dï¿½Â¼Ã©Ã›ÂµTXP2-Ã¼Å“Ã’BaÃªÂ¿ï¿½cÃ‘FÂ·(Ã€Â¸fGÃºâ‚¬sWâ‚¬Ã±Ã§â€:Âµâ€™l+Ã“Â¼KÂ°Ã¡Ã„â€`pÃŠÃˆÃ©Ã¡Ã¤tGÃ…Â´â€™<zÃ˜v}ÃÃ–] Ãï¿½%Ã‘Â¬â€šÃ¤Ã†Ã¢dÅ“(â„¢ajÂ¡Ã«xâ€ºÃ d15Â©â€¢Ëœ#"eâ€¹Ãˆ9jÃ¶="" btÃ”Ã“Ë†kÂ£Ã‰iÃ¹Ã­ÂµÂ¹Ã“Ã­ÃgÂ»fÂ»â€šzâ€º2ÃškÅ ;kâ€¹;jkÂºxeÅ¡Ã–Ã„yuÃ€Ã™Â®Ã 9uÂ Å¡â€¡cfÃµâ€¢vÃ”="" 4'ÃvÃºÃtÃºÅ½jcÃ¤Ã´|Â¤="" }Ã‡Ã½Å’â€™%&gÅ hbÂ¿"Â£Â«!`hÃ Ã˜ÃŸÃ¢(Â¥ï¿½Å¸ÂªÂ¾(Â¹Â®0Â©Â¡Â£dÃšÂ©Ã˜2â€ m]q="" Â¢="" Â°3Â·2Ã°Â²Ã„ï¿½Â¢Â¸pvÂ©Æ’Â²Ã†nÃ5Â¥â€¡yi)uÃ‡ï¿½Ãvkâ‚¬{Â¦ï¿½Ã€iÃ‡ï¿½Ã­Å’Â§Ã•)Â«â€œ="" ÃÃƒ="Å¾â€¡Ã›ÃÃ¶8Ã”Ã¡vHâ„¢ï¿½Âº;ÃÂ«Ãªï¿½Ã«}Ã¬7Ã©ooÂ°Â®Ã‘Ã‡ÃÃ¦)Ã”XÃ·Å¾Â°*Ë†ï¿½lllÃ´Â¬Âª_Â¿Ã«ÃµkXÂµÆ’S;Ã¥ul<ï¿½ÃªÃ­TÃÃ±Ã¡â‚¬cxÃ‡Â£v&amp;Ã‡Ã-NxÃ©zN:â€¡ÃªÂ¸-Ã…xÂ¹Â°â€œ1ÃŒÃ‹qâ€“Â±^Â®Â¹Ã‘Ã¶Â¼JÃ˜Ã¥Ã”JÂ²ÃŠï¿½qÃ‹Å½Ã°ÃCÃ´V@Â¶k*Â·Â¯HÃ¶ÃƒÃ‡â€!Â¥â€ ÃÃ«Ã±tÂ¢HiÃ*Ã”[EÂ­ÃÂ±ÂºBÂ¢Â·)]ï¿½Â¾Ãƒbâ€”1Â©K'DDIÃ‘ÃªÂ­â€â€™=," â€˜uÂ°Ã’eÃ”b9Â­Â Â»!cÂº#Ã•Ã›Â®ÃºÃœÂ Â·ÃŒÂ¢Å½z|w}Ã¾Â¨8Ã•Ã›yuÃ ï¿½7Â­Â£Â¶Ã¨mgmÂ¡Å¡Ã´vÂºÃo#Å’ï¿½tâ€¢ÃˆÂ«Ã³Â ÃrwÃœ&ÂµzkÃŒp5yâ€Ã®Ã£:â€°ÂªÃ‚Å â€œÃ«Ã |Ã¹dnidwÂ½â€¢Å c!Â­Â¶Â­Ã‰Â£d@ï¿½g(5Â´ÃµÂ¶0.â€_iÃ“Ãâ€z[wlÅ¸Ã¥Â¥Â«Â·Â¸@Â§Ãº,t="" 'Âµ!â€œï¿½ÃiÃ‹sÂ±Â¶'â‚¬Ã’Âª<+Â½Ã­t="Â¤Â¬â‚¬Â¬ÂªhÃ¯PÃˆÃ¥Â¿Å¾UuÃ—_sÂ²Ãª.Ã‡ÃµÃ—iVEMÃ—QV577Ã—Â³Âª~Ã½Â¡Ã–.VÃ½aâ€¡UAÃ”Ã›Ã—Ã—Â·Â¹ÂµuÃ¥Ã²eâ€UÃ›ÃšÃštYË†Â³(Ã‹Â·ï¿½Ã¯Ã²ÃÃ¥â‚¬Ã„Ã­" Ã›Ã©="Â»Â£oÃºâ€œÃ‰Ã¡?â„¢yÃ‹Ã´Ã¨Å¸Ãï¿½Ã½Ã…Ã²Ã¸Ã›Ã–'ÃŸ$ef;ÃÃªÅ’Â¤Y=-Å½{[Â¡Ã’}ÃšÃŸÃ®ÃŒÃ}#Ãª?`Ã©nâ€ ÃŒÃ›5vÃªdÃ¬Ã¬qï¿½)!Å½)!NÃ©Â¡ÃÃ©aÃÃ¡pÂ¾ï¿½Ã€Å“HÃÃœ(Â¯Â¼hÃ¯|8hÃƒÂ»0Ã–Â»(ÃÂ§8ÃÂ·Ã«[Ã¯Ã Â±Ã¬Ã„Ã€Â²D8Â¼" lÃaÃ‰`wÃ€Å“,ÂºÃÅ¸Æ’â€°Ãˆgd#Ã€Ã â€ _rÅ¾;gÃ‹p&Ã…Ã‡Ã»#5Â½Â°ÃŸÂ¿(pÂ³o="">bÂ¥Å¾Ã£â€¢
~*ï¿½Ã¬Ã·Â¬pÂ·ÃŒpÃ—Ã´0Ã¨Ã¨â€¹Ã†Â´IHâ€¢ Ã¢
â€¢6ÃÃ›
qHÂ¶Å’Ã²0Ã=Ã‚Ã•4ÃŒÃ™$Ã„^Ã˜Ã¸#MÂ©^VÂ§Ãr_HÂ©&amp;G Â¥Â²;sÃ€Ã¦Ã”{V'ÃŸÂµ&lt;Ã±Â¶Ã™Â±Â¿Ã¾sÂ¢Ã±Å¸Ã©6oÃ—Ã˜Â¾MÂ³yâ€ºfÃ½ÂºÃaâ„¢HÃÃÃ™Â¥Ã¼uÂ¬ÂºÅ¸[Ã‹?Â¿Zï¿½ÂµÃ†JÃšÃÃ—MÃ–Â³ÃªÂ¿ÃˆÂªBÂ¾:Ã˜\Ã£Ã‹Mâ€¡Ã½Ã¡Ã‡jÃ§#VG^Â¨vÂ°9Ã­gk&nbsp;Ã£ï¿½Ã¡jÃ¦lÃB4oÂ®0Ã'YUÂ¦[+jÃŒTï¿½â€“ÃµÃ…â€°Ã¾Å¾Ã°Â²Ã…Â«Ã§ÃšJÂ¶VÃ™P2ÃœÃ€Ã€Ã‡ï¿½Ãƒâ€¦GÂ£fÃ³*Å“Ã“uÃ–â„¢Â·3Â­â€º	Å¾Â´Ã¬xX'Å¸â€ºÃ„Ã†G)â„¢Æ’&lt;Ã›Å¾}WÆ’â€¡ï¿½Ã“Zâ„¢(Â¢`Â»Ã¼G%.C9#NPâ€˜+Â¡Â¤Â¶Â³Ã¢F$cmncR;FÃHmÂ£fK)yRjÂ®Â²6
|rÂ¼ÃcBÃ¦Â®Ã¸wÂ°â€™Â¤Ã”9#Â­Â·)lTÃª:"qjÃµPÃ”bÂ¥â€aeF+â€“Â¶ÃÃÅ¡Ã‹â€œÂ¹eIï¿½Ã…Ã©Â¼Å ÃˆvÃ¬mogÃ™Ã²*Â½Ã«
Â£Ã«â€¹Ã‚Dâ€ºÃ:â€¹â€“Â»Ã”Â£*=Å’ËœÃ›rÂ¡Z`1xvIÂ¾â€¢i^&lt;Â¢M;x^,3Ã™Â²"Ã…1'Ãš59ÃˆDMÂ¨Ã–gWÅ“P4?hâ‚¬vÃ„Â«Â®Ã¦'Â¼-Å½â€¹Ã*ÃÂµï¿½Ã­vÂ°ÃÃ¥â‚¬,Â£PÃˆâ€¢]Â¿Â«Â¾Â¢=ÂªÂºÂµÃºÂºÃ“jtkÃµuÃ’Â´Â±â€œÅ¾UÃµÃ«ÃŸoÃ½VmgÃ—Å½xUÃ»BÂ¥Â¸:Ã wÂ´ÃÃ®Ë†ï¿½!Ã”[xQoÂ¡SÃÂ²Ã£Ã ï¿½Ã¨-ï¿½kyï¿½9Â»Ã”Â¤ Ãâ€ Å¾gÃ™Ã2BDÃÂµÃ‚xfF@Â½%Â¦:Â·Ã‘Â¬Z*Ã¬Hi%Ã°N&gt;zNÂ½M	Â£eâ€°ÃˆvHÂ½â€¡Â¹Å“aÃ‹)Ã³Â£Ã§`kÃ³Ã£jrqÅ“Â²Ë†Â®â€”AÂ¾Ã­@â€¹};Ã‹GPÃ´VBï¿½Uq|Ã†eN<o)' Ã¦hÂ«sÂºÂ¢ÂµzÃ›Ã•â‚¬â€¢Ã“Ã“!u"zÃ›yÅ¸8Ã–Ã¦1.Ã³Ëœï¿½Â»="" Âµ*krÂ¥â€emrs0ÃÃ›aâ€°Ã«ï¿½ÃÂ§ï¿½Å½â€œtÂ¥="" Â ÃÂ¦Â½Ã¥Ã­Ã¨msÂ fÂ Ã€a]="" ÃfÂ¾Ã†Â¾â„¢Ã Ã´â€“ï¿½â€™t[w7â‚¬Â§iywÃ¨mjbnl)Ã‡Æ’ÃˆÂª$="">Â°Ã§KJÃ·UYâ€šÃ§Ã´â€“[nUâ€“Ã¤â€â€°ÃªÃ­vÃ¸â€ºÂ¤ï¿½tÃªÃ³Âº_c]ÃƒIOÃ‹â€œ.Ã¦'Â¢Â¬Å½IÃœJâ€¢Âºâ€™Â½u&gt; Â¯Ãˆ2Â«|Â£Â¬ÃºÅ i5Â¯Ã™pÂ¡Ã•Ã›Â½Ã€zVÃ•Â¯?Ã¸zÂ«Ã¶Ã¶Ãµmll\Â¾|yxxx/Â«ÃŠÃ›ÃšÃ™XÅ½Ã­;Â§wÃÃ¦Â»`9Â¾kwlâ€ºUÂ·Ã·Â¡?â„¢~Ã‹Ã¬(â€™f=Ã±Å½ÃµÂ©w!Â´â€ÃjtË†â€“Âµ9â€[Â·}Æ’C Â·Å¡â€š`â€ÃQÃ®ÃˆÃ#:Ã«XÂ¬Â¯Ã­6ÂºÃº;â‚¬Ã¤â€â€šf]C]Ã“Ã‚ÃœÃ’aÃ0Ã€CÃ·lÃ„&gt;'ÃŠ372,Å“Â¾AÂ²lâ€¢Ã›Ã™Ã˜Ã­ï¿½â€¦Æ’9ï¿½Ã­_â€â€¦Ã¬â€°Ã¼~}@aÅ“_Ã¡ÃWï¿½Ã¯Â¾Ã¸nâ€œÂ¢Â½Ãâ€™.;Ã’#+Ã‚â€¦</o)'></zÃ¸v}Ã­Ã¶]></blÃ½|rqÃ¾Ã¶mlÃ±vÃ¹Ã«k\dtâ€”6Ã¸Ã®m4')Ã­Â©â€¢Ã¤]wËœtwË†ebâ„¢Ã¨5></r@ul;Ã¶!zÃ«Ã¬oâ€˜Ã—fÅ“Ã«Ã¼Ã¦z|Ã§eÃ¡ï¿½Ãµ></iuxÃ—k-pÃ²Ë†Ã¬â€¡Ã¡â€šÂ¿ÃµÃ¨Â®h%fhÂ­Ã¤Ã¼vÂ¨zÃ <"â€ â€“Â§jï¿½[g]â‚¬Â²&xï¿½Ã¯Â®8></urâ€“ÃŸ[_></iuÅ¾Ë†\Â¤`dï¿½hbg$â€˜2*^Ã©(pÃ°jâ€ â€¦â€°s=!Ã³Â½!Ã£mÃ±ï¿½ÂµÂ¥Ã°Â´Ã¨'aÃ­o?Ã»Â±Ã¸Â²Ã°:Â¥Ë†Ã«Â©(zÃ°sw4Â¥,0ÃµÃ²Ã—â€â€š|Ã¿<Ã¹ÃªhÂ¹mÃ¨dfiuâ€“Ëœâ€%$e*j1â‚¬Â£â€¡eÅ¾]></wÂ¥â€¡sÃ¢Â©Ã¹Å¡Å¡mv%Â¥yÃ¤Ã§Ã ï¿½ÂªÂºÂ½o></eÂº=Â«ï¿½qÃ´></yrÃ¯Âª;yÃµgh^uzxx,vÂ½{Ã§Ã®Ã¢kyÂµÂ£Â«cÃ¤Â¿â€œdÃ¿ï¿½â„¢Ã·Ã·0Ã¾Ã¨^Å“qgÂ°â€˜â€”Ã£Â¶Â·ÃºtÃ¾Ã¹asyâ‚¬#xÂ¯gÂ½></s-Ã¼Ã¬(ÂµpÃ¾Â°Ãª?[oÂ¶Â·yÃµÃµfÂ¨Ã©:Ã°[â€umllï¿½Â«â€šÃ«yuÂ¿Ã¾Ã«_fuÂ¹Â¬mÂ¤4y9Ã¨Ã¤r(Ã¼kÃ¡Â§Â§â€šodÃ¸Å¾Ã¶Â´></ziÃ»Ã¶iÃ—Â³gÃª></u></a></i></u></i></u></s></b></s></i></b></b></i></s></i></b></b></s></i></i></s></i></i></i></i></i></s></b></i></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf">https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</a></em></p>]]>
            </description>
            <link>https://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693589</guid>
            <pubDate>Tue, 06 Oct 2020 00:17:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical guide to SAML security vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24693133">thread link</a>) | @duckduckwut
<br/>
October 5, 2020 | https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns | <a href="https://web.archive.org/web/*/https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><p>If youâ€™re here, youâ€™ve likely been tasked with building SAML-based SSO as a requirement for an enterprise deal. If youâ€™re just diving into the problem space of SSO / SAML, weâ€™d first suggest checking out <a href="https://workos.com/blog/the-developers-guide-to-sso">The Developerâ€™s Guide to SSO</a>. Otherwise, buckle up for a brief but titillating foray into why XML-based authentication is... challenging.</p><h2>Why is SAML SSO so vulnerability-prone</h2><p>The attack surface for SAML authentication is extensive, mostly due to the fact that SAML is XML-based. <a href="https://everypageispageone.com/2016/01/28/why-does-xml-suck/">XML is a semantic-free meta-language</a> - itâ€™s hard to form, hard to read, and hard to parse. Combined with the high complexity of the <a href="http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.pdf">SAML specification</a> and the number of parties involved in establishing authentication, we get what often feels like a <a href="http://www.laputan.org/mud/mud.html">big ball of mud</a> and all the accompanying implications. Be prepared to tackle a steep learning curve, lots of bugs, high maintenance costs, attack vectors galore, and an absurd spread of edge cases.</p><p>Most SAML SSO security vulnerabilities are introduced by Service Providers (SPs) improperly validating and processing SAML responses received from Identity Providers (IdPs). This happens because SAML SSO is typically not a core-value feature for an application, nor is the implementation common knowledge for most developers. Unknowns become even more unlikely to be identified and addressed when the pressure is on to just deliver <em>something </em>to unblock a high-value contract - as is oftentimes the case. However, to build SAML SSO safely and securely in-house requires significant buy-in and <a href="https://stackoverflow.blog/2019/07/11/single-sign-on-sso-stack-overflow-okta-integration/">investment by teams</a> - on the scale of months, representing hundreds of thousands of dollars in developer time.<strong>â€</strong></p><p><strong>If not done right, you expose your application and your customers to potentially huge security risks. </strong>To drive that home, here are just a few recently published SAML-related vulnerabilities:</p><ul role="list"><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2019-15585">January 27, 2020</a> - â€œ... GitLab SAML integration had a validation issue that permitted an attacker to takeover another user's account.â€</li><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-4427">May 7, 2020</a> - â€œ... an attacker could exploit this [SAML] vulnerability to bypass the authentication process and gain full administrative access to the system [IBM Data Risk Manager].â€</li><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2018-21263">June 19, 2020</a> - â€œAn attacker could authenticate to a different user's [Mattermost] account via a crafted SAML response.â€</li><li><a href="https://nvd.nist.gov/vuln/detail/CVE-2020-2021">June 29, 2020</a> - â€œ... improper verification of signatures in PAN-OS SAML authentication enables an unauthenticated network-based attacker to access protected resources.â€</li></ul><p>It should be evident by now that oversights in SAML implementations are ubiquitous and problematic, even among experienced engineering teams.</p><p>So letâ€™s dive into some of the more common security pitfalls developers building SAML-based SSO should be aware of, as well as cover a few suggested countermeasures. Just to be clear, <strong>this guide is by no means comprehensive</strong> and is meant to provide a starting point for SAML security considerations as well as some follow-on resources.</p><h2>Brief anatomy of a SAML response</h2><p>Let's say we're integrating our application with Okta via SAML. Below is an example of an XML document we might get when attempting to authenticate a user, containing a simplified but valid SAML response:</p><p>Like we mentioned earlier, the SAML spec is complex and responses can get lengthy, so this example is comparatively quite terse. Keeping things to what you should know before we go into SAML vulnerabilities, letâ€™s walk through what the response (<strong><em>&lt;saml2p:Response&gt;</em></strong>) is communicating:<br></p><ul role="list"><li>Line 2 begins the SAML response, which has the unique ID <strong><em>id72697176167120131651975993</em></strong> and is intended for consumption by the <strong><em>workos-test</em></strong> service providerâ€™s Assertion Consumer Service (ACS) URL, i.e. the endpoint <strong><em>https://api.workos-test.com/auth/okta/callback</em></strong>.</li><li>Line 3 specifies the issuer (<strong><em>&lt;saml2:Issuer&gt;</em></strong>) and contains the unique URI (also referred to as EntityID) of the IdP that issued the response, in this case <strong><em>http://www.okta.com/exk1klancwHzz1SNi357.</em></strong></li><li>Line 7 begins the assertion (<strong><em>&lt;saml2:Assertion&gt;</em></strong>) with the unique ID <strong><em>id7269717616793800631152500</em></strong>. An assertion is a package of information asserting the identity of a user, often containing additional user attributes like first / last name, email, ID, etc.</li><li>Line 8 specifies the issuer of the assertion itself, in this case also <strong><em>http://www.okta.com/exk1klancwHzz1SNi357</em></strong>.</li><li>Lines 9 - 30 contains the digital signature (<strong><em>&lt;ds:Signature&gt;</em></strong>) over the assertion, which should be validated to determine the authenticity of the assertion.</li><li>Lines 31 - 36 specify the subject (<strong><em>&lt;saml2:Subject&gt;</em></strong>) of the assertion, i.e. the authenticated principal / user corresponding to the unique identifier found in <strong><em>&lt;saml2:NameID&gt;</em></strong>, who in this case is <strong><em><a href="https://workos.com/cdn-cgi/l/email-protection" data-cfemail="0c686961634c7b637e67637f216367786d226f6361">[email&nbsp;protected]</a></em></strong>.</li><li>Line 37 (<strong><em>&lt;saml2:Conditions&gt;</em></strong>) defines the window of time for which the assertion should considered valid, i.e. from <strong><em>NotBefore</em></strong> (inclusive) to <strong><em>NotOnOrAfter</em></strong> (exclusive).</li></ul><p>For the purposes of readability, the SAML 2.0 XML snippets in the remainder of this blog will be simplified, use shorthand, and be stripped of nodes that would otherwise be required in reality but are not relevant to whatâ€™s being illustrated. Weâ€™ll use a mythical IssueTracker, ContractManager, and PayrollService as hypothetical SPs that have implemented SAML authentication, which you should think of as placeholders for your application or other SAML SSO-enabled apps.</p><h2>Disable DTD processing</h2><p>The first step in processing a SAML response is parsing the payload. Parsing and loading an XML document into memory is an inherently expensive set of operations, but can be unexpectedly costly due to a feature of XML that allows references to external or remote documents, i.e. <a href="https://en.wikipedia.org/wiki/Document_type_definition">Document Type Definitions</a> (DTDs).</p><p>When a DTD is encountered, parsers will try to fetch and load the referenced document as well. If the referenced document is large enough or results in infinitely looping references, your server can be slowed or even brought down trying to complete the process. The same holds true if the payload itself is very large, DTDs or not.</p><p>Two low-hanging mitigations you should implement to prevent buffer overflows are:<br></p><ol role="list"><li>Limiting SAML payload size to &lt; 1MB. 1MB is a generous upper limit and should be tuned down based on average received payload size.</li><li>Configuring your XML parser to never fetch remote files or try to load and parse DTDs. Some XML parsers do so by default, for example, Pythonâ€™s <a href="https://docs.python.org/3/library/xml.etree.elementtree.html"><strong><em>xml.etree.ElementTree</em></strong></a> module.</li></ol><p>XML processing, and thus by extension SAML response processing, is vulnerable to buffer overflow attacks from other scenarios described later on in this post. And unfortunately, protecting your application from a service outage is among the most mild of outcomes compared to the <a href="https://www.vsecurity.com//download/papers/XMLDTDEntityAttacks.pdf">possibilities exploiting XML DTD</a> allows - it is a dark and anxiety-inducing rabbit hole.</p><p>So, if youâ€™re not writing your own XML parser (generally not suggested), itâ€™s important to <strong>vet the XML parser(s) your application and its dependencies use</strong> - ensure they handle other exploits like <a href="https://en.wikipedia.org/wiki/Billion_laughs_attack">Billion Laughs</a> and <a href="https://en.wikipedia.org/wiki/Zip_bomb">Zip Bombs</a>.</p><h2>Validate the SAML response schema first<br></h2><p>The primary security mechanism in the SAML handshake is the cryptographic validation of <a href="https://en.wikipedia.org/wiki/XML_Signature">XML Signatures</a> (XML-DSig) - which establishes the trust chain between IdPs and SPs. XML-DSig validation should always be done prior to executing business logic; however, the separation between signature verification and operating on the rest of a SAML payload opens up SAML authentication to vulnerabilities exposed by what are called XML Signature Wrapping (XSW) attacks. &nbsp;These attacks have numerous permutations which can result in outcomes such as (but not limited to):<br></p><ul role="list"><li>Denial-of-service by inserting arbitrary elements that lead to buffer overflows.</li><li>Escalating permissions by injecting assertions that allow an adversary to impersonate and be authenticated as another user, like an account admin.</li></ul><p>The exploit here consists of modifying the payload without invalidating any signatures - think <a href="https://owasp.org/www-community/attacks/SQL_Injection">SQL Injection</a> or <a href="https://owasp.org/www-community/attacks/xss/">Cross Site Scripting,</a> but for for XML.</p><p>Original response (pre-XSW):</p><p>Modified response (post-XSW):</p><p>The broadest countermeasure to XSW attacks is <strong>validating the schema</strong> of the SAML XML document. Payloads for SAML responses of any given IdP should have a deterministic standard schema that can be used as a reference in a schema compliance validation module, which should be executed prior to XML-DSig verification. Here are <a href="https://github.com/onelogin/python3-saml/tree/master/src/onelogin/saml2/schemas">example schemas</a> used by OneLoginâ€™s <strong><em>python3-saml</em></strong> package to perform <a href="https://pythonhosted.org/python-saml/library/saml2.html#saml2.utils.OneLogin_Saml2_Utils.validate_xml">XML schema validation</a>. <strong>Schemas should be vetted local copies</strong> as opposed to being fetched from 3rd party remote locations at runtime or on server start.</p><p>All of that being said, <a href="https://www.nds.ruhr-uni-bochum.de/media/nds/veroeffentlichungen/2013/03/25/paper.pdf">schema validation isnâ€™t foolproof</a>; there is room for error in the validation module logic itself, as well as in the syntactic rigor of the reference schema. A second low-hanging countermeasure to XSW attacks that should be employed for the sake of redundancy is to <strong>always use absolute XPath expressions</strong> to select elements in processes post-schema validation. Explicit absolute XPath expressions set an unambiguous expectation for the location of elements.</p><p>Hereâ€™s an example of a valid response thatâ€™s been modified in an XSW attack (specifically a signature exclusion attack, more on that later):</p><p>This modification also exploits the common, incorrect, but not unreasonable assumption that a well-formed SAML response will only ever have a single assertion. So while XML-DSig verification would succeed for the signature returned by <strong><em>doc.getElementsByTagName(â€œSignatureâ€)[0]</em></strong>, the assertion returned and processed by <strong><em>doc.getElementsByTagName(â€œAssertionâ€)[0]</em></strong> would be the injected <strong><em>snek</em></strong> assertion. This attack would have been more likely to fail if the XPath expression&nbsp;<strong><em>â€œ/Response/Assertion[0]/Signatureâ€</em></strong> was used in the assertion signature validation logic.</p><h2>Check that youâ€™re the intended recipient</h2><p>This sounds obvious, but make sure to check that a SAML response is intended for your app. This is low-hanging fruit that can prevent attacks exploiting IdPs that use a shared private signing key for all integrated SPs of a given tenant, as opposed to issuing unique keys per application. The most common attack entails the â€¦</p></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns">https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns</a></em></p>]]>
            </description>
            <link>https://workos.com/blog/fun-with-saml-sso-vulnerabilities-and-footguns</link>
            <guid isPermaLink="false">hacker-news-small-sites-24693133</guid>
            <pubDate>Mon, 05 Oct 2020 23:20:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Observer Effect: Daniel Ek]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24691710">thread link</a>) | @jger15
<br/>
October 5, 2020 | https://www.theobservereffect.org/daniel.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/daniel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the second interview on 'The Observer Effect'. We are lucky to have one
									of the most influential founders/CEOs in technology and media - Daniel Ek, Founder
									and CEO of Spotify. This interview was published on 4th October, 2020.

							</em></p><p><em>Daniel does things very differently from other business leaders and was generous to go
								deep with us on his leadership style, time management, decision making, Spotify's impact
								on the world and much, much more. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Letâ€™s start with the basics. Walk me through a typical day in the life of
										Daniel Ek.</strong></em>
							</p><p><strong>Daniel Ek</strong><br>
								So, this will sound incredibly lazy compared to some leaders. I wake up at around 6:30
								in the morning and spend some time with my kids and wife. At 7:30, I go work out. At
								8:30, I go for a walk â€“ even in the winter. Iâ€™ve found this is often where I do my best
								thinking. At 9:30, I read for thirty minutes to an hour. Sometimes I read the news, but
								youâ€™ll also find an ever-rotating stack of books in my office, next to my bed, on tables
								around the house. Books on history, leadership, biographies. Itâ€™s a pretty eclectic mix
								â€“ much like my taste in music. Finally, my â€œworkâ€ day really starts at 10:30.
							</p><p>
								Many people make big decisions early on in the day, I make them later in the day--at
								least later in the day here in Europe. Ironically, it's not actually because I'm more
								productive then, rather because we have so many of our staff in the US, and as a result,
								I've kind of primed myself to work that way.
							</p><p>
								So the earlier part of my day is focused on coaching, one-on-ones, and planning. Then, I
								typically tackle one topic a day which takes a lot of my time. That's my big thing for
								the day. Before we go into a live team discussion on that particular topic, I invest
								time to prepare beforehand â€“ reading and talking to members of the team who are either
								part of the decision-making process or who have insights and context. I sometimes even
								get external perspectives.
							</p><p>
								I also think about what my role is at that meeting. Sometimes I'm the approver. Other
								times, I'm supposed to come with a thoughtful perspective on whether an initiative makes
								sense or not.
							</p><p>
								Iâ€™ve found that creating this clarity of role for myself is critical. Itâ€™s something I
								challenge my direct reports to think about as they engage with their own teams. I remind
								them that all meetings are not the same. Even when we are meeting to discuss really,
								really complicated topics I always ask myself: â€œWhat am I going to do in this meeting?
								What does my involvement really need to be?â€
							</p><p>
								The truth is: it's entirely contextual. I find it crucial to be upfront about everyoneâ€™s
								role in different meetings, I think this is super, super important. Often that's my
								number one thing: to make sure I know what role I'm playing.</p><p>
								<b><i>Wow, okay, there are multiple things in there ranging from how you choose to spend
										your time to how you handle meetings. To work backwards, what makes a good
										meeting in your mind?
									</i></b></p><p>A great meeting has three key elements: the desired outcome of the meeting is clear ahead
								of time; the various options are clear, ideally ahead of time; and the roles of the
								participants are clear at the time.
							</p><p>
								I often find that meetings lack one of those elements. Sometimes they lack all those,
								which is when you have to say, â€œThis is a horrible meeting, let's end it and regroup so
								it can be more effective for everyone.â€
							</p><p>
								To clarify outcomes, options, and roles ahead of time, we sometimes rely upon a preread.
								Prereads are a great way to share context so that attendees can quickly get into the
								meat of the issue and not waste time getting everyone up to speed. What I find is when
								you use a tool like a Google Doc, you can take in a great deal of information by reading
								comments, assessing options, and understanding how opinions have evolved over time. With
								this uniform background and context, attendees can focus on discussing the matter at
								hand versus getting on the same page. When the latter happens, the meeting becomes an
								incredible waste of time.
							</p><p>
								I think that's the single largest source of optimization for a company: the makeup of
								their meetings. To be clear, it's not about fewer meetings because meetings serve a
								purpose. Rather, itâ€™s key to improve the meetings, themselves. A lot of my efforts focus
								on teaching people this framework. Ironically, I find that most people are just
								challenged by that stuff.
							</p><p>
								Candidly, thatâ€™s my role as leader: to coach others on how best to make use of their
								limited time. Not only is time the most precious resource the company has, itâ€™s also the
								most precious resource they have! Itâ€™s crucial that they approach the use of their time
								with a holistic perspective. By way of example, I had a recent call with one of my
								directors who had not taken a vacation in six months. Our conversation delved into why
								this person thought that they could not be away for two weeks, and me arguing for why
								the person had to take two weeks to recharge!
							</p><p>
								There is never enough time â€“ for work, for family and friends â€“ and it takes work to
								make the best use of it. It's all about fostering a holistic perspective in life.

							</p><p>
								<b><i>
										Thatâ€™s fascinating. Letâ€™s turn to your team.

										Your direct reports are highly accomplished people; what are the common mistakes
										you see executives at that level make when it comes to personal time management?
									</i>
							</b></p><div>
							<div><p>
								I donâ€™t think most executives dedicate enough time to thinking. They spend too much time
								in meetings. By the way, I will say as a caveat, I do know people who are incredibly
								organized and succeed with a lot of â€œdo time.â€ Shishir Mehrotra [Co-founder and CEO of
								Coda] is a great example. If you've seen the docs on how he organizes his time...
								</p><p>

								<b><i>Oh yeah, he has a lot of very well-organized docs! [laughs]</i></b></p></div><p>
								He is a source of inspiration. For a while, I tried to mimic his style because I was so
								impressed with his thinking behind it. But in the end, it just wasnâ€™t for me. It
								actually drove me nuts. <i>[Sriram laughs]</i>
								But I respect him. I would say he's a highly effective executive. His system works for
								him. It's not one size fits all. Some of my direct reports thrive on lots of meetings.
								But, in general, I would say the largest mistake is that they conflate meetings with
								productivity. Often fewer meetings and better decisions drive the business forward.

							</p>
							<h2 id="opencalendar"><b>On Creating an Open Calendar</b></h2>
							<p>


								<b><i>This dovetails nicely with something that fascinates many of your colleagues: how
										do you have so much open time on your calendar?

										This drastically differs from your typical â€œsuccessful CEOâ€ who is booked from
										8:30am to 6pm. Walk us through your calendar and how you manage to create this
										open space.
									</i></b>

							</p>

							<p>

								My friends know me well! I do keep a lot of open time. I understand this comes from a
								place of privilege and Iâ€™m very lucky to have this flexibility.
							</p>
							<p>

								I feel like synchronous time is very costly; asynchronous time is better. I know there
								are some leaders who prefer to have all executive decisions travel through them. But
								then, you have to wait until the leader has availability to review things. Sometimes you
								run into delays in that process.
							</p>
							<p>
								I typically don't have more than really three or four meetings per day. There are
								exceptions; when I travel, I book in a lot more and I don't keep to my normal schedule.
								That said, most of the time it's three or four meetings a day.

							</p>
							<p>
								My way is to plan long term and do so ahead of time so that people better understand the
								direction in which they're going. You have to be incredibly crisp and clear when doing
								that. For instance, right now we're finalizing our five year plans and long range
								planning. These are actual, real targets fueled by real insights. They are made up of
								lots of super-detailed quarterly and annual goals. I donâ€™t spend much time on the
								quarterly goals and instead focus on our so-called â€œbig rocks.â€
							</p>


							<h2 id="bets"><b>On Company Bets</b></h2>
							<p>
								At Spotify, we have something called â€œCompany Bets.â€ These are large-scale initiatives
								that we believe will have a significant impact on the business within a relatively short
								period of time. I find that these bets are a much better use of my time. Our Company
								Bets typically update every six months, so I'm not needed that much in between. This
								way, I can constantly be thinking: â€œWhere are we headed in the next six months?â€ Right
								now, I am thinking more about H2 2021. From a timeline perspective, that's the earliest
								place where I focus most of my time.
							</p>
							<p>
								Itâ€™s also my role to think far beyond that. For instance, Iâ€™m immersing myself in our
								2025 plans. I trust my team to manage the day-to-day, shorter-term initiatives and
								iterate as needed based on data and insights. Theyâ€™re the best at that and I appreciate
								that this then frees me up to think about the long term.
							</p>

							<h2 id="decisionmaking"><b>On Delegated Decision Making<br></b></h2>
							<p>
								<b><i>
										Your system reminds me of Jack [Dorsey] at Twitter a â€¦</i></b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/daniel.html">https://www.theobservereffect.org/daniel.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/daniel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24691710</guid>
            <pubDate>Mon, 05 Oct 2020 20:33:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[.NET Orleans]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 222 (<a href="https://news.ycombinator.com/item?id=24691500">thread link</a>) | @swyx
<br/>
October 5, 2020 | http://dotnet.github.io/orleans/ | <a href="https://web.archive.org/web/*/http://dotnet.github.io/orleans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <div>
          <div>
            <article id="_content" data-uid="">

<p>
  <img src="https://raw.githubusercontent.com/dotnet/orleans/gh-pages/assets/logo_full.png" alt="Orleans logo" width="600px">
</p><p><a href="http://www.nuget.org/profiles/Orleans"><img src="https://img.shields.io/nuget/v/Microsoft.Orleans.Core.svg?style=flat" alt="NuGet"></a>
<a href="https://gitter.im/dotnet/orleans?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge"><img src="https://badges.gitter.im/Join%20Chat.svg" alt="Gitter"></a></p>
<h3 id="orleans-is-a-cross-platform-framework-for-building-robust-scalable-distributed-applications">Orleans is a cross-platform framework for building robust, scalable distributed applications</h3>
<p>Orleans builds on the developer productivity of .NET and brings it to the world of distributed applications, such as cloud services. Orleans scales from a single on-premises server to globally distributed, highly-available applications in the cloud.</p>
<p>Orleans takes familiar concepts like objects, interfaces, async/await, and try/catch and extends them to multi-server environments. As such, it helps developers experienced with single-server applications transition to building resilient, scalable cloud services and other distributed applications. For this reason, Orleans has often been referred to as "Distributed .NET".</p>
<p>It was created by <a href="http://research.microsoft.com/projects/orleans/">Microsoft Research</a> and introduced the <a href="http://research.microsoft.com/apps/pubs/default.aspx?id=210931">Virtual Actor Model</a> as a novel approach to building a new generation of distributed systems for the Cloud era. The core contribution of Orleans is its programming model which tames the complexity inherent to highly-parallel distributed systems without restricting capabilities or imposing onerous constraints on the developer.</p>
<p>Documentation is located <a href="http://dotnet.github.io/orleans/Documentation/index.html">here</a></p>
</article>
          </div>
          
          
        </div>
      </div></div>]]>
            </description>
            <link>http://dotnet.github.io/orleans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24691500</guid>
            <pubDate>Mon, 05 Oct 2020 20:12:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Type-Level Programming in Rust]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24687685">thread link</a>) | @fanf2
<br/>
October 5, 2020 | https://willcrichton.net/notes/type-level-programming/ | <a href="https://web.archive.org/web/*/https://willcrichton.net/notes/type-level-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>
    
    Will Crichton
    
    &nbsp; â€” &nbsp;
    April 24, 2020
  </p>
  <p>I show how two domain-specific type systems, information flow control and two-party communication protocols, can be implemented in Rust using type-level programming. I explain how interesting properties of these domains can be verified at compile-time. Finally, I construct a general correspondence between type operators, logic programs, and their encoding in Rust.</p>
  <p>Typestate is the concept of encoding state machines in a programming languageâ€™s type system. While not specific to Rust, typestate has been <a href="http://cs242.stanford.edu/f19/lectures/08-2-typestate">explored</a> <a href="https://yoric.github.io/post/rust-typestate/">elsewhere</a> <a href="https://blog.systems.ethz.ch/blog/2018/a-hammer-you-can-only-hold-by-the-handle.html">at length</a> in the context of Rust. Typestate boils down to four ideas:</p>

<ol>
  <li>Each state is represented as a unique type.</li>
  <li>State transitions are only available as methods for the corresponding state type.</li>
  <li>Taking a state transition returns a state machine of the new state type.</li>
  <li>State transitions invalidate old state.</li>
</ol>

<p>For example, hereâ€™s a state machine for a send-then-receive channel:</p>

<div><div><pre><code><span>// Each state is a unique type</span>
<span>struct</span> <span>Receiving</span><span>;</span>
<span>struct</span> <span>Sending</span><span>;</span>

<span>// The state machine is parameterized by the state</span>
<span>#[repr(transparent)]</span>
<span>struct</span> <span>Channel</span><span>&lt;</span><span>State</span><span>&gt;</span> <span>{</span>
  <span>chan</span><span>:</span> <span>...</span><span>,</span>
  <span>_</span><span>state</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>State</span><span>&gt;</span>
<span>}</span>


<span>// Methods for the state are uniquely associated with only the state</span>
<span>impl</span> <span>Channel</span><span>&lt;</span><span>Receiving</span><span>&gt;</span> <span>{</span>
  <span>// recv consumes ownership, ensuring old state is invalidated</span>
  <span>fn</span> <span>recv</span><span>(</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>(</span><span>Channel</span><span>&lt;</span><span>Sending</span><span>&gt;</span><span>,</span> <span>String</span><span>)</span> <span>{</span>
    <span>let</span> <span>msg</span> <span>=</span> <span>self</span><span>.chan</span><span>.recv</span><span>();</span>
    <span>// The state type changes after executing a transition</span>
    <span>(</span><span>unsafe</span> <span>{</span> <span>transmute</span><span>(</span><span>self</span><span>)</span> <span>},</span> <span>msg</span><span>)</span>
  <span>}</span>
<span>}</span>

<span>impl</span> <span>Channel</span><span>&lt;</span><span>Sending</span><span>&gt;</span> <span>{</span>
  <span>fn</span> <span>send</span><span>(</span><span>mut</span> <span>self</span><span>,</span> <span>msg</span><span>:</span> <span>String</span><span>)</span> <span>-&gt;</span> <span>Channel</span><span>&lt;</span><span>Receiving</span><span>&gt;</span> <span>{</span>
    <span>self</span><span>.chan</span><span>.send</span><span>(</span><span>msg</span><span>);</span>
    <span>unsafe</span> <span>{</span> <span>transmute</span><span>(</span><span>self</span><span>)</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>#[test]</span>
<span>fn</span> <span>channel_test</span><span>()</span> <span>{</span>
  <span>let</span> <span>c</span><span>:</span> <span>Channel</span><span>&lt;</span><span>Sending</span><span>&gt;</span> <span>=</span> <span>Channel</span><span>::</span><span>new</span><span>();</span>
  <span>let</span> <span>c</span><span>:</span> <span>Channel</span><span>&lt;</span><span>Receiving</span><span>&gt;</span> <span>=</span> <span>c</span><span>.send</span><span>(</span><span>"hi"</span><span>);</span>
  <span>let</span> <span>(</span><span>c</span><span>,</span> <span>msg</span><span>)</span> <span>=</span> <span>c</span><span>.recv</span><span>();</span>
  <span>// and so on</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>There are <a href="https://news.ycombinator.com/item?id=24688233">many</a> <a href="https://www.reddit.com/r/rust/comments/gaxlm3/typelevel_programming_in_rust/fp2gjhg/">readers</a> concerned with the use of <code>transmute</code>. The use of <code>#[repr(transparent)]</code> ensures that the layout of <code>Channel</code> is <a href="https://doc.rust-lang.org/nomicon/other-reprs.html#reprtransparent">stable across transmutations</a> of the marker type.</p>
</blockquote>

<p>This pattern works effectively for simple finite state machines, where the logic to determine the next state is straightforward. In this note, I will explore situations where determining the next state is not so simple. In the process, weâ€™ll talk about <strong>type-level programming</strong>, or how you can use Rustâ€™s type system to encode <strong>computations on types</strong>.</p>

<blockquote>
  <p>Part of the goal of this note is to show the value of type-level programming in practice. These same mechanisms have already been used for more esoteric purposes like <a href="https://sdleffler.github.io/RustTypeSystemTuringComplete/">showing Rustâ€™s type system is Turing complete</a>, but I think type-level programming can really help us design better systems!</p>
</blockquote>

<h2 id="1-information-flow-control">1. Information flow control</h2>

<p>As a first example, consider a basic information flow control problem. In our program we have low security values (anyone can read them) and high security values (only authorized users can read them).</p>

<p>We represent this idea like so:</p>

<div><div><pre><code><span>// Each security level is a type</span>
<span>struct</span> <span>HighSec</span><span>;</span>
<span>struct</span> <span>LowSec</span><span>;</span>

<span>// An Item wraps an arbitrary type T, associating it with a Level</span>
<span>#[repr(transparent)]</span>
<span>struct</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>{</span>
  <span>t</span><span>:</span> <span>Box</span><span>&lt;</span><span>T</span><span>&gt;</span><span>,</span>
  <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>Level</span><span>&gt;</span>
<span>}</span>

<span>// Constructors for building items of a particular security</span>
<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>low_sec</span><span>(</span><span>t</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
    <span>Item</span> <span>{</span> <span>t</span><span>:</span> <span>Box</span><span>::</span><span>new</span><span>(</span><span>t</span><span>),</span> <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span> <span>}</span>
  <span>}</span>

  <span>pub</span> <span>fn</span> <span>high_sec</span><span>(</span><span>t</span><span>:</span> <span>T</span><span>)</span> <span>-&gt;</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>HighSec</span><span>&gt;</span> <span>{</span>
    <span>Item</span> <span>{</span> <span>t</span><span>:</span> <span>Box</span><span>::</span><span>new</span><span>(</span><span>t</span><span>),</span> <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span> <span>}</span>
  <span>}</span>
<span>}</span>

<span>// For simplicity, a naked Item can be read by anyone</span>
<span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>Deref</span> <span>for</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Target</span> <span>=</span> <span>T</span><span>;</span>
  <span>fn</span> <span>deref</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>T</span> <span>{</span>
    <span>&amp;</span><span>self</span><span>.t</span>
  <span>}</span>
<span>}</span>

</code></pre></div></div>

<p>We would like to have a vector of these items with the following property:</p>
<ul>
  <li>If all of the items are low security, anyone can read any item.</li>
  <li>If any of the items are high security, only an authorized user can read any item.</li>
</ul>

<p>For example, our vector should pass this test:</p>

<div><div><pre><code><span>let</span> <span>v</span> <span>=</span> <span>SecureVec</span><span>::</span><span>new</span><span>();</span>
<span>let</span> <span>lo</span> <span>=</span> <span>Item</span><span>::</span><span>low_sec</span><span>(</span><span>1</span><span>);</span>
<span>let</span> <span>hi</span> <span>=</span> <span>Item</span><span>::</span><span>high_sec</span><span>(</span><span>2</span><span>);</span>
<span>let</span> <span>v</span> <span>=</span> <span>v</span><span>.push</span><span>(</span><span>lo</span><span>);</span>         <span>// v is still low sec</span>
<span>assert_eq!</span><span>(</span><span>*</span><span>v</span><span>.get</span><span>(</span><span>0</span><span>),</span> <span>1</span><span>);</span>   <span>// ok to read v</span>

<span>let</span> <span>v</span> <span>=</span> <span>v</span><span>.push</span><span>(</span><span>hi</span><span>);</span>         <span>// v is now high sec</span>
<span>// assert_eq!(v.get(0), 1); // can't read any more, compiler error</span>

<span>let</span> <span>w</span> <span>=</span> <span>HighSecWitness</span><span>::</span><span>login</span><span>();</span>
<span>assert_eq!</span><span>(</span><span>*</span><span>v</span><span>.get_secure</span><span>(</span><span>1</span><span>,</span> <span>w</span><span>),</span> <span>2</span><span>);</span> <span>// can read after login</span>
</code></pre></div></div>

<p>A basic type-state attempt looks like this. We can create and read a low-security vector:</p>

<div><div><pre><code><span>#[repr(transparent)]</span>
<span>struct</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;</span> <span>{</span>
  <span>items</span><span>:</span> <span>Vec</span><span>&lt;</span><span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>Level</span><span>&gt;&gt;</span><span>,</span>
  <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span><span>&lt;</span><span>Level</span><span>&gt;</span>
<span>}</span>

<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>new</span><span>()</span> <span>-&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>{</span>
    <span>SecureVec</span> <span>{</span> <span>items</span><span>:</span> <span>Vec</span><span>::</span><span>new</span><span>(),</span> <span>_</span><span>marker</span><span>:</span> <span>PhantomData</span> <span>}</span>
  <span>}</span>

  <span>pub</span> <span>fn</span> <span>get</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>i</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>T</span> <span>{</span>
    <span>&amp;</span><span>self</span><span>.items</span><span>[</span><span>i</span><span>]</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And we can protect a high-security vector through a witness:</p>

<div><div><pre><code><span>struct</span> <span>HighSecWitness</span><span>;</span>
<span>impl</span> <span>HighSecWitness</span> <span>{</span>
  <span>// sprinkle some high-security authentication in here...</span>
  <span>pub</span> <span>fn</span> <span>login</span><span>()</span> <span>-&gt;</span> <span>HighSecWitness</span> <span>{</span> <span>HighSecWitness</span> <span>}</span>
<span>}</span>


<span>impl</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>HighSec</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>get_secure</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>i</span><span>:</span> <span>usize</span><span>,</span> <span>_</span><span>witness</span><span>:</span> <span>HighSecWitness</span><span>)</span> <span>-&gt;</span> <span>&amp;</span><span>T</span> <span>{</span>
    <span>&amp;</span><span>self</span><span>.items</span><span>[</span><span>i</span><span>]</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Now, to the main idea: how can we implement <code>push</code>? There are four possible state combinations: a high/low security vector with a high/low security item. While we can implement each combination as a separate method, itâ€™s simpler to consider the underlying logic. <code>push</code> should return a vector of level <code>max(vec_level, item_level)</code> where <code>max(hi, lo) = hi</code>.</p>

<p>Our goal is to encode <code>max</code> as a <em>type-level computation</em>, i.e. an operator on types. The high-level idea:</p>
<ul>
  <li>Traits definitions are function signatures from types to types.</li>
  <li>Trait type parameters represent inputs and associated types represent outputs.</li>
  <li>Trait implementations define individual mappings from inputs to outputs.</li>
</ul>

<p>Here are those ideas in action to compute the max security level:</p>

<div><div><pre><code><span>// Self (implicitly) is the left operand, Other is the right operand,</span>
<span>// and Output is the output</span>
<span>trait</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>Other</span><span>&gt;</span> <span>{</span>
  <span>type</span> <span>Output</span><span>;</span>
<span>}</span>

<span>// These impls define the core computation</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>LowSec</span><span>&gt;</span>  <span>for</span> <span>LowSec</span>  <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>LowSec</span><span>;</span>  <span>}</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>HighSec</span><span>&gt;</span> <span>for</span> <span>LowSec</span>  <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>HighSec</span><span>;</span> <span>}</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>LowSec</span><span>&gt;</span>  <span>for</span> <span>HighSec</span> <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>HighSec</span><span>;</span> <span>}</span>
<span>impl</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>HighSec</span><span>&gt;</span> <span>for</span> <span>HighSec</span> <span>{</span> <span>type</span> <span>Output</span> <span>=</span> <span>HighSec</span><span>;</span> <span>}</span>

<span>// The type alias gives us a more convenient way to "call" the type operator</span>
<span>type</span> <span>MaxLevel</span><span>&lt;</span><span>L</span><span>,</span> <span>R</span><span>&gt;</span> <span>=</span> <span>&lt;</span><span>L</span> <span>as</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>R</span><span>&gt;&gt;</span><span>::</span><span>Output</span><span>;</span>
</code></pre></div></div>

<blockquote>
  <p>The most confusing part is the <code>MaxLevel</code> alias. In brief: <code>L as ComputeMaxLevel&lt;R&gt;</code> says â€œtreat <code>L</code> as the trait object <code>ComputeMaxLevel&lt;R&gt;</code>â€. This is necessary since multiple computation traits may have associated <code>Output</code> with <code>L</code>, so the explicit cast disambiguates the <code>MaxLevel</code> computation from the rest.</p>
</blockquote>

<p>Hereâ€™s an example of using the type operator:</p>

<div><div><pre><code><span>let</span> <span>_</span> <span>:</span> <span>MaxLevel</span><span>&lt;</span><span>HighSec</span><span>,</span> <span>LowSec</span><span>&gt;</span> <span>=</span> <span>HighSec</span><span>;</span> <span>// ok</span>
<span>let</span> <span>_</span> <span>:</span> <span>MaxLevel</span><span>&lt;</span><span>LowSec</span> <span>,</span> <span>LowSec</span><span>&gt;</span> <span>=</span> <span>LowSec</span><span>;</span>  <span>// ok</span>
<span>let</span> <span>_</span> <span>:</span> <span>MaxLevel</span><span>&lt;</span><span>LowSec</span> <span>,</span> <span>LowSec</span><span>&gt;</span> <span>=</span> <span>HighSec</span><span>;</span> <span>// type error</span>
</code></pre></div></div>

<p>Now, we can implement <code>SecureVec::push</code> in one method:</p>

<div><div><pre><code><span>impl</span><span>&lt;</span><span>T</span><span>,</span> <span>VecLevel</span><span>&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>VecLevel</span><span>&gt;</span> <span>{</span>
  <span>pub</span> <span>fn</span> <span>push</span><span>&lt;</span><span>ItemLevel</span><span>&gt;</span><span>(</span>
    <span>mut</span> <span>self</span><span>,</span>
    <span>t</span><span>:</span> <span>Item</span><span>&lt;</span><span>T</span><span>,</span> <span>ItemLevel</span><span>&gt;</span><span>,</span>
  <span>)</span> <span>-&gt;</span> <span>SecureVec</span><span>&lt;</span><span>T</span><span>,</span> <span>MaxLevel</span><span>&lt;</span><span>ItemLevel</span><span>,</span> <span>VecLevel</span><span>&gt;&gt;</span>
  <span>where</span>
    <span>ItemLevel</span><span>:</span> <span>ComputeMaxLevel</span><span>&lt;</span><span>VecLevel</span><span>&gt;</span><span>,</span>
  <span>{</span>
    <span>unsafe</span> <span>{</span>
      <span>self</span><span>.items</span><span>.push</span><span>(</span><span>transmute</span><span>(</span><span>t</span><span>));</span>
      <span>transmute</span><span>(</span><span>self</span><span>)</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Notice the usage of <code>MaxLevel</code> in the return type of <code>push</code>. This is the key use of the type operator as a type-level computation. The other main component is the <code>where</code> clause: when used generically (over any possible <code>ItemLevel</code>), we have to use a trait bound to ensure that <code>ComputeMaxLevel</code> can be â€œcalledâ€ on <code>ItemLevel</code>.</p>

<p>Excellent! Weâ€™ve now used a type-level computation to more abstractly specify typestate in our information flow control API. Next, weâ€™ll look at an example with a more complex type-level program.</p>

<h2 id="2-two-party-communication-protocols">2. Two-party communication protocols</h2>

<p>When two parties synchronously communicate with each other (e.g. a client and server exchanging information), that communication protocol can be modeled as a session type. Weâ€™re going to look at session types <a href="https://munksgaard.me/papers/laumann-munksgaard-larsen.pdf">implemented in Rust</a>. While their full implementation is beyond the scope of the post (see the linked paper or my <a href="http://cs242.stanford.edu/f19/lectures/09-1-session-types">course notes</a>), I will focus on the aspects of session types that showcase type-level programming.</p>

<p>Session types are a domain-specific language of state machines, described by this grammar:</p>



<p>For example, this session type describes a ping server that sends and receives a ping in a loop, exiting on demand. The label/goto scheme uses <a href="https://en.wikipedia.org/wiki/De_Bruijn_index">de Bruijn indices</a> to locally encode label names as integers.</p>



<p>The grammar, and this example, can be encoded in Rust like so:</p>

<div><div><pre><code><span>struct</span> <span>Send</span><span>&lt;</span><span>T</span><span>,</span> <span>S</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>S</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Recv</span><span>&lt;</span><span>T</span><span>,</span> <span>S</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>T</span><span>,</span> <span>S</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Offer</span><span>&lt;</span><span>Left</span><span>,</span> <span>Right</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>Left</span><span>,</span> <span>Right</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Choose</span><span>&lt;</span><span>Left</span><span>,</span> <span>Right</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>(</span><span>Left</span><span>,</span> <span>Right</span><span>)</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Label</span><span>&lt;</span><span>S</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>S</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Goto</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>N</span><span>&gt;</span><span>);</span>
<span>struct</span> <span>Z</span><span>;</span>
<span>struct</span> <span>S</span><span>&lt;</span><span>N</span><span>&gt;</span><span>(</span><span>PhantomData</span><span>&lt;</span><span>N</span><span>&gt;</span><span>);</span> <span>// Peano encoding for natural numbers</span>
<span>struct</span> <span>Close</span><span>;</span>

<span>struct</span> <span>Ping</span><span>;</span>
<span>type</span> <span>PingServer</span> <span>=</span>
  <span>Label</span><span>&lt;</span>
    <span>Offer</span><span>&lt;</span>
      <span>Send</span><span>&lt;</span><span>Ping</span><span>,</span>
        <span>Recv</span><span>&lt;</span><span>Ping</span><span>,</span>
        <span>Goto</span><span>&lt;</span><span>Z</span><span>&gt;&gt;&gt;</span><span>,</span>
      <span>Close</span><span>&gt;&gt;</span><span>;</span>
</code></pre></div></div>

<p>The runtime communication API uses the type-state concept as a channel whose type changes as the protocol advances. Initially, a <code>Chan</code> is created for the server and the client (the â€œdualâ€ of the server). Hereâ€™s an example where the type annotations show the change.</p>

<div><div><pre><code><span>fn</span> <span>example_ping_server</span><span>()</span> <span>{</span>
  <span>let</span> <span>(</span><span>c</span><span>,</span> <span>_</span><span>):</span> <span>(</span><span>Chan</span><span>&lt;</span><span>(),</span> <span>PingServer</span><span>&gt;</span><span>,</span>
               <span>Chan</span><span>&lt;</span><span>(),</span> <span>Dual</span><span>&lt;</span><span>PingServer</span><span>&gt;</span><span>)</span> <span>=</span> <span>Chan</span><span>::</span><span>new</span><span>();</span>
  <span>let</span> <span>mut</span> <span>c</span><span>:</span> <span>Chan</span><span>&lt;</span><span>(</span><span>Offer</span><span>&lt;</span><span>_</span><span>,</span><span>_</span><span>&gt;</span><span>,</span> <span>()),</span> <span>Offer</span><span>&lt;</span><span>_</span><span>,</span><span>_</span><span>&gt;&gt;</span> <span>=</span> <span>c</span><span>.label</span><span>();</span>
  <span>loop</span> <span>{</span>
    <span>c</span> <span>=</span> <span>match</span> <span>c</span><span>.offer</span><span>()</span> <span>{</span>
      <span>Branch</span><span>::</span><span>Left</span><span>(</span><span>c</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>let</span> <span>c</span><span>:</span> <span>Chan</span><span>&lt;</span><span>_</span><span>,</span> <span>Recv</span><span>&lt;</span><span>_</span><span>,</span><span>_</span><span>&gt;&gt;</span> <span>=</span> <span>c</span><span>.send</span><span>(</span><span>Ping</span><span>);</span>
        <span>let</span> <span>(</span><span>c</span><span>,</span> <span>Ping</span><span>):</span> <span>(</span><span>Chan</span><span>&lt;</span><span>_</span><span>,</span> <span>Goto</span><span>&lt;</span><span>_</span><span>&gt;&gt;</span><span>,</span> <span>_</span><span>)</span> <span>=</span> <span>c</span><span>.recv</span><span>();</span>
        <span>c</span><span>.goto</span><span>()</span>
      <span>},</span>
      <span>Branch</span><span>::</span><span>Right</span><span>(</span><span>c</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>c</span><span>.close</span><span>();</span>
        <span>return</span><span>;</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Note that the <code>Chan</code> has two type arguments: an environment <code>Env</code> and a current action <code>Sigma</code>. The environment contains a list of session types generated by calls to <code>label</code>. When we <code>goto</code>, we look up the corresponding type in the <code>Env</code> list and â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://willcrichton.net/notes/type-level-programming/">https://willcrichton.net/notes/type-level-programming/</a></em></p>]]>
            </description>
            <link>https://willcrichton.net/notes/type-level-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24687685</guid>
            <pubDate>Mon, 05 Oct 2020 13:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a lay-down desk]]>
            </title>
            <description>
<![CDATA[
Score 530 | Comments 354 (<a href="https://news.ycombinator.com/item?id=24687458">thread link</a>) | @polote
<br/>
October 5, 2020 | https://blog.luap.info/drafts/i-built-a-lay-down-desk.html?hnn | <a href="https://web.archive.org/web/*/https://blog.luap.info/drafts/i-built-a-lay-down-desk.html?hnn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>After spending part of the last 12 months <a href="https://blog.luap.info/travelling-with-24-monitors.html">travelling in Europe</a> I'm now settling down around Paris and I need to adapt my multi-screens setup.</p>
<p>You probably have seen an ads for <a href="https://altwork.com/">the altwork desk</a> <em>a $7000 desk that let you work laying down</em>. Spending a big part of my day in front of a computer I want to have the most comfortable position as possible, but well $7000 + $1000 for the delivery seems so expensive. There is also <a href="http://www.ergoquest.com/">this company</a> but this is still about $4000 all included. Let's be creative and build it myself.</p>
<p>Here is the result</p>
<p><img alt="complete desk" src="https://blog.luap.info/drafts/static/desk/complete.jpg"> </p>
<p>The things I have to take into account are:</p>
<ul>
<li>
<p>I have three monitors</p>
</li>
<li>
<p>I have no diy tools</p>
</li>
<li>
<p>I want a laying down position</p>
</li>
<li>
<p>This should be easy to use</p>
</li>
<li>
<p>This should be light and not take too much space</p>
</li>
<li>
<p>I have only a bike to move the parts</p>
</li>
<li>
<p>I haven't found anyone who has done something similar and so don't really have examples</p>
</li>
</ul>
<p>So instead of doing the waterfall way I decided to go the agile way and to not do any plans, I didn't know what to expect, so let's do it step by step and see how it goes</p>
<h2>Take care of the chair</h2>
<p>There are several options:</p>
<ol>
<li>
<p>Built a chair from scratch including the 'mattress' part</p>
</li>
<li>
<p>Use a reclined chair</p>
</li>
<li>
<p>Adapt a chair</p>
</li>
</ol>
<p>The issue with the first option is that I will not be sure of the result, is it going to be comfortable ? How I'm going to wash the seat covers ? I have no idea of the things to take into account for building a comfortable chair.</p>
<p>Reclined chairs are great but they are very heavy (except the garden ones but not very comfortable) and expensive. So again let's be creative, I got inspired by <a href="https://www.ikeahackers.net/2017/04/poang-gravity-recliner.html">this</a> and <a href="https://www.ikeahackers.net/2020/04/remove-poang-arms.html">this</a> ikea hacks which use a IKEA POANG chair and transform it into a reclined chair.</p>
<p>Here is the result :</p>
<p><img alt="ikea poang adaptation" src="https://blog.luap.info/drafts/static/desk/chair.jpg"></p>
<p>The chair is 69 euro, I had to buy three cushions to extend it</p>
<p>The most complex part was to do 7km with the chair on a bike. I do not recommend doing the same, particularly because I have done it on a rainy day but well a bit of challenge in my life is always welcome!</p>
<p><img alt="ikea bike" src="https://blog.luap.info/drafts/static/desk/ikea_bike.jpg"></p>
<p>Great, the chair is comfortable, let's do something for the desk part.</p>
<h2>What structure for the desk</h2>
<p>The biggest issue you are going to have with the lay down position, is that the desk is going to be on your legs and you cant 'enter' or 'leave' the desk if you can't move the desk. So you need the 'desk' part to be dynamic from the 'chair' part.</p>
<p>I had two ideas for that, either the Altwork way, the structure goes above your head and can incline, or the the base is on the side and the desk can move somewhere (writing that, having the desk in front of me, I wonder if having the base where the foot are is not an even better solution ? Damn, too late). Having the base on the side seems better because it would be smaller and lighter and also you can balance the weight much better. But the structure also needs to be more rigid and I need to find a way to incline the desk, anyway I haven't found a way to do it :(, after a night of thinking I went the altwork way.</p>
<p>There are two parts to design:</p>
<ol>
<li>
<p>The base + the incline system</p>
</li>
<li>
<p>The desk + the screen supports</p>
</li>
</ol>
<h3>1. Base + incline system</h3>
<p>The base is pretty standard, you need something strong enough so that it can suppot the whole thing. At that point I still didn't know the weight of the complete platform so I didn't know how strong it should be. After a few failing choices, I ended up with a main pole of 7cm x 7cm.</p>
<p>Now the complex part, how to design the rotation part ? How heavy is going to be the rest of desk ? How much does the desk need to move so that I can 'enter' the desk ? So many questions I didnt have an answer for.</p>
<p>So let's try something and see how it goes, I bought an <a href="https://www.amazon.fr/gp/product/B00H8SZ87W">gaz actuator on Amazon</a> which can support 70kg with a range of 31cm, it is built for cars and pretty cheap, 19euro. Actually 70kg is a lot. So at least I have a some freedom on the weight of the structure.</p>
<p>I had two issues with the actuator:</p>
<ul>
<li>70kg IS A LOT, it is so much that when I was fixing it on the wood of the base, it was breaking the wood. The best would be to have an iron piece that I can fix to the wood but I didnt have the tools for that so I used stronger woods but this is still fragile. </li>
</ul>
<p><img alt="fixation verrin" src="https://blog.luap.info/drafts/static/desk/fixation_verrin.jpg"></p>
<ul>
<li>The desk follows a circular trajectory when you move it up and down. As a result the barycenter of the structure changes depending on the Y position of the 'desk part' and so there is more strength applied on the actuator when it is up than when it is down. So basically the desk will not stay by itself when in the up position.  I need to find a way to get the desk in the up position.</li>
</ul>
<p>I'm not really proud of the way I've done it, but it somewhat works. I've built a piece of wood that inserts itself in the area between the two poles where the actuator is. There is a counterweight which drags the piece into the zone when in up position, and when I want to release it, I just need to pull on the rope. (I think I will replace the actuator with a real electric actuator when the current system breaks so that I can control the movement, it is about 120euro)</p>
<p><img alt="system block" src="https://blog.luap.info/drafts/static/desk/blocking_system.jpg"></p>
<h3>2. Desk + screens support</h3>
<p>I bought a chipboard plate of 80cm x 120cm, and cut some space for my body</p>
<p><img alt="plaque bois" src="https://blog.luap.info/drafts/static/desk/agglo.jpg"> </p>
<p>This is pretty solid, so I can directly screw this plate to the pole and we have a desk surface</p>
<p><img alt="plaque bureau" src="https://blog.luap.info/drafts/static/desk/bureau_with_plaque.jpg"></p>
<p>For holding the monitors I did something pretty basic, I created a box for each screen. Then comes the position of the screen, how to know the position of each screen ? I didnt know how to know it beforehand, so I just created dynamic arms and adjusted them while in front of the screens</p>
<p><img alt="support monitor" src="https://blog.luap.info/drafts/static/desk/support_monitor.jpg"></p>
<h2>Next steps</h2>
<p>This is only a few days old so I can't really make a feedback but there are already a few things that I need to fix</p>
<ul>
<li>
<p>I can't use a mouse anymore, as the mouse would fall down, I'm probably going to replace it by a trackball</p>
</li>
<li>
<p>I need to invest in an ergonomic keyboard to get really comfortable, probably going to buy the kenesis advantage 2, but this is expensive !</p>
</li>
</ul>
<p>Here is a video of the complete desk:</p>
<video controls="">
  <source src="https://blog.luap.info/drafts/static/desk/video.mp4" type="video/mp4">
</video>

<h2>Conclusion</h2>
<p>When you want to build this kind of structure, I'm not sure you can plan everything beforehand, there are always things that will happen that you didn't expect, like when you code: if you want to modify the actuator when the 60kg setup is mounted how do you do ? (I have done it 6 times) When your base can't support the weight because it lacks one screw and you need to unmount everything what do you do ? ...</p>
<p>I'm really annoyed by the actuator part, I hope I will find something more reliable</p>
<p>Overall it cost me :</p>
<ul>
<li>
<p>45 euro for tools</p>
</li>
<li>
<p>130 euro for wood pieces, screws, joins, ...</p>
</li>
<li>
<p>110 euro for the IKEA chair + cushions</p>
</li>
</ul>
<p>and I spent 26 hours working, excluding the transport and the time shopping for pieces</p>
<p>Don't forget when you do woodworking to clean afterwards  :)</p>
<p><img alt="dirty" src="https://blog.luap.info/drafts/static/desk/dirty_floor.jpg"></p>
<p>If you have done something similar and know a few advice, please send me an email</p>
<p>PS: If you wonder whether you can do that or not, everyone can do it, basic woodworking is not complex, you need to know how to cut wood, how to join wood, how to screw and a little bit of imagination, you dont even need a car to transport parts, I transported everything: pole of 2m40, big plate ... on a bike</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/drafts/i-built-a-lay-down-desk.html?hnn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24687458</guid>
            <pubDate>Mon, 05 Oct 2020 13:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Concatenative Programming; the Free Monoid of Programming Languages (2019)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24687026">thread link</a>) | @gbrown_
<br/>
October 5, 2020 | https://doisinkidney.com/posts/2019-05-11-concatenative-free.html | <a href="https://web.archive.org/web/*/https://doisinkidney.com/posts/2019-05-11-concatenative-free.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on May 11, 2019
</p>



<p>This post demonstrates a simple encoding of a (typed) concatenative language in Haskell.</p>
<p>Point-free style is one of the distinctive markers of functional programming languages. Want to sum a list? Thatâ€™s as easy as:</p>

<p>Now I want to sum every number after adding one to it.</p>
<div id="cb2"><pre><code><span id="cb2-1">sumSuccs <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> <span>.</span> <span>map</span> ((<span>+</span>) <span>1</span>)</span></code></pre></div>
<p>One more step to make this function truly abstractâ„¢ and generalâ„¢: weâ€™ll allow the user to supply their own number to add</p>
<div id="cb3"><pre><code><span id="cb3-1">sumAdded <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> <span>.</span> <span>map</span> <span>.</span> (<span>+</span>)</span></code></pre></div>
<p>And here the trouble begins. The above expression wonâ€™t actually type check. In fact, itâ€™ll give a pretty terrible error message:</p>
<pre><code>â€¢ Non type-variable argument in the constraint: Num [a]
  (Use FlexibleContexts to permit this)
â€¢ When checking the inferred type
    sumThoseThat :: forall a.
                    (Num [a], Foldable ((-&gt;) [a])) =&gt;
                    a -&gt; [a]</code></pre>
<p>I remember as a beginner being confused by similar messages. Whatâ€™s <code>FlexibleContexts</code>? I had thought that the â€œpoint-free styleâ€ just meant removing the last variable from an expression if itâ€™s also the last argument:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>sum</span> xs <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> xs</span>
<span id="cb5-2"><span>sum</span> <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span></span></code></pre></div>
<p>Why doesnâ€™t it work here?</p>
<p>Well, it doesnâ€™t work because the types donâ€™t line up, but Iâ€™m going to try and explain a slightly different perspective on the problem, which is <em>associativity</em>.</p>
<p>To make it a little clearer, letâ€™s see what happens when we point-fill the expression:</p>
<div id="cb6"><pre><code><span id="cb6-1">sumAdded n xs <span>=</span> (<span>foldr</span>(<span>+</span>) <span>0</span> <span>.</span> (<span>map</span> <span>.</span> (<span>+</span>))) n xs</span>
<span id="cb6-2">             <span>=&gt;</span> <span>foldr</span>(<span>+</span>) <span>0</span> ((<span>map</span> <span>.</span> (<span>+</span>)) n) xs</span>
<span id="cb6-3">             <span>=&gt;</span> <span>foldr</span>(<span>+</span>) <span>0</span> (<span>map</span> ((<span>+</span>) n)) xs</span></code></pre></div>
<p>Indeed, the problem is the placement of the parentheses. What we want at the end is:</p>
<div id="cb7"><pre><code><span id="cb7-1">             <span>=&gt;</span> <span>foldr</span>(<span>+</span>) <span>0</span> (<span>map</span> ((<span>+</span>) n) xs)</span></code></pre></div>
<p>But, no matter. We have to jiggle the arguments around, or we could use something terrible like this:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>infixr</span> <span>9</span> <span>.:</span></span>
<span id="cb8-2">(<span>.:</span>) <span>=</span> (<span>.</span>)<span>.</span>(<span>.</span>)</span>
<span id="cb8-3"></span>
<span id="cb8-4">sumAdded <span>=</span> <span>foldr</span> (<span>+</span>) <span>0</span> <span>.:</span> <span>map</span> <span>.</span> (<span>+</span>)</span></code></pre></div>
<p>Is there something, though, that could do this automatically?</p>

<p>We run into a similar problem in Agda. Weâ€™re forever having to prove statements like:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>(</span>x + y<span>)</span> + z â‰¡ x + <span>(</span>y + z<span>)</span></span>
<span id="cb9-2">x â‰¡ x + <span>0</span></span></code></pre></div>
<p>There are a couple of ways to get around the issue, and for monoids thereâ€™s a rich theory of techniques. Iâ€™ll just show one for now, which relies on the <em>endomorphism</em> monoid. This monoid is created by partially applying the monoidâ€™s binary operator:</p>
<div id="cb10"><pre><code><span id="cb10-1">Endo <span>:</span> <span>Set</span></span>
<span id="cb10-2">Endo <span>=</span> â„• <span>â†’</span> â„•</span>
<span id="cb10-3"></span>
<span id="cb10-4">âŸ¦<span>_</span>â‡‘âŸ§ <span>:</span> â„• <span>â†’</span> Endo</span>
<span id="cb10-5">âŸ¦ n â‡‘âŸ§ m <span>=</span> n + m</span></code></pre></div>
<p>And you can get back to the underlying monoid by applying it to the neutral element:</p>
<div id="cb11"><pre><code><span id="cb11-1">âŸ¦<span>_</span>â‡“âŸ§ <span>:</span> Endo <span>â†’</span> â„•</span>
<span id="cb11-2">âŸ¦ n â‡“âŸ§ <span>=</span> n <span>0</span></span></code></pre></div>
<p>Hereâ€™s the important parts: first, we can lift the underlying operation into the endomorphism:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>_</span>âŠ•<span>_</span> <span>:</span> Endo <span>â†’</span> Endo <span>â†’</span> Endo</span>
<span id="cb12-2">xs âŠ• ys <span>=</span> <span>Î»</span> x <span>â†’</span> xs <span>(</span>ys x<span>)</span></span>
<span id="cb12-3"></span>
<span id="cb12-4">âŠ•-homo <span>:</span> <span>âˆ€</span> n m <span>â†’</span> âŸ¦ âŸ¦ n â‡‘âŸ§ âŠ• âŸ¦ m â‡‘âŸ§ â‡“âŸ§ â‰¡ n + m</span>
<span id="cb12-5">âŠ•-homo n m <span>=</span> cong <span>(</span>n +<span>_)</span> <span>(</span>+-identityÊ³ m<span>)</span></span></code></pre></div>
<p>And second, itâ€™s <em>definitionally</em> associative.</p>
<div id="cb13"><pre><code><span id="cb13-1">âŠ•-assoc <span>:</span> <span>âˆ€</span> x y z <span>â†’</span> <span>(</span>x âŠ• y<span>)</span> âŠ• z â‰¡ x âŠ• <span>(</span>y âŠ• z<span>)</span></span>
<span id="cb13-2">âŠ•-assoc <span>_</span> <span>_</span> <span>_</span> <span>=</span> refl</span></code></pre></div>
<p>These are all clues as to how to solve the composition problem in the Haskell code above. We need definitional associativity, somehow. Maybe we can get it from the endomorphism monoid?</p>

<p>Youâ€™re probably familiar with Haskellâ€™s state monad:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>newtype</span> <span>State</span> s a <span>=</span> <span>State</span> {<span> runState ::</span> s <span>-&gt;</span> (a, s) }</span></code></pre></div>
<p>It can help a lot when youâ€™re threading around fiddly accumulators and so on.</p>
<div id="cb15"><pre><code><span id="cb15-1"><span>nub ::</span> <span>Ord</span> a <span>=&gt;</span> [a] <span>-&gt;</span> [a]</span>
<span id="cb15-2">nub <span>=</span> go Set.empty</span>
<span id="cb15-3">  <span>where</span></span>
<span id="cb15-4">    go seen [] <span>=</span> []</span>
<span id="cb15-5">    go seen (x<span>:</span>xs)</span>
<span id="cb15-6">      <span>|</span> x <span>`Set.member`</span> seen <span>=</span> go seen xs</span>
<span id="cb15-7">      <span>|</span> <span>otherwise</span> <span>=</span> x <span>:</span> go (Set.insert x seen) xs</span></code></pre></div>
<div id="cb16"><pre><code><span id="cb16-1"><span>nub ::</span> <span>Ord</span> a <span>=&gt;</span> [a] <span>-&gt;</span> [a]</span>
<span id="cb16-2">nub <span>=</span> <span>flip</span> evalState Set.empty <span>.</span> go</span>
<span id="cb16-3">  <span>where</span></span>
<span id="cb16-4">    go [] <span>=</span> <span>pure</span> []</span>
<span id="cb16-5">    go (x<span>:</span>xs) <span>=</span> <span>do</span></span>
<span id="cb16-6">        seen <span>&lt;-</span> gets (Set.member x)</span>
<span id="cb16-7">        <span>if</span> seen</span>
<span id="cb16-8">          <span>then</span> go xs</span>
<span id="cb16-9">          <span>else</span> <span>do</span></span>
<span id="cb16-10">              modify (Set.insert x)</span>
<span id="cb16-11">              (x<span>:</span>) <span>&lt;$&gt;</span> go xs</span></code></pre></div>
<p>Of course, these days state is a transformer:</p>
<div id="cb17"><pre><code><span id="cb17-1"><span>newtype</span> <span>StateT</span> s m a <span>=</span> <span>StateT</span> {<span> runStateT ::</span> s <span>-&gt;</span> m (a, s) }</span></code></pre></div>
<p>This lets us stack multiple effects on top of each other: error handling, IO, randomness, even another state monad. In fact, if you <em>do</em> stack another state monad on top, you might be surprised by the efficiency of the code it generates:</p>
<div id="cb18"><pre><code><span id="cb18-1"><span>type</span> <span>DoubleState</span> s1 s2 a <span>=</span> <span>StateT</span> s1 (<span>State</span> s2) a</span>
<span id="cb18-2">                        <span>=&gt;</span> s1 <span>-&gt;</span> <span>State</span> s2 (a, s1)</span>
<span id="cb18-3">                        <span>=&gt;</span> s1 <span>-&gt;</span> s2 <span>-&gt;</span> ((a, s1), s2)</span></code></pre></div>
<p>Itâ€™s nothing earth shattering, but it inlines and optimises well. That output is effectively a left-nested list, also.</p>

<p>If we can do one, and we can do two, why not more? Can we generalise the state pattern to an arbitrary number of variables? First weâ€™ll need a generic tuple:</p>
<div id="cb19"><pre><code><span id="cb19-1"><span>infixr</span> <span>5</span> <span>:-</span></span>
<span id="cb19-2"><span>data</span> <span>Stack</span> (<span>xs ::</span> [<span>Type</span>])<span> ::</span> <span>Type</span> <span>where</span></span>
<span id="cb19-3">    <span>Nil</span><span>  ::</span> <span>Stack</span> '[]</span>
<span id="cb19-4"><span>    (:-) ::</span> x <span>-&gt;</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> (x <span>:</span> xs)</span></code></pre></div>
<p>Then, the state type.</p>
<div id="cb20"><pre><code><span id="cb20-1"><span>newtype</span> <span>State</span> xs a <span>=</span> <span>State</span> {<span> runState ::</span> <span>Stack</span> xs <span>-&gt;</span> (a, <span>Stack</span> xs) }</span></code></pre></div>
<p>We can actually clean the definition up a little: instead of a tuple at the other end, why not push it onto the stack.</p>
<div id="cb21"><pre><code><span id="cb21-1"><span>newtype</span> <span>State</span> xs a <span>=</span> <span>State</span> {<span> runState ::</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> (a <span>:</span> xs) }</span></code></pre></div>
<p>In fact, letâ€™s make this as polymorphic as possible. We should be able to change the state is we so desire.</p>
<div id="cb22"><pre><code><span id="cb22-1"><span>infixr</span> <span>0</span> <span>:-&gt;</span></span>
<span id="cb22-2"><span>type</span> (<span>:-&gt;</span>) xs ys <span>=</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> ys</span></code></pre></div>
<p>And suddenly, our endomorphism type from above shows up again.</p>
<p>We can, of course, get back our original types.</p>
<div id="cb23"><pre><code><span id="cb23-1"><span>newtype</span> <span>State</span> xs a <span>=</span> <span>State</span> {<span> runState ::</span> xs <span>:-&gt;</span> a <span>:</span> xs }</span></code></pre></div>
<p>And it comes with all of the instances you might expect:</p>
<div id="cb24"><pre><code><span id="cb24-1"><span>instance</span> <span>Functor</span> (<span>State</span> xs) <span>where</span></span>
<span id="cb24-2">    <span>fmap</span> f xs <span>=</span> <span>State</span> (\s <span>-&gt;</span> <span>case</span> runState xs s <span>of</span></span>
<span id="cb24-3">        (x <span>:-</span> ys) <span>-&gt;</span> f x <span>:-</span> ys)</span>
<span id="cb24-4">        </span>
<span id="cb24-5"><span>instance</span> <span>Applicative</span> (<span>State</span> xs) <span>where</span></span>
<span id="cb24-6">    <span>pure</span> x <span>=</span> <span>State</span> (x <span>:-</span>)</span>
<span id="cb24-7">    fs <span>&lt;*&gt;</span> xs <span>=</span> <span>State</span> (\s <span>-&gt;</span> <span>case</span> runState fs s <span>of</span></span>
<span id="cb24-8">        (f <span>:-</span> s') <span>-&gt;</span> <span>case</span> runState xs s' <span>of</span></span>
<span id="cb24-9">            (x <span>:-</span> s'') <span>-&gt;</span> f x <span>:-</span> s'')</span>
<span id="cb24-10">            </span>
<span id="cb24-11"><span>instance</span> <span>Monad</span> (<span>State</span> xs) <span>where</span></span>
<span id="cb24-12">    xs <span>&gt;&gt;=</span> f <span>=</span> <span>State</span> (\s <span>-&gt;</span> <span>case</span> runState xs s <span>of</span></span>
<span id="cb24-13">        y <span>:-</span> ys <span>-&gt;</span> runState (f y) ys)</span></code></pre></div>

<p>But whatâ€™s the point? So far weâ€™ve basically just encoded an unnecessarily complicated state transformer. Think back to the stacking of states. Written in the <a href="https://hackage.haskell.org/package/mtl">mtl</a> style, the main advantage of stacking monads like that is you can write code like the following:</p>
<div id="cb25"><pre><code><span id="cb25-1"><span>pop ::</span> (<span>MonadState</span> [a] m, <span>MonadError</span> <span>String</span> m) <span>=&gt;</span> m a</span>
<span id="cb25-2">pop <span>=</span> get <span>&gt;&gt;=</span> \<span>case</span></span>
<span id="cb25-3">    [] <span>-&gt;</span> throwError <span>"pop: empty list"</span></span>
<span id="cb25-4">    x<span>:</span>xs <span>-&gt;</span> <span>do</span></span>
<span id="cb25-5">        put xs </span>
<span id="cb25-6">        <span>pure</span> x</span></code></pre></div>
<p>In other words, we donâ€™t care about the rest of <code>m</code>, we just care that it has, somewhere, state for an <code>[a]</code>.</p>
<p>This logic should apply to our stack transformer, as well. If it only cares about the top two variables, it shouldnâ€™t care what the rest of the list is. In types:</p>
<div id="cb26"><pre><code><span id="cb26-1"><span>infixr</span> <span>0</span> <span>:-&gt;</span></span>
<span id="cb26-2"><span>type</span> (<span>:-&gt;</span>) xs ys <span>=</span> <span>forall</span> zs<span>.</span> <span>Stack</span> (xs <span>++</span> zs) <span>-&gt;</span> <span>Stack</span> (ys <span>++</span> zs)</span></code></pre></div>
<p>And straight away we can write some of the standard combinators:</p>
<div id="cb27"><pre><code><span id="cb27-1"><span>dup ::</span> '[a] <span>:-&gt;</span> '[a,a]</span>
<span id="cb27-2">dup (x <span>:-</span> xs) <span>=</span> (x <span>:-</span> x <span>:-</span> xs)</span>
<span id="cb27-3"></span>
<span id="cb27-4"><span>swap ::</span> '[x,y] <span>:-&gt;</span> '[y,x]</span>
<span id="cb27-5">swap (x <span>:-</span> y <span>:-</span> xs) <span>=</span> y <span>:-</span> x <span>:-</span> xs</span>
<span id="cb27-6"></span>
<span id="cb27-7"><span>drop</span><span> ::</span> '[x,y] <span>:-&gt;</span> '[y]</span>
<span id="cb27-8"><span>drop</span> (_ <span>:-</span> xs) <span>=</span> xs</span>
<span id="cb27-9"></span>
<span id="cb27-10"><span>infixl</span> <span>9</span> <span>!</span></span>
<span id="cb27-11">(f <span>!</span> g) x <span>=</span> g (f x)</span></code></pre></div>
<p>Youâ€™ll immediately run into trouble if you try to work with some of the more involved combinators, though. Quote should have the following type, for instance:</p>
<div id="cb28"><pre><code><span id="cb28-1"><span>quote ::</span> (xs <span>:-&gt;</span> ys) <span>-&gt;</span> '[] <span>:-&gt;</span> '[ xs <span>:-&gt;</span> ys ]</span></code></pre></div>
<p>But GHC complains again:</p>
<pre><code>â€¢ Illegal polymorphic type: xs :-&gt; ys
  GHC doesn't yet support impredicative polymorphism
â€¢ In the type signature:
    quote :: (xs :-&gt; ys) -&gt; '[] :-&gt; '[xs :-&gt; ys]</code></pre>
<p>I wonâ€™t go into the detail of this particular error: if youâ€™ve been around the block with Haskell you know that it means â€œwrap it in a newtypeâ€. If we do <em>that</em>, though, we get yet more errors:</p>
<div id="cb30"><pre><code><span id="cb30-1"><span>newtype</span> (<span>:~&gt;</span>) xs ys <span>=</span> <span>Q</span> {<span> d ::</span> xs <span>:-&gt;</span> ys }</span></code></pre></div>
<pre><code>â€¢ Couldn't match type â€˜ys ++ zs0â€™ with â€˜ys ++ zsâ€™
  Expected type: Stack (xs ++ zs) -&gt; Stack (ys ++ zs)
    Actual type: Stack (xs ++ zs0) -&gt; Stack (ys ++ zs0)
  NB: â€˜++â€™ is a type function, and may not be injective</code></pre>
<p>This injectivity error comes up often. It means that GHC needs to prove that the input to two functions is equal, but it only knows that their outputs are. This is a doubly serious problem for us, as we canâ€™t do type family injectivity on two type variables (in current Haskell). To solve the problem, we need to rely on a weird mishmash of type families and functional dependencies:</p>
<div id="cb32"><pre><code><span id="cb32-1"><span>type</span> <span>family</span> (<span>++</span>) xs ys <span>where</span></span>
<span id="cb32-2">    '[] <span>++</span> ys <span>=</span> ys</span>
<span id="cb32-3">    (x <span>:</span> xs) <span>++</span> ys <span>=</span> x <span>:</span> (xs <span>++</span> ys)</span>
<span id="cb32-4">    </span>
<span id="cb32-5"><span>class</span> (xs <span>++</span> ys <span>~</span> zs) <span>=&gt;</span> <span>Conc</span> xs ys zs <span>|</span> xs zs <span>-&gt;</span> ys <span>where</span></span>
<span id="cb32-6"><span>    conc ::</span> <span>Stack</span> xs <span>-&gt;</span> <span>Stack</span> ys <span>-&gt;</span> <span>Stack</span> zs</span>
<span id="cb32-7">    </span>
<span id="cb32-8"><span>instance</span> <span>Conc</span> '[] ys ys <span>where</span></span>
<span id="cb32-9">    conc _ ys <span>=</span> ys</span>
<span id="cb32-10">    </span>
<span id="cb32-11"><span>instance</span> <span>Conc</span> xs ys zs <span>=&gt;</span> <span>Conc</span> (x <span>:</span> xs) ys (x <span>:</span> zs) <span>where</span></span>
<span id="cb32-12">    conc (x <span>:-</span> xs) ys <span>=</span> x <span>:-</span> conc xs ys</span>
<span id="cb32-13"></span>
<span id="cb32-14"><span>infixr</span> <span>0</span> <span>:-&gt;</span></span>
<span id="cb32-15"><span>type</span> (<span>:-&gt;</span>) xs ys <span>=</span> <span>forall</span> zs yszs<span>.</span> <span>Conc</span> ys zs yszs <span>=&gt;</span> <span>Stack</span> (xs <span>++</span> zs) <span>-&gt;</span> <span>Stack</span> yszs</span></code></pre></div>
<p>And it does indeed work:</p>
<div id="cb33"><pre><code><span id="cb33-1"><span>pure</span><span> ::</span> a <span>-&gt;</span> '[] <span>:-&gt;</span> '[a]</span>
<span id="cb33-2"><span>pure</span> <span>=</span> (<span>:-</span>)</span>
<span id="cb33-3"></span>
<span id="cb33-4"><span>newtype</span> (<span>:~&gt;</span>) xs ys <span>=</span> <span>Q</span> {<span> d ::</span> xs <span>:-&gt;</span> ys }</span>
<span id="cb33-5"></span>
<span id="cb33-6"><span>quote ::</span> (xs <span>:-&gt;</span> ys) <span>-&gt;</span> '[] <span>:-&gt;</span> '[ xs <span>:~&gt;</span> ys ]</span>
<span id="cb33-7">quote x <span>=</span> <span>pure</span> (<span>Q</span> x)</span>
<span id="cb33-8"></span>
<span id="cb33-9"><span>dot ::</span> <span>forall</span> xs ys<span>.</span> ((xs <span>:~&gt;</span> ys) <span>:</span> xs) <span>:-&gt;</span> ys</span>
<span id="cb33-10">dot (x <span>:-</span> xs) <span>=</span> d x xs</span>
<span id="cb33-11"></span>
<span id="cb33-12"><span>true ::</span> (xs <span>:~&gt;</span> ys) <span>:</span> (xs <span>:~&gt;</span> ys) <span>:</span> xs <span>:-&gt;</span> ys</span>
<span id="cb33-13">true <span>=</span> swap <span>!</span> <span>drop</span> <span>!</span> dot</span>
<span id="cb33-14"></span>
<span id="cb33-15"><span>false ::</span> (xs <span>:~&gt;</span> ys) <span>:</span> (xs <span>:~&gt;</span> ys) <span>:</span> xs <span>:-&gt;</span> ys</span>
<span id="cb33-16">false <span>=</span> <span>drop</span> <span>!</span> dot</span>
<span id="cb33-17"></span>
<span id="cb33-18"><span>test ::</span> '[] <span>:-&gt;</span> '[ '[a] <span>:~&gt;</span> '[a,a] ]</span>
<span id="cb33-19">test <span>=</span> quote dup</span></code></pre></div>
<p>Interestingly, these combinators represent the monadic operations on state (<code>dot</code> = <code>join</code>, <code>pure</code> = <code>pure</code>, etc.)</p>
<p>And can we get the nicer composition of the function from the intro? Kind of:</p>
<div id="cb34"><pre><code><span id="cb34-1">sumAdded <span>=</span> quote add <span>!</span> <span>curry</span> <span>!</span> dot <span>!</span> <span>map</span> <span>!</span> <span>sum</span></span></code></pre></div>
<p>Here are some references for concatenative languages: <span data-cites="okasaki_techniques_2002">Okasaki (<a href="#ref-okasaki_techniques_2002" role="doc-biblioref">2002</a>)</span>, <span data-cites="purdy_big_2012">Purdy (<a href="#ref-purdy_big_2012" role="doc-biblioref">2012</a>)</span>, <span data-cites="kerby_theory_2007">Kerby (<a href="#ref-kerby_theory_2007" role="doc-biblioref">2007</a>)</span>, <span data-cites="okasaki_theoretical_2003">Okasaki (<a href="#ref-okasaki_theoretical_2003" role="doc-biblioref">2003</a>)</span>.</p>


        </div></div>]]>
            </description>
            <link>https://doisinkidney.com/posts/2019-05-11-concatenative-free.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24687026</guid>
            <pubDate>Mon, 05 Oct 2020 12:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Bootstrapping an asset store for AR creators and ML engineers]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24686922">thread link</a>) | @dan_zaitsev
<br/>
October 5, 2020 | https://catchar.io/marketplace | <a href="https://web.archive.org/web/*/https://catchar.io/marketplace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="change-log-app">  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> October 03, 2020</span></p><h2><a href="https://catchar.io/blog/catchar-3-0" title="Catchar 3.0">Catchar 3.0</a></h2> <div><p>Our team is officially announcing the launch of a new 3.0 version of Catchar with a <a href="https://catchar.io/marketplace" rel="noopener noreferrer" target="_blank">marketplace</a> module.&nbsp;</p><p>We found that some creators use Sketchfab, Gumroad and Etsy to sell and monetize their AR/MR assets. However, creators from CIS, Georgia, Ukraine, Asia and some other countries are limited in payouts from these services.</p><p>We released a marketplace and asset store where Augmented Reality creators and Machine Learning engineers can list for sale their templates, source code, 3D models and tutorials. Our system provides direct profit payouts through SWIFT and SEPA.</p><p><img src="https://catchar.io/storage/articles/455/art_img_5f78bd46b8967.jpg"></p><p>Please note! Currently, the marketplace is in the beta phase, so we are looking for early adopters and partners to test the marketplace and improve it. We are especially looking for designers, developers and studios who are ready to upload for sale their 3D models, templates and source code related to Augmented and Mixed Reality, Machine Learning, etc.</p><p>You can join the beta-testing program by using our <a href="http://t.me/catchar" rel="noopener noreferrer" target="_blank">Telegram</a> chat. Using Telegram chat, you can aslo discover Catchar updates that sorts Alice (our AI assistant). Be up to date regarding the latest AR projects, articles, new creators and other activities.</p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> May 23, 2020</span></p><h2><a href="https://catchar.io/blog/catchar-2-4" title="Catchar 2.4">Catchar 2.4</a></h2> <div><p>Some updates and new features available on Catchar ğŸ”¥</p><ul><li>Be informed that we rescheduled our weekly AR/MR digest to Tuesday.</li><li>In addition, I would like to let you know that we released the instant post feature â†™ï¸</li></ul><p><img src="https://catchar.io/storage/articles/355/art_img_5ec83bce82e64.jpg"></p><p>This feature is only available for our creators and companies. Upgrade to company or creator role to start sharing. If you are one of them post information only about AR/MR domains otherwise youâ€™ll be muted! Feel free to post related to AR/MR news, tutorials, guides, tips from Medium, TechCrunch, YouTube, Twitter, LinkedIn or private blogs. Please donâ€™t promote yourself too much ğŸ˜‰</p><ul><li><span>We continue working in terms of improving our SEO results, social and direct marketing. As a result, we have reached 350 unique visitors per day. Donâ€™t miss the chance to showcase your AR/MR projects, articles and other updates.</span></li></ul><p><img src="https://catchar.io/storage/articles/355/art_img_5ec83cda45431.jpg"></p></div> </div>    <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> April 13, 2020</span></p><h2><a href="https://catchar.io/blog/catchar-2-3" title="Catchar 2.3">Catchar 2.3</a></h2> <div><p>Catchar has been updated! Our new 2.3 version is available: </p><ul><li><span>List services of your company</span></li></ul><p><span>From now our business users are able to list services, description and prices. If you are one of them please visit your profile to add them.</span></p><p><img src="https://catchar.io/storage/articles/290/art_img_5e947ac6a71d8.jpg"></p><ul><li>Improved page with projects</li></ul><p>Our new feature provides the ability to discover AR apps and lenses through screenshots or list views. Find the button to try it out!</p><p><img src="https://catchar.io/storage/articles/290/art_img_5e947cb780e39.jpg"></p><ul><li><span>We changed project presentations in the newsfeed</span></li></ul><p>We also changed the preview of projects in the newsfeed. Now you can discover them through screenshots.</p><p><img src="https://catchar.io/storage/articles/290/art_img_5e947d49a1c80.jpg"></p><ul><li>SEO improvements</li></ul><p>We continue working on SEO improvements so your profiles and projects can be searchable well across the web.</p><p><span>Feel free to share with us any your suggestions/feedback!</span></p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> March 11, 2020</span></p><h2><a href="https://catchar.io/blog/catchar2-2" title="Catchar 2.2">Catchar 2.2</a></h2> <div><p>Catchar has been updated! Discover below what changed in 2.2 version:</p><ul><li>We have made some updates on our index page (visible for unauthenticated users only). So now we are displaying our top creators, companies and projects with the highest rating there.</li><li>We have also added the â€˜Whatâ€™s newâ€™ feature where you can discover the latest product updates.</li><li>Finally, we released the â€˜Instant postâ€™ feature that allows sharing external links and text content. We are still testing it and currently, this feature is only available for our community leaders. If you want to be one of them, please contact @<a href="https://catchar.io/creator/dan-zaitsev" target="_blank">Dan Zaitsev</a>.</li><li>We added the ability to share external articles. Find this feature through the '<a href="https://catchar.io/submit-article" target="_blank">article submission</a>' button.</li><li><span>Our newsfeed has been </span><span>Improved. Also, we</span><span> added more events.</span></li></ul><p><span>Let us know if you have any suggestions/feedback!</span></p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> December 07, 2019</span></p><h2><a href="https://catchar.io/blog/catchar-21-open-beta" title="Catchar 2.1 (open beta)">Catchar 2.1 (open beta)</a></h2> <div><p>We are happy to inform you that Catchar 2.1 (open beta) is available worldwide. We have done a lot of work in terms of creating new features, bug fixing and from the SEO perspective. Hereâ€™s the changelog for 2.1 version:</p><ul><li>Product <a href="https://catchar.io/blog?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>blog</strong></a></li><li>Global search has been added</li><li>Improved ranking system of creators and companies</li><li>Improved ranking system of projects and articles</li><li>Improved newsfeed</li><li>Delivered quality SEO</li><li>Fixed responsive layout</li><li>Improved desktop layout</li><li>Lazy loading feature has been added</li><li>Improved design of <a href="https://catchar.io/login?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>Login</strong></a> / <a href="https://catchar.io/register?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>Sign up</strong></a> pages</li><li>Added ability to register and login via <a href="https://catchar.io/login?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>LinkedIn</strong></a></li><li>Added sharing through all social media and email</li><li>Ability to send direct messages via emails to creators and companies</li><li>Improved instant email notifications</li><li>Added different placeholders</li><li>Ability to get AR lenses and apps by scanning QR codes from desktops and laptops</li></ul><p>Guys, the most important thing is that currently, our website works through an open based model (No signup is required). That means our guests can easily visit us and discover AR / MR projects, profiles and articles. So, don't miss your chance to create your portfolio of XR creator by <a href="https://catchar.io/submit-project?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>submitting</strong></a> your AR / MR projects, <a href="https://catchar.io/submit-article?utm_source=blog&amp;utm_medium=changelog_2_1" target="_blank"><strong>articles</strong></a> and updates to be visible worldwide. In addition, it will help you to receive more scores to your profile and appear at the top of search results.</p><p><em>Image credit: Hyper-reality</em></p></div> </div>  <div> <p><span><img src="https://catchar.io/assets/icons/published.svg" alt=""> November 28, 2019</span></p><h2><a href="https://catchar.io/blog/catchar-2-0-private-beta" title="Catchar 2.0 (private beta)">Catchar 2.0 (private beta)</a></h2> <div><p>We have some wonderful news! Finally our MVP of <a href="https://catchar.io/" target="_blank">Catchar 2.0</a> is ready and we are going into private beta phase. We greatly appreciate you staying with us. Feel free to sign in and start creating your XR portfolio by submitting and contributing your XR projects, news and updates. It will help you to become #1 XR creator or contributor when we launch globally in the next 3-4 weeks. We apologize if you will find some bugs in our private beta. Just click 'LEAVE FEEDBACK' button at the right section of the website and we would definitely check them and fix them.</p><p>Hereâ€™s the list of features that are available in private beta:</p><ul><li><a href="https://catchar.io/login" target="_blank">User login / sign up</a></li><li><a href="https://catchar.io/login" target="_blank">Creator login / sign up</a></li><li><a href="https://catchar.io/login" target="_blank">Company login / sign up</a></li><li><a href="https://catchar.io/creators" target="_blank">List with XR creators and developers</a></li><li><a href="https://catchar.io/companies" target="_blank">List with XR companies and studios</a></li><li><a href="https://catchar.io/articles" target="_blank">List with XR articles, news and tutorials</a></li><li>Profile page of XR creators and developers</li><li>Profile page of XR companies and studios</li><li>Community pages with projects, updates, creators and companies</li><li><a href="https://catchar.io/submit-project" target="_blank">Ability to submit XR projects</a> (apps, lenses and campaigns)</li><li><a href="https://catchar.io/submit-article" target="_blank">Ability to submit XR articles, news and tutorials</a></li><li>Ability to submit project updates</li><li>Activity feed and live updates (Available on home and community pages)</li><li>Ability to share projects, company and creator profiles (Find it at the left section)</li><li>Ability to like XR projects and articles (Find it at the left section)</li><li><a href="https://catchar.io/my-projects" target="_blank">Promotion of XR projects</a> (apps, lenses and campaigns)</li><li>Become a PRO to unlock more features&nbsp;</li><li><a href="https://catchar.io/our-team" target="_blank">Page about our team</a></li><li><a href="https://catchar.io/catchar-mission" target="_blank">Page about our mission</a></li><li><a href="https://catchar.io/ar-categories" target="_blank">Page with XR categories</a></li><li>Secret ranking system for XR projects (apps, lenses and campaigns)</li><li>Secret ranking system for XR creators and companies</li><li>Secret ranking system for XR articles and news</li></ul><p>Feel free to reach out to us regarding any ideas or improvements.</p></div> </div>  </div></div>]]>
            </description>
            <link>https://catchar.io/marketplace</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686922</guid>
            <pubDate>Mon, 05 Oct 2020 12:07:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles of Data Oriented Programming]]>
            </title>
            <description>
<![CDATA[
Score 350 | Comments 127 (<a href="https://news.ycombinator.com/item?id=24686863">thread link</a>) | @viebel
<br/>
October 5, 2020 | https://blog.klipse.tech/databook/2020/09/29/do-principles.html?essence | <a href="https://web.archive.org/web/*/https://blog.klipse.tech/databook/2020/09/29/do-principles.html?essence">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  <div itemprop="articleBody">
    <div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
<p>This chapter is an attempt to illustrate what are the core principles of Data Oriented Programming as I understand them.
It is highly influenced by my programming experience in Clojure, but I believe that those principles are language agnostic.</p>
<p>One could adhere to them in an Object Oriented (OO) language like Java or C# and one could break them
in a Functional Programming (FP) language like Ocaml, Haskell, JavaScript (or even in Clojure).</p>
<p>In fact, in this chapter, I am going to illustrate how those principles could be applied or broken
in JavaScript, a programming language that supports both FP and OOP.</p>
<p>The principles of Data Oriented (DO) Programming are:</p>

<p>Each principle is explored in a separate article.</p>

<p>Enjoy!</p>
<div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
  </div>

</article><p>
  If you enjoy this kind of interactive articles would you consider a (small) donationğŸ’¸  on <a href="https://www.patreon.com/bePatron?u=18227864">Patreon</a> or at least giving a starâ­ for the Klispe repo on <a href="https://github.com/viebel/klipse/stargazers"> Github</a>?
</p></div>]]>
            </description>
            <link>https://blog.klipse.tech/databook/2020/09/29/do-principles.html?essence</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686863</guid>
            <pubDate>Mon, 05 Oct 2020 11:59:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Digital Euro]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24686582">thread link</a>) | @perfunctory
<br/>
October 5, 2020 | https://www.ecb.europa.eu/euro/html/digitaleuro.en.html | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/euro/html/digitaleuro.en.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="ecb-content-col">
					<main>
						ï»¿
<div>
	<div>
		
			<p>The ECB, as guardian of the euro, provides currency in two forms: we issue banknotes and we transfer electronic deposits to banks and other financial institutions.</p>
			<p>Digitalisation has spread to every corner of our lives and transformed how we pay. In this new era, a digital euro would guarantee that citizens in the euro area can maintain free access to a simple, universally accepted, safe and trusted means of payment. A digital euro is not meant to replace cash, but rather to complement it. Together, they give people more choices about how to pay, and make it easier for them to do so,  increasing financial inclusion. </p>

			<p>The Eurosystem will continue to ensure that all citizens have access to euro banknotes and coins across the euro area.</p>


		
	</div>

	
</div>

<!-- <hr class="dark thick no-top-margin"> -->

	  <div>
		
		<!-- <div class="ecb-grid grid-width-6 tablet-grid-width-6 phone-grid-width-12 ecb-grid-bottom-padding ecb-no-phone-grid-inside-padding ecb-no-phone-grid-bottom-padding ecb-grid-fake-inside-padding-left"> 
		  <div class="fullWidth special-box-image min-full-height arrow-right arrow-extra-light" style="background-image:url('../shared/img/Christine_Lagarde_Quote_600x380.jpg'); height: 334px"> </div>
		   </div>
		<div class="ecb-grid grid-width-6 tablet-grid-width-6 phone-grid-width-12 ecb-grid-bottom-padding ecb-grid-fake-inside-padding-right">
		  <div class="ecb-grid inside min-full-height flex flex-column-nowrap container-special-box">
			<div class="ecb-box modernBox flex-grow">
			  <p><em>We need to make sure the euro is future ready. Inaction is not an option.</em></p>
			  <p><strong>Christine Lagarde, President of the ECB</strong></p>
			</div>
		  </div>
		</div> -->
<div>
<p><em>â€œThe euro belongs to Europeans and we are its guardian. We should be prepared to issue a digital euro, should the need arise.â€</em></p>
			  <p><strong>Christine Lagarde, President of the ECB</strong></p>
			</div>

		</div>
	<!-- <hr class="dark thick"> -->


<div>
	
	<div>
		<div>
			<div>
				<h3>Why a digital euro?</h3>
				<p>A digital euro would make your daily payments faster, easier and more secure.
						It could support the digitalisation of the European economy and actively encourage innovation in retail payments. 			
				</p>
				<p>The ECB and the national central banks of the euro area are exploring the benefits and risks so that money continues to serve Europeans well.</p>
				<p><a href="https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf#page=4">Report on a digital euro</a>
				</p>
			</div>
		</div>
	</div>
	
	<div>
		<div>
			<div>
				<h3>What are other benefits of a digital euro?</h3>
				<p>A digital euro would preserve the benefits that the euro provides to all of us. It would help to deal with situations in which people no longer prefer cash. </p>
						<p>It would help cushion the impact of extreme events â€“ such as natural disasters or pandemics â€“ when traditional payment services may no longer function. It could also be crucial if people were to turn to foreign digital means of payment, which might undermine financial stability and monetary sovereignty in the euro area.
						</p>
		
			</div>
		</div>
	</div>
	

	
<div>
	<div>
		<div>
			<h3>When will it be ready?</h3>
			<p>During the preparation phase, we are working on the concept, starting practical experimentation on possible designs, and discussing with stakeholders and international partners.
					Towards the middle of 2021 we will decide whether to launch a digital euro project. This will be followed by an investigation phase on user requirements and service providers.
								
			</p>
			<p>It would take time to develop a safe, accessible and efficient digital currency. We will ensure that the systems we use to pay keep up with the needs of the people who use them.   </p>
			
		</div>
	</div>
</div>






</div>
<div>
	<p><em>â€œWe need to make sure that our currency is fit for the future. Inaction is not an option.â€</em></p>
				  <p><strong>Fabio Panetta, ECB Executive Board Member</strong></p>
				</div>

<!-- <hr class="dark thick no-top-margin"> -->
<div>
	<div>
		<p>
			<h3>Weâ€™ve analysed the possible benefits and challenges of a digital euro
			</h3>
		</p>
	</div>
</div>



<!--<div class="ecb-grid grid-width-12 ecb-grid-bottom-padding">
  <div class="ecb-grid inside min-full-height flex flex-column-nowrap container-special-box">
    <div class="ecb-box modernBox highlight-medium flex-grow centeredText">
      <h3 class="no-margin-bottom">Read more and join the conversation</h3>
    </div>
  </div>
</div>	-->
	
  <div>

	<div>
		<div>
			<div>
				<h3>Why would a digital euro not be a crypto-asset?</h3>
				<p>Crypto-assets are fundamentally different from central bank money: their prices are volatile because they lack any intrinsic value and there is no reliable institution backing them. 
				</p>
			<p>People using a digital euro would have the same level of confidence as with cash, since they are both backed by a central bank, which is something crypto-assets such as stablecoins cannot provide.  </p>
			
			<p><a href="https://www.ecb.europa.eu/explainers/tell-me/html/what-is-bitcoin.en.html">Explainer: What is bitcoin?</a> </p>
					</div></div>
			</div>


 
	  
  <div>
	<div>
	  <div>
		<h3>Share your opinion with us!</h3>
		
		 <p>Like the euro we already use every day, the design of a digital euro should meet the needs of a broad range of users. Any assessment must therefore take into account all of its implications, for instance for monetary policy and financial stability.
  </p>
 <p>We will open a public consultation on 12 October â€“ stay tuned!</p>  
		  <p>Do you have any questions? <a href="mailto:DigitalEuro@ecb.europa.eu">E-mail us</a>.</p>
	  </div>
	</div>
  </div>
   
	</div>


<div>
  <div>
    <p>
      <h3>Speeches, interviews and publications</h3>
    </p>
  </div>
</div>

			
		
							


					</main>
						
				</div></div>]]>
            </description>
            <link>https://www.ecb.europa.eu/euro/html/digitaleuro.en.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686582</guid>
            <pubDate>Mon, 05 Oct 2020 11:19:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fortunately, I don't squash my commits]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 319 (<a href="https://news.ycombinator.com/item?id=24686527">thread link</a>) | @lelf
<br/>
October 5, 2020 | https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/ | <a href="https://web.archive.org/web/*/https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>
		<em>The story of a bug, and how I addressed it.</em>
	</p>
	<p>
		Okay, I admit it: I could have given this article all sorts of alternative titles, each of which would have made as much sense as the one I chose. I didn't want to go with some of the other titles I had in mind, because they would give it all away up front. I didn't want to spoil the surprise.
	</p>
	<p>
		I recently ran into this bug, it took me hours to troubleshoot it, and I was appalled when I realised what the problem was.
	</p>
	<p>
		This is the story of that bug.
	</p>
	<p>
		There are several insights from this story, and I admit that I picked the most click-baity one for the title.
	</p>
	<h3 id="94bc204499df483897121bb0343f73f7">
		Yak shaving <a href="#94bc204499df483897121bb0343f73f7" title="permalink">#</a>
	</h3>
	<p>
		I was working on the umpteenth variation of an online restaurant reservations system, and one of the features I'd added was a schedule only visible to the <a href="https://en.wikipedia.org/wiki/Ma%C3%AEtre_d%27h%C3%B4tel">maÃ®tre d'</a>. The schedule includes a list of all reservations for a day, including guests' email addresses and so on. For that reason, I'd protected that resource by requiring a valid <a href="https://en.wikipedia.org/wiki/JSON_Web_Token">JSON Web Token</a> (JWT) with an appropriate role.
	</p>
	<p>
		I'd deployed a new version of the API and went for an ad-hoc test. To my surprise, that particular resource didn't work. When I tried to request it, I got a <code>403 Forbidden</code> response.
	</p>
	<p>
		"That's odd," I though, "it worked the last time I tried this."
	</p>
	<p>
		The system is set up with continuous deployment. I push <em>master</em> to a remote repository, and a build pipeline takes over from there. It only deploys the new version if all tests pass, so my first reaction was that I might have made a mistake with the JWT.
	</p>
	<p>
		I wasted significant time decoding the JWT and comparing its contents to what it was supposed to be. I couldn't find any problems.
	</p>
	<p>
		I also meticulously compared the encryption key I'd used to sign the JWT with the key on the server. They were identical.
	</p>
	<p>
		Incredulous, and running out of ideas, I tried running all tests on my development machine. Indeed, all 170 tests passed.
	</p>
	<p>
		Finally, I gave up and ran the API on my development machine. It takes all of a 30 seconds to configure the code to run in that environment, so you're excused if you wonder why I didn't already do that. What can I say? I've almost two decades of experience with automated test suites. Usually, if all tests pass, the problem is environmental: a network topology issue, a bad or missing connection string, a misconfigured encryption key, an invalid JWT, things like that.
	</p>
	<p>
		To my surprise, the problem also manifested on my machine.
	</p>
	<h3 id="b726532ae06844eb8aeaa2c27ca0d913">
		Not my code <a href="#b726532ae06844eb8aeaa2c27ca0d913" title="permalink">#</a>
	</h3>
	<p>
		Okay, even with hundreds of tests, perhaps some edge case went unnoticed. The only problem with that hypothesis was that this was hardly an edge case. I was only making a <code>GET</code> request with a <code>Bearer</code> token. I wasn't going through some convoluted sequence of steps.
	</p>
	<pre>GET /restaurants/1/schedule/2020/9/30 HTTP/1.1
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5c[...]</pre>
	
	<p>
		I expected a successful response containing some JSON, but the result was <code>403 Forbidden</code>. That was the same behaviour I saw in the production environment.
	</p>
	<p>
		Now, to be clear, this is indeed a protected resource. If you present an invalid JWT, <code>403 Forbidden</code> is the expected response. That's why I wasted a few hours looking for problems with the the JWT.
	</p>
	<p>
		I finally, hesitatingly, concluded that the problem might be somewhere else. The JWT looked okay. So, hours into my troubleshooting I reluctantly set a breakpoint in my code and started the debugger. It isn't rational, but I tend to see it as a small personal defeat if I have to use the debugger. Even so, if used judiciously, it can be an effective way to identify problems.
	</p>
	<p>
		The debugger never hit my breakpoint.
	</p>
	<p>
		To be clear, the beginning of my Controller method looked like this:
	</p>
	<pre>[<span>Authorize</span>(Roles&nbsp;=&nbsp;<span>"MaitreD"</span>)]
[<span>HttpGet</span>(<span>"restaurants/{restaurantId}/schedule/{year}/{month}/{day}"</span>)]
<span>public</span>&nbsp;<span>async</span>&nbsp;<span>Task</span>&lt;<span>ActionResult</span>&gt;&nbsp;Get(
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;restaurantId,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;year,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;month,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;day)
{
&nbsp;&nbsp;&nbsp;&nbsp;<span>if</span>&nbsp;(!AccessControlList.Authorize(restaurantId))
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>return</span>&nbsp;<span>new</span>&nbsp;<span>ForbidResult</span>();</pre>
	
	<p>
		My breakpoint was on the first line (the <code>if</code> conditional), but the debugger didn't break into it. When I issued my <code>GET</code> request, I immediately got the <code>403 Forbidden</code> response. The breakpoint just sat there in the debugger, mocking me.
	</p>
	<p>
		When that happens, it's natural to conclude that the problem occurs somewhere in the framework; in this case, ASP.NET. To test that hypothesis, I commented out the <code>[Authorize]</code> attribute and reissued the <code>GET</code> request. My hypothesis was that I'd get a <code>200 OK</code> response, since the attribute is what tells ASP.NET to check authorisation.
	</p>
	<p>
		The hypothesis held. The response was <code>200 OK</code>.
	</p>
	<h3 id="fdff404f12644a898b6a3e695fb6533f">
		Test interdependency <a href="#fdff404f12644a898b6a3e695fb6533f" title="permalink">#</a>
	</h3>
	<p>
		I hate when that happens. It's up there with fixing other people's printers. The problem is in the framework, not in my code. I didn't have any authorisation callbacks registered, so I was fairly certain that the problem wasn't in my code.
	</p>
	<p>
		I rarely jump to the conclusion that there's a bug in the framework. In my experience, <a href="https://blog.codinghorror.com/the-first-rule-of-programming-its-always-your-fault">select is rarely broken</a>. My new hypothesis had to be that I'd somehow managed to misconfigure the framework.
	</p>
	<p>
		But where? There were automated tests that verified that a client could request that resource with a valid JWT. There were other automated tests that verified what happened if you presented an invalid JWT, or none at all. And all tests were passing.
	</p>
	<p>
		While I was fiddling with the tests, I eventually ran a parametrised test by itself, instead of the entire test suite:
	</p>
	<pre>[<span>Theory</span>]
[<span>InlineData</span>(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>"Hipgnosta"</span>,&nbsp;2024,&nbsp;11,&nbsp;&nbsp;2)]
[<span>InlineData</span>(&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span>"Nono"</span>,&nbsp;2018,&nbsp;&nbsp;9,&nbsp;&nbsp;9)]
[<span>InlineData</span>(<span>"The&nbsp;Vatican&nbsp;Cellar"</span>,&nbsp;2021,&nbsp;10,&nbsp;10)]
<span>public</span>&nbsp;<span>async</span>&nbsp;<span>Task</span>&nbsp;GetRestaurantScheduleWhileAuthorized(
&nbsp;&nbsp;&nbsp;&nbsp;<span>string</span>&nbsp;name,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;year,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;month,
&nbsp;&nbsp;&nbsp;&nbsp;<span>int</span>&nbsp;day)</pre>
	
	<p>
		This parametrised test has three test cases. When I ran just that test method, two of the test cases passed, but one failed: the <em>Nono</em> case, for some reason I haven't yet figured out.
	</p>
	<p>
		I didn't understand why that test case ought to fail while the others succeeded, but I had an inkling. I commented out the <em>Nono</em> test case and ran the test method again.
	</p>
	<p>
		One passed and one failing test.
	</p>
	<p>
		Now <em>The Vatican Cellar</em> test case was failing. I commented that out and ran the test method again. The remaining test case failed.
	</p>
	<p>
		This reeks of some sort of test interdependency. Apparently, <em>something</em> happens during the first test run that makes succeeding tests pass, but it happens too late for the first one. But what?
	</p>
	<h3 id="c95c3e707f46467abbf8ff02a9594c4c">
		Bisect <a href="#c95c3e707f46467abbf8ff02a9594c4c" title="permalink">#</a>
	</h3>
	<p>
		Then something occurred to me that I should have thought of sooner. This feature used to work. Not only had the tests been passing, but I'd actually interacted with the deployed service, presenting a valid JWT and received a <code>200 OK</code> response.
	</p>
	<p>
		Once than dawned on me, I realised that it was just a manner of performing a binary search. Since, of course, I use version control, I had a version I knew worked, and a version that didn't work. The task, then, was to find the commit that introduced the defect.
	</p>
	<p>
		As I've already implied, the system in question is an example code base. While I have a cloud-based production environment, none but I use it. It had been four or five days since I'd actually interacted with the real service, and I'd been busy making changes, trusting exclusively in my test suite. I tend to make frequent, small commits instead of big, infrequent commits, so I had accumulated about a hundred and fifty commits since the 'last known good' deployment.
	</p>
	<p>
		Searching through hundreds of commits sounds overwhelming, but using binary search, it's actually not that bad. Pick the commit halfway between the 'last known good' commit and the most recent commit, and check it out. See if the defect is present there. If it is, you know that it was introduced somewhere between the commit you're looking at, and the 'last known good' commit. If it isn't present, it was introduced later. Regardless of the outcome, you know in which half to look. You now pick a new commit in the middle of that set and repeat the exercise. Even with, say, a hundred commits, the first bisection reduces the candidate set to 50, the next bisection to 25, then 13, then 7, 4, 2, and then you have it. If you do this systematically, you should find the exact commit in less than eight iterations.
	</p>
	<p>
		This is, as far as I understand it, the algorithm used by <em>Git bisect</em>. You don't have to use the <code>bisect</code> command - the algorithm is easy enough to do by hand - but let's see how it works.
	</p>
	<p>
		You start a <code>bisect</code> session with:
	</p>
	<pre><span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((93c6c35...))</span>
$ git bisect start

<span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((93c6c35...)|BISECTING)</span></pre>
	
	<p>
		This starts an interactive session, which you can tell from the Git integration in Git Bash (it says <code>BISECTING</code>). You now mark a commit as being bad:
	</p>
	<pre>$ git bisect bad

<span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((93c6c35...)|BISECTING)</span></pre>
	
	<p>
		If you don't provide a commit ID at that point, Git is going to assume that you meant that the current commit (in this case <code>93c6c35</code>) is bad. That's what I had in mind, so that's fine.
	</p>
	<p>
		You now tell it about a commit ID that you know is good:
	</p>
	<pre>$ git bisect good 7dfdab2
Bisecting: 75 revisions left to test after this (roughly 6 steps)
[1f78c9a90c2088423ab4fc145b7b2ec3859d6a9a] Use InMemoryRestaurantDatabase in a test

<span>mark@Vindemiatrix</span> <span>MINGW64</span> <span>~/Documents/Redacted/Restaurant</span> <span>((1f78c9a...)|BISECTING)</span></pre>
	
	<p>
		Notice that Git is already telling us how many iterations we should expect. You can also see that it checked out a new commit (<code>1f78c9a</code>) for you. That's the half-way commit.
	</p>
	<p>
		At this point, I manually ran the test method with the three test cases. All three passed, so I marked that commit as good:
	</p>
	<pre>$ git bisect good
Bisecting: 37 revisions left to test after this (roughly 5 steps)
[5abf65a72628efabbf05fccd1b79340bac4490bc] â€¦</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/">https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/</a></em></p>]]>
            </description>
            <link>https://blog.ploeh.dk/2020/10/05/fortunately-i-dont-squash-my-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24686527</guid>
            <pubDate>Mon, 05 Oct 2020 11:09:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast, consistent, durable and scalable streaming data with Pravega]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24685835">thread link</a>) | @fpj
<br/>
October 5, 2020 | https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/ | <a href="https://web.archive.org/web/*/https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <!-- Share buttons by mashshare.net - Version: 3.7.7--><p><em><a href="https://es.linkedin.com/in/raulgraciatinedo">Raul Gracia</a> and <a href="https://www.linkedin.com/in/flavio-junqueira-bab134/">Flavio Junqueira</a></em></p>
<h2>Introduction</h2>
<p>Streaming systems continuously ingest and process data from a variety of data sources. They build on append-only data structures to enable efficient write and read access, targeting low-latency end-to-end. As more of the data sources in applications are machines, the expected volume of continuously generated data has been growing and is expected to grow further [1][2]. Such growth puts pressure on streaming systems to handle machine-generated workloads not only with low latency, but also with high throughput to accommodate high volumes of data.</p>
<p><a href="https://pravega.io/" target="_blank" rel="noopener">Pravega</a>&nbsp;(â€œgood speedâ€ in Sanskrit) is an open-source storage system for streams that we have built from the ground up to ingest data from continuous data sources and meet the <a href="https://pravega.io/docs/latest/" target="_blank" rel="noopener">stringent requirements</a> of such streaming workloads. It provides the ability to store an unbounded amount of data per stream using&nbsp;<a href="https://pravega.io/docs/latest/pravega-concepts/#a-note-on-tiered-storage" target="_blank" rel="noopener">tiered storage</a>&nbsp;while being <a href="https://pravega.io/docs/latest/pravega-concepts/#elastic-streams-auto-scaling" target="_blank" rel="noopener">elastic</a>, <a href="https://pravega.io/docs/latest/pravega-concepts/#architecture">durable</a> and <a href="https://pravega.io/docs/latest/pravega-concepts/#ordering-guarantees" target="_blank" rel="noopener">consistent</a>. Both the write and read paths of Pravega have been designed to provide low latency along with high throughput for event streams in addition to features such as long-term retention and stream scaling. This post is a performance evaluation of Pravega focusing on the ability of reading and writing.</p>
<p>To contrast with different design choices, we additionally show results from other systems: <a href="https://kafka.apache.org/">Apache Kafka</a> and <a href="https://pulsar.apache.org/">Apache Pulsar</a>. Initially qualified as messaging systems, both Pulsar and Kafka make a conscious effort to become more like a storage system; they have recently added features like tiered storage. These systems have made fundamentally different design choices, however, leading to different behavior and performance characteristics that we explore in this post.</p>
<p>The main aspects covered in this post and the highlights of our results are the following:</p>
<ul>
<li><em><a href="#pravega-ingestion">Overall ingestion performance</a>.</em>&nbsp;A Pravega writer produces over <strong>1 million events</strong>&nbsp;<strong>per second</strong>&nbsp;<strong>for small events</strong> (100 bytes) and <strong>sustains 350MB/s throughput for large events</strong> (10,000 bytes), both with <strong>single-digit millisecond latency</strong>&nbsp;(at the 95th percentile).</li>
<li><a href="#durability"><em>Durability</em></a>. <strong>Pravega always makes the data durable on acknowledgment</strong>. The write throughput of Kafka is at least 40% less compared to Pravega for a single-segment stream, independent of flushing on every message or not. For a 16-segment stream, the Pravega writer provides comparable throughput to the Kafka writer flushing on every message, but Pravega write latency is lower (<em>i.e.</em>, single-digit millisecond vs. 1+ seconds for Kafka).</li>
<li><em><a href="#dynamic-batching">Dynamically adjusting batches</a>.</em>&nbsp;Pravega <strong>does not</strong>&nbsp;<strong>require a complex configuration for client batching</strong>. The Pulsar client can achieve either low latency or high throughput, but not both. For Kafka, configuring large batches is detrimental for throughput when the application uses routing keys (throughput is 80% lower for a 16-segment stream). In both cases, forcing the user to statically configure batching is undesirable.</li>
<li><em><a href="#high-throughput">Behavior in the presence of large events for throughput-oriented workloads</a>. </em><strong>Pravega obtains up to 350MB/s for a 16-segment stream with 10kB events.&nbsp;</strong>The throughput&nbsp;is 40% higher than the one of Pulsar and comparable to the throughput of Kafka (about 6% difference). However, the latency in the case of Kafka is over 800ms while the one of Pravega is in single-digit milliseconds.</li>
<li><em><a href="#end-to-end-latency">End-to-end latency</a></em>. When tailing a stream, the Pravega reader also provides <strong>single-digit millisecond latency</strong>&nbsp;<strong>end-to-end&nbsp;</strong>while serving data at high throughput. It provides a higher throughput (roughly 80% more) for a single-segment stream when compared to Kafka. For Pulsar, adding partitions and readers leads to lower performance (single-partition case achieves 3.6x the throughput of the 16-segment case).</li>
<li><em><a href="#routing-keys">Use of routing keys</a></em>. <strong>Pravega does not present any significant performance difference when using or omitting routing keys.</strong>&nbsp;For moderate/high throughput rates, Kafka and Pulsar show over 2x end-to-end latency when using routing keys and, specifically for Kafka, a maximum read throughput that is over 37% lower.</li>
<li><em><a href="#historical-catchup">Tiered storage for catch-up and historical reads</a>.</em>&nbsp;Pravega can&nbsp;<strong>catch up with 100GB of historical data dynamically</strong>&nbsp;<strong>while ingesting 100MB per second of new data</strong>. Pulsar with tiering enabled was not able to catch up for the same scenario, inducing a backlog that grows without bounds.</li>
<li><em><a href="#auto-scaling">Performance with auto-scaling</a>. </em><strong>Auto-s</strong><strong>caling is a unique feature of Pravega</strong>. Scaling up a stream provides higher ingestion performance. We show that scaling up a stream using a constant ingestion rate of 100MB/s causes&nbsp;<strong>write latency to drop.</strong></li>
</ul>
<p>Except when we show time series, we plot latency along with throughput. It is a problem we commonly find across blog posts; they plot either latency or throughput, whereas both are jointly relevant for streaming workloads. For example, the maximum throughput for a given configuration might look very good while the latency is of the order of hundreds of milliseconds to a few seconds. We plot latency-throughput graphs to avoid misleading conclusions. We additionally provide tables with the data points used to complement the plots. The tables give more data than the plots (<em>e.g.</em>, different percentile ranks) for completeness.</p>
<h2>Background</h2>
<p>Pravega is a complex system, and we encourage the reader to investigate further our documentation, including <a href="https://blog.pravega.io/" target="_blank" rel="noopener">previous blog posts</a>. Here, we provide a very brief summary of the write and read paths, along with some key points of Kafka and Pulsar.</p>
<h3>The Pravega write path</h3>
<p>Pravega has different APIs for adding data to a stream. In this section, we primarily focus on the <a href="https://pravega.io/docs/latest/javadoc/clients/index.html"><em>event stream API</em></a>.</p>
<p>The <em>event stream writer&nbsp;</em>writes events to a stream. A stream can have parallel segments that can change dynamically according to an auto-scaling policy. When an application provides routing keys, the client uses them to map events to segments.&nbsp; If the routing key is omitted when writing an event, then the client selects a segment randomly.</p>
<p>The client opportunistically batches event data, and writes such batches to a segment. The client controls when to open new batches and close them, but the data for a batch accumulates on the server. The component in Pravega managing segments is called the <em><a href="https://blog.pravega.io/2019/04/22/events-big-or-small-bring-them-on/" target="_blank" rel="noopener">segment store</a></em>. The segment store receives such requests to write to a segment, and both add the data to a cache and appends it to a <em>durable log</em>, currently implemented with <a href="https://bookkeeper.apache.org/" target="_blank" rel="noopener">Apache BookKeeper</a>. When appending to the durable log, the segment store performs a second round of batching. We have this second level of aggregation to sustain high throughput for use cases in which the message size is small and possibly infrequent.</p>
<p>The log guarantees durability: Pravega acknowledges events once they are made durable to the log, and uses such logs only for recovery. As the segment store keeps a copy of the written data to its cache, it flushes data out of the cache to tiered storage, called <em>long-term storage </em>(LTS), asynchronously.</p>
<p>BookKeeper splits its storage among journal, entry logger, and index. The journal is an append-only data structure, and it is the only data structure critical for the write path. Entry loggers and indexes are used in the read path of BookKeeper. In Pravega, the BookKeeper read path is only exercised during the recovery of segment stores. Consequently, the capacity of the write path depends primarily on the journal and not the other data structures, setting aside any occasional interference they can induce.</p>
<h3>The Pravega read path</h3>
<p>An application reads events individually using instances of the <em>event stream reader</em>. Event stream readers form part of a reader group and internally coordinate the assignment of stream segments. Stream readers read from the assigned segments, and they pull segment data from the segment store. Each time a reader fetches segment data, it fetches as much as it is available, up to a maximum of 1MB.</p>
<p>The segment store always serves data from the cache. If it is a cache hit, then serving the read does not require an additional IO. Otherwise, the segment store fetches the data from LTS in blocks of 1MB, populates the cache, and responds to the client. The segment store does not serve reads reading data from the durable log.</p>
<h3>Pulsar and Kafka</h3>
<p>Both Pulsar and Kafka define themselves as streaming platforms. Pulsar implements a broker that builds on Apache BookKeeper. The broker builds on the abstraction of a managed ledger, which is an unbounded log comprising BookKeeper ledgers that are sequentially organized. BookKeeper is the primary data store of Pulsar, although it optionally enables as part of a recent feature to <a href="https://pulsar.apache.org/docs/en/concepts-tiered-storage/" target="_blank" rel="noopener">tier data to long-term storage</a>.</p>
<p>Pulsar exposes the topic abstraction, and enables topics to be partitioned. Pulsar producers produce messages to topics.&nbsp; It provides different options for receiving and consuming messages, such as different subscription modes and reading manually from topics.</p>
<p>Kafka also implements a broker and exposes partitioned topics. Kafka does not use an external storage dependency like Pravega and Pulsar; it relies on local broker storage as the primary storage of the system. There is a proposal for <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage" target="_blank" rel="noopener">adding tiered storage to Kafka in open-source</a>, but to our knowledge, it is only available as a <a href="https://www.confluent.io/blog/infinite-kafka-storage-in-confluent-platform/" target="_blank" rel="noopener">preview feature in the Confluent platform</a>. Consequently, we only compare tiered storage with Pulsar.</p>
<p>Both Pulsar and Kafka implement client batching, and enable the configuration of such batching. For both, two main parameters control client-side batching:</p>
<ul>
<li><strong>Maximum batch size</strong>: this is the maximum amount of data that the client is willing to accumulate for a single batch.</li>
<li><strong>Maximum wait time or linger</strong>: this is the maximum amount of time that the client is willing to wait to close a batch and submit it.</li>
</ul>
<p>There is an inherent trade-off between maximum batch size and waiting time: larger batches favor throughput in detriment of latency, whereas shorter waiting times have the opposite effect. If batches can be accumulated fast enough, then it is possible to obtain both high throughput and low â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/">https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/</a></em></p>]]>
            </description>
            <link>https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685835</guid>
            <pubDate>Mon, 05 Oct 2020 08:55:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying â€œmake invalid states unrepresentableâ€]]>
            </title>
            <description>
<![CDATA[
Score 366 | Comments 180 (<a href="https://news.ycombinator.com/item?id=24685772">thread link</a>) | @fanf2
<br/>
October 5, 2020 | https://kevinmahoney.co.uk/articles/applying-misu/ | <a href="https://web.archive.org/web/*/https://kevinmahoney.co.uk/articles/applying-misu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="applying-make-invalid-states-unrepresentable">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">02 October 2020</time></p>

<p>Here are some real life cases of applying one of my
<a href="https://kevinmahoney.co.uk/articles/my-principles-for-building-software/">favourite principles</a>.</p>

<p>Iâ€™ll try to update this as I come across good examples.</p>

<h2 id="case-1-contiguous-time-periods">Case 1: Contiguous Time Periods</h2>

<p>A straightforward way to represent a period of time is by its start
and end dates (<code>(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c1.png"></p>

<p>If we need to represent a timeline split in to contiguous periods, it
may be tempting to represent this as a sequence of periods (e.g. <code>List
(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c2.png"></p>

<p>However, with this representation there can be both gaps in the
timeline and overlapping periods:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c3.png"></p>

<h3 id="improved-representation">Improved Representation</h3>

<p>We can improve this representation so that the contiguous and
non-overlapping constraints always hold, and we can do this in a way
that may remind you of database normalisation - by removing
redundancy.</p>

<p>In a well formed contiguous timeline, the joint start/end
of the adjacent periods are redundant. Contiguous, non-overlapping
splits can simply be represented by a set of dates (<code>Set Date</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c4.png"></p>

<p>You can begin to see how this representation simplifies the system
when you consider how to make a further split in the timeline. In the
list representation, splitting a period requires carefully modifying
the data-structure and ensuring constraints arenâ€™t violated. In the
â€˜set of datesâ€™ representation you simply add a date to the set.</p>

<p>It is sometimes still useful to represent the periods as a sequence of
start and end dates. It is trivial to project the set of dates in to
this form. As long as the canonical representation is the set, the
constraints will still hold.</p>

<h2 id="case-2-default-contracts">Case 2: Default Contracts</h2>

<p>In this system, a customer pays us a recurring rent based upon a contract.
Contracts last for a fixed amount of time, and when they expire we fall back to
a â€˜default contractâ€™. The customer can have many fixed contracts, and can
sign new contracts at any time.</p>

<p>This was represented as:</p>
<ul>
  <li>A â€˜customersâ€™ table storing
    <ul>
      <li>The customer start date.</li>
      <li>An optional end date, should the customer leave.</li>
    </ul>
  </li>
  <li>A â€˜contractsâ€™ table storing
    <ul>
      <li>The contract start date.</li>
      <li>An optional end date, for default contracts that donâ€™t end.</li>
      <li>If it was a â€˜fixedâ€™ or â€˜defaultâ€™ contract.</li>
    </ul>
  </li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f1.png"></p>
<p>Customer and contract timelines</p>

<p>This representation allows for some undesirable states that are trivial to prevent:</p>
<ul>
  <li>The customer may have gaps in their contracts.</li>
  <li>A fixed contract may not have an end date.</li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f2.png"></p>
<p>Contract gaps</p>

<p>To make matters worse, the API for these contracts allowed you to
modify each individual contract, fixed or default, without guarding against
these states. This shows how a poor choice of
representation propagates itself through the design of a system.</p>

<p>This poor choice was not just a theoretical problem -
gaps in contracts were found on more than one occasion, requiring
hours of engineering effort to hunt down and fix.</p>

<h3 id="improved-representation-1">Improved Representation</h3>

<p>This is easily improved by removing the â€˜defaultâ€™ contracts from the
contract table. If the customer doesnâ€™t have a fixed contract, it is
assumed they are on a default contract:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f3.png"></p>
<p>Inferred default contracts</p>

<p>Now there can no longer be any gaps, and 
the end date of a contract no longer needs to be optional as it only represents fixed contracts.</p>

<p>Itâ€™s worth reiterating that this representation can be projected in to the previous
representation using a database view if that form is more convenient. What is
important is that the underlying representation enforces these constraints, it
is not important how you view the data.</p>

<p>As with the first case, a better representation makes the manipulation
of the data structure simpler. In this case, adding a new fixed contract is
greatly simplified. There is no need to create or modify default contracts, or ensure
that the contracts are contiguous.</p>

<h3 id="the-influence-of-object-oriented-thinking">The Influence of Object-Oriented Thinking</h3>

<p>If this improvement seems obvious to you, you may wonder how the
original design happened in the first place.</p>

<p>I think this happens because of atomistic, object-oriented thinking.</p>

<p>In this mindset, the fixed contracts are <em>objects</em>, the default contracts are
<em>objects</em>, and each of these concepts must be reified as a row in a table and
never inferred.
There is a distrust of using any features the database
offers beyond storing or retrieving <em>objects</em>.</p>

<p>This approach is antithetical to quality relational design and
the principle of making invalid states unrepresentable.</p>

<p>It may feel â€œsimplerâ€ on some level, as you donâ€™t really need
to think about your design.
However, as we see here, this lack of forethought inevitably
leads to complexity.</p>

  </div>
</article></div>]]>
            </description>
            <link>https://kevinmahoney.co.uk/articles/applying-misu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685772</guid>
            <pubDate>Mon, 05 Oct 2020 08:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What you could steal from the Kakoune code editor, and get away with]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24685267">thread link</a>) | @todsacerdoti
<br/>
October 5, 2020 | https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
      <h2>What you could steal from the Kakoune code editor right now, and get away with it</h2>

<p><a href="https://kakoune.org/">Kakoune</a> is a (fairly) young modal code editor
that has matured for as long and as well as a good red wine. It places
multiple-selections, operability and interactivity at the heart of its
distinctive characteristics. It provides users with an efficient and
comfortable text editing experience â€” but thatâ€™s not what this article
is about.</p>

<p>Now 8 years old at the time of writing, Kakoune has gone through several
iterations that removed a dependency here, optimised a core feature there,
even factorised entire parts of its codebase! And as any long-term user
will tell you, itâ€™s easy to take all that good stuff for granted.</p>

<p>So here it is. Iâ€™m stopping time for a couple minutes, and listing in
this article a few things that the Kakoune project does well in several
dimensions. Some are technical, but the rest should hopefully be easily
adaptable to other projects (whether they are code editors or not), and
generic enough to be adopted seamlessly.</p>

<p>Now why does the title of this piece mention stealing? Read on, thatâ€™s item
number one.</p>

<h2 id="from-its-licensing-model">From its licensing model</h2>

<p>If something doesnâ€™t belong to anybody, is it stealing if you take it for
yourself? What if it belongs equally to everybody?</p>

<p>Fortunately we donâ€™t need to solve that problem: Kakoune is a public domain
project. Which means that anyone is free to do anything they want with the
source code of the editor, no questions asked.</p>

<p>This has several advantages:</p>

<ul>
  <li>the tool can be shipped with any distribution or suite, regardless of
licensing</li>
  <li>users can modify the code (to fix bugs, add new features or tweak already
existing ones etc.) and publish it (or compiled binaries) without worrying
about attribution</li>
  <li>it lifts some weight of responsibility of the maintainer for the whole
project, which anyone can re-brand or heavily modify to their liking</li>
</ul>

<p>Users donâ€™t like paying for tools, and when they are free and open-source,
Iâ€™d argue that they turn out to be more useful (with several iterations,
over time) in the end if they place no limits on what users are allowed to
do with the code.</p>

<p>Iâ€™m not in favour of abolishing licenses, I think it would be more
productive for everyone if specialised tools were in the public
domain. In fact, the Kakoune project <em>is</em> licensed, under the
<a href="https://choosealicense.com/licenses/unlicense/">terms</a> of the
<a href="https://unlicense.org/">UNLICENSE</a>, in order to avoid conflicts with
jurisdictions that donâ€™t recognise the <em>public domain</em> model.</p>

<p>As for the small riddle above, thatâ€™s a tough one, bordering on the
philosophical, but since weâ€™re talking about replicating data, we can easily
break out of that paradox: copying is not stealing.</p>

<h2 id="from-its-code">From its code</h2>

<p>New comers like to praise Kakoune for having a clean codebase, easy to
navigate and modify. And for good reason! Written in C++, the code uses the
smallest amount of bells and whistles possible to keep the code elegant,
compilable with (reasonably) old compiler versions, but more importantly
convenient.</p>

<p>And when it comes to convenience, Kakoune has some interesting assets your
project could benefit from:</p>

<ul>
  <li>a header-only implementation of a diffing algorithm
(<a href="https://github.com/mawww/kakoune/blob/master/src/diff.hh">diff.hh</a>)</li>
  <li>a regex engine mostly following the ECMA syntax â€” this implementation
allowed the project to drop
<a href="https://www.boost.org/doc/libs/1_74_0/libs/regex/doc/html/index.html">boost::regex</a>
as a dependency
(<a href="https://github.com/mawww/kakoune/blob/master/src/regex.hh">regex.hh</a>)</li>
  <li>a minimal JSON (un)marshaller
(<a href="https://github.com/mawww/kakoune/blob/master/src/json.hh">json.hh</a>)</li>
  <li>a custom hash map implementation
(<a href="https://github.com/mawww/kakoune/blob/master/src/hash_map.hh">hash_map.hh</a>)</li>
  <li>wrappers for string types (e.g. string view) and associated utilities:
join, wrap, split, quote, pad etc.
(<a href="https://github.com/mawww/kakoune/blob/master/src/string.hh">string.hh</a>
Â· <a href="https://github.com/mawww/kakoune/blob/master/src/string_utils.hh">string_utils.hh</a>)</li>
  <li>various functional range filters: filter, transform, gather, map etc.
(<a href="https://github.com/mawww/kakoune/blob/master/src/ranges.hh">ranges.hh</a>)</li>
  <li>an implementation of Goâ€™s defer statement that runs code once the execution
flow leaves the current scope
(<a href="https://golang.org/ref/spec#Defer_statements">Go specification</a>
Â· <a href="https://github.com/mawww/kakoune/blob/master/src/utils.hh#L53">utils.hh</a>)</li>
</ul>

<p>The above snippets are not exactly drop-in, as they are still coupled to
custom types defined for the editor, but should nonetheless be adaptable
without much difficulty to other C++ projects.</p>

<h2 id="from-its-user-interface">From its user interface</h2>

<p>Originally an easter-egg that savvy users found out about by reading the
code that handles the terminal clientâ€™s user interface, the Clippy character
has become a mascot that is now enabled out of the box. However, although
itâ€™s undeniable that nostalgia for Microsoft Officeâ€™s assistant has fuelled
prolonged interest in Clippy itself, the easter eggâ€™s notoriety has cast a
shadow on the larger feature itâ€™s a prisoner of: the auto-info pop up window.</p>

<p>The auto-info window is a big contributor to the general level of
interactivity the editor provide, as it pops up any time the user hits a
key in normal mode or has typed a function name in the command prompt. Its
purpose is to provide instant feedback to the user, communicate usage
information or possible options that are available to the user. Every time
Iâ€™m using a terminal program that lets me type commands but never hints
at what parameters they take, I sorely wished more people would steal that
from Kakoune!</p>

<p>Another command prompt related improvement that the editor proposes is
fuzzy matching: the user doesnâ€™t need to type out letters that make up
the name of the command they need in order, which makes for much faster
completion selection, and increased discoverability.</p>

<p>All command names in Kakoune are WORDS that start with the name of the
functionality group they belong to. The examples below follow:</p>

<ul>
  <li>to figure out what commands interact with the buffer, typing <code>:buff</code>
would return candidates like <code>buffer-next</code>, <code>lint-buffer</code>,
<code>format-buffer</code>â€¦</li>
  <li>to call the <code>lint-buffer</code> command, typing <code>:lb&lt;tab&gt;</code> would insert the
entire command name in the prompt</li>
</ul>

<p>Use Kakoune once, and youâ€™ll wish your browser enabled fuzzy
matching in your history/bookmarks for the rest of your days. But
you might wonder: there are individual tools that handles
fuzzy-matching, like <a href="https://github.com/junegunn/fzf">fzf</a>,
<a href="https://github.com/kien/ctrlp.vim">ctrlp</a> or
<a href="https://github.com/jhawthorn/fzy">fzy</a>, what if the user would rather
use them to handle opening, for example, files? Great question! Read on,
thatâ€™s the next dimension I want you to steal from.</p>

<h2 id="from-its-philosophy">From its philosophy</h2>

<p>The UNIX philosophy states that tools should focus on doing one thing,
and do it well. The implications are that tools that implement too many
unrelated features end up providing users with an underwhelming experience
because they only allow so much granularity over their behaviour, and that
their maintainers are spread too thin to improve/fix them.</p>

<p>If we re-frame this into the context of text editing, editors should only
worry about exactly that â€” text editing. And Kakoune does its job as
a UNIX citizen brilliantly, but it also goes one step further: it allows
other tools to interact with it, via shell scripting.</p>

<p>Remember the case of spawning a third-party fuzzy matching program,
above? Without getting into details, in Kakoune youâ€™d implement that by
spawning a new terminal (or pane/tab), which would run the program, and
its output would be interpreted by the editor. Users are free to run any
program they want, any terminal or multiplexer they prefer.</p>

<p>And the concept isnâ€™t bound to terminal programs either, although they are
probably the type of tools that Kakoune users would intuitively want to
interact with, on account of the editor being one itself. For example, do
you want to edit a file using a graphical interface? Try the following:</p>

<div><div><pre><code>:edit %sh{zenity --file-selection}
</code></pre></div></div>

<p>If that doesnâ€™t sound anything special, it means that it makes
sense. Unfortunately, the field of text editors on UNIX systems has over
the years turned into an archipelago, in which every editor aims at being an
island. Job management, shell, terminal emulation,&nbsp;window multiplexingâ€¦
Text editors have turned into closed ecosystems (or Integrated Development
Environments) that provide many (sometimes cardboard-looking) features
unrelated to editing, which new comers have to buy into, or be left out in
the cold.</p>

<p>So hereâ€™s an idea everybody should not feel guilty about stealing, if
applicable to their projects: donâ€™t re-invent the wheel, we have enough
bad imitations already<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> â€” instead, work on ways to make your tools
interface with others more easily!</p>

<p>If you have comments or questions, feel free to drop by the official IRC
channel: #kakoune @ FreeNode.</p>




<p>
    â€” written by

    

    <a href="https://github.com/lenormf">

    

        Frank Lenormand
    </a>

    Â· <time datetime="2020-10-01T00:00:00+00:00">
        <i>1st October 2020</i>
    </time>

    Â· license <strong>CC BY-SA 4.0</strong>
</p>


      
    </div></div>]]>
            </description>
            <link>https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685267</guid>
            <pubDate>Mon, 05 Oct 2020 07:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Principles of Data Oriented Programming]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24684638">thread link</a>) | @viebel
<br/>
October 4, 2020 | https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show | <a href="https://web.archive.org/web/*/https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  <div itemprop="articleBody">
    <div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
<p>This chapter is an attempt to illustrate what are the core principles of Data Oriented Programming as I understand them.
It is highly influenced by my programming experience in Clojure, but I believe that those principles are language agnostic.</p>
<p>One could adhere to them in an Object Oriented (OO) language like Java or C# and one could break them
in a Functional Programming (FP) language like Ocaml, Haskell, JavaScript (or even in Clojure).</p>
<p>In fact, in this chapter, I am going to illustrate how those principles could be applied or broken
in JavaScript, a programming language that supports both FP and OOP.</p>
<p>The principles of Data Oriented (DO) Programming are:</p>

<p>Each principle is explored in a separate article.</p>

<p>Enjoy!</p>
<div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
  </div>

</article><p>
  If you enjoy this kind of interactive articles would you consider a (small) donationğŸ’¸  on <a href="https://www.patreon.com/bePatron?u=18227864">Patreon</a> or at least giving a starâ­ for the Klispe repo on <a href="https://github.com/viebel/klipse/stargazers"> Github</a>?
</p></div>]]>
            </description>
            <link>https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show</link>
            <guid isPermaLink="false">hacker-news-small-sites-24684638</guid>
            <pubDate>Mon, 05 Oct 2020 04:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking static website hosting providers]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24683403">thread link</a>) | @rencire
<br/>
October 4, 2020 | https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/ | <a href="https://web.archive.org/web/*/https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Static websites are still a hot topic. They are fast, and theyâ€™re incredibly secure because there isnâ€™t a CMS to hack. Once you build a static website, however, the question becomes: Where do I host?</p>

<p>In other words: what is the fastest static website hosting provider in 2020? Well, letâ€™s find out!</p>

<!--more-->

<p>I did <a href="https://www.savjee.be/2017/10/Static-website-hosting-who-is-fastest/">a similar test in 2017</a>, so it will be curious to see if the hosting providers have been improving.</p>

<h2 id="test-setup">Test setup</h2>
<p>Just like in 2017, I created a simple webpage that I could host on many services. I opted to use my own homepage, including all the images, CSS, and JS files. I then uploaded these files to the following hosting providers:</p>

<ul>
  <li>
<strong>Pay-as-you-go</strong>
    <ul>
      <li>
<a href="https://aws.amazon.com/s3/" target="_blank" data-no-instant="data-no-instant">AWS S3</a> (Region: <code>eu-west-1</code>, Ireland)</li>
      <li><a href="https://aws.amazon.com/cloudfront/" target="_blank" data-no-instant="data-no-instant">AWS CloudFront</a></li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (regional bucket, <code>europe-west1</code>, Belgium)</li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (multi-region bucket)</li>
      <li>
<a href="https://workers.cloudflare.com/sites" target="_blank" data-no-instant="data-no-instant">Cloudflare Workers Sites</a> ($5/month)</li>
    </ul>
  </li>
  <li>
<strong>Freemium (some parts free)</strong>
    <ul>
      <li><a href="https://firebase.google.com/docs/hosting" target="_blank" data-no-instant="data-no-instant">Firebase Hosting</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Cloudflare CDN</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Netlify</a></li>
    </ul>
  </li>
  <li>
<strong>Free</strong>
    <ul>
      <li><a href="https://pages.github.com/" target="_blank" data-no-instant="data-no-instant">GitHub Pages</a></li>
    </ul>
  </li>
</ul>

<p><em>Quick note</em>: I did not test Microsoft Azure, because I couldnâ€™t sign up for it with my <a href="https://revolut.com/referral/xavierh5x" target="_blank" data-no-instant="data-no-instant">Revolut Visa card</a>. Thanks, Microsoft!</p>

<p>To check the performance, I used Pingdom and <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>. Pingdom measures uptime and response times from <a href="https://my.pingdom.com/probes/feed" target="_blank" data-no-instant="data-no-instant">their worldwide network of probe servers</a> while Oh Dear is located in a single location.</p>

<p>Some other things to keep in mind:</p>

<ul>
  <li>I tested the HTTPS endpoints for all services</li>
  <li>I added <code>index.html</code> to all URLâ€™s, meaning no time wasted resolving the index document</li>
  <li>The services were probed <strong>once every minute</strong> for <strong>10 days</strong>
</li>
  <li>Oh Dear did not only track response times, but also DNS lookup time,  TCP connection time, content download time, and more. Pretty cool! All of the raw data is available at the end of this post.</li>
</ul>

<p><strong>Note:</strong> Pingdom or Oh Dear did NOT sponsor this blog post in any way! <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>, however, gave me a free trial with enough slots for all the test sites. Thanks a lot!</p>

<h2 id="expectations">Expectations</h2>
<p>My expectations are pretty much aligned to when I did this last time around:</p>

<ul>
  <li>I expect paid services to do better than free servers. There must be a reason for the prices they charge, right?</li>
  <li>Firebase and Google Cloud belong to the same company, so I expect them to perform similarly.</li>
  <li>I use CloudFront for my website, so hopefully they donâ€™t come out as a bad option. Otherwise, thereâ€™s some additional homework for me ;)</li>
  <li>Netlify performed quite inconsistently last time around. With a few years passing, I hope they were able to address those issues.</li>
  <li>Last time, I didnâ€™t have Cloudflare in the benchmark. I expect them to be a strong contender, given how popular they are and how many edge locations they have.</li>
</ul>

<h2 id="results">Results</h2>
<p>Hereâ€™s a screenshot from the Pingdom dashboard after 10 days of testing:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-overview.png" alt="Overview of the Pingdom dashboard">
<em>Overview of the Pingdom dashboard</em></p>

<p>At first glance, it seems that all services perform very consistently, with CloudFront, GitHub Pages, and Google Cloud, leading the pack. But letâ€™s not jump to conclusions.</p>

<h3 id="uptime">Uptime</h3>
<p>Letâ€™s start with uptime. All of these services had 100% uptime, except for Firebase. Pingdom detected 1 minute of downtime. One check returned, â€œNetwork is unreachable,â€ and the other returned â€œInvalid certificate.â€</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-error-log.png" alt="Firebase downtime as reported by Pingdom">
<em>Firebase downtime as reported by Pingdom</em></p>

<p>This was not detected by Oh Dear, so Iâ€™m willing to give Firebase the benefit of the doubt and say that this was an issue on Pingdomâ€™s side.</p>

<h3 id="response-times">Response times</h3>
<p>Letâ€™s start with some basic statistics: the median, and average response time of each service (including standard deviation):</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times.png" alt="Median response times, measured by Pingdom">
<em>Median response times as reported by Pingdom</em></p>

<p>A few things might catch your attention:</p>

<ul>
  <li>CloudFront &amp; GitHub Pages are speedy and consistent. They have the lowest median, average, and deviation. Interesting because one is a paid service, while the other is completely free.</li>
  <li>AWS S3 is the slowest of them all (but performs consistently). It is kind of expected from a hosting provider that is located only in a single region (in this case Ireland, <code>eu-west-1</code>)</li>
  <li>Google Cloudâ€™s regional and multi-regional buckets perform fairly alike. Interestingly, both are much faster than S3, which is a comparable service. Is Google doing some caching behind the scenes?</li>
  <li>I expected Cloudflare to be much more competitive with the top rankings, but somehow both their CDN and Workers arenâ€™t the top performers. Their Workers product does, however, perform slightly better than their CDN.</li>
</ul>

<p>Since I used both Pingdom and Oh Dear, letâ€™s check the difference in median response times:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-pingdom-oh-dear.png" alt="Pingdom vs Oh Dear (median response times)">
<em>Pingdom vs Oh Dear (median response times)</em></p>

<p>Interestingly, Oh Dear is reporting much faster response times compared to Pingdom. This is probably related to the fact that they only test from a single (apparently very well connected) location.</p>

<p>Pingdom is testing from various locations around the world, some of which arenâ€™t as well connected, which increases the response times.</p>

<p>Some additional findings:</p>

<ul>
  <li>Somehow, AWS S3 is the fastest performer, even though the content is only hosted in a single location. It also outperformed Amazonâ€™s CDN! Wherever Oh Dear is hosted, it must be somewhere in the EU with good connections to the Ireland region of AWS.</li>
  <li>The difference between CloudFront, S3, Firebase, GitHub Pages, and Google Cloud Storage is minimal. Once more, showing that free and paid services compete quite closely with one another.</li>
</ul>

<h3 id="time-to-first-byte">Time to first byte</h3>
<p>Oh Dear also kept track of other metrics like how long it took for the first bytes to start being transferred. This can give us an indication of how responsive the webserver is (how long does it need to think before being able to fulfill a request).</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-time-to-first-byte.png" alt="Time to first byte: measures responsiveness of web servers">
<em>Time to first byte: measures responsiveness of web servers</em></p>

<ul>
  <li>The â€œsimpleâ€ storage services like S3 and Google Cloud Storage are doing very well.</li>
  <li>Once again, GitHub Pages, Firebase, and CloudFront are great performers, delivering the first byte in under 40ms.</li>
  <li>Surprisingly, Cloudflare is taking quite a while to start delivering the first bytes. Maybe this is due to all of their protection services?</li>
</ul>

<h3 id="compared-to-2017">Compared to 2017</h3>
<p>Comparing this new data with the one from 2017 reveals that not much has changed. Note that here Iâ€™m comparing the data from Pingdom:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-2017-vs-2020.png" alt="Benchmark from 2017 vs 2020: median response times">
<em>Benchmark from 2017 vs 2020: median response times</em></p>

<p>All providers (except GitHub Pages) have become slightly slower. Most noticeably AWS S3 (+13%) and Firebase (+31%). The others are so close to their 2017 performance that I would consider these differences to be in the margin of error.</p>

<p>Netlify has a slower median response time in 2020 compared to 2017. But it did improve massively on its consistency. Last time around, they had weird spikes in performance but not anymore. Nice!</p>

<p>This could be explained by Pingdom having added additional test servers located in areas that are further away from these providers.</p>

<h3 id="trying-to-find-edge-cases">Trying to find edge cases</h3>
<p>A scatter plot reveals that there arenâ€™t many outliers, and no service is suffering from regular spikes in performance. There are some outliers here and there, but I wouldnâ€™t look into them too much:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-scatter-response-times.png" alt="Scatter plot of all response times">
<em>Scatter plot of all response times</em></p>

<p>If we visualize the response times with a box plot, we see something interesting:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-boxplot-response-times.png" alt="Box plot of response times, showing some high spikes">
<em>Box plot of response times, showing some high spikes</em></p>

<p>All services, except for AWS, GitHub Pages, and Firebase, have weird spikes. Last time around, this was only limited to Netlify. Not sure what to make of these, but Iâ€™m guessing itâ€™s more related to Pingdomâ€™s tests than to the services themselves.</p>

<h2 id="conclusions">Conclusions</h2>
<p>Time to draw some conclusions:</p>

<p>The best all-around performer is <strong>AWS CloudFront</strong>, followed closely by <strong>GitHub Pages</strong>. Not only do they have the fastest response times (median), theyâ€™re also the most consistent.</p>

<p>They are, however, closely followed by Google Cloud Storage. Interestingly, there is very little difference between a regional and multi-regional bucket. The only reason to pick a multi-regional bucket would be the additional uptime guarantee.</p>

<p><strong>Cloudflare</strong> didnâ€™t perform as well I wouldâ€™ve expected. Itâ€™s certainly faster than a standard S3 bucket but falls away when compared to other CDNâ€™s like CloudFront. Their Workers product is slightly faster than their CDN, but itâ€™s hard to recommend it when it costs $5 a month, and free products like GitHub Pages perform better.</p>

<p>Netlify has improved big time; the spikes in performance are gone and performs in line with Google Cloud and Firebase hosting.</p>

<h2 id="which-should-you-choose">Which should you choose?</h2>
<p>If you want a fast website without breaking the bank, go for GitHub Pages. Itâ€™s completely free and super fast. It does, however, require you to open source your site.</p>

<p>If thatâ€™s not doable, CloudFront is a good alternative, but its price depends on how much bandwidth you push around. For most personal sites, CloudFront wonâ€™t cost more than a couple of dollars per month. The same thing goes for Google Cloud Storage.</p>

<p>Netlify and Firebase Hosting are pretty solid choices as well. While they donâ€™t perform as well as CloudFront or GitHub Pages, they make up for it with excellent development tools. Everything works out-of-the-box with no configuration required on your end. Just push your website live with their easy to use CLI tools.</p>

<h2 id="download-the-data">Download the data</h2>
<p>The raw CSV data <a href="https://github.com/Savjee/static-website-hosting-benchmark" target="_blank" data-no-instant="data-no-instant">is available on GitHub</a>. Both of 2017 and 2020. Feel free to do your analysis and let me know if you find other interesting things in the dataset. Definitely check out the detailed statistics from Oh Dear!</p>

    </div></div>]]>
            </description>
            <link>https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683403</guid>
            <pubDate>Mon, 05 Oct 2020 00:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Whitworth Three Plates Method (2017)]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24683158">thread link</a>) | @ethanwillis
<br/>
October 4, 2020 | https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method | <a href="https://web.archive.org/web/*/https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper" role="main">
        <!-- CATEGORY NAV -->
        
      <section id="page">

      <div data-content-field="main-content">
        <article id="article-597e8ac1bf629a06939204a8" data-item-id="597e8ac1bf629a06939204a8">

  <!--SPECIAL CONTENT-->

  
     
  

  
  <!--POST HEADER-->
    
  <header>
    
    
  </header>
  
  
  <!--POST BODY-->

  <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1501467179009" id="item-597e8ac1bf629a06939204a8"><div><div><div data-block-type="2" id="block-fbbf397e596a02c81f90"><div><p>A key contribution to precision machine tools was the understanding of the importance of flatness, and the development of processes that are used to make surfaces very flat.&nbsp;Henry Maudslay invented the first machine that could cut standard screw threads and contributed to the invention of the now-common surface plate, which serves an important role in metrology today. A classic book called Foundations of Mechanical Accuracy described this and other concepts in detail. Itâ€™s available as a PDF <a href="http://frank.villaro-dixon.eu/public_upload/Foundations%20of%20Mechanical%20Accuracy%20by%20Wayne%20R%20Moore%20-%201970.pdf">here</a> and in print <a href="https://www.amazon.com/gp/product/B0006CAKT8/ref=as_li_tl?camp=1789&amp;creative=9325&amp;creativeASIN=B0006CAKT8&amp;ie=UTF8&amp;linkCode=as2&amp;linkId=9a3b69c12fefcdb4c52fac9cb6d7d37d&amp;tag=eweinhoffer-20">here</a>.</p><p>Typically made of granite, surface plates act as a datum, or the basis upon which precise measurements and movements can be made. They can be finished to a variety of grades of flatness, based on their intended use, and can even be used to <a href="https://youtu.be/sFrVdoOhu1Q?t=378" target="_blank">build up precise structures</a>&nbsp;(that whole video is a must-watch, btw). When dealing with such flat surfaces, tiny imperfections or gradual wear can have drastic effects: using a gauge over the same spot on a surface plate, or leaving it in a space where the temperature varies by more than a few degrees, can negatively affect their flatness. Due to this, calibrating and conditioning your plate is important. The process is really neat, partially because it requires an autocollimator and an incredibly precise repeat-o-meter. Watch a great video from Tom Lipton about the process <a href="https://www.youtube.com/watch?v=EWqThb9Z1jk">here</a>.</p><p>The neat thing about surface plates is that they do not require precision tools to create. By using the â€œthree plate methodâ€, developed by Joseph Whitworth, flat surfaces can be created by using gravity and a simple hand-scraping tool, or by lapping the plates against each other. By starting with three plates of relative flatness, rubbing the plates against each other in alternating pairs to remove the high spots can yield fantastic results.&nbsp;</p><p>The process can be completed in six steps, and then repeated until the desired level of flatness is achieved. In this visual explanation, the surface finishes of the three plates are exaggerated. Before beginning this process, the three plates (Red, Green and Blue) should be machined or ground to as flat a surface as possible, to remove all unnecessary lapping work. In addition, a fine abrasive compound is often used between plates to assist in material removal. Tom also has <a href="https://youtu.be/rHmsQEAx16o" target="_blank">a great video series</a> about this, which includes some compound and technique recommendations.</p><h3><strong>STEP 1</strong></h3><p>To begin, the Red and Green plates are lapped against each other in an alternating manner. That is, one plate remains stationary while the other is lapped against it, and then the opposite is performed:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_27886"><div><p>At the completion of this step, the Red and Green plates â€œagree withâ€ each other, but that is all.</p><h3><strong>STEP 2</strong></h3><p>Next, the Red plate acts as the control (it remains stationary) while the Blue plate is lapped against it:</p></div></div><div data-aspect-ratio="61" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_70590"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466847775-58UA12B6IE1GFQINDMGP/ke17ZwdGBToddI8pDm48kKjydk0csocbYJxIVcMQ1bZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzqU3cEBtqRRwYjAYGyosNgQsOKq0UmUo64vi4mlvYfjdsZzedh78aVv83vtx0Hbu8/Step2.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466847775-58UA12B6IE1GFQINDMGP/ke17ZwdGBToddI8pDm48kKjydk0csocbYJxIVcMQ1bZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzqU3cEBtqRRwYjAYGyosNgQsOKq0UmUo64vi4mlvYfjdsZzedh78aVv83vtx0Hbu8/Step2.PNG" data-image-dimensions="641x461" data-image-focal-point="0.5,0.5" alt="Step2.PNG" data-load="false" data-image-id="597e90dfe6f2e130978984d8" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_70867"><div><p>At the end of this step, both the Green and Blue plates have picked up the error from the Red plate. They do not agree with each other, however.</p><h3><strong>STEP 3</strong></h3><p>Next, the Green and Blue plates are lapped against each other in an alternating manner:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_77200"><p>Since both of these plates picked up the error of the Red plate from the first two steps, lapping them together removes some of the error from the Red plate, bringing them closer to flat. At this point, the Green and Blue plates are more flat than the Red plate:</p></div><div data-aspect-ratio="33.111111111111114" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_88664"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png" data-image-dimensions="669x316" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="597e913f1e5b6c655dc59803" data-type="image" src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_92197"><div><h3><strong>STEP 4</strong></h3><p>Next, the Green plate acts as the control and the Red plate is lapped against it:</p></div></div><div data-aspect-ratio="46.33333333333333" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_94647"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png" data-image-dimensions="659x381" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="597e91bd893fc0db647a42a7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_94925"><p>At the completion of this step, all three plates are of roughly equal flatness, but one (Green) is convex and the other two are concave:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_121764"><div><h3><strong>STEP 5</strong></h3><p>Next, move back to an alternating pattern and lap the two concave plates against each other:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_152855"><p>This results in two fairly flat plates. At this point, only the Green plates needs to be brought to the same level of flatness as the other two.</p></div><div data-aspect-ratio="31.88888888888889" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_165836"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475603295-OFW3C82RD552KQ49A7RV/ke17ZwdGBToddI8pDm48kNWCFiWWhfaNS5VLrcZyQutZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyy9Fy2RaNboFpBomQTPg1txkql11BZnuEVTVDPZ9u31D5I1QL-tcg8zvJ8M0lhae8/Step5_result.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475603295-OFW3C82RD552KQ49A7RV/ke17ZwdGBToddI8pDm48kNWCFiWWhfaNS5VLrcZyQutZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyy9Fy2RaNboFpBomQTPg1txkql11BZnuEVTVDPZ9u31D5I1QL-tcg8zvJ8M0lhae8/Step5_result.PNG" data-image-dimensions="658x331" data-image-focal-point="0.5,0.5" alt="Step5_result.PNG" data-load="false" data-image-id="597eb313be6594cef6b0bcbd" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_166114"><div><h3><strong>STEP 6</strong></h3><p>Finally, the single convex plate is lapped against the Blue control plate:</p></div></div><div data-aspect-ratio="38.88888888888889" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_192139"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475861656-22C2B4NEM6ZAZQ0P4K4F/ke17ZwdGBToddI8pDm48kI9eWsscw_kS1_uRgVsEHexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwGSioTyTafrclwm5SZpGyT2rpSgTdNg3Xh5CnqFcW2oD55xYIdUfkjC4EKb91nUpg/Step6.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475861656-22C2B4NEM6ZAZQ0P4K4F/ke17ZwdGBToddI8pDm48kI9eWsscw_kS1_uRgVsEHexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwGSioTyTafrclwm5SZpGyT2rpSgTdNg3Xh5CnqFcW2oD55xYIdUfkjC4EKb91nUpg/Step6.PNG" data-image-dimensions="670x342" data-image-focal-point="0.5,0.5" alt="Step6.PNG" data-load="false" data-image-id="597eb4151b631b24fd8c15c9" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_192416"><p>And the result is three plates that are in agreement with each other!</p></div><div data-aspect-ratio="46.666666666666664" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_200838"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475898272-437GDLHUTW5BMSQZQDCN/ke17ZwdGBToddI8pDm48kNvUiQrA4HGuW7moH_5i-xpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzrkbryVTHu8zEnqOVmzRanTXYKAn9EoQRz2Y-iL-5Xp9ba_nGnlK6x3VCG914hy60/Step6_result.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475898272-437GDLHUTW5BMSQZQDCN/ke17ZwdGBToddI8pDm48kNvUiQrA4HGuW7moH_5i-xpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzrkbryVTHu8zEnqOVmzRanTXYKAn9EoQRz2Y-iL-5Xp9ba_nGnlK6x3VCG914hy60/Step6_result.PNG" data-image-dimensions="667x386" data-image-focal-point="0.5,0.5" alt="Step6_result.PNG" data-load="false" data-image-id="597eb43ae58c621d0696f9cf" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_201115"><div><p>Itâ€™s also worth noting that, although this yields great precision â€œfrom nothingâ€, Joseph Whitworth later improved upon the technique by utilizing engineerâ€™s blue and hand scraping, as mentioned previously. Engineerâ€™s blue alone would be an instrumental improvement over using no indicator - with the blue, itâ€™s easy to see which areas have, and havenâ€™t been, scraped.</p><p>Let me know if youâ€™ve tried this yourself or have any comments about how I can improve the instruction. Most of what I know about the original Three Plates Method came from <a href="https://etshare.pbworks.com/f/Chapter%2014%20Reference%20Planes.pdf" target="_blank">this PDF</a>.</p></div></div><div data-block-type="44" id="block-yui_3_17_2_1_1571515799694_114027"><p><span data-preserve-html-node="true" size="2"><span data-preserve-html-node="true"><span data-preserve-html-node="true" color="#d6d6d6">Note: ericweinhoffer.com is a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to amazon.com.</span></span></span></p></div></div></div></div></div>
      
  <!--POST FOOTER-->
    
  
  

</article>




<!--PAGINATION-->
  

  




<!-- COMMENTS -->


      </div>

      
        
      

      </section>
      </div></div>]]>
            </description>
            <link>https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683158</guid>
            <pubDate>Sun, 04 Oct 2020 23:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting Lemire's nearly divisionless random number generator]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24682483">thread link</a>) | @fanf2
<br/>
October 4, 2020 | https://veryseriousblog.com/posts/dissecting-lemire | <a href="https://web.archive.org/web/*/https://veryseriousblog.com/posts/dissecting-lemire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-74174200445ef6e30546"><div><p>This blog post is very late. Itâ€™s well over a year since<a href="https://twitter.com/colmmacc/status/1153727018896244736"> I posted a coding challenge on twitter</a>. The idea was simple, Iâ€™ve always felt that code readability is undervalued so I figured Iâ€™d put cold hard cash up. I announced a $1,000 pot, divided into $500, $300, and $200 prizes for the most readable implementations of <a href="https://lemire.me/blog/2019/06/06/nearly-divisionless-random-integer-generation-on-various-systems/">Daniel Lemireâ€™s nearly divisionless algorithm for selecting a random number from an interval.</a> I now have winners to announce and congratulate, and theyâ€™re in this blog post, but thereâ€™s more to this story.</p><p>I didnâ€™t know it at the time but Iâ€™d end up reviewing the entries with colleagues to see if they could follow what was happening (spoiler: they couldnâ€™t). When people got stuck, weâ€™d whiteboard&nbsp;our way through so that we could better understand why and where people were getting stuck. Oh, to be able to whiteboard in person again!  </p><p>I learned a lot about how people think through problems, and that process led to me writing a seperate implementation of Lemireâ€™s Algorithm, with a twenty-to-one comment to code ratio (thatâ€™s a lot of comments), and finding a sort-of security issue with the algorithm in the process. I say â€œsort ofâ€ because you really have a ridiculously enormous struggle to find a case where itâ€™s going to be practical to exploit. But it still surprised me, and you probably canâ€™t use Lemireâ€™s algorithm in Vegas.</p><h4>Why Lemireâ€™s Algorithm?</h4><p>I chose Lemireâ€™s algorithm because it is brilliant. When I read Lemireâ€™s code I get that kind of brain-tingling and gawk at the sheer â€œHow on earth did someone think of thisâ€ of it all. Lemire has a mastery of code and how code is executed, and then pairs that with transcendent creativity and concision.  Lemire also writes well, and the papers that accompany his code and algorithms are easily some of the most cogent and approachable youâ€™ll find in academia. They are short and clear and avoid the jargon and obtuseness that plagues the field, while containing just enough formalism to be rigorous.</p><p>Lemireâ€™s algorithm is a solution to the problem â€œGive me a random number between 0 and N, not including N itselfâ€. For simulating a dice, N would be 6 and youâ€™d get back either 0, 1, 2, 3, 4, or 5 with equal probability. Computers like to start at zero. We can always add one to the result to get the familiar results youâ€™d get on a real dice. Iâ€™ve worked on random number generators and written quite a few. In 20 years of doing that, Iâ€™d never come across a solution as cool as Lemireâ€™s.</p><p>Before Lemire, the best-known solutions to this problem required one or two divisions per number generated. You probably learned long division when you were quite young. You may remember that it can be get pretty tedious and cumbersome. Itâ€™s the same for computers. Division is actually one of the slowest things we can ask a computer to do. Lemire avoids division by translating numbers into a much larger number â€œspaceâ€ and using binary-friendly powers-of-two operations instead. His technique almost always avoids needing a division.</p><p>The second reason I chose Lemireâ€™s algorithm is that it is impenetrable upon first reading. There are lucky few people who are so practiced and conversant in number manipulation that they can see inside of algorithms like Neo in the matrix, but I donâ€™t mean them. To the average reader, myself included, itâ€™s not clear whatâ€™s going on and why.</p><p>Lemireâ€™s reference code is fourteen lines long, like a sonnet. Twelve of the lines are simple, and any proficient programmer could tell <em>what</em> they are doing. Two specific lines of the code are pretty hard to decipher.. But the real difficulty is how hard it is to understand <em>why</em> all 14 lines are doing what they are doing, and <em>why</em> it results in a fair and correct algorithm for choosing a random number.</p><div><p>As a case in point, if you read the comments to Lemireâ€™s blog, youâ€™ll find several misunderstandings of the code. Thatâ€™s within an audience of primed Lemire fans and critics who are familiar with the field. <a href="https://arxiv.org/abs/1805.10941">Lemireâ€™s accompanying paper</a> is great and very readable, but it still takes effort and concentration to follow everything. I work on cryptography and write cryptographic code for a living and Iâ€™m not ashamed to tell you it took me about 3 readings to really get it. The algorithm is based on an interaction between two modular spaces, one of which is sized 2 to power of 64, and the other is â€œNâ€ sized, and if I just totally lost you there, I beg forgiveness and if you bear with me I promise thereâ€™s a link to my detailed dissection of how and why everything works. </p><p>All of this makes Lemireâ€™s algorithm a really good challenge for creating a more readable version. Ideally something that an average coder can read in one pass, understand, and agree that itâ€™s correct. </p></div><h4>Why does readability matter?</h4><p>Code readability is the most important pillar of code correctness and maintainability. When code is unreadable, it is harder to spot errors. Thatâ€™s true when youâ€™re doing a code review and itâ€™s even more true when youâ€™re adding more code to an existing code base. Great testing can compensate for some of the correctness challenges, but it doesnâ€™t do as much for maintainability. </p><p>In s2n, one of our <a href="https://github.com/awslabs/s2n/blob/main/docs/DEVELOPMENT-GUIDE.md">development principles</a> is to write clear readable code with a light cognitive load. Weâ€™re serious about it, and I wasnâ€™t going to try and use Lemireâ€™s algorithm in s2n without a very readable implementation.</p><p>Working in software development Iâ€™ve heard the opinion more than once about how programmers and coders should be more familiar with the fundamental mathematics of logic and number theory that underpin their field, and that academic style papers and explanations should be sufficient. I happen to work with teams that are made up of both expert coders and expert mathematicians, and even there I donâ€™t think this is a good idea.</p><p>Software engineering is engineering, which means translating science into solutions that work in the real world.  To wildly generalize, there are better dividends to be found in focusing on deepening ones understanding of the â€œreal worldâ€ part of that, the users, the customers, the business models, usability, ergonomics, and so on, than on the â€œscienceâ€ part of that. Some science is needed, but thereâ€™s a shallow limit. Just as a civil engineer doesnâ€™t need too detailed an understanding of the chemistry of concrete. PHs and setting times, but not quantum numbers.</p><p>Code should be self-documenting. The average programmer, including someone straight out of college, should be able to understand and work on a well put-together codebase. This greatly improves the odds of finding problems, and thatâ€™s what matters. </p><h4>The contest</h4><p>One of the reasons Iâ€™ve been so tardy about this blog post is that the contest didnâ€™t go as Iâ€™d expected. </p><p>Letâ€™s start with the great thing that happened. I got several submissions, more than enough to pick winners from. Many of these submissions are good and do improve upon Lemireâ€™s code. The most common improvement was to use more descriptive names for the variables. Lemire uses variable names such as â€œsâ€, â€œtâ€, â€œlâ€ which seemingly donâ€™t correspond to much. In such a short piece of code, this actually isnâ€™t too big an offense. I kept these terms in my own implementation, because I want to be consistent with the paper, but itâ€™s absolutely a valid improvement. Another great improvement is to write and include tests, which is really an essential part of software development. </p><p>The first place <a href="https://github.com/ziglang/zig/blob/98183e47436699f6e5eab200061c46eec342806e/std/rand.zig#L74-L118">winner</a> did both of these, and also cleared up some of the confusing lines of code by making an implicit truncation explicit. According to GitHub the winner had 5 contributors, but twitter user <a href="https://twitter.com/komu_wairagu/status/1161643573223317504">komu_wairagu</a> submitted it, so thatâ€™s who Iâ€™ll be contacting to Venmo $500.</p><p>The second place <a href="https://github.com/nimia/Lemire_RNG">winner</a> comes from <a href="https://twitter.com/NimrodAviram">Nimrod Aviram</a>, who I know professionally as the discoverer of the DROWN vulnerability and fun person to hang out with at RealWorldCrypto. Nimrodâ€™s implementation includes some great testing too.</p><p>The third place winner wants to stay anonymous, and cheated their way to some bonus points by writing a great implementation in LISP. How can you not love that? If they change their minds about anonymity Iâ€™ll update this post with a link. The sha256 checksum of their implementation is ae008644b2f0b10eddbbce3a0508b103b19925e4e0c9354c569ff0816acb760c. </p><p>Now on to the not as great, and one of the reasons Iâ€™ve taken this long to write. It doesnâ€™t feel right to criticize any of these efforts, made in spare time and as part of a fun challenge I put out there, but none of them actually explained Lemireâ€™s algorithm or broke down how and why it worked. I asked several colleagues to look through these implementations and tell me if they understood what was going on, and the response was a uniform zero. Noone could fully understand even one of the implementations, or Lemireâ€™s original.  When I asked people to also read the paper, things got a bit better, but everyone still seemed to trip on some issues.  These are smart people who absolutely know what they are doing. Iâ€™m sure given more time they could fully understand everything, but that wasnâ€™t the goal. The goal was to have understanding after one or two, or at most just a few, readings.</p><h4>What did people find hard to follow?</h4><p>Talking through things with people I found some common problems. Some directly in the code, and others in the paper. The first line of code that threw people was:</p><pre><code>uint64_t l = ( uint64_t ) m;</code></pre><p>This line of code does an unusual operation called truncation. It takes a 128-bit value â€œmâ€ and truncates that to its least significant 64-bits. All of this is implicit in the code, rather than explicit. Reading the code, you have to recall that m is 128-bits. Then thereâ€™s also the question of why are we doing this truncation? Iâ€™ll leave that for a minute. </p><p>The next problematic line of code was:</p><pre><code>uint64_t t = -s % s;</code></pre><p>This line of code is using an unusual combination of unary negation, on an unsigned int, and the modulus operator.  Nobody remembers what unary negation does to an unsigned int - and why should they â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://veryseriousblog.com/posts/dissecting-lemire">https://veryseriousblog.com/posts/dissecting-lemire</a></em></p>]]>
            </description>
            <link>https://veryseriousblog.com/posts/dissecting-lemire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24682483</guid>
            <pubDate>Sun, 04 Oct 2020 21:43:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[California Is Built to Burn]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24682470">thread link</a>) | @tomohawk
<br/>
October 4, 2020 | https://www.spiegel.de/international/world/fire-historian-on-the-west-coast-wildfires-california-is-built-to-burn-to-burn-explosively-a-44380d6a-b9e6-468c-9090-e7aad3a366b7 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/fire-historian-on-the-west-coast-wildfires-california-is-built-to-burn-to-burn-explosively-a-44380d6a-b9e6-468c-9090-e7aad3a366b7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;f982d5fa-1c5c-4740-8453-32d3c228a31d&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;4848a74d-3440-4ae5-8966-3ef367937e7c&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/f982d5fa-1c5c-4740-8453-32d3c228a31d_w948_r1.77_fpx28.34_fpy44.84.jpg" srcset="https://cdn.prod.www.spiegel.de/images/f982d5fa-1c5c-4740-8453-32d3c228a31d_w520_r1.77_fpx28.34_fpy44.84.jpg 520w, https://cdn.prod.www.spiegel.de/images/f982d5fa-1c5c-4740-8453-32d3c228a31d_w948_r1.77_fpx28.34_fpy44.84.jpg 948w" width="948" height="536" sizes="948px" title="Firefighters battle a blaze in California's Angeles National Forest." alt="Firefighters battle a blaze in California's Angeles National Forest.">
</span>
</span>
</span>

</p>
<figcaption>
<p>Firefighters battle a blaze in California's Angeles National Forest.</p>
<span>
Foto:â€‚Kyle Grillot / EPA-EFE / Shutterstock
</span>
</figcaption>
</figure>
</div><div>
<p><strong>DER SPIEGEL:</strong> The sky over California is reddish brown. An army of nearly 20,000 firefighters has been battling against wildfires that have already charred over 3 million acres, destroyed over 6,000 houses and driven thousands of residents to flee. How could this happen?</p>


<p><strong>Pyne:</strong> California is built to burn, to burn explosively. That is a condition of its physical geography. And then we have decided to meet that implacable force with another one, a society that wants to live there&nbsp;-- and how it chooses to do so. We have relied on firefighting agencies to stand between&nbsp;those two forces. And I think they are reaching the point that they cannot do that.</p>

<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 40/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;9c235991-81c3-4869-86ea-dd5913c9a102&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;1fa8e108-5fdf-4eff-9385-1c9c0957e13e&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/9c235991-81c3-4869-86ea-dd5913c9a102_w568_r0.7613972764949675_fpx48.96_fpy47.93.jpg" srcset="https://cdn.prod.www.spiegel.de/images/9c235991-81c3-4869-86ea-dd5913c9a102_w284_r0.7613972764949675_fpx48.96_fpy47.93.jpg 284w, https://cdn.prod.www.spiegel.de/images/9c235991-81c3-4869-86ea-dd5913c9a102_w335_r0.7613972764949675_fpx48.96_fpy47.93.jpg 335w, https://cdn.prod.www.spiegel.de/images/9c235991-81c3-4869-86ea-dd5913c9a102_w568_r0.7613972764949675_fpx48.96_fpy47.93.jpg 568w" width="568" height="746" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/9c235991-81c3-4869-86ea-dd5913c9a102_w284_r0.7613972764949675_fpx48.96_fpy47.93.jpg 284w, https://cdn.prod.www.spiegel.de/images/9c235991-81c3-4869-86ea-dd5913c9a102_w335_r0.7613972764949675_fpx48.96_fpy47.93.jpg 335w, https://cdn.prod.www.spiegel.de/images/9c235991-81c3-4869-86ea-dd5913c9a102_w568_r0.7613972764949675_fpx48.96_fpy47.93.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<div>
<p><strong>DER SPIEGEL:</strong> Were the fires triggered by climate change?</p><p><strong>Pyne:</strong> Climate change is one factor among many others; it acts as a performance enhancer for fires. This is the fourth year of serial conflagrations. and that is quite remarkable. California would have a bad year and then five or seven or 10 years would pass. Now, we're four years running and there's no reason to think it's going to end.</p>
</div>

<div>
<p><strong>DER SPIEGEL:</strong> Can the cooling off in the fall calm the situation?</p><p><strong>Pyne:</strong> No, the dry katabatic winds like the Santa Ana and the Diablo, especially, increase the wildfire risk, and the wind season is just beginning. The losses could double before the calendar year ends.</p><p><strong>DER SPIEGEL:</strong> Even without climate change, California would be burning just as badly as it does now, Danish academic&nbsp;BjÃ¸rn Lomborg&nbsp;recently wrote in an editorial. Much bigger wildfires than today were already raging over a hundred years ago.</p>
</div>
<p><strong>Pyne:</strong> No, itâ€™s nonsense, to dismiss climate change, of course it plays a role as a performance enhancer. It is true, especially in the 19th century, there was a whole wave of huge mega fires, which often claimed many more lives than today. But at that time, the driving force was the new railroad lines, which opened up the land and triggered a wave of settlement,&nbsp;accompanied by the immense load of debris or slash left by land-clearing and logging. Sometimes more than 400 people died in a single fire. This phase continued into the 1930s. Since then,&nbsp;those conditions have passed&nbsp;and wildland fire fighting has been professionalized and expanded, and California is probably the world leader in this field. So, it looked like the problem was solved, but it wasn't. There are many reasons for this, including the fact that Californiaâ€™s&nbsp;wildfire season now lasts over a month longer than it did then.</p>

<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;853e255e-228a-4f42-8cec-b324557189c7&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;95f7011a-de9c-445b-88ec-be26d1c7075f&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/853e255e-228a-4f42-8cec-b324557189c7_w718_r1.642935377875137_fpx48.67_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/853e255e-228a-4f42-8cec-b324557189c7_w488_r1.642935377875137_fpx48.67_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/853e255e-228a-4f42-8cec-b324557189c7_w616_r1.642935377875137_fpx48.67_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/853e255e-228a-4f42-8cec-b324557189c7_w718_r1.642935377875137_fpx48.67_fpy50.jpg 718w" width="718" height="437" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/853e255e-228a-4f42-8cec-b324557189c7_w488_r1.642935377875137_fpx48.67_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/853e255e-228a-4f42-8cec-b324557189c7_w616_r1.642935377875137_fpx48.67_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/853e255e-228a-4f42-8cec-b324557189c7_w718_r1.642935377875137_fpx48.67_fpy50.jpg 718w" title="Beach goers enjoy St. Andrews State Park in Florida with smoke from controlled fires on the horizon in March 2016." alt="Beach goers enjoy St. Andrews State Park in Florida with smoke from controlled fires on the horizon in March 2016.">
</span>
</span>
</span>
</p><figcaption>
<p>Beach goers enjoy St. Andrews State Park in Florida with smoke from controlled fires on the horizon in March 2016.</p>
<span>
Foto:â€‚Patti Blake/ AP/dpa
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> President Trump remarked that the fire crisis could have been averted by simply "cleaning your floorsâ€ and clearing out some trees and dead underbrush that can act as fuel for a fire.</p><p><strong>Pyne:</strong> That is not&nbsp;wholly&nbsp;wrong.&nbsp;But&nbsp;even if we improve the forest, we're going to be dealing with a worsening climate. In the current political situation, the fires are being misused to redirect to a political agenda. For some, it is all about climate change, for others it is all about logging more. But the issue is much more complex. We are all gathering around the fire, so to speak, everyone is commenting on it, but they all have their backs to the flames. Many people are just using the fire to animate some other message for their particular group. And that does nothing to solve the fire problem.&nbsp;What we need is for everybody to turn around, look at the flames.</p>
</div>

<div>
<p><strong>DER SPIEGEL:</strong> Would it make sense to start regularly controlled fires to reduce the dry biomass, as is done in Florida, for example?</p><p><strong>Pyne:</strong> Yes, prescribed burning makes&nbsp;sense. Florida has&nbsp;a culture of burning that was never extinguished because of ranchers&nbsp;and&nbsp;a lot of favorable conditions.&nbsp;They don't have mountains. They don't have Santa Ana winds. They don't have the concentration of people in the interior.&nbsp;In fact, the&nbsp;saying&nbsp;was Florida burned twice a year because they would burn the same place more than once. So, the state forester of Florida once declared that 100 and 115 percent of the state had burned last year.<strong>&nbsp;</strong>In California, on the other hand, there are many mountainous regions, there are these strong Santa Ana winds, and many people live inland, in the Central Valley, in the Los Angeles basin, where the air quality is notoriously bad, even without fires. And now we're going to put millions or tens of millions of acres to deliberate burning?</p><p><strong>DER SPIEGEL:</strong> If prescribed fires can prevent the big conflagrations, where does the strong aversion come from?</p><p><strong>Pyne:</strong> A very important impulse came from&nbsp;Europe. Bernhard Eduard Fernow, a Prussian forestry official who&nbsp;married an American,&nbsp;came to the United States in 1876, and was soon naturalized. He headed the Bureau of Forestry, which was a small agency in the Department of Agriculture. When&nbsp;Americaâ€™s&nbsp;National Forests were actually transferred to its jurisdiction,&nbsp;it was renamed the Forest Service and headed by Gifford Pinchot, an American who trained in forestry in Europe.&nbsp;But Fernow also brought with him his Central European convictions. The problem was that&nbsp;the place he grew up in&nbsp;is a temperate climate. It's very unusual in the world because it does not have wet and dry periods regularly. So, the only fires that occur in your part of the world are ones set by people. So, fire was seen as a social problem, a problem of social order and disorder. Fernow looked at the American fire scene and declared that it was all a problem of "bad habits and loose morals.â€ Well, thatâ€™s a great phrase. But it was totally inappropriate.</p><p><strong>DER SPIEGEL:</strong> But Fernow is celebrated in America as a pioneer of forestry science.</p><p><strong>Pyne:</strong> Yes, he and his colleagues were smart, committed people, but they had no sense of how fire actually functioned&nbsp;outside of Europe. He didn't understand the ecological role of fire. Many Europeans regarded landscape as a kind of garden and&nbsp;contained fire by intensive cultivation. There's a tradition in European agronomy that really dislikes fire because it's messy. Potentially dangerous. It seems irrational. And there was a very clear distinction made by the 18th century that if you use fire, you are primitive. But in many regions of the world, fire simply belongs to the landscape. And relying exclusively on keeping fire out of the landscape does not work in the long run.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;8a70e03b-fb9d-4741-8c76-46923cfb674a&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;5be4cc50-1a0f-458a-9b42-f2b625f15bee&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/8a70e03b-fb9d-4741-8c76-46923cfb674a_w718_r1.5342960288808665_fpx66.48_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/8a70e03b-fb9d-4741-8c76-46923cfb674a_w488_r1.5342960288808665_fpx66.48_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/8a70e03b-fb9d-4741-8c76-46923cfb674a_w616_r1.5342960288808665_fpx66.48_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/8a70e03b-fb9d-4741-8c76-46923cfb674a_w718_r1.5342960288808665_fpx66.48_fpy50.jpg 718w" width="718" height="468" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/8a70e03b-fb9d-4741-8c76-46923cfb674a_w488_r1.5342960288808665_fpx66.48_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/8a70e03b-fb9d-4741-8c76-46923cfb674a_w616_r1.5342960288808665_fpx66.48_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/8a70e03b-fb9d-4741-8c76-46923cfb674a_w718_r1.5342960288808665_fpx66.48_fpy50.jpg 718w" title="Firefighters battle a blaze on the North Rim near Grand Canyon National Park in Arizona in 2006." alt="Firefighters battle a blaze on the North Rim near Grand Canyon National Park in Arizona in 2006.">
</span>
</span>
</span>
</p><figcaption>
<p>Firefighters battle a blaze on the North Rim near Grand Canyon National Park in Arizona in 2006.</p>
<span>
Foto:â€‚JEFF TOPPING/ REUTERS
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> How did you become a fire historian?</p><p><strong>Pyne:</strong> When I started, the subject didnâ€™t exist yet.&nbsp;It began for me when&nbsp;I was 18, just out of high school, and&nbsp;I worked&nbsp;as a firefighter on the north rim of the Grand Canyon. A lot of people did it for two years. Very few people did it for three. I did it for 15,&nbsp;moving between the&nbsp;wildfire season&nbsp;and the university. I didn't see any reason why I should&nbsp;not&nbsp;continue as long as I&nbsp;went&nbsp;to graduate school and the rest of it. We were a small team&nbsp;that did&nbsp;initial attack (the initial response to a wildfire). At that time,&nbsp;our&nbsp;biggest forest fires were perhaps 300 acres (about 200 soccer fields). That's ridiculously small by todayâ€™s standards. Most forest fires were triggered quite naturally by lightning.&nbsp;The part of firefighting I enjoyed most was what&nbsp;is&nbsp;called "size up.â€ It's when you first reach the fire and you have to make quick judgments. There would be two of us. Can we contain this fire? Do we need to call for some retardant? Do we need reinforcements? If so, what kind?&nbsp;If we&nbsp;can't contain the fire, where do we stop it next? Where do we make a stand?</p><p><strong>DER SPIEGEL:</strong> How did that shape your thinking?</p><p><strong>Pyne:</strong> We developed a very close relationship with fire as part of the landscape: How will it behave? We often sat around the campfire at night and talked endlessly about fire. But what I learned was there was a kind of relationship with fire. And I learned to talk about fires the way most ordinary people would not. You know, there&nbsp;were&nbsp;really sweet fires. There were miserable fires. This was a fun fire. This was a real gut-wrenching fire. You know, this one&nbsp;just kicked us up and down the hill for a week. We were quite isolated at the rim,&nbsp;although there were many tourists and accommodations. It&nbsp;may be&nbsp;hard for people&nbsp;today to appreciate our isolation. We had newspapers that were two or three days old. We certainly had no television. We had no Internet. We had no private phones. It&nbsp;was a great life. Who cared? I&nbsp;learned&nbsp;about the lunar landing in 1969 from <em>Time</em> magazine, which I read days later.</p><p><strong>DER SPIEGEL:</strong> The coronavirus pandemic is often compared to a forest fire. Is that an apt metaphor?</p><p><strong>Pyne:</strong> Yes. Maybe this metaphor even works the other way around: To me, Fire is the <em>other contagion</em>.&nbsp;Wildfires can be described as a kind of infection! But fire is a lot like&nbsp;a&nbsp;virus. It's not alive, but it depends on the living world to spread.&nbsp;And if we start controlled fires to prevent bad fires with good fire, it is similar to an annual flu shot or herd immunity. And then how do we respond to it? Well, you are wearing masks that protect against ember spread. Social distancing. Well, that's like defensible space. Unfortunately, fire research is dominated by physicists and chemists, and we would need biologists to study how fire behaves in an ecosystem -- and how to contain fire with ecological interventions. The corona epidemic can help to find a new language to talk about fire.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;5b46f0ac-0001-0004-0000-000000696307&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;8b6dc414-502e-4349-8973-2ae15c4a24b3&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/5b46f0ac-0001-0004-0000-000000696307_w718_r1.3363028953229399_fpx51.6_fpy52.97.jpg" srcset="https://cdn.prod.www.spiegel.de/images/5b46f0ac-0001-0004-0000-000000696307_w488_r1.3363028953229399_fpx51.6_fpy52.97.jpg 488w, https://cdn.prod.www.spiegel.de/images/5b46f0ac-0001-0004-0000-000000696307_w616_r1.3363028953229399_fpx51.6_fpy52.97.jpg 616w, https://cdn.prod.www.spiegel.de/images/5b46f0ac-0001-0004-0000-000000696307_w718_r1.3363028953229399_fpx51.6_fpy52.97.jpg 718w" width="718" height="537" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/5b46f0ac-0001-0004-0000-000000696307_w488_r1.3363028953229399_fpx51.6_fpy52.97.jpg 488w, https://cdn.prod.www.spiegel.de/images/5b46f0ac-0001-0004-0000-000000696307_w616_r1.3363028953229399_fpx51.6_fpy52.97.jpg 616w, https://cdn.prod.www.spiegel.de/images/5b46f0ac-0001-0004-0000-000000696307_w718_r1.3363028953229399_fpx51.6_fpy52.97.jpg 718w" title="A home burning on top of a hill in San Marcos in San Diego County in May 2014" alt="A home burning on top of a hill in San Marcos in San Diego County in May 2014">
</span>
</span>
</span></p><figcaption>
<p>A home burning on top of a hill in San Marcos in San Diego County in May 2014</p>
<span>
Foto:â€‚Stuart Palley/ dpa
</span>
</figcaption>
</div>
</div>
</div>
</figure>
<div>
<p><strong>DER SPIEGEL:</strong> How can Californians prepare for future wildfire seasons?</p><p><strong>Pyne:</strong> There are a variety of relatively simple interventions. For example, we urgently need to think about where to build houses and how we build â€¦</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/fire-historian-on-the-west-coast-wildfires-california-is-built-to-burn-to-burn-explosively-a-44380d6a-b9e6-468c-9090-e7aad3a366b7">https://www.spiegel.de/international/world/fire-historian-on-the-west-coast-wildfires-california-is-built-to-burn-to-burn-explosively-a-44380d6a-b9e6-468c-9090-e7aad3a366b7</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/fire-historian-on-the-west-coast-wildfires-california-is-built-to-burn-to-burn-explosively-a-44380d6a-b9e6-468c-9090-e7aad3a366b7</link>
            <guid isPermaLink="false">hacker-news-small-sites-24682470</guid>
            <pubDate>Sun, 04 Oct 2020 21:39:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turing Machine Notation and Normal Form]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24681272">thread link</a>) | @nickdrozd
<br/>
October 4, 2020 | https://nickdrozd.github.io/2020/10/04/turing-machine-notation-and-normal-form.html | <a href="https://web.archive.org/web/*/https://nickdrozd.github.io/2020/10/04/turing-machine-notation-and-normal-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>A <strong>Turing machine</strong> (TM) can be defined formally as the collection of the following objects:</p>

<ul>
  <li>a finite, non-empty set ğ‘¸ of <em>active states</em>;</li>
  <li>a distinguished state ğ’’<sub>0</sub> âˆˆ ğ‘¸, the <em>initial state</em>;</li>
  <li>an object ğ’’<sub>H</sub> âˆ‰ ğ‘¸, the <em>halt state</em>;</li>
  <li>a finite set with quantity &gt; 1 ğœ of <em>symbols</em>;</li>
  <li>a distinguished symbol ğœ¸<sub>0</sub> âˆˆ ğœ, the <em>blank symbol</em>;</li>
  <li>a 2-element set ğ‘«, the <em>shifts</em>; and</li>
  <li>a <strong>total</strong> function ğœ¹ : ğ‘¸ Ã— ğœ â†’ ğœ Ã— ğ‘« Ã— ğ‘¸ âˆª { ğ’’<sub>H</sub> }, the <em>transition function</em>.</li>
</ul>

<p>A few remarks about this definition:</p>

<ol>
  <li>Some presentations of TMs allow the transition function to be <strong>partial</strong>, but this difference is inessential; a partial function can be made total by adding a catch-all default case.</li>
  <li>Although the halt state is stipulated to be distinct from the â€œactive statesâ€, it is occasionally convenient to group together the <strong>set of all states</strong>, ğ‘¸ âˆª { ğ’’<sub>H</sub> } (for instance, in the range of the transition function). The expression â€œactive statesâ€ is used in cases where the halt state is not under consideration</li>
  <li>An element of ğ‘¸ âˆª { ğ’’<sub>H</sub> } Ã— ğœ Ã— ğ‘« is known as an <strong><em>action</em></strong>.</li>
  <li><strong>Alternative â€œarchitecturesâ€</strong> can be obtained by modifying this definition. The architecture described here is the <em>quintuple variation</em>, so called because its transition function can be represented as a set of 5-tuples. Another common architecture is the <em>quadruple variation</em>, with the transition function of the form ğ‘¸ Ã— ğœ â†’ ğ‘¸ âˆª { ğ’’<sub>H</sub> } Ã— ğœ âˆª ğ‘«. Whereas the quintuple variation prints and moves at each step, the quadruple variation does one or the other but not both. (In other words, the transition function prescribes different kinds of actions.)</li>
  <li>TMs are typically <strong>grouped by number of active states and symbols</strong>. An <em>n-state, m-symbol</em> TM has <em>n</em> active states and <em>m</em> symbols.</li>
  <li>It has become customary to represent states with capital Roman letters starting with <code>A</code>, with the halt state as <code>H</code> (or something else if itâ€™s needed for the active states), <em>m</em> symbols with the numbers <em>0 â€¦ m-1</em> (with <em>0</em> as the blank symbol), and the shifts with <code>L</code> and <code>R</code> (or something else, if these letter are needed for the active states). In the old days, numbers were used for states, symbols, and shifts, and TM programs were much, much harder to read.</li>
</ol>

<p>Individual TMs are typically <strong>identified</strong> with their transition functions, or with <strong>representations thereof</strong>. These represenations may also be referred to simply as <strong><em>programs</em></strong><sup><a id="fnr.1" href="#fn.1">1</a></sup>. Transition functions are often represented as tables, with actions indexed by state and symbol:</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
      <th>E</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1RB</td>
      <td>1RC</td>
      <td>1RD</td>
      <td>1LA</td>
      <td>1RH</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1LC</td>
      <td>1RB</td>
      <td>0LE</td>
      <td>1LD</td>
      <td>0LA</td>
    </tr>
  </tbody>
</table>

<p>What this says is: if the machine is in state <code>A</code> and scanning a <code>0</code> on the tape, it will print <code>1</code>, shift to the right, and transition to state <code>B</code>, and so on. Less transparently but more compactly, TMs can also be represented as <strong>simple strings</strong>. The actions are laid out, delimited by spaces, in such a way that actions from earlier states go earlier than later ones, and actions from the same state are ordered by the symbol they come from. Thus the table above comes out as <code>1RB 1LC 1RC 1RB 1RD 0LE 1LA 1LD 1RH 0LA</code>.</p>

<p>Table notation is easier to read than string notation, but since itâ€™s not possible in general to tell what a TM does just by looking at it, this is of little benefit. On the other hand, string notation is excellent for <strong>ease of communication</strong>; a string TM description can easily be dropped into an email or a blog comment. String notation is also amenable to the use of <strong>standard text manipulation tools</strong>. For instance, a file of line-separated TMs in string form can be editted with <code>sed</code> and searched with <code>grep</code>.</p>

<p>Given two distinct TM strings, it might be asked if they represent <strong>meaningfully different</strong> programs or if they are only <strong>superficially different</strong>. This question can be answered by defining a canonical representation. A TM string is in <strong><em>lexical normal form</em></strong> iff the following conditions obtain:</p>

<ol>
  <li>The first shift is <code>R</code>.</li>
  <li>The non-initial active states (ğ‘¸ âˆ– ğ’’<sub>0</sub>) first occur in ascending order.</li>
  <li>The non-blank symbols (ğœ âˆ– ğœ¸<sub>0</sub>) first occur in ascending order.</li>
</ol>

<p>The first condition rules out the possibility of two TMs being identical except for <strong>â€œmirror imagesâ€</strong> of each other. The second and third conditions rule out TMs that are the same except for <strong>permutations of states and symbols</strong>. Note that the second condition is trivially true for 1- and 2-state TMs, and the third condition is trivially true for 2-symbol TMs.</p>

<p>Itâ€™s <strong>easy</strong> determine whether or not a given TM is in normal form, and reasonably short TMs can be judged as normal or not by <strong>eyeball</strong>. Itâ€™s also straightforward, though a little more difficult, to <strong>generate</strong> the corresponding normal form for an arbitrary non-normal TM (doing so requires permuting graphs, which can be tricky).</p>

<p>There is another â€œnormal formâ€ that has been in use since the 60s. A TM string is in <strong><em>tree normal form</em></strong> iff the following conditions obtain:</p>

<ol>
  <li>The first shift is <code>R</code>.</li>
  <li>When run on a blank tape, the TM enters its non-initial active states in order.</li>
  <li>When run on a blank tape, the TM prints its non-blank symbols in order.</li>
</ol>

<p>Tree normal form is so-named because it is what results from the <strong>tree generation procedure</strong>. In that procedure, a partially-specified TM is partially run and its transition function â€œholesâ€ are filled in as needed in a â€œtreeâ€ fashion. New states and symbols are added in order, yielding some kind of canonical form.</p>

<p>Notice that the definition of lexical normal form considers only to the TM string itself, and therefore belongs to <strong>static analysis</strong>. In contrast, the definition of tree normal form makes reference to the actual <strong>runtime behavior</strong> of the program represented by the TM string. Unfortunately, this means that it is <strong>not generally decideable</strong> whether a particular TM string is in tree normal form or not, or whether two distinct TM strings have the same tree normal form or not. Without impugning the tree generation procedure, which has been successfully used by researchers for decades, itâ€™s safe to say that â€œtree normal formâ€ is a <strong>misnomer</strong>.</p>

<p>For the reasons above, I propose that <strong>lexical normal form should be considered the canonical representation of TMs, and TM should be communicated and published in lexical normal form</strong>.</p>



<ol>
  <li>Which of the following are in lexical normal form? Which are in tree normal form?
    <ul>
      <li><code>1LB 0RB 1RA 0LC 1RC 1RA</code></li>
      <li><code>1RB 0LB 1LA 0RC 1LC 1LA</code></li>
      <li><code>1LC 0RC 1RB 1RA 1RA 0LB</code></li>
      <li><code>1RC 0LC 1LB 1LA 1LA 0RB</code></li>
    </ul>
  </li>
  <li>Can a program be in both lexical and tree normal forms at once? If so, give an example. If not, why not?</li>
  <li>Write a program to determine whether or not an arbitrary TM string is in lexical / tree normal form.</li>
  <li>Write a program to convert an arbitrary TM string to lexical / tree normal form.</li>
  <li>There are <em>(2m(n+1))<sup>mn</sup></em> <em>n</em>-state <em>m</em>-symbol TMs. How many are there in lexical normal form? How many are there in tree normal form?</li>
</ol>

<p>The following questions have to do with Pascal Michelâ€™s <strong><a href="http://www.logique.jussieu.fr/~michel/ha.html">historical survey of Busy Beaver candidate machines</a></strong>.</p>

<ol>
  <li>Determine <em>by eyeball</em> which programs in the list are in lexical or tree normal forms.</li>
  <li>Use your program from exercise 2 above to determine which programs in the list are in lexical or tree normal form.</li>
  <li>(Extra credit) Go through the list and convert every program to lexical normal form, then email Pascal Michel and politely ask him to update the list to be lexical-normal.</li>
</ol>



<p><sup><a id="fn.1" href="#fnr.1">1</a></sup> In some philosophical quarters a sharp distinction is drawn between <strong>â€œuseâ€ and â€œmentionâ€</strong>. However, itâ€™s both practical and instructive to let oneâ€™s eyes go out of focus when looking at the difference between a â€œTuring machineâ€ and its â€œrepresentationâ€. See <strong><a href="https://nickdrozd.github.io/2020/09/14/programmable-turing-machine.html">â€œAre Turing Machines Programmable?â€</a></strong></p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nickdrozd.github.io/2020/10/04/turing-machine-notation-and-normal-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24681272</guid>
            <pubDate>Sun, 04 Oct 2020 18:43:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple sues Canadian recycling firm for reselling 100k devices, not destroying]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 130 (<a href="https://news.ycombinator.com/item?id=24680870">thread link</a>) | @geuis
<br/>
October 4, 2020 | https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/ | <a href="https://web.archive.org/web/*/https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<!-- .entry-social-links -->
<div>
	
	
	
		
		
	
<!-- .entry-social-links -->	
		
		
	<div>
	<p><a href="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png"><img src="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png" alt="" width="696" height="488" srcset="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png 696w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-350x245.png 350w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-640x449.png 640w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-660x463.png 660w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-560x393.png 560w" sizes="(max-width: 696px) 100vw, 696px"></a></p>
<p>According to <a href="https://thelogic.co/news/exclusive/apple-sues-ontario-electronics-recycling-firm-claiming-it-stole-nearly-100000-products-for-resale/"><em>The Logic</em></a>, an Ontario electronics recycling firm is being sued by Apple, alleging the company stole and resold iOS and watchOS devices instead of destroying them.</p>	
	
	
	
<p>GEEP Canada is being accused of reselling 100,000 iPhones, iPads and Apple Watches, according to Appleâ€™s lawsuit.</p>
<p>Apple says Barrie-based GEEP and members of its senior management team were aware of its activity. GEEP denies all wrongdoing and says when it discovered the reselling ring, it shut it down immediately.</p>
<p>As for damages, Apple is seeking $31 million from GEEP, plus proceeds made from selling iPhones, iPads and Apple Watches.</p>
<p>GEEP was hired by Apple back in the fall of November 2014 to assist in recycling old products instead of being discarded into landfills.</p>
<p>Apple says it sent 531,966 iPhones, 25,673 iPads and 19,277 Apple Watches to GEEP to be recycled from the start of 2015 to the end of 2017, according to lawsuit, seen by <em>The Logic</em>.</p>
<p>â€œAt least 11,766 pounds of Apple devices left GEEPâ€™s premises without being destroyed â€“ a fact that GEEP itself confirmed. These misappropriated devices were then subsequently sold at a significantly higher price than other recycled materials to downstream vendors who refurbished and resold the devices to consumers,â€ explains Appleâ€™s suit, filed in January.</p>
<p>Apple discovered GEEP was moving devices into areas not under camera surveillance after auditing the Ontario companyâ€™s warehouse. The iPhone maker found 18% of devices shipped to GEEP were active on wireless carrier networks.</p>
<p>While some devices like Wi-Fi iPads wonâ€™t show up on carrier networks, which Apple says makes the total number of stolen products higher.</p>
<p>GEEP says the reselling ring was due to three â€œrogueâ€ employees, Roger Micks, Edward Cooper and Steven White, who sold the devices to Fu Yuan Yang at Whitby Recycling. Yang then sold these Apple devices to people in China.</p>
<p>GEEPâ€™s third-party claim from July says it wants these employees, Yang and Whitby Recycling to pay damages if Apple wins, plus cover its legal fees.</p>
<p>The Ontario recycler says it has suffered â€œextensive business lossesâ€ due to the incident and its reputation, to go with Apple cancelling its contract.</p>

	</div>

</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680870</guid>
            <pubDate>Sun, 04 Oct 2020 17:54:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sonos is spying on me (and you)]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 146 (<a href="https://news.ycombinator.com/item?id=24680614">thread link</a>) | @gingerlime
<br/>
October 4, 2020 | https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2630">
		<!-- .entry-header -->

	
	<div>
		
<p>I recently decided to get a wireless speaker for our Kitchen. Sonos seems like an obvious choice these days. The sound quality and aesthetics were very appealing. So I ordered a Sonos One SL speaker.</p>



<p>In terms of sound quality and looks, I was very pleased. Iâ€™m not an audiophile but the sound quality seemed superb and the speaker just looks fantastic. A very clean and unassuming look.</p>



<div><figure><img loading="lazy" width="768" height="1024" src="https://blog.gingerlime.com/assets/IMG_6571-1-768x1024.jpg" alt="" srcset="https://blog.gingerlime.com/assets/IMG_6571-1-768x1024.jpg 768w, https://blog.gingerlime.com/assets/IMG_6571-1-225x300.jpg 225w, https://blog.gingerlime.com/assets/IMG_6571-1.jpg 1024w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"><figcaption>whatâ€™s hiding underneath ?</figcaption></figure></div>



<p><strong>As I later discovered, a dirty beast hides under the cool exterior.</strong></p>



<p>My concerns started to grow almost immediately as I was setting up the new speaker. I downloaded the app, and started the setup process, soon to realize that I need to register with my email just to set up the device on my networkâ€¦ And of course, I had to accept the terms and conditions â€¦. hmmmâ€¦ ok, I guess.</p>



<div><figure><img loading="lazy" src="https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-576x1024.jpeg" alt="" width="236" height="420" srcset="https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-576x1024.jpeg 576w, https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-169x300.jpeg 169w, https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1.jpeg 750w" sizes="(max-width: 236px) 100vw, 236px"></figure></div>



<div><figure><img loading="lazy" src="https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1.png" alt="" width="203" height="361" srcset="https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1.png 375w, https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1-169x300.png 169w" sizes="(max-width: 203px) 100vw, 203px"></figure></div>



<p>I was then asked to allow sharing my location as well, which raised another alarm bell. <strong>Why does my speaker need my location?</strong> Iâ€™m not 100% sure, but if I recall, I had to allow it to access my location, or else I couldnâ€™t continue.</p>



<p>Once the device was finally set up, I went through the settings, to explore and see what else is there. I was rather disappointed to find that <strong>â€œAdditional usage dataâ€ was turned on by default</strong>. I live in Europe, and I thought that the EU regulations should prevent this kind of behaviour. They should explicitly ask my permission to track my usage, especially if it isnâ€™t necessary for the device to function.</p>



<p>I could opt-out of it luckily, but it didnâ€™t feel right to me.</p>



<h2>What data is Sonos collecting, and why?</h2>



<p>Digging into the <a href="https://www.sonos.com/en/legal/privacy" target="_blank" rel="noreferrer noopener nofollow">Sonos privacy policy</a> made my hair standâ€¦ </p>



<div><div>
<h5>Functional Data:</h5>



<div><p>This data is absolutely necessary for your Sonos Product or Service, including Sonos Radio, to perform its basic functions in a secure way and <strong>you will not be able to opt out from this data collection, sharing, and/or processing</strong> if you want to continue to use your Sonos Products.</p><p><strong>We collect:</strong></p></div>



<p><strong>Registration data.</strong> This data includes your email address, location, language preference, Product serial number, IP address, and Sonos account login information (as described above).<br><strong>System data.</strong> This data includes things like Product type, controller device type, controller operating system, software version, content source (audio line in), signal input (e.g. whether your TV outputs a specific audio signal such as Dolby to your Sonos system), information about WiFi antennas, system settings (such as equalisation or stereo pair), Product orientation, names of the music service(s) you added/enabled on your Sonos product, the names you have given your Sonos Product in different rooms, whether your Product has been tuned using Sonos Trueplay technology, system performance metrics (e.g. the temperature of your Product or WiFi signal strength) and error information.</p>
</div></div>



<p>(emphasis not mine)</p>



<p>So this is <em>just</em> the data that you <strong><em>cannot</em></strong> opt-out of. The data <strong>absolutely necessary to perform basic functions.</strong>  And in case you wonder why they track this data, hereâ€™s what the privacy policy says</p>



<div><p><strong>Why we collect Functional Data:</strong> We collect this information to help ensure that your Products are working properly, to provide you with customer support, to honour your audio preferences, and to guide product improvement and customer support decisions. We also collect this information to guide product improvement and customer support decisions which is <strong>our legitimate interest</strong>.</p></div>



<p>emphasis mineâ€¦ weâ€™ll go back to what <em><strong>legitimate interest</strong></em><strong> </strong>actually means later on.</p>



<p>Iâ€™m not sure what basic functions for a speaker might be, that they require to share so much data with Sonos. And if this not enough, thereâ€™s also the (optional) Usage data that Sonos happily collects, by default, without asking for permission</p>



<div><div>
<div><div>
<h5>Additional Usage Data:</h5>



<p>In order to improve your experience with Sonos Products and to offer better, personalised Sonos Products and Services, including Sonos Radio, that meet the needs and expectations of our customers, we collect the following Additional Usage Data. The processing of this information is in our legitimate interest as further set out below (under Why). You can opt out of sharing this data by following the steps listed <a href="https://www.sonos.com/en/legal/privacy#data-opt-out" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p>



<p><strong>We collect:</strong></p>



<ul><li><strong>Performance Information.</strong> This includes things like the temperature of your Product, WiFi information like signal strength, how often you use music services you have connected to your Sonos system (including, for some services, your login username, but not password), information about how often you use the Sonos app versus other control mechanisms, flow of interactions within the Sonos app, how often you use the physical controls on the unit, the flow of interactions within the Sonos app, duration of Sonos Product use, and, as required for certain Services, location-based data using GPS (or similar technology, where available) and crowdsourced WiFi access points and cell tower locations collected from your third party device when the Sonos app is in use.</li><li><strong>Activity Information.</strong> This includes duration of music service use, Product or room grouping information, command information (such as play, pause, change volume, or skip tracks), information about playlist or station container data including listening history (â€˜Recently Playedâ€™), and Sonos playlist or Sonos favourites information; each correlated to individual Sonos Products and your interactions with them. If you enable voice control or use Sonos Radio, we will additionally collect information about track data when using those features.</li></ul>



<blockquote><p><strong>Why:</strong> We collect this information so that we can help ensure Sonos Products are functioning properly, provide a personalised experience for our customers, determine what types of Product or feature improvements would please our customers most, and to help predict potential problems with Sonos Products. Additionally, to provide Sonos Radio, we collect location-based information for licensing and reporting purposes. <strong>Collecting this data is our legitimate interest</strong> to support a user-friendly experience that meets your needs and help you with issues you may experience. It is your choice if you want us to collect this information, and therefore you can opt out of sharing this data by following the steps listed <a href="https://www.sonos.com/en/legal/privacy#rights-choices" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p><p><strong>Note:</strong> personalisation services (e.g. Recently Played), Sonos Radio, Voice Control, and Direct Control functionality require Additional Usage Data to function. If you decide to use any of these features and/or Services, the <a href="https://www.sonos.com/en/legal/privacy#additional-data" target="_blank" rel="noreferrer noopener nofollow">Additional Usage Data</a> becomes functional. You can always clear all Recently Played by following the instructions in the Sonos app.</p></blockquote>
</div></div>
</div></div>



<p>Again, the legitimate interest emphasis is mineâ€¦</p>



<p>If you read their privacy policy further, you could spot the real incentives and potential uses of the data, but I wonâ€™t dive into it here. I do recommend reading it though.</p>



<h2>(il)legitimate interest</h2>



<p>So what is this all about? Well, if youâ€™re familiar with the General Data Protection Regulation (GDPR), you might guess the answer. Iâ€™m not a lawyer, so without going into too much detail, hereâ€™s my brief understanding of it.</p>



<p>First off, the GDPR is the regulation that aims to protect the privacy of all EU citizens. Itâ€™s meant to reduce privacy invasive practices, force companies to protect private data, and encourage companies to treat private data with care and respect.</p>



<p>But whatâ€™s â€œlegitimate interestâ€, and why is it important?</p>



<p>Essentially, companies arenâ€™t simply allowed to store any customer data they want. They need a â€œgood reasonâ€ to do so. Or in other words, they need to have a legitimate interest in storing such data. Otherwise, theyâ€™re simply not allowed to store it at all.</p>



<p>So now, can I just ask someone who accesses my website â€œWhatâ€™s your home addressâ€? and store it, if they give it to me. I need to have a real reason to ask for this address. It can be my legitimate interest to ask it if, for example, Iâ€™m going to send you a free gift. I obviously canâ€™t send you a gift without knowing your address.</p>



<p>As you can imagine, â€œlegitimate interestâ€ can be interpreted in many different ways. Is it legitimate interest to ask for an email address in order to send marketing emails? well, actually it might be. Thereâ€™s no black and white answer here.</p>



<h2>Putting it to the test</h2>



<p>There are <a href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/legitimate-interests/what-is-the-legitimate-interests-basis/#balancing_test" target="_blank" rel="noreferrer noopener">3 tests for â€œlegitimate interestâ€</a>:</p>



<div><div>
<div><div>
<ul><li><strong>Purpose test</strong> â€“ is there a legitimate interest behind the processing?</li><li><strong>Necessity test</strong> â€“ is the processing necessary for that purpose?</li><li><strong>Balancing test</strong> â€“ is the legitimate interest overridden by the individualâ€™s interests, rights or freedoms?</li></ul>
</div></div>



<p>Whilst Sonos tries very hard to meet those first two tests with their policies (but in my opinion, have a very weak position there), I think it clearly fails the balancing test. Sonos blatantly violates its customer privacy by excessively tracking, analysing and making use of very detailed information about them. They capture their listening preferences, their location, neighbouring Wifi access points and lots more. And worse of all, they do it without asking for explicit consent. Itâ€™s all hidden in the privacy policy, and set to expose all this data by default.</p>



<p>Whatâ€™s the <strong>purpose</strong> of collecting all this data? Sonos claims that their purpose is â€œ[To] help ensure Sonos Products are functioning properly, provide a personalised experience for our customers, determine what types of Product or feature improvements would please our customers most, and to help predict potential problems with Sonos Productsâ€. This seems fairly clear as a purpose. Still rather widespread and invasive, but thereâ€™s a purpose.</p>



<p>But is collecting all this data <strong>necessary</strong> to meet this purpose? I donâ€™t think so. I think they collect far too detailed information, and they could meet the same purpose with far less data, or by using non-private / anonymised data. </p>



<p>For example: how does the IP address of the customer help with any of those stated purposes? Or why do they need to map neighbouring Wifi access â€¦</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/">https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/</a></em></p>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680614</guid>
            <pubDate>Sun, 04 Oct 2020 17:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I left my tenured academic job]]>
            </title>
            <description>
<![CDATA[
Score 377 | Comments 222 (<a href="https://news.ycombinator.com/item?id=24680154">thread link</a>) | @adamnemecek
<br/>
October 4, 2020 | https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/ | <a href="https://web.archive.org/web/*/https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><time datetime="2020-10-03T09:00:00+0200">Sat, Oct 3, 2020</time></p>

    <p>RSS: </p> <p><a href="https://reyammer.io/blog/index.xml"><img src="https://reyammer.io/rss.png" width="23px"></a></p>

  <p>The <a href="https://twitter.com/reyammer/status/1311338230139232258" target="_blank">news is out</a>: I left France, I'm no longer a professor at EURECOM, I joined the Malware Research Team at CISCO Talos, and I moved to beautiful Vienna. Big change :-)</p>
<p>I have been a professor for a bit more than three years, but I have had contrasting feelings about the "prof job" for a long time (even before finishing my PhD), it took me a couple of years to realize that I would eventually have needed to move on, and it took even more (mental) effort to actually make the call and leave. Despite being <em>very</em> excited for what's next, oh boy, this was tough :-) But independently of the concrete next step, it was time to move on. Even if Talos realizes the mistake and kicks me out next week, I'm still confident that moving on was the right call.</p>
<p>Especially when it comes to take big decisions, I tend to obsess about trying to stay rational, and I spent years collecting notes on the various pros/cons. Many of these thoughts often started surfacing as "feeling something is not right", without consciously understanding what was going on. But by keep thinking and writing notes down, patterns of thoughts started to emerge and I was eventually able to pinpoint some more defined thoughts on what kept me on the current job and what pushed me to change. Once these reasons were clear, it was much easier to take the decision.</p>
<p>This is a very long blog post, and I don't expect more than a very few people to actually read it. I wrote it mostly for selfish reasons: before changing to a new life, I wanted to wrap up all these notes in something more structured. I can't be certain I took a good decision, but systematizing these thoughts allowed me to move on with enough confidence to know I'm likely making a step forward.</p>
<p>With that being said, I know that someone may be actually interested in hearing these thoughts and my experience. When I was a PhD student and I needed to take the notorious academia vs. industry decision, I would have paid big bucks to read more thoughts on the various pros/cons. One of the stupidest things you can do is to take big decisions based on what other people do and think, but reading about other people's thought process has helped me a lot. It is time I do my part.</p>
<p>The target audience for this post is, other than myself, PhD students / postdocs that are about to decide what to do next and junior profs that somehow feel that "something is wrong". I also expect some senior academics and industry people to read this post, but I guess they will find themselves skipping directly to the academic rant part and mostly agree with much I have to say :-) Anyways, I tried to stay away from the "very known things" (e.g., ğŸ‘€-level BS when writing proposals, generally "more limited" immediate impact of your work, different compensation level, etc.), and I tried to focus on thoughts I have not seen much discussed around (at least not in this depth).</p>
<p>So, if you feel clueless and you want to hear more from an equivalently clueless random dude on the Internet, here we are :-) If you think this is <em>the</em> blog post that will make everything clear, I have a bad news for you: it's all about tradeoffs and in my opinion there is no clear-cut winner. And, unfortunately, the problem with tradeoffs and balancing many aspects is that figuring out which one to weigh more is yet another very personal decision in its own way. So, you will not find any answer in this post and you will eventually need to figure this thing out on your own, but I hope this will help you forming your own opinion.</p>
<p>This post is organized in three parts:</p>
<ul>
<li><a href="#part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good â€” What pushed me to keep the job</a></li>
<li><a href="#part-2-the-bad-mdash-what-pushed-me-to-leave-the-job">Part 2: The Bad â€” What pushed me to leave the job</a></li>
<li><a href="#part-3-the-bye-bye-mdash-the-decision-to-leave">Part 3: The Bye Bye â€” The decision to leave</a></li>
</ul>
<p>Enjoy!</p>
<p><em>Mandatory disclaimer: I have no idea what I'm talking about, and these are personal takes/opinions anyways. Unless you are a bad person, please don't take anything personal. Please feel free to reach out, ping me on twitter, or shoot me an email: I'm of course happy to share more thoughts if you have any question. And if you disagree with something, bring it on! I love to argue, especially with people with strong and different opinions :-)</em></p>
<br>
<h2 id="part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good â€” What pushed me to keep the job</h2>
<p>Before I discuss why I left, I want to touch on what pushed me to keep the job. I want to make sure it's a balanced post despite the upcoming mega rant, so that my overall opinion is more closely reflected. And I really don't want to discourage anyone to take this path, I still think it is a great one.</p>
<p>Note that some of my "reasons to stay" are good, but some are bad. Also note that many of these refer to my personal situation at EURECOM, working in the field of systems security, and not all these points can be generalized to all universities. As they say, your mileage may vary.</p>
<h3 id="its-a-very-good-job">It's a very good job</h3>
<p>The first pros is... ğŸ¥: "it's a very good job". At first, I was shocked to find out that it's an actual job. When I joined this prof thingy I thought that this would be a "job" (note the double quotes). But, while it's true that you don't have a direct boss that tells you what to do, at the end of the day you need to deliver, and you actually work very hard: If your PhD students are in trouble or you teaching sucks, you will run into problems. This doesn't necessarily mean "they kick out", but if you value being a professional (and I do), failing at your core tasks will make you feel bad, even without additional pressure from your superior, and even if you have tenure.</p>
<p>And now that we got this "it's an actual job" out of the way, I can tell you: it's a very good one. There is <em>a lot</em> of freedom in what you do and how you structure your time. Research-wise I felt very free (but you eventually work on what your students like to work on â€” as it should be), and the department values the right things (I've heard some BS in other schools where, in the context of systems security research, they pressure you to "publish more journal papers..." ğŸ¤¦â€â™‚ï¸). I really like teaching and mentoring, and there were many opportunities to do so. They let me create and teach my own class on mobile security, <a href="https://mobisec.reyammer.io/" target="_blank">MOBISEC</a>, and the teaching load is overall very low (1 or 1.5 classes per year). I love playing CTFs and I was even <em>encouraged</em> to spend time and push for NOPS, the EURECOM CTF team (after winning <a href="https://ctftime.org/event/647" target="_blank">HXP CTF 2018</a> and after being referred to as "<a href="https://youtu.be/j0taw78tCYs?t=968" target="_blank">probably a top team</a>" we are mostly enjoying our eternal and well-deserved glory).</p>
<p>The environment is extremely relaxed, informal, and friendly. You are surrounded by top-skilled colleagues and humans, from MS students to profs. I felt in a family from day 1. Last very good point: since in France positions come with tenure, there were not even problems in terms of pre-tenure stress, a real luxury. And on this aspect, EURECOM delivered: I never felt any sort of pressure (but: I did work my ass off... so if you stop doing anything, bad things may happen :-)).</p>
<p>[BTW, EURECOM is frantically trying to replace me, you should apply :-)]</p>
<h3 id="you-are-surrounded-by-students">You are surrounded by students</h3>
<p>When I took my decision to remain in academia, my top reason was for teaching and mentorship. Probably the best perk of the job is that you are surrounded by people eager to learn, from MS to PhD students to postdocs. It is extremely fulfilling and rewarding. Working with my students has been the highlight of my time at EURECOM, from traditional teaching, to suffering through the various rejections, to celebrating defeats of Reviewer #2, to cluelessly getting CTF-close in many stego CTF challenges. I feel very lucky that during these years we found enough interesting ideas that we enjoyed working on together, and that my next job will allow me to keep advising them until they graduate. As a prof, I believe the net output of my work is to see students becoming independent researchers, not the actual papers â€” I can't wait to see the bright careers I'm sure they will have :-)</p>
<h3 id="i-have-deep-respect-for-the-role-of-profs-in-society-and-it-felt-great-to-be-one">I have deep respect for the role of "profs" in society, and it felt great to be one</h3>
<p>I somehow have a profound admiration for the role that professors have in society and that had in my life. For their hard work, knowledge, passion, patience, and ultimately their service to the community. I'm referring to all teachers and mentors (from elementary schools to universities), who spend their life helping others, while at the same time often being asked to do many useless things and being massively underpaid. I admire and deeply respect these efforts: my most sincere thank you to all past, present, and future profs!</p>
<p>And, to be frank, it felt great to be one. I have been in love with the idea of being a prof for many years. In part, I think it is because some of the people who impacted me the most are professors, and I wanted to do my part in helping others. And after all the uncertainties that one has during a PhD, I think I was even more in love with the idea of having finally found my place in society. [Narrator: LOL, this clueless dude did not find his place. [Answer to narrator: But I've surely found it <em>now</em>!!1!]]</p>
<p>Overcoming all these positive emotions and feelings attached to this job was likely the biggest challenge I faced in coming to terms with the several problems and cons I did have during these three years. As mentioned, I have no intention to give up on this teaching/mentoring thing (taking the time for this long blog post is part of this!), but it will surely not be the same thing. I'm very grateful I had a chance to try this job out. Thanks to all who made it possible, from family to advisors, colleagues, and students â¤ï¸. I owe you big time.</p>
<p>[Of course, being a prof does not necessarily make you a smart or great person. Some profs I know are some of the dumbest people I have ever met (by far) and they would not survive one day in the real world. And some profs I know are the most asshole, selfish, egomaniac, and delusional humans I have ever heard of (Are you pushing your students to stay in the lab â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</a></em></p>]]>
            </description>
            <link>https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680154</guid>
            <pubDate>Sun, 04 Oct 2020 16:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running a Unix-like OS on a home-built CPU with a home-built C compiler]]>
            </title>
            <description>
<![CDATA[
Score 565 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24680109">thread link</a>) | @abc_tkys
<br/>
October 4, 2020 | https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/ | <a href="https://web.archive.org/web/*/https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>Itâ€™s been two years since I started working as a software engineer.
I sometimes tell my colleagues about a student project I did in my junior year of university,
and itâ€™s so well-received that Iâ€™m writing this post.
<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Now, let me ask you a question. Have you ever designed your own ISA, built a processor of that ISA on FPGA, and built a compiler for it?
Furthermore, have you run an operating system on that processor?
Actually, we have.</p>
<p>In this post, Iâ€™m going to talk about my undergraduate days in 2015,
our four months of building a home-built CPU of a home-built RISC ISA,
building a home-built C toolchain, and porting Xv6, a Unix-like OS, to that CPU.</p>
<h2 id="cpu-experiment-at-the-university-of-tokyo">CPU Experiment at the University of Tokyo</h2>
<p>It was all done as a student experiment project called CPU Experiment.
So, letâ€™s start with what is CPU experiment.</p>
<p>CPU experiment is a little famous exercise held in the winter of the junior year in my department,
the Department of Information Science at the University of Tokyo.
In the experiment, students are divided into groups of four or five students.
Each group designs an own CPU architecture, implements it on an FPGA,
builds an OCaml subset compiler for that CPU, and then runs a given ray-tracing program on the CPU.
Typically, one or two people are responsible for each of the CPU, FPU, CPU simulator and compiler.
I was in charge of the CPU in my group, Group 6.</p>
<p>This exercise is well known for the high expectation of self learning.
The instructor only asks the students to â€œtake this ray-tracing program written in OCaml and run it on your CPU implemented on an FPGAâ€, and the class ends.
He/she doesnâ€™t tell much about the concrete steps of how to write CPU and compilers.
The students learn for themselves how to embody the general knowledge of CPUs and compilers learned in previous lectures to the level of real circuits and code.
Well, this is a very tough exercise, but very exciting and educational.</p>
<h2 id="lets-run-operating-system-on-our-own-cpu">Letâ€™s run Operating System on our own CPU.</h2>
<p>As some of you may have noticed, I didnâ€™t talk about operating system at all.
Iâ€™ll add a little explanation.</p>
<p>Typically, the experiment proceeds as follows.
First, you make a CPU that works reliably, no matter how slow it is.
If you can make a working CPU and successfully run the ray-tracing program, you can earn the credit of the experiment.
After that, your team has a free time.
The traditional way to spend this free time is to further speed up their CPU.
In past experiments, students have made out-of-order CPU, VLIEW CPU, multi-core CPU, or even superscalar CPU, which is amazing.</p>
<p>However, some teams put more energy into doing fun such as running games or playing music by connecting a speaker with their CPU.
Group 6, to which I belonged, was a group of such people who loved entertainment,
and we decided to run an OS as our team goal.</p>
<p>As a result of other groups showing interest in this idea, a joint group of about 8 people, Group X,
was formed, and their goal was â€œLetâ€™s run an OS on our own CPU!â€</p>
<p>Although I was in charge of creating a CPU in Group 6,
this time I chose to be the leader of the OS team in the Group X.
So this post is written primarily from the perspective of the OS team,
but of course I also introduce the overall groupâ€™s results.</p>
<h2 id="xv6">Xv6</h2>
<p>As the OS to be ported, we chose Xv6, a simple Unix v6-inspired OS created by MIT for educational purposes.
Xv6 is written in ANSI C, unlike Unix v6, and it runs on x86.
Xv6 is an educational OS, so its features are a bit poor, but it has sufficient features as a simple Unix-like OS.
You can find more information of Xv6 on <a href="https://en.wikipedia.org/wiki/Xv6" target="_blank">Wikipedia</a>

 or <a href="https://github.com/mit-pdos/xv6-public" target="_blank">the GitHub repository</a>

.</p>
<h2 id="challenges">Challenges</h2>
<p>In porting xv6, there are a lot of challenges on the software side alone because we were trying to create everything from scratch.</p>
<p><strong>1. C Compiler and tool chain for Xv6</strong></p>
<p>In the CPU experiment, we usually create an ML compiler. Naturally, you canâ€™t compile C codes of Xv6.</p>
<p><strong>2. What kind of CPU features required for operating system?</strong></p>
<p>Privilege protections? Virtual address? Interrupt?
Yes, we had overall understanding of what operating system does by lectures,
but we didnâ€™t have solid enough understanding to explain what specific CPU features could make that happen at that time.</p>
<p><strong>3. What about the simulator?</strong></p>
<p>We had a simulator made in the core part of CPU experiment,
but it was a simple one that executes one instruction by instruction,
and there was no interruption or no virtual address conversion.</p>
<p><strong>4. Low portability of xv6</strong></p>
<p>Xv6 was not very portable.
For example, it assumes the <code>char</code> is 1 byte and <code>int</code> is 4 bytes, and manipulates the stack heavily.
Well, the name â€œXv6â€ I guess comes from x86 and Unix â€œv6â€, so itâ€™s kind of natural.</p>
<p>We had a lot of concerns, but started the Group Xâ€™s OS porting project in December.<br>
From here Iâ€™m going to write about what we did in roughly chronological order.
Itâ€™s a little bit long, so if you want to look at our final products quickly, <a href="#march---xv6-runs">please jump to March</a>

.</p>
<h2 id="late-november---starting-the-compiler">Late November - Starting the compiler</h2>
<p>The first problem that we saw the answer to was the compiler and tool chain.
To be surprise, our decision was to build the C89 compiler from scratch.
To be honest, I hadnâ€™t imagined that we would choose this way.
I remember I talked with Yuichi, who became in charge of CPU of Group X, about doing a gcc or llvm port at first.</p>
<p>However, one of the team members, Keiichi, suddenly said he had written a C compiler and showed us a prototype of a compiler with a simple parser and emitter.
It seemed more fun to write the toolchain from scratch, so we decided to write a compiler by ourselves.</p>
<p>Yuichi and Wataru from Group 3, who had already finished the core part of the experiment that year, joined Keiichi, and the Group X compiler team was born.
We later named our compiler Ucc.</p>
<h2 id="mid-december---the-os-team-is-up">Mid-December - The OS team is up!</h2>
<p>At the beginning of December, I completed my CPU, and Group 6 completed the core part of the CPU experiment.
So, we moved on to the fun part, Group Xâ€™s OS porting task.
At this time, myself and Shohei from Group 6 started working in Group X and became the OS team. Masayoshi joined it at the same time.</p>
<h3 id="core-part-of-the-experiment-writing-a-cpu">Core part of the experiment: Writing a CPU</h3>
<p>By the way, I guess not so many software engineers have ever written a CPU, so let me talk a little bit about making a CPU as well.</p>
<p>Nowadays, making a CPU doesnâ€™t mean wiring every single jump wire on a breadboard; you write the circuitry in Hardware Description Language.
Then you synthesize that HDL into a real circuit using Vivado or Quartus.
This process is called logic synthesis, not compilation.</p>
<p>HDL and programming language are similar but different.
Think of it like writing a function that maps the signal state of registers to another signal state, triggered by a clock or input signal.
If you want to experience real reactive programming, I suggest you try writing an HDL.
Please also remember to write HDLs, always worrying about whether the signal propagation of the HDLs you write really ends up in one clock.
Otherwise, the behavior of your circuits would be incomprehensible to humans.</p>
<!-- You'd write a CPU state machine that decodes the machine instructions each time the clock rises, and then performs ALUs and branches accordingly, and updating the state of the exposed registers as an interface to the assembly. -->
<p>The hardest part of the actual development was that this logic synthesis took a ridiculous amount of time.
It was not uncommon for us to have to wait up to 30 minutes after starting the synthesis,
so once I started the synthesis,
I was often playing Smash Bros. Melee with the other CPU guys who were also waiting for the synthesis to finish.
FYI, my character was Sheik.</p>
<h2 id="late-december-to-mid-january---learn-by-porting-xv6-to-mips">Late December to mid-January - Learn by porting Xv6 to MIPS</h2>
<p>We began to find the answer to â€œWhat kind of CPU features required for operating system?â€</p>
<p>After the OS team was born, we started weekly rounds of Xv6 source code reading.</p>
<p>At the same time, I started porting Xv6 to MIPS.
This was partly to learn how an OS works at the implementation level, and partly because there appeared to be no Xv6 port to MIPS.
I completed the port until the process scheduler started in about a week.
I did a lot of research on MIPS during this porting process,
and on x86 to understand how xv6 works.
Thanks to that, I understood mechanisms around interrupts and MMU at the implementation level.
At this stage I got a solid understanding of the CPU functionality required for Xv6.</p>
<p>Also, in mid-January, we worked hard to compile the entire Xv6 code by commenting out the various parts.
As a result, Xv6 on the simulator of our homebrew architecture showed the first message of the boot sequence,</p>
<pre><code>xv6...
cpu0: starting...
</code></pre><p>At the same time, this meant that by this time Ucc had already grown enough to compile most of xv6, which was awesome.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<h2 id="february---our-cpu-gaia-was-born">February - our CPU, GAIA was born!</h2>
<p>In the MIPS port, I completed the initialization of the PIC, which was a real pain,
and also completed the implementation of the interrupt handler.
As a result, the porting of Xv6 to MIPS was completed until just before the first user program started.</p>
<p>Based on this experience, I made the draft specifications of the interrupt and virtual address translation for our homebrew CPU.
In order to keep it simple, we decided to omit hardware privilege mechanisms like Ring protection.
For virtual address translation, we decided to use a hardware page-walking method, just like x86.
It may seem difficult to implement in hardware, but we thought it was cheaper if we sacrificed the speed and omit TLB implementation.
After all, Yuichi made an excellent CPU core later, and it installed TLB from the beginning though.</p>
<p>Yuichi completed the overall design of the ISA of our CPU.
He named our CPU GAIA.
In typical CPU experiment projects, we donâ€™t implement interrupt nor MMU.
However, Yuichi started to implement them for Xv6, based on the refactored version of the CPU of Group 3.</p>
<p>Iâ€™ll note the weekly records as the rapid progress begins from then on!</p>
<h2 id="1st-week">1st Week</h2>
<p>Instead of just commenting boot sequences out, Masayoshi started implementing actual initialization of our CPU,
and Shohei rewrote the x86 assembly of Xv6 into our homebrew architectureâ€™s.
I added interrupt simulation capability to our simulator which Wataru had made â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/">https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/</a></em></p>]]>
            </description>
            <link>https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680109</guid>
            <pubDate>Sun, 04 Oct 2020 16:17:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fibers, Oh My]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24679740">thread link</a>) | @zdw
<br/>
October 4, 2020 | https://graphitemaster.github.io/fibers/ | <a href="https://web.archive.org/web/*/https://graphitemaster.github.io/fibers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Written by Dale Weiler, last updated Oct 5th, 2020</p>
<ul>
<li>
  <a href="https://twitter.com/actualGraphite">Twitter</a></li>
<li>
  <a href="https://github.com/graphitemaster">GitHub</a></li>
</ul>
<p>Itâ€™s been brought to the attention of many people in the game development industry that you can use fibers to parallelize your engines and games. This one presentation in particular:
  <a href="http://twvideo01.ubm-us.net/o1/vault/gdc2015/presentations/Gyrling_Christian_Parallelizing_The_Naughty.pdf">Parallelizing the Naughty Dog engine using fibers</a> has been a talking point since it came out in 2015. However, it doesnâ€™t quite go into the details enough to really explain why fibers are a good fit or how to actually implement them. In my pursuit to educate myself and take a stab at implementing them, Iâ€™ve concluded that thereâ€™s a distinctive lack of good information online. In response to the lack of literature on this topic, Iâ€™ve decided to explain it from multiple angles, and provide less known information on the subject. This document serves as a
  <a href="https://en.wikipedia.org/wiki/Sourcebook">Sourcebook</a> for those who really want to determine if itâ€™s a right fit for them and how to go about actually doing it.</p>
<h2 id="disambiguation-of-terms">
  Disambiguation of terms.
  <a href="#disambiguation-of-terms">#</a>
</h2>
<p>Before we get started I want to define three distinctive terms.</p>
<ul>
<li>OS-thread (the thread given to us by the OS)</li>
<li>Hardware-thread (the actual physical thread on a CPU)</li>
<li>Fiber-thread (the thread of execution that is our fiber)</li>
</ul>
<h2 id="what-are-fibers">
  What are fibers?
  <a href="#what-are-fibers">#</a>
</h2>
<p>Fibers are a lightweight thread of execution similar to OS threads. However, unlike OS threads, theyâ€™re cooperatively scheduled as opposed to preemptively scheduled. What this means in plain English is that fibers <em>yield</em> themselves to allow another fiber to run. You may have used something similar to this in your programming language of choice where itâ€™s typically called a <em>coroutine</em>, thereâ€™s no real distinction between coroutines and fibers other than that coroutines are usually a language-level construct, while fibers tend to be a systems-level concept.</p>
<p>Other names for fibers you may have heard before include:</p>
<ul>
<li>green threads</li>
<li>user-space threads</li>
<li>coroutines</li>
<li>tasklets</li>
<li>microthreads</li>
</ul>
<p>There are very few and minor differences between fibers and the above list. For the purposes of this document, we should consider them equivalent as the distinctions donâ€™t quite matter.</p>
<h2 id="scheduling">
  Scheduling
  <a href="#scheduling">#</a>
</h2>
<p>At any given moment the OS is running multiple processes all with their own OS threads. All of those OS threads need to be making forward progress. Thereâ€™s two classes of thought when it comes to how you solve this problem.</p>
<ul>
<li>
  <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">Cooperative scheduling</a></li>
<li>
  <a href="https://en.wikipedia.org/wiki/Preemption_%28computing%29">Preemptive scheduling</a></li>
</ul>
<p>Itâ€™s important to note that while you may observe that all processes and OS threads are running in parallel, scheduling is really providing the <em>illusion</em> of that. Not all threads are running in parallel, the scheduler is just switching between them quickly enough that it appears everything is running in parallel. That is theyâ€™re <em>concurrent</em>. Threads start, run, and complete in an <em>interleaved</em> fashion.</p>
<blockquote>
<p>It is possible for multiple OS threads to be running in parallel with
  <a href="https://en.wikipedia.org/wiki/Symmetric_multiprocessing">symmetric multiprocessing</a> (SMP) where theyâ€™re mapped to multiple hardware threads, but only as many hardware threads as the CPU physically has.</p>
</blockquote>
<h3 id="premptive-scheduling">
  Premptive scheduling
  <a href="#premptive-scheduling">#</a>
</h3>
<p>Most people familiar with threads know that you donâ€™t have to <strong>yield</strong> to other threads to allow them to run. This is because most operating systems (OS) schedule threads <strong>preemptively</strong>.</p>
<p>The points at which the OS may decide to preempt a thread include:</p>
<ul>
<li>IO</li>
<li>sleeps</li>
<li>waits (seen in locking primitives)</li>
<li>interrupts (hardware events mostly)</li>
</ul>
<p>The first three in particular are often expressed by an application as a
  <a href="https://en.wikipedia.org/wiki/System_call">system call</a>. These system calls cause the CPU to cease executing the current code and execute the OSâ€™s code registered for that system call. This allows the OS to service the request then resume execution of your applicationâ€™s calling thread, or another thread entierly.</p>
<p>This is possible because the OS will decide at one of the points listed above to save all the relevant state of that thread then resume some other thread, the idea being that when this thread can run again, the OS can reinstate that thread and continue executing it like nothing ever happened. These transition points where the OS switches a thread are called
  <a href="https://en.wikipedia.org/wiki/Context_switch">context switches</a>.</p>
<p>Thereâ€™s a cost associated with this context switching and all modern operating systems have made great deals of effort to reduce this cost as much as possible. Unfortunately, that overhead begins to show itself when you have <em>a lot</em> of threads. In addition, recent cache
  <a href="https://en.wikipedia.org/wiki/Side-channel_attack">side channel attacks</a> like:
  <a href="https://en.wikipedia.org/wiki/Spectre_%28security_vulnerability%29">Spectre</a>,
  <a href="https://en.wikipedia.org/wiki/Meltdown_%28security_vulnerability%29">Meltdown</a>,
  <a href="https://en.wikipedia.org/wiki/Spoiler_%28security_vulnerability%29">Spoiler</a>,
  <a href="https://en.wikipedia.org/wiki/Foreshadow_%28security_vulnerability%29">Foreshadow</a>, and
  <a href="https://en.wikipedia.org/wiki/Microarchitectural_Data_Sampling">Microarchitectural Data Sampling</a> on modern processors has led to a series of both user-space and kernel-space mitigation strategies, some of which increased the overhead of context switches significantly.</p>
<blockquote>
<p>You can read more about context switching overhead in
  <a href="https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf">this paper</a>.</p>
</blockquote>
<h3 id="cooperative-scheduling">
  Cooperative scheduling
  <a href="#cooperative-scheduling">#</a>
</h3>
<p>This idea of fibers yielding to each other is what is known as cooperative scheduling. Fibers effectively move the idea of context switching from kernel-space to user-space and then make those switches a fundamental part of computation, that is, theyâ€™re a deliberate and explicitly done thing, by the fibers themselves. The benefit of this is that a lot of the previously mentioned overhead can be entierly eliminated while still permitting an excess count of threads of execution, just in the form of these fibers now.</p>
<h2 id="the-problem-with-multi-threading">
  The problem with multi-threading
  <a href="#the-problem-with-multi-threading">#</a>
</h2>
<p>Thereâ€™s many problems related to multi-threading, most obviously that itâ€™s difficult to get right. Most proponents of fibers make false claims about how this problem goes away when you use fibers because you donâ€™t have parallel threads of execution. Instead, you have these cooperatively scheduled fibers which yield to each other. This means itâ€™s not possible to
  <a href="https://en.wikipedia.org/wiki/Race_condition">race data</a>,
  <a href="https://en.wikipedia.org/wiki/Deadlock">dead lock</a>,
  <a href="https://en.wikipedia.org/wiki/Deadlock#Livelock">live lock</a>, etc. While this statement is true when you look at fibers as a N:1 proposition, the story is entierly different when you introduce M:N.</p>
<h3 id="n1-and-what-it-means">
  N:1 and what it means
  <a href="#n1-and-what-it-means">#</a>
</h3>
<p>Most documentation, libraries, and tutorials on fibers are almost exclusively based around using a single thread given to you by the OS, then sharing it among multiple fibers that cooperatively yield and run all your asynchronous code. This is called N:1 (â€œN to oneâ€). <code>N</code> fibers to <code>1</code> thread, and itâ€™s the most prevalent form of fibers. This is how Lua coroutines work, how Javascriptâ€™s and Pythonâ€™s async/await work, and itâ€™s <strong>not what youâ€™re interested in</strong> doing if you actually want to take advantage of hardware threads. What youâ€™re interested in is M:N, (â€œM to Nâ€) <code>M</code> fibers to <code>N</code> threads.</p>
<h3 id="mn-and-what-it-means">
  M:N and what it means
  <a href="#mn-and-what-it-means">#</a>
</h3>
<p>The idea behind M:N is to take the model given to us by N:1 and map it to multiple actual OS threads. Just like weâ€™re familiar to the concept of thread pools where we execute tasks, here we have a pool of threads where we execute fibers and those fibers get to yield more of themselves on that thread.</p>
<blockquote>
<p>I should stress that M:N fibers have all the usual problems of multi-threading. You still need to syncronize access to resources shared between multiple fibers because thereâ€™s still multiple threads.</p>
</blockquote>
<h2 id="the-problem-with-thread-pools">
  The problem with thread pools
  <a href="#the-problem-with-thread-pools">#</a>
</h2>
<p>A lot of you may be wondering how this is different from traditional task based parallelism choices seen in many game engines and applications. The model where you have a fixed-size pool of threads you queue tasks on to be executed at some point in the future by one of those threads.</p>
<h3 id="locality-of-reference">
  Locality of reference
  <a href="#locality-of-reference">#</a>
</h3>
<p>The first problem is <em>locality of reference</em>. The data-oriented / cache-aware programmers reading this will have to mind my overloading of that phrase because what Iâ€™m really talking about is the resources that a job needs access to are usually local. The job isnâ€™t going to be executed immediately, but rather when the thread pool has a chance to. Any resource that job needs access to, needs to be available for the job at some point in the future. This means local values need their lifetimeâ€™s extended for an undefined amount of time.</p>
<p>Thereâ€™s many ways to solve this lifetime problem, except they all have overhead. Consider this trivial example where I want to asynchronously upload a local file to a webserver</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>upload_file</span>(<span>const</span> String<span>&amp;</span> filename) {
  thread_pool<span>-&gt;</span>add_job([<span>&amp;</span>] {
    <span>auto</span> file <span>=</span> open_file(filename);
    <span>auto</span> data <span>=</span> read_file(file);
    post_binary_data(data);
  });
}
</code></pre></div><p>Do you see the bug?</p>
<p>The issue is that the string passed to <code>upload_file</code>, i.e the local <code>filename</code>, only has a lifetime of the body of the function. When this function returns, <code>filename</code> no longer is a valid string. However, at some point this lambda function will be executed and try to access <code>filename</code> in itâ€™s local context and itâ€™ll be a dangling reference by then.</p>
<p>This can be surprsing to those more familiar with dynamic languages, since they support this functionality with something called a closure. The closure will actually extend the lifetime of <code>filename</code>. In native languages like C or C++ though, this isnâ€™t the case and all lifetime extension needs to be done explicitly with obvious runtime which introduces overhead.</p>
<p>What you could do is <strong>copy</strong> the string. The copy will then have the lifetime of the lambda. However, if we had a much larger resource to share with this job that couldnâ€™t be as cheaply copied, we would have to use something like a <strong>reference count</strong> instead. As you can see, the solutions to the resource problem involve a great deal of overhead in many cases and requires you to really think and reason about lifetimes here when you didnâ€™t have to, nor should you have to.</p>
<p>Weâ€™re experiencing a lot of friction here already and itâ€™s only a few lines of code. My personal rule of thumb is if you find yourself experiencing friction like this, itâ€™s usually indicative of bad design and the problem needs to be rethought.</p>
<h3 id="nested-induced-deadlocks">
  Nested induced deadlocks
  <a href="#nested-induced-deadlocks">#</a>
</h3>
<p>The other significant problem with thread pools is what I call <em>nested induced deadlocks</em>. No matter how you slice and dice it, jobs are going to want to schedule other jobs and need the result before they themselves can continue.</p>
<p>Let me set up a real world example because itâ€™s easier to â€¦</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphitemaster.github.io/fibers/">https://graphitemaster.github.io/fibers/</a></em></p>]]>
            </description>
            <link>https://graphitemaster.github.io/fibers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679740</guid>
            <pubDate>Sun, 04 Oct 2020 15:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Put a Raspberry Pi in a Rocket]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24679435">thread link</a>) | @johnjones4
<br/>
October 4, 2020 | https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/ | <a href="https://web.archive.org/web/*/https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://news.ycombinator.com/item?id=24679435">Q&amp;A on Hacker News about this project</a></p>
<p>As we're driving out to our launch site in Leesburg, VA, my wife turns to me and asks, "did you intentionally wear a yellow and blue striped rugby shirt to match your yellow and blue striped rocket?" I look down, and realize that, yes I had indeed accidentally dressed exactly like my rocket. I wonder if that ever happens to Elon?</p>
<h2>Launches</h2>
<p><img src="https://johnjonesfour.com/images/rocket/launch.jpg" alt="Launch images"></p>
<p>Very special thank you to my exceptionally patient wife who tagged along, captured these great pictures, and ended up actually having a lot of fun with her very nerdy husband.</p>
<p>Ida Lee Park in Leesburg, VA allows rocket launches up to 400 feet with a permit, so I applied earlier in September for an October 3rd launch and received fast approval. With the day upon us, my wife and I made the 40 minute drive to Leesburg (apparently in uniform?), set up in our designated part of the park, and got to work.</p>
<h3>Launch 1</h3>
<p><img src="https://johnjonesfour.com/images/rocket/telemetry.gif" alt="Telemetry"></p>
<p><img src="https://johnjonesfour.com/images/rocket/launch1.png" alt="Launch 1"></p>
<p>The first launch was a huge success. The rocket reached 110.3 meters (~362 feet), which beat my simulation's prediction of 90 meters, and it reached a peak velocity of 41.69 meters per second (~93 mph) at 1.44 seconds into the flight. We can see the rocket started to descend very quickly after apogee, and the chute deployed successfully 7.5 seconds into the flight. From there, the chute allowed for a linear rate of descent to a gentle field landing.</p>
<h3>Launch 2</h3>
<p><img src="https://johnjonesfour.com/images/rocket/launch2.png" alt="Launch 2"></p>
<p>Launch 2 was less of a success. While the ascent went smoothly, telemetry was lost 4.57 seconds into flight and the ejection charge ripped the shock cord causing the two rocket components to separate with no parachute to slow their descent. This incident also knocked out the battery cable causing inboard video and data capture to also fail. Unfortunately no video data could be recovered.</p>
<h2>Next Steps</h2>
<p><img src="https://johnjonesfour.com/images/rocket/recovery.jpg" alt="Rocket after launch"></p>
<p>The second launch revealed three major issues that need to be resolved: </p>
<ol>
<li>The shock cord is not strong enough to absorb the force caused by separation, likely because of how heavy the payload is. In a future upgrade I will need to double-up the cords OR use two parachutes for each component to let them descend separately.</li>
<li>When the payload section hit the ground, it drove the coupler way into the body tube. Upon impact, the battery bracket absorbed the force and shattered. However all of the electronics survived. Part of the coupler also broke off when I attempted to pull the it out of the payload section, so this will all need to be redesigned to better absorb hard landings.</li>
<li>There must be a buffer that holds a certain amount of camera footage before saving it to disk. Because the battery disconnected in-flight, no flight video saved. I'd like to figure out how to write video data more frequently in case the battery issue happens again.</li>
</ol>
<p>In addition to those major issues, I'd also like to make the following improvements:</p>
<ol>
<li>The software performed well, but I'd still like to increase the data capture rate. There are Adafruit libraries for the components I'm using in C++, so I'm considering rewriting <code>air.py</code> in C++, but I'd really love it if someone talked me out of that.</li>
<li>Between launches I manually rebooted the ground computer so that it would clear the visualizations and start logging to a new file. To make this easier, I plan to add the option to the dashboard to start new "capture sessions" without needing to restart the system.</li>
</ol></div></div>]]>
            </description>
            <link>https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679435</guid>
            <pubDate>Sun, 04 Oct 2020 14:48:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physical distancing, mask-wearing could be in place for 2-3 years with vaccine]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24678863">thread link</a>) | @just-juan-post
<br/>
October 4, 2020 | https://www.cbc.ca/news/politics/covid-19-vaccine-tam-1.5673729 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/covid-19-vaccine-tam-1.5673729">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Canadians shouldn't expect a COVID-19 vaccine to be a&nbsp;"silver bullet" that will bring a swift end to the coronavirus&nbsp;pandemic and a return to normal, according to the&nbsp;country's chief public health officer.</p><div><p><span><span><div><div role="button" tabindex="0" title="Dr. Tam cautions COVID-19 vaccines not a 'silver bullet'"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/345/911/ftr%20TAM%20vaccine_frame_66.jpg" alt=""></p></div></div></div><span>Canada's chief public health officer Dr. Theresa Tam responds to reporter questions about the search for a vaccine for COVID-19.<!-- --> <!-- -->2:08</span></span></span></p><p><span><p>Canadians shouldn't expect a COVID-19 vaccine to be a&nbsp;"silver bullet" that will bring a swift end to the coronavirus&nbsp;pandemic and a return to normal, according to the&nbsp;country's chief public health officer.</p>  <p>Dr. Theresa Tam used her briefing on Tuesday in Ottawa to temper expectations about the speed and effectiveness of a vaccine. She reiterated the importance of physical distancing, proper hand hygiene and mask-wearing, and attempted to&nbsp;dispel any&nbsp;notion&nbsp;that a vaccine will make life go back to the way it was in a couple of months.</p>  <p>"We can't at this stage just put all of our focus [on a vaccine] in the hopes that this is the silver bullet solution," said Tam.</p>  <p>"We're going to have to manage this pandemic certainly over the next year, but certainly [we are]&nbsp;planning for the longer term of the next two to three years during which the vaccine may play a role but we don't know yet."</p>  <p>Tam said it's unclear at this stage how effective a vaccine will be. She said key questions remain about the degree and duration of immunity a vaccine will provide, the dosage that will be needed&nbsp;and whether it will prevent people from getting infected altogether or simply prevent severe illness requiring hospitalization.</p>  <h2>More than 150&nbsp;under development</h2>  <p>There are <a href="https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">more than 166 vaccines</a> at various stages of <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">preclinical and clinical (human) testing</a>&nbsp;across the globe right now, the World Health Organization says. <a href="https://www.cbc.ca/news/world/us-azar-vaccine-global-supply-1.5571264">U.S.</a> and <a href="https://www.cbc.ca/news/world/coronavirus-vaccine-1.5569165">European</a> experts say under an optimistic scenario, the first of those vaccines could complete testing and get approval for distribution next year.&nbsp;</p>  <p>Tam warned that even once a vaccine is tested and deemed to be both safe and effective, there will be challenges with distributing it widely to those who need it.</p>  <p>"It's likely that there won't be enough vaccines for the population," said Tam. "So there'll be prioritization and we're looking at that."</p>  <p>Tam said she agreed with Dr. Anthony Fauci, the&nbsp;top infectious disease specialist in the U.S., who told Congress last week that he was "cautiously optimistic" that a safe and effective vaccine will be available by the end of the year.</p>  <p>Despite that, she said&nbsp;public health officials are planning for a scenario in which measures that have been put in place thus far, including physical distancing to limiting crowd sizes,&nbsp;could be required even after a vaccine is found.</p>  <p>"[A vaccine] is one important layer of protection," said Tam. "It is a very important solution if we get a safe and effective vaccine,&nbsp;but I would say that the public health measures that we have in place&nbsp;â€” the sort of personal, daily measures that we take â€” is going to have to continue."</p>  <p><em><strong>WATCH: Tam on&nbsp;how Canadians should psychologically prepare for the future:</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Tam questioned about how Canadians should psychologically prepare for the future"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/385/450/ftr%20TAM%20looking%20forward_frame_167.jpg" alt=""></p></div></div></div><span>Canada's chief public health officer Dr. Theresa Tam spoke with reporters, including the CBC's Tom Parry on Parliament Hill Tuesday.<!-- --> <!-- -->2:19</span></span></span></p>  <h2>Recommends masks for children over 10</h2>  <p>Tam said one of the busiest areas of planning for officials&nbsp;is the reopening of schools in September, for which,&nbsp;she said, the Public Health Agency of Canada will be publishing detailed guidelines later this week.</p>  <p>The guidelines will include a recommendation that children over the age of 10 be required to wear masks, said Tam, in French. Extra consideration should be given for children under the age of 10, she said.</p>  <p>"The recommendations will undergo evolution as the evidence changes and we'll also have to see what happens as we understand transmission in different age groups&nbsp;and what happens in schools." said Tam. "We may have to adapt this recommendation as we go along."</p>    <p>Tam also addressed criticism of another layer of protection the federal government rolled out last week&nbsp;â€” the COVID Alert exposure notification app&nbsp;â€” which is meant to tell users if their phones have recently been close to a phone registered to someone who volunteers that they've tested positive for the coronavirus.</p>  <p>The app&nbsp;works only on phones released in the last five years or so because it needs a relatively recent operating system.</p>  <p><a href="https://www.cbc.ca/news/politics/covid-alert-app-accessibility-1.5672881">Critics say that will leave out poorer and older Canadians</a>, who are more likely to use older devices and suffer worse effects from the virus.</p>  <p>Tam said&nbsp;the app is&nbsp;one of many tools available to fight the pandemic, and that people should use them even if they aren't perfect.</p>  <p>"Despite these gaps, we need to have a go at using it," said Tam. "As many people who can download it and use it as possible will make the app more successful."</p>  <p>The government said Monday that more than 1.1 million people had downloaded the app.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/covid-19-vaccine-tam-1.5673729</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678863</guid>
            <pubDate>Sun, 04 Oct 2020 13:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Ways of DevOps]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24678055">thread link</a>) | @kiyanwang
<br/>
October 4, 2020 | https://ermetic.com/whats-new/blog/the-three-ways-of-devops/ | <a href="https://web.archive.org/web/*/https://ermetic.com/whats-new/blog/the-three-ways-of-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			
				<article>
			<header>
				<img src="https://ermetic.com/wp-content/uploads/2020/09/DevOps-header_933x300.jpg" alt="">				
				
				<p>By Tanya Janca, CEO and Founder of WeHackPurple, September 30, 2020</p>
				<p>
	share:
	<a target="blank" href="http://twitter.com/home/?status=The%20Three%20Ways%20of%20DevOps%20-%20https://ermetic.com/?p=1310%20via%20@kenmata" title="Tweet this!"><span></span></a>
	<a target="blank" href="http://www.facebook.com/sharer.php?u=https://ermetic.com/whats-new/blog/the-three-ways-of-devops/%20-%20https://ermetic.com/?p=1310" title="Share on Facebook!"><span></span></a>
		<a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://ermetic.com/whats-new/blog/the-three-ways-of-devops/%20-%20%20https://ermetic.com/?p=1310;source=LinkedIn" title="Share on LinkedIn!"><span></span></a>
</p>			</header>
			<section><p>In this article we will explore applying the security concept of least privilege to your cloud instances, within a DevOps environment, without adding bulk and delays to your pipeline.</p>
<p>DevOps is not a tool that you buy, or the act of using pipeline software to release your code, it is so much more. Letâ€™s define DevOps, then the three ways, then letÃ¢â‚¬â„¢s apply least privilege.</p>
<p><em>Although there are many different definitions of exactly what DevOps is, the most popular definition is from the Phoenix project and the DevOps Handbook. We will follow this definition in this article.</em></p>
<p>DevOps is a way of developing software, as well as a culture within a software development shop, and a mixture of processes and tooling that helps you get there.</p>
<h3>In Order to do DevOps, You Must Follow the Three Ways of DevOps</h3>
<p><em>The first way of DevOps</em> is to emphasize the speed and efficiency of the entire system, instead of just your part. Sometimes this means that you have to help another team do their work, rather than your own, because that will make the entire system so much better. Sometimes this means, asking for help from other teams. Often, automation helps with this, which is why we use a DevOps pipeline software, in order to release and deploy our code quickly and efficiently. Automation generally results in fewer errors, and it almost always results in much faster results. This is the first way of DevOps.</p>
<p><em>The second way of DevOps</em> is fast feedback. This means getting feedback to the correct person or people, in a timely manner. It also means the feedback needs to be accurate, because feedback that is inaccurate is not only unhelpful, it is potentially harmful. We add security testing, and all sorts of other quality tests, to our pipeline software in order to ensure the code that we are creating is high quality, and so that we get very fast feedback. That said, a pipeline is not the only way that you can get feedback, we will talk about this when we apply least privilege.</p>
<p><em>The third way of DevOps</em> is continuous learning. This means setting time aside on a regular basis to improve your daily work. Sometimes this means training. Sometimes this means tuning your tools or doing a proof of concept of several new tools that you are considering ensuring that the one you choose is the absolute best for your specific business needs. Sometimes this means introducing artificial intelligence and machine learning into your systems or tooling, to ensure that it is continuously learning. The point being that you want to be in a constant state of striving for improvement.</p>
<p>Quite often when people think of DevOps, they assume that every single tool or test must go into the pipeline. This is not true. We need to abide by the three ways of DevOps, and that definitely means using pipeline software and putting security tests inside of it, but our work is not done with just that. We cannot possibly complete all of our security requirements within a pipeline.</p>
<h3>Least Privilege and the Three Ways</h3>
<p>Letâ€™s look at how we can implement the concept of <em>least privilege</em> to our cloud processes within a DevOps environment, and how it relates to each of the three ways.</p>
<p>Now we could attempt to put some tests for least privilege in our DevOps pipeline, however, what would we test for? If a permission is included in the pipeline, itâ€™s likely because the software developer assumed that they would need it. What test could we put in a pipeline that would clarify whether or not a permission was actually required? To see if it is in use, or not? This means, it is unlikely we can test for this in our pipeline.</p>
<p>Instead of putting a test in the pipeline, we could set up monitoring in our systems of new processes, to watch which permissions are actually being used and which are not. Whichever permissions are not being used, could be removed, in order to implement<em> least privilege</em>. Now, letâ€™s look at how we can apply this to <em>the three ways</em> of DevOps.</p>
<p>The first of the three ways, to repeat, is speed and efficiency of the entire system. By not putting a tool like this in the pipeline, this would not slow the pipeline down, and that would increase the speed of the system. Instead, we could create automation outside the pipeline, to ensure that this work was done quickly and efficiently, that would obey the first rule for instance, if we had a monitoring tool that did this for us. LetÃ¢â‚¬â„¢s take this imaginary monitoring system with us to the next way.</p>
<p>The second way is fast, accurate and timely feedback. LetÃ¢â‚¬â„¢s say our automated monitoring system that is watching all of our processes to see which permissions are being used, it gives feedback quickly and to the right people [the security team], that would be a very handy tool. If it could automate removing unused permissions, tell us if someone tries to use a removed permission, and shows us reports of both, that would certainly fit well into the second way. Having it also automate sending alerts and creating tickets would be a cherry on top of all of this; feedback going directly to who needs it.</p>
<p>The third way involves continuous learning. If our automated monitoring system, itself, can learn continuously from the traffic, access, and behavior of our cloud activity and users, then that respects the third way. A system that can train itself, learn when to remove permissions, when to replace permissions, and when to block access, not only respects the third way, it makes for a fantastic least privilege security tool. With enough learning (monitoring), a tool can even start to recommend which access policies would be the best option, given specific situations and previous decisions.</p>
<p>Although many people seem to think that DevOps tools need to go in a pipeline, this article makes it clear that you can still respect the three ways of DevOps and work within DevOps processes, without having your tool in the pipeline. And gain fantastic security results to boot!</p>
<p><a href="https://l.ermetic.com/get-a-demo" target="_blank" rel="noopener noreferrer">Find out how Ermetic can help you continually enforce least privilege access in your cloud environment.</a></p>
<p><strong>About the Guest Author</strong></p>
<p>Tanya Janca, also known as <a href="https://shehackspurple.ca/" target="_blank" rel="noopener noreferrer">SheHacksPurple</a>, is the author of Ã¢â‚¬ËœAlice and Bob Learn Application SecurityÃ¢â‚¬â„¢. She is also the founder of <a href="https://wehackpurple.com/" target="_blank" rel="noopener noreferrer">We Hack Purple</a>, an online learning academy, community and weekly podcast that revolves around teaching everyone to create secure software. Tanya has been coding and working in IT for over twenty years, won numerous awards, and has been everywhere from startups to public service to tech giants (Microsoft, Adobe, &amp; Nokia). She has worn many hats; startup founder, pentester, CISO, AppSec Engineer, and software developer. She is an award-winning public speaker, active blogger &amp; streamer and has delivered hundreds of talks and trainings on 6 continents. She values diversity, inclusion and kindness, which shines through in her countless initiatives.</p>
<p>Founder: We Hack Purple (Academy, Community and Podcast), WoSEC International (Women of Security), OWASP DevSlop, OWASP Victoria, #CyberMentoringMonday</p>
</section>
			
		</article>
				</div></div>]]>
            </description>
            <link>https://ermetic.com/whats-new/blog/the-three-ways-of-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678055</guid>
            <pubDate>Sun, 04 Oct 2020 11:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knolling]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24678050">thread link</a>) | @any1
<br/>
October 4, 2020 | https://andri.yngvason.is/knolling.html | <a href="https://web.archive.org/web/*/https://andri.yngvason.is/knolling.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Software development is a craft. We tend to call it â€œengineeringâ€, but most of
the time, it feels more like plumbing or carpentry. Most of the time, completing
a task does not require any inventiveness. Sometimes we fool ourselves
into thinking that we are more than a craftsmen, engineers even, and in order to
verify our bias, we try to be clever where no inventiveness is required. This
only complicates things, both in the moment and the future.</p>

<p>Because software development is a craft, it is perhaps fair to deduce that
principles which apply to crafts also apply to computer programming. An efficient
workshop is, invariably, a tidy workshop, where every tool has its place.
Consistency is the key to completing tasks at a constant pace. When nothing is
amiss and there are no surprises, it is easy to make plans and execute them. To
keep a tidy workshop, you must <a href="https://www.youtube.com/watch?v=s-CTkbHnpNQ">always be knolling</a>.</p>

<p>An efficient team is, invariably, a team that keeps the code tidy and all
external aspects of it up to date. <em>Always be knolling</em>. This does not directly
contribute to the solution or success of the current task, but the current task
is not your entire job responsibility. In the long run, your job is to complete
tasks consistently and in accordance to specifications. If youâ€™re held up by
ancillary tasks such as upgrading dependencies or unwinding an abstraction that
was meant to solve duplication that turned out to be incidental, then you have
failed to keep a tidy system.</p>

<p>Keeping a tidy system is not only useful to you as a programmer, it is also
useful for team leaders because it helps them to accurately report progress and
estimates to management. Another important aspect is the psychological well-being
of the team. A tidy system is a joy to work on. You do not dread a task because
you know that you are going to have to work on poorly maintained part of the
system or because youâ€™ll have to edit code that offends your sensibilities.
Instead, what you get is the dopamine boost that comes with closing the task in
the issue tracker after youâ€™ve completed it and verified that it works.</p>

<p>A software project is never complete. It can always be extended and changed to
take on new roles and fulfill new design criteria. This is perhaps also true
of physical items such a furniture, but software has more possibilities.
Notably, this is where software development differs from other crafts: it is
more dynamic. This is a an extremely powerful attribute of software. Just
imagine having the possibility of morphing a regular kitchen chair into a
wheelchair or a rocking-chair just by carving an incantation into its seat.</p>

<p>In order to exploit this powerful aspect of software that sets it apart from all
other things, it must be possible to actually make changes to the software. An
untidy system resists change and stands in the way of progress. By constantly
clearing away detritus, we can take advantage of softwareâ€™s full potential.</p>

<p>Consistency enables change.</p>


  </div>

  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://andri.yngvason.is/knolling.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678050</guid>
            <pubDate>Sun, 04 Oct 2020 11:12:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lambda Calculus Diagrams (2015)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24677614">thread link</a>) | @fanf2
<br/>
October 4, 2020 | https://tromp.github.io/cl/diagrams.html | <a href="https://web.archive.org/web/*/https://tromp.github.io/cl/diagrams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


Lambda Diagrams are a graphical notation for closed lambda terms,
in which abstractions (lambdas) are represented by horizontal lines,
variables by vertical lines emanating down from their binding lambda,
and applications by horizontal links connecting the leftmost variables.
In the alternative style, applications link the nearest deepest variables,
for a more stylistic, if less uniform, look.
<p>

The following table shows diagrams of identity, the booleans, some standard combinators,
some Church numerals, the predecessor function on Church numerals, and Omega.

<table>
<tbody><tr> <td>term</td><td>definition</td> <td>diagram</td> <td>alternative</td> </tr>
<tr> <td>I/1</td> <td> Î»x.x</td>
  <td><img src="https://tromp.github.io/img/cl/I.gif"></td><td> </td></tr>
<tr> <td>K/true</td> <td> Î»x.Î»y.x</td>
  <td><img src="https://tromp.github.io/img/cl/K.gif"></td><td> </td></tr>
<tr> <td>false/0</td> <td> Î»x.Î»y.y</td>
  <td><img src="https://tromp.github.io/img/cl/false.gif"></td><td> </td></tr>
<tr> <td>S</td> <td> Î»x.Î»y.Î»z.(x z)(y z)</td>
  <td><img src="https://tromp.github.io/img/cl/S.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/S.alt.gif"></td> </tr>
<tr> <td>Y</td> <td> Î»f.(Î»x.x x)(Î»x.f(x x))</td>
  <td><img src="https://tromp.github.io/img/cl/Y.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/Y.alt.gif"></td> </tr>
<tr> <td>2</td> <td> Î»f.Î»x.f(f x)</td>
  <td><img src="https://tromp.github.io/img/cl/2.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/2.alt.gif"></td> </tr>
<tr> <td>3</td> <td> Î»f.Î»x.f(f(f x))</td>
  <td><img src="https://tromp.github.io/img/cl/3.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/3.alt.gif"></td> </tr>
<tr> <td>4</td> <td> Î»f.Î»x.f(f(f(f x)))</td>
  <td><img src="https://tromp.github.io/img/cl/4.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/4.alt.gif"></td> </tr>
<tr> <td>pred</td> <td> Î»n.Î»f.Î»x.n(Î»g.Î»h.h(g f))(Î»u.x)(Î»u.u)</td>
  <td><img src="https://tromp.github.io/img/cl/pred.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/pred.alt.gif"></td> </tr>
<tr> <td>fac</td> <td> Î»n.Î»f.n(Î»f.Î»n.n(f(Î»f.Î»x.n f(f x))))(Î»x.f)(Î»x.x)</td>
  <td><img src="https://tromp.github.io/img/cl/fac.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/fac.alt.gif"></td> </tr>
<tr> <td>fib</td> <td> Î»n.Î»f.n(Î»c.Î»a.Î»b.c b(Î»x.a (b x)))(Î»x.Î»y.x)(Î»x.x)f</td>
  <td><img src="https://tromp.github.io/img/cl/fib.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/fib.alt.gif"></td> </tr>
<tr> <td>Î©</td> <td> (Î»x.x x)(Î»x.x x)</td>
  <td><img src="https://tromp.github.io/img/cl/Omega.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/Omega.alt.gif"></td> </tr>
</tbody></table>
Curiously, the alternative Omega diagram somewhat resembles an (upside-down) Omega.
</p><p>
And here, on a larger scale, is a prime number sieve (alternative style): </p><p>
<img src="https://tromp.github.io/img/cl/primes.alt.gif">
</p><p>
which reduces to an infinite list of booleans that starts out as
</p><p>
<img src="https://tromp.github.io/img/cl/primebits.gif">

</p><h2>Dimensions and complexity</h2>

In terms of pixels, a diagram's width is one less than 4 times the number of variables
(vertical lines),
and its height is one more than twice the maximum number of nested abstractions and applications
(one less for alternaitve diagrams with multiple variables).
<p>
The size of the binary encoding of a term is closely related to
the graphical complexity: it is exactly twice the number of lines
plus the number of (4-way) intersections.

</p><h2>Reduction</h2>

Beta-reduction on lambda diagrams can be shown in several steps, as demonstrated in this reduction
from Y=Î»f.(Î»x.x x)(Î»x.f(x x)) to Î»f.(Î»x.f(x x))(Î»x.f(x x))

<table>
<tbody><tr><td>initial term</td><td><img src="https://tromp.github.io/img/cl/Y.gif"></td></tr>
<tr><td>show application of abstraction</td><td><img src="https://tromp.github.io/img/cl/Y0.gif"></td></tr>
<tr><td>show bound variables and argument</td><td><img src="https://tromp.github.io/img/cl/Y1.gif"></td></tr>
<tr><td>expand function body</td><td><img src="https://tromp.github.io/img/cl/Y2.gif"></td></tr>
<tr><td>to make room for substitution</td><td><img src="https://tromp.github.io/img/cl/Y3.gif"></td></tr>
<tr><td>substitute argument for variables</td><td><img src="https://tromp.github.io/img/cl/Y4.gif"></td></tr>
<tr><td>final term</td><td><img src="https://tromp.github.io/img/cl/Y5.gif"></td></tr>
</tbody></table>

In the third frame, we show only the part of bound variables below abstractions, e.g. when
applying <img src="https://tromp.github.io/img/cl/applied.gif">, the function body x(Î»y.x) shows as <img src="https://tromp.github.io/img/cl/bound.gif">.

<h2>Diagrams In Motion</h2>

Paul Brauner has produced some awesome <a href="https://www.youtube.com/playlist?list=PLi8_XqluS5xc7GL-bgVrxpA2Uww6nK0gV">videos</a> of beta reductions, produced with this <a href="https://github.com/polux/lambda-diagrams">software</a>.
 
<h2> Related work</h2>
<a href="http://dkeenan.com/">Dave Keenan</a> has a comprehensive online paper
<a href="http://dkeenan.com/Lambda/">To Dissect a Mockingbird:
A Graphical Notation for the Lambda Calculus with Animated Reduction</a>,
which partly inspired this page.
<p>
In his <a href="http://bntr.planet.ee/lambda/work/visual_lambda.pdf">Master thesis</a>, Viktor MassalÃµgin discusses 4 existing graphical notations before introducing his own "bubble" notation. Figure 3 on page 10 shows 4 depictions of the fixpoint combinator (which differs from Y above in one beta reduction), while the bubble form is in Figure 5 on page 13.

</p><h3>Note</h3>

The diagram in the title, produced by the postscript code below, is a slightly deformed alternative Y diagram made to look like a Y.
<pre>%!PS-Adobe-2.0 EPSF-2.0
%%BoundingBox:0 0 118 110
/m{moveto}def/l{lineto}def/c{concat 6 m 0 6 l 7 8 m 0 8 l l l 3 6 l 2 6 m 7 6 l
3 4 m 6 4 l 6 6 l stroke}def 3 0 0 0 1[-8 4 0 8 60 9]c 3 2 0 2 2[-1 1 0 1 0 0]c
</pre>

<hr>
Back to my <a href="http://tromp.github.io/cl/cl.html">Binary Lambda Calculus page</a>. <br>


</div>]]>
            </description>
            <link>https://tromp.github.io/cl/diagrams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677614</guid>
            <pubDate>Sun, 04 Oct 2020 09:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dual licensing GPL for fame and profit]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 112 (<a href="https://news.ycombinator.com/item?id=24677481">thread link</a>) | @george3d6
<br/>
October 4, 2020 | https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-10-04</p>
        
<p>Dual licensing with GPL is the idea that if I own a certain piece of GPL code, I can also relicense it as a proprietary library. This is how Oracle licenses Java and how QT licenses QT.</p>
<h2>I - All rights for me but not for thee</h2>
<p>But my general feeling is that there is some stigma associated with this practice, to quote <a href="https://www.gnu.org/licenses/gpl-faq.en.html#ReleaseUnderGPLAndNF">gnu.org</a>:</p>
<blockquote>
<p>To release a nonfree program is always ethically tainted, but legally there is no obstacle to your doing this. If you are the copyright holder for the code, you can release it under various different non-exclusive licenses at various times.</p>
</blockquote>
<p>The "ethically tainted" doesn't resonate with me, I think this licensing model should be encouraged.</p>
<p>I will admit I am kind of biased on this because I work on a for-profit GPL-license project. But it strikes me as silly that this business model is shunned by the open-source community in favor of licensing under MIT/BSD.</p>
<p>Dual licensing is a way in which the "owner" of the code ends up in an advantageous position compared to other users.</p>
<p>That is to say, a user must abide by the strict rules of the GPL license:</p>
<ul>
<li>Release all modifications.</li>
<li>Potentially (depending on the specifics of the GPL license) have to release other projects that are used "in relation" to the library.</li>
<li>Not ship the code under a different license.</li>
</ul>
<p>The "owner" of the code abides by none of these and can thus benefit in ways that the users can't.</p>
<p>In the open-source utopia, where resources are aplenty for everyone, everything is open source and nothing is for sale, so dual-licensing doesn't fit that particular utopia. But we live in the real world, where money makes things a bit more complicated, and in the long term, dual-licensing might be better than equal-rights open licenses.</p>
<p>Well, developers have to eat.</p>
<p>Even worst, good software is made by good developers, developers which can get six-figure salaries designing skinner boxes. On the contingency that those developers aren't ideal altruists, they have to get way-above-subsistence salaries to work on useful open source projects instead of skinner boxes.</p>
<p>So if dual-licensing provides a middle ground for that which is better than the current situation where a lot of good software is proprietary, what's the harm?</p>
<p>Some would say it's a middle ground that will hamper the development of truly free software. But who release said truly free software anyway?</p>
<h2>II - Who release fully-free projects</h2>
<p>When it comes to license like MIT and BSD, that impose no restrictions upon usage, where the "owner" doesn't exist, it's interesting to look at who release projects under those licenses:</p>
<p>a) Students or hobbyists, people creating software for fun, notoriety, and experience.</p>
<p>b) Very large companies (Facebook, Google, Amazon, Uber) or government &amp; donation founded organizations (Universities, Public Research centers, software foundations such as GNU, Apache, and LSF)</p>
<p>The first group is one I don't wish to dismiss, I think a lot of important programs stem from here. But their end goal is not to work for free for their whole life. Usually, they moonlight for their open-source projects and work a paid gig to earn money. A small minority can be funded by donations, but it's a small minority.</p>
<p>The project I use for allowing comments on this website (<a href="https://github.com/umputun/remark42">remark42</a>), has 2.3k stars on GitHub and <a href="https://www.patreon.com/remark42/posts">earns 9$/month from donations</a>. The <a href="https://github.com/mindsdb/mindsdb">project I work on</a> has 2.9k stars on Github and an operating budget of <a href="https://venturebeat.com/2020/04/16/mindsdb-raises-3-million-for-open-source-automated-machine-learning/">a few million</a> dollars.</p>
<p>You can certainly get to a point where you are funded by donations, but the reality is that it's not a good enough incentive. Doubly so since the developers working on these projects are usually the "creme de la creme", releasing and maintaining truly useful software usually requires expertise only a small fraction of engineers have.</p>
<p>The second group, the corporation and government-funded teams can only exist because of the scale.</p>
<p>Why can Facebook develop PyTorch?</p>
<ul>
<li>Because Facebook hires so many ML engineers that in the cost-benefit analysis it's cheaper to have your internal framework be popular enough such that you can get already-trained people from day 1. The &lt; 100 people working full time on PyTorch save months of training for every single one of the thousands of ML people facebook hires, since it can hire people that already know PyTorch.</li>
<li>Because Facebook doesn't dominate by having better ML models, it dominates by having thousands of times more data than anyone else. It's in facebook's interest to keep research open since it's objective is not to get ahead, but just to stay even, or at least not fall significantly behind.</li>
</ul>
<p>Why can Nvidia assign engineers to dozens of open source ML and game-engine projects?</p>
<ul>
<li>Because Nvidia makes hundreds of billions each year selling GPUs. The little work they put into those libraries to make sure it works ideally with their GPUs is insignificant to the revenue they get from those markets.</li>
</ul>
<p>Why can Google develop TensorFlow?</p>
<ul>
<li>For about the same reasons as Facebook.</li>
<li>Because they can make a lot more money from selling/renting TensorFlow optimized hardware.</li>
</ul>
<p>And that's on the happier side of the spectrum. On the "shadier" end of the scale, one could argue projects like Flutter and Angular might be worth their investment because they make spyware-free browsers like Firefox send-class citizens in the war for the web, not to mention easier integration into internet-monopolizing schemas like AMP.</p>
<p>You've also got, I will admit, projects that seem to be open source purely for flexing. To my knowledge, Yandex might have well never released Clickhouse and the column-store database landscape would have been set back 10+ years for it. Why did they do it? Maybe just because few dozens of people working on it wanted to showcase how good they are.</p>
<p>But at the end of the day, this is not a reliable model</p>
<h2>III - Profit motives</h2>
<p>So would it not be nice for open source if one can bring profit motives into the whole thing?</p>
<p>Even better, profit from the people that don't support or contribute to open source, but not from those that do.</p>
<p>It seems to me like double-licensing with GPL achieves just that. One can release a project and charge large companies for using it, at the risk of breaking the license if they don't pay. Even if a lot of them will use the software illegally, as is the case now, the threat of lawsuits will end up deterring some or most heavy-users from doing so.</p>
<p>On the other hand, people using the project in an open-source project of their own have nothing to worry about.</p>
<p>The only problem that remains here is the fact that you can't chain GPL projects. That is to say, one can't use GPL code in their own double-licensed GPL code, but there are workarounds for that (e.g. isolating the GPL dependency and open-sourcing the changes to that alone). Still, this seems like the kind of problem that could be fixed by an off-shoot of the GPL meant for just this use-case.</p>
<p>This model keeps all the advantages of GPL, in that it incentives your users to open-source their product. It doesn't force them to do so, like a purely-GPL licensed software might, but it's not like GPL is working as intended, outside of a few cases where enough money was at stake to sue (e.g. TiVo), violations of the GPL go unpunished.</p>
<p>Currently, a company that wants to include GPL into their project has two options:</p>
<ul>
<li>Use the code in such a way that GPL won't force you to open source the rest of your code.</li>
<li>Use the code and break the license.</li>
</ul>
<p>Since the wording of GPL is not that clear, it could often be argued that companies go for alternative nr 2. After all, who will ever know?</p>
<p>But what if the "pay the maintainer a small sum" option was available. Wouldn't the liability afraid giants look towards this much more favorably than either of the other 2 options? Wouldn't this, in the long run, give an edge to open source projects which don't have to worry about these fees ?</p>
<hr>
<p>Thus I think I come in squarely on the side of open-source companies dual-licensing GPL on their product[s]. A model that already exists and often enough has great success (see MariaDB and Aerospike).</p>
<p>It's a nice compromise for moving towards a more open world, without having to live in Stallman's utopia. It's an amazingly pragmatic solution and anyone who reads this blog knows I'm a fan of those.</p>

      </div></div>]]>
            </description>
            <link>https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677481</guid>
            <pubDate>Sun, 04 Oct 2020 09:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A modular, extensible DIY NAS]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24677407">thread link</a>) | @ggeorgovassilis
<br/>
October 4, 2020 | https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/ | <a href="https://web.archive.org/web/*/https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This post was extensively <a href="https://news.ycombinator.com/item?id=24677407">discussed on Hacker News</a>.</p>



<p>Iâ€™ve been running for a decade a self-built NAS at home, so I thought Iâ€™d write down my experience so that others might gloat over my many failures and gasp in awe at my few triumphs.</p>



<figure><img data-attachment-id="1780" data-permalink="https://blog.georgovassilis.com/img_20200929_210932458_hdr/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg" data-orig-size="1728,2304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;moto x4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1601413773&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.519&quot;,&quot;iso&quot;:&quot;763&quot;,&quot;shutter_speed&quot;:&quot;0.071428571428571&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20200929_210932458_hdr" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=225" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768" src="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768 768w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=1536 1536w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=113 113w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>The HP Proliant microsever gen8 is affordable, compact and runs on Ubuntu</figcaption></figure>



<p>The NAS is <strong>perfect</strong> because it is simple, safe, modular and extensible and it is <strong>cheap </strong>because it is built of second hand, commodity parts.</p>



<p>The NAS mostly stores files (documents and media) on a software RAID 6 and serves them over Windows shares to the local network. Iâ€™m staying away from proprietary NAS solutions because a hardware failure would make data recovery hard to impossible without the exact same hardware replacement. Every piece of hardware,  from the hard disks to the case and motherboard have been switched out for something else in this decade, sometimes more than once, so the focus on modularity paid for itself. Since long-term data integrity and robustness is a concern, the NAS should run some sort of redundant RAID level.</p>



<h2>Goals</h2>



<figure><table><tbody><tr><td><strong>Goal</strong></td><td><strong>Description</strong></td><td><strong>Solution</strong></td></tr><tr><td>Function</td><td>The NAS serves as a <strong>network attached file system</strong> for home use; the NAS operates a few hours a day and is either off or in standby most of the time </td><td>Commodity hardware, open source software, modularity, keep it simple</td></tr><tr><td>Interoperability</td><td>Commonly used computer platforms should be able to access files on the NAS. Commodity hardware should be able to connect to the NAS.</td><td>Samba (aka Windows shares) on Ubuntu, USB, SATA. Connect LAN to Wifi router, does name resolution and time server. Access and manage with SSH.</td></tr><tr><td>Modularity</td><td>Hardware and software components should be <strong>interchangeable </strong>without redesigning the entire system  </td><td>x86 PC platform, Linux, Docker</td></tr><tr><td>Control</td><td>I want to control <strong>which software is installed</strong> on the NAS and what it does </td><td>Ubuntu 18.04 LTS</td></tr><tr><td>Data integrity</td><td>Files of arbitrary <strong>size </strong>(within reason) and content should be stored on the NAS and not <strong>corrode or lose integrity</strong> over time </td><td>RAID 6 with 4 hard drives, ext4fs with checksumming, scrubbing, manually assembled RAID, ECC RAM. Sign archives with par2.</td></tr><tr><td>Noise</td><td>Noise should be low and tolerable </td><td>HDDs in standby, SSD as primary OS disk, write-mostly, lots of RAM, passive cooling</td></tr><tr><td>Cost</td><td>Use commodity hardware and free, open source software </td><td>2nd-hand commodity hardware, hard disks instead of SSDs</td></tr><tr><td>Low maintenance</td><td>Avoid time critical maintenance</td><td>ufw firewall accepting connections only from internal network, no auto-updates, limited software, Docker, not accessible from the Internet.</td></tr><tr><td>Data safety</td><td>In case of hardware loss or theft unauthorised parties shouldnâ€™t be able to access the data</td><td>dmcrypt with key on external device</td></tr><tr><td>Low power consumption</td><td>Power consumption should be in line with the serverâ€™s function</td><td>Components in stand-by most of the time, SSD, RAID in write-mostly</td></tr><tr><td>Compact</td><td>Physical NAS dimensions should be small; no space wasted</td><td>2nd hand HP proliant microsever gen8 </td></tr></tbody></table></figure>



<h2>Non-goals</h2>



<ul><li>Typical media-server tasks: streaming, encoding, transcoding etc</li><li>Bitcoin mining</li><li>Torrenting</li><li>Everything else ğŸ™‚</li></ul>



<h2>Getting the Hardware</h2>



<p>Getting the right hardware is the hard-(pun)-est part as it is the platform for modularity, price, energy consumption, size and many other goals Iâ€™m interested in. There are many second-hand, cheap proprietary NAS servers around, but I donâ€™t like the idea of closed hardware and software systems. Eg, if a hardware RAID controller stores data in a proprietary format on the hard drives I would need the exact same replacement controller to recover that data in case of a controller failure.</p>



<p>Space is also an issue, so the server should be compact while allowing running Linux on it; that is quite hard to find as most compact NASâ€™ out there are proprietary systems and donâ€™t allow installing your own OS. There are plenty of used x86 PCs and servers, but they are mostly too big or donâ€™t have enough drive bays or SATA ports. Connecting drives over USB is also not an option because of the low speed, higher power consumption and space requirements. The first couple of my NAS revisions around 2010 used a compact barebone and later a mini tower case around which had 3 or 4 hard disk bays, but I find those box formats harder to come by these days. Lucky you if you get one at an affordable price!</p>



<p>I came across a used <a href="https://support.hpe.com/hpsc/doc/public/display?docId=emr_na-c03793258">HP proliant microserver</a> gen8 and havenâ€™t regretted it ever since. The base model came with 2GB ECC RAM, a Celeron 2-core CPU and no hard drives for about 100â‚¬. Thereâ€™s an excellent review of that server on <a href="https://louwrentius.com/zfs-performance-on-hp-proliant-microserver-gen8-g1610t.html">Louwrentius</a>. The server is extremely compact (about 26cm each dimension), reasonably low noise (although not silent) in standby, has a passively cooled CPU, two GBit ethernet ports, four 3,5â€³ hard drive bays and a somewhat hidden proprietary format slot for a fifth low-profile 2,5â€³ disk which I use for an SSD. The drive bays can directly receive SATA disks while the 5th slot requires a 4 pin FDD male-to-SATA adapter and a SATA cable to connect a 2.5â€³ SSD to the motherboard, which requires an FDD 4 pin (male)-to-SATA connector. As an added bonus, the server features <a href="https://en.wikipedia.org/wiki/HP_Integrated_Lights-Out">ILO</a> which allows remote access to the server with a web browser â€“ so no need for a keyboard or screen!</p>



<p>I admit that the server isnâ€™t 100% commodity parts; eg. a motherboard or CPU failure would require ordering the exact same spare parts (which is probably going to be expensive) or building a completely new server on a different platform. However RAM, network and storage are fairly standard, I run Ubuntu on it and the benefits outlined earlier weigh enough to take that risk. About 6 years later the server still runs without any issues; barring <a href="https://en.wikipedia.org/wiki/Survivorship_bias">survivor bias</a>, I think that approach worked well.</p>



<p>The server I purchased had firmware from 2014 and HP thankfully started publishing updates for free recently, the last one from late 2019 which I flashed the microserver with for a slick HTML5 management UI.</p>



<p>The server underwent various upgrades over the years; from a RAID5 array of three 2TB hard disks to the current setup of 3x6TB + 1x8TB + 1x 512MB SSD and a CPU upgrade to a Xeon model and a RAM upgrade to 16GB ECC. I almost exclusively repurpose external USB hard drives (after opening , extracting the HDD and kissing the warranty goodbye) which are cheaper than internal onesâ€¦ at first that is surprising considering the extra hardware (case, USB-to-SATA adapter, cables, power supply) they come with; however the warranty and technical specs are significantly inferior to those of internal drives which explains the price difference. Since the server runs a RAID 6 (the entire point of which is to survive disk failures) I think that is an ok risk to take.</p>



<p>The server is connected over an Ethernet cable to the home Wifi router; network speeds are close to 100mb/s which is ok, the USB3 ports can do around 40mb/s.</p>



<h2>Installation</h2>



<p><a href="https://en.wikipedia.org/wiki/HP_Integrated_Lights-Out">ILO </a>makes setting up the server easy even without a physical keyboard and screen. I started with Ubuntu server LTS 14.04, switched over to 16.04 and am currently running 18.04. The upgrades never worked in place, in each case a fresh installation was required. </p>



<p>I recommend installing a VM (like VirtualBox) on your workstation, booting Ubuntu Server 18.04 from a live image and installing Ubuntu on a USB harddisk. I couldnâ€™t get the Proliant microserver to boot with UEFI, so a traditional grub BIOS installation is required. </p>



<p>The four hard disks are partitioned according to the schema below: a 1MB partition at the beginning for the GRUB boot loader, a 50GB partition for Ubuntu and a 5.5TB partition for the RAID.</p>



<p>I used the Ubuntu Server 18.04 alternative installer to set up the Ubuntu partitions as a RAID 1 which mirrors that partition over all hard disks. The installer is able to install Ubuntu into that RAID 1 and GRUB is able to boot from it. In case of a hard disk failure, just removing that hard disk will allow the server to boot again.</p>



<pre><code>+-------------------+
| 1MB bios_grub     |
|                   |
+-------------------+
| 50GB Ubuntu ext4  |
| RAID 1            |
+-------------------+
| 5.5TB Data        |
| RAID 6            |
+-------------------+</code></pre>



<p>For the installer to work, there need to be at least two disks in the RAID. More disks can be <a href="https://raid.wiki.kernel.org/index.php/Growing">added later</a>. Just make sure to install the GRUB bootloader on all disks with:</p>



<pre><code>grub-install /dev/sdX</code></pre>



<p>In my first experiments Ubuntu was able to boot fine, but wouldnâ€™t activate the ethernet cards. This requires some fiddling with netplan.</p>



<p> <strong>/etc/netplan/01-netcfg.yaml</strong> </p>


<pre title="">network:
  version: 2
  ethernets:
    eno1:
      dhcp4: true
      dhcp6: true
      optional: true
    eno2:
      dhcp4: true
      dhcp6: true
      optional: true
</pre>


<h2>Boot RAID considerations</h2>



<p>As discussed in â€œinstallationâ€, Ubuntu boots from a RAID 1. md mirrors changes to all boot partitions, which is awesome. The boot RAID is mapped under /dev/md0 â€“ I didnâ€™t find a way to assign a name to it, but I found the device name to be stable. Unfortunately Ubuntu will constantly access the boot drive during normal operation, which in my case means that four drives are always spinning. I tried various things like remapping log directories to a ram disk and pre-loading files, but the resulting jungle of scripts is impossible to maintain. The solution turned out to be quite simple and elegant, after a hack: I installed an SSD in the 5th hard disk bay and added it to the boot RAID 1. While mirroring worked, the Proliant (gen8) BIOS wonâ€™t boot from the 5th bay if it finds hard disks somewhere else. The solution is a script which runs after boot and fails all mechanical hard disks in the RAID:</p>



<pre><code>mdadm --manage /dev/md0 --fail /dev/sda2 /dev/sdb2 /dev/sdc2 /dev/sdd2</code></pre>



<p>The script is a bit more complex than that as device names are not stable and various error conditions need to be taken into account (eg. the RAID shouldnâ€™t be touched if a harddisk is failing) â€“ but that is a topic for a different post. MD will forget that the disks have been marked as failed after a reboot, which â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/">https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/</a></em></p>]]>
            </description>
            <link>https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677407</guid>
            <pubDate>Sun, 04 Oct 2020 09:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Left My Tenured Academic Job]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24677171">thread link</a>) | @DyslexicAtheist
<br/>
October 4, 2020 | https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/ | <a href="https://web.archive.org/web/*/https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><time datetime="2020-10-03T09:00:00+0200">Sat, Oct 3, 2020</time></p>

    <p>RSS: </p> <p><a href="https://reyammer.io/blog/index.xml"><img src="https://reyammer.io/rss.png" width="23px"></a></p>

  <p>The <a href="https://twitter.com/reyammer/status/1311338230139232258" target="_blank">news is out</a>: I left France, I'm no longer a professor at EURECOM, I joined the Malware Research Team at CISCO Talos, and I moved to beautiful Vienna. Big change :-)</p>
<p>I have been a professor for a bit more than three years, but I have had contrasting feelings about the "prof job" for a long time (even before finishing my PhD), it took me a couple of years to realize that I would eventually have needed to move on, and it took even more (mental) effort to actually make the call and leave. Despite being <em>very</em> excited for what's next, oh boy, this was tough :-) But independently of the concrete next step, it was time to move on. Even if Talos realizes the mistake and kicks me out next week, I'm still confident that moving on was the right call.</p>
<p>Especially when it comes to take big decisions, I tend to obsess about trying to stay rational, and I spent years collecting notes on the various pros/cons. Many of these thoughts often started surfacing as "feeling something is not right", without consciously understanding what was going on. But by keep thinking and writing notes down, patterns of thoughts started to emerge and I was eventually able to pinpoint some more defined thoughts on what kept me on the current job and what pushed me to change. Once these reasons were clear, it was much easier to take the decision.</p>
<p>This is a very long blog post, and I don't expect more than a very few people to actually read it. I wrote it mostly for selfish reasons: before changing to a new life, I wanted to wrap up all these notes in something more structured. I can't be certain I took a good decision, but systematizing these thoughts allowed me to move on with enough confidence to know I'm likely making a step forward.</p>
<p>With that being said, I know that someone may be actually interested in hearing these thoughts and my experience. When I was a PhD student and I needed to take the notorious academia vs. industry decision, I would have paid big bucks to read more thoughts on the various pros/cons. One of the stupidest things you can do is to take big decisions based on what other people do and think, but reading about other people's thought process has helped me a lot. It is time I do my part.</p>
<p>The target audience for this post is, other than myself, PhD students / postdocs that are about to decide what to do next and junior profs that somehow feel that "something is wrong". I also expect some senior academics and industry people to read this post, but I guess they will find themselves skipping directly to the academic rant part and mostly agree with much I have to say :-) Anyways, I tried to stay away from the "very known things" (e.g., ğŸ‘€-level BS when writing proposals, generally "more limited" immediate impact of your work, different compensation level, etc.), and I tried to focus on thoughts I have not seen much discussed around (at least not in this depth).</p>
<p>So, if you feel clueless and you want to hear more from an equivalently clueless random dude on the Internet, here we are :-) If you think this is <em>the</em> blog post that will make everything clear, I have a bad news for you: it's all about tradeoffs and in my opinion there is no clear-cut winner. And, unfortunately, the problem with tradeoffs and balancing many aspects is that figuring out which one to weigh more is yet another very personal decision in its own way. So, you will not find any answer in this post and you will eventually need to figure this thing out on your own, but I hope this will help you forming your own opinion.</p>
<p>This post is organized in three parts:</p>
<ul>
<li><a href="#part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good â€” What pushed me to keep the job</a></li>
<li><a href="#part-2-the-bad-mdash-what-pushed-me-to-leave-the-job">Part 2: The Bad â€” What pushed me to leave the job</a></li>
<li><a href="#part-3-the-bye-bye-mdash-the-decision-to-leave">Part 3: The Bye Bye â€” The decision to leave</a></li>
</ul>
<p>Enjoy!</p>
<p><em>Mandatory disclaimer: I have no idea what I'm talking about, and these are personal takes/opinions anyways. Unless you are a bad person, please don't take anything personal. Please feel free to reach out, ping me on twitter, or shoot me an email: I'm of course happy to share more thoughts if you have any question. And if you disagree with something, bring it on! I love to argue, especially with people with strong and different opinions :-)</em></p>
<br>
<h2 id="part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good â€” What pushed me to keep the job</h2>
<p>Before I discuss why I left, I want to touch on what pushed me to keep the job. I want to make sure it's a balanced post despite the upcoming mega rant, so that my overall opinion is more closely reflected. And I really don't want to discourage anyone to take this path, I still think it is a great one.</p>
<p>Note that some of my "reasons to stay" are good, but some are bad. Also note that many of these refer to my personal situation at EURECOM, working in the field of systems security, and not all these points can be generalized to all universities. As they say, your mileage may vary.</p>
<h3 id="its-a-very-good-job">It's a very good job</h3>
<p>The first pros is... ğŸ¥: "it's a very good job". At first, I was shocked to find out that it's an actual job. When I joined this prof thingy I thought that this would be a "job" (note the double quotes). But, while it's true that you don't have a direct boss that tells you what to do, at the end of the day you need to deliver, and you actually work very hard: If your PhD students are in trouble or you teaching sucks, you will run into problems. This doesn't necessarily mean "they kick out", but if you value being a professional (and I do), failing at your core tasks will make you feel bad, even without additional pressure from your superior, and even if you have tenure.</p>
<p>And now that we got this "it's an actual job" out of the way, I can tell you: it's a very good one. There is <em>a lot</em> of freedom in what you do and how you structure your time. Research-wise I felt very free (but you eventually work on what your students like to work on â€” as it should be), and the department values the right things (I've heard some BS in other schools where, in the context of systems security research, they pressure you to "publish more journal papers..." ğŸ¤¦â€â™‚ï¸). I really like teaching and mentoring, and there were many opportunities to do so. They let me create and teach my own class on mobile security, <a href="https://mobisec.reyammer.io/" target="_blank">MOBISEC</a>, and the teaching load is overall very low (1 or 1.5 classes per year). I love playing CTFs and I was even <em>encouraged</em> to spend time and push for NOPS, the EURECOM CTF team (after winning <a href="https://ctftime.org/event/647" target="_blank">HXP CTF 2018</a> and after being referred to as "<a href="https://youtu.be/j0taw78tCYs?t=968" target="_blank">probably a top team</a>" we are mostly enjoying our eternal and well-deserved glory).</p>
<p>The environment is extremely relaxed, informal, and friendly. You are surrounded by top-skilled colleagues and humans, from MS students to profs. I felt in a family from day 1. Last very good point: since in France positions come with tenure, there were not even problems in terms of pre-tenure stress, a real luxury. And on this aspect, EURECOM delivered: I never felt any sort of pressure (but: I did work my ass off... so if you stop doing anything, bad things may happen :-)).</p>
<p>[BTW, EURECOM is frantically trying to replace me, you should apply :-)]</p>
<h3 id="you-are-surrounded-by-students">You are surrounded by students</h3>
<p>When I took my decision to remain in academia, my top reason was for teaching and mentorship. Probably the best perk of the job is that you are surrounded by people eager to learn, from MS to PhD students to postdocs. It is extremely fulfilling and rewarding. Working with my students has been the highlight of my time at EURECOM, from traditional teaching, to suffering through the various rejections, to celebrating defeats of Reviewer #2, to cluelessly getting CTF-close in many stego CTF challenges. I feel very lucky that during these years we found enough interesting ideas that we enjoyed working on together, and that my next job will allow me to keep advising them until they graduate. As a prof, I believe the net output of my work is to see students becoming independent researchers, not the actual papers â€” I can't wait to see the bright careers I'm sure they will have :-)</p>
<h3 id="i-have-deep-respect-for-the-role-of-profs-in-society-and-it-felt-great-to-be-one">I have deep respect for the role of "profs" in society, and it felt great to be one</h3>
<p>I somehow have a profound admiration for the role that professors have in society and that had in my life. For their hard work, knowledge, passion, patience, and ultimately their service to the community. I'm referring to all teachers and mentors (from elementary schools to universities), who spend their life helping others, while at the same time often being asked to do many useless things and being massively underpaid. I admire and deeply respect these efforts: my most sincere thank you to all past, present, and future profs!</p>
<p>And, to be frank, it felt great to be one. I have been in love with the idea of being a prof for many years. In part, I think it is because some of the people who impacted me the most are professors, and I wanted to do my part in helping others. And after all the uncertainties that one has during a PhD, I think I was even more in love with the idea of having finally found my place in society. [Narrator: LOL, this clueless dude did not find his place. [Answer to narrator: But I've surely found it <em>now</em>!!1!]]</p>
<p>Overcoming all these positive emotions and feelings attached to this job was likely the biggest challenge I faced in coming to terms with the several problems and cons I did have during these three years. As mentioned, I have no intention to give up on this teaching/mentoring thing (taking the time for this long blog post is part of this!), but it will surely not be the same thing. I'm very grateful I had a chance to try this job out. Thanks to all who made it possible, from family to advisors, colleagues, and students â¤ï¸. I owe you big time.</p>
<p>[Of course, being a prof does not necessarily make you a smart or great person. Some profs I know are some of the dumbest people I have ever met (by far) and they would not survive one day in the real world. And some profs I know are the most asshole, selfish, egomaniac, and delusional humans I have ever heard of (Are you pushing your students to stay in the lab â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</a></em></p>]]>
            </description>
            <link>https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677171</guid>
            <pubDate>Sun, 04 Oct 2020 07:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Gzip Format (2011)]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24676831">thread link</a>) | @WoodenChair
<br/>
October 3, 2020 | http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001 | <a href="https://web.archive.org/web/*/http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><tbody><tr><td><div id="main">
<p>
In this article I describe the DEFLATE algorithm that GZIP implements and depends on. The DEFLATE algorithm uses a combination of LZ77, Huffman codes and run-length-encoding; this article describes each in detail by walking through an example and developing source code to implement the algorithm. My aim is to implement readable rather than efficient or extensible code. I'll focus here on unzipping, rather than zipping, but by the end of the article, the zipping process should be clear.
</p>
<p>
Material intended for human consumption tends to be highly redundant, from an information processing perspective. Because of the mysterious human mind, we need to have the same thing repeated to us in different ways in order for it to be processed correctly. Natural language, for example, is inefficient - the English language phrase "I am going to the store" could easily be abbreviated "I go store". If the subject of conversation has already been established as "me", it could be further abbreviated unambiguously as "go store". This is how children communicate until they are taught proper grammar - but as we mature, we like/want/need the redundancy.
</p>
<p>
Computers are no better when it comes to demanding redundancy. Computer programs repeat the same instructions over and over again, and program source code is verbose, even when the programmer isn't concerned about using readable variable names (you know who you are). Computer storage, on the other hand, is a scarce resource. It becomes less and less scarce every day, but every time capacity increases, we seem to find a way to run out of it. I'm sure that someday, my children will be complaining that their thumbnail computer devices can "only store four holodeck simulations!"
</p>
<p>
Computer scientists have been studying ways to use computer storage more efficiently since the 1960s. In 1977, Abraham Lempel and Jacob Ziv published "A Universal Algorithm for Sequential Data Compression " [1] which described what is now referred to as the "LZ77" compression algorithm. Conceptually, LZ77 is pretty straightforward - read the source document, and, for each sequence of bytes encountered, search backward through the document to see if the same sequence occurs previously. If so, rather than outputting the sequence, output a back pointer to the first occurrence of the sequence.
</p>
<p>
To get a sense of just how redundant English text is, take a look at figure 1 and figure 2. Figure 1 contains the first few verses of the Bible's book of Genesis and figure 2 shows all of the places where text from a prior point in the document is repeated. LZ77 does a very good job of exploiting that redundancy and making efficient use of available storage.
</p>
<p>
<img src="http://www.infinitepartitions.com/genesis.gif">
</p><p>Figure 1: Uncompressed ASCII text</p>

<p>
<img src="http://www.infinitepartitions.com/genesis_compressed.gif">
</p><p>Figure 2: LZW compression</p>

<p>
The first 17 verses, with LZ77 compression applied, is shown below. The &lt;#,#&gt; brackets indicate backpointers in the form &lt;distance, length&gt;. So, the first backpointer &lt;25,5&gt; indicates that, to uncompress the document, search backward 25 characters, and reproduce the five characters you find there. As you can see, the first sentence is mostly uncompressed, but by the middle of the text, there's almost no uncompressed text.
</p>
<p>
001:001 In the beginning God created&lt;25, 5&gt;heaven an&lt;14, 6&gt;earth.
0&lt;63, 5&gt;2 A&lt;23, 12&gt; was without form,&lt;55, 5&gt;void;&lt;9, 5&gt;darkness&lt;40, 4&gt;
&lt;0, 7&gt;upo&lt;132, 6&gt;face of&lt;11, 5&gt;deep.&lt;93, 9&gt;Spirit&lt;27, 4&gt;&lt;158, 4&gt;mov&lt;156, 3&gt;&lt;54, 4&gt;&lt;67, 9&gt;&lt;62, 16&gt;w&lt;191, 3&gt;rs&lt;167, 9&gt;3&lt;73, 5&gt;&lt;59, 4&gt;said, Let&lt;38, 4&gt;r&lt;248, 4&gt; light:&lt;225, 8&gt;re&lt;197, 5&gt;&lt;20, 5&gt;&lt;63, 9&gt;4&lt;63, 11&gt;w&lt;96, 5&gt;&lt;31, 5&gt;,&lt;10, 3&gt;at &lt;153, 3&gt;&lt;50, 4&gt;good&lt;70, 6&gt;&lt;40, 4&gt;divid&lt;323, 6&gt;&lt;165, 9&gt;&lt;52, 5&gt; from&lt;227, 6&gt;&lt;269, 7&gt;&lt;102, 9&gt;5&lt;102, 9&gt;call&lt;384, 7&gt;&lt;52, 6&gt;Day,&lt;388, 9&gt;&lt;326, 9&gt;&lt;11, 3&gt;&lt;41, 6&gt;&lt;98, 9&gt;N&lt;183, 5&gt;&lt;406, 10&gt;&lt;443, 3&gt;&lt;469, 4&gt;&lt;57, 8&gt;mor&lt;15, 5&gt;w&lt;231, 4&gt;&lt;308, 5&gt;irst&lt;80, 3&gt;y&lt;132, 9&gt;6&lt;299, 28&gt;a&lt;48, 4&gt;mamen&lt;246, 3&gt;&lt;437, 6&gt;midst&lt;375, 7&gt;&lt;134, 9&gt;&lt;383, 6&gt;&lt;177, 6&gt;le&lt;290, 5&gt;&lt;272, 6&gt;&lt;413, 11&gt;&lt;264, 10&gt;&lt;429, 15&gt;7&lt;129, 9&gt;mad&lt;166, 9&gt;&lt;117, 6&gt;&lt;82, 6&gt;&lt;348, 11&gt;&lt;76, 8&gt;which&lt;215, 5&gt;&lt;600, 10&gt;nder&lt;62, 14&gt;&lt;115, 16&gt;&lt;54, 11&gt; ab&lt;599, 3&gt;&lt;197, 13&gt;&lt;54, 9&gt;&lt;470, 6&gt;&lt;487, 7&gt;so&lt;169, 9&gt;8&lt;432, 20&gt;&lt;108, 10&gt;H&lt;827, 5&gt;&lt;397, 25&gt;&lt;103, 9&gt;&lt;405, 17&gt;seco&lt;814, 5&gt;&lt;406, 10&gt;9&lt;406, 22&gt;&lt;199, 8&gt;&lt;235, 10&gt;&lt;944, 7&gt;&lt;428, 3&gt;ga&lt;439, 5&gt;&lt;540, 10&gt;toge&lt;18, 4&gt;&lt;45, 3&gt;to one pl&lt;820, 3&gt;&lt;422, 10&gt;&lt;604, 5&gt;ry l&lt;16, 4&gt;app&lt;981, 3&gt;&lt;250, 8&gt;&lt;474, 11&gt;&lt;258, 12&gt;10&lt;258, 20&gt;&lt;67, 9&gt;E&lt;1046, 4&gt;;&lt;638, 9&gt;&lt;145, 6&gt;&lt;234, 4&gt;&lt;138, 8&gt;&lt;86, 9&gt;&lt;952, 13&gt;&lt;75, 8&gt;&lt;1018, 4&gt;eas&lt;853, 10&gt;&lt;894, 6&gt;&lt;883, 14&gt;&lt;138, 9&gt;1&lt;290, 23&gt;&lt;1179, 6&gt;b&lt;119, 5&gt;&lt;1173, 3&gt;&lt;11, 3&gt;grass,&lt;302, 7&gt;rb&lt;132, 9&gt;yield&lt;38, 4&gt;seed&lt;879, 10&gt;fru&lt;111, 3&gt;tree&lt;33, 10&gt;&lt;19, 6&gt;af&lt;174, 3&gt; hi&lt;1229, 10&gt;kin&lt;57, 3&gt;whose&lt;69, 5&gt; is&lt;809, 4&gt;itself,&lt;1260, 10&gt;&lt;148, 5&gt;&lt;599, 23&gt;1&lt;1367, 16&gt;brou&lt;1082, 5&gt;&lt;189, 12&gt;&lt;58, 4&gt;&lt;189, 4&gt;&lt;181, 14&gt;&lt;136, 9&gt;&lt;154, 9&gt;&lt;146, 7&gt;&lt;204, 8&gt;&lt;198, 19&gt;&lt;175, 13&gt;&lt;138, 4&gt;i&lt;1369, 10&gt;&lt;184, 8&gt;&lt;78, 14&gt;&lt;401, 39&gt;3&lt;1160, 42&gt;thir&lt;753, 13&gt;14&lt;1460, 33&gt;s&lt;1155, 8&gt;&lt;882, 10&gt;&lt;1159, 15&gt;&lt;780, 7&gt;&lt;749, 3&gt;&lt;1150, 11&gt;&lt;100, 3&gt;&lt;1031, 10&gt;n&lt;72, 4&gt;;&lt;769, 12&gt;m&lt;95, 4&gt;&lt;361, 3&gt;&lt;68, 9&gt;sign&lt;367, 7&gt;&lt;22, 3&gt;&lt;293, 3&gt;aso&lt;16, 12&gt;&lt;79, 3&gt;&lt;13, 7&gt;y&lt;430, 3&gt;s:&lt;192, 8&gt;&lt;1486, 6&gt;&lt;85, 15&gt;&lt;185, 31&gt;&lt;177, 10&gt;&lt;126, 9&gt;giv&lt;1541, 8&gt;&lt;573, 38&gt;6&lt;1343, 15&gt;wo&lt;562, 3&gt;&lt;2001, 3&gt;&lt;122, 7&gt;;&lt;906, 6&gt;&lt;2019, 5&gt;&lt;142, 7&gt;&lt;288, 4&gt;rul&lt;1277, 14&gt;d&lt;1650, 12&gt;l&lt;1646, 3&gt;&lt;45, 20&gt;&lt;319, 6&gt;:&lt;937, 4&gt;&lt;1452, 9&gt;st&lt;261, 3&gt;&lt;647, 10&gt;l&lt;154, 11&gt;&lt;1498, 10&gt;s&lt;278, 8&gt;&lt;264, 33&gt;&lt;256, 11&gt;&lt;2099, 18&gt;&lt;264, 5&gt;,
</p>
<p>
Example 1: LZ77 compressed representation of the first 17 verses of Genesis
</p>
<p>
This relatively short document is compressed at just over 3:1 - and the compression ratio generally improves as documents get longer.
</p>
<p>
Of course, when discussing computer formats, it's not enough to talk about concepts - a concrete representation must be agreed upon. The decoder/decompressor must have a way to distinguish which input bytes are literals, and which input bytes are backpointers. One simple, naive representation might be to introduce an "escape code" - say, 0x255, to distinguish backpointers from literals. Of course, a literal escape code would need to be similarly escaped.
</p>
<p>
Unfortunately, all of these escape codes end up defeating the purpose of compressing in the first place. As it turns out, there's a better way to encode these backpointers and still allow them to be correctly distinguished from literals: variable length codes. In ordinary byte-oriented data, each code is a fixed length (typically 8 bits). Variable length codes remove this restriction. Some codes can be shorter and some can be longer. Once there's no need to restrict yourself to eight-bit bytes, you can define an arbitrarily-sized "alphabet", which is exactly what GZIP does. The first 255 characters in this alphabet are the literal codes - the 8-bit bytes that were read from the input stream. The 256th character is a "stop code" that tells the decode when to stop decoding. The 257-285th codes indicate the length of the matched range (followed immediately by a distance code).
</p>
<p>
Now, if there are only 285-257=28 length codes, that doesn't give the LZ77 compressor much room to reuse previous input. Instead, the deflate format uses the 28 pointer codes as an indication to the decompressor as to how many extra bits follow which indicate the actual length of the match. This logic is complex but important for compatibility; I'll cover it in more detail below.
</p>
<p>
In a fixed-length world, this 285-symbol alphabet would require 9 bits per symbol, but would use only a little more than half of the available 512 bytes that 9 bits can encode. This alphabet can be encoded much more efficiently by assigning the symbols variable-length codes. However, the problem with variable length codes is that the decoder needs to know where one code ends and the other begins. This isn't a problem with fixed-length codes such as ASCII - the decoder reads 8 bits, decodes them, and then reads another 8 bits. To ensure that the encoder can unambiguously interpret the variable length codes, you have to be careful how you assign these codes. Imagine that you were dealing with a four-character "alphabet" with four variable-length codes:
</p>
<pre>1. A: 1
2. B: 0
3. C: 10
4. D: 11
</pre>
<p>
Example 2: Invalid variable-length code assignment
</p>
<p>
The problem with this assignment is that the codes are ambiguous. The decoder can't tell if the input sequence "10" is an A followed by a B, or a C by itself.
</p>
<p>
The solution is to assign prefix codes. With prefix codes, once you use a prefix to delineate a range of codes, it can't be used by itself as a code. So if the character "A" is assigned the 1-bit code "1", no other code can start with "1". If "B" is assigned the code "01", no other code can start with "01". A valid Huffman coding of the four-character alphabet above, then, is:
</p>
<pre>1. A: 1
2. B: 01
3. C: 001
4. D: 000
</pre>
<p>
Example 3: Valid prefix-coding variable-length code assignment
</p>
<p>
This means that there can only be one 1-bit code, one two-bit code, two three-bit codes, four four-bit codes, etc. You may deal with prefix codes on a regular basis - the country calling codes that allow you to make international phone calls are assigned using prefix code rules. Prefix codes are usually referred to as Huffman codes [2] after the inventor of a provably optimal algorithm for generating them when symbol probabilities are known. These Huffman codes are often represented as trees, where each leaf is a symbol, and each branch is a bit value.
</p>
<p>
<img src="http://www.infinitepartitions.com/huffman_tree_1.gif">
</p><p>Figure 3: a prefix code tree</p>

<p>
Once such a tree structure has been constructed, decoding is simple - start at the top of the tree and read in a bit of data. If the bit is a 0, follow the left-branch of the tree; if 1, follow the right-branch. When a leaf node is hit, stop; a symbol has been completely read. Output the symbol and return to the top of the tree.
</p>
<p>
Listing 1 illustrates a tree structure for representing Huffman codes in memory:
</p>
<pre>typedef struct huffman_node_t
{
  int code; // -1 for non-leaf nodes
  struct huffman_node_t *zero;
  struct huffman_node_t *one;
}
huffman_node;
</pre>
<p>Listing 1: Huffman tree structure</p>
<p>
Once constructed, reading â€¦</p></div></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001">http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001</a></em></p>]]>
            </description>
            <link>http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676831</guid>
            <pubDate>Sun, 04 Oct 2020 06:02:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Formal Models for Ethics]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24676411">thread link</a>) | @queueue
<br/>
October 3, 2020 | https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/ | <a href="https://web.archive.org/web/*/https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<main>
  
<section id="post-the-ethical-question-mk-ii"> 
   
    <div>
      <a href="https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">
        <h2>The Ethical Question, Mk. II</h2>
      </a> 
      <h3>
        <span>September 28, 2020</span>
        <span>26 minutes</span>
      </h3>
      
    </div>
  
    
  <div>
    
<p>As the reading time estimate crept over 30 minutes, without any end in sight, I was starting to feel like a bit of a blowhard.</p>



<p>The draft Iâ€™d originally intended to inaugurate this blog is still sitting there. Maybe I will condense and finish it (eventually), but I think it makes more sense to write <s>briefly</s> less long-windedly about what I mean. Instead of trying to exhaust the subject matter, Iâ€™m going to offer a perspective, and present a more intuitive argument for it.</p>



<p>So, more briefly, Iâ€™d like to ask you to think, for a moment, about what makes humans <em>ethically</em> important. There are two parts to this question, hidden just under the surface. The first asks you to consider why humans are ethical <em>agents</em>. What makes it possible for them to do, want, or experience things that could fall under the umbrella of ethics? The second (no particular order) asks you to consider why humans are ethical <em>patients</em>. How is it that what happens to them, what is wanted of them, or what is experienced about them might also be part of an ethical problem? (This agent/patient distinction I inherit from Coeckelbergh, whose book, <em>Growing Moral Relations</em>, is worth your time.)</p>



<p>I will add before you start: ethics has been defined in a few different ways, over the millennia. I consider a few definitions interesting. </p>



<p>Charles Taylor, for instance, describes ethics as pertaining not just to moral choices and obligations between people, but questions like â€œwhat is the good life?â€ and â€œwhat is good?â€. His more expansive account, following Aristotle, moves closer to the Greek root, which refers to oneâ€™s <em>character</em>, and can be read to have a slant towards something resembling <em>virtue ethics</em>. Using Taylor, we could ask questions like â€œwhat is it good to love?â€ and not just â€œwhat is the right way to act?â€ </p>



<p>Conversely, followers of Nietzsche contrast <em>ethics</em> with <em>morality</em>, arguing that morality is about passing judgment on what people (or living beings) are and do, whereas ethics can be about <em>affirming</em> life as intrinsically self-justifying. From a (post-) Nietzschean point of view, lifeâ€™s capacity to want, struggle, and change, <em>is, from the very beginning, what is good</em> (maybe not in those words). Living well means trying to overcome the need to judge, and instead to explore and express what it is to be alive, for all its intensities and tragedies. Nietzsche is often read to be asking his readers to abandon compassion, or to think only of themselves and never of the common good, but I donâ€™t think that is exactly the case. Nietzsche is asking us to live in pursuit of what is good, but not to define it as the enemy of the bad, rather, to live <em>for its own sake, come what may</em>, and to do what is good, <em>defined in itself</em>, rather than as a reaction.</p>



<p>I donâ€™t know Coeckelberghâ€™s position on ethics broadly, but he considers morality to be embedded in social relationships themselves. Rather than what is right or wrong to do to a <em>patient</em> being about its properties (whether it has consciousness, for instance) and defined in absolute terms, morality is about what relationships exist between an agent and a patient, and what kinds of relationships are good to have, knowing what the agent and patient already are to each other. Do I already mostly act like itâ€™s a person? I should probably treat it like one. Coeckelbergh is interesting in that he tries to legitimate ideas that have, until recently, not had much hearing in the community of western philosophers, although citing him as a source for them over others might, fairly, be challenged. For instance, he would consider our dependence on our ecology grounds to entertain an obligation towards it. I havenâ€™t finished his book yet, so Iâ€™m not aware of the extent of the advice he gives for considering problems in these relationships, but it seems fair to say that he doesnâ€™t believe thereâ€™s a system of absolute rules out there, or that we should try to find final answers to ethical problems. Relationships are particular, and they evolve. We shouldnâ€™t seek to use the fact that we donâ€™t get hard answers for our convenience; instead, we should consider relationships, for their lumpiness, their particularity, their uncertainty, and live them as best we can.</p>



<p>All of these viewpoints are very different from our ordinary patterns of ethical thought. We are used to thinking that <em>individuals</em>, or sometimes <em>social groups</em> (such as nations) have <em>rights</em> that must be guaranteed to them, but everything else goes. Sometimes, referencing Isaiah Berlin, we might say we believe that this obligation is <em>negative</em> (there are some things that people are fundamentally allowed to do, and our only obligation is to stop people who try to mess with that), or it is <em>positive</em> (there are some things that people should fundamentally be allowed to do, and we need to do our best to make that possible for them). Maybe, for whatever definition of the good, we are utilitarians, who think that we should do the most good for the most people, whatever means that could entail. Perhaps we take the <em>view from afar</em>, and ask â€œif I had the choice of all reasonably possible societies, which would I like to be born into, knowing that I might be anyone?â€ Perhaps we see ethics as different versions of the trolley problem, and find reasons, based on our moral intuitions, about what choices we should make when push comes to shove. Some of us, unfashionably, believe in immortal souls and divine law, against which we must not sin, or that her majesty inherits the right to judge from God, and that the highest good is obedience to an Earthly law. A scientist, being familiar with Hume, might read his argument that we cannot derive statements about what <em>ought to be</em> from statements about what <em>is</em>, and see cause to be an anti-realist. Maybe <em>ought</em> statements only express our personal preferences, derived from what weâ€™ve been either (or both) biologically or socially conditioned to think is pleasing. Scientists might say this implies some sort of <em>relativism</em>, or that itâ€™s best to follow whatever is the <em>conventional</em> way to think about ethics (although, if weâ€™re not in the business of assuming the world is already a pretty just place to be in, that last one may not be safe). </p>



<p>So, knowing what you know about what humans are made of, and how they relate to one another, to society, or to other beings, what makes them ethical agents, and what does it mean that they are? What about patients? I think itâ€™s probably a bad idea to try to find an answer too quickly. It might be better to think through what kinds of approaches are better, and what facts could be relevant to the question. For instance, maybe the way people want things matters, as it is defined in terms of elaborations on whatâ€™s generated by the default mode network. Maybe there canâ€™t be exactly one right answer, or maybe there must be, or maybe itâ€™s impossible to know. How would you argue that?</p>



<h2>Why it Matters </h2>



<p>I donâ€™t fully agree with Taylor, but, in <em>Sources of the Self</em>, he makes a good case for why we shouldnâ€™t be self-serving, and why we already care about ethics. He says ethics are about what we <em>want to be</em>, how we identify ourselves. This is always done in terms of social groups we identify <em>with</em>. â€œI am a professional, so I shouldâ€¦â€ Identity gives us community, people who share something about us (a way of life, perhaps), or maybe it contrasts us against a community (we can identify ourselves as rebels). We rarely, if ever, identify with just one thing, and itâ€™s no use to try to come up with a completely original identity, if itâ€™s possible to do it meaningfully at all, because it doesnâ€™t tell us much about what weâ€™re trying to be, given weâ€™re the only one who would know or care that weâ€™re being it. Identity is critically important to us in interpreting our place in the world, and what we are trying to do with it. So, says he, without identity, we would struggle to come to grips with life. It is a good thing, then, that you and I already have some ideas about <em>who we are</em>, or if weâ€™re struggling to figure that out, generally already acknowledge that it <em>is</em> an important thing to get down. Taylor says that, since itâ€™s all about coming to grips with life, we escape Humeâ€™s is/ought problem, because we donâ€™t have to set up an ethics from scratch. Ethics are already there from the beginning, and have some known properties, so we can argue about them by contrasting them. â€œGiven these two frameworks, which one of them provides the richer set of tools for figuring out how to live a good life?â€ To Taylor, ethics are certainly <em>real</em>, but not in the sense that theyâ€™re an object embedded in a reality perfectly detached from us, rather, they come <em>from</em> the fact that we are social creatures, and relate <em>to</em> how we are trying to live in society. They arenâ€™t just individual, or perfectly culturally relative (as there are no perfectly incommensurable cultures, which share none of the same moral ideas and cannot communicate with each other), but they arenâ€™t exactly objective and final either.</p>



<p>I like Taylor, for how he grounds consciousness of <em>ethics</em> in <em>social consciousness</em>, and I like how good he is at striking down the (usually unanswerable) â€œwhy should I care about ethics?â€ question. I share Coeckelberghâ€™s complaint that he considers only one kind of relation (between the individual and the community), and I would also gripe that his ethics are unusually centred on the <em>self</em>, for a subject that tends to ask us to think beyond ourselves. But then, that is why the argument against selfishness works so well. Itâ€™s difficult to get through to somebody who only thinks of themself unless thatâ€™s the place youâ€™re starting from. </p>



<p>Taylorâ€™s other issues, which I will not go too in-depth on here, are first, that he frames the source of ethics as appearing in the fact that one is an <em>indâ€¦</em></p></div></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/</a></em></p>]]>
            </description>
            <link>https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676411</guid>
            <pubDate>Sun, 04 Oct 2020 03:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open-source self-hosted comments systems for static websites]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24676152">thread link</a>) | @nuker
<br/>
October 3, 2020 | https://lisakov.com/projects/open-source-comments/ | <a href="https://web.archive.org/web/*/https://lisakov.com/projects/open-source-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This comparison table is inspired by
<a href="http://staticsitegenerators.net/">staticsitegenerators.net</a>. Contribute at
<a href="https://github.com/pozitron57/open-source-comments">github</a> â€”
add the missing data. Github-related data (stars, open issues + PR, etc.)
are updated daily automatically. Want different columns? Noted a bug? Submit
an <a href="https://github.com/pozitron57/open-source-comments/issues/new">issue</a>.</p>
<h2>Whatâ€™s wrong with Disqus</h2>
<p>Disqus loads absurd amount of tracking services, which exposes your visitorsâ€™
personal data and significantly increases loading time. See, e.g., 
<a href="http://donw.io/post/github-comments/#what-s-wrong-with-disqus">this post</a>.</p>
<h2>Whatâ€™s not covered here</h2>
<p>For a static website, one usually wants a lightweight commenting server with
as little dependencies as possible. Few commenting engines listed on the page
are provided by heavy applications (e.g.,
<a href="https://github.com/discourse/discourse">discourse</a>,
<a href="https://github.com/debiki/talkyard">talkyard</a>), but the majority are
relatively lightweight applications designed specifically to provide 
comments for the static pages.</p>
<p>This page prioritizes information on self-hosted comments. However, there
are other open-source solutions, including implementations of third-party
services (e.g., Github issues, such as
<a href="https://github.com/imsun/gitment">[1]</a>,
<a href="https://github.com/gitalk/gitalk">[2]</a>,
<a href="https://github.com/Blankj/awesome-comment">[3]</a>,
<a href="https://github.com/utterance/utterances">[4]</a>).</p>
<h2>Stars vs. time</h2>
<p>The figure below shows some of the top competitors except for Discourse (as it's not
just a light commenting server like others). The figure is useful to
indirectly estimate how active the project is.</p>
<p><a href="https://lisakov.com/projects/open-source-comments/stars-v-date.png">
<img src="https://lisakov.com/projects/open-source-comments/stars-v-date.png" alt="Plot stars vs. time" width="800px">
</a></p>
<h2>Choose columns to show</h2>
</div></div>]]>
            </description>
            <link>https://lisakov.com/projects/open-source-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676152</guid>
            <pubDate>Sun, 04 Oct 2020 02:31:45 GMT</pubDate>
        </item>
    </channel>
</rss>
