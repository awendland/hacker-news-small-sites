<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 05 Dec 2020 08:31:14 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 05 Dec 2020 08:31:14 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Sockets in Your Shell]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25287144">thread link</a>) | @signa11
<br/>
December 3, 2020 | https://who23.github.io/2020/12/03/sockets-in-your-shell.html | <a href="https://web.archive.org/web/*/https://who23.github.io/2020/12/03/sockets-in-your-shell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Something I learned recently and I thought was <em>amazing</em> - you can create sockets straight from your shell! Well, assuming you use bash or zsh - from some surface level digging, I couldnâ€™t find anything for fish.</p>

<p>Hereâ€™s how it works:</p>

<h2 id="bash">bash</h2>
<p>Bash supports tcp and udp connections out of the box, and does so with an imaginary device in <code>/dev</code>. Enter</p>
<div><div><pre><code><span>$ </span><span>echo</span> <span>"text!"</span> <span>&gt;</span> /dev/<span>$PROTO</span>/<span>$HOST</span>/<span>$PORT</span>
</code></pre></div></div>
<p>And youâ€™ll create a connection to <code>HOST:PORT</code>. <code>$PROTO</code> can be <code>tcp</code> or <code>udp</code>. If the connection canâ€™t be made, writing to/reading the file will fail.</p>

<p>Along with being easy to access from the terminal, itâ€™s <em>very</em> handy for scripts, especially if you donâ€™t have <code>nc</code>/<code>telnet</code>. For example, if a local build of a web app runs on port 8000, you can check if itâ€™s running with:<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<div><div><pre><code><span>#!/bin/bash</span>
<span>if </span><span>exec </span>3&gt;/dev/tcp/localhost/8000 <span>;</span> <span>then
	</span><span>echo</span> <span>"server up!"</span>
<span>else
	</span><span>echo</span> <span>"server down."</span>
<span>fi</span>
</code></pre></div></div>
<p>And then use that information somewhere else.</p>

<p>If youâ€™re unfamiliar, <code>exec</code> without any arguments is used to redirect file descriptors and files. By associating fd 3 with <code>/dev/tcp/localhost/4000</code>, it attempts to create a file there and thus a connection. We use <code>&gt;</code> to open the socket for writing, although we donâ€™t need to write anything in this case.</p>

<p>By using <code>&lt;&gt;</code> we can open a file for reading and writing, and use it to create a super simple curl:</p>
<div><div><pre><code><span>#!/bin/bash</span>
<span>exec </span>3&lt;<span>&gt;</span>/dev/tcp/<span>"</span><span>$1</span><span>"</span>/80
<span>echo</span> <span>-e</span> <span>"GET / HTTP/1.1</span><span>\n</span><span>"</span> <span>&gt;</span>&amp;3
<span>cat</span> &lt;&amp;3
</code></pre></div></div>
<div><div><pre><code>$ ./simplecurl www.google.com
HTTP/1.1 200 OK
Date: Thu, 03 Dec 2020 00:57:30 GMT
Expires: -1
....
&lt;google website&gt;
</code></pre></div></div>

<p>Iâ€™m sure you can see the power of being able to open sockets with bash alone. Go play around with it!</p>

<h2 id="zsh">zsh</h2>
<p>zsh has an external module you can load in order to use itâ€™s socket capabilities. It doesnâ€™t support udp like bash, but itâ€™s more powerful in a few ways!</p>

<p>To load the module, put the following in your <code>.zshrc</code> or run it in your shell:</p>


<p>We now have access to the zsh networking builtin - <code>ztcp</code>!</p>

<p><code>ztcp</code> allows creating connections, like bash, but also allows listening for connections.</p>

<p>Straight from the zsh docs, we can create a connection between two machines with <code>ztcp</code>:</p>

<div><div><pre><code><span># host machine:</span>
ztcp <span>-l</span> 7128
<span>lfd</span><span>=</span><span>$REPLY</span>
ztcp <span>-a</span> <span>$lfd</span>
<span>talkfd</span><span>=</span><span>$REPLY</span>

<span># client machine</span>
ztcp HOST 7128
<span>talkfd</span><span>=</span><span>$REPLY</span>
</code></pre></div></div>

<p>The <code>$REPLY</code> variable here is a file descriptor returned by the last <code>ztcp</code> command, referring to the socket/connection it just created.</p>

<p>So, <code>talkfd</code> on both machines is a file descriptor for talking to the other:</p>
<div><div><pre><code><span># host machine</span>
<span>echo</span> <span>-e</span> <span>"hello!"</span> <span>&gt;</span>&amp;<span>$talkfd</span>

<span># client machine</span>
<span>read</span> <span>-r</span> line &lt;&amp;<span>$talkfd</span><span>;</span> print <span>-r</span> - <span>$line</span>
<span>&gt;</span> hello!
</code></pre></div></div>

<p>Again, thereâ€™s a lot more you can do, especially with the ability to listen for connections.</p>

<p>Hope this was as interesting to you as it was to me!</p>

<hr>


</div></div>]]>
            </description>
            <link>https://who23.github.io/2020/12/03/sockets-in-your-shell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25287144</guid>
            <pubDate>Thu, 03 Dec 2020 09:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg: Twitter lockout, again]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25286809">thread link</a>) | @sohkamyung
<br/>
December 3, 2020 | https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong>Status: 00:27 in the morning of December 4 my account was restored again.</strong> No words or explanations on how it happened – yet.</p>



<p>This morning (December 3rd, 2020) I woke up to find myself logged out from my Twitter account on the devices where I was previously logged in. Due to “suspicious activity” on my account. I don’t know the exact time this happened. I checked my phone at around 07:30 and then it has obviously already happened. So at time time over night.</p>



<p>Trying to log back in, I get prompted saying I need to update my password first. Trying that, it wants to send a confirmation email to an email address that isn’t mine! Someone has managed to modify the email address associated with my account.</p>



<p>It has only been two weeks since someone <a href="https://daniel.haxx.se/blog/2020/11/16/i-lost-my-twitter-account/" data-type="post" data-id="15196">hijacked my account</a> the last time and abused it for scams. When I got the account back, I made very sure I both set a good, long, password and activated 2FA on my account. 2FA with auth-app, not SMS.</p>



<p>The last time I wasn’t really sure about how good my account security was. This time I know I did it by the book. And yet this is what happened.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/Screenshot_2020-12-03-Losenordsaterstallning.png" alt="" width="467" height="328"><figcaption>Excuse the Swedish version, but it wasn’t my choice. Still, it shows the option to send the email confirmation to an email address that isn’t mine and I didn’t set it there.</figcaption></figure></div>



<h2>Communication</h2>



<p>I was in touch with someone at Twitter security and provided lots of details of my systems , software, IP address etc while they researched their end about what happened. I was totally transparent and gave them all info I had that could shed some light.</p>



<p>I was contacted by a Sr. Director from Twitter (late Dec 4 my time). We have a communication established and I’ve been promised more details and information at some point next week. Stay tuned.</p>



<h2>Was I breached?</h2>



<p>Many people have proposed that the attacker must have come through my local machine to pull this off. If someone did, it has been a very polished job as there is no trace at all of that left anywhere on my machine. Also, to reset my password I would imagine the attacker would need to somehow hijack my twitter session, need the 2FA or trigger a password reset and intercept the email. I don’t receive emails on my machine so the attacker would then have had to (also?) manage to get into my email machine and removed that email – and not too many others because I receive a lot of email and I’ve kept on receiving a lot of email during this period.</p>



<p>I’m not ruling it out. I’m just thinking it seems unlikely.</p>



<p>If the attacker would’ve breached my phone and installed something nefarious on that, it would not have removed any reset emails and it seems like a pretty touch challenge to hijack a “live” session from the Twitter client or get the 2FA code from the authenticator app. Not unthinkable either, just unlikely.</p>



<h2>Most likely?</h2>



<p>As I have no insights into the other end I cannot really say which way I think is the most likely that the perpetrator used for this attack, but I will maintain that I have no traces of a local attack or breach and I know of no malicious browser add-ons or twitter apps on my devices.</p>



<h2>Details</h2>



<p>Firefox version 83.0 on Debian Linux with Tweetdeck in a tab – a long-lived session started over a week ago (ie no recent 2FA codes used), </p>



<p>Browser extensions: Cisco Webex, Facebook container, multi-account containers, HTTPS Everywhere, test pilot and ublock origin.</p>



<p>I only use one “authorized app” with Twitter and that’s Tweetdeck.</p>



<p>On the Android phone, I run an updated Android with an auto-updated Twitter client. That session also started over a week ago. I used <em>Google Authenticator</em> for 2fa.</p>



<p>While this hijack took place I was asleep at home (I don’t know the exact time of it), on my WiFi, so all my most relevant machines would’ve been seen as originating from the same “NATed” IP address. This info was also relayed to Twitter security.</p>



<h2>Restored</h2>



<p>The actual restoration happens like this (and it was the exact same the last time): I just suddenly receive an email on how to reset my password for my account.</p>



<p>The email is a standard one without any specifics for this case. Just a template press the big button and it takes you to the Twitter site where I can set a new password for my account. There is nothing in the mail that indicates a human was involved in sending it. There is no text explaining what happened. Oh, right, the mail also include a bunch of standard security advice like “use a strong password”, “don’t share your password with others” and “activate two factor” etc as if I hadn’t done all that already…</p>



<p>It would be prudent of Twitter to explain how this happened, at least roughly and without revealing sensitive details. If it was my fault somehow, or if I just made it easier because of something in my end, I would really like to know so that I can do better in the future.</p>



<h2>What was done to it?</h2>



<p>No tweets were sent. The name and profile picture remained intact. I’ve not seen any DMs sent or received from while the account was “kidnapped”. Given this, it seems possible that the attacker actually only managed to change the associated account email address.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25286809</guid>
            <pubDate>Thu, 03 Dec 2020 08:27:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In-Database Machine Learning [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25285983">thread link</a>) | @redwrasse
<br/>
December 2, 2020 | https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf | <a href="https://web.archive.org/web/*/https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25285983</guid>
            <pubDate>Thu, 03 Dec 2020 06:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the US Banning Crypto Wallets?]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25283610">thread link</a>) | @mkmccarty3
<br/>
December 2, 2020 | https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets | <a href="https://web.archive.org/web/*/https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5fc557916457125654ede725" data-item-id="5fc557916457125654ede725">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1606768551080" id="item-5fc557916457125654ede725"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_4996"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image-dimensions="834x466" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baa31d106d256baa5ca2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-98c39078cd9c52d11cda"><div><p>Just as Bitcoin was guiding cryptocurrency markets skyward with a renewed push for an all-time high valuation, prices came crashing down without warning.</p><p>Wait — <em>was there a warning</em>?</p><p><a href="https://twitter.com/brian_armstrong/status/1331744884856741888">In a tweet</a> with what some deemed suspicious timing, Coinbase CEO Brian Armstrong let loose an alarming rumor. The United States Treasury, with Secretary Mnuchin at the helm, is poised to ban the use of anonymous non-custodial crypto wallets before the year's end.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_22941"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          <a href="https://twitter.com/brian_armstrong/status/1331745659989360640">
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image-dimensions="589x256" data-image-focal-point="0.5,0.5" alt="brian armstrong tweet.PNG" data-load="false" data-image-id="5fc6bc78e2dcb1274dd6fb85" data-type="image">
          </p>
        
          </a>
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_23230"><div><p>What is a non-custodial crypto wallet, you ask? Simple — any crypto wallet that is self-hosted (i.e., you own and hold the private keys) fits the description.</p><p>So, if you currently use a cold storage wallet like a Ledger Nano S or a software wallet such as MetaMask, you may soon find yourself running afoul of new regulations.</p><p>While this all seems pretty bad for Bitcoin when you consider the sheer amount of people using non-custodial crypto wallet storage, there are a couple silver linings worth considering.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_25472"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image-dimensions="1306x735" data-image-focal-point="0.5,0.5" alt="wallet guide.PNG"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>In this article, we will discuss how experts choose their cryptocurrency wallets and what types of wallets exist. </p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_25761"><div><p>At the core of the rumored regulations is what appears to be a bank-centric push to force all current and future cryptocurrency users toward intermediary platforms.</p><p>What this means for you is, if the rumors are true, you will need to share KYC information (identification data) with exchanges you use before withdrawing or depositing from your self-hosted wallet. This push will make it so your currently anonymous crypto wallet will be inextricably linked to your real-world identity.</p><p>OK — so there go crypto wallets, right? You might as well delete your Exodus wallet, shut down the MetaMask, and turn everything over to the bankers lying in wait.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_7734"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baf2ad3e6411922cd0a2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_8023"><div><p><strong>Wrong.</strong> Try as they might, there is simply <strong>no way</strong> to enforce data collection on the use of non-custodial wallets. Such regulations appear more symbolic than anything else — they might scare newbies looking to enter the market discreetly, but anyone who understands how cryptocurrency storage works, especially when using hardware wallets, knows there are options outside of centralized exchanges.</p><p>Consider the scenario where the US Treasury makes good on their threat to enforce data collection on crypto wallets. Now, Coinbase requires you to KYC your wallet before allowing you to withdraw freshly purchased BTC. What are your options?</p><p>For one thing, you can use a decentralized exchange to trade crypto. Uniswap has already surpassed Coinbase in terms of trading volume — if crypto wallets regulations come into play, expect Uniswap to get much more action.</p><p>Moreover, with the push toward DeFi in the cryptocurrency industry, along with endless options for swapping liquidity, the likelihood that centralized exchanges stay relevant gets slimmer every day.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_15299"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6bbd593ad1a48120388ca" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_15588"><div><p>Satoshi Nakamoto never envisioned cryptocurrency as a way for governments to collect private data. That's why blockchains are built to enable censorship-free financial access.</p><p>As CoinDesk noted <a href="https://www.coindesk.com/crypto-wallet-regulations-industry-pros">in a recent analysis of the situation</a>, there exists a revealing difference in the language used to refer to crypto wallets by regulators and crypto investors.</p><p>Regulators call crypto wallets <em>unhosted wallets,</em> whereas investors refer to them as <em>self-hosted wallets</em>. The difference here is all about privacy — crypto users believe in financial independence, freedom from oversight, and digital asset autonomy.</p><p>On the other hand, an unhosted wallet points to the view that such wallets lack hosting — a situation that should be remedied by regulation and the cooperation of centralized institutions.</p><p>This seemingly small difference in language does indeed point to a large divide in exactly how each side views the purpose of storing crypto assets.</p><p>As Armstrong noted in his original Twitter thread, the crypto industry has been preparing for this eventuality for at least a few months. In fact, they've known long enough to form a lobby, and have responded to the rumors by sending the US Treasury a plea to leave crypto alone.</p><p>The regulation is expected to come into effect before the year's end, mostly owing to the US election results and the impending changing of the guard. As such, the rush is on for Mnuchin to push through regulations before time is up.</p><p>Does data-collection on self-hosted crypto wallets amount to the US government declaring a ban on cryptocurrency wallets we know them?</p><p><strong>Not really</strong>.</p><p>Moreover, can the government enforce these regulations and push people onto the centralized platforms decentralized blockchains were built to avoid?</p><p>The answer there is clearer: <strong>certainly not.</strong></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_28135"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image-dimensions="1442x669" data-image-focal-point="0.5,0.5" alt="beginners guide to bitcoin cover.png" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>Each of these strategies is simple to implement, even for novice investors, but that doesn’t mean these strategies aren’t used by professions.</p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div>

    

    

    <section id="comments-5fc557916457125654ede725">
      
  


    </section>

  </article>





  <nav>

    
      <a href="https://blog.shrimpy.io/blog/coinbase-vs-uniswap">
        <svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="21.5,1.3 2.6,23.4 21.5,45.7 "></polyline>
          </g>
        </svg><!--
        --><div>
          <p>Previous</p>
          <h4>Coinbase vs. Uniswap — Which Exchange Is Better?</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-12-02">December 2, 2020</time></p><!--

            Tags

            --><p><span>coinbase, uniswap, review, general, notlatest</span></p><!--

            Comments

            --></div>
        </div>
      </a>
    

    
      <a href="https://blog.shrimpy.io/blog/machine-learning-for-crypto-portfolio-management-case-study-week-30">
        <div>
          <p>Next</p>
          <h4>Machine Learning for Crypto Portfolio Management Case Study: Week 30</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-11-30">November 30, 2020</time></p><!--

            Tags

            --><p><span>data, notlatest, topsection</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div></div>]]>
            </description>
            <link>https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25283610</guid>
            <pubDate>Thu, 03 Dec 2020 00:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spaced Repetition in the Classroom]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25283013">thread link</a>) | @jlmao
<br/>
December 2, 2020 | https://www.podsie.org/blog/spaced-practice-in-the-classroom/ | <a href="https://web.archive.org/web/*/https://www.podsie.org/blog/spaced-practice-in-the-classroom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When my students bombed their first semester exam, it shocked me. It was my second year of teaching eighth grade math, and unlike the previous year, my students had actually done well on the exit tickets and tests up to that point. However, my students seemed to have forgotten everything.</p><p>The next semester, I made a concerted effort to carve out time for review, but it was tedious, and I never knew which specific topics to review, and how often to review each topic.</p><p>Years later when I was no longer a teacher, I found out that there was actually a science behind the best way to review, and that there was also <a href="https://www.gwern.net/Spaced-repetition" target="_blank" rel="noopener noreferrer">a large body of research to back it up</a>.</p><h5>Ebbinghaus and the Forgetting Curve</h5><p>This body of research goes as far back as the 1880s, when a German psychologist named Hermann Ebbinghaus mapped out memory and how we forget over time.</p><p><img src="https://www.researchgate.net/profile/Bo_Ae_Chun/publication/324816198/figure/fig1/AS:620205050982405@1524879815703/Ebbinghaus-forgetting-curve-and-review-cycle.png" alt="Forgetting Curve"></p><p>In his model of memory, Ebbignhaus stated that when content is first learned, without review, memory of that content deteriorates quickly. However, with each subsequent review and retrieval of that information, the memory becomes more durable, and over time, less and less review is required to keep retention fresh.</p><p>When I first learned about this, I felt an "Aha!" moment as Ebbinghaus broke down exactly why my students struggled when I was teaching.</p><p>For me, because planning out new lessons was already such a tough process, I never had enough time to adequately review throughout the school year. Instead, every year in March, I dedicated an entire month to review all of the content before the state exam. In fact, several lower-performing districts encouraged students and teachers to have â€œreview weeksâ€� to cram review before state assessments. We would power through countless hours of material that students had already "learned", but it never stuck as well as I would have liked.</p><p>Ebbinghaus proposed something that I had always intuitively known, but failed to put into practice in my own classroom: spreading out review over time is much more effective than cramming it all into one session.</p><h5>More Research</h5><p>Since Ebbinghuas, several researchers have fleshed out this idea of the forgetting curve and spaced review.</p><p>To start, <a href="https://pcl.sitehost.iu.edu/rgoldsto/courses/dunloskyimprovinglearning.pdf" target="_blank" rel="noopener noreferrer">John Dunlosky, a professor of psychological sciences at Kent State University, and others broke down 10 different learning techniques</a>, including common practices like re-reading and highlighting, and found that spaced review was one of the most effective ways to learn and retain knowledge and skills.</p><p>Meanwhile, <a href="https://www.dartmouth.edu/~cogedlab/pubs/Kang(2016,PIBBS).pdf" target="_blank" rel="noopener noreferrer">Sean Kang, a cognitive psychologist at the University of Melbourne, highlighted spaced review as a highly effective learning technique</a> that does not require more time and drastic changes to the classroom.</p><p>Specifically, he states:</p><blockquote><p>Incorporating spaced practice into education can be a cost-effective approachâ€” learning becomes more durable in the same amount of time (relative to massed practice), and this can lead to future savings because less time needs to be spent on relearning content that has been forgotten, leaving more time for other productive learning activities (e.g., higher order analysis, application of knowledge). <strong>In short, spaced practice enhances the efficacy and efficiency of learning, and it holds great promise as an educational tool.</strong></p></blockquote><p>In a different paper, <a href="https://scottbarrykaufman.com/wp-content/uploads/2014/01/Lindsey-et-al.-2014.pdf" target="_blank" rel="noopener noreferrer">Robert Lindsey, another research scientist and now the founder of Imagen Technologies, and others also assessed the efficacy of a computer program that personalized review for each student over time</a>. In this study, personalized spaced review improved retention by 16.5%!</p><p>The more research I read, the more I was perplexed â€”perplexed as to why I hadn't learned about this research-backed learning technique while I was teaching. I had sat through countless hours of professional development and undergone a long certification process, but I had never once heard about how to maximize learning in my classroom through spaced review.</p><p>Clearly, there was a gap between research and practical application, and I wanted to see if there was a way to fill that gap.</p><h5>Spacing in the Classroom</h5><p>So how would spaced review work in the classroom?</p><p>After I learned about spaced review, I shared it with my best friend, Chris, who is currently a science teacher in Texas. He also dug into the research and was excited to try it out in his classroom the next school year. He did a deep dive into all of the learning tools available to help him facilitate spaced review in the classroom. Most tools he came across seemed better suited for individual learners, and were not well-suited for the classroom.</p><p>Long story short, Chris and I decided to build out Podsie, a platform that fully automates spaced review in a personalized way for each student. With Podsie, Chris creates an exit ticket of around 5-8 questions that assesses the content that students learned that day. When students complete a question, the question goes into that student's personal deck.</p><p>Each student's personal deck is powered by a spacing algorithm that determines when the student should review a question again. Then, Chris gives his students 10 minutes in the beginning of class to complete every question that is due on their personal decks, ensuring that each student reviews exactly what they should be reviewing on that day.</p><p>With this approach, Chris no longer has to do the traditional cram session before state assessments. This year, even with distance learning, the spaced review has been so effective for him that he's decided to completely cut out that month of review that he also traditionally did. Like the quote from Sean Kang above predicted, spacing out review saved Chris a significant amount of time because "less time needs to be spent on relearning content that has been forgotten."</p><h5>Last Thoughts</h5><p>In Sean Kang's paper on spacing, he reflects:</p><blockquote><p>Despite over a century of research findings demonstrating the spacing effect, however, it does not have widespread application in the classroom. <strong>The spacing effect is â€œa case study in the failure to apply the results of psychological researchâ€� (Dempster, 1988, p. 627).</strong></p></blockquote><p>Podsie hopes to be that bridge between psychological research and the classroom.</p><p>We know this year has been extraordinarily challenging for everyone in the education system, and we hope that by providing an effective and efficient tool, each student and teacher's life can be made a little easier.</p><p><strong><em>If you're interested in using Podsie in your classroom to help with your students' retention of content, you can <a href="https://www.podsie.org/#sign-up">sign up here!</a></em></strong></p></div></div></div>]]>
            </description>
            <link>https://www.podsie.org/blog/spaced-practice-in-the-classroom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25283013</guid>
            <pubDate>Wed, 02 Dec 2020 23:08:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GitHub Issues as a Hugo Front End with GitHub Actions and Netlify]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25281958">thread link</a>) | @todsacerdoti
<br/>
December 2, 2020 | https://shazow.net/posts/github-issues-as-a-hugo-frontend/ | <a href="https://web.archive.org/web/*/https://shazow.net/posts/github-issues-as-a-hugo-frontend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I got into the habit of dumping quick blog post ideas into issues on my blog’s repo. It’s a convenient place to iterate on them and share with friends for feedback before actually publishing on my blog post.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100761218-a6cb2280-33c0-11eb-92df-1b52d91cc16e.png" alt="image"></p><p>The drafts keep accumulating, how do I trick myself into publishing more? Perhaps by reducing the effort required for the next step? Let’s do it!</p><h2 id="architecture">Architecture</h2><p>My blog is statically generated using <a href="https://github.com/gohugoio/hugo">Hugo</a>, the <a href="https://github.com/shazow/shazow.net">code is hosted on Github</a>, then when a pull request comes in it is built, previewed, and published on merge by <a href="https://netlify.com/">Netlify</a>.</p><p>The blog post drafts are posted as Github issues, so there is a clear gap: How do we convert issues into pull requests for Netlify? Enter Github Actions!</p><h2 id="github-action-issue-to-pull-request">Github Action: Issue to Pull Request</h2><p>My <a href="https://github.com/shazow/shazow.net/blob/master/.github/workflows/publish.yml">full workflow lives here</a> if we want to jump ahead, but let’s break down the broad strokes.</p><p>I decided to trigger the publishing process once an issue is labelled with ‘publish’, so let’s start with that:</p><div><pre><code data-lang="yaml"><span>name</span><span>:</span><span> </span>Publish<span> </span>post<span> </span>from<span> </span>issue<span>
</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>issues</span><span>:</span><span>
</span><span>    </span><span>types</span><span>:</span><span> </span><span>[</span><span>'labeled'</span><span>]</span><span>
</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>build</span><span>:</span><span>
</span><span>    </span><span>if</span><span>:</span><span> </span>${{<span> </span>github.event.label.name<span> </span>==<span> </span><span>'publish'</span><span> </span>}}<span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span>ubuntu-latest<span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>      </span>...<span>
</span></code></pre></div><p>Next up we want to specify the steps, first thing is to check out the repository into the action’s environment:</p><p>Once the source code is available, we want to generate the blog post from the issue metadata. Here is a very basic version of this, though I ended up doing more tweaking in the end:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Generate<span> </span>Post<span>
</span><span>        </span><span>env</span><span>:</span><span>
</span><span>          </span><span>POST_TITLE</span><span>:</span><span> </span>${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>          </span><span>POST_BODY</span><span>:</span><span> </span>${{<span> </span>github.event.issue.body<span> </span>}}<span>
</span><span>        </span><span>run</span><span>:</span><span> </span><span>|
</span><span>          cat &gt; "content/posts/${POST_TITLE}.md" &lt;&lt; EOF</span><span>
</span><span>          </span>${POST_BODY}<span>
</span><span>          </span>EOF<span>
</span></code></pre></div><p>This shoves the body of the issue, which is already markdown, into a markdown file named based on the title of the issue. This is a good place to add frontmatter, or slugify the title, or whatever else your blog setup requires.</p><p>Running the payload through environment variables helps with not needing to escape various characters like `.</p><p>And finally, we make the pull request using Peter Evan’s create-pull-request action which makes this super easy:</p><p>This is the minimum of what we need, but we can specify all kinds of additional options here: like auto-deleting the branch, setting a custom title, body, and whatever else. Here’s an example of what I’m doing:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Create<span> </span>Pull<span> </span>Request<span>
</span><span>        </span><span>uses</span><span>:</span><span> </span>peter-evans/<a href="https://shazow.net/cdn-cgi/l/email-protection" data-cfemail="80e3f2e5e1f4e5adf0f5ececadf2e5f1f5e5f3f4c0f6b3">[email&nbsp;protected]</a><span>
</span><span>        </span><span>with</span><span>:</span><span>
</span><span>          </span><span>delete-branch</span><span>:</span><span> </span><span>true</span><span>
</span><span>          </span><span>title</span><span>:</span><span> </span><span>"publish: ${{ github.event.issue.title}}"</span><span>
</span><span>          </span><span>body</span><span>:</span><span> </span><span>|
</span><span>            Automagically sprouted for publishing.</span><span>
</span><span>            </span><span>Merging will publish to</span><span>:</span><span> </span>https<span>:</span>//shazow.net/posts/${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>            </span>Closes<span> </span><span>#${{ github.event.issue.number }}</span><span>
</span><span>          </span><span>reviewers</span><span>:</span><span> </span>${{<span> </span>github.repository_owner<span> </span>}}<span>
</span><span>          </span><span>commit-message</span><span>:</span><span> </span><span>"post: ${{ github.event.issue.title }}"</span><span>
</span></code></pre></div><h2 id="result">Result</h2><p>When my blog post draft is ready, I add the tag and the Github action takes it away, creating a pull request:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763017-a764b880-33c2-11eb-860f-5bab932ac558.png" alt="image"></p><p>The pull request automatically pings me as a reviewer, and includes a “Closes #X” line which will close the draft issue once the PR is merged. Very convenient!</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763219-ded36500-33c2-11eb-8387-ff28b6561875.png" alt="image"></p><p>Once the pull request is ready, Netlify takes it away, builds everything and generates a handy preview:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763300-fa3e7000-33c2-11eb-9172-206f58556ddd.png" alt="image"></p><p>I can make sure everything looks right, and even apply edits directly inside the pull request. This is another great step to send a long blog post for feedback, using all of the wonderful Pull Request Review features!</p><p>When all is said and done, merging the pull request triggers Netlify to publish my changes to my domain, and merging closes the original issue, and I’m done!</p><h2 id="bonus">Bonus</h2><p>Drag n’ drop images work in Github Issues, so it’s super easy to write a quick post with a bunch of screenshots or what have you.</p><p>It’s important to me that I’m not too tightly coupled to third-party services, so the pull request and code merge flow makes sure that all of the published state continues to live inside of my Git repository.</p><p>I can still make blog posts the way I used to: Pull the latest repo, write some markdown, and push to publish.</p><p>I added a little <a href="https://github.com/shazow/shazow.net/blob/master/frontmatterify">frontmatterify script</a> to process the incoming markdown and convert the remote Github Issue uploaded images into local images that are included in the pull request. The script also generates frontmatter that I use for Hugo. It’s a bit clunky but works for now.</p><p>Alright, let’s do this.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100764184-11ca2880-33c4-11eb-8c84-e992765ace49.png" alt="image"></p></div></div>]]>
            </description>
            <link>https://shazow.net/posts/github-issues-as-a-hugo-frontend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25281958</guid>
            <pubDate>Wed, 02 Dec 2020 21:35:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Topology to Classify Labelled Graphs]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25279820">thread link</a>) | @Topolomancer
<br/>
December 2, 2020 | https://bastian.rieck.me/blog/posts/2020/topology_graphs/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/topology_graphs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I have written at lengths about certain aspects of topological data
analysis, but I have neglected to discuss one of its main applications,
i.e. the classification of graphs. In this post, I will therefore take
you on a quick tour of our ICML paper <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">A Persistent Weisfeiler–Lehman Procedure for Graph Classification</a>.</p>
<p>Let us assume that we are given a graph with node label information. The
graph could, for instance, be a molecule, whose nodes are atoms such as
carbon or oxygen, and whose edges indicate chemical bonds. The goal
could now be to classify a given molecule into a set of classes, such as
‘toxic’, ‘carcinogen’, etc. How can we achieve such a classification?
One of the simplest techniques dates back to the 1960s and involves
calculating an <em>iterative fingerprint</em> of the graph! This procedure was
suggested by <a href="https://en.wikipedia.org/wiki/Boris_Weisfeiler">Boris Weisfeiler</a>
and Andrei Lehman&nbsp;(sometimes also transliterated as ‘Leman’) in
their seminal article <a href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf">The reduction of a graph to canonical form and the
algebra which appears therein</a>.</p>
<p>At its core, the algorithm is an iteration scheme that works like this:</p>
<ol>
<li>For a node $v$, collect its label and the labels of adjacent nodes in
a multiset.</li>
<li>Assign this multiset a new label by hashing it—with the proviso
that the hashing function is <a href="https://en.wikipedia.org/wiki/Perfect_hash_function"><em>perfect</em></a>, i.e.
it maps distinct labels to distinct values with no collisions.</li>
<li>Replace all node labels by their multiset hashes.</li>
</ol>
<p>Intuitively, each step of the algorithm accumulates more information
from nodes that are further removed from the current node. The hashed
multiset label is thus an expression of the neighbourhood around
a node—and after a sufficiently large number of iterations, the
hashed labels will not change any more.</p>
<p>For example, suppose you are dealing with this simple graph&nbsp;(to
prevent confusion of node labels and node IDs, I used <em>colours</em> to
indicate node labels in this example):</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_graph.svg" alt="Weisfeiler--Lehman example graph" height="128"> 
</figure>

</div>
<p>Tabulating the neighbourhood of each node then results in the following
table:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_1.svg" alt="Weisfeiler--Lehman multiset example (before hashing)" height="128"> 
</figure>

</div>
<p>Now for the hashing step. In this example, <em>perfect hashing</em> means
choosing a set of colours that is distinct for every distinct
combination of neighbourhood labels and vertex labels:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_2.svg" alt="Weisfeiler--Lehman multiset example (after hashing)" height="128"> 
</figure>

</div>
<p>Notice how nodes A, B, and G are hashed to the same colour—because
in the first iteration of the algorithm, they cannot be distinguished.
How can we use the information about the hashed labels in a subsequent
comparison task? The answer is lies in <em>counting</em> them in a histogram
vector, which is indexed by the unique labels—this is where our
requirement of the perfect hashing function is helpful. For the
previously-shown graph, it looks like this:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_feature_vector.svg" alt="Weisfeiler--Lehman subtree feature vector" height="128"> 
</figure>

</div>
<p>The <em>fingerprint</em> of this graph, according to the first iteration of the
Weisfeiler–Lehman scheme is therefore $(3, 1, 2, 1)$. Further iterations
just make the feature vector longer&nbsp;(technically, the initial
labels already give rise to a feature vector of counts). This procedure
can now be repeated for higher-order iterations and the resulting
feature vectors can be compared across graphs by evaluating, for
example, their dot product. More formalisations of this idea have
resulted in the very successful <a href="https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf">Weisfeiler–Lehman Graph
Kernels</a>
publication. This method arguably constitutes the basis for graph neural
networks—in fact, these networks can be seen as a parametrised
version of the Weisfeiler–Lehman iteration scheme. But I digress—if
you are interested in these aspects, please read <a href="https://towardsdatascience.com/beyond-weisfeiler-lehman-approximate-isomorphisms-and-metric-embeddings-f7b816b75751">Michael Bronstein’s
article on going beyond graph
isomorphism</a>
for more details.</p>
<p>Now, despite its great practical utility, this feature vector is lacking
some <em>structural</em> information about the graph. It does not know whether
a certain label contributes much to the topological structure of
a graph—such as a ring of carbon atoms would in molecule—or not. To
this end, we introduced a notion of topological relevance for each node
label! Briefly put, we first developed a distance metric that would
permit us turn any <em>labelled</em> graph into a <em>weighted</em> graph. We then
calculate a persistence barcode, a topological descriptor of the graph.
This descriptor assesses the relevance of a topological feature created
by some node label. We use the topological relevance of each feature as
an additional <em>weight</em> for the previously-shown feature vector. In
essence, labels that contribute a large amount of topological structure
in a graph are assigned a higher weight than labels that only contribute
a meagre amount!</p>
<p>Here is a graphical depiction of our process:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/p_wl_pipeline.svg" alt="Persistent Weisfeiler--Lehman pipeline" height="128"> 
</figure>

</div>
<p>If you want to brush up your understanding of the barcode calculation,
head on over to <a href="https://christian.bock.ml/">Christian’s website</a>; he has
an <a href="https://christian.bock.ml/posts/persistent_homology">excellent article on persistent
homology</a>.</p>
<p>The neat thing about our approach is that we can easily integrate
information about <em>cycles</em> into the feature vector—this is
a functionality that the original Weisfeiler–Lehman Graph Kernels
Framework lacks. Moreover, these cycles turn out to be crucial in
improving classification performance—we get an increase of more than
3% in classification accuracy by considering them in some data sets!</p>
<p>If this has whet your appetite, I invite you to <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">read our
paper</a> or <a href="https://github.com/BorgwardtLab/P-WL">take
a look at the code</a>. If you want
to learn more about graph classification using graph kernels, take
a look at our <a href="https://arxiv.org/abs/2011.03854">recent survey on graph kernels</a>,
which will hopefully be officially announced in time for NeurIPS 2020.
In the best tradition of Fermat, I would very much like to cover the
content of the survey here, but this blog is too small to contain all of
it—maybe for a subsequent post?</p>
<p>Until next time!</p>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/topology_graphs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279820</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A founder’s guide to understanding users]]>
            </title>
            <description>
<![CDATA[
Score 184 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25279814">thread link</a>) | @mgadams3
<br/>
December 2, 2020 | https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44 | <a href="https://web.archive.org/web/*/https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="9bcd">Four steps to ensure your customer discovery &amp; development efforts result in great products that solve real customer problems</h2><div><div><div><p><a href="https://medium.com/@mgadams?source=post_page-----c68feaecac44--------------------------------" rel="noopener"><img alt="Mike Adams" src="https://miro.medium.com/fit/c/96/96/1*Myw6S5WzM6_5PfbkyNAwUQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="4ad5">When building any technology product, one of the most common pieces of advice is “talk to your users.”</p><p id="cec4">But the default way most of us talk to customers and prospects is unscientific and fraught with confirmation bias, putting us in danger of being lied to and wasting months building something nobody wants.</p><p id="ee5b">I learned this truth the hard way over the past decade founding multiple companies — but it wasn’t until I was working on my <a href="http://grain.co/utm_source=medium" rel="noopener">third startup</a> that I came to understand a better way to actually understand users.</p><p id="a218">When I first started building start-ups a decade ago, I never anticipated how applicable Yoda’s wisdom about the value of failure would be as a founder.</p><p id="3a5b">When I first started out, we had an idea, turned it into a UI, and hired developers to make it real. After nearly a year and tens of thousands of dollars — we launched it.</p><p id="d4d8">Ghost town. Crickets. Nobody wanted what we’d built.</p><p id="998b">I determined that the missing piece of the puzzle was my <a rel="noopener" href="https://mgadams.com/want-to-learn-to-code-start-with-excel-4f5902fb1b2f?source=collection_home---6------0-----------------------">lack of technical ability</a>, so I enrolled as one of the first dozen students at a now-famous<a href="https://www.hackreactor.com/" rel="noopener"> coding bootcamp</a> and actually got a job as a software engineer at a <a href="http://opentable.com/" rel="noopener">real company</a>.</p><p id="3b53">So surely when I started my <a href="https://twitter.com/missionu?lang=en" rel="noopener">next start-up</a>, this time things would be different. This time we talked to dozens of potential users and industry experts before we built anything. This time it worked. Sort of.</p><p id="d494">Our mission was compelling as we launched to <a href="https://www.inc.com/magazine/201806/leigh-buchanan/missionu-career-training-school.html" rel="noopener">fanfare</a> and raised <a href="https://techcrunch.com/2017/09/14/missionu-raises-8-5m-to-build-an-alternative-one-year-education-program/" rel="noopener">$11.5M</a> within 10 months of founding the company. However, after just two years we were acqui-hired, our investors got their money back, and the product was immediately <a href="https://www.insidehighered.com/digital-learning/article/2018/05/23/missionu-self-styled-alternative-higher-education-closes-after" rel="noopener">shut down</a>.</p><p id="6863">I was gutted, still am TBH.</p><p id="0f28">But with hindsight, I could look back to my original research notes and see I had ignored several fatal warnings. I had listened to what they said — exactly as they said it, but I did not realize until much later that I failed to actually understand what they meant.</p><p id="9305">So if I wanted to avoid failing a third time, I needed to figure out what I was missing about how to <em>really</em> understand users.</p><p id="9c98">Marty Cagan, Silicon Valley Product Group founder and former PM at early eBay, says there are “<a href="https://svpg.com/the-inconvenient-truth-about-product/" rel="noopener">two inconvenient truths about product</a>.”</p><p id="b881">Truth #1: <strong>At least half of our ideas are just not going to work</strong>:</p><p id="ed0c">Truth #2: <strong>Even the good ideas take several iterations to become viable.</strong></p><p id="3d8c">My experience has also been that there’s simply no escaping these inconvenient truths — I only wish I would have learned about them sooner.</p><p id="30d3">It doesn’t matter how smart or experienced we may be, statistically speaking, most of our ideas are simply not going to work. And the successful ones take time and hard work to turn into a real product that gets widely adopted by a market.</p><p id="de93">Your ideas are not nearly as important as your process — and the best process starts with understanding what the customers you wish to serve <em>already</em> do to solve their problems today and even more importantly, understanding why.</p><p id="9883">Yet, even as a 3rd time founder, I fell into the trap of ignoring the two inconvenient truths <em>again.</em></p><p id="87c7">Confirmation bias is a hell of a drug.</p><p id="f8b7">When we started <a href="http://grain.co/?utm_source=medium" rel="noopener">grain.co</a> two years ago, we began with a specific product solution in mind, built prototypes, and got feedback from users. They told us they’d love to use it but after months turning prototypes into a product, few actually did.</p><p id="a400">So we started over from scratch, but this time with a different approach:</p><ol><li id="2be7">Focus on a very specific user type with a very specific job to be done.</li><li id="bb56">Interview dozens of them only to understand how and why they solve their problem today.</li></ol><p id="0128">Our goal was not to validate whether the merit of a specific solution but to observe existing customer behaviors and desires as a means of generating new ideas for potential product solutions.</p><p id="3dec">This is what is known as <strong>generative research</strong>.</p><p id="4699">As you listen to your target market describe what they do today to solve their problems, you can better understand potential customers’ existing incentives, behaviors, and desires in anticipation for how they’d react to a new solution.</p><p id="331b"><a href="https://twitter.com/robfitz" rel="noopener">Rob Fitzpatrick</a> has famously coined this generative research phase “ <a href="http://momtestbook.com/" rel="noopener">The Mom Test</a>,” which is a set of simple rules to ask good questions so that even your Mom can’t lie to you in her answers to protect your ego.</p><p id="7e65">Generative research questions are focused on understanding existing behavior. For example, here are some questions from an interview guide we used at <a href="http://grain.co/" rel="noopener">Grain</a> to understand how our prospective users already document and share information from live meetings:</p><ul><li id="fcb3">What’s your current process to document and share information from a video meeting?</li><li id="fa1f">How important is it that the information you document and share is accurate?</li><li id="6568">What measures do you currently take to ensure accuracy of captured information?</li><li id="33f9">What can happen if your documentation is inaccurate?</li><li id="32f3">How often are you in conversations where you don’t need to document or share anything?</li><li id="cda6">Which types of conversations are the most important for you to document and share?</li></ul><p id="9e72">Be sure to avoid hypothetical questions about what people <em>might</em> do. Don’t try to validate your future product with questions that begin with “would you use this” or “what do you think about the possibility of” — that’s what we call leading the witness, and it will inevitably bias your data and waste your time building the wrong thing. At this stage, you simply need to observe what users are <em>already doing,</em> not what they might theoretically do.</p><figure><div></div></figure><p id="69d3">I recently connected with <a href="https://twitter.com/robfitz" rel="noopener">Rob</a> where he shared an updated model of 3 ways where users will lie to you if you’re not careful:</p><ol><li id="afa0">Asking the wrong questions</li><li id="6697">Remembering the wrong thing</li><li id="6a57">Making the wrong decision “justified” by what you think you heard</li></ol><p id="ecb1">Rob and most other researchers suggest asking for permission from their interviewees to record these interviews and take time-annotated notes that will help them to accurately remember and codify behavioral patterns that could eventually help to define <a href="https://www.uxmatters.com/mt/archives/2019/02/the-pitfalls-of-personas-and-advantages-of-jobs-to-be-done.php" rel="noopener">“jobs to be done”</a> that product, engineering, and design teams can build for with confidence.</p><p id="556d">After gaining insights about the problems your target market faces in generative research, you may be confident enough to test out a specific product solution to see if these users would actually value it.</p><p id="4717">This is the concept behind <strong>evaluative testing</strong>.</p><p id="f326">At this early stage, you want to put an <em>ultra-lightweight implementation </em>of a product solution in front of your target users to see how they react. While the closer to reality your prototype is the better, it doesn’t need to be a fully functional product yet: designs on paper, prototypes, mock-ups-anything like that will work.</p><p id="b1b0">Your goal at this stage is to get clear qualitative signals that users:</p><ol><li id="9f21">understand the proposed product solution</li><li id="fcda">express unmistakable excitement about the prospect of the product as a superior solution to the status quo</li></ol><p id="2033">Unfortunately, all too many product teams speed through this testing or skip it all together and simply march ahead to engineering and delivery. Depending on the complexity of the market and the problem you’re trying to solve, this stage could take months or, in some cases, years.</p><p id="d10d">That might sound discouraging and time-consuming, but I know this for certain: the success of your product will be <strong><em>directly proportiona</em>l</strong> to the quality of work done in this initial customer discovery phase. It’s worth doing it, and it’s certainly worth doing it well.</p><p id="0fd4">Even if your team creates something that people want, if customers can’t figure out how to use it, the product is dead in the water. This is why product teams conduct usability testing throughout the build process.</p><p id="ee09">The traditional approach to usability interviews is to set up a test environment, where we watch as a user navigates the product. An interviewer encourages a user to explain what they see, think, and observe. The interviewer also offers prompts for what the user might consider next if they get stuck using the product. Usability issues in the product become self-evident in most of these cases.</p><p id="8825">My friend <a href="https://medium.com/u/b2d49a9606e3?source=post_page-----c68feaecac44--------------------------------" target="_blank" rel="noopener">Behzod Sirjani</a>, has created a framework for conducting usability testing interviews where he recommends asking the participant about their:</p><ol><li id="084d">Expectation (about what will happen)</li><li id="4d83">Reaction (to what happens)</li><li id="64e1">Reflection (on the difference between 1 and 2)</li></ol><figure><div></div></figure><p id="ec98">A less scientific and more agile approach to identifying lower-hanging usability issues is concierge onboarding. In concierge onboarding, someone from your team guides — via video call is best — new users through setting up the product and answers the questions in real-time. Concierge onboarding helps the team member understand the steps users are asked to take and the ways those steps directly lead to value.</p><figure><div></div></figure><p id="2293">In a recent Zoom call with Behzod, he told me how at Slack it was essential to turn usability interviews into video highlights of moments of user struggle to help his team form a shared understanding of the problem and gain alignment around solutions that will actually work.</p><p id="5379">The best product teams never stop this work of generative and evaluative testing for new features. Even as their initial research and testing turns into a real product, they know the importance of creating a customer discovery and product delivery engine that never stops learning and growing.</p><p id="b7d9">It’s much more common for product teams to continually learn and discover from their existing users than it is for them to gather insights from completely unbiased non-users. But a balance between the two groups — existing and new — is ideal. New users can give you a better understanding of your initial product experience, and existing “power users” can offer you insights that come from living with a product for weeks or months.</p><p id="1af9">Great product teams develop long-standing relationships of trust with their most active users. You’ll often see the people on these teams setting up recurring feedback sessions to gain insight and listen to users’ concerns and ideas. The point of these interviews is to find out what’s delightful and what’s frustrating, what’s there and working well, and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</a></em></p>]]>
            </description>
            <link>https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279814</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop slacking, start rocking: Why we built Rock for a distributed workforce]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25279417">thread link</a>) | @kenzofong
<br/>
December 2, 2020 | http://rock.so/stopslacking | <a href="https://web.archive.org/web/*/http://rock.so/stopslacking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <!-- split row one -->
      <div>
        <div>

          <!-- Row one -->
          <div>
            
            <div>
              <p>
                  <br><b>tl;dr</b> <i>Remote work is here to stay and the productivity tools that currently exist are not built for a more distributed workforce. With Rock, we're bringing together both synchronous and asynchronous ways of collaborating, so working with a distributed team becomes easier. <span><a href="#"><i></i> See how Rock works.</a></span></i>
                </p>
            </div>
            
          </div>

          <!-- Row one -->
          <div>
            
            <div>
              <div>
                <p>
                  <br>
                  <b>We are now in more meetings and work longer hours than ever before.</b> With <a href="https://time.com/collection/great-reset/5900753/rethinking-work-covid-19/">62% of people working from home</a> because of the pandemic -- the number of meetings has gone up 12.9%, the volume of emails has increased and workdays have grown 48 ½ minutes longer.
                </p>
                <p>
                  All of these distractions take up 40% of someone’s productive time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row two -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-1.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row three -->
          <div>
            
            <div>
              <div>
                <p>
                  There are different reasons why this has happened, but one of the main reasons is that the way we work hasn't really changed. When companies started shifting their workforce to a remote model, they took the tools they were already using (e.g. Slack, Zoom) and sent their employees home.
                </p>
                <p>
                  These tools are now being used in the same way they were used in the office, where most of the interaction happened in real-time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row four -->
          <div>
            
            <div>
              <div>
                <h3>We're moving towards a more distributed way of working.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row five -->
          <div>
            
            <div>
              <div>
                <p>
                  A quick chat is now another Zoom meeting in a long succession of meetings and a tap on the shoulder is yet another Slack message that pulls you away from what you were doing.
                  This firehose of messages and meetings is not sustainable as it leads to <a href="https://www.cnbc.com/2020/07/28/remote-work-burnout-is-growing-as-coronavirus-pandemic-stretches-on.html">anxiety</a>, <a href="https://www.fastcompany.com/90554935/the-red-flag-signs-you-may-be-burning-out-while-working-from-home">burnout</a> and <a href="https://www.forbes.com/sites/bryanrobinson/2020/09/06/how-remote-workers-can-recognize-burnout-and-6-actions-to-take/?sh=64da6cf14326">pressure</a> to always be connected.
                </p>
                <p>
                  With a <a href="https://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/covid-19-driving-lasting-change-for-business-practices-it-spending-8211-451-survey-60716654">majority of companies</a> stating that remote work is here to stay, <a href="https://socketsite.com/archives/2020/10/nearly-12-million-square-feet-of-vacant-office-space-in-s-f.html">office footprints</a> being reduced dramatically and tech companies like Twitter telling their staff that they can <a href="https://www.washingtonpost.com/technology/2020/10/01/twitter-work-from-home/?arc404=true">work from home forever</a> some of these changes will become the new normal. Most people agree that whatever happens, companies will be way more distributed than they were before the pandemic.
                  One thing is for sure -- the communication &amp; collaboration tools that exist today just don't cut it.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row six -->
          <div>
            
            <div>
              <div>
                <h3>We need tools for a distributed workforce.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row seven -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-2.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eight -->
          <div>
            
            <div>
              <div>
                <p>
                  <b>This is where <a href="http://rock.so/">Rock</a> comes in</b>. <a href="https://www.linkedin.com/in/liming/">Ming</a> and I started building Rock about a year ago to make it easier to shift towards a <a href="http://rock.so/about">more asynchronous way of working</a>. This way of working gives you <b>more control</b> over your workday, makes you <b>more productive</b> while <b>reserving face-to-face meetings</b> for the most important things. It's also ideally suited to a workforce that is more distributed.
                </p>
                <p>
                  With the right tools and mindset, working with your team becomes more like a <b>relay race</b>. Everybody knows what's going on, you can pick things up when you're ready, and work happens in a state of flow.
                </p>
              </div>
            </div>
            
          </div>

          

          <div>
            
            <div>
              <div>
                <p>
                  Rock combines real-time messaging and video calls with more asynchronous ways of communicating like <a href="http://rock.so/tasks">tasks</a>, <a href="http://rock.so/notes">notes</a>, and <a href="http://rock.so/files">files</a> and makes this available in <a href="http://rock.so/product">one space</a>. Because we combine these different types of communication, we make it easy for you to pick and choose the best way to interact with your team. We also work with Google Drive (and will work with Zoom and others soon) so it's easier to tap into your existing workflows.
                </p>
                <p>
                  When you <a href="http://rock.so/better-than-slack">compare Rock to Slack</a> you can easily see why we think Rock just works better for how work happens today.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row nine -->
          <div>
            
            <div>
              <p>
                <h3>Rock empowers anyone to work from anywhere</h3>
              </p>
            </div>
            
          </div>

          <!-- Row ten -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-3.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eleven -->
          <div>
            
            <div>
              <div>
                <p>
                  It's our mission to <b>build tools to empower anyone to work from anywhere</b>. When this happens - companies are more diverse, job opportunities are not limited by location and we all meet less, while doing more.
                </p>
                <p>
                  We have a lot more to say and lots more to build. If you want to join us on this journey to bring some much needed balance to the way we work, check out the video below or try out <a href="https://web.rock.so/?utm_source=website&amp;utm_medium=blog&amp;utm_campaign=hello">Rock</a> today.
                </p>
              </div>
            </div>
            
          </div>

          

          

          <section>
            <div>
              
          <!-- box card section -->
          <div>
            <div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/async.svg" alt="async"></p><h4>Product <br> details</h4>
                  <p>
                    Key features and more details about Rock.
                    <a href="http://rock.so/product">Read more</a>
                  </p>
                </div>

              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/recruiting/cross-org.svg" alt="async"></p><h4>How Rock <br> Works</h4>
                  <p>
                    Videos and walkthroughs to get you ready to Rock.
                    <a href="http://rock.so/how-rock-works">Read more</a>
                  </p>
                </div>
              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/zoom.svg" alt="async"></p><h4>Stop slacking, <br> start rocking.</h4>
                  <p>
                    Why Rock is better than Slack
                    <a href="http://rock.so/better-than-slack">Read more</a>
                  </p>
                </div>
              </div>
            </div>
          </div>
          <!-- box card section end -->


        </div>
      </section></div>

      
    </div></section></div>]]>
            </description>
            <link>http://rock.so/stopslacking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279417</guid>
            <pubDate>Wed, 02 Dec 2020 18:16:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PTM – Page Table Manipulation from Usermode]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25279155">thread link</a>) | @DyslexicAtheist
<br/>
December 2, 2020 | https://back.engineering/01/12/2020/ | <a href="https://web.archive.org/web/*/https://back.engineering/01/12/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<div>

<hr>
<p>PDF Version (Best Version) can be downloaded here: <a href="https://githacks.org/_xeroxz/PTM/-/blob/master/PTM.pdf">PDF Download</a>.<br>
You can download the source from the open source repo here: <a href="https://githacks.org/_xeroxz/PTM">VDM Repo</a>.</p>

<hr>
<p>PTM is a Windows 10 C++ library that allows a programmer to manipulate all memory, physical, and virtual from user-mode. The project inherits an interface from VDM allowing the use of a physical memory read-write primitive to fuel this project. VDM is used solely to configure the page tables in such a way that PTM can manage them from user-mode. Once the page tables are configured for PTM VDM is no longer required. However, VDM can inherit an instance of PTM as a means to read and write physical memory. Both VDM and PTM work extremely well together and independently from each other.</p>

<hr>
<p>Page table manipulation is an extremely powerful primitive. One that allows groundbreaking projects to be created such as patching the kernel only in specific process-contexts, or mapping of a source process address space into a target process address space. PTM is a user-mode library that allows a programmer to manipulate page tables from user-mode on 64-bit Windows 10 systems. PTM does this by using VDM; a project designed to abuse vulnerable drivers exposing a physical memory read-write primitive (RWP) to elevate to arbitrary kernel execution. VDM is used to configure the page tables in such a way that they can be managed from user-mode without the need for VDM’s vulnerable driver being loaded into the kernel after initialization. PTM can then be used to get and set all levels of page table entries, translation linear virtual addresses from user-mode, map physical memory into virtual memory, and even create new page tables. PTM can also be used as a means to directly read and write physical memory, thus it can be used with VDM to leverage arbitrary kernel execution without the need of VDM’s vulnerable driver being loaded into the kernel.</p>

<hr>
<p>Paging is the concept of breaking memory into fixed-sized chunks called pages. Pages can be moved in and out of physical memory allowing for memory that is not accessed frequently to be moved to disk. In order for this to work, the CPU cannot directly interface with physical memory instead the CPU interfaces with virtual memory. Virtual addresses are translated to physical addresses using a set of tables called page tables. On a 64-bit system with the CPU in long mode, there are four layers of page tables: PML4(s), PDPT(s), PD(s), and lastly PT(s). All page tables are the same size (1000h bytes) unless configured otherwise. Each page table entry is eight bytes in size. This means that each table contains 512 entries (8 * 512 = 1000h). The last twelve bits of every virtual address is called the page offset and is an offset into a physical page. The page offset of a virtual address can be bigger than 12 bits depending on the paging structure configuration for a given virtual address. The length of the page offset field can be either 12 bits (physical page is 4kB), 21 bits (2MB physical page), or 30 bits (1GB page).</p>
<p><img src="https://imgur.com/IqB4B22.png"></p><p>In order to translate linear virtual addresses to linear physical addresses, the page tables must be traversed. As depicted in figure one, each virtual address space has its own PML4, the physical address of this table is stored in CR3.</p>

<hr>
<p>On Windows, the thread scheduler utilizes KPROCESS.DirectoryTableBase when scheduling threads. The KPROCESS structure is a substructure of the EPROCESS structure and contains DirectoryTableBase at offset 28h. A programmer using VDM can obtain the linear physical address of the PML4 of a process easily by DKOM’ing a desired process KPROCESS structure.</p>
<pre><code>kd&gt; dt !_KPROCESS ffffc38759d9e080
nt!_KPROCESS
   +0x000 Header           : _DISPATCHER_HEADER
   +0x018 ProfileListHead  : _LIST_ENTRY 
   +0x028 DirectoryTableBase : 0x00000001`15684000
   +0x030 ThreadListHead   : _LIST_ENTRY 
   +0x040 ProcessLock      : 0
   +0x044 ProcessTimerDelay : 0
   +0x048 DeepFreezeStartTime : 0
</code></pre><p>Once the physical address of the desired processes PML4 has been obtained the trick is interfacing with the paging structures. Although VDM allows reading and writing of physical memory, be aware that MmMapIoSpace cannot be used to map the paging structures into virtual memory. Drivers that use MmCopyMemory and ZwMapViewOfSection to interface with physical memory can however be used to directly manipulate the page tables. To properly support VDM which PTM inherits as a codebase, the project does not rely on the physical read and write primitive exposed from the driver. Instead PTM allocates its own set of page tables and inserts a PML4E into the current processes PML4 pointing at such tables. This allows a programmer to map physical memory at will into the current virtual memory address space, all from user-mode. In other words, once the tables are allocated and configured, there is no need for VDM anymore since the paging tables can be controlled entirely from user-mode.</p>

<hr>
<p>The translation look-aside buffer is a hardware-based cache that assists in translating linear virtual addresses to linear physical addresses. The TLB caches virtual to physical address translations, as well as other information like page access rights and cache type information. Although extremely important for efficiency, the TLB has made PTM an interesting challenge. For example, when physical memory is mapped into a virtual address space, page table entries will be inserted, or changed. This insertion or alteration of an existing page table entry may be of a cached entry in the TLB. This means that the effects applied to the page table entry will not be seen until the TLB entry for the given virtual page has been invalidated, along with the changes written to main memory. To counteract this, the CPU has an instruction that allows a programmer to invalidate a page table entry in the TLB’s cache. This instruction is called INVLPG and is a privileged instruction. It’s not something PTM can use since the library is designed to operate entirely from user-mode. Directly invalidating TLB is not the only way to invalidate entries. If a page fault occurs, the TLB invalidates entries for the given address that caused the fault (the address in CR2). This is an effective method for invalidating desired virtual addresses from user-mode but is extremely slow. Context switches do not inherently cause the TLB to flush, rather the PCID is changed to another PCID. This allows the TLB to retain entries from multiple address spaces and improve performance. However, yielding execution can invalidate TLB entries because the scheduler will reschedule the logical processor to execute somewhere else for some time, possibly filling the TLB with other entries and removing the ones that were previously cached.</p>
<h3 id="tlb_outrun"><a href="#tlb_outrun">TLB - Outrun</a></h3>
<hr>
<p>Although the TLB is an effective hardware-based cache, it cannot cache linear virtual addresses that have not been accessed before, this simple fact means a programmer can create a new linear virtual address every single time they would want to map a new physical page into virtual memory. This, however, is not a solid solution that works soundly on all modern CPUs. With the industry pushing forward with virtualization technology, the expansion of the TLB continues. Thus solely generating a new linear virtual address every time you would want to interface with a physical page is not a sound solution and is already unstable on most modern AMD chips. Instead combining this technique with other techniques is ideal.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>map_page(<span>void</span><span>*</span> addr) <span>-&gt;</span> <span>void</span><span>*</span>
{
	<span>++</span>pte_index;
	<span>if</span> (pte_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pde_index;
		pte_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pde_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pdpte_index;
		pde_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pdpte_index <span>&gt;</span> <span>511</span>)
		pdpte_index <span>=</span> <span>0</span>;

	<span>// insert paging table entries down here…
</span><span></span>	<span>//... (refer to PTM repo to see that code)...
</span><span></span>	<span>// returns the newly generated virtual address...
</span><span></span>	<span>return</span> <span>get_virtual_address</span>();
}
</code></pre></div><p>The code above generates a new linear virtual address that has not been accessed before. This linear virtual address points to the requests physical page in memory. This allows the programmer to circumvent the TLB by accessing new linear virtual addresses instead of trying to invalidate TLB entry of an existed and already cached page. This however has limitations since the code only provides 512^3 different possible virtual pages.</p>
<h3 id="tlb_benefit_of_the_doubt"><a href="#tlb_benefit_of_the_doubt">TLB - Benefit of The Doubt</a></h3>
<hr>
<p>Although outrunning the TLB is the fastest solution for mapping physical memory into virtual memory without needing to invalidate any TLB entries, it is not the most stable on modern hardware. Instead, a mixture of generating a new virtual address and an SEH try/except loop is preferred. By giving the new virtual address the benefit of the doubt that it has not been cached yet, an attempt to access the newly created page is performed. If the access is successful, the new linear virtual address is returned to the caller of ptm::ptm_ctx::map_page. However, if the access causes a page fault, the TLB invalidates the entries associated with this newly created linear virtual address. The except block then attempts to access the new page in a loop whilst yielding execution at each failure to access the new virtual address. This technique provides the most performant solution to dealing with the TLB from user-mode. This method guarantees that the linear virtual address generated is accessible before returning it to the caller.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>get_virtual_address() <span>const</span> <span>-&gt;</span> <span>void</span><span>*</span>
{
    <span>//...
</span><span></span>    
    <span>// start off by making sure that 
</span><span></span>	<span>// the address is accessible...
</span><span></span>	<span>__try</span>
	{
		<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value <span>=</span> <span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value;
		<span>return</span> new_addr.value;
	}

	<span>// if its not accessible then the
</span><span></span>	<span>// TLB just invalidated its entry...
</span><span></span>	<span>__except</span> (EXCEPTION_EXECUTE_HANDLER)
	{
		<span>// loop until this new address is accessible…
</span><span></span>		<span>// do not return until this new virtual
</span><span></span>		<span>// address is accessible....
</span><span></span>		<span>while</span> (true)
		{
			<span>// try again to access the page again 
</span><span></span>			<span>// and it should return...
</span><span></span>			<span>__try</span>
			{
				<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new…</code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://back.engineering/01/12/2020/">https://back.engineering/01/12/2020/</a></em></p>]]>
            </description>
            <link>https://back.engineering/01/12/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279155</guid>
            <pubDate>Wed, 02 Dec 2020 17:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vector 0.11 Release: K8s, ARC, and metrics collection]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25278771">thread link</a>) | @zhs
<br/>
December 2, 2020 | https://vector.dev/releases/0.11.0/ | <a href="https://web.archive.org/web/*/https://vector.dev/releases/0.11.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><li><div><p><a href="https://github.com/timberio/vector/pull/3099" target="_blank" title="View pull request..."><i></i> 3099</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Cleanup `list` command</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3190" target="_blank" title="View pull request..."><i></i> 3190</a></p></div><h4><span title="Filter to 'buffers' changes only">buffers</span><span title="Filter to 'sinks' changes only">sinks</span>Upgrade all VecBuffer sinks to allow setting `max_bytes`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3236" target="_blank" title="View pull request..."><i></i> 3236</a></p></div><h4><span title="Filter to 'socket source' changes only">socket source</span>Add max_length to UDP</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3151" target="_blank" title="View pull request..."><i></i> 3151</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'stdin source' changes only">stdin source</span>Instrument "stdin" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3241" target="_blank" title="View pull request..."><i></i> 3241</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Add received and invalid line events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3278" target="_blank" title="View pull request..."><i></i> 3278</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Provide error context on parse error</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3187" target="_blank" title="View pull request..."><i></i> 3187</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'kafka source' changes only">kafka source</span>Instrument "kafka" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3300" target="_blank" title="View pull request..."><i></i> 3300</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3317" target="_blank" title="View pull request..."><i></i> 3317</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'prometheus source' changes only">prometheus source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3315" target="_blank" title="View pull request..."><i></i> 3315</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'syslog source' changes only">syslog source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3264" target="_blank" title="View pull request..."><i></i> 3264</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'http source' changes only">http source</span>Add internal events for `http` source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3351" target="_blank" title="View pull request..."><i></i> 3351</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Make sourcetype templatable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3254" target="_blank" title="View pull request..."><i></i> 3254</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'statsd source' changes only">statsd source</span>Add events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3345" target="_blank" title="View pull request..."><i></i> 3345</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'docker source' changes only">docker source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3312" target="_blank" title="View pull request..."><i></i> 3312</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'splunk_hec source' changes only">splunk_hec source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/2913" target="_blank" title="View pull request..."><i></i> 2913</a></p></div><h4><span title="Filter to 'data_dog_metrics sink' changes only">data_dog_metrics sink</span>Add DataDog's `distribution` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3327" target="_blank" title="View pull request..."><i></i> 3327</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Add configuration for source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3337" target="_blank" title="View pull request..."><i></i> 3337</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field (#3300)</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3328" target="_blank" title="View pull request..."><i></i> 3328</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Add source configuration to Humio sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3356" target="_blank" title="View pull request..."><i></i> 3356</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logplex source' changes only">logplex source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3417" target="_blank" title="View pull request..."><i></i> 3417</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Add more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3421" target="_blank" title="View pull request..."><i></i> 3421</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'ansi_stripper transform' changes only">ansi_stripper transform</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3419" target="_blank" title="View pull request..."><i></i> 3419</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3418" target="_blank" title="View pull request..."><i></i> 3418</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3439" target="_blank" title="View pull request..."><i></i> 3439</a></p></div><h4><span title="Filter to 'aws_s3 sink' changes only">aws_s3 sink</span>Add additional canned ACLs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3434" target="_blank" title="View pull request..."><i></i> 3434</a></p></div><h4><span title="Filter to 'codecs' changes only">codecs</span><span title="Filter to 'console sink' changes only">console sink</span>Add "text" encoding for metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3436" target="_blank" title="View pull request..."><i></i> 3436</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Even more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3286" target="_blank" title="View pull request..."><i></i> 3286</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Rewrite parser, improve error handlings </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3476" target="_blank" title="View pull request..."><i></i> 3476</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'startup' changes only">startup</span><span title="Filter to 'shutdown' changes only">shutdown</span>Add events for starting, stopping, and reloading</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3502" target="_blank" title="View pull request..."><i></i> 3502</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add Heartbeat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3373" target="_blank" title="View pull request..."><i></i> 3373</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span><span title="Filter to 'compression' changes only">compression</span>Add support for gzip compression</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3475" target="_blank" title="View pull request..."><i></i> 3475</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span>Sync all data before finishing</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3521" target="_blank" title="View pull request..."><i></i> 3521</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3486" target="_blank" title="View pull request..."><i></i> 3486</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket source' changes only">socket source</span>Add and unify events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3523" target="_blank" title="View pull request..."><i></i> 3523</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'regex_parser transform' changes only">regex_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3553" target="_blank" title="View pull request..."><i></i> 3553</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'grok_parser transform' changes only">grok_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3598" target="_blank" title="View pull request..."><i></i> 3598</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add the ability to store pod labels flat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3602" target="_blank" title="View pull request..."><i></i> 3602</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Store pod labels flat by default, remove the switch</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3586" target="_blank" title="View pull request..."><i></i> 3586</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Add `file` label</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3582" target="_blank" title="View pull request..."><i></i> 3582</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add more `main` events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3593" target="_blank" title="View pull request..."><i></i> 3593</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3490" target="_blank" title="View pull request..."><i></i> 3490</a></p></div><h4><span title="Filter to 'wasm transform' changes only">wasm transform</span>Implement some UX improvements for WASM</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3610" target="_blank" title="View pull request..."><i></i> 3610</a></p></div><h4><span title="Filter to 'kuberentes platform' changes only">kuberentes platform</span>Adds new Helm template variable for podsLabels.</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3607" target="_blank" title="View pull request..."><i></i> 3607</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Multiline support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3577" target="_blank" title="View pull request..."><i></i> 3577</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tag_cardinality_limit transform' changes only">tag_cardinality_limit transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3554" target="_blank" title="View pull request..."><i></i> 3554</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'coercer transform' changes only">coercer transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3655" target="_blank" title="View pull request..."><i></i> 3655</a></p></div><h4><span title="Filter to 'http sink' changes only">http sink</span>Increase rate_limit_num to its maximum</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3690" target="_blank" title="View pull request..."><i></i> 3690</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span>Add a new options to control the auto concurrency limiter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3720" target="_blank" title="View pull request..."><i></i> 3720</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Fix TcpEventSent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3730" target="_blank" title="View pull request..."><i></i> 3730</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'swimlanes transform' changes only">swimlanes transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3699" target="_blank" title="View pull request..."><i></i> 3699</a></p></div><h4><span title="Filter to 'socket sink' changes only">socket sink</span>Add IPv6 supports</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3726" target="_blank" title="View pull request..."><i></i> 3726</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3782" target="_blank" title="View pull request..."><i></i> 3782</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Enhance checkpoint errors with file name</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3812" target="_blank" title="View pull request..."><i></i> 3812</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'reduce transform' changes only">reduce transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3809" target="_blank" title="View pull request..."><i></i> 3809</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'dedupe transform' changes only">dedupe transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3807" target="_blank" title="View pull request..."><i></i> 3807</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tokenizer transform' changes only">tokenizer transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3846" target="_blank" title="View pull request..."><i></i> 3846</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Support `summary` statistic</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3725" target="_blank" title="View pull request..."><i></i> 3725</a></p></div><h4><span title="Filter to 'datadog_metrics sink' changes only">datadog_metrics sink</span>Support datadog `distribution` metric </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3850" target="_blank" title="View pull request..."><i></i> 3850</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Regularize internal event messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3824" target="_blank" title="View pull request..."><i></i> 3824</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'security' changes only">security</span>Enable tls by default  for `papertrail` and `datadog_logs` sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3861" target="_blank" title="View pull request..."><i></i> 3861</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Improve retry error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3989" target="_blank" title="View pull request..."><i></i> 3989</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Accept more timestamp patterns in `to_timestamp`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4018" target="_blank" title="View pull request..."><i></i> 4018</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Include container_name in kubernetes_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3833" target="_blank" title="View pull request..."><i></i> 3833</a></p></div><h4><span title="Filter to 'gcp_stackdriver sink' changes only">gcp_stackdriver sink</span>Insert timestamp into stackdriver message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3778" target="_blank" title="View pull request..."><i></i> 3778</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>GraphQL client</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4075" target="_blank" title="View pull request..."><i></i> 4075</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_timestamp` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4090" target="_blank" title="View pull request..."><i></i> 4090</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `contains` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4092" target="_blank" title="View pull request..."><i></i> 4092</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `slice` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4093" target="_blank" title="View pull request..."><i></i> 4093</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `tokenize` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4020" target="_blank" title="View pull request..."><i></i> 4020</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add container_image and pod_node_name annotations</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4034" target="_blank" title="View pull request..."><i></i> 4034</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Emit warning on incomplete UDP sent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4170" target="_blank" title="View pull request..."><i></i> 4170</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `strip_ansi_escape_codes` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4188" target="_blank" title="View pull request..."><i></i> 4188</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha2` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4198" target="_blank" title="View pull request..."><i></i> 4198</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha3` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4215" target="_blank" title="View pull request..."><i></i> 4215</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>add field's value in warn message when failing to parse</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4236" target="_blank" title="View pull request..."><i></i> 4236</a></p></div><h4><span title="Filter to 'docker platform' changes only">docker platform</span>Added distroless-libc and distroless-static docker container bases</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4186" target="_blank" title="View pull request..."><i></i> 4186</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `parse_duration` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4032" target="_blank" title="View pull request..."><i></i> 4032</a></p></div><h4><span title="Filter to 'prometheus sink' changes only">prometheus sink</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4049" target="_blank" title="View pull request..."><i></i> 4049</a></p></div><h4><span title="Filter to 'auth' changes only">auth</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'aws service' changes only">aws service</span>Add EKS Web Identity Support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4191" target="_blank" title="View pull request..."><i></i> 4191</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Initial GraphQL topology</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4288" target="_blank" title="View pull request..."><i></i> 4288</a></p></div><h4><span title="Filter to 'console sink' changes only">console sink</span>Improve error handling</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4220" target="_blank" title="View pull request..."><i></i> 4220</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_number` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4383" target="_blank" title="View pull request..."><i></i> 4383</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Bidirectional source/transform/sink GraphQL types</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4429" target="_blank" title="View pull request..."><i></i> 4429</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Improve error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4412" target="_blank" title="View pull request..."><i></i> 4412</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span><span title="Filter to 'sinks' changes only">sinks</span>Option to specify `quantiles`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4037" target="_blank" title="View pull request..."><i></i> 4037</a></p></div><h4><span title="Filter to 'security' changes only">security</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>add TLS settings to influxdb_logs and influxdb_metrics sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4068" target="_blank" title="View pull request..."><i></i> 4068</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Add a tags configuration options to add user-defined tags</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4544" target="_blank" title="View pull request..."><i></i> 4544</a></p></div><h4><span title="Filter to 'debian platform' changes only">debian platform</span>Add vector user to adm in debian packaging</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/3557" target="_blank" title="View pull request..."><i></i> 3557</a></p></div><h4><span title="Filter to 'statsd sink' changes only">statsd sink</span>Support all socket types in statsd sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3032" target="_blank" title="View pull request..."><i></i> 3032</a></p></div><h4><span title="Filter to 'sinks' changes only">sinks</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'compression' changes only">compression</span>Add compression level</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4182" target="_blank" title="View pull request..."><i></i> 4182</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Allow using custom selectors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4406" target="_blank" title="View pull request..."><i></i> 4406</a></p></div><h4><span title="Filter to 'aws service' changes only">aws service</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'auth' changes only">auth</span>Support assume_role with EKS web identity</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4580" target="_blank" title="View pull request..."><i></i> 4580</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>Rename "identifier_fields" to "group_by"</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4579" target="_blank" title="View pull request..."><i></i> 4579</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>"concat_newline" strategy merges using newline</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4586" target="_blank" title="View pull request..."><i></i> 4586</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Advanced container filtering</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4428" target="_blank" title="View pull request..."><i></i> 4428</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Add `parse_url` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4164" target="_blank" title="View pull request..."><i></i> 4164</a></p></div><h4><span title="Filter to 'datadog_logs sink' changes only">datadog_logs sink</span><span title="Filter to 'networking' changes only">networking</span>Support datadog logs new HTTPS transport</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4385" target="_blank" title="View pull request..."><i></i> 4385</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span><span title="Filter to 'auth' changes only">auth</span>Basic auth support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4174" target="_blank" title="View pull request..."><i></i> 4174</a></p></div><h4><span title="Filter to 'datadog service' changes only">datadog service</span>Added region configuration parameter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4408" target="_blank" title="View pull request..."><i></i> 4408</a></p></div><h4><span title="Filter to 'windows platform' changes only">windows platform</span>Correctly handle service restart</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4557" target="_blank" title="View pull request..."><i></i> 4557</a></p></div><h4><span title="Filter to 'statsd source' changes only">statsd source</span>Add support for all socket types</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4647" target="_blank" title="View pull request..."><i></i> 4647</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'internal_metrics source' changes only">internal_metrics source</span>Updated internal metrics names to match standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4481" target="_blank" title="View pull request..."><i></i> 4481</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logfmt_parser transform' changes only">logfmt_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4701" target="_blank" title="View pull request..."><i></i> 4701</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span><span title="Filter to 'metrics' changes only">metrics</span>Add `namespace` to `Metric` </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4734" target="_blank" title="View pull request..."><i></i> 4734</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Force daemonset to redeploy when configmap is updated</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4581" target="_blank" title="View pull request..."><i></i> 4581</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Topology added/removed GraphQL subscriptions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4652" target="_blank" title="View pull request..."><i></i> 4652</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API host metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4733" target="_blank" title="View pull request..."><i></i> 4733</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span>annotate logs with query parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4751" target="_blank" title="View pull request..."><i></i> 4751</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Expose the performance related parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4735" target="_blank" title="View pull request..."><i></i> 4735</a></p></div><h4><span title="Filter to 'reload' changes only">reload</span>Resolve port conflict in sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4835" target="_blank" title="View pull request..."><i></i> 4835</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Add the ability to set conatiner ports at vector-agent Helm chart</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4480" target="_blank" title="View pull request..."><i></i> 4480</a></p></div><h4><span title="Filter to 'aws_ec2_metadata transform' changes only">aws_ec2_metadata transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4819" target="_blank" title="View pull request..."><i></i> 4819</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Adds optional file output to generator</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4831" target="_blank" title="View pull request..."><i></i> 4831</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add `namespace` option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4859" target="_blank" title="View pull request..."><i></i> 4859</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>display full error chain</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4884" target="_blank" title="View pull request..."><i></i> 4884</a></p></div><h4><span title="Filter to 'logdna sink' changes only">logdna sink</span>Support template syntax in hostname and tags field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4881" target="_blank" title="View pull request..."><i></i> 4881</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Add TLS and authentication options</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4873" target="_blank" title="View pull request..."><i></i> 4873</a></p></div><h4><span title="Filter to 'gcp_pubsub sink' changes only">gcp_pubsub sink</span>Add configurable endpoint</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4928" target="_blank" title="View pull request..."><i></i> 4928</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Kind/type for `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4836" target="_blank" title="View pull request..."><i></i> 4836</a></p></div><h4><span title="Filter to 'journald source' changes only">journald source</span>Restart journalctl on errors, save checkpoint on shutdown</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4998" target="_blank" title="View pull request..."><i></i> 4998</a></p></div><h4><span title="Filter to 'sources' changes only">sources</span>make scrape interval configurable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4945" target="_blank" title="View pull request..."><i></i> 4945</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Humanized formatting for `vector top` metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4958" target="_blank" title="View pull request..."><i></i> 4958</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Batch events processed total</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5002" target="_blank" title="View pull request..."><i></i> 5002</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Added batch subscriptions for component bytes and errors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5004" target="_blank" title="View pull request..."><i></i> 5004</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API batch support + tests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5018" target="_blank" title="View pull request..."><i></i> 5018</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API version + hostname queries</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4887" target="_blank" title="View pull request..."><i></i> 4887</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add PodIPs into Pod Metadata events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4999" target="_blank" title="View pull request..."><i></i> 4999</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>More debug info on more HTTP requests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5026" target="_blank" title="View pull request..."><i></i> 5026</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>add internal option to ignore missing files</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5034" target="_blank" title="View pull request..."><i></i> 5034</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Edited a few vector top error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4902" target="_blank" title="View pull request..."><i></i> 4902</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>compile-time program result type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5008" target="_blank" title="View pull request..."><i></i> 5008</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>support enum variants for function arguments</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5015" target="_blank" title="View pull request..."><i></i> 5015</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>use path arguments for `del` and `only_field` functions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5039" target="_blank" title="View pull request..."><i></i> 5039</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Renamed docker source to docker_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5053" target="_blank" title="View pull request..."><i></i> 5053</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>expressions no longer return an option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5074" target="_blank" title="View pull request..."><i></i> 5074</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Rename `version` -&gt; `versionString` in GraphQL schema</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5056" target="_blank" title="View pull request..."><i></i> 5056</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>undefined path or variable return null</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5016" target="_blank" title="View pull request..."><i></i> 5016</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add I/O (throughput) columns to `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5146" target="_blank" title="View pull request..."><i></i> 5146</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Expire checkpoints</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5153" target="_blank" title="View pull request..."><i></i> 5153</a></p></div><h4><span title="Filter to 'kafka source' changes only">kafka source</span>Include kafka metadata as optional keys</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4918" target="_blank" title="View pull request..."><i></i> 4918</a></p></div><h4><span title="Filter to 'sampler transform' changes only">sampler transform</span>Add rating by `index`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5095" target="_blank" title="View pull request..."><i></i> 5095</a></p></div><h4><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Support basic-auth credentials in endpoint configuation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5171" target="_blank" title="View pull request..."><i></i> 5171</a></p></div><h4><span title="Filter to 'api' changes only">api</span> Allow querying transform outputs on transform components</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4615" target="_blank" title="View pull request..."><i></i> 4615</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span>Expose internal metrics cardinality as a internal metric counter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5218" target="_blank" title="View pull request..."><i></i> 5218</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add test for component links</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5204" target="_blank" title="View pull request..."><i></i> 5204</a></p></div><h4><span title="Filter to 'loki sink' changes only">loki sink</span>Allow tenant_id to be templatable on loki sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5059" target="_blank" title="View pull request..."><i></i> 5059</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>improve arithmetic type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4699" target="_blank" title="View pull request..."><i></i> 4699</a></p></div><h4><span title="Filter to 'mongodb_metrics source' changes only">mongodb_metrics source</span>Renamed mongo metrics to new naming standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4681" target="_blank" title="View pull request..."><i></i> 4681</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `ConnectionOpen` gauge</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4806" target="_blank" title="View pull request..."><i></i> 4806</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sinks</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4833" target="_blank" title="View pull request..."><i></i> 4833</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sources</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4996" target="_blank" title="View pull request..."><i></i> 4996</a></p></div><h4><span title="Filter to 'shutdown' changes only">shutdown</span>Extend `Resource` to sources </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5048" target="_blank" title="View pull request..."><i></i> 5048</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Beautify reports of conflicting `Resource` usage</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5098" target="_blank" title="View pull request..."><i></i> 5098</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>add _total suffix to events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4922" target="_blank" title="View pull request..."><i></i> 4922</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Emit `FileOpen` in `file` sink and source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5183" target="_blank" title="View pull request..."><i></i> 5183</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Incorrect Log Level Message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5005" target="_blank" title="View pull request..."><i></i> 5005</a></p></div><h4><span title="Filter to 'config' changes only">config</span>Allow JSON and YAML config formats in addition to TOML</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5296" target="_blank" title="View pull request..."><i></i> 5296</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Enable TLS subscription connections in vector top</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5021" target="_blank" title="View pull request..."><i></i> 5021</a></p></div><h4><span title="Filter to 'pulsar sink' changes only">pulsar sink</span>introduce encoding schema and pulsar avro schema</h4></li></div></div>]]>
            </description>
            <link>https://vector.dev/releases/0.11.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25278771</guid>
            <pubDate>Wed, 02 Dec 2020 17:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Materialize Raises a $32M Series B]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25277511">thread link</a>) | @austinbirch
<br/>
December 2, 2020 | https://materialize.com/materialize-series-b/ | <a href="https://web.archive.org/web/*/https://materialize.com/materialize-series-b/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today we <a href="https://www.prnewswire.com/news-releases/materialize-raises-40-million-to-simplify-streaming-data-with-sql-and-speed-up-real-time-analytics-301180777.html">announced</a> that we raised a $32M Series B round of funding led by Kleiner Perkins. This follows a $8.5m Series A last year led by Lightspeed Venture Partners, bringing our total funding to-date to a little over $40 million. With our Series B, <a href="https://www.kleinerperkins.com/people/bucky-moore/" target="_blank" rel="noopener noreferrer">Bucky Moore</a> joins <a href="https://lsvp.com/?team=ravi-mhatre/" target="_blank" rel="noopener noreferrer">Ravi Mhatre</a> on our board of directors.</p>
<p>At Materialize, we believe that at every business it will soon be essential for all information to be always up-to-date. Whether it’s delivering personalized experiences, accurately identifying fraud, building predictive AI, or discovering new business opportunities, the ability to run complex queries on multiple streams of data and keep their answers up to date is critical to making better decisions about the changing world around us.</p>
<p>While the past decade has seen a groundswell in the adoption of streaming platforms, they are still too difficult to use. Current systems require users to make tradeoffs between dumbing down their queries, waiting for hours-long batch ETL pipelines to finish, or building and orchestrating sprawling microservices. We believe users should not have to make these tradeoffs.</p>
<p>Materialize’s mission is to make queries against streaming data simple. We support industry standard SQL: write queries with multi-way joins, correlated subqueries, and complex aggregations, and we’ll keep the answers always up to date for you. In a world where “real-time” has become an empty buzzword, Materialize provides answers that are up to date within milliseconds. All of this comes in <a href="https://materialize.com/docs/install/" target="_blank" rel="noopener noreferrer">a single binary</a> that is easy to install, easy to use, and easy to deploy. With Materialize, users can get interactive and always-up-to-date answers about their changing data using only their existing SQL skills.</p>
<p>While Materialize is a young company, it is built on top of the award winning Timely Dataflow project, spanning almost a decade of cutting-edge research on stream processing led by my co-founder Frank McSherry. Starting from this solid foundation, $40 million dollars of capital gives us the resources to build the no-compromise streaming database that lets every developer build streaming applications.</p>
<p>With this new round of funding, we are well equipped to deliver on <a href="https://materialize.com/blog-roadmap/" target="_blank" rel="noopener noreferrer">an ambitious roadmap</a>, including a fully-managed cloud service with tiered storage and replication. We’re also excited to continue work on broadening the suite of SQL tools that we support, as well as investing in a SQL optimizer, performance and benchmarking work, and in making Materialize more resilient and battle-tested. If you’re interested in working on any of these challenges, Materialize <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">is hiring</a> across the board.</p>
<p>And finally, while it is exciting to build Materialize, it has been even more exciting to see how Materialize is being used to build applications that previously would have required months of development, using just a few simple SQL queries. If you’re as excited about Materialize as we are, we’d love for you to get involved. <a href="https://materialize.com/quickstart/" target="_blank" rel="noopener noreferrer">Download</a> and try Materialize, try <a href="https://materialize.com/docs/katacoda/?intro-wikipedia" target="_blank" rel="noopener noreferrer">a demo</a> in your browser, <a href="https://join.slack.com/t/materializecommunity/shared_invite/zt-jjwe1t45-klG9k7V7xibdtqA6bcFpyQ" target="_blank" rel="noopener noreferrer">join the community</a> and say hello, or <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">apply</a> to join our growing team today!</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/materialize-series-b/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277511</guid>
            <pubDate>Wed, 02 Dec 2020 15:55:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rga: Ripgrep, but also search in PDFs, E-Books, Office documents, zip, tar.gz]]>
            </title>
            <description>
<![CDATA[
Score 627 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25277280">thread link</a>) | @angrygoat
<br/>
December 2, 2020 | https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/ | <a href="https://web.archive.org/web/*/https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><small><time datetime="2019-06-16T00:00:00.000Z">Jun 16, 2019</time> • <a href="https://github.com/phiresky/blog/commits/master/posts/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg.md">Last Update <time datetime="2019-06-16T00:00:00.000Z">Oct 21, 2019</time></a></small></p><p><a href="https://github.com/phiresky/ripgrep-all">rga</a> is a line-oriented search tool that allows you to look for a regex in a multitude of file types. rga wraps the awesome <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> and enables it to search in pdf, docx, sqlite, jpg, zip, tar.*, movie subtitles (mkv, mp4), etc.</p><p><a href="https://github.com/phiresky/ripgrep-all"><img src="https://img.shields.io/badge/repo-github.com%2Fphiresky%2Fripgrep--all-informational.svg" title=""></a>
<a href="https://crates.io/crates/ripgrep-all"><img src="https://img.shields.io/crates/v/ripgrep-all.svg" title=""></a>
<a href="https://www.reddit.com/r/rustjerk/top/?sort=top&amp;t=all"><img src="https://img.shields.io/badge/concurrency-fearless-success.svg" title=""></a></p><h2 id="examples">Examples</h2><h3 id="pdfs">PDFs</h3><p>Say you have a large folder of papers or lecture slides, and you can’t remember which one of them mentioned <code>GRU</code>s. With rga, you can just run this:</p><div><pre>~$ rga "GRU" slides/
<span>slides/2016/winter1516_lecture14.pdf</span>
Page 34:   <span></span><span>GRU</span>                            LSTM
Page 35:   <span></span><span>GRU</span>                            CONV
Page 38:     - Try out <span></span><span>GRU</span>-RCN! (imo best model)

<span>slides/2018/cs231n_2018_ds08.pdf</span>
Page  3: ●   CNNs, GANs, RNNs, LSTMs, <span></span><span>GRU</span>
Page 35: ● 1) temporal pooling 2) RNN (e.g. LSTM, <span></span><span>GRU</span>)

<span>slides/2019/cs231n_2019_lecture10.pdf</span>
Page 103:   <span></span><span>GRU</span> [Learning phrase representations using rnn
Page 105:    - Common to use LSTM or <span></span><span>GRU</span>

</pre></div><p>and it will recursively find a string in pdfs, including if some of them are zipped up.</p><p>You can do mostly the same thing with <a href="https://pdfgrep.org/"><code>pdfgrep -r</code></a>, but you will miss content in other file types and it will be much slower:</p><div><p>Searching in 65 pdfs with 93 slides each</p><div><div><svg width="600" height="200" viewBox="0 0 600 200" version="1.1"><defs><clipPath id="recharts2-clip"><rect x="105" y="5" height="160" width="490"></rect></clipPath></defs><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="165" x2="595" y2="165"></line><g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="171" x2="105" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="105" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="105" dy="0.71em">0</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="227.5" y1="171" x2="227.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="227.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="227.5" dy="0.71em">5</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="350" y1="171" x2="350" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="350" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="350" dy="0.71em">10</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="472.5" y1="171" x2="472.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="472.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="472.5" dy="0.71em">15</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="595" y1="171" x2="595" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="595" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="595" dy="0.71em">20</tspan></text></g></g></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="105" y1="5" x2="105" y2="165"></line><g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="31.666666666666668" x2="105" y2="31.666666666666668"></line><text type="category" width="100" orientation="left" height="160" x="97" y="31.666666666666668" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">pdfgrep</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="85" x2="105" y2="85"></line><text type="category" width="100" orientation="left" height="160" x="97" y="85" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (first run)</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="138.33333333333334" x2="105" y2="138.33333333333334"></line><text type="category" width="100" orientation="left" height="160" x="97" y="138.33333333333334" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (subsequent runs)</tspan></text></g></g></g><g><g><g><path name="pdfgrep" fill="#8884d8" width="469.41999999999996" height="42" x="105" y="10.333333333333334" radius="0" d="M 105,10.333333333333334 h 469.41999999999996 v 42 h -469.41999999999996 Z"></path></g><g><path name="rga (first run)" fill="#8884d8" width="72.27500000000003" height="42" x="105" y="63.66666666666667" radius="0" d="M 105,63.66666666666667 h 72.27500000000003 v 42 h -72.27500000000003 Z"></path></g><g><path name="rga (subsequent runs)" fill="#8884d8" width="2.2539999999999907" height="42" x="105" y="117" radius="0" d="M 105,117 h 2.2539999999999907 v 42 h -2.2539999999999907 Z"></path></g></g></g></svg><div><ul><li><svg width="14" height="14" style="display:inline-block;vertical-align:middle;margin-right:4px" viewBox="0 0 32 32" version="1.1"><path stroke="none" fill="#8884d8" d="M0,4h32v24h-32z"></path></svg><span>run time (seconds, lower is better)</span></li></ul></div></div></div></div><p>On the first run rga is mostly faster because of multithreading, but on subsequent runs (with the same files but any regex query) rga will cache the text extraction, so it becomes almost as fast as searching in plain text files. All runs were done with a warm FS cache.</p><h3 id="other-files">Other files</h3><p>rga will recursively descend into archives and match text in every file type it knows.</p><p>Here is an example directory with different file types:</p><pre><code>demo
├── greeting.mkv
├── hello.odt
├── hello.sqlite3
└── somearchive.zip
    ├── dir
    │&nbsp;&nbsp; ├── greeting.docx
    │&nbsp;&nbsp; └── inner.tar.gz
    │&nbsp;&nbsp;     └── greeting.pdf
    └── greeting.epub</code></pre><p>(see the actual directory <a href="https://github.com/phiresky/ripgrep-all/tree/master/exampledir/demo">here</a>)</p><div><pre>~$ rga "hello" demo/

<span>demo/greeting.mkv</span>
metadata: chapters.chapter.0.tags.title="Chapter 1: <span></span><span>Hello</span>"
00:08.398 --&gt; 00:11.758: <span></span><span>Hello</span> from a movie!

<span>demo/hello.odt</span>
<span></span><span>Hello</span> from an OpenDocument file!

<span>demo/hello.sqlite3</span>
tbl: greeting='<span></span><span>hello</span>', from='sqlite database!'

<span>demo/somearchive.zip</span>
dir/greeting.docx: <span></span><span>Hello</span> from a MS Office document!
dir/inner.tar.gz: greeting.pdf: Page 1: <span></span><span>Hello</span> from a PDF!
greeting.epub: <span></span><span>Hello</span> from an E-Book!
</pre></div><p>It can even search jpg / png images and scanned pdfs using OCR, though this is disabled by default since it is not useful that often and pretty slow.</p><div><pre>~$ # find screenshot of crates.io
~$ rga crates ~/screenshots --rga-adapters=+pdfpages,tesseract
<span>screenshots/2019-06-14-19-01-10.png</span>
<span></span><span>crates</span>.io I Browse All <span></span><span>Crates</span>  Docs v
Documentation Repository Dependent <span></span><span>crates</span>

~$ # there it is!
</pre></div><h2 id="setup">Setup</h2><p>Linux, Windows and OSX binaries are available in GitHub releases. See <a href="https://github.com/phiresky/ripgrep-all#installation">the readme</a> for more information.</p><p>For Arch Linux, I have packaged <code>rga</code> in the AUR: <a href="https://aur.archlinux.org/packages/ripgrep-all/"><code>yay -S ripgrep-all</code></a></p><h2 id="technical-details">Technical details</h2><p>The code and a few more details are here: <a href="https://github.com/phiresky/ripgrep-all">https://github.com/phiresky/ripgrep-all</a></p><p><code>rga</code> simply runs ripgrep (<code>rg</code>) with some options set, especially <code>--pre=rga-preproc</code> and <code>--pre-glob</code>.</p><p><code>rga-preproc [fname]</code> will match an <span>"<!-- -->adapter<!-- -->"</span> to the given file based on either it’s filename or it’s mime type (if <code>--rga-accurate</code> is given). You can see all adapters currently included in <a href="https://github.com/phiresky/ripgrep-all/tree/master/src/adapters">src/adapters</a>.</p><p>Some rga adapters run external binaries to do the actual work (such as pandoc or ffmpeg), usually by writing to stdin and reading from stdout. Others use a Rust library or bindings to achieve the same effect (like sqlite or zip).</p><p>To read archives, the <code>zip</code> and <code>tar</code> libraries are used, which work fully in a streaming fashion - this means that the RAM usage is low and no data is ever actually extracted to disk!</p><p>Most adapters read the files from a <a href="https://doc.rust-lang.org/std/io/trait.Read.html">Read</a>, so they work completely on streamed data (that can come from anywhere including within nested archives).</p><p>During the extraction, rga-preproc will compress the data with ZSTD to a memory cache while simultaneously writing it uncompressed to stdout. After completion, if the memory cache is smaller than 2MByte, it is written to a <a href="https://docs.rs/rkv/0.9.6/rkv/">rkv</a> cache. The cache is keyed by (adapter, filename, mtime), so if a file changes it’s content is extracted again.</p><h2 id="future-work">Future Work</h2><ul><li>I wanted to add a photograph adapter (based on object classification / detection) for fun, so you can grep for <span>"<!-- -->mountain<!-- -->"</span> and it will show pictures of mountains, like in Google Photos. It worked with <a href="https://pjreddie.com/darknet/yolo/">YOLO</a>, but something more useful and state-of-the art <a href="https://github.com/aimagelab/show-control-and-tell">like this</a> proved very hard to integrate.</li><li>7z adapter (couldn’t find a nice to use Rust library with streaming)</li><li>Allow per-adapter configuration options (probably via env (RGA_ADAPTERXYZ_CONF=json))</li><li>Maybe use a different disk kv-store as a cache instead of rkv, because I had some <a href="https://github.com/phiresky/ripgrep-all/blob/05835c1c42bc3575023a81e5494c5530078730fc/src/preproc_cache.rs#L30">weird problems</a> with that. SQLite is great. All other Rust alternatives I could find don’t allow writing from multiple processes.</li><li>Tests!</li><li>There’s some more (mostly technical) todos in the code I don’t know how to fix. Help wanted.</li><li>Other <a href="https://github.com/phiresky/ripgrep-all/issues">open issues</a></li></ul><ul><li><a href="https://pdfgrep.org/">pdfgrep</a></li><li><a href="https://gist.github.com/phiresky/5025490526ba70663ab3b8af6c40a8db">this gist</a> has my proof of concept version of a caching extractor to use ripgrep as a replacement for pdfgrep.</li><li><a href="https://gist.github.com/ColonolBuendia/314826e37ec35c616d70506c38dc65aa">this gist</a> is a more extensive preprocessing script by <a href="https://github.com/ColonolBuendia">@ColonolBuendia</a></li><li><a href="https://github.com/wofr06/lesspipe">lesspipe</a> is a tool to make <code>less</code> work with many different file types. Different usecase, but similar in what it does.</li></ul></div></div>]]>
            </description>
            <link>https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277280</guid>
            <pubDate>Wed, 02 Dec 2020 15:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Netflix]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25277041">thread link</a>) | @leopold_a
<br/>
December 2, 2020 | https://www.forourposterity.com/against-netflix/ | <a href="https://web.archive.org/web/*/https://www.forourposterity.com/against-netflix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>It has become fashionable to lambast big tech corporations and social media sites, the Facebooks and Twitters and Googles, blaming them for a litany of social ills. Seemingly escaping this ire has been the—in my view—most pernicious by far: Netflix.</p><p>Simply put, Netflix (and its imitators) produce too many TV shows that are too good—and too easy to binge. Consequently, too many great minds spend their time watching TV rather than thinking and inventing and creating.</p><h2 id="the-greatness-we-lose">The Greatness We Lose</h2><p>Consider the writer Matthew Yglesias. He just wrote an excellent <a href="https://www.amazon.com/One-Billion-Americans-Thinking-Bigger/dp/0593190211/">book</a>, which partially inspired my <a href="https://www.forourposterity.com/canada-and-mexico-should-join-the-union/">last post</a>. Recently, Yglesias <a href="https://web.archive.org/web/20200912220900/https://twitter.com/mattyglesias/status/1304904789055156225">tweeted</a>:</p><blockquote>Someone asked … “how’d you get this book written without taking time off work?” and the dumb boring answer was basically “didn’t watch much TV for six months.”</blockquote><p>He adds,</p><blockquote>I am perfectly aware that the difference between times when I’m most productive &amp; creative and times when I’m not is how much of the week I waste on watching television, yet tonight I’m almost certainly going to finish season two of Hannibal.</blockquote><p>Yglesias, turn off the TV! Write more books instead! Heck, write more tweets, if you prefer!</p><p>Just think of all the original ideas Yglesias could be contributing if he continued to abstain from watching TV. Of them we are being robbed. That is an epic <a href="https://applieddivinitystudies.com/murder-of-wilbur/">tragedy</a>.</p><h2 id="why-modern-tv-is-different">Why Modern TV Is Different</h2><p>I don’t mean to pick on Yglesias. In fact, I don’t blame him. Modern shows are just too good. As a result, it’s become accepted—even the norm—among elite, educated classes to watch inordinate amounts of TV.</p><p>Modern shows are different from classic TV in two key ways. First, they are much more engrossing. Netflix shows are just on a different level in terms of quality than what TV once offered. Second, they are bingeable. Instead of tuning in for an hour each week, Netflix encourages viewers to enter the dark hole of watching episode after episode after episode. This becomes a vicious cycle. Viewers binge late into the night, lose sleep, and then don’t feel energetic enough to do much in their free time the next day besides…watching more Netflix.</p><p>Movies were always pretty engrossing. But the boundless quantity of content on Netflix—as well as their deliberate addictiveness—puts it on a different level.</p><p>To be sure, the broad America public has always watched <a href="https://www.theatlantic.com/technology/archive/2018/05/when-did-tv-watching-peak/561464/">extraordinary amounts</a> of television, in particular retirees. For them, the improved quality of modern shows is surely an upgrade. But I do think Netflix has distinctly changed the culture around TV among the young and educated.</p><p>As an undergraduate at Columbia, it was extremely common for students to spend much of their free time engorging themselves on Netflix. Many were caught in that maelstrom of bingeing, losing sleep, and then bingeing more. What was most shocking was this practice’s sheer acceptability. Watching dozens of hours of Netflix a week wasn’t something out of the ordinary, something people were embarrassed by. Rather, Netflix bingeing was a core part of the culture, something people would make countless memes about and base their identities on. Amazingly, people’s chief complaint was often that they had exhausted all of Netflix’s content (how do you even do that?!).</p><p>Yglesias got his start blogging in college. Would the next Yglesias be able to do the same? Or would his free time and energy instead be sucked up by the latest, ever-more addictive Netflix show? What a loss for civilization that would be.</p><h2 id="for-a-new-temperance-movement">For a New Temperance Movement</h2><p>Again, I don’t blame the students. I am victim to the same human follies. But I do blame the culture we have created. We don’t tell our bright young minds that it’s alright to waste away your days drinking or abusing drugs. Sure, some end up doing so regardless, but the cultural tabu keeps those impulses in check. Why do we tell them it’s alright to waste away your days watching Netflix?</p><p>Indeed, there has been considerable pushback against video games, which for some are a similar time suck. While many still struggle, this cultural pushback has kept video games in check. At least among the educated classes, Netflix and its imitators have become the far greater time suck.</p><p>For those who can enjoy TV in moderation—great. Modern shows are often meaningful art worth appreciating. The problem with modern TV is that for many, it is closer to alcoholism than a one-off drink. One you watch that first episode—take that first drink—it often doesn’t stay at one episode—as it doesn’t stay at one drink.</p><p>Perhaps it is time for a modern TV-temperance movement. It would be worth encouraging moderation in TV consumption in general. But given that many TV habits resemble alcoholism, it may be appropriate to take a more radical approach: advocating TV-abstinence. Although complete avoidance of TV may be difficult at first, once it becomes a habit, I think most wouldn’t miss much. But they would enjoy an abundance of reclaimed time and energy. And the rest of us would enjoy the wonderful works they create with that newfound time and energy.</p><h2 id="brains-in-vats">Brains in Vats</h2><p>The culture we establish around Netflix matters not just for the present, but for what comes next. As entertainment technology relentlessly advances, are we destined to become brains in vats, nominally pumped full of artificial bliss but doomed to lives of passivity and complacency?</p><p>Look, if that’s what the Europeans want to do, they should go for it. But part of what makes America special is a certain harshness—first embodied in the Puritans and their quest to settle America’s unforgiving wilderness. Great achievements, new ideas, ingenious inventions emerge from a culture that prizes travail and perseverance, not one that prioritizes comfort and ephemeral satisfaction.</p><p>A blithe acceptance of Netflix has insidiously infiltrated our culture. We should push back. Let’s look to the stars, not the next episode.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to For Our Posterity</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
              <h2><span id="cove-count"></span> Comments</h2>

    <p>Sign in or become a For Our Posterity member to join the conversation.<br>
    Just enter your email below to get a log in link.</p>
    

  


  


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.forourposterity.com/against-netflix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277041</guid>
            <pubDate>Wed, 02 Dec 2020 15:15:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Escape the Modern Rat Race]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 87 (<a href="https://news.ycombinator.com/item?id=25276844">thread link</a>) | @durmonski
<br/>
December 2, 2020 | https://durmonski.com/psychology/escape-the-modern-rat-race/ | <a href="https://web.archive.org/web/*/https://durmonski.com/psychology/escape-the-modern-rat-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span>Last updated:</span><time datetime="2020-11-30T06:06:37+00:00">30/11/2020</time></p>
<p><em>The worst thing about our modern culture is the growing ignorance towards what’s really valuable in the world. From an early age, we join a long-distance rat race where the competition is measured not by who we are, but by what we own. Therefore, the desire for material possessions and attention from our peers become our chief goals. Survival, it seems to us, is based on how well we portray our qualities to the outside world – even if we don’t necessarily possess them.</em></p>



<p>Living a normal life according to our society, even if we don’t always admit it, is tightly connected to the acquisition of funds. One of the most talked-about traits promoted by institutions regardless of our location is the value of money. Of course, this is not directly mentioned by the media outlets or by our neighbors, it’s beautifully camouflaged by what money can buy.</p>



<p>As soon as we understand that all breathing humans worship money and stuff, the sooner we start to desire <a href="https://durmonski.com/psychology/why-we-hate-cheap-things/" target="_blank" aria-label="luxury items (opens in a new tab)" rel="noreferrer noopener">luxury items</a>. Not so much because they are useful, but because these fancy goods make us look like we are more.</p>



<p>And so it happens, that directly after we come into being, these values and principles get embedded in our brains and later influence our decisions. We want better and more beautiful things. But most of all, we want others to <em>see</em> that we actually own these marvelous objects.</p>



<p>This game of competitive signaling has become unbearable only recently. When the number of available choices vastly increased and the way we communicate with others (compare ourselves with them) significantly improved.</p>



<p>In this post, we’ll look at why we’re stuck in this competitive rat race. Why the desire to acquire new things is never tamed and what we can do about it. </p>



<p>By bringing awareness to the problems, I want to liberate more people from the destructive components of this never-ending race to the bottom.</p>







<h2>What is Rat Race Life?</h2>



<p>A modern rat race categorizes as an endless pursuit – often quite exhausting – where you earn small rewards by conspicuous behavior reinforced by acquiring more financial gains or possessions – or both. However, these gains never feel satisfactory enough. As new things constantly appear on the horizon – new products and new competitors who are also part of the race – the only way we can stay ahead of the curve is by constantly investing resources in this rivalry.</p>



<p>In a way, participating in this vain competition is required. After all, our survival is tightly related to the tools, the resources we personally own, plus the relationship we form with others. That’s why we stay devoted to the race – because deep inside, our genes are focused on survival and replication.</p>



<p>That’s the general concept of the modern rat race. Or in the words of Tyler Durden, the protagonist in the masterpiece Fight Club, “We buy things we don’t need with money we don’t have to impress people we don’t like.” But to really grasp the reasons we commit to a life of struggle over resources, we need to go a step deeper.</p>



<p>Let’s unpack the modern rat race ideology further…</p>







<h2>Why and How The Rat Race Was Formed?</h2>



<p>The first reference of the expression rat race was used in the 1930s during aviation training. As stated by Popular Science magazine in 1941, ‘A rat race is … a simple game of “follow the leader.'”<span id="easy-footnote-1-12306"></span><span><a href="#easy-footnote-bottom-1-12306" title="&amp;#8220;<a aria-label=&quot;Rat-race (opens in a new tab)&quot; rel=&quot;noreferrer noopener nofollow&quot; href=&quot;https://www.etymonline.com/search?q=rat+race&quot; target=&quot;_blank&quot; class=&quot;ek-link&quot;>Rat-race</a>&amp;#8220;. Online Etymology Dictionary."><sup>1</sup></a></span> Or in other words, the expression meant that the trainee fighter pilot had to copy all the actions performed by the senior pilot. </p>



<p>A decade later, the term changed its original meaning.</p>



<p>Nowadays, the expression is more closely related to how we live our lives day by day. We don’t simply “follow the leaders”, we compete with them. We want to be like them. To have what they have and to eventually beat them in the game of resources.</p>



<p>This fierce rivalry for wealth is inspired and fueled by three main motivators:</p>







<h3>1. The Genes Want to Survive</h3>



<p>We, our actions, are highly influenced by the desires of the microorganisms that form our bodies – our genes. According to Richard Dawkins, the author of <a aria-label="The Selfish Gene (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/the-selfish-gene/" target="_blank">The Selfish Gene</a>, “the main goal of the body is to propagate copies of the genes which ride inside it.” To achieve this feat, the body is required to strictly follow two commands: survive and replicate.</p>



<p>There is nothing more important for the genes. We live to live another day and to copy ourselves.</p>







<h3>2. Universal Recognition of Money</h3>



<p>Different religions exist in different countries but we are all loyal to one and only lord – the money lord. Or as Yuval Noah Harari writes in his bestseller, <a aria-label="Sapiens (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/sapiens-a-brief-history-of-humankind/" target="_blank">Sapiens</a>, “Money is the most universal and most efficient system of mutual trust ever devised.”</p>



<p>During the years of our existence, we form a love-hate relationship with money. On the one hand, we hate it when we see people who are willing to do whatever it takes to earn more and to gain more power. We have movies, literature, songs, and words that mock the aggressive pursuit of more cash.</p>



<p>On the other hand, however, we adequately recognize the need for this resource. Since money is the currency that can literally save our lives from misery and decay, we have no other choice but to obey some sort of rules to gain more of this finite resource. Even so, while it surely exists, our desire to get more money is usually not directly expressed. Throughout our lives, we learn to successfully decoy our desire for wealth. That’s actually why money is a taboo subject.</p>







<h3>3. Technological Advancements</h3>



<p>High-tech gizmos and the internet greatly exceeded our expectations. These two innovations enabled us to connected like no other species.</p>



<p>At first, we used the Wi-Fi connection to send emails and to communicate better. Now, we use it to showcase our self-worth and to advertise our qualities to the whole world. All of this, done with the underlying desire to feel more desirable by others.</p>







<hr>



<p>The three above-mentioned notes can be portrayed in the following way:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg" alt="the-modern-rat-race" srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg"><figcaption>The cravings for money, survival, being appreciated by others is something we don’t verbally express. We show it by the stuff we obtain and the things we say/do.</figcaption></figure>







<p>Our inner eagerness to survive forces us to obtain money. And cash, supports our existence. But for most, the comfort of holding large chunks of capital in the bank is not enough. We also want to be seen as wealthy.</p>



<p>After all, just owning money is not enough to increase your chances of survival – meeting new friends that will help you along the way and also potential mates. That’s why, we’re also eager to parade with what we have.&nbsp;&nbsp;</p>



<p>Just as the peacock spreads its feathers to show its impeccable genes, we, through our actions and the things we acquire, show the world our features hoping that they’ll pick us. This our way of saying to others, “Look at me, my qualities and traits are so good that I can afford to spend $50,000 on a car. You should want to hang around with me.”</p>



<p>Our possessions are an advertisement, a way of showing off. They reinforce the image we desire to portray. And by going around and talking about ourselves, we want to signal to others – in a non-verbal way in most of the cases – why we are a worthy choice.</p>



<p>This is also called competitive signaling.</p>







<h2>What is Competitive Signaling?</h2>



<p>The way you spend your money can say a lot about how you want to position yourself in modern competition. </p>



<p>If you think carefully about everything before you buy it, and you’re not interested in high-end goods, your income is either average or you’re careless of what others think of you. In contrast, if you focus primarily on obtaining premium goods, you’re probably either rich or you want to be perceived as rich.<span id="easy-footnote-2-12306"></span><span><a href="#easy-footnote-bottom-2-12306" title="The last two are completely different things."><sup>2</sup></a></span></p>



<p>Thorstein Veblen, an American economist and sociologist, argued that the demand for luxury goods is driven largely by a single social motive: “flaunting one’s wealth.”</p>



<p>For example, Nissan is a car. It’s an average, not-flashy, automobile that will help you go from point A to point B, faster. Porsche, on the other hand, is an art museum on wheels. It can also get you from point A to point B, but while driving around town in this beast on wheels you radiate a completely different vibe. You present yourself as a modern, high-paid individual with taste and ambition. Figuratively speaking, the amount of cash that each of them has in the bank – the person owning a Nissan and the person owning a Porsche – can be exactly the same. On the outside though, they appear quite different.&nbsp;&nbsp;</p>



<p>The more interesting thing to consider, if say the individuals in the above example really do have the same amount of cash stashed, is how they approach buying domestic goods – a set of dishes, blankets, or say cleaning products. Since these goods are not to be seen by others, they both, even the person owning a sports car, will most probably end up getting the same cheap things.<span id="easy-footnote-3-12306"></span><span><a href="#easy-footnote-bottom-3-12306" title="This, of course, says a lot more things about their personality. For example, you can have an average income and still get a flashy car. But then, the things that are not visible by others will probably be average to compensate. Conversely, if you&amp;#8217;re <em>really</em> rich, you&amp;#8217;ll probably buy luxury domestic goods, too."><sup>3</sup></a></span></p>



<p>With this, we can conclude that the available products on the market are a mix of personal value and signaling value.</p>



<p>The car you have is simultaneously a way to move faster in the city and also a representation of your hierarchy in the world. Each product on the market, nowadays, comes with these qualities.</p>



<p>And if we can put this in a graph, it will look something like this:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg" alt="luxury-goods-vs-useful-goods" srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg"><figcaption>Above the line the products don’t get more useful, they do something else. Luxury goods help you display, publicly, your wealth. The “scientific term” for this is conspicuous consumption.<span id="easy-footnote-4-12306"></span><span><a href="#easy-footnote-bottom-4-12306" title="<a aria-label=&quot;Conspicuous consumption (opens in a new tab)&quot; href=&quot;https://en.wikipedia.org/wiki/Conspicuous_consumption&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener nofollow&quot; class=&quot;ek-link&quot;>Conspicuous consumption</a>, Thorstein Veblen"><sup>4</sup></a></span></figcaption></figure>







<p>At some point, certain products become a beacon of your self-worth. If you want to signal to others that you have more money, which internally means that you want to show that you’re smarter, slimmer, better than others in a way, you’ll eventually lean towards goods that are considered a luxury.</p>



<p>The extra you’re paying for a Porche, for example, has more to do with the message you want to convey to others, not with the usefulness of the product itself.<span id="easy-footnote-5-12306"></span><span><a href="#easy-footnote-bottom-5-12306" title="We all know that Porche is certainly a great vehicle. But there are still cheaper alternatives that will do the same job in terms of helping you move from point A to point B."><sup>5</sup></a></span></p>



<p>You might be …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/psychology/escape-the-modern-rat-race/">https://durmonski.com/psychology/escape-the-modern-rat-race/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/psychology/escape-the-modern-rat-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276844</guid>
            <pubDate>Wed, 02 Dec 2020 14:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Many Customers Does a Successful Side Hustle Need? Just 99]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25276662">thread link</a>) | @i-dont-remember
<br/>
December 2, 2020 | https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/ | <a href="https://web.archive.org/web/*/https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane"><div><p>The founding stories of big tech companies get people pumped on the idea of starting their own thing, from <a href="https://en.wikipedia.org/wiki/Software_as_a_service" title="https://en.wikipedia.org/wiki/Software_as_a_service">SaaS</a> products to <a href="https://trends.vc/trends-0036-paid-newsletters/" title="https://trends.vc/trends-0036-paid-newsletters/">paid newsletters</a> . The concept sounds awesome. Build something, it picks up speed, and swiftly grows into a multi-million dollar company. It’s a crazy success story, you’re set for life! Silicon Valley has no shortage of examples to be gawked at: AirBnb, Amazon, Dropbox, Facebook, Google, Netflix, etc which all exploded in the last 15 years.</p><p>Once you start trying to create it, though, odds are your idea is not a runaway success. There are ideas where the problem is so important, so valuable, so sticky to businesses that you can give them the worst pile of garbage in the world and they will fork over bajillions of dollars. If you are in that camp and pulling in cash is as easy as drinking water, stop reading, this isn’t for you.</p><p>Getting users is really freakin’ hard. Getting customers who will pay you to use your idea is even harder. When you’re struggling to acquire new users, it’s frustrating to look at the big tech companies and realize they have millions, if not billions of users. How are you ever supposed to convince that many people your idea is awesome, but you’re struggling to get just 10.</p><p>Divorce yourself from the notion you need to match those giant tech companies. How many customers does it actually take to support one person? Is it a million? 100,000? 10,000? Try 99.</p><p>I’ll back it up with the math in a second, but for now, think about how awesome this is. 99 is an achievable number. You know more than 99 people on a first-name basis. You’ve waited in lines longer than 99 people! But, I’m just some guy on the internet saying this. Heck, for all you know I’m not actually a person, this is just a <a href="https://www.theverge.com/2020/8/16/21371049/gpt3-hacker-news-ai-blog" title="https://www.theverge.com/2020/8/16/21371049/gpt3-hacker-news-ai-blog">pile of words GPT-3 thinks sound nice together</a>. So let’s break it down and see how you only need 99 people’s support to make a drastic change to your life.</p><h2 id="assumptions--definitions">Assumptions &amp; Definitions</h2><p>Assumptions first. I’ll be calculating this for one person, but it should scale up if you have a team. When it comes to making money, I see several inflection points of Monthly Recurring Revenue (MRR).</p><ol><li>$1</li><li><strong>Beer Money (BM) MRR</strong> - $100</li><li><strong>Rent MRR</strong> - $1,000</li><li><strong>College Grad (CG) MRR</strong> - $5,000</li><li><strong>Magical (MA) MRR</strong> - $10,000</li></ol><p>Stage 1, you’ve made your first dollar. Somebody out there thinks your idea doesn’t suck. Celebrate this, it’s a big achievement! One caveat for your dollar, it does <strong>NOT</strong> count if it came from your mom.</p><p>At <strong>Beer Money MRR</strong>, you are making $100 every month. You have cracked the 3 digit barrier, and can buy a lot of beer/wine/cheese/whatever without feeling too guilty about your budget.</p><p><strong>Rent MRR</strong> is where things get good, this is $1,000 a month. In some places this isn’t enough to live on by itself, but it is life-changing money no matter where you are. It likely covers all or a good chunk of your rent, hence the name. If you are poo-pooing me for saying $1k MRR is a big deal, you should get your head out of your ass and look at the rest of the world outside your bubble.</p><p><strong>College Grad MRR</strong> is $5k a month. This is $60k a year, which is near the average for a college graduate in the U.S. and more importantly, the math is easy when it divides nice. No calculators needed to read this article!</p><p><strong>Magical MRR</strong> is the last stop for this train. This is $10k a month, which is a <strong>TON</strong> of money. You’ll have taxes and expenses and junk, but to have people paying you $120k a year to use your idea must feel fantastic. I call it magical because $10k gets thrown around a lot in indie hacker articles &amp; community as a magic number to reach.</p><h2 id="show-me-the-money">Show Me the Money!</h2><p>Ok we have some definitions locked in, now we’ll go through 2 product examples: <strong>Product A</strong> at $10 and <strong>Product B</strong> at $50, again keeping the math easy. This could be a <a href="https://en.wikipedia.org/wiki/Software_as_a_service" title="https://en.wikipedia.org/wiki/Software_as_a_service">SaaS</a> charging monthly, an eBook, a course, paid newsletter, whatever. We’re looking per month, so the specifics of what is pulling in the dough don’t matter for this article. I took a couple liberties to knock off 1 sale here and there to keep it to 2 or 3 digits, because seeing those inflection points is what inspires me personally. Only 2 digits of people? I can do that.</p><p><strong>Product A, $10:</strong></p><p><strong>BM =</strong> 10 people</p><p><strong>Rent =</strong> 99 people is all it takes</p><p><strong>CG =</strong> 500 people</p><p><strong>MA =</strong> 999 people a month need to feel like your idea is worth it</p><hr><p><strong>Product B, $50:</strong></p><p><strong>BM =</strong> 2 people</p><p><strong>Rent =</strong> 20 people is all it takes</p><p><strong>CG =</strong> 99 people</p><p><strong>MA =</strong> 200 people a month need to feel like your idea is worth it</p><p>You can reach a life changing amount of money from your side hustle, and you need to convince less than 1,000 people that what you do/create/build is worth it. It’s often thrown around that you need <a href="https://kk.org/thetechnium/1000-true-fans/" title="https://kk.org/thetechnium/1000-true-fans/">1,000 true fans</a>, or as the math would suggest, just 99. Out of <a href="https://www.worldometers.info/world-population/" title="https://www.worldometers.info/world-population/">7.8 billion</a> humans, you only need 99 in your corner to break the threshold to <strong>Rent MRR</strong>. It’s still a large group of people, don’t get me wrong. I would be terrified to give a speech to that crowd, but it’s small enough you can comprehend it. To make it even easier, let’s do some visualizations and connect these numbers to concrete concepts in our lives. Recognizing a connection with something you already know helps it feel achievable.</p><h3 id="20-people">20 People</h3><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>At some point in your life, you’ve been in a class greater than 20 people.</p><p>Your extended family gatherings are close to this many people.</p><p>You’ve likely been forced to give a presentation to <em>at least</em> this many listeners.</p><h3 id="99-people">99 People</h3><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>You’ve waited in lines longer than 99 people.</p><p>This is a small lecture hall, mostly full.</p><p>You could reasonably have a short conversation with 99 different people over the course of a day.</p><h3 id="200-people">200 People</h3><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>A couple hundred people could fit in a crowded bar or a conference presentation.</p><p>You can know the names and faces of 200 people with very little effort.</p><p>The majority of you have <a href="https://brandongaille.com/17-great-facebook-friend-statistics/" title="https://brandongaille.com/17-great-facebook-friend-statistics/">more than 200 friends on Facebook</a>.</p><p>If you’ve ever worked in a customer facing job, you’ve probably talked to more than 200 people in one shift!</p><h3 id="500-people">500+ People</h3><p><a href="https://blog.lime.link/visualizing-crowd-sizes/" title="https://blog.lime.link/visualizing-crowd-sizes/">This article</a> gives a great rundown of audience sizes from 50 to 100k people, and it’ll have to cover for the 500+ user visualizations. I won’t make you look at another 1499 emoji people. Okay, just one more. This is you making something awesome for all these people 👩‍💻 .</p><h2 id="the-real-world">The Real World</h2><p>The real world can be brutal when theories come into contact with it. It’s easy for me to sit here and talk about how you only need 99 customers to change your world, but you want to see something to back it up and show it still rings true out in the wild. Luckily, there are a lot of companies that share their stats as a part of being <a href="https://trends.vc/trends-0015-open-startups/" title="https://trends.vc/trends-0015-open-startups/">Open Startups</a>, many listed at <a href="https://openstartup.dev/" title="https://openstartup.dev/">https://openstartup.dev/</a> and <a href="https://baremetrics.com/open-startups" title="https://baremetrics.com/open-startups">https://baremetrics.com/open-startups</a>. You can also find great interviews on <a href="http://starterstory.com/" title="http://starterstory.com">starterstory.com</a>, where they go in-depth on how people started their businesses and their current revenue. Diving into a few data points from Nov 2020:</p><p>$1.3k : 124 users - <strong>Grip</strong> <a href="https://grip.baremetrics.com/" title="https://grip.baremetrics.com/"><em>https://grip.baremetrics.com/</em></a></p><p>$5.3k : 49 users - **Friendly **<a href="https://friendly.baremetrics.com/" title="https://friendly.baremetrics.com/"><em>https://friendly.baremetrics.com/</em></a></p><p>$7.0k : 144 users - <strong>Bannerbear</strong> <a href="https://www.bannerbear.com/open/" title="https://www.bannerbear.com/open/"><em>https://www.bannerbear.com/open/</em></a></p><p>$7.6k : 513 users - <strong>Simple Analytics</strong> <a href="https://simpleanalytics.com/open" title="https://simpleanalytics.com/open"><em>https://simpleanalytics.com/open</em></a></p><p>$9.0k : 479 users - <strong>Software Ideas</strong> (Paid reports/newsletter) <a href="https://softwareideas.baremetrics.com/" title="https://softwareideas.baremetrics.com/"><em>https://softwareideas.baremetrics.com/</em></a></p><p>$11k : 728 users - <strong>Hypefury</strong> <a href="https://hypefury.baremetrics.com/" title="https://hypefury.baremetrics.com/"><em>https://hypefury.baremetrics.com/</em></a></p><p>. . . . and then a crazy one</p><p>$<strong>133k</strong> : 871 users - **Baremetrics **<a href="https://demo.baremetrics.com/" title="https://demo.baremetrics.com/"><em>https://demo.baremetrics.com/</em></a></p><p>These companies are in all sorts of industries, they all have less than 1,000 users, and yet are making at minimum <strong>Rent MRR.</strong> While most of the Open Startups I listed are SaaS products built by developers, don’t be discouraged if you are non-technical or not interested in building software. There are examples out there of people growing non-technical products like ebooks, courses, newsletters, and more to sustain their livelihood if you take the time to look. Starter Story, mentioned above, is a collection of interviews &amp; ideas built up to <a href="https://www.starterstory.com/open" title="https://www.starterstory.com/open">$18k MRR in ~2 years</a>. Twitter and <a href="https://www.indiehackers.com/" title="https://www.indiehackers.com/">Indie Hackers</a> are great sources if you need even more inspiration.</p><h2 id="find-99-people-that-love-you">Find 99 people that love you</h2><p>If you haven’t gathered yet, the takeaway from all this is you don’t need to gun for crazy scale like the Facebooks of the world. You can aim to just support yourself. Find your true fans, as Kevin Kelley calls them in his essay <a href="https://kk.org/thetechnium/1000-true-fans/" title="https://kk.org/thetechnium/1000-true-fans/">1000 true fans</a>, and create for them.</p><p>This is not to trivialize the work needed to get to $100 MRR , or 10 users that love your product. It’s hard to get users. But making your vision more achievable helps keep the fire burning. It feels different pulling in the 1st of 99 people than the 1st of 100,000. So go forth and make something, you have the power and the global reach of the internet at your disposal. Go find 99 people that love your idea enough to pay you for it, and …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/">https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/</a></em></p>]]>
            </description>
            <link>https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276662</guid>
            <pubDate>Wed, 02 Dec 2020 14:35:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Cybersecurity Escape Room]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25276033">thread link</a>) | @atum47
<br/>
December 2, 2020 | https://eloeffler.gitlab.io/eloeffler/proto-vcser/ | <a href="https://web.archive.org/web/*/https://eloeffler.gitlab.io/eloeffler/proto-vcser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="indexgreeter">
    
<p>    Marwin Mueller, age 65, owns Spass GmbH. An SME in Luzern which has an annual turnover of close to 1.000.000 CHF and an annual profit of 200.000 CHF.  </p>
<p>    Spass GmbH has been operating in the hospitality industry for the last 30 years and is managing renouned hotels and villas in the Luzern Lake area.  </p>
<p>    Anne Kingston, age 29, is Marwins assistant and accountant. She has joined a year back and during her interactions, she mentioned to Marwin that she is a single mom of a six year old boy named Ryan.  </p>
<p>    Anne is a pleasant and helping personality. She likes plants and playing video games.  </p>
<p>    Marwin is very proud of his business achievements and sometimes acts as an arrogant boss. He is a bit insensitive to kids, due to his experiences. In general, he gets along with Anne and they form a great team at Spass. In the past year, Anne took over most of the office tasks at Spass. She is technology savvy and Marwin likes this quality of Anne's over his other staff.  </p>
<p>    Marwin and Anne worked on important digital initiatives at Spass like listing its properties on booking portals, creating their own website, launching social media accounts and enabling online banking at UBC Bank in Luzern.  </p>
<p>    This gave Marwin an edge over his competitors and Spass has seen a 30% increase in revenues and profits this year.  </p>
<p>    Today, Marwin remembers that two weeks back, Anne came to him and wanted a 1 week vacation to spend time with her son Ryan on occasion of his birthday.  </p>
<p>    Once again, Marwin and Anne had arguments on Anne's vacations in peak season and Marwin blamed Ryan for this.  At the end, Marwin reluctantly agreed to the holidays.</p>
<p>Since then, Anne did not turn up for work. She is not reachable on her mobile and her house is locked.</p>
<p>Marwin has just found that his bank account is debited with 2.000 CHF every day since Anne left.</p>
<p>Marwin has no idea what is happening and he is worried. Therefor, as trusted friends, he has requested that you come here and help him.</p>
<p>Marwin believes it is not a good idea to report the incident immediately to the police or bank as it can damage his reputation.</p>
<p>Now it's Friday. It's 7pm and the UBC Bank is already closed for the weekend.</p>
<p>You need to analyze the gaps Anne might have in her Cybersecurity awareness and secure the Online Banking to stop the money transfers.</p>
<p>Also, try to find out where Anne might be.</p>
<p>All the very best.
  </p></div></div>]]>
            </description>
            <link>https://eloeffler.gitlab.io/eloeffler/proto-vcser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276033</guid>
            <pubDate>Wed, 02 Dec 2020 13:15:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National parks of New Zealand in 3D]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25275588">thread link</a>) | @pheelicks
<br/>
December 2, 2020 | https://felixpalmer.github.io/new-zealand-3d/ | <a href="https://web.archive.org/web/*/https://felixpalmer.github.io/new-zealand-3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://felixpalmer.github.io/new-zealand-3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275588</guid>
            <pubDate>Wed, 02 Dec 2020 12:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK approves Pfizer vaccine for rollout next week]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25275329">thread link</a>) | @williamsharris
<br/>
December 2, 2020 | https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week | <a href="https://web.archive.org/web/*/https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>LONDON –</strong> Britain today became the first Western country to approve a Covid-19 vaccine for general use as it announced a rollout of Pfizer-BioNTech's drug from next week.&nbsp;</p>

<p>"The government has today accepted the recommendation from the independent Medicines and Healthcare products Regulatory Agency (MHRA) to approve Pfizer-BioNTech's Covid-19 vaccine for use," the Health Department said in a statement.</p>

<p>"The vaccine will be made available across the UK from next week," the statement said. Priority groups will include care home residents, health and care staff, the elderly and the clinically extremely vulnerable.</p>

<p>After months of "rigorous" clinical trials and thorough analysis of the data, the MHRA "concluded that the vaccine has met its strict standards of safety, quality and effectiveness", the statement added.</p>

<p>"To aid the success of the vaccination programme, it is vital everyone continues to play their part and abide by the necessary restrictions in their area so we can further suppress the virus and allow the NHS (National Health Service) to do its work without being overwhelmed."</p>

<p>Pfizer chairman Albert Bourla said it was a "historic moment in the fight against Covid-19".&nbsp;</p>

<p>"This authorisation is a goal we have been working toward since we first declared that science will win, and we applaud the MHRA for their ability to conduct a careful assessment and take timely action to help protect the people of the UK," he said.</p>

<p>Pfizer and BioNTech added that they expected further regulatory decisions from other countries "in the coming days and weeks".</p>

<p>The announcement came as England exited a month-long coronavirus lockdown, but most of the country remained under restrictions as a new regional system for cutting infection rates kicked in.</p>

<p>The four-week lockdown, which began last month, was imposed to stop surging rates of infection, ease pressure on health services, and to allow families to gather for Christmas.</p>

<p>Prime Minister Boris Johnson, a Covid survivor, succeeded in winning a vote on the measures in parliament late yesterday, despite significant opposition within his own Conservative ranks.</p>

<p>"All we need to do now is to hold our nerve until these vaccines are indeed in our grasp and indeed being injected into our arms," he told lawmakers before the vote.</p>

<p>Until then "we cannot afford to relax, especially during the cold months of winter", he warned. – AFP, December 2, 2020</p>

                
                

                <div>
                    <div>
                        <h2>Get news, from every side. Subscribe to our newsletter!</h2>
                        


                    </div>
                </div>
            </div></div>]]>
            </description>
            <link>https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275329</guid>
            <pubDate>Wed, 02 Dec 2020 11:06:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux kernel heap quarantine versus use-after-free exploits]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25274928">thread link</a>) | @kmwyard
<br/>
December 2, 2020 | https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html | <a href="https://web.archive.org/web/*/https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It's 2020. Quarantines are everywhere – and here I'm writing about one, too.
But this quarantine is of a different kind.</p>

<p>In this article I'll describe the <strong>Linux Kernel Heap Quarantine</strong> that I developed
for mitigating kernel use-after-free exploitation. I will also summarize
the discussion about the prototype of this security feature on the Linux Kernel
Mailing List (LKML).</p>



<p>Use-after-free (UAF) vulnerabilities in the Linux kernel are very popular for
exploitation. There are many exploit examples, some of them include:</p>
<ul>
  <li><a href="https://seclists.org/oss-sec/2016/q4/607">CVE-2016-8655</a></li>
  <li><a href="https://www.openwall.com/lists/oss-security/2017/02/26/2">CVE-2017-6074</a></li>
  <li><a href="https://a13xp0p0v.github.io/2017/03/24/CVE-2017-2636.html">CVE-2017-2636</a></li>
  <li><a href="https://ssd-disclosure.com/ssd-advisory-linux-kernel-af_packet-use-after-free/">CVE-2017-15649</a></li>
  <li><a href="https://a13xp0p0v.github.io/2020/02/15/CVE-2019-18683.html">CVE-2019-18683</a></li>
</ul>

<p>UAF exploits usually involve <strong>heap spraying</strong>.
Generally speaking, this technique aims to put attacker-controlled bytes at a defined memory
location on the heap. Heap spraying for exploiting UAF in the
Linux kernel relies on the fact that when <code>kmalloc()</code> is called, the slab
allocator returns the address of memory that was recently freed:</p>

<center><a href="https://a13xp0p0v.github.io/img/no_quarantine.png"><img src="https://a13xp0p0v.github.io/img/no_quarantine.png" width="60%"></a></center>


<p>So allocating a kernel object with the same size and attacker-controlled
contents allows overwriting the vulnerable freed object:</p>

<center><a href="https://a13xp0p0v.github.io/img/uaf.png"><img src="https://a13xp0p0v.github.io/img/uaf.png" width="70%"></a></center>


<p>Note: Heap spraying for out-of-bounds exploitation is a separate technique.</p>



<p>In July 2020, I got an idea of how to break this heap spraying technique for UAF
exploitation. In August I found some time to try it out. I extracted the slab
freelist quarantine from <a href="https://www.kernel.org/doc/html/latest/dev-tools/kasan.html">KASAN</a> functionality and called it <code>SLAB_QUARANTINE</code>.</p>

<p>If this feature is enabled, freed allocations are stored in the quarantine
queue, where they wait to be actually freed. So there should be no way for them
to be instantly reallocated and overwritten by UAF exploits.
In other words, with <code>SLAB_QUARANTINE</code>, the kernel allocator behaves like so:</p>

<center><a href="https://a13xp0p0v.github.io/img/with_quarantine.png"><img src="https://a13xp0p0v.github.io/img/with_quarantine.png" width="60%"></a></center>


<p>On August 13, <a href="https://www.openwall.com/lists/kernel-hardening/2020/08/13/7">I sent</a> the first early PoC to LKML and started deeper research of
its security properties.</p>



<p>For researching the security properties of the kernel heap quarantine, I developed
two <code>lkdtm</code> tests (<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/7">code is available here</a>).</p>

<p>The first test is called <code>lkdtm_HEAP_SPRAY</code>. It allocates and frees an object
from a separate <code>kmem_cache</code> and then allocates 400,000 similar objects.
In other words, this test attempts an original heap spraying technique for UAF
exploitation:</p>

<div><div><pre><code><span>#define SPRAY_LENGTH 400000
</span>    <span>...</span>
    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>...</span>
    <span>pr_info</span><span>(</span><span>"Original heap spraying: allocate %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>if</span> <span>(</span><span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"FAIL: attempt %lu: freed object is reallocated</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>
    
    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span>
        <span>pr_info</span><span>(</span><span>"OK: original heap spraying hasn't succeeded</span><span>\n</span><span>"</span><span>);</span>
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is disabled, the freed object is instantly
reallocated and overwritten:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000002b5b3ad4 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: FAIL: attempt 0: freed object is reallocated
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is enabled, 400,000 new allocations don't overwrite
the freed object:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000009909e777 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: OK: original heap spraying hasn't succeeded
</code></pre></div></div>

<p>That happens because pushing an object through the quarantine requires <strong>both
allocating and freeing memory</strong>. Objects are released from the quarantine as
new memory is allocated, but only when the quarantine size is over the limit.
And the quarantine size grows when more memory is freed up.</p>

<p>That's why I created the second test, called <code>lkdtm_PUSH_THROUGH_QUARANTINE</code>.
It allocates and frees an object from a separate <code>kmem_cache</code> and then performs
<code>kmem_cache_alloc()+kmem_cache_free()</code> for that cache 400,000 times.</p>

<div><div><pre><code>    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>

    <span>pr_info</span><span>(</span><span>"Push through quarantine: allocate and free %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>push_addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>push_addr</span><span>);</span>

        <span>if</span> <span>(</span><span>push_addr</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"Target object is reallocated at attempt %lu</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span> <span>{</span>
        <span>pr_info</span><span>(</span><span>"Target object is NOT reallocated in %d attempts</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>);</span>
    <span>}</span>
</code></pre></div></div>

<p>This test effectively pushes the object through the heap quarantine and
reallocates it after it returns back to the allocator freelist:</p>

<div><div><pre><code>  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000008fdb15c3 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182994
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000004e223cbe of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 186830
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000007663a058 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182010
</code></pre></div></div>

<p>As you can see, the number of the allocations needed for overwriting
the vulnerable object is almost the same. That would be good for stable
UAF exploitation and should not be allowed.
That's why I developed <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6"><strong>quarantine randomization</strong></a>. This randomization
required very small hackish changes to the heap quarantine mechanism.</p>

<p>The heap quarantine stores objects in batches. On startup, all
quarantine batches are filled by objects. When the quarantine shrinks,
I randomly choose and free half of objects from a randomly chosen batch.
The randomized quarantine then releases the freed object at an unpredictable moment:</p>

<div><div><pre><code>   lkdtm: Target object is reallocated at attempt 107884
   lkdtm: Target object is reallocated at attempt 265641
   lkdtm: Target object is reallocated at attempt 100030
   lkdtm: Target object is NOT reallocated in 400000 attempts
   lkdtm: Target object is reallocated at attempt 204731
   lkdtm: Target object is reallocated at attempt 359333
   lkdtm: Target object is reallocated at attempt 289349
   lkdtm: Target object is reallocated at attempt 119893
   lkdtm: Target object is reallocated at attempt 225202
   lkdtm: Target object is reallocated at attempt 87343
</code></pre></div></div>

<p>However, this randomization alone would not stop the attacker:
the quarantine stores the attacker's data (the payload) in the sprayed objects!
This means the reallocated and overwritten vulnerable object contains the payload
until the next reallocation (very bad!).</p>

<p>This makes it important to <strong>erase heap objects before placing them in the heap quarantine</strong>.
Moreover, filling them with zeros gives a chance to detect UAF
accesses to non-zero data for as long as an object stays in the quarantine (nice!).
That functionality already exists in the kernel, it's called <code>init_on_free</code>.
<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/5">I integrated it</a> with <code>CONFIG_SLAB_QUARANTINE</code> as well.</p>

<p>During that work I found a bug: in <code>CONFIG_SLAB</code>, <code>init_on_free</code> happens too
late. Heap objects go to the KASAN quarantine while still "dirty." I provided the fix
in a <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/4">separate patch</a>.</p>

<p>For a deeper understanding of the heap quarantine's inner workings, I provided an <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/8">additional
patch</a>, which contains verbose debugging (not for merge).
It's very helpful, see the output example:</p>

<div><div><pre><code>   quarantine: PUT 508992 to tail batch 123, whole sz 65118872, batch sz 508854
   quarantine: whole sz exceed max by 494552, REDUCE head batch 0 by 415392, leave 396304
   quarantine: data level in batches:
     0 - 77%
     1 - 108%
     2 - 83%
     3 - 21%
   ...
     125 - 75%
     126 - 12%
     127 - 108%
   quarantine: whole sz exceed max by 79160, REDUCE head batch 12 by 14160, leave 17608
   quarantine: whole sz exceed max by 65000, REDUCE head batch 75 by 218328, leave 195232
   quarantine: PUT 508992 to tail batch 124, whole sz 64979984, batch sz 508854
   ...
</code></pre></div></div>

<p>The heap quarantine <code>PUT</code> operation you see in this output happens during kernel memory freeing.
The heap quarantine <code>REDUCE</code> operation happens during kernel memory allocation, if the quarantine
size limit is exceeded. The kernel objects released from the heap quarantine return to the allocator
freelist – they are actually freed.
In this output, you can also see that on <code>REDUCE</code>, the quarantine releases some part of
a randomly chosen object batch (see the <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6">randomization patch</a> for more details).</p>



<p>I made <a href="https://www.openwall.com/lists/kernel-hardening/2020/10/01/7">brief performance tests</a> of the quarantine PoC on real hardware and in virtual machines:</p>
<ol>
  <li>
    <p>Network throughput test using <code>iperf</code> <br>
server: <code>iperf -s -f K</code> <br>
client: <code>iperf -c 127.0.0.1 -t 60 -f K</code></p>
  </li>
  <li>
    <p>Scheduler stress test <br>
<code>hackbench -s 4000 -l 500 -g 15 -f 25 -P</code></p>
  </li>
  <li>
    <p>Building the defconfig kernel <br>
<code>time make -j2</code></p>
  </li>
</ol>

<p>I compared vanilla Linux kernel in three modes:</p>
<ul>
  <li><code>init_on_free=off</code></li>
  <li><code>init_on_free=on</code> (upstreamed feature)</li>
  <li><code>CONFIG_SLAB_QUARANTINE=y</code> (which enables <code>i…</code></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</a></em></p>]]>
            </description>
            <link>https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274928</guid>
            <pubDate>Wed, 02 Dec 2020 09:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hackers can take full control of online compilers through a RCE exploit (2018)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25274699">thread link</a>) | @crecker
<br/>
December 2, 2020 | https://serhack.me/articles/hackers-full-control-of-online-compilers-through-a-common-exploit/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/hackers-full-control-of-online-compilers-through-a-common-exploit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://serhack.me/images/compilers/1.png" alt="Compilers security report"></p><p>Online compilers are a handy tool to save time and resources for coders, and are freely available for a variety of programming languages. They are useful for learning a new language and developing simple programs, such as the ubiquitous <a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program">“Hello World”</a> exercise. I often use online compilers when I am out, so that I don’t have to worry about locating and downloading all of the resources myself.</p><p>Since these online tools are essentially remote compilers with a web interface, I realized that I might be able to take remote control of the machines through command injection. My research identified a common weakness in many compilers: inadequate sanitization of user-submitted code prior to execution. My analysis revealed that this lack of input filtration enables exploits that an hacker can use to take control of the machine or deliberately cause it to crash.</p><p>A clever attacker can exploit built-in C functions and POSIX libraries to gain control over the computer hosting the online compiler. Commands like <a href="https://linux.die.net/man/3/execl">execl()</a>, <a href="https://linux.die.net/man/3/system">system()</a>, and <a href="https://linux.die.net/man/3/getenv">GetEnv()</a> can be used to probe the target machine operating system and run any command on its built-in shell.</p><p>I wanted to write this article to remind how sandboxed environment are important when shipping an application such as this!</p><h2 id="vulnerability-description">Vulnerability description</h2><p>In this section, I will introduce the reader to the vulnerability explaining both theory and practice processes.</p><h3 id="gaining-access">Gaining access</h3><p>In several of the C/C++ compilers that I analyzed, the GetEnv(), system(), functions allow an attacker to study and execute any command on the remote machine. The GetEnv() function allows a hacker to learn information about the machine that is otherwise concealed from the web interface, such as the username and OS version.</p><p>Once this information is revealed, the attacker can begin testing various exploits to achieve privilege escalation and gain access to a root shell. For example, the system() command can be used to execute malicious code and access sensitive data such as logs, website files, etc.</p><p>Since the exploit I discovered involves inserting hostile commands to gain control of an unwitting machine, this attack vector is classified as a <a href="https://en.wikipedia.org/wiki/Code_injection">code injection</a> vulnerability.</p><h3 id="maintaining-control">Maintaining control</h3><p>If hacker tries to run the online compiler every time they want to send a new command, the attack would leave an obvious trace, and the resource use might draw attention to the suspicious activity. These obstacles can be conveniently sidestepped by using the execl() function, which allows the user to specify any arbitrary program to replace the current process. An attacker can gain access to the machine’s built-in shell by invoking the execl() function to replace the current process with <code>/bin/sh</code>, with catastrophic implications.</p><p>Many compilers allow input from the browser, in which case the hacker can craft a program to relay input commands to the shell of the compromised machine. Once the hacker uses <code>execl()</code> to open a shell via browser, they can simply operate the remote machine using <code>system()</code> to inject various instructions. This avoids the need to run the compiler each time the attacker wishes to explore or exploit the compromised machine.</p><h3 id="implications">Implications</h3><p>A hacker that obtains shell access in this way gains access to files and services typically protected from outside users. The attacker now has many options at their disposal for exploiting the machine and/or wreaking havoc; how they proceed will depend on their tools and motives.</p><p>If the attacker wishes to crash the target machine, they can achieve this by (mis)using the fork() function, which creates <a href="https://serhack.me/articles/introduction-to-monerov-and-its-inherent-risks/"><del>a new cryptocurrency</del></a> clone of the current process. A fork() function placed within a while (true) loop will execute indefinitely, repeatedly cloning the process to greedily consumed precious RAM memory. This rapid uncontrolled use of resources will overwhelm the machine, causing a self-DOS (denial of service attack).</p><p>Instead of maliciously crashing a machine, an attacker may wish to monetize their illicit access. This can be accomplished by injecting a cryptocurrency miner, which will generate funds for the attacker at the expense of the victim’s computational resources and electric bill. My analysis showed that this maneuver allows useful exploitation of online compilers that successfully stymied other attacks by sandboxing the environment or adopting more advanced techniques to limit file access.</p><h3 id="theory">Theory</h3><p>This section documents the commands used to gain and maintain access to the online compiler. These functions require the unistd.h and stdlib.h libraries.</p><h4 id="execl">execl()</h4><h5 id="declaration">Declaration</h5><div><pre><code data-lang="c"><span>int</span> <span>execl</span>(<span>const</span> <span>char</span> <span>*</span>pathname, <span>const</span> <span>char</span> <span>*</span>arg, ...);</code></pre></div><p>Parameters:</p><ul><li><p><strong>pathname</strong> - char*, the name of the program</p></li><li><p><strong>arg</strong> - char*, arguments passed to the program, specified by _pathname_</p></li></ul><h6 id="description">Description</h6><p>The execl() function replaces the current process with a new process. This is the command exploited to maintain control over the remote machine without having to repeatedly use the online compiler. Reference the underlying <em>execve()</em> function for more details.</p><h4 id="system">system()</h4><h6 id="declaration-1">Declaration</h6><div><pre><code data-lang="c"><span>int</span> <span>system</span>(<span>const</span> <span>char</span><span>*</span> command);</code></pre></div><p>Parameters:</p><ul><li><strong>command</strong> - char* command name</li></ul><h6 id="description-1">Description</h6><p>The C system function passes the command name, specified by command, to the host’s built-in shell (/bin/sh for UNIX-based systems) which executes it. This function is based on execl(), so system() will be called by executing:</p><div><pre><code data-lang="c">execl(, <span>"sh"</span>, <span>"-c"</span>, command, (<span>char</span> <span>*</span>)<span>0</span>);</code></pre></div><p>This function returns the output of the command after it has been executed. If the shell encounters an error while executing the command, it will return the numeric value -1.</p><h4 id="getenv">GetEnv()</h4><h6 id="declaration-2">Declaration</h6><div><pre><code data-lang="c"><span>char</span> <span>*</span>getenv(<span>const</span> <span>char</span> <span>*</span>name)</code></pre></div><p>Parameters:</p><ul><li><strong>name</strong> - const char* variable name.</li></ul><h6 id="description-2">Description</h6><p>Retrieves a string containing the value of the environment variable whose name is specified as an argument ( <em>name</em> ). The function returns the contents of the requested environment variable as a string. If the requested variable is not part of the list of environments, the function returns a null pointer.</p><h3 id="proof-of-concepts">Proof of Concepts</h3><div><pre><code data-lang="C"><span>#include</span> <span>"stdio.h"</span><span>
</span><span>#include</span> <span>"unistd.h"</span><span>
</span><span></span>
<span>int</span> <span>main</span>(){
	 execl(<span>"/bin/sh"</span>,NULL,NULL); <span>// Open the shell 
</span><span></span>	 <span>return</span> <span>0</span>;
}</code></pre></div><div><pre><code data-lang="C"><span>#include</span> <span>"stdio.h"</span><span>
</span><span>#include</span> <span>"stdlib.h"</span><span>
</span><span></span>
<span>int</span> <span>main</span>(){
	system(<span>"whoami"</span>); <span>// Find username 
</span><span></span>	system(<span>"cd / &amp;&amp; ls"</span>); <span>// Lists all files and directories on /
</span><span></span>	<span>return</span> <span>0</span>;
}</code></pre></div><h3 id="solutions-sandboxed-environment">Solutions: sandboxed environment</h3><p>Thankfully, most of the risks highlighted above can be mitigated relatively easily. Access to protected files and services can be prevented by creating a secure sandbox for the application. This minimizes the potential for collateral damage and inappropriate data access, but will not prevent some attacks such as cryptocurrency miner injection. In order to avoid these “mining” attacks, the sandbox should have limited resources and it should be able to reboot itself every 10 minutes.</p><p>To eliminate the underlying weakness, the libraries could be recompiled without the particular exploitable functions. An attacker cannot gain a foothold if the execl() and system() are removed or disabled by recompiling libraries.</p><p>In addition to this, tools such as <a href="https://docker.com/">Docker</a> might be used to create a sandboxed environment. A sandbox is a mechanism to run applications in a limited space. It usually provides a restricted and controlled set of resources to the program that needs to be tested, such as a restricted area of memory or a set of limited system calls; normally, network access, the ability to inspect the host system or read from input devices, are disabled or highly restricted.</p><p>At the time of my search, I found at least two compilers with a non-sandboxed environment. I contacted the managers and they resolved in less than a week. For others I verified that they were actually under a sandboxed environment. Injected scripts were immediately identified and the “malicious” user was banned.</p><p>Do you have any suggestions for my articles? Please reach me at <a href="https://twitter.com/@serhack_">Twitter</a> or <a href="mailto:hi@serhack.me">send me an e-mail</a>.</p><h3 id="screenshot">Screenshot</h3><p><img src="https://serhack.me/images/compilers/2.png"></p><p><img src="https://serhack.me/images/compilers/3.png" alt="Shell opened">
<img src="https://serhack.me/images/compilers/4.png" alt="PoC code"></p></div></div>]]>
            </description>
            <link>https://serhack.me/articles/hackers-full-control-of-online-compilers-through-a-common-exploit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274699</guid>
            <pubDate>Wed, 02 Dec 2020 09:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Security: Getting Started with Dependabot]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25274169">thread link</a>) | @henrikwm
<br/>
December 1, 2020 | https://security.christmas/2020/2 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Integrating security as a part of application development is desirable, but it's often forgotten or dismissed in practice. Dependabot is a Github feature that will help you keep all your dependencies invulnerable and up-to-date, and you can enable it in just a few clicks!</p>
</section><article><section><p>I've often been told that integrating security as a role and shared responsibility in application development is important. Yet, in my experience, security is frequently given a low priority by developers. Progress is primarily estimated by looking at an application's new features, and security measures are considered invasive and complicating to our day-to-day-work. Luckily, there are tools that requires little effort to increase our focus on security, such as Github's Dependabot  </p>
<h2>What is Dependabot?</h2>
<p>Simply put, Dependabot is a tool designated to keep dependencies secure and up-to-date. How it works can be summarized in the following three steps:</p>
<ol>
<li>Dependabot scans your dependency files for outdated or insecure dependencies.</li>
<li>Dependabot creates pull requests for dependencies that need an update.</li>
<li>You review, test and merge Dependabot’s changes.</li>
</ol>
<p>Following Github's acquisition of Dependabot in May 2019, the feature was added natively to Github. With only a few clicks, Dependabot can easily be enabled from the Github dashboard, and help you keep your application’s dependencies up-to-date.</p>
<h2>Getting started</h2>
<p>Enough background information, let us talk about how to get started. Github's security settings can be configured for an <a href="https://docs.github.com/en/free-pro-team@latest/github/setting-up-and-managing-organizations-and-teams/managing-security-and-analysis-settings-for-your-organization">entire organization</a>, applying to all of the organization’s repositories, or it can be configured <a href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/managing-security-and-analysis-settings-for-your-repository">per repository</a>. Which is the better option depends on your context. If you are the owner of your organization and it is desirable to enable the security features across all of its repositories, obviously it would be less time consuming to configure this on the organization level, rather than for each repository individually. However, if you are a part of a large organization with lots of teams and projects, enabling Dependabot on the repository level might be the only option.</p>
<p>In this example, we will enable Dependabot on a single repository. In your repository, there should be a button titled “Security”. Note that the security option is only visible to administrators, hence it will not be visible if you don't have the admin role in the repository. </p>
<p><img src="https://i.ibb.co/kScW0pN/screenshot-2020-11-21-at-18-06-01-1.png" alt="To enable Dependabot, click on the &quot;Security&quot; button."></p>
<p>In the security overview, there is a row titled “Dependabot alerts”. If not already activated, there should be a button to “Enable Dependabot alerts”. Click it. You should now have three options that you can enable:</p>
<ul>
<li>Dependency graph</li>
<li>Dependabot alerts</li>
<li>Dependabot security updates</li>
</ul>
<h3>Dependency graph</h3>
<p>The dependency graph is a summary of the manifest and lock files stored in a repository. Enabling this feature is a prerequisite for the other options, as Dependabot requires access to the dependency graph in order to create alerts and updates.</p>
<h3>Dependabot alerts</h3>
<p>The alerts allows Dependabot to notify you when it finds a weakness. This is probably the key feature that you are here for. When activated, the number of unresolved alerts is highlighted in the "Security" button that we previously clicked. On the security tab, the alerts highlighting currently outdated dependencies are listed. By clicking on an alert, you will find more details on it, such as a description of the vulnerability and in what version of the dependency it was patched.</p>
<p><img src="https://i.ibb.co/VMrM5Kh/screenshot-2020-11-16-at-19-59-16.png" alt="Security: Dependabot alerts" title="Unresolved Dependabot alerts are listed in the repository."></p>
<h3>Dependabot security updates</h3>
<p>By enabling the third option, the security updates, whenever a vulnerable dependency is discovered, Dependabot will try to fix it. If it is possible to upgrade the vulnerable dependency without disrupting the dependency graph of the repository, Dependabot will generate a pull request bringing the dependency up-to-date. The pull request is given a compatibility score indicating whether the update could cause breaking changes. The number is based on the percentage of tests in public repositories that passed when performing the same update.</p>
<p><img src="https://i.ibb.co/2vr3GBb/dependabot-pull-request.png" alt="Example pull request generated by Dependabot" title="A pull request generated by Dependabot"></p>
<p>Unfortunately, in my experience working with Dependabot, more often than not, it is unable to generate pull requests. This is often because the source of the vulnerability is an indirect or transitive dependency. The Dependabot documentation states that <em>“(...) security updates are triggered only for dependencies that are specified in a manifest or lock file. Dependabot is unable to update an indirect or transitive dependency that is not explicitly defined.”.</em> This means that even though Dependabot is able to perform some automatic updates, you should expect to perform most of the updates yourself - for now.</p>
<p>Even though Dependabot is unable to perform automated dependency updates most of the time, I would recommend enabling the feature. Occasionally it <em>will</em> be able to create the pull request for you, and you'll have saved yourself a couple of minutes that you can spend on something else.</p>
<p><img src="https://i.ibb.co/xXLhGLr/dependabot-pr-error.png" alt="Error message: Dependabot cannot update to the required version" title="More often than not, Dependabot is unable to generate a pull request"></p>
<p>If you already have established an effective process to update your project's dependencies, Dependabot might not be able to help you. Otherwise, you should definitely give it a try. It's free, it takes minimal effort to set up and - no matter how you use it - it's a better option than not monitoring your dependencies in any way.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274169</guid>
            <pubDate>Wed, 02 Dec 2020 07:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reggie Fowler owes lawyers $600k]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25274167">thread link</a>) | @amycastor
<br/>
December 1, 2020 | https://amycastor.com/2020/12/02/man-linked-to-missing-bitfinex-tether-funds-owes-lawyers-600000/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2020/12/02/man-linked-to-missing-bitfinex-tether-funds-owes-lawyers-600000/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4872">
			<!-- .entry-header -->
		<div>
		
<p>Reggie Fowler, the former NFL minority owner linked to missing Tether and Bitfinex funds, owes his defense team more than $600,000, according to a new<a href="https://amyhcastor.files.wordpress.com/2020/12/106df130-d8cc-418e-bbc0-8e46715e7b0a.pdf"> court filing</a> on Tuesday.&nbsp;</p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg"><img loading="lazy" data-attachment-id="4875" data-permalink="https://amycastor.com/reginald-fowler/" data-orig-file="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg" data-orig-size="1644,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="reginald-fowler" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=241" data-large-file="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=822" src="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=822" alt="" width="313" height="390" srcset="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=313 313w, https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=626 626w, https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=120 120w, https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=241 241w" sizes="(max-width: 313px) 100vw, 313px"></a></figure></div>



<p>Fowler’s lawyers <a href="https://amycastor.com/2020/11/12/reginald-fowlers-lawyers-want-to-quit-did-he-neglect-to-pay-them/">want to drop out of the case</a> due to nonpayment, but they need to get permission from the court first.&nbsp;</p>



<p><a href="https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/">Last we left off</a>, U.S. District Judge Andrew Carter ordered attorneys at law firm Hogan Lovells—also representing defense lawyer Scott Rosenblum at Rosenblum Schwartz &amp; Fry—to file three versions of a sealed letter dated Nov. 18.</p>



<p>The public version—redacting what should not be revealed to the government or the public—discloses more details on the lawyers’ frustrations with a client who perpetually strings them along.&nbsp;</p>



<p>Hogan Lovells attorneys James McGovern and Michael Hefter initially asked for a $25,000 retainer in late 2018 when they first met with their client. Fowler only ever paid the retainer, and two years later, he now owes them $600,000.</p>



<p>His defense team believed all the stories he told them that he was swimming in money, so they weren’t too concerned—at first.</p>



<p>“From the very inception of this matter, we have been led to believe that Mr. Fowler is a high net worth individual with substantial assets, which would allow him to pay his legal bills with little hardship,” the lawyers said in their letter to the judge. </p>



<p>Hogan Lovells started working with Fowler on October 18, 2018. They had their first meeting with him on Nov. 8, 2018, around the time Fowler was initially contacted by the FBI. </p>



<p>“When we agreed to represent Mr. Fowler, it was our understanding that he had been targeted by cryptocurrency businessmen seeking to take advantage of Mr. Fowler’s personal balance sheet as a means of transacting cryptocurrency transactions without drawing the attention of bank compliance officers or regulators,” they said. </p>



<p>Fowler was later arrested in Chandler, Arizona, on<a href="https://www.justice.gov/usao-sdny/pr/arizona-man-and-israeli-woman-charged-connection-providing-shadow-banking-services"> </a>April 30, 2019. (<a href="https://www.justice.gov/usao-sdny/pr/arizona-man-and-israeli-woman-charged-connection-providing-shadow-banking-services">DoJ press release and indictment</a>.)</p>



<p>After his release in May <a href="https://amycastor.com/2019/05/11/reginald-fowler-man-at-center-of-cryptocurrency-scheme-out-on-5-million-bail/">on $5 million bail</a>, Fowler hired Scott Rosenblum to join the defense team. Rosenblum asked for a $275,000 retainer and an additional $85,000 per week retainer, if the case went to trial.&nbsp;Rosenblum received a partial retainer of $100,000, which Hogan Lovells notes that Fowler paid “while he had several unpaid, overdue invoices for legal services issued by Hogan Lovells.”&nbsp;</p>



<p>Additionally, Fowler paid another lawyer (unnamed) in Portugal in full for her services. He also paid international law firm Reed Smith LLP for&nbsp;services rendered in 2018.</p>



<p>“The fact that other attorneys had received payments from Mr. Fowler for their services led us reasonably to believe that Mr. Fowler’s representations to us that he would pay our bills was truthful,” the lawyers said.</p>



<p>In the second half of 2019, the lawyers were diligent about contacting Fowler for money. Each time they reached out, he told them payment was imminent and that “transactions or business deals that would fund the payment of our fees were in process”—but he never paid him.&nbsp;</p>



<p>In February, following a plea bargain that went awry and a superseding indictment, the defense team realized the case would likely go to trial, requiring a substantial amount of work, and still no check from their client. </p>



<p>Fowler has ample funds, they said, including “$10 million in real estate that is unencumbered and could have been liquidated or monetized at any point during the past two years.” His refusal to pay, the lawyers added, has “led to a breakdown in the attorney-client relationship.”</p>



<p>The government has till Dec. 8 to respond and replies are due Dec. 11.</p>



<p><em>If you like my work, please consider supporting my writing by subscribing to my&nbsp;<a href="https://www.patreon.com/amycastor">Patreon account</a>&nbsp;for as little as $5 a month.</em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://amycastor.com/2020/12/02/man-linked-to-missing-bitfinex-tether-funds-owes-lawyers-600000/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274167</guid>
            <pubDate>Wed, 02 Dec 2020 07:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enigma: Archaeologists find legendary Nazi cipher machine in the Baltic Sea]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25274023">thread link</a>) | @jhoechtl
<br/>
December 1, 2020 | https://www.de24.news/en/2020/12/enigma-archaeologists-find-legendary-nazi-cipher-machine-in-the-baltic-sea.html | <a href="https://web.archive.org/web/*/https://www.de24.news/en/2020/12/enigma-archaeologists-find-legendary-nazi-cipher-machine-in-the-baltic-sea.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="https://i1.wp.com/cdn.prod.www.spiegel.de/images/6020fe30-75d6-43d7-95e1-f6aea75091d4_w1280_r1.77_fpx39_fpy40.jpg?ssl=1" data-caption=""><img fifu-featured="1" width="696" height="" src="https://i1.wp.com/cdn.prod.www.spiegel.de/images/6020fe30-75d6-43d7-95e1-f6aea75091d4_w1280_r1.77_fpx39_fpy40.jpg?w=696&amp;resize=696%2C&amp;ssl=1" alt="" title=""></a></p>
 

<p>
As an archaeologist, Florian Huber is in the truest sense of the word with all waters. He searched for ancient Mayan antiquities in the flooded caves of the Yucatán, and dived to the bottom of fjords and deep alpine lakes. Again and again, however, the Kiel underwater researcher was drawn to the bottom of the Baltic Sea, where he tracked down wrecks or examined flora and fauna together with biologists.
</p>
<p>
It was here, of all places, that the well-traveled researcher made his most exciting discovery. Huber was actually working with two colleagues in the Geltinger Bucht, not far from Flensburg, in the service of environmental protection. The divers looked for ghost nets, abandoned fishing nets that become deadly traps for marine animals at the bottom.
</p>
<p>
From on board the “Mola Mola”, a nearly eight-meter-long motor catamaran, the researchers systematically scanned the sea floor with sonar. If the system detects a disused network or another object on the ground, the tracking device receives conspicuous sound pulses. The divers then slip into their suits, strap on their compressed air cylinders and drop backwards from the ship’s railing into the cold water to check.
</p>
 <p>
<a href="https://www.spiegel.de/wissenschaft/mensch/enigma-archaeologen-finden-legendaere-nazi-chiffriermaschine-in-der-ostsee-a-6058cbd5-6daf-49bb-937f-eb79b9423d56" target="_blank" rel="nofollow noopener noreferrer">Source link </a><br>
<a href="https://www.spiegel.de/wissenschaft/mensch/enigma-archaeologen-finden-legendaere-nazi-chiffriermaschine-in-der-ostsee-a-6058cbd5-6daf-49bb-937f-eb79b9423d56" target="_blank" rel="nofollow noopener noreferrer">https://www.spiegel.de/wissenschaft/mensch/enigma-archaeologen-finden-legendaere-nazi-chiffriermaschine-in-der-ostsee-a-6058cbd5-6daf-49bb-937f-eb79b9423d56</a></p>
 </div></div>]]>
            </description>
            <link>https://www.de24.news/en/2020/12/enigma-archaeologists-find-legendary-nazi-cipher-machine-in-the-baltic-sea.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274023</guid>
            <pubDate>Wed, 02 Dec 2020 07:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front: The $1.3B Startup Slackifying Email]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 129 (<a href="https://news.ycombinator.com/item?id=25272533">thread link</a>) | @bdr
<br/>
December 1, 2020 | https://sacra.com/research/front-inside-the-startup-slackifying-email/? | <a href="https://web.archive.org/web/*/https://sacra.com/research/front-inside-the-startup-slackifying-email/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="appMain">
      <article>
        <header>
          
          
          <div>
            <p><img src="https://images.prismic.io/sacra/869b3341-1d4e-4cdd-abfc-731301d0af9d_CleanShot+2020-09-04+at+16.02.20%402x.png?auto=compress,format&amp;rect=48,0,1148,1148&amp;w=48&amp;h=48"></p><address>
              Jan-Erik Asplund
            </address>
            <p><time pubdate="" datetime="12-01-2020">Published Dec 01st, 2020</time>
          </p></div>
        </header>
        <section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="email-is-just-a-wedge">Email is just a wedge</h2><p>Slack's meteoric growth won the headlines, generated case studies, and drew the admiration of venture capitalists and Wall Street investors alike.</p><p>But there's another company that—albeit growing more slowly—may have a much higher ceiling than the intra-team chat app.</p><p>Front is like Slack for your email, except instead of creating another distracting, noisy, always-on tool, Front allows users to spin up ephemeral chats within email threads themselves. </p><p>Instead of forwarding an email to a colleague or going into Slack to ask them a question that relates to a customer question or request, you can tag them into the thread and have a quick chat right in the context that's most useful.</p><p>At first, this sounds like a localized version of Slack—a niche tool. And Front was, at first, popular mostly with support teams and other teams that deal with a high volume of customer inquiries. But over time, Front has grown from being a product for a specific kind of workflow to being a tool that people use across organizations.</p><p>The fact is that most companies are still stuck in time from twenty years ago when it comes to managing how they triage, assign, and respond to all those emails. That's a big pain point, because as it turns out, a lot of the critical work that companies do takes place over email. </p><p>What Front has realized is that owning the orchestration and collaboration around email puts them in a position to “back into” $66B worth of vertical markets—CRM, project management, knowledge management, conversational marketing, and others.</p><p>To show the size of that opportunity and demonstrate the progress that Front has made towards its goal in this report, we aggregated all the public data out there on Front, then extrapolating and interpolating to fill in the gaps using backchannels to confirm our numbers.&nbsp;</p><p>We learned that Front, like Slack, has consumer-grade engagement, elite compounding revenue from their land and expand strategy, and increasingly broad adoption inside teams.</p><p>By focusing on external vs. internal communication, however, Front may also have a TAM that is several times as large as Slack's.</p><h2 id="front-s-roadmap-to--2b--4b--20b">Front's roadmap to $2B/$4B/$20B</h2><ul><li><strong>Our financial model values Front at $1.3B, with a price per share around $11.</strong> At their Series C in January, they were valued at $920M, or about $7.70~ per share.</li><li><strong>Front is currently trading on the secondary market between $7.25 and $9.00 per share.</strong> 5-year IRR for each scenario in our model ranges from 3% to 22% in the bear case, 22% to 46% in the base case, and 84% to 118% in the bull case.</li><li><strong>Front is like Slack for email</strong>. It is a multiplayer tool that lets teams better communicate—via chatting with other team members within the context of a personal or shared inbox—and coordinate—via tagging, rules, and 3rd-party integrations—how they respond to email.</li><li><strong>Front's 72% DAU/MAU ratio is on par with elite, consumer-grade apps</strong>. WhatsApp was at 70% pre-Facebook acquisition. Combined with its 148 minutes of average active daily usage (compare to Slack at 90 minutes) Front effectively has the engagement of a high-grade consumer app.</li><li><strong>Front's 137% net dollar retention demonstrates they are landing and expanding with an extremely efficient bottom-up model.</strong> Compare to 143% for Slack at IPO and 140% for Zoom at IPO.</li><li><strong>Zendesk and Intercom pose a threat because they have much deeper access to customer data. </strong>Intercom embeds itself in their customers' websites, giving them direct insight into the behavior of their customers, while Zendesk serves as a centralized hub for all things sales, support, and/or knowledge management for hundreds of thousands of companies.</li><li><strong>However, Front's high engagement platform makes them attractive to third-party developers. </strong>The more activity Front can promote on its platform, and the larger the variety of integrations their customers are using, the more adoption they'll have inside organizations and the wider their moat—based on the cost of switching away to another email product—will become.</li><li><strong>Expanding across organization opens up the opportunity to "back into" $66B worth of adjacent vertical markets </strong>. While today Front is focused on facilitating third-party integrations to tools like Hubspot, Marketo, and Salesforce, building their own versions of these products would allow them to (at minimum, and per product) 2-3x their average revenue per user—today, Zendesk's Enterprise plan costs $199 a seat, while Front's most expensive plan is just $79 per seat.</li><li><strong>Building their own vertical solutions also puts Front on a converging course with Salesforce ($226B), Microsoft ($1.63T), and Google ($1.19T).</strong> Front's endgame is essentially to recreate the Google or Office 365 suite. But Microsoft was able to overtake Slack's active user count within just two years—a company that had similar ambitions. The threat Microsoft/Google pose and their ability to freely push copycat products to a user base of millions could make it extremely challenging for Front to move upmarket and reach enterprise scale.</li><li><strong>Front's product also makes them an attractive acquisition target. </strong>Rather than attempt to build their own team email product, Microsoft and/or Google could buy Front. That said, Salesforce is the company most likely to acquire Front—both because they don't have any email tool of their own yet and because there's no risk of cannibalization or customer confusion as there would be with a Microsoft/Google acquisition.</li><li><strong>Ultimately, Front’s consumer-grade engagement and ability to achieve org-wide adoption position them well to compete on their own in the cloud productivity space</strong>. Most deep workflow products serve specific functional units (Intercom, Zendesk, Salesforce) while products that serve whole teams (Outlook, Gmail) have only superficial access to customer data. Front, on the other hand, is a workflow product and an org-wide tool all in one: a combination that could make them a formidable competitor even to the 800 lb. gorillas of B2B SaaS.
</li></ul><h2 id="valuation--front-is-worth--1-3b">Valuation: Front is worth $1.3B</h2><p>Today, based on our model, we estimate Front is worth about $1.3B, with a fair share price of $9.5 to $11.</p><p>That’s up 40% from Front’s Series C, which valued the company at about $7.7 per share or $920M post-money. At the time, Front was at $26M ARR growing 5% CMGR6 for a 35x multiple.&nbsp;</p><p>Today, we project Front is at about $38M ARR or $3.1M MRR, growing 3% CMGR6.&nbsp;</p><img src="https://images.prismic.io/sacra/731caebc-6ce9-4c26-8451-56f39d4618df_image13.png?auto=compress,format"><p><em>Applying the 35x multiple from Front’s last round to their current $38M revenue run rate gives us a valuation of $1.3B and an implicit per share price of $11. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Slack, for reference, was growing at 12% CMGR6 at the same ARR. According to our model, Front hasn’t grown at more than 10% CMGR6 since the summer of 2017, with growth hanging steady around 5% CMGR between April 2019 and early 2020, then declining slightly with the onset of COVID-19 in March.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/898c9394-e3df-4252-9a04-11f7995f0454_image33.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front today is at about $3.1M MRR, growing at 3% CMGR6. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s relatively slow and steady growth has been buoyed by impressive net dollar retention, though: 150% by their Series B and 137% by their Series C.&nbsp;</p><p>A large percentage of Front’s revenue comes from expansion versus bringing on new customers—based on our model, Front could grow at 2.66% monthly without any further investment in new customer acquisition.</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/6b8fe508-6373-4fae-a20b-49e5ea3c01e6_image6.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front’s -2.66% net monthly MRR churn creates a floor on growth. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s organic growth will be helped along by secular growth in the cloud-based productivity market.&nbsp;</p><p>Long-term, the total addressable market for cloud-based productivity tools is large and mostly unpenetrated, suggesting strong industry-wide growth for the next 10 to 15 years. Gartner estimates 1 billion knowledge workers worldwide. A 20% paid conversion rate with $100 - $300 contract value per year per user suggests $20 – 60 billion TAM.&nbsp;</p><p>Looking towards the future, Front’s bear, base, and bull cases hinge largely on whether the company’s growth will re-accelerate or whether it will continue to decline, and if so, how quickly it will do so:</p><ul><li>Our 5-year bull case has Front growing at 70% CAGR and reaching a $19B valuation ($600M ARR at a 30x multiple).</li><li>Our base case has them slowing to a steady 30% growth rate and being valued at a more modest $3.8B ($139M ARR on a 25x multiple).&nbsp;</li><li>In our bear case, Front’s growth slows even further, with the company reaching a …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/front-inside-the-startup-slackifying-email/?">https://sacra.com/research/front-inside-the-startup-slackifying-email/?</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/front-inside-the-startup-slackifying-email/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272533</guid>
            <pubDate>Wed, 02 Dec 2020 02:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NN-SVG: Generate publication-ready NN-architecture schematics]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25272360">thread link</a>) | @tzm
<br/>
December 1, 2020 | https://alexlenail.me/NN-SVG/AlexNet.html | <a href="https://web.archive.org/web/*/https://alexlenail.me/NN-SVG/AlexNet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    
                    <div id="collapsable">
                        <div id="AlexNet" role="tabpanel">


                            <h4>Style:</h4>
                            <div id="rendererType">
                                <p><label for="rendererType">Renderer</label></p><p><label>
                                         webGL
                                    </label>
                                </p>
                                <p><label>
                                         SVG
                                    </label>
                                </p>
                                <p><small>The SVG renderer is required to download SVG, however the WebGL renderer is required to show tensor dimensions.</small>
                            </p></div>

                            
                            <p>
                                <label for="color1">Color 1</label>
                            </p>
                            <p>
                                <label for="color2">Color 2</label>
                            </p>
                            <p>
                                <label for="color3">Color 3</label>
                            </p>
                            <p><label for="rectOpacity">Tensor Opacity</label>
                                
                            </p>
                            <div>
                            <p><label for="strideOpacity">Filter Opacity</label>
                                
                            </p>
<!--                             <div>
                                <label for="borderWidth">Border Width</label>
                                <input type="range" id="borderWidth" name="" min="0.01" max="3" step="0.01" value="1" style="position: relative; top: 3px;">
                            </div> -->
                            <p><label for="betweenLayers">Spacing Between Layers</label>
                                
                            </p>

                            <hr>
                            <p>
                                <label for="logDepth">Log Feature-Map Depth Scaling</label>
                            </p>
                            <p><label for="depthScale">Depth Size Scaling</label>
                                
                                <span id="depthSpan">10</span>
                            </p>
                            <p>
                                <label for="logWidth">Log Feature-Map Width Scaling</label>
                            </p>
                            <p><label for="widthScale">Width Size Scaling</label>
                                
                                <span id="widthSpan">10</span>
                            </p>
                            <p>
                                <label for="logConvSize">Log Convolutional Filter Size Scaling</label>
                            </p>
                            <p><label for="convScale">Convolutional Filter Scaling</label>
                                
                                <span id="convSpan">1</span>
                            </p>

                            <hr>
                            <p>
                                <label for="showDims">Show Tensor Dimensions</label>
                            </p>
                            <p>
                                <label for="showConvDims">Show Conv Dimensions</label>
                            </p>

                            <hr>
                            <h4>Architecture:</h4>
                            <div id="architecture">
                                <p>Height | Width | Depth | filter Height | filter Width</p>
                                
                                
                                
                                
                                
                                
                                
                            </div>

                            <hr>
                            

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexlenail.me/NN-SVG/AlexNet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272360</guid>
            <pubDate>Wed, 02 Dec 2020 01:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer Science Degree – Is it worthy it? Should You Get it?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25272222">thread link</a>) | @amiamigo
<br/>
December 1, 2020 | https://monalidor.com/computer-science-degree-is-it-worthy-it/ | <a href="https://web.archive.org/web/*/https://monalidor.com/computer-science-degree-is-it-worthy-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>This is my own journey on getting a CS degree and why I think you should or shouldn't major in Computer Science.</p><p>If you google right now, what are the best majors to study in college, it's a guarantee that Computer Science (CS) will be on almost every list. There are so many statistics about how much <a href="https://insights.dice.com/2019/06/12/computer-science-graduates-earnings/">CS graduates make</a>. At some big companies the likes of FAANG (Facebook, Amazon, Apple, Netflix, Google), fresh CS graduates can easily command six figures salaries, including benefits and cool perks. The total compensation in these companies is hardly less than six figures ($100,000)!</p><p>Computer Science is considered one of the top majors as far as ROI (Return on Investment) is concerned. Just year one out of school and into the workforce a CS grad will be making higher compared to grads from other majors. Even when someone isn't lucky enough to land one of the positions in big tech companies (FAANG), still they can easily make 55k fresh from school. <em>It should also be noted that the writer of this article is based in the US, so the figures here might not be so representative of other regions in the world.</em></p><p>So looking at the job prospects and earning potential, you can see why there is such a flux of students wanting to do CS in college.</p><p>And here is the question, should you major in Computer Science? </p><p>This post is about my journey on deciding to major in CS and why I would advise someone to major or not to major in CS. </p><p>...</p><p>December 2014, I got the news that I will be going to a small college in the Midwest of the United States for my college education. I was 23 by the time and at that point in my life, I had made some big life mistakes already (like quitting high school to become a professional athlete). As you might have guessed that didn't end well. 2 years and a half taught me a lot about life, dreams, aspirations. and most importantly it taught me about family...that will be a blog post for some other time. But there I was reading the email that in about 8 months I would be in school again for my bachelor's. Before quitting high school, I used to say to myself... "if I go to college I would study Psychology and Philosophy"...because the two fields really dug my intellectual curiosity. But when people asked me what would I do with Psychology or Philosophy...I didn't know what to tell them...I only knew I wanted to learn more about the two fields. I wasn't interested in a professional career in any of the two fields...just wanted to study them. Did that ever happen to you?</p><p>So I didn't want to make the same mistakes I did during high school years...I intentionally made a choice of choosing a major field of study that will be lucrative and pretty much guarantee me success. There I was googling the best majors to study in college.</p><p>Here is a short snippet of that research:</p><figure><img src="https://monalidor.com/content/images/2020/11/Majors-That-Pay-Back.png" alt="Majors That Pay You Back" srcset="https://monalidor.com/content/images/size/w600/2020/11/Majors-That-Pay-Back.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Majors-That-Pay-Back.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Majors-That-Pay-Back.png 1600w, https://monalidor.com/content/images/2020/11/Majors-That-Pay-Back.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Majors That Pay You Back</figcaption></figure><figure><img src="https://monalidor.com/content/images/2020/11/Major-vs-Salary.png" alt="Major vs Salary Potential" srcset="https://monalidor.com/content/images/size/w600/2020/11/Major-vs-Salary.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Major-vs-Salary.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Major-vs-Salary.png 1600w, https://monalidor.com/content/images/2020/11/Major-vs-Salary.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Major vs Salary Potential</figcaption></figure><p>Armored with that research plus a lot of other information I got from friends who were already studying CS and those who graduated with good jobs, I narrowed to Computer Science.</p><p>...</p><p>Fall 2015, my first year in college:</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Fall-2015-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2015-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2015-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2015-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2015-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Spring-2016-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2016-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2016-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2016-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2016-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Fall 2015 (Left) &amp; Spring 2016(Right) CS Classes</figcaption></figure><p>Sophomore year, Fall 2016</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Fall-2016-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2016-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2016-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2016-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2016-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Spring-2017-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2017-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2017-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2017-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2017-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Fall 2016 (Left) &amp; Spring 2017 (Right) CS Classes</figcaption></figure><p>By the end of Spring semester 2017, I had completed<strong> 22 credits of the 46 credits</strong> required by the CS program at my school.</p><p>In the fall of 2017, I didn't return back to campus...I had an opportunity to study abroad in London where for the whole semester I didn't take any Computer Science class. The school offered just general classes like Art History, Psychology, Religion, etc. In short, the study abroad program was a mixture of travel experience and study.</p><p>...</p><p>Junior Year, 2018</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Spring-2018-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2018-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2018-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2018-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2018-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Fall-2018-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2018-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2018-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2018-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2018-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Spring 2018 (Left) &amp; Fall 2018 (Right) CS Classes</figcaption></figure><p>Senior Year, 2019</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Spring-2019-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2019-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2019-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2019-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2019-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Fall-2019-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2019-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2019-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2019-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2019-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Spring 2019 (Left) &amp; Fall 2019 (Right) CS Classes</figcaption></figure><p>That was the order in which I took most of my CS classes, I dropped a few classes during my time and had to take them in the semesters that followed. But for easy of following through I just listed in the order of the first time I took them. In addition, I took one elective from another school which was <strong>CS 428</strong> <strong>Network Programming, </strong>and also I took <strong>EN 300C,</strong> an <strong>Advanced Writing</strong> class from another department in my school which substituted for my <strong>Technical Writing</strong> class in my CS major. And one more <strong>Math class</strong> was required to satisfy the requirements for the CS major.</p><p>So in a nutshell, that was my major. 4.5 or 5 years later, <strong>46 CS credits</strong> bagged and I graduated with a bachelor's in Computer Science.</p><p>The reason I listed all those classes above is to give you kinda a full picture of what a CS degree is about. When you just hear the words 'Computer Science', you might not really know what it's about...So the subjects above will at least shade some light. However, if you really wanna dive deep, I would suggest not just to look at the subjects offered in the program BUT make sure you read the syllabus too if you're able to get one. Syllabi will list topic by topic and week by week of exactly what the specific CS subjects will cover, there will be no surprises!</p><p>...</p><p>Now comes the meat of my blog post...Should you major in Computer Science?</p><p>Taking the money component out - we already know that a CS major can result in higher earning potential overall. What other reasons are there for you to major in Computer Science? Are you even interested in the field itself?</p><p>Most people when they hear about the Tech fields or Silicon Valley or working at Google or Microsoft, they mostly think about Computers and they might think about Computer Science as a way to get there, though they might not really know much about the Computer Science field itself.</p><p>I don't blame them, I was in the same situation...Initially I thought Computer Science will be learning about how to create these beautiful websites that I see on the Internet. Or maybe by studying Computer Science I will be able to make the next Facebook, Instagram and so forth. That was what initially clouded my mind.</p><p>Some of you might be surprised to know that a career in tech especially the one involving Computer Science or Programming for that matter...might not necessarily constitute you making products from scratch. There will be a lot of trying to understand, fix and maintain past code base. It might not be as alluring as some of the TV shows might make you believe. The technologies you work with might not be the ones of your interest. For example, I have never liked C# as a programming language or .NET framework as a web dev platform but there I was at my first job...using Windows, Visual Studio and .NET framework. You can imagine how excited I was.</p><p>...</p><p>As someone who has traveled this journey though not for so long, I can't emphasize enough on the importance of knowing exactly what you're getting yourself into. After all, college is a big investment both in terms of money and time, so pick both your majors and careers carefully. One way of getting a good feel for what you're getting yourself into, either it's Computer Science or any other field is to make sure you get some internships while in college. Get an internship in something you're either majoring in or considering a career in. That will give you real-world experience of what your profession will look like once you graduate. It will give you time to think about the work culture, the work hours, the pressure, the work itself, etc. ...I had a friend in college who after doing an internship for about 4 months or so...he found out a career in Computer Science or programming wasn't for him. And he went ahead and changed his major from Computer Science to Economics, on the way he secured a minor in Computer Science.</p><figure><img src="https://monalidor.com/content/images/2020/12/Monalidor---Do-you-like-your-job.png" alt="Do you like your job?" srcset="https://monalidor.com/content/images/size/w600/2020/12/Monalidor---Do-you-like-your-job.png 600w, https://monalidor.com/content/images/size/w1000/2020/12/Monalidor---Do-you-like-your-job.png 1000w, https://monalidor.com/content/images/size/w1600/2020/12/Monalidor---Do-you-like-your-job.png 1600w, https://monalidor.com/content/images/2020/12/Monalidor---Do-you-like-your-job.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Do you like your job?</figcaption></figure><p>One of the things that will make you like your job is by first enjoying studying the field that you're in. Do you enjoy the field you're majoring in?</p><p>Look at the classes I listed above, do they interest you in any way? If they do then congrats! A CS program might be a good fit. But don't just end there like I said in the beginning...I would like you to go and check the syllabus for all those classes and see what you will study week in and week out. </p><p>Let me tell you something... as someone who was more interested in web development...I didn't enjoy most if not all of my CS classes. Had I used that time to learn more about web design and development...learning specific languages used for the job I would have benefited more and enjoyed my time in college. Here am talking about web development technologies like JavaScript, PHP and their frameworks together with WordPress, SASS, the JAM stack, etc.</p><p>So what am I trying to say here..? If the reason you decided to get into a CS program is because you love to design and develop websites...then you might be in the wrong place...a CS class in Computational modeling will be pretty much a bore to you. You would appreciate that time instead if you were learning first hand the tools and languages you will be working with in the real world.</p><p>Walk this process backward...ask yourself...who do you want to become...a web developer? a software engineer? a UI/UX engineer? a database administrator..? a network engineer? Then once you know whom you want to become...look for resources that will allow you to do that...these might involve a major in college, maybe a minor, books, online courses, tools used in the industry, etc.</p><p> If you pick a major, don't be blinded by a bracket name like a 'Computer Science'. Understand exactly what that entails...go and look at the syllabus of each course you will take in that major. Don't just assume a CS major will grant you those mobile or web development skills etc. The job market can be very specific...They might look for a Java developer, a PHP developer, a Python developer, an iOS developer etc. While knowledge of one language might help you easily pick up another one...it's a good thing if you can focus on what you're interested in early on. </p><p>...Being a mobile developer is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://monalidor.com/computer-science-degree-is-it-worthy-it/">https://monalidor.com/computer-science-degree-is-it-worthy-it/</a></em></p>]]>
            </description>
            <link>https://monalidor.com/computer-science-degree-is-it-worthy-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272222</guid>
            <pubDate>Wed, 02 Dec 2020 01:18:25 GMT</pubDate>
        </item>
    </channel>
</rss>
