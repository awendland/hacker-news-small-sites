<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 10 Aug 2020 00:49:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 10 Aug 2020 00:49:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Bootstrap finance and the cost of other people's money [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24090104">thread link</a>) | @sturza
<br/>
August 8, 2020 | http://library.cust.edu.pk/teacher_resources/Cases&Articles/Entrepreneurship/BootstrapFinance-TheArtofStart-Ups.pdf | <a href="https://web.archive.org/web/*/http://library.cust.edu.pk/teacher_resources/Cases&Articles/Entrepreneurship/BootstrapFinance-TheArtofStart-Ups.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://library.cust.edu.pk/teacher_resources/Cases&amp;Articles/Entrepreneurship/BootstrapFinance-TheArtofStart-Ups.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24090104</guid>
            <pubDate>Sat, 08 Aug 2020 08:43:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intel, ARM, IBM, AMD Processors Vulnerable to New Side-Channel Attacks]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24089281">thread link</a>) | @beefhash
<br/>
August 7, 2020 | https://modernnetsec.io/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks/ | <a href="https://web.archive.org/web/*/https://modernnetsec.io/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><a href="https://modernnetsec.io/wp-content/uploads/2020/08/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks-1.jpg"><amp-img alt="Side-Channel Attacks" data-original-height="380" data-original-width="728" src="https://modernnetsec.io/wp-content/uploads/2020/08/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks-1.jpg" title="Side-Channel Attacks" width="728" height="380" layout="intrinsic" i-amphtml-layout="intrinsic"><img alt="Side-Channel Attacks" src="https://modernnetsec.io/wp-content/uploads/2020/08/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks-1.jpg" title="Side-Channel Attacks" width="728" height="380" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzM4MCcgd2lkdGg9JzcyOCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a></div>
<p>It turns out that the root cause behind several previously disclosed speculative execution attacks against modern processors, such as <a href="https://thehackernews.com/2018/01/meltdown-spectre-vulnerability.html" target="_blank" rel="noopener noreferrer">Meltdown</a> and <a href="https://thehackernews.com/2018/08/foreshadow-intel-processor-vulnerability.html" target="_blank" rel="noopener noreferrer">Foreshadow</a>, was misattributed to ‘prefetching effect,’ resulting in hardware vendors releasing incomplete mitigations and countermeasures.</p>
<p>Sharing its findings with The Hacker News, a group of academics from the Graz University of Technology and CISPA Helmholtz Center for Information Security finally revealed the exact reason behind why the kernel addresses are cached in the first place, as well as presented several new attacks that exploit the previously unidentified underlying issue, allowing attackers to sniff out sensitive data.</p>
<p>The <a href="https://arxiv.org/pdf/2008.02307.pdf" target="_blank" rel="noopener noreferrer">new research explains</a> microarchitectural attacks were actually caused by speculative dereferencing of user-space registers in the kernel, which not just impacts the most recent Intel CPUs with the latest hardware mitigations, but also several modern processors from ARM, IBM, and AMD — previously believed to be unaffected.</p>
<div>
<a href="https://go.thn.li/contrast" rel="nofollow noopener sponsored noreferrer" target="_blank" title="cybersecurity"><amp-img alt="cybersecurity" src="https://modernnetsec.io/wp-content/uploads/2020/08/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks-2.jpg" width="728" height="90" layout="intrinsic" i-amphtml-layout="intrinsic"><img alt="cybersecurity" src="https://modernnetsec.io/wp-content/uploads/2020/08/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks-2.jpg" width="728" height="90" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzkwJyB3aWR0aD0nNzI4JyB4bWxucz0naHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmcnIHZlcnNpb249JzEuMScvPg=="></amp-img></a>
</div>
<p>“We discovered that effects reported in several academic papers over the past 4 years were not correctly understood, leading to incorrect assumptions on countermeasures,” the researchers told The Hacker News.</p>
<p>“This <a href="https://gruss.cc/files/prefetch.pdf" target="_blank" rel="noopener noreferrer">prefetching effect</a> is actually unrelated to software prefetch instructions or hardware prefetching effects due to memory accesses and instead is caused by speculative dereferencing of user-space registers in the kernel.”</p>
<p>Besides analyzing the actual root cause of the prefetching effect, some other key findings from the research are:</p>
<ul>
<li>Discovery of several new attacks exploiting the underlying root cause, including an address-translation attack in more restricted contexts, direct leakage of register values in specific scenarios, and an end-to-end Foreshadow exploit targeting non-L1 data.</li>
<li>A novel cross-core covert channel attack that, in some instances, could let attackers observe caching of the address (or value) stored in a register without relying on shared memory.</li>
<li>Spectre ‘prefetch’ gadgets can directly leak actual data, which not only makes <a href="https://thehackernews.com/2019/11/zombieload-cpu-vulnerability.html" target="_blank" rel="noopener noreferrer">ZombieLoad attack</a> efficient on Intel CPUs to leak sensitive data from internal buffers or memory but also impact non-Intel CPUs.</li>
<li>The speculative dereferencing issue — in certain attacks like <a href="https://thehackernews.com/2020/03/rowhammer-vulnerability-ddr4-dram.html" target="_blank" rel="noopener noreferrer">Rowhammer</a>, cache attacks, and DRAMA — could let attackers recover the physical addresses of JavaScript variables and exfiltrate information via <a href="https://gruss.cc/files/rowhammerjs.pdf" target="_blank" rel="noopener noreferrer">transient execution</a> remotely via a web browser.</li>
</ul>
<p>Additionally, researchers also demonstrated that the Foreshadow vulnerability on Intel CPUs could be exploited even when the recommended mitigations are enabled. This is made possible due to the fact the attack can be mounted on data not residing in L1 cache on kernel versions containing ‘prefetch’ gadgets.</p>
<h2>From Address Translation Attack to Foreshadow</h2>
<p>The idea behind this is straight-forward. System software relies on the CPU’s address translation mechanism to implement isolation among different processes. Each process has its own virtual memory space and cannot access arbitrary physical memory addresses outside of it.</p>
<p>[embedded content]</p>
<p>Address translation, thus, acts as an intermediate layer that maps the virtual address space, which is used by a program, to the physical address to a physical address.</p>
<p>The virtual address space also includes a kernel address space to house Linux kernel threads, thus making it easy for the underlying hardware to handle privileged instructions from user threads in kernel mode.</p>
<p>While operating system kernels can be secured against prefetch side-channel attacks via a technique called kernel page-table isolation (<a href="https://en.wikipedia.org/wiki/Kernel_page-table_isolation" target="_blank" rel="noopener noreferrer">KPTI</a> or <a href="https://gruss.cc/files/kaiser.pdf" target="_blank" rel="noopener noreferrer">KAISER</a>) — which enforces a strict kernel and userspace isolation such that the hardware does not hold any information about kernel addresses while running in user mode — the researchers found that it does not guarantee full protection from address-translation attacks, where an attacker tries to check if two different virtual addresses map to the same physical address.</p>
<p>Put differently, the “address-translation attack allows unprivileged applications to fetch arbitrary kernel addresses into the cache and thus resolve virtual to physical addresses on 64-bit Linux systems.”</p>
<p>While the original line of thought was that such attacks were related to prefetch instructions, the new finding proves otherwise, thereby validating that KAISER isn’t an adequate countermeasure against microarchitectural side-channel attacks on kernel isolation.</p>
<p>Instead, it exploits a Spectre-BTB-SA-IP (Branch Target Buffer, same address, in-place) gadget to cause information leakage, causing speculative execution, and further carry out Meltdown and Foreshadow (L1 Terminal Fault) attacks by bypassing current L1TF mitigations.</p>
<p><a href="https://thehackernews.com/2018/11/meltdown-spectre-vulnerabilities.html" target="_blank" rel="noopener noreferrer">Spectre-BTB-SA-IP</a> is a variant of <a href="https://arxiv.org/pdf/1811.05441.pdf" target="_blank" rel="noopener noreferrer">Spectre vulnerability</a> that exploits the Branch Target Buffer — a cache-like component in CPUs that’s used for branch prediction — to perform attacks within the same address space and the same branch location.</p>
<p>“The same prefetching effect can be used to perform Foreshadow,” the researchers said. “If a secret is present in the L3 cache and the direct-physical map address is derefenced in the hypervisor kernel, data can be fetched into the L1. This reenables Foreshadow even with Foreshadow mitigations enabled if the unrelated Spectre-BTB mitigations are disabled.”</p>
<p>“The consequence is that we are able to mount a Foreshadow attack on older kernels patched against Foreshadow with all mitigations enabled and on a fully patched kernel if only Spectre-v2 mitigations are disabled.”</p>
<h2>Enable Spectre-BTB mitigations such as Retpoline</h2>
<p>To highlight the impact of the side-channel attacks, the researchers established a cache-based covert channel that exfiltrated data from a process running on an Intel Core i7-6500U CPU to another stealthy process, achieving a transmission rate of 10 bit/s to relay a total of 128 bytes from the sender to the receiver process.<br>Furthermore, the researchers disclosed that it’s possible to leak register contents from an SGX enclave of Intel CPUs using a register that’s speculatively dereferenced (called “Dereference Trap”), using it to recover a 32-bit value stored in a 64-bit register within 15 minutes.</p>
<p>Lastly, ‘certain attacks’ can now be mounted remotely using JavaScript in a web browser, and “fill 64-bit registers with an attacker-controlled value in JavaScript by using WebAssembly.”</p>
<p>To mitigate these attacks, it’s recommended that current CPUs enable Spectre-BTB mitigations, including <a href="https://support.google.com/faqs/answer/7625886" target="_blank" rel="noopener noreferrer">retpoline</a> (short for “return trampoline”), which aims to <a href="https://software.intel.com/security-software-guidance/insights/deep-dive-retpoline-branch-target-injection-mitigation" target="_blank" rel="noopener noreferrer">prevent branch-target-injection</a> by isolating <a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor" target="_blank" rel="noopener noreferrer">indirect branches</a> from speculative execution.</p>
</div></div>]]>
            </description>
            <link>https://modernnetsec.io/intel-arm-ibm-amd-processors-vulnerable-to-new-side-channel-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24089281</guid>
            <pubDate>Sat, 08 Aug 2020 05:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alcohol as a social technology to check the trustworthiness of others (2014)]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 255 (<a href="https://news.ycombinator.com/item?id=24088202">thread link</a>) | @searchableguy
<br/>
August 7, 2020 | https://hndex.org/7798063 | <a href="https://web.archive.org/web/*/https://hndex.org/7798063">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>

<a href="https://news.ycombinator.com/item?id=7798063" target="_blank">comments</a> <a href="https://plus.google.com/+KajSotala/posts/hofuxyXz78j" target="_blank">original article</a></header>
<p>Ohhh, never thought of this hypothesis: that the act of getting
drunk together might be a social technology that helps us verify
the trustworthiness of others by inhibiting their higher cognitive
functions and thus making it harder to consciously fake things.
That would make sense.</p>
<p>&gt; To enhance our natural thin-slicing abilities, humans have
therefore also developed various cultural practices that make these
instant assessments more reliable. These techniques take advantage
of the fact that deception is fundamentally a cold-cognition act
and relies on cognitive control centers. This means that if we can
impair the cognitive control abilities of people we're trying to
judge, we’ll do a better job of sussing them out: they will
be less able to confuse our cheater-detection systems.</p>
<p>&gt; In one study that has proven enormously useful to law
enforcement agencies, researchers found that police officers could
significantly improve their ability to detect false statements if
suspects were asked to give their alibis in reverse order, starting
with the most recent event and working their way back. This is not
the way we normally tell stories, so being forced to do it
increases cognitive load. Dishonest suspects, it turns out, are
less effective liars if you handicap their conscious minds in this
way.</p>
<p>&gt; This reverse-order alibi technique is a great tool for law
enforcement but not terribly practical when evaluating a potential
business partner or deciding if the people you’re about to
make a peace treaty with are being sincere. There are other ways to
achieve the same effect, though. The police study aimed to reduce
subjects’ cognitive control ability by increasing the
load-adding more weight, as it were. Alternately, you can keep the
load constant but decrease cognitive control ability-weaken the
mental muscles-by suppressing cognitive control centers. One way to
do this is transcranial magnetic stimulation (TMS), which involves
applying a powerful magnetic force to the appropriate region of the
skull. TMS, however, is a very recent technology and not exactly
widely available. Also, in most cultures it’s considered bad
form to shock the heads of new acquaintances with huge magnets.</p>
<p>&gt; A much more low-tech and socially acceptable way to produce
the same effect is to get someone completely wasted. As we
discussed in chapter 6, one of the primary effects of alcohol and
other intoxicants is to "downregulate," or temporarily paralyze,
areas of the prefrontal cortex associated with cognitive control. A
couple shots of tequila is the liquid equivalent of a nice jolt of
TMS. It’s therefore no accident that intoxicants of various
sorts are frequently employed by human beings as social lubricants.
Alcohol, kava, cannabis, magic mushrooms, you name it: any
intoxicant that people can get their hands on quickly comes to play
a central role in social occasions, both formal and informal. In
ancient China, no major treaty was signed without first bringing
everyone together in an extended, alcohol-soaked banquet. In fact,
this is one feature of Chinese culture that has not changed a bit
in over four thousand years. Any modern businessperson hoping to
ink a deal with Chinese partners had better get his or her liver in
shape first.</p>
<p>&gt; On a less formal level, this is no doubt why intoxicants
are a universal feature of all sorts of human social gatherings,
from casual cocktail parties to fraternity mixers. Not only is
getting drunk pleasant, it also typically causes people to get
along more freely and easily (at least to a certain point, after
which the drunken fights break out). Intoxication enhances
cooperation in at least two ways. First of all, it reduces social
faking by inhibiting cognitive control centers. Second, if we all
get drunk together, we create a situation of mutual vulnerability
that makes trust easier to establish. Getting drunk is essentially
an act of mental disarmament. In the same way that shaking right
hands with someone assures them that you’re not holding a
weapon, downing a few tequila shots is like checking your
prefrontal cortex at the door. See? No cognitive control. You can
trust me.</p>
<p>Excerpt From: Slingerland, Edward. "Trying Not to Try." Crown
Publishing Group, 2014-03-04. ﻿</p>
</article></div>]]>
            </description>
            <link>https://hndex.org/7798063</link>
            <guid isPermaLink="false">hacker-news-small-sites-24088202</guid>
            <pubDate>Sat, 08 Aug 2020 01:32:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating a Server to AWS]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24087614">thread link</a>) | @pcast
<br/>
August 7, 2020 | https://www.iobasis.com/How-Migrate-a-server-to-AWS/ | <a href="https://web.archive.org/web/*/https://www.iobasis.com/How-Migrate-a-server-to-AWS/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Migrating a server to the cloud</em> always sounds great. But we know it’s a hassle. Especially for servers in production. We want a new server, but keeping current data. And we need to migrate it fast with minimum service disruption.</p>
<p>It takes some time to understand how to do it. Therefore I wrote a <strong>step-by-step guide</strong> to make migration simple and repeatable. Here is how I did it.</p>
<p>
  <span>
    <span>
      <img alt="Intro" title="" src="https://www.iobasis.com/static/8d61fb2550e39d4d1476d5512d9afb97/4b190/How-to-migrate-a-server-to-AWS.jpg" srcset="https://www.iobasis.com/static/8d61fb2550e39d4d1476d5512d9afb97/e07e9/How-to-migrate-a-server-to-AWS.jpg 200w,
https://www.iobasis.com/static/8d61fb2550e39d4d1476d5512d9afb97/066f9/How-to-migrate-a-server-to-AWS.jpg 400w,
https://www.iobasis.com/static/8d61fb2550e39d4d1476d5512d9afb97/4b190/How-to-migrate-a-server-to-AWS.jpg 800w,
https://www.iobasis.com/static/8d61fb2550e39d4d1476d5512d9afb97/e5166/How-to-migrate-a-server-to-AWS.jpg 1200w,
https://www.iobasis.com/static/8d61fb2550e39d4d1476d5512d9afb97/b17f8/How-to-migrate-a-server-to-AWS.jpg 1600w,
https://www.iobasis.com/static/8d61fb2550e39d4d1476d5512d9afb97/0f98f/How-to-migrate-a-server-to-AWS.jpg 1920w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<h2>1. Creating a CloudEndure Account</h2>
<p>The tool I used is CloudEndure. This is a free tool that orchestrates migration tasks. To get started, I created a <a href="https://console.cloudendure.com/#/register/register">CloudEndure account</a>. I received a confirmation email. And afterward, I was able to log in to CloudEndure console.</p>
<h2>2. Granting Access to AWS Account</h2>
<p>The first step in the console was creating a new project.</p>
<p>
  <span>
    <span>
      <img alt="Adding access key ID and secret access key" title="" src="https://www.iobasis.com/static/e62f6c9eac1269c4728b5f760976cd0a/5a190/CloudEndure01.png" srcset="https://www.iobasis.com/static/e62f6c9eac1269c4728b5f760976cd0a/772e8/CloudEndure01.png 200w,
https://www.iobasis.com/static/e62f6c9eac1269c4728b5f760976cd0a/e17e5/CloudEndure01.png 400w,
https://www.iobasis.com/static/e62f6c9eac1269c4728b5f760976cd0a/5a190/CloudEndure01.png 800w,
https://www.iobasis.com/static/e62f6c9eac1269c4728b5f760976cd0a/7e4a6/CloudEndure01.png 952w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>Note that the CloudEndure account is different from the AWS account. So I needed to create a user that gives CloudEndure access to my AWS account. I followed the steps described in <a href="https://docs.cloudendure.com/#Generating_and_Using_Your_Credentials/Working_with_AWS_Credentials/Generating_the_Required_AWS_Credentials/Generating_the_Required_AWS_Credentials.htm">Generating the Required AWS Credentials</a>. The result was an access key ID and a secret access key.</p>
<p>Then I added these credentials in CloudEndure console and click Save. This verified that CloudEndure got access to my AWS account. And the project changed from <em>“Project not setup”</em> to <em>“Project not fully setup”</em> status.</p>
<p>
  <span>
    <span>
      <img alt="Setting Replication Settings" title="" src="https://www.iobasis.com/static/b63c54ee57aade1dc4ce326fa92dcbd3/5a190/CloudEndure02.png" srcset="https://www.iobasis.com/static/b63c54ee57aade1dc4ce326fa92dcbd3/772e8/CloudEndure02.png 200w,
https://www.iobasis.com/static/b63c54ee57aade1dc4ce326fa92dcbd3/e17e5/CloudEndure02.png 400w,
https://www.iobasis.com/static/b63c54ee57aade1dc4ce326fa92dcbd3/5a190/CloudEndure02.png 800w,
https://www.iobasis.com/static/b63c54ee57aade1dc4ce326fa92dcbd3/97bfd/CloudEndure02.png 1078w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<h2>3. Defining Replication Settings</h2>
<p>Once communication with AWS is enabled, the next step was configuring the migration project details. I set the migration source to <em>“Other Infrastructure”</em> (because the server to migrate was located on-premises). And I set the target to <em>“AWS US East (Northern Virginia)”</em>. That was the region chosen to migrate the server.</p>
<p>That project tab also had these settings:</p>
<ul>
<li>Replication instance type</li>
<li>Converter instance type</li>
<li>Disks types (SSD or standard)</li>
<li>Subnet (where Replication Servers will be launched)</li>
<li>Security Groups (for Replication servers)</li>
<li>Network Bandwith Throttling</li>
</ul>
<p>Note that the <strong>replication instances</strong> are used to continuously sync your source disks to the cloud. CloudEndure completely manages them.</p>
<p>Apart from these, CloudEndure uses temporary <strong>converter instances</strong>. They adapt the source disks just before launching the target machine, so they can boot and run in the cloud. This might include changing the bootloader and adding drivers for the new HW.</p>
<p>In my case, I just used default settings, and click <em>“Save replication Settings”</em>. And I got a <em>“Project setup complete”</em> message.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure project setup complete" title="" src="https://www.iobasis.com/static/5c4d3d5e1f6676482cb11fc622f6a34e/a6d36/CloudEndure03.png" srcset="https://www.iobasis.com/static/5c4d3d5e1f6676482cb11fc622f6a34e/772e8/CloudEndure03.png 200w,
https://www.iobasis.com/static/5c4d3d5e1f6676482cb11fc622f6a34e/e17e5/CloudEndure03.png 400w,
https://www.iobasis.com/static/5c4d3d5e1f6676482cb11fc622f6a34e/a6d36/CloudEndure03.png 650w" sizes="(max-width: 650px) 100vw, 650px">
    </span>
  </span>
  </p>
<h2>4. Verifying Agent Requirements</h2>
<p>The <em>“Cloudendure agent”</em> is a small program to install on the source machine. It connects to CloudEndure and sends the disks data to <em>“replication servers”</em> on the AWS account. The replication is continuous. So any change in the source is automatically sent to the cloud.</p>
<p>First I checked CloudEndure <a href="https://docs.cloudendure.com/Content/Getting_Started_with_CloudEndure/Supported_Operating_Systems/Supported_Operating_Systems.htm">supported operating systems</a>. Ubuntu is supported from version 12.04. So my OS was supported.</p>
<p>I also checked the other agent <a href="https://docs.cloudendure.com/Content/Installing_the_CloudEndure_Agents/Agent_Installation_Requirements/Agent_Installation_Requirements.htm">installation prerequisites</a>. All these verifications makes sure that the agent works correctly in the source machine.</p>
<h2>5. Installing the Agent</h2>
<p>Then I installed the CloudEndure agent on the source server. The <em>“Machine”</em> window on CloudEndure console showed how to install the agent.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure agent installation instructions" title="" src="https://www.iobasis.com/static/e6fccda739f4a9d99b3816d12447d156/5a190/CloudEndure04.png" srcset="https://www.iobasis.com/static/e6fccda739f4a9d99b3816d12447d156/772e8/CloudEndure04.png 200w,
https://www.iobasis.com/static/e6fccda739f4a9d99b3816d12447d156/e17e5/CloudEndure04.png 400w,
https://www.iobasis.com/static/e6fccda739f4a9d99b3816d12447d156/5a190/CloudEndure04.png 800w,
https://www.iobasis.com/static/e6fccda739f4a9d99b3816d12447d156/0f67e/CloudEndure04.png 921w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>For Linux source machines, there are 2 commands. The first one downloads the agent. And the second one installs it. This command also has a code (the <em>“Agent Installation Code”</em>) that links the agent to a particular CloudEndure account.</p>
<p>The installation wasn’t as simple as it appeared. I had to use <code>python3</code> command (instead of <code>python</code>). The first installation also failed. The agent didn’t detect the root disk correctly. But I removed the <code>--no-prompt</code> argument from the second installation command. That allowed me to specify the correct device <code>/dev/sda</code> during the installation process.</p>
<p>The second installation had issues also. CloudEndure agent couldn’t establish a connection to the console. In order to solve this, I installed some packages (<code>make</code>, <code>openssl</code>, <code>wget</code>, <code>curl</code>, <code>gcc</code>, and <code>build-essential</code>). This solved the problem and the agent was finally installed. Both product documentation and <code>~/cloudendure.log</code> were useful for troubleshooting.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure agent installed" title="" src="https://www.iobasis.com/static/6cce179e8a0a83e3acead559400a4259/76cea/CloudEndure05.png" srcset="https://www.iobasis.com/static/6cce179e8a0a83e3acead559400a4259/772e8/CloudEndure05.png 200w,
https://www.iobasis.com/static/6cce179e8a0a83e3acead559400a4259/e17e5/CloudEndure05.png 400w,
https://www.iobasis.com/static/6cce179e8a0a83e3acead559400a4259/76cea/CloudEndure05.png 799w" sizes="(max-width: 799px) 100vw, 799px">
    </span>
  </span>
  </p>
<h2>6. Replicating Disk</h2>
<p>After installing the agent, a row appeared in the <em>“Machines”</em> tab of CloudEndure console, and it showed the source server’s name (<em>“ubuntu”</em>).</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure new source machine" title="" src="https://www.iobasis.com/static/6cbea1d7ca1d3b0b154b537e2a1d6be2/5a190/CloudEndure06.png" srcset="https://www.iobasis.com/static/6cbea1d7ca1d3b0b154b537e2a1d6be2/772e8/CloudEndure06.png 200w,
https://www.iobasis.com/static/6cbea1d7ca1d3b0b154b537e2a1d6be2/e17e5/CloudEndure06.png 400w,
https://www.iobasis.com/static/6cbea1d7ca1d3b0b154b537e2a1d6be2/5a190/CloudEndure06.png 800w,
https://www.iobasis.com/static/6cbea1d7ca1d3b0b154b537e2a1d6be2/3dde1/CloudEndure06.png 1018w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>That row also showed the status of the replication. For example, at the moment of the screenshot, replication was 3.78% complete. And the ETA to get full replication was <em>“An hour”</em>. This indicator is very useful when you need to sync lots of data (or your upload bandwidth is limited).</p>
<p>I also noticed that CloudEndure launched a <strong>t3.small</strong> machine on the target region.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure replication server" title="" src="https://www.iobasis.com/static/843277e88d0bc650ef2fc1b7981ec69e/5a190/CloudEndure07.png" srcset="https://www.iobasis.com/static/843277e88d0bc650ef2fc1b7981ec69e/772e8/CloudEndure07.png 200w,
https://www.iobasis.com/static/843277e88d0bc650ef2fc1b7981ec69e/e17e5/CloudEndure07.png 400w,
https://www.iobasis.com/static/843277e88d0bc650ef2fc1b7981ec69e/5a190/CloudEndure07.png 800w,
https://www.iobasis.com/static/843277e88d0bc650ef2fc1b7981ec69e/4ff83/CloudEndure07.png 843w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>That instance was used as the <strong>Replication instance</strong>. It runs when there is any replication in progress. And it replicates up to 15 source volumes simultaneously.</p>
<p>I also noticed that CloudEndure created 2 EBS volumes:</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure EBS Volumes" title="" src="https://www.iobasis.com/static/7dcd217a12ee248e880a4175081dcf8a/227ba/CloudEndure08.png" srcset="https://www.iobasis.com/static/7dcd217a12ee248e880a4175081dcf8a/772e8/CloudEndure08.png 200w,
https://www.iobasis.com/static/7dcd217a12ee248e880a4175081dcf8a/e17e5/CloudEndure08.png 400w,
https://www.iobasis.com/static/7dcd217a12ee248e880a4175081dcf8a/227ba/CloudEndure08.png 769w" sizes="(max-width: 769px) 100vw, 769px">
    </span>
  </span>
  </p>
<p>Both volumes were attached to the replication server. The first one was intended to store the replicated data. And the volume size was the same as the source disk (in this case 8 GiB). And the second volume was for the <strong>replication server</strong> software.</p>
<p>I also found that CloudEndure created snapshots of these volumes. I found multiple snapshots of my disc, as shown below.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure EBS Snapshots" title="" src="https://www.iobasis.com/static/f035b9fe3ffeaa9115782c893733a0f8/5a190/CloudEndure09.png" srcset="https://www.iobasis.com/static/f035b9fe3ffeaa9115782c893733a0f8/772e8/CloudEndure09.png 200w,
https://www.iobasis.com/static/f035b9fe3ffeaa9115782c893733a0f8/e17e5/CloudEndure09.png 400w,
https://www.iobasis.com/static/f035b9fe3ffeaa9115782c893733a0f8/5a190/CloudEndure09.png 800w,
https://www.iobasis.com/static/f035b9fe3ffeaa9115782c893733a0f8/6c745/CloudEndure09.png 893w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<h2>7. Completing Replication</h2>
<p>After some time, the sync finished. It took me around 2 hours to sync an 8 Gb disk. Here is a screenshot of the console at that moment:</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Sync finished" title="" src="https://www.iobasis.com/static/4d22c1882462ebd90bfcd6252636399c/5a190/CloudEndure10.png" srcset="https://www.iobasis.com/static/4d22c1882462ebd90bfcd6252636399c/772e8/CloudEndure10.png 200w,
https://www.iobasis.com/static/4d22c1882462ebd90bfcd6252636399c/e17e5/CloudEndure10.png 400w,
https://www.iobasis.com/static/4d22c1882462ebd90bfcd6252636399c/5a190/CloudEndure10.png 800w,
https://www.iobasis.com/static/4d22c1882462ebd90bfcd6252636399c/e24fe/CloudEndure10.png 1073w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>Note that the Data Replication Progress changed to <em>“Continuous Data Replication”</em>. That means there was an EBS volume with a complete replica of my source volume. And that any changes were replicated instantly to AWS.</p>
<p>By clicking in the target machine row, I was able to see the details of the machine in CloudEndure. And the main characteristics of the source server were also described there (e.g. CPUs, Memory, OS, Disks, and installed packages).</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Machine Details" title="" src="https://www.iobasis.com/static/631057def589e8d5c0da54ab2a4adfa0/4597d/CloudEndure11.png" srcset="https://www.iobasis.com/static/631057def589e8d5c0da54ab2a4adfa0/772e8/CloudEndure11.png 200w,
https://www.iobasis.com/static/631057def589e8d5c0da54ab2a4adfa0/e17e5/CloudEndure11.png 400w,
https://www.iobasis.com/static/631057def589e8d5c0da54ab2a4adfa0/4597d/CloudEndure11.png 631w" sizes="(max-width: 631px) 100vw, 631px">
    </span>
  </span>
  </p>
<p>The Blueprint tab described the Target configuration. These are the settings of the target server to launch in AWS.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Machine BluePrint" title="" src="https://www.iobasis.com/static/211938a6c9fd54555cdc886eab1c9403/4597d/CloudEndure12.png" srcset="https://www.iobasis.com/static/211938a6c9fd54555cdc886eab1c9403/772e8/CloudEndure12.png 200w,
https://www.iobasis.com/static/211938a6c9fd54555cdc886eab1c9403/e17e5/CloudEndure12.png 400w,
https://www.iobasis.com/static/211938a6c9fd54555cdc886eab1c9403/4597d/CloudEndure12.png 631w" sizes="(max-width: 631px) 100vw, 631px">
    </span>
  </span>
  </p>
<p>CloudEndure automatically defines the settings of the target machine (for example machine type, subnets, IP, Security Group, and Disk Type). These settings are very important because they define the new EC2 instance characteristics. It’s important to review these settings and adjust default values if necessary.</p>
<p>In my case, I just adjusted a few parameters. First, I changed the machine type to t3.medium. I also set the <em>“Private IP”</em> to <em>“Create new”</em>. This assigns the target machine an IP in the target subnet. And also changed the disk type to SDD. That was all I needed to fine-tune my new server.</p>
<h2>8. Testing the Launch</h2>
<p>The next step was making sure that the server migration would be successful. So I made a test launch before final migration. This is started with the <em>“Launch Target Machines”</em> button.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Test Launch" title="" src="https://www.iobasis.com/static/6e9b2130ecb217a1a1f27f8bbd014b1e/8b153/CloudEndure13.png" srcset="https://www.iobasis.com/static/6e9b2130ecb217a1a1f27f8bbd014b1e/772e8/CloudEndure13.png 200w,
https://www.iobasis.com/static/6e9b2130ecb217a1a1f27f8bbd014b1e/8b153/CloudEndure13.png 366w" sizes="(max-width: 366px) 100vw, 366px">
    </span>
  </span>
  </p>
<p>This process creates the new EC2 instance with the migrated volume. That was completed in 7 minutes. And I found the new EC2 instance in the AWS Console. That was very fast.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Instances created on Test Launch" title="" src="https://www.iobasis.com/static/d6a32080e7205bc329dc32e11b089d45/5a190/CloudEndure14.png" srcset="https://www.iobasis.com/static/d6a32080e7205bc329dc32e11b089d45/772e8/CloudEndure14.png 200w,
https://www.iobasis.com/static/d6a32080e7205bc329dc32e11b089d45/e17e5/CloudEndure14.png 400w,
https://www.iobasis.com/static/d6a32080e7205bc329dc32e11b089d45/5a190/CloudEndure14.png 800w,
https://www.iobasis.com/static/d6a32080e7205bc329dc32e11b089d45/a1dd2/CloudEndure14.png 838w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>I noticed that there was an instance in <em>“Terminated”</em> state. That’s normal. That’s the temporary converter instance. The conversion time was below 2 minutes. And that conversion instance was terminated afterward.</p>
<p>I wrote down the public IP address of the new instance just launched in the Virginia region. And I was able to login to the instance without any issue. That means that the migration test was successful.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Successful Launch Test" title="" src="https://www.iobasis.com/static/444bd785438bc571a15028a3812bfbac/a0209/CloudEndure15.png" srcset="https://www.iobasis.com/static/444bd785438bc571a15028a3812bfbac/772e8/CloudEndure15.png 200w,
https://www.iobasis.com/static/444bd785438bc571a15028a3812bfbac/e17e5/CloudEndure15.png 400w,
https://www.iobasis.com/static/444bd785438bc571a15028a3812bfbac/a0209/CloudEndure15.png 725w" sizes="(max-width: 725px) 100vw, 725px">
    </span>
  </span>
  </p>
<h2>9. Removing Unused Test Resources</h2>
<p>After all tests on the instance were completed, I still had the target instance running on AWS. And it wasn’t useful anymore. So I decided to remove its resources from AWS. This was done by selecting the instance in CloudEndure console and choosing <em>“Delete Target Machine”</em>.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Delete Target Machine" title="" src="https://www.iobasis.com/static/ebff82e8acaa67b072fc56c3a3eb7bd8/07484/CloudEndure16.png" srcset="https://www.iobasis.com/static/ebff82e8acaa67b072fc56c3a3eb7bd8/772e8/CloudEndure16.png 200w,
https://www.iobasis.com/static/ebff82e8acaa67b072fc56c3a3eb7bd8/e17e5/CloudEndure16.png 400w,
https://www.iobasis.com/static/ebff82e8acaa67b072fc56c3a3eb7bd8/07484/CloudEndure16.png 540w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<p>Then, the target instance was terminated in AWS as expected.</p>
<p>Note that the replication instance was still active. It was still used to sync the source machine.</p>
<p>
  <span>
    <span>
      <img alt="CloudEndure Delete Target Machine results" title="" src="https://www.iobasis.com/static/0388c95175ff7ecd2de6dc50baed27a7/5a190/CloudEndure17.png" srcset="https://www.iobasis.com/static/0388c95175ff7ecd2de6dc50baed27a7/772e8/CloudEndure17.png 200w,
https://www.iobasis.com/static/0388c95175ff7ecd2de6dc50baed27a7/e17e5/CloudEndure17.png 400w,
https://www.iobasis.com/static/0388c95175ff7ecd2de6dc50baed27a7/5a190/CloudEndure17.png 800w,
https://www.iobasis.com/static/0388c95175ff7ecd2de6dc50baed27a7/ddc81/CloudEndure17.png 837w" sizes="(max-width: 800px) 100vw, 800px">
    </span>
  </span>
  </p>
<p>But I noticed that the Volume previously used by the Target instance wasn’t removed from AWS. So deleted it on my own.</p>
<h2>10. Cutover</h2>
<p>Then the last step was the final migration. I launched a new machine. But this time I used <em>“Cutover Mode”</em> instead of <em>“Test Mode”</em>.</p>
<p>The process was the same as in the <em>“Test Mode”</em>. A new machine was launched in 7 minutes. And I was able to log into the migrated server successfully. So the migration completed successfully again.</p>
<h2>11. Cleaning up</h2>
<p>I still had lots of unused resources on my AWS account. These are the steps I took to clean everything up:</p>
<ul>
<li>I completed a <em>“Remove Machine from this console”</em> on CloudEndure Console. This removes the agent from the source server and stops replication. Note that the target machine isn’t modified. We don’t want the migrated server to be terminated.</li>
<li>I terminated the <em>“Replication Server”</em> instance in AWS (because I had no other replication in progress). This has to be done manually because it isn’t done by CloudEndure.</li>
<li>I removed the EBS volumes previously used by <em>“Replication Server”</em>.</li>
<li>I also removed all unused snapshots.</li>
</ul>
<h2>Conclusion</h2>
<p>This process allowed me to <strong>lift-and-shift</strong> the server. Lift-and-shift is always the first step in the cloud journey. And this tool allowed to complete it efficiently.</p>
<p>I want to mention that the process had many advantages. For example, I used the same tool for uploading the data to the cloud and orchestrate the migration. I was also able to test the process before the cutover. That’s very important because it eliminates possible migration mistakes. The unavailability period was very short. Additionally, I didn’t have to adapt the disk to boot in the cloud, because that was managed by the tool. And this process allows me to automate the migration of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.iobasis.com/How-Migrate-a-server-to-AWS/">https://www.iobasis.com/How-Migrate-a-server-to-AWS/</a></em></p>]]>
            </description>
            <link>https://www.iobasis.com/How-Migrate-a-server-to-AWS/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24087614</guid>
            <pubDate>Fri, 07 Aug 2020 23:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Swedish doctor's perspective on Covid]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 244 (<a href="https://news.ycombinator.com/item?id=24087287">thread link</a>) | @gofiggy
<br/>
August 7, 2020 | https://sebastianrushworth.com/2020/08/04/how-bad-is-covid-really-a-swedish-doctors-perspective/ | <a href="https://web.archive.org/web/*/https://sebastianrushworth.com/2020/08/04/how-bad-is-covid-really-a-swedish-doctors-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Ok, I want to preface this article by stating that it is entirely anecdotal and based on my experience working as a doctor in the emergency room of one of the big hospitals in Stockholm, Sweden, and of living as a citizen in Sweden. As many people know, Sweden is perhaps the country that has taken the most relaxed attitude of any towards the covid pandemic. Unlike other countries, Sweden never went in to complete lockdown. Non-essential businesses have remained open, people have continued to go to cafés and restaurants, children have remained in school, and very few people have bothered with face masks in public.</p>



<p>Covid hit Stockholm like a storm in mid-March. One day I was seeing people with appendicitis and kidney stones, the usual things you see in the emergency room. The next day all those patients were gone and the only thing coming in to the hospital was covid. Practically everyone who was tested had covid, regardless of what the presenting symtom was. People came in with a nose bleed and they had covid. They came in with stomach pain and they had covid.</p>



<p>Then, after a few months, all the covid patients disappeared. It is now four months since the start of the pandemic, and I haven’t seen a single covid patient in over a month. When I do test someone because they have a cough or a fever, the test invariably comes back negative. At the peak three months back, a hundred people were dying a day of covid in Sweden, a country with a population of ten million. We are now down to around five people dying per day in the whole country, and that number continues to drop. Since people generally die around three weeks after infection, that means virtually no-one is getting infected any more. If we assume around 0.5 percent of those infected die (which I think is very generous, more on that later), then that means that three weeks back 1,000 people were getting infected per day in the whole country, which works out to a daily risk per person of getting infected of 1 in 10,000, which is miniscule. And remember, the risk of dying is at the very most 1 in 200 if you actually do get infected. And that was three weeks ago. Basically, covid is in all practical senses over and done with in Sweden. After four months.</p>



<p>In total covid has killed under 6,000 people in a country of ten million. A country with an annual death rate of around 100,000 people. Considering that 70% of those who have died of covid are over 80 years old, quite a few of those 6,000 would have died this year anyway. That makes covid a mere blip in terms of its effect on mortality.</p>



<p>That is why it is nonsensical to compare covid to other major pandemics, like the 1918 pandemic that killed tens of millions of people. Covid will never even come close to those numbers. And yet many countries have shut down their entire economies, stopped children going to school, and made large portions of their population unemployed in order to deal with this disease.</p>



<p>The media have been proclaiming that only a small percentage of the population have antibodies, and therefore it is impossible that herd immunity has developed. Well, if herd immunity hasn’t developed, where are all the sick people? Why has the rate of infection dropped so precipitously? Considering that most people in Sweden are leading their lives normally now, not socially distancing, not wearing masks, there should still be high rates of infection.</p>



<p>The reason we test for antibodies is because it is easy and cheap. Antibodies are in fact not the body’s main defence against virus infections. T-cells are. But T-cells are harder to measure than antibodies, so we don’t really do it clinically. It is quite possible to have T-cells that are specific for covid and thereby make you immune to the disease, without having any antibodies. Personally, I think this is what has happened. Everybody who works in the emergency room where I work has had the antibody test. Very few actually have antibodies. This is in spite of being exposed to huge numbers of infected people, including at the beginning of the pandemic, before we realized how widespread covid was, when no-one was wearing protective equipment.</p>



<p>I am not denying that covid is awful for the people who do get really sick or for the families of the people who die, just as it is awful for the families of people who die of cancer, or influenza, or an opioid overdose. But the size of the response in most of the world (not including Sweden) has been totally disproportionate to the size of the threat.</p>



<p>Sweden ripped the metaphorical band-aid off quickly and got the epidemic over and done with in a short amount of time, while the rest of the world has chosen to try to peel the band-aid off slowly. At present that means Sweden has one of the highest total death rates in the world. But covid is over in Sweden. People have gone back to their normal lives and barely anyone is getting infected any more. I am willing to bet that the countries that have shut down completely will see rates spike when they open up. If that is the case, then there won’t have been any point in shutting down in the first place, because all those countries are going to end up with the same number of dead at the end of the day anyway. Shutting down completely in order to decrease the total number of deaths only makes sense if you are willing to stay shut down until a vaccine is available. That could take years. No country is willing to wait that long.</p>



<p>Covid has at present killed less than 6000 in Sweden. It is very unlikely that the number of dead will go above 7,000. An average influenza year in Sweden, 700 people die of influenza. Does that mean covid is ten times worse than influenza? No, because influenza has been around for centuries while covid is completely new. In an average influenza year most people already have some level of immunity because they’ve been infected with a similar strain previously, or because they’re vaccinated. So it is quite possible, in fact likely, that the case fatality rate for covid is the same as for influenza, or only slightly higher, and the entire difference we have seen is due to the complete lack of any immunity in the population at the start of this pandemic. </p>



<p>This conclusion makes sense of the Swedish fatality numbers – if we’ve reached a point where there is hardly any active infection going on any more in Sweden in spite of the fact that there is barely any social distancing happening then that means at least 50% of the population has been infected already and have developed immunity, which is five million people. This number is perfectly reasonable if we assume a reproductive number for the virus of two: If each person infects two new, with a five day period between being infected and infecting others, and you start out with just one infected person in the country, then you will reach a point where several million are infected in just four months. If only 6000 are dead out of five million infected, that works out to a case fatality rate of 0.12 percent, roughly the same as regular old influenza, which no-one is the least bit frightened of, and which we don’t shut down our societies for.</p>



<p>If you thought this article was interesting, then you might be interested in my follow-up article, about <a href="https://sebastianrushworth.com/2020/08/08/what-is-the-best-way-to-measure-rates-of-covid-immunity/">the best way to measure rates of covid infection in a population</a></p>



<p>Additionally, If you liked this article, then please click the link at the bottom of this page to subscribe and receive future articles straight to your inbox.</p>

<div>
	<p><img alt="" src="https://0.gravatar.com/avatar/f80948fe1de6fa8784ebcbce1a6c153c?s=42&amp;d=identicon&amp;r=G" height="42" width="42">	</p><!-- .author-avatar -->

	<div>
		

		<p>
			I am a practicing physician in Stockholm, Sweden. Every day I get asked questions by my patients about health, diet, exercise, supplements, and medications. There is a lot of misinformation on the internet and it is easy to get the wrong advice, and hard to tell what is right and what is wrong if you don’t have advanced scientific training. The purpose of this blog is to share what the science actually says.			<a href="https://sebastianrushworth.com/author/doctorsebastian/" rel="author">
				View all posts by Sebastian Rushworth, M.D.			</a>
		</p><!-- .author-bio -->
	</div><!-- .author-description -->
</div><!-- .author-info -->
	</div></div>]]>
            </description>
            <link>https://sebastianrushworth.com/2020/08/04/how-bad-is-covid-really-a-swedish-doctors-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24087287</guid>
            <pubDate>Fri, 07 Aug 2020 23:00:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terran: A Human Perception Library]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24084632">thread link</a>) | @nagitsu
<br/>
August 7, 2020 | https://pento.ai/blog/introducing-terran | <a href="https://web.archive.org/web/*/https://pento.ai/blog/introducing-terran">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><main><article><main><a href="https://pento.ai/blog/introducing-terran"><p>Introducing Terran: A human perception library</p></a></main><p>Computer vision has seen tremendous change in the last decade. Along this journey, the nature of the techniques used has shifted from fixed-pipeline algorithms based mostly in heuristics and little data to resource-intensive general-purpose models that require both heavy computing power and a lot of data. This shift, while unlocking new capabilities, presents some drawbacks.</p><p>Most of the work done at the research level is fragmented because researchers, by the very nature of good research, need to focus on one aspect at a time when planning their experiments. And while there are papers on unifying techniques, the difficulty to evaluate, and the requirements on what a novel contribution is being so stringent, these are few and apart. Most of these works come from non-academic initiatives such as <a href="http://fast.ai/">fast.ai</a>.</p><p>The objective of research is to present and validate a novel approach to a problem. Being that their end goal, the focus is on results and the published paper, not on the code used to run those experiments. Even when code is made publicly available, more often than not, it tends to be hard to extend, optimize, or integrate with other pieces of code.</p><p>Commercially available APIs may solve this issue since they are usually easy to use and integrate. However, they come with another set of problems.</p><p>First and foremost, code is not auditable. Since they are commercial solutions, code is not open source, so you cannot be certain what the code is doing. You may trust the company you are working with, but that may not be enough for other stakeholders. Plus, it is always nice to be able to check what is being done. Also, since they are usually cloud solutions, you have to share your data with them. This is a no-go for some companies, since the data may be somewhat sensitive.</p><p>There are some great services by some big-name companies, which may work fine for some set of problems. Nevertheless, their "best" models remain behind closed door. In addition to this, the technique that it is used may be unknown. While you can easily use Amazon Rekognition or Google Vision AI, you can't know what's under the hood. This may be fine for some scenarios, but for other cases you may need to have a sense of in which cases the solution fails, or which biases it has.</p><p>We believe that there's a place for an open-source initiative focusing on addressing the above
points.</p><p>That's where <a href="https://terran-project.com/">Terran</a> comes in.</p><p><img src="https://pento.ai/images/blog/terran-faces.png" alt="Terran Face Detection"></p><p>An example of Face Detection made with Terran</p><p>An open-source human perception library. We focus on providing open, auditable, and performant alternatives to closed approaches. Solutions that can run on your computer or device and that will adapt to the environment that it's in. But most importantly, code that you can test (without piling-up costs), understand and modify to your needs.</p><p>We strive for code that is easy to integrate and understand. While it is open-source, it is not specifically targeted for researchers. We want to make computer vision accessible to anyone who can code, and enable them to create innovative applications. To achieve this, Terran was built with these guiding principles in mind:</p><ul><li>A self-explanatory API that tells you what you are doing.</li><li>No intricate configuration files.</li><li>Simplest I/O operations for any kind of videos and images.</li></ul><p>The focus is on being a production-grade library, not a toy project. Only models whose performance can be assessed and with reasonable (and knowable) computational and memory requirements will be included.</p><p><img src="https://pento.ai/images/blog/terran-poses.png" alt="Terran Pose Estimation"></p><p>An example of Pose Estimation using Terran</p><p>Let's see a small example of what we can build with it.</p><p>We could do our own image album creator grouping photos of the same people. That's a use case that all cloud providers (such as Google Photos and Apple Photos) do. For the sake of keeping it simple and focusing on Terran, lets do the core of this problem: finding on which photos someone is present.</p><p>We will start with some imports:</p><pre><pre><code>import click

from pathlib import Path
from scipy.spatial.distance import cosine

from terran.face import extract_features, face_detection
from terran.io import open_image, resolve_images
from terran.vis import display_image, vis_faces
</code></pre></pre><p>We will use <code>click</code> to create a small CLI tool (we love click — highly recommended). We will use <code>pathlib</code> to handle paths and a measure of distance from <code>scipy</code>. Finally, we import some functions from Terran's modules: from face, core functions to detect faces and extract features; from io, utility functions to resolve paths and open images; from vis, some visualization functions (extremely important and useful when working with images!).</p><ol><li>from <code>terran.face</code>, we import core functions to detect and extract features from faces</li><li>from <code>terran.io</code>, utility functions to resolve paths and open images</li><li>and finally, from <code>terran.vis</code>, we import some visualization functions that are extremely important and useful when working with images!</li></ol><p>Now we will create a function that deals with the problem of finding the photos where a person is present. You'll see how easy it is with Terran!</p><pre><pre><code>@click.command(name='match-dir')
@click.argument('reference')
@click.argument('image-dir')
@click.option('--batch-size', type=int, default=1)
@click.option('--threshold', type=float, default=0.5)
@click.option('--display', is_flag=True, default=False)
def match_directory(reference, image_dir, batch_size, threshold, display):

    reference = open_image(reference)
    faces_in_reference = face_detection(reference)

    if len(faces_in_reference) != 1:
        click.echo('Reference image must have exactly one face.')
        return

    ref_feature = extract_features(reference, faces_in_reference[0])
</code></pre></pre><p>Our function takes in two arguments: a reference image and a directory where we should scan the photos. Then, our first step is to get a set of features out of our reference image that represents the person we are looking for.</p><p>Then, we get the paths to all of the images that we will be scanning:</p><pre><pre><code>    paths = resolve_images(
        Path(image_dir).expanduser(),
        batch_size=batch_size
    )
</code></pre></pre><p>This Terran function gives paths in batches, so you can process them in parallel (if needed).</p><p>So the only thing remaining to do is, for each image, open it, detect the faces, get the features, and compare it with our reference image. Easy enough with Terran!</p><pre><pre><code>    for batch_paths in paths:
        # Open them
        batch_images = list(map(open_image, batch_paths))

        # Detect the faces
        faces_per_image = face_detection(batch_images)

        # Get the features
        features_per_image = extract_features(batch_images, faces_per_image)

        for path, image, faces, features in zip(
            batch_paths, batch_images, faces_per_image, features_per_image
        ):
            for face, feature in zip(faces, features):
                # Compare each feature with our reference feature
                confidence = cosine(ref_feature, feature)

                # If it is a match print it / display it!
                if confidence &lt; threshold:
                    click.echo(f'{path}, confidence = {confidence:.2f}')
                    if display:
                        display_image(vis_faces(image, face))
</code></pre></pre><p>All the code together:</p><pre><pre><code>import click

from pathlib import Path
from scipy.spatial.distance import cosine

from terran.face import extract_features, face_detection
from terran.io import open_image, resolve_images
from terran.vis import display_image, vis_faces

@click.command(name='match-dir')
@click.argument('reference')
@click.argument('image-dir')
@click.option('--batch-size', type=int, default=1)
@click.option('--threshold', type=float, default=0.5)
@click.option('--display', is_flag=True, default=False)
def match_directory(reference, image_dir, batch_size, threshold, display):
    reference = open_image(reference)
    faces_in_reference = face_detection(reference)
    if len(faces_in_reference) != 1:
        click.echo('Reference image must have exactly one face.')
        return
    ref_feature = extract_features(reference, faces_in_reference[0])

    paths = resolve_images(
        Path(image_dir).expanduser(),
        batch_size=batch_size
    )
    for batch_paths in paths:
        batch_images = list(map(open_image, batch_paths))
        faces_per_image = face_detection(batch_images)
        features_per_image = extract_features(batch_images, faces_per_image)

        for path, image, faces, features in zip(
            batch_paths, batch_images, faces_per_image, features_per_image
        ):
            for face, feature in zip(faces, features):
                confidence = cosine(ref_feature, feature)
                if confidence &lt; threshold:
                    click.echo(f'{path}, confidence = {confidence:.2f}')
                    if display:
                        display_image(vis_faces(image, face))

if __name__ == '__main__':
    match_directory()
</code></pre></pre><p>With just a few lines of code, you can easily check in which images you are present! From your computer, not needing to upload them anywhere, and tweaking the parameters to fit your case (take a look at threshold). You can also take a look at this example in our <a href="https://github.com/pento-group/terran/blob/master/examples/match.py">Github</a>, and to the rest of Terran and see how it works.</p><p>Right now, Terran has models for Face Detection, Face Recognition, and Pose Estimation. We think that several applications can be created using these features, like controlling your computer with body gestures or changing what gets displayed depending on the presence of a face or not. You can use Terran as an interface to interact to your computer with your body, among several other ideas that one could think of.</p><p>In the future, we plan to:</p><ul><li>Add more models for these same problems, but that are more lightweight, in case you need it to run on a small device.</li><li>Add other models to tackle other problems, e.g. segmentation.</li><li>Add the functionality to train or fine-tune the existing models.</li></ul><p>While this is our current roadmap, feel free to create an issue on github to tell us if you'd like us to work on …</p></article></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pento.ai/blog/introducing-terran">https://pento.ai/blog/introducing-terran</a></em></p>]]>
            </description>
            <link>https://pento.ai/blog/introducing-terran</link>
            <guid isPermaLink="false">hacker-news-small-sites-24084632</guid>
            <pubDate>Fri, 07 Aug 2020 17:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Psychedelic Inspiration for Hypercard (2018)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24083738">thread link</a>) | @bobbiechen
<br/>
August 7, 2020 | https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/ | <a href="https://web.archive.org/web/*/https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2917">
	<!-- .entry-header -->

	<div>
		
		<p><img data-attachment-id="2921" data-permalink="https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/images-20/" data-orig-file="https://i2.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg?fit=511%2C286&amp;ssl=1" data-orig-size="511,286" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="images" data-image-description="" data-medium-file="https://i2.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg?fit=300%2C168&amp;ssl=1" data-large-file="https://i2.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg?fit=511%2C286&amp;ssl=1" src="https://i2.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg?resize=511%2C286" alt="" width="511" height="286" srcset="https://i2.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg?w=511&amp;ssl=1 511w, https://i2.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg?resize=300%2C168&amp;ssl=1 300w, https://i2.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-1.jpeg?resize=210%2C118&amp;ssl=1 210w" sizes="(max-width: 511px) 100vw, 511px" data-recalc-dims="1"></p>
<p>by Bill Atkinson, as told to Leo Laporte</p>
<p>In 1985 I swallowed a tiny fleck of gelatin containing a medium dose of LSD, and I spent most of the night sitting on a concrete park bench outside my home in Los Gatos, California.</p>

<p>I gazed up at a hundred billion galaxies each with a hundred billion stars, and each star a giant thermonuclear fusion reaction as powerful as our Sun. And for the first time in my life I knew deep down inside that we are not alone.&nbsp;</p>

<p>I knew that life on planet Earth is not the only pocket of consciousness in the universe, and likely not the most advanced. But we still have a role to play in the unfolding drama of creation.&nbsp;</p>

<p>It seemed to me the universe is in a process of coming alive. Consciousness is blossoming and propagating to colonize the universe, and life on Earth is one of many bright spots in the cosmic birth of consciousness.</p>

<p>But the stars are separated by enormous distances of darkness and vacuum, which may hinder communication between them. I lowered my gaze and saw the street lamps below glowing brightly, each casting a pool of light but surrounded by darkness before the next lamp. As above, so below.</p>


<p><img data-attachment-id="2928" data-permalink="https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/nightsk/" data-orig-file="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/NightSK.jpeg?fit=446%2C297&amp;ssl=1" data-orig-size="446,297" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="NightSK" data-image-description="" data-medium-file="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/NightSK.jpeg?fit=300%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/NightSK.jpeg?fit=446%2C297&amp;ssl=1" src="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/NightSK.jpeg?resize=777%2C517" alt="" width="777" height="517" srcset="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/NightSK.jpeg?w=446&amp;ssl=1 446w, https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/NightSK.jpeg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/NightSK.jpeg?resize=210%2C140&amp;ssl=1 210w" sizes="(max-width: 777px) 100vw, 777px" data-recalc-dims="1"></p>

<p>The street lamps reminded me of bodies of knowledge, gems of discovery and understanding, but separated from each other by distance and different languages. Poets, artists, musicians, physicists, chemists, biologists, mathmeticians, and economists all have separate pools of knowledge, but are hindered from sharing and finding the deeper connections.</p>

<p>My vision distorted by thick eyeglasses, I witnessed the curvature of the Earth’s horizon, and I felt the pull of gravity toward its center, such that every one of us is standing at the very apex. Each of us stands at the top of planet Earth, and each of us is a leader or captain of the “Blue Marble” team.</p>

<p>How could I help? By focusing on the weak link. If I were captain of a soccer team, I would look for the weak link and work on it. If the goalie was letting too many through, I would spend extra practice time with him, and the whole team would prosper.</p>

<p>It occurred to me the weak link for the Blue Marble team is wisdom. Humanity has achieved sufficient technological power to change the course of life and the entire global ecosystem, but we seem to lack the perspective to choose wisely between alternative futures. But I was young, without much life experience or wisdom myself.</p>

<p>Knowledge, it seemed to me, consists of the “How” connections between pieces of information, the cause and effect relationships. How does this action bring about that result. Science is a systematic attempt to discover the “How” connections.&nbsp;</p>

<p><img data-attachment-id="2923" data-permalink="https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/images-2-11/" data-orig-file="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-2.jpeg?fit=454%2C340&amp;ssl=1" data-orig-size="454,340" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="images-2" data-image-description="" data-medium-file="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-2.jpeg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-2.jpeg?fit=454%2C340&amp;ssl=1" src="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-2.jpeg?resize=454%2C340" alt="" width="454" height="340" srcset="https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-2.jpeg?w=454&amp;ssl=1 454w, https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-2.jpeg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/images-2.jpeg?resize=210%2C157&amp;ssl=1 210w" sizes="(max-width: 454px) 100vw, 454px" data-recalc-dims="1"></p>

<p>Wisdom, it seemed to me, was a step further removed, the bigger perspective of the “Why” connections between pieces of knowledge. Why, for reasons ethical and aesthetic, should we choose one future over another?</p>

<p>I thought if we could encourage sharing of ideas between different areas of knowledge, perhaps more of the bigger picture would emerge, and eventually more wisdom might develop. Sort of a trickle-up theory of information leading to knowledge leading to wisdom.</p>

<p>This was the underlying inspiration for HyperCard, a multimedia authoring environment that empowered non-programmers to share ideas using new interactive media called HyperCard stacks.&nbsp;</p>

<p><img data-attachment-id="2922" data-permalink="https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/mtiymzi2odgxmjywntyznzm3/" data-orig-file="https://i1.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/MTIyMzI2ODgxMjYwNTYzNzM3.jpg?fit=600%2C424&amp;ssl=1" data-orig-size="600,424" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="MTIyMzI2ODgxMjYwNTYzNzM3" data-image-description="" data-medium-file="https://i1.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/MTIyMzI2ODgxMjYwNTYzNzM3.jpg?fit=300%2C212&amp;ssl=1" data-large-file="https://i1.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/MTIyMzI2ODgxMjYwNTYzNzM3.jpg?fit=600%2C424&amp;ssl=1" src="https://i1.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/MTIyMzI2ODgxMjYwNTYzNzM3.jpg?resize=600%2C424" alt="" width="600" height="424" srcset="https://i1.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/MTIyMzI2ODgxMjYwNTYzNzM3.jpg?w=600&amp;ssl=1 600w, https://i1.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/MTIyMzI2ODgxMjYwNTYzNzM3.jpg?resize=300%2C212&amp;ssl=1 300w, https://i1.wp.com/www.mondo2000.com/wp-content/uploads/2018/06/MTIyMzI2ODgxMjYwNTYzNzM3.jpg?resize=210%2C148&amp;ssl=1 210w" sizes="(max-width: 600px) 100vw, 600px" data-recalc-dims="1"></p>

<p>Each card in a HyperCard stack included graphics, text, interactive buttons, and links that took you to another card or stack. Built-in painting tools, drag-and-drop authoring with a library of pre-fab buttons and fields, and simple event based scripting made HyperCard flexible and easy to use.</p>

<p>It took a lot of hard work and a dedicated team to complete this mission. Apple shipped HyperCard in August 1987, and included it free with every Mac so any user could create and share HyperCard stacks. Many creative people expressed their ideas and passions, and several million interactive HyperCard stacks were created.&nbsp;</p>

<p>HyperCard was a precurser to the first web browser, except chained to a hard drive before the worldwide web. Six years later Mosaic was introduced, influenced by some of the ideas in HyperCard, and indirectly by an inspiring LSD experience.</p>

<p><em>Leo Laporte did a great interview with me in April 2016. You can <a href="https://twit.tv/shows/triangulation/episodes/247?autostart=false">watch it here</a>&nbsp;—&nbsp; with the part about hypercard inspiration starting at 22:43&nbsp;</em></p>




<p><span></span>
				<span>Post Views: </span>
				<span>7,716</span>
			</p>			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.mondo2000.com/2018/06/18/the-inspiration-for-hypercard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24083738</guid>
            <pubDate>Fri, 07 Aug 2020 16:30:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Fast Design]]>
            </title>
            <description>
<![CDATA[
Score 552 | Comments 181 (<a href="https://news.ycombinator.com/item?id=24083260">thread link</a>) | @no_wizard
<br/>
August 7, 2020 | https://www.fast.design/docs/introduction | <a href="https://web.archive.org/web/*/https://www.fast.design/docs/introduction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to the FAST documentation! We're glad you're here. We can't wait to show you around.</p><h2>What is FAST?</h2><p>FAST is a collection of JavaScript packages centered around web standards, designed to help you efficiently tackle some of the most common challenges in website and application design and development.</p><p>Have you ever needed a reusable set of UI components that you could drop into your app and have an amazing experience? <em><strong>That's FAST.</strong></em></p><p>Have you ever needed to create your own components, and share them across your company, including across groups that use different, incompatible front-end frameworks? <em><strong>That's FAST.</strong></em></p><p>Have you ever needed to implement a branded experience or a design language like Microsoft's Fluent UI or Google's Material Design? <em><strong>That's FAST.</strong></em></p><p>Have you ever wanted to improve your app's startup time, render speed, or memory consumption? <em><strong>That's FAST.</strong></em></p><p>Have you ever wanted to adopt more web standards and build your site or app on a native web foundation that's immune to the shifting sands of the modern JavaScript front-end landscape? <em><strong>That's FAST.</strong></em></p><p>Let's take a look at what each of FAST's core packages gives us today.</p><h3>fast-element</h3><p><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
<a href="https://badge.fury.io/js/%40microsoft%2Ffast-element" target="_blank" rel="noopener noreferrer"><img src="https://badge.fury.io/js/%40microsoft%2Ffast-element.svg" alt="npm version"></a></p><p>The <code>fast-element</code> library is a lightweight means to easily building performant, memory-efficient, standards-compliant Web Components. FAST Elements work in every major browser and can be used in combination with any front-end framework or even without a framework. To get up and running with <code>fast-element</code> see <a href="https://www.fast.design/docs/fast-element/getting-started">the Getting Started guide</a>.</p><h3>fast-foundation</h3><p><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
<a href="https://badge.fury.io/js/%40microsoft%2Ffast-foundation" target="_blank" rel="noopener noreferrer"><img src="https://badge.fury.io/js/%40microsoft%2Ffast-foundation.svg" alt="npm version"></a></p><p>The <code>fast-foundation</code> package is a library of Web Component classes, templates, and other utilities intended to be composed into registered Web Components by design systems (e.g. Fluent Design, Material Design, etc.). The exports of this package can generally be thought of as un-styled base components that implement semantic and accessible markup and behavior.</p><p>This package does not export Web Components registered as <a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_custom_elements" target="_blank" rel="noopener noreferrer">custom elements</a> - it exports parts and pieces intended to be <em>composed</em> into Web Components, allowing you to implement your own design language by simply applying CSS styles and behaviors without having to write all the JavaScript that's involved in building production-quality component implementations.</p><h3>fast-components</h3><p><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
<a href="https://badge.fury.io/js/%40microsoft%2Ffast-components" target="_blank" rel="noopener noreferrer"><img src="https://badge.fury.io/js/%40microsoft%2Ffast-components.svg" alt="npm version"></a></p><p><code>fast-components</code> is a library of Web Components that <em>composes</em> the exports of <code>fast-foundation</code> with stylesheets aligning to the FAST design language. This composition step registers a custom element. See the <a href="https://www.fast.design/docs/components/getting-started">quick start</a> to get started using the components.</p><h3>fast-components-msft</h3><p><a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
<a href="https://badge.fury.io/js/%40microsoft%2Ffast-components-msft" target="_blank" rel="noopener noreferrer"><img src="https://badge.fury.io/js/%40microsoft%2Ffast-components-msft.svg" alt="npm version"></a></p><p><code>fast-components-msft</code> is a library of Web Components that <em>composes</em> <code>fast-foundation</code>. <code>fast-components-msft</code> uses the same custom element names as <code>fast-components</code>, but makes use of different stylesheets that support Microsoft's Fluent design language.</p><h3>Component Explorer</h3><p>Launch our <a href="https://explore.fast.design/" target="_blank" rel="noopener noreferrer">Component Explorer</a> to experience our <a href="https://www.npmjs.com/package/@microsoft/fast-components" target="_blank" rel="noopener noreferrer">FAST Components</a> and development tools.</p><h2>Getting started</h2><p>If you're looking to get started using our components right away, take a look at <a href="https://www.fast.design/docs/components/getting-started">the components quick start</a>. You'll also want to check out <a href="https://www.fast.design/docs/integrations/introduction">our integrations</a> if you're looking to add the components into a Webpack build or incorporate them with another front-end framework. For those interested in implementing their own design system or customizing the styles of the components, after you <a href="https://www.fast.design/docs/components/getting-started">have a look at the components</a>, you'll want to read through <a href="https://www.fast.design/docs/design/introduction">our styling docs</a>. Finally, if your goal is to build your own components or apps with <code>fast-element</code>, you can learn all about that in our <a href="https://www.fast.design/docs/fast-element/getting-started">guide to building web components with FASTElement</a>.</p><h2>Joining the community</h2><p>Looking to get answers to questions or engage with us in realtime? Our community is most active <a href="https://discord.gg/FcSNfg4" target="_blank" rel="noopener noreferrer">on Discord</a>. Submit requests and issues on <a href="https://github.com/Microsoft/fast/issues/new/choose" target="_blank" rel="noopener noreferrer">GitHub</a>, or join us by contributing on <a href="https://github.com/Microsoft/fast/labels/community:good-first-issue" target="_blank" rel="noopener noreferrer">some good first issues via GitHub</a>.</p><p>We look forward to building an amazing open source community with you!</p></div></div>]]>
            </description>
            <link>https://www.fast.design/docs/introduction</link>
            <guid isPermaLink="false">hacker-news-small-sites-24083260</guid>
            <pubDate>Fri, 07 Aug 2020 15:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A T Cell Army against SARS-CoV-2]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24082327">thread link</a>) | @karmel
<br/>
August 7, 2020 | https://www.hellovirology.com/2020/08/a-t-cell-army-against-sars-cov-2.html | <a href="https://web.archive.org/web/*/https://www.hellovirology.com/2020/08/a-t-cell-army-against-sars-cov-2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3178459137750369132">



<p>
We have talked a fair <a href="https://www.hellovirology.com/2020/07/what-is-mrna-vaccine.html">amount</a> <a href="https://www.hellovirology.com/2020/07/antibody-hope-in-sars-cov-2.html">about</a> antibodies, and much of the SARS-CoV-2 discussion is focused on antibodies as indicators, treatments, or vaccines. However, antibodies produced by B-cells are only one part of the larger immune picture, albeit one of the most accessible parts. To develop a comprehensive treatment strategy for SARS-CoV-2, we will likely need to understand how the broader network of immune cells responds to the virus. Today, we’ll take a closer look at the T cell response to SARS-CoV-2 infection, and what it says about long-term immunity.
</p>
<h3>A robust T cell response</h3>


<p>
A brief refresher: T cells, <a href="https://www.hellovirology.com/2020/06/adaptive-immune-cells.html">you may remember</a>, are adaptive immune cells. Each T cell has a unique T cell receptor that recognizes a different set of foreign peptides, and if a T cell’s receptor is activated, that T cell clones itself and produces an army of similar T cells capable of fighting off the invader that was recognized. T cells come in several varieties, the two most prominent of which are CD4+ T cells and CD8+ T cells. CD4+ T cells are responsible for surveying peptides (that is, short protein fragments) presented by antigen-presenting cells like B cells and macrophages and starting a signaling cascade that activates the rest of the immune system, and are thus referred to as “helper” T cells. CD8+ T cells survey peptides presented by normal tissue cells throughout the body, and, if they recognize one of the presented peptides as foreign, they kill the cell under the assumption that it has been infected. CD8+ T cells are thus called “killer” T cells.</p><p><img height="441" src="https://lh6.googleusercontent.com/VHihcE0ie5EooWOw2mc8MzfuYgaOlru5R7lLNl22U_DTENRS9eBrKdPNZd1a0q609Hhyl7WZLuQpw8lVU3fO2ZsWAYwdT_anu_JpkUAMOyP1IkBQ_TGsvrYS4geTdOtRC1TVjQLU=w499-h441" width="499"></p><p>Given these critical roles in immune system activation, scientists are studying the extent to which CD4+ and CD8+ T cells recognize peptides from SARS-CoV-2. In <a href="https://www.nature.com/articles/s41586-020-2550-z">one recent paper</a>, Grifoni et al. created pools of peptides that tile the entire set of proteins that make up SARS-CoV-2. In one pool, they created a peptide for every set of 15 amino acids from the Spike protein, tiled such that each length-15 chain overlapped by ten amino acids with the next peptide in the pool. In another pool, they computationally predicted which peptides would be efficiently held by antigen presenting cells like macrophages, and made peptides that covered the rest of the SARS-CoV-2 proteins. A similar pool was made for the peptides predicted to be efficiently held in the MHC class I molecules that CD8+ T cells recognize.</p> <p><img height="250" src="https://lh4.googleusercontent.com/zUoM8PrduU9w1Tw6QW9QYVvR_PE7ctTnUvJyqoBkLcEO6jqFuuZwkc97g5hStxr7hNOl4ceN3bcB4PBHx0GrHLioF1cOAWLW9-eK3K7Xk6U_rw-ZTmx9oj5FiyisoABi1VRZ7fYv" width="241"></p><p>
Scientists regularly create overlapping peptides that tile proteins of interest when studying which pieces of a protein immune cells recognize. This is a generic example showing overlap strategies from Mimotopes.com, a company that creates and sells custom peptides.
</p>
<p>
To test out the effects of these peptide pools, the researchers collected blood from patients who tested positive for COVID-19 but were not hospitalized, 20 - 35 days after symptom onset. The researchers extracted the Peripheral Mononuclear Blood Cells (PBMCs) from the blood, as these include circulating T cells and other immune cells, and then ran a series of experiments to see how the T cells responded to the peptide pools. The number of patients was small (20 patients exposed to SARS-CoV-2, and 20 unexposed controls), but even so, the results were consistent: all recovered COVID-19 patients showed evidence of a robust T cell response to SARS-CoV-2 peptides. 100% of patients had CD4+ T cells that recognized and became activated in response to peptides from the Spike pool as well as peptides from the non-Spike peptide pool. These activated cells were able to produce inflammatory cytokines (immune signaling molecules) and to quickly clone themselves. The response of the patients’ CD8+ T cells was less universal, but still robust: 70% of patients had CD8+ T cells that were activated in response to the SARS-CoV-2 peptide pools. 
</p>
<h3>Memories of infections past</h3>


<p>
What does this T cell response mean? For starters, it indicates that recovered COVID-19 patients have a stronghold of “memory” T cells— T cells that have seen SARS-CoV-2 and learned its patterns so that they are ready to respond more quickly in the future. It’s unclear whether these T cells are able to confer long-term immunity for the patients, but there is some evidence that they might: another paper published by <a href="https://www.nature.com/articles/s41586-020-2550-z">Le Bert et al.</a> ran a similar set of peptide/T cell experiments, but they were able to include a set of long-recovered SARS-CoV-1 patients. They found that even after 17 years, these patients had T cells that were able to quickly respond to both SARS-CoV-1 and SARS-CoV-2 peptides, which gives us hope that T cell memory of SARS-CoV-2 will be similarly long-lived.
</p>
<p>
These cross-reactive T cells were not limited to SARS-CoV-1 patients, either. Both Grifoni et al. and Le Bert et al. used PBMCs drawn from donors without any exposure to COVID as controls, but these unexposed controls proved more interesting than the “zero baseline” we might have expected, as up to 50% of the unexposed controls showed some degree of reactivity to peptides from SARS-CoV-2, though these reactions were skewed toward the non-spike peptide pools. The researchers reason this is likely due to previous exposure to coronaviruses that cause common colds, and indeed, all unexposed controls had antibodies for two common coronaviruses, HCoV-OC43 and HCoV-NL63. If true, this cross-reactivity between common cold coronaviruses and SARS-CoV-2 could explain some of the variability in severity of COVID-19 across different people; some immune systems may already be primed to react to SARS-CoV-2 by prior infections. Further, given that the cross-reactive responses were more pronounced for non-spike proteins, this finding lends support to the idea that we should have a multi-target approach to vaccination and treatment, rather than a Spike-only approach.
</p>
<p>
(We should pause for a moment here to address a nagging question: wait, if even the unexposed controls showed responses to SARS-CoV-2 peptides, how do we know any of these responses are real? Isn’t the whole idea of a control to give a baseline to compare to? There are several reasons to believe these results are legitimate: peptide assays are fairly robust in immunological studies; the amplitude and targets of the control response are distinct from the COVID-19-exposed response; and multiple studies from multiple labs found the same results with the same peculiarities. That said, the sample size is very small, and the lack of a non-reactive control should always be concerning, so more studies in this area should be conducted before we draw any strong conclusions here.)
</p>

<p>
COVID-19-exposed cells (top row) showed a robust response to a number of SARS-CoV-2 targets, but the unexposed controls also showed some responsiveness, especially among lesser-known viral peptides.
</p>
<h3>Reading the T leaves</h3>


<p>
Taken all together, these T cell experiments demonstrate that, well, T cells matter, too. A robust immune response requires many cells, and the evidence of consistent T cell activation in recovered patients indicates that T cells play an important role in the natural clearance of the virus. It stands to reason, then, that an effective vaccination strategy will likely have to consider how and when to activate T cells. These studies identify a number of distinct peptides that activate T cells across patients, and could therefore be used along with antibodies as part of a vaccination strategy.
</p>
<h3 id="sources">Sources</h3>


<ul>

<li>Image 1: <a href="https://commons.wikimedia.org/wiki/File:Figure_42_02_04.png">https://commons.wikimedia.org/wiki/File:Figure_42_02_04.png</a>

</li><li>Image 2: Product image from <a href="http://www.mimotopes.com/peptideLibraryScreening.asp?id=90">http://www.mimotopes.com/peptideLibraryScreening.asp?id=90</a> , which sells peptide services

</li><li>Image 3: Figure 6B and 6C from Grifoni et al.

</li><li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7289747/">Vaccination strategies to combat novel corona virus SARS-CoV-2</a>

</li><li>Grifoni et al: <a href="https://www.sciencedirect.com/science/article/pii/S0092867420306103">Targets of T Cell Responses to SARS-CoV-2 Coronavirus in Humans with COVID-19 Disease and Unexposed Individuals</a> 

</li><li>Le Bert et al: <a href="https://www.nature.com/articles/s41586-020-2550-z">SARS-CoV-2-specific T cell immunity in cases of COVID-19 and SARS, and uninfected controls</a> </li></ul>
</div>
</div></div>]]>
            </description>
            <link>https://www.hellovirology.com/2020/08/a-t-cell-army-against-sars-cov-2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24082327</guid>
            <pubDate>Fri, 07 Aug 2020 14:38:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JuliaCon2020: Julia Is Production Ready]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24082281">thread link</a>) | @ViralBShah
<br/>
August 7, 2020 | https://bkamins.github.io/julialang/2020/08/07/production-ready.html | <a href="https://web.archive.org/web/*/https://bkamins.github.io/julialang/2020/08/07/production-ready.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p>Last time I have <a href="https://bkamins.github.io/julialang/2020/08/02/post_juliacon_1.html">posted</a> about the take-aways for DataFrames.jl from
<a href="https://juliacon.org/2020/">JuliaCon 2020</a>. This time I wanted to share my general conclusions
from attending different talks at this extremely successful event.</p>

<p>I have spent 20 years now deploying data science related projects in corporate
environments (back then it was not called data science, but we were already
training neural networks to make predictions) and have many colleagues who are
deeply into enterprise software development. Quoting a discussion with
Tomasz Olczak I had some time ago, who is a genuine one-man army in
delivering complex enterprise projects:</p>

<blockquote>
  <p>Julia is fast, and has a very nice syntax, but its ecosystem is not mature
enough for use in serious production projects.</p>
</blockquote>

<p>For many years I would agree with it, but after <a href="https://juliacon.org/2020/">JuliaCon 2020</a>
I believe we can confidently announce that</p>

<p>
  <b><i>Julia is production ready!</i></b>
</p>

<p>Let me now give a list of key (in my opinion) presentations given during
<a href="https://juliacon.org/2020/">JuliaCon 2020</a> that make me draw this conclusion.</p>

<p>I will not comment here on functionalities related to number crunching, as it
is clear that Julia shines here, but rather I want to focus on the things that
make Julia a great tool for deployment in production (still I skip many
interesting talks in this area — check out the detailed <a href="https://live.juliacon.org/agenda/">agenda</a> to
learn more).</p>



<p>In <a href="https://live.juliacon.org/talk/Y3H7FG">this talk</a> <a href="https://github.com/quinnj">Jacob Quinn</a> gives an end to end tutorial how
to build and deploy in an enterprise setting a microservice using Julia.
He gives ready recipes how to solve typical tasks that need to be handled in
such contexts: logging, context management, middleware setup, authentication,
caching, connection pooling, dockerization, and many other, that
are bread and butter of enterprise projects.</p>

<p>As an addition be sure to check out:</p>

<ul>
  <li>the <a href="https://live.juliacon.org/talk/Z8TE39">shippable apps</a> talk, where <a href="https://github.com/KristofferC">Kristoffer Carlsson</a> guides you
through creating executables which can be run on machines that do not have Julia
installed.</li>
  <li>the <a href="https://live.juliacon.org/talk/N39HSX">Julia for scripting</a> presentation, during which
<a href="https://github.com/fredrikekre">Fredrik Ekre</a> discusses the best practices for using Julia in contexts
where you need to execute short code snippets many times.</li>
  <li>the <a href="https://live.juliacon.org/talk/DTLBM9">Genie.jl</a> talk, in which <a href="https://github.com/essenciary">Adrian Salceanu</a> shows that it is currently
a mature, stable, performant, and feature-rich Julia web development framework.</li>
</ul>



<p>The two talks <a href="https://live.juliacon.org/talk/PLFURQ">Pkg.update()</a> and <a href="https://live.juliacon.org/talk/RXAN8F">What’s new in Pkg</a> show that
currently Julia has best in class functionalities for enterprise grade dependency
management for your projects. The list of provided functionalities is so long
that it is hard to list them all here.</p>

<p>Let me just mention one particular tool in this ecosystem, that is presented in
<a href="https://live.juliacon.org/talk/9WMAVU">BinaryBuilder.jl</a> talk that explains how to take software written in compiled
languages such as C, C++, Fortran, Go or Rust, and build precompiled artifacts
that can be used from Julia packages with ease (which means that no compilation
has to take place on client side when you install packages having such dependencies).</p>



<p>A natural topic related to dependency management is how to integrate Julia with
external tools. This area of functionality is really mature. Here is a list of
talks that cover this topic:</p>
<ul>
  <li><a href="https://live.juliacon.org/talk/7MALUA">Make your Julia code faster and compatible with non-Julia code</a></li>
  <li><a href="https://live.juliacon.org/talk/NNVQQF">Wrapping a C++ library using CxxWrap.jl</a></li>
  <li><a href="https://live.juliacon.org/talk/XGHSWW">Julia and C++: a technical overview of CxxWrap.jl</a></li>
  <li><a href="https://live.juliacon.org/talk/Y7ERM9">Introducing the @ccall macro</a></li>
  <li><a href="https://live.juliacon.org/talk/PHGCKB">Integrating Julia in R with the JuliaConnectoR</a></li>
  <li><a href="https://live.juliacon.org/talk/Q88P8U">Integrate Julia and Javascript using Node.js extensions</a></li>
</ul>

<p>Here it is worth to add Julia has had a great integration with Python for many
years now, see <a href="https://github.com/JuliaPy">JuliaPy</a>.</p>

<p>A good end to end example of doing some real work in Julia that requires integration
is <a href="https://live.juliacon.org/talk/KK9S9V">Creating a multichannel wireless speaker setup with Julia</a>
talk that show how to easily stitch things together (and in particular featuring
ZMQ.jl, Opus.jl, PortAudio.jl, and DSP.jl).</p>

<p>Another interesting talk showcasing integration capabilities is
<a href="https://live.juliacon.org/talk/GFE3DB">JSServe: Websites &amp; Dashboards in Julia</a>
that shows a high performance framework to easily combine interactive plots,
markdown, widgets and plain HTML/Javascript in Jupyter / Atom / Nextjournal and
on websites.</p>



<p>The two great talks <a href="https://live.juliacon.org/talk/DWCJUK">Juno 1.0</a> and <a href="https://live.juliacon.org/talk/HBTFT7">Using VS Code</a> that current IDE
support for Julia in VS Code is first class. You have all tools that normally you
would expect to get: code analysis (static and dynamic), debugger, workspaces,
integration with Jupyter Notebooks, and remote capabilities.</p>



<p>I do not want to cover many different ML algorithms that are available in Julia
natively, as there are just too many of them (and if something is missing you
can easily integrate it — see the integration capabilities section above).</p>

<p>However, on top of particular models you need frameworks that let you manage
ML workflows. In this area there are two interesting talks, one about
<a href="https://live.juliacon.org/talk/DMHZCC">MLJ: a machine learning toolbox for Julia</a> and the other showing
<a href="https://live.juliacon.org/talk/AD7TQW">AutoMLPipeline: A ToolBox for Building ML Pipelines</a>. From my experience
such tools are crucial when you want to move with your ML models from data scientist’s
sandbox to a real production usage.</p>



<p>Obviously, I have omitted many interesting things that were shown during
<a href="https://juliacon.org/2020/">JuliaCon 2020</a>. However, I hope that the aspects I have covered here,
that is:</p>

<ul>
  <li>enterprise grade patterns to create microservices and applications in Julia,</li>
  <li>robust dependency management tools,</li>
  <li>very flexible and powerful capabilities to integrate Julia with existing code
bases that were not written in Julia,</li>
  <li>excellent developer tooling in VSCode,</li>
  <li>mature packages that help you to create production-grade code for ML solutions
deployment,</li>
</ul>

<p>show that already now Julia can (and should) be considered as a serious option
for your next project in enterprise environment.</p>

<p>What I believe is crucially important is that not only we have required tools
ready but also we have great practical showcases how they can be used to build
robust production code with.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://bkamins.github.io/julialang/2020/08/07/production-ready.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24082281</guid>
            <pubDate>Fri, 07 Aug 2020 14:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-Contained Development Environments (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24082194">thread link</a>) | @tosh
<br/>
August 7, 2020 | https://charig.github.io/assets/papers/SCDE-DLS.pdf | <a href="https://web.archive.org/web/*/https://charig.github.io/assets/papers/SCDE-DLS.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://charig.github.io/assets/papers/SCDE-DLS.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24082194</guid>
            <pubDate>Fri, 07 Aug 2020 14:25:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Performance of User-Mode Threads and Coroutines]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24081713">thread link</a>) | @carimura
<br/>
August 7, 2020 | https://inside.java/2020/08/07/loomperformance/ | <a href="https://web.archive.org/web/*/https://inside.java/2020/08/07/loomperformance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://inside.java/2020/08/07/loomperformance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24081713</guid>
            <pubDate>Fri, 07 Aug 2020 13:46:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surprising Economics of Load-Balanced Systems]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24081681">thread link</a>) | @MindGods
<br/>
August 7, 2020 | http://brooker.co.za/blog/2020/08/06/erlang.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2020/08/06/erlang.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>The M/M/c model may not behave like you expect.</p>


<p>I have a system with <code>c</code> servers, each of which can only handle a single concurrent request, and has no internal queuing. The servers sit behind a load balancer, which contains an infinite queue. An unlimited number of clients offer <code>c * 0.8</code> requests per second to the load balancer on average. In other words, we increase the offered load linearly with <code>c</code> to keep the per-server load constant. Once a request arrives at a server, it takes one second to process, on average. How does the client-observed mean request time vary with <code>c</code>?</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/erlang_c_plot.png" alt=""></p>

<p>Option A is that the mean latency decreases quickly, asymptotically approaching one second as <code>c</code> increases (in other words, the time spent in queue approaches zero). Option B is constant. Option C is a linear improvement, and D is a linear degradation in latency. Which curve do you, intuitively, think that the latency will follow?</p>

<p>I asked my Twitter followers the same question, and got an interestingly mixed result:
<img src="https://mbrooker-blog-images.s3.amazonaws.com/erlang_twitter_poll.png" alt=""></p>

<p>Breaking down the problem a bit will help figure out which is the right answer. First, names. In the terminology of queue theory, this is an <a href="https://en.wikipedia.org/wiki/M/M/c_queue">M/M/c</a> queuing system: Poisson arrival process, exponentially distributed client service time, and <code>c</code> backend servers. In teletraffic engineering, it's <a href="https://en.wikipedia.org/wiki/Agner_Krarup_Erlang">Erlang's</a> delay system (or, because terminology is fun, M/M/n). We can use a classic result of queuing theory to analyze this system: Erlang's C formula <em>E<sub>2,n</sub>(A)</em>, which calculates the probability that an incoming customer request is enqueued (rather than handled immediately), based on the number of servers (<code>n</code> aka <code>c</code>), and the offered traffic <code>A</code>. For the details, see page 194 of the <a href="https://www.itu.int/dms_pub/itu-d/opb/stg/D-STG-SG02.16.1-2001-PDF-E.pdf">Teletraffic Engineering Handbook</a>. Here's the basic shape of the curve (using our same parameters):</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/erlang_c_result.png" alt=""></p>

<p>Follow the blue line up to half the saturation point, at 2.5 rps offered load, and see how the probability is around 13%. Now look at the purple line at half its saturation point, at 5 rps. Just 3.6%. So at half load the 5-server system is handling 87% of traffic without queuing, with double the load and double the servers, we handle 96.4% without queuing. Which means only 3.6% see any additional latency.</p>

<p>It turns out this improvement is, indeed, asymptotically approaching 1. The right answer to the Twitter poll is A.</p>

<p>Using the mean to measure latency is controversial (although <a href="http://brooker.co.za/blog/2017/12/28/mean.html">perhaps it shouldn't be</a>). To avoid that controversy, we need to know whether the percentiles get better at the same rate. Doing that in closed form is somewhat complicated, but this system is super simple, so we can plot them out using a Monte-Carlo simulation. The results look like this:</p>

<p><img src="https://mbrooker-blog-images.s3.amazonaws.com/sim_result.png" alt=""></p>

<p>That's entirely good news. The median (p50) follows the mean line nicely, and the high percentiles (99<sup>th</sup> and 99.9<sup>th</sup>) have a similar shape. No hidden problems.</p>

<p>It's also good news for cloud and service economics. With larger <code>c</code> we get better latency at the same utilization, or better utilization for the same latency, all at the same per-server throughput. That's not good news only for giant services, because most of this goodness happens at relatively modest <code>c</code>. There are few problems related to scale and distributed systems that get easier as <code>c</code> increases. This is one of them.</p>

<p>There are some reasonable follow-up questions. Are the results robust to our arbitrary choice of 0.8? Yes, they are<sup><a href="#foot1">1</a></sup>. Are the M/M/c assumptions of Poisson arrivals and exponential service time reasonable for typical services? I'd say they are reasonable, albeit wrong. Exponential service time is especially wrong: realistic services tend to be something more like log-normal. It may not matter. More on that another time.</p>

<p><em>Update:</em> Dan Ports responded to my thread with a fascinating <a href="https://twitter.com/danrkports/status/1291517540280070144">Twitter thread</a> pointing to <a href="https://drkp.net/papers/latency-socc14.pdf">Tales of the Tail: Hardware, OS, and Application-level Sources of Tail Latency</a> from SoCC'14 which looks at this effect in the wild.</p>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> Up to a point. As soon as the mean arrival rate exceeds the system's ability to complete requests, the queue grows without bound and latency goes to infinity. In our case, that happens when the request load exceeds <code>c</code>. More generally, for this system to be stable <code>λ/cμ</code> must be less than 1, where <code>λ</code> is the mean arrival rate, and <code>μ</code> is the mean time taken for a server to process a request.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2020/08/06/erlang.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24081681</guid>
            <pubDate>Fri, 07 Aug 2020 13:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker install and upgrade guide – CentOS and Ubuntu]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24081171">thread link</a>) | @lukasbar
<br/>
August 7, 2020 | https://knowledgepill.it/posts/docker-install-upgrade/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/docker-install-upgrade/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Install and upgrade of Docker Engine is simple and straightforward process.</p>
<p>In this post I will cover all important information in one place.</p>
<h2 id="docker-install-requirements">Docker install requirements</h2>
<p>Minimum requirements</p>
<ul>
<li>8GB RAM per manager node</li>
<li>4GB RAM per worker node</li>
<li>3GB of free disk space</li>
</ul>
<p>Recommended production requirements</p>
<ul>
<li>16GB RAM per manager node</li>
<li>4 vCPUs per manager node</li>
<li>25-100GB of free disk space on each node</li>
</ul>
<p>Also you must have one of the following OS:</p>
<ul>
<li>CentOS 7.1+ 64 bit version</li>
<li>Ubuntu 16.04/18.04/19.10 64 bit versions</li>
</ul>
<p>Preferable storage driver on newer OS is <code>overlay2</code>.<br>
Docker engine will set it by default.</p>
<p>If you want to get to know what is storage driver, what storage drivers are advised on certain OS and how to change it or looking for detailed info about setup of devicemapper, look at:</p>
<p><a href="https://knowledgepill.it/posts/docker_storage_drivers/">Docker storage driver - guide </a><br>
<a href="https://knowledgepill.it/posts/docker_configure_devicemapper/">Docker devicemapper - setup</a></p>
<hr>
<h4 id="important">Important</h4>
<p>If you plan to use Docker Enterprise with multiple nodes or Swarm - remember to set up time synchro between nodes - use NTP for that.</p>
<hr>
<h2 id="docker-install-centos">Docker install CentOS</h2>
<ul>
<li>Ensure that <code>centos-extras</code> repo is enabled</li>
<li>Install <code>yum-utils</code>:</li>
</ul>
<ul>
<li>Add repo</li>
</ul>
<div><pre><code data-lang="bash">yum-config-manager <span>\
</span><span></span>  --add-repo <span>\
</span><span></span>  https://download.docker.com/linux/centos/docker-ce.repo
</code></pre></div><ul>
<li>Install docker engine(Valid GPG Key: <code>060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35</code>)</li>
</ul>
<div><pre><code data-lang="bash">yum install docker-ce docker-ce-cli containerd.io
</code></pre></div><p>CentOS 8 at day of writing this post has problem with dependiences for containerd.io - you can solve this by installing manually correct version of containerd.io before running <code>docker-ce</code> instalation command. Example</p>
<div><pre><code data-lang="bash">yum install https://download.docker.com/linux/centos/7/x86_64/stable/Packages/containerd.io-1.2.6-3.3.el7.x86_64.rpm
</code></pre></div><ul>
<li>Start and enable autostart of daemon:</li>
</ul>
<div><pre><code data-lang="bash">systemctl start docker
systemctl enable docker
</code></pre></div><p>Optionally you can list available versions of docker and install preferable one:</p>
<div><pre><code data-lang="bash">yum list docker-ce --showduplicates | sort -r
</code></pre></div><div><pre><code data-lang="bash"> yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io
</code></pre></div><hr>
<p>For installing Docker Enterprise Edition you have to set up repo on your OS after getting from <a href="https://hub.docker.com/my-content">Docker Hub Account</a> Docker EE Repo Adress.</p>
<hr>
<h2 id="docker-install-ubuntu">Docker install Ubuntu</h2>
<ul>
<li>Update system and install important packages</li>
</ul>
<div><pre><code data-lang="bash">apt-get update

apt-get install <span>\
</span><span></span>   apt-transport-https <span>\
</span><span></span>   ca-certificates <span>\
</span><span></span>   curl <span>\
</span><span></span>   gnupg-agent <span>\
</span><span></span>   software-properties-common
</code></pre></div><ul>
<li>Add GPG Key(fingerprint: <code>9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88</code>)</li>
</ul>
<div><pre><code data-lang="bash">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
</code></pre></div><ul>
<li>Add repo</li>
</ul>
<div><pre><code data-lang="bash">add-apt-repository <span>\
</span><span></span>   <span>"</span><span>deb [arch=amd64] https://download.docker.com/linux/ubuntu \
</span><span>   </span><span>$(</span>lsb_release -cs<span>)</span><span> \
</span><span>   stable</span><span>"</span>
</code></pre></div><ul>
<li>Install docker engine</li>
</ul>
<div><pre><code data-lang="bash">apt-get update

apt-get install docker-ce docker-ce-cli containerd.io
</code></pre></div><p>Optionally check available versions:</p>
<div><pre><code data-lang="bash">apt-cache madison docker-ce
</code></pre></div><p>And install specific one:</p>
<div><pre><code data-lang="bash">apt-get install docker-ce<span>=</span>&lt;VERSION_STRING&gt; docker-ce-cli<span>=</span>&lt;VERSION_STRING&gt; containerd.io
</code></pre></div><h2 id="docker-upgrade">Docker upgrade</h2>
<h3 id="live-restore">Live restore</h3>
<p>If you want that running containers won’t stop with docker daemon you can enable live restore feature. After enabling it you can perform upgrade of docker engine without stopping running containers.</p>
<p>In <code>/etc/docker/daemon.json</code> set:</p>
<p>Upgrade on CentOS or Ubuntu - if we install docker engine from repo - can be performed with simple <code>yum upgrade</code> or <code>apt-get upgrade</code> commands.</p>

</div></div>]]>
            </description>
            <link>https://knowledgepill.it/posts/docker-install-upgrade/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24081171</guid>
            <pubDate>Fri, 07 Aug 2020 12:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok’s potential $588 per user valuation in Microsoft deal]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24081067">thread link</a>) | @dig6x
<br/>
August 7, 2020 | https://4thquadrant.io/snippets/business-model2/snippet-tiktoks-potential-588-per-user-valuation/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/snippets/business-model2/snippet-tiktoks-potential-588-per-user-valuation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_27_555">

<div>
<p><em>“At a market cap of $755 billion (at point of writing) Facebook’s per user value is around $288. If Facebook is some leading indicator for the pinnacle of per user value for social media, then at $50 billion for the roughly 85 million American users, TikTok’s per user value would be $588.”</em></p>



<p>As talks of TikTok’s ban or potential acquisition picks up steam, Microsoft is navigating rocky waters in an attempt to extrude some kind of deal amid the crossfire between Beijing and Washington – not to mention the multitude of big tech forces shaping the narrative. Whether the deal takes place, for what price and for how much of TikTok’s operations will have a resounding impact on the competition between Instagram, Facebook, Microsoft and even Amazon.&nbsp;</p>



<p>Let’s break down speculation around the deal first:</p>



<p><strong>Price:</strong> The estimated value of the US arm is currently ranging between $20-50 billion. The exact amount depends on a plethora of factors and several discordant stakeholders coming to consensus. The best speculative guess we can make has to be grounded in as much context as possible.&nbsp;</p>



<p><strong>Bytedance valuation:</strong> Bytedance, TikTok’s parent company has a private-market valuation of more than <a href="https://www.bloomberg.com/news/articles/2020-05-20/tiktok-owner-s-value-surpasses-100-billion-in-private-markets" target="_blank" rel="noreferrer noopener">$100 billion</a>, reaching up to $140 billion based on a small private sale made by early stakeholder Cheetah Mobile. Some analysts have predicted that Bytedance could IPO at a valuation north of this, going up as far as $180 billion.</p>



<p><strong>TikTok share of Bytedance:</strong> Bytedance revenue in 2019 was estimated to be around $17 billion, of this TikTok (including DouYin) revenue made up about $179.6 million.&nbsp;</p>



<p><strong>TikTok projected revenue 2020:</strong> $1 billion, 315 million downloads globally in Q1 (TikTok and DouYin)</p>



<p><strong>Tiktok projected revenue 2021</strong>: TikTok expects to bring in $6 billion in revenue in 2021 according to TikTok management but outsiders have expressed that this is an aggressive estimate, putting a more reasonable range at around $4 billion.&nbsp;</p>



<p><strong>American Share of TikTok: </strong>Of the 2019 revenue China’s DouYin arm accounted for $122.9 million (69%) while the American market accounted for about $36 million (20%). In April of 2020 in-app purchases on the app increased ten-fold to $78 million where the Chinese market accounted for 86.6% followed by an 8.2% contribution from the American market. At the moment it is predicted that there are about 85 million monthly active TikTok users in the U.S.</p>



<p>There have been reports of investors valuing TikTok around $50 billion in the takeover bid, this is approximately 50 times its projected revenue for 2020. Many publications have compared this to SnapChat’s market capitalization which sits around $33 billion at the moment (15 times its 2020 projected revenue). While Snapchat exists within the same social media ecosystem the comparison has to account for two factors.&nbsp;</p>



<ol><li>TikTok vs Snapchat’s position in the growth cycle</li><li>TikTok vs Snapchat’s core proposition&nbsp;</li></ol>



<p>Snapchat is vastly different on both fronts. For this reason, it’s difficult to gauge whether the current 50x pricing model is absurd or not in relative terms. A reference point, despite being more distant, that I find more revealing is the 2012 Facebook acquisition of Instagram for $1 billion.&nbsp;</p>



<p>At the time Instagram represented an up and coming giant in the social media landscape (which in and of itself was quite new) and was doing for photo sharing what TikTok has been doing for short video content (at least, doing more effectively than any of its predecessors). Facebook acquired Instagram at an average price of about $30 per user, when its own platform was valued at about $100 per user. Given that social media in 2012 represented a far less developed market and the almost ten year lead time, it’s difficult to directly compare Instagram to TikTok. Today Instagram is valued at over $100 billion and has over 1 billion users, placing its per user rate at $100. At a market cap of $755 billion (at point of writing) Facebook’s per user value is around $290. If Facebook is some leading indicator for the pinnacle of per user value for social media, then at $50 billion for the roughly 85 million American users, TikTok’s per user value would be $588 (this doesn’t change significantly when accounting for the Australian/Canadia/NZ markets given low penetration).&nbsp;&nbsp;</p>



<p><br>Where Instagram made up less than a third of Facebooks per user value at the point of acquisition, TikTok is hovering around double or more and more than 5x Instagrams current per user value. Of course, Instagram had no revenue generation and far few users (33 million) in 2012 while TikTok’s rapid growth has made it a giant in its own right. What we’re then looking at, assuming a $50 billion valuation is a complete market disruptor. Even at a $30 billion takeover bid, Microsoft would be paying $352 per user. </p>



<p>Microsoft isn’t negotiating a price range between $20-50 billion based on revenue projections of which a majority are derivative of the Chinese Douyin market, they are at the table on the basis of becoming potentially larger than the largest social media platform in the world. Rather than how this valuation pans out for investors, the longer-lasting and more pertinent question is how does this change the entire social media landscape and Microsoft’s role in the next decade. With such weighty questions up in the air, a 50x pricing model of revenue projection doesn’t seem so absurd – rather a significant turning point in the decade’s narrative around big tech.</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. Or sign-up for our free weekly newsletters. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>
</div></div><div data-td-block-uid="tdi_28_f59">

<div><h3><span>CONTACT THE EDITOR</span></h3>
<p>We welcome thoughtful discourse on all our content. If you would like to further explore or discuss any of the ideas covered in this article please contact our editors directly.<br><span>Contact Details</span></p>
</div></div></div>]]>
            </description>
            <link>https://4thquadrant.io/snippets/business-model2/snippet-tiktoks-potential-588-per-user-valuation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24081067</guid>
            <pubDate>Fri, 07 Aug 2020 12:20:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a mechanical keyboard with 3D-printed switches]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24081046">thread link</a>) | @jstanley
<br/>
August 7, 2020 | https://incoherency.co.uk/blog/stories/jesboard.html | <a href="https://web.archive.org/web/*/https://incoherency.co.uk/blog/stories/jesboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>I made a mechanical keyboard with 3d-printed switches</h3>
<p><i>Fri  7 August 2020</i></p>
<p><i>Tagged: <a href="https://incoherency.co.uk/blog/tags/3dprinting.html">3dprinting</a>, <a href="https://incoherency.co.uk/blog/tags/keyboard.html">keyboard</a></i></p>
<p>The keyboard is done! This is basically the result of what I've been working on for the past 2 months, which has
involved 3 iterations of testing machines, over 100 printed switches, and now finally a keyboard that I can type on.
Unfortunately it is not a very good keyboard, but you can't win them all.</p>
<p>Here's some pictures of the keyboard:</p>
<p><a href="https://img.incoherency.co.uk/2843"><img src="https://img.incoherency.co.uk/2843"></a></p>
<p><a href="https://img.incoherency.co.uk/2844"><img src="https://img.incoherency.co.uk/2844"></a></p>
<p><a href="https://img.incoherency.co.uk/2845"><img src="https://img.incoherency.co.uk/2845"></a></p>
<p>And here's a video of me typing on it:</p>
<p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/iEBbCk1WJUk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>(In the video it is a bit wobbly because the back is propped up to take the pressure off the exposed wiring. I have subsequently printed a couple of small legs to raise up
the back of the keyboard and now it is a lot <i>less</i> wobbly, but it could still do with some soft feet).</p>
<p>I am very happy with how the keyboard looks, and also happy that I have managed to produce a working keyboard using 3d-printed switches in the first place. I believe
this may be a world first.</p>
<p>That said, I started using the jesboard to write this blog post, and it was too annoying to type on so I went back to the Filco. Spending some time typing
on my homemade switches has given me a newfound appreciation for just how good Cherry MX switches are. I'm not sure what it is that makes the
jesboard so unpleasant to type on, there's just a general vagueness to it that makes typing frustrating. Pressing a single key up and down feels basically fine, which is why I hadn't
noticed this problem while developing the switches. But trying to use it as an actual keyboard, and type at a sensible speed, just feels <i>really</i> bad. It
is genuinely the worst keyboard I have ever used. So that's disappointing.</p>
<p>I think to improve upon this you'd probably want to reduce the activation force (that's easy, just make the spring thinner) and add some tactile feedback so it is easier to tell
when the switch has actually been pressed. Beyond that, I'm not sure.</p>
<h2>Switches</h2>
<p><a href="https://img.incoherency.co.uk/2841"><img src="https://img.incoherency.co.uk/2841"></a></p>
<p>If you want to learn more about the switches, I would recommend looking at some of my other <a href="https://incoherency.co.uk/blog/tags/keyboard.html">posts tagged "keyboard"</a>, but in short:
pressing on the stem at the top compresses the spiral spring (I copied the spring design from <a href="https://www.youtube.com/channel/UCSsm4h2ccJMdR6bsAFyIu6A">Riskable 3D Printing</a>, he
is also developing 3d-printable keyboard switches, but using magnet sensors instead of making mechanical switches himself). Once
the stem is pressed down far enough, a contact wire bridges the 2 contacts at the bottom, activating the switch. As the switch is pressed further, the leaf spring compresses, allowing
the stem to move further down while allowing the contact wire to remain in place. Eventually the spiral spring bottoms out against its casing and then stem movement stops. When the key is released,
the spiral spring pushes everything back up to the top.</p>
<p>The leaf spring has a section in its bend that is narrow in the "other" axis, to allow it easily tilt side-to-side to ensure good contact with both of the contact wires.</p>
<p>I don't have a good photo of the latest switch design, but I have this of an earlier version:</p>
<p><a href="https://img.incoherency.co.uk/2757"><img src="https://img.incoherency.co.uk/2757"></a></p>
<p>The working principle is the same but the new version is a bit shorter.</p>
<p>The switches are printed in PETG. If you want to see them in action, you might enjoy my <a href="https://www.youtube.com/watch?v=hRBQBf6jzFM">video of operating the switch tester</a>.
The final incarnation of the switch design lasted over 350k presses in all cases, and some instances still hadn't failed at 500k presses. This is a lot lower than the "tens of millions" that might be
expected of a commercial switch, but it's a big improvement over <a href="https://incoherency.co.uk/blog/stories/keyswitch-failure.html">13907</a> which is where the first iteration failed, and that was on an extremely
gentle machine.</p>
<p>I said I was going to experiment with moving the activation point down to 75% of the plunger travel so as to reduce the strain on
the leaf spring. I did test this on the <a href="https://incoherency.co.uk/blog/stories/another-new-tester.html">new machine</a>, with 5 of the old design and 5 of the new design side-by-side, and the new design lasted almost
twice as long, so that was a good improvement.</p>
<p>The gold-plated "jewellery wire" that I bought off eBay ended up working well and soldering well (so I conclude it was not varnished),
and 4 metres (costing £4) was <i>just</i> enough to do the entire keyboard.</p>
<p>If you want, you can <a href="https://incoherency.co.uk/interest/3dpswitch.tar.gz">download the switch CAD</a>, including STL and FreeCAD files.</p>
<h2>Case</h2>
<p><a href="https://img.incoherency.co.uk/2805"><img src="https://img.incoherency.co.uk/2805"></a></p>
<p><a href="https://img.incoherency.co.uk/2804"><img src="https://img.incoherency.co.uk/2804"></a></p>
<p><a href="https://img.incoherency.co.uk/2832"><img src="https://img.incoherency.co.uk/2832"></a></p>
<p>The case is split into 2 halves that are then glued together, so that it fits on the bed of the 3D printer. There is a large rectangular hole at the top and bottom in each half, and a long bit of plastic
inside joining them, to add a bit more strength to the joint. There's not a lot to the case design really, it is just a shape to fit the switches into,
with a bulge at the top to house the microcontroller, an exit hole for the cable, stabiliser mounts, and a cool-looking logo. I made the general shape of the case halves in FreeCAD, and then imported the resulting STL
into OpenSCAD to cut out the holes for the switches, because I found it easier to get the layout correct with code.</p>
<p>I printed the logo in a different colour by having the printer stop and wait for me to change the filament at the layer height where the colour changes, using the
<a href="https://marlinfw.org/docs/gcode/M600.html">M600</a> G-code command. PrusaSlicer has a nice GUI for setting this up, so I didn't even need to manually edit the G-code.</p>
<p><a href="https://img.incoherency.co.uk/2846"><img src="https://img.incoherency.co.uk/2846"></a></p>
<p>If I were to make another keyboard, I would give myself more space to work with underneath by reducing the thickness of the "solid" middle part that the switches are mounted in.
I found that there was not really enough room to run the diodes and wires. I would also add provision for a few screws to attach a bottom cover to protect the wiring inside.</p>
<p>The case and keycaps are printed in Prusament Galaxy Black PLA, which I think gives a really nice finish.</p>
<h2>Keycaps</h2>
<p><a href="https://img.incoherency.co.uk/2848"><img src="https://img.incoherency.co.uk/2848"></a></p>
<p>The keycaps were designed using <a href="https://github.com/rsheldiii/KeyV2">KeyV2</a>, a free parametric keycap library for OpenSCAD. If you want to design
some keycaps, you should check out KeyV2. Its creator, <a href="https://github.com/rsheldiii">Bob</a>, is friendly and gave me helpful advice and assistance.</p>
<p>There are several different ways to make an ISO (UK-style) enter key in KeyV2, but I couldn't find any combination of settings that would let me have rounded corners, sloping top,
and dished top, so I ended up making the enter key by hand in FreeCAD.</p>
<p>I was originally going to use "outset" legends on the keycaps, like I used on the <a href="https://incoherency.co.uk/blog/stories/3pct-keyboard.html">macro keypad</a>. But I read this comment in the KeyV2 source
which changed my mind, so I used inset legends instead:</p>
<pre><code>// make legends outset instead of inset.
// broken off from artisan support since who wants outset legends?
$outset_legends = false;</code></pre>
<p>But having printed all the keycaps, I'm not sure whether I think inset legends actually <i>are</i> better. They range from "perfectly fine" to "almost invisible" depending on the lighting. I'd
say the outset legends were easier to read.</p>
<h2>Wiring</h2>
<p><a href="https://img.incoherency.co.uk/2836"><img src="https://img.incoherency.co.uk/2836"></a></p>
<p>The switches are hand-wired in a 15x5 <a href="https://en.wikipedia.org/wiki/Keyboard_matrix_circuit">keyboard matrix</a>, with diodes allowing current to pass only in one direction. 14x5 would be enough
if you thought about it a bit more than I did, but 15x5 is fine.</p>
<p>Originally I was planning to use an Arduino for the microcontroller, which has only 16 IO pins. This would allow for an 8x8 matrix, but when I went to layout the wiring, I came up with this, where
red is columns and green is rows:</p>
<p><a href="https://img.incoherency.co.uk/2824"><img src="https://img.incoherency.co.uk/2824"></a></p>
<p>Obviously this is too complicated to wire up in real life, particularly in the small amount of space provided in the bottom of my case. You may also notice it was too complicated for me to
lay out in GIMP, as I have failed to connect the full-stop and apostophe keys to any row. For these reasons I decided to use a <a href="https://www.pjrc.com/teensy/">Teensy</a> 2.0 instead, which allowed me to use a more sensible matrix layout:</p>
<p><a href="https://img.incoherency.co.uk/2835"><img src="https://img.incoherency.co.uk/2835"></a></p>
<p>(I laid this out on <a href="https://kbfirmware.com/">kbfirmware.com</a>).</p>
<p>The other part of the wiring is that the USB cable has to reach the microcontroller. I left a 4mm hole in the side of the case for the cable to run through, but this is too small for the connector
on the end. I was originally planning to cut the connector off and solder the wires directly to the USB pads on the micocontroller board, but they were too small and annoying to access, so instead
I just soldered the MiniUSB end back on and plugged it in. It's a tight fit but it does the job.</p>
<p><a href="https://img.incoherency.co.uk/2847"><img src="https://img.incoherency.co.uk/2847"></a></p>
<p>In hindsight, I am not sure whether I regret hand-wiring the keyboard. I toyed with the idea of getting a PCB made up that I could directly solder my switches to. It would certainly have
made it easier to put the keyboard together, but I thought outsourcing the manufacturing of a PCB kind of takes the edge off making your own switches...</p>
<h2>Stabilisers</h2>
<p>Here's a clip showing how the stabilisers work:</p>
<p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZTvDP3Qutwk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>The idea is that when you press down on one side you cause the bar to rotate, which then pulls down on the other side of the switch, forcing the key to move down parallel (instead of rocking)
and activate the switch properly. The bar is made of 1.75mm stainless steel wire bent into a suitable shape. Thick stainless wire is quite hard to cut, but doable with a big-ish pair of nippers.</p>
<p>While trying to fit the stabilisers for the spacebar, I managed to break off the mounts attached to the case. This is bad news because the case halves are about a 10-hour print each, and aside from
that I had already soldered up all of the switches. To reprint the case halves would involve undoing all of my soldering work, and then 20 hours of printing, and then redoing all of the soldering.</p>
<p>I wasn't interested in redoing all of that work, so as a last resort I drilled a hole into the case in the position of each stabiliser mount, and printed 2 new stabiliser mounts, long enough to fit
in the holes. I printed the mounts in PETG so that they'd be less likely to break.</p>
<p><a href="https://img.incoherency.co.uk/2842"><img src="https://img.incoherency.co.uk/2842"></a></p>
<p>This worked really well, disaster averted! The mounts were a tight fit in the drilled holes so I didn't even need to use any glue.</p>
<h2>QMK</h2>
<p>I used <a href="https://qmk.fm/">QMK</a> for the keyboard firmware, running on a Teensy 2.0. I found it quite hard to get started with my custom keyboard, because almost all of the documentation
is geared towards the case where you are using an off-the-shelf keyboard which is already defined in QMK. The key point I needed to know was that you can use the script "<tt>./util/new_keyboard.s…</tt></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://incoherency.co.uk/blog/stories/jesboard.html">https://incoherency.co.uk/blog/stories/jesboard.html</a></em></p>]]>
            </description>
            <link>https://incoherency.co.uk/blog/stories/jesboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24081046</guid>
            <pubDate>Fri, 07 Aug 2020 12:17:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pocket P.C. Open Sourced]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24078853">thread link</a>) | @nullagent
<br/>
August 6, 2020 | https://blog.popcorncomputer.com/2020/08/05/pocket-p-c-open-sourced/ | <a href="https://web.archive.org/web/*/https://blog.popcorncomputer.com/2020/08/05/pocket-p-c-open-sourced/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-194">

	
<!-- .entry-header -->

	<div>

		<div>

			
<div><figure><img src="https://opensource.popcorncomputer.com/community/bottom-2lyr-pcb-twitter-resolution-scaled.jpg" alt=""></figure></div>



<p>If you would like to follow along with the latest design or would like to dive deep into the internals of <a href="https://pocket.popcorncomputer.com/" target="_blank" rel="noreferrer noopener">Pocket P.C.</a> we have created a repository on <a href="https://github.com/PopcornComputer/PocketPC-Hardware" target="_blank" rel="noreferrer noopener">GitHub</a> for the latest hardware files. The work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/3.0/us/">Creative Commons Attribution-ShareAlike 3.0 United States License</a>.</p>



<p>&nbsp; Click the GitHub image below to check out the latest files.</p>



<figure><a href="https://github.com/PopcornComputer/PocketPC-Hardware" target="_blank" rel="noopener noreferrer"><img src="https://opensource.popcorncomputer.com/blog/GitHub_PocketPC.png" alt="GitHub Repository Badge"></a></figure>



<h3><strong>We are one step closer to shipping Pocket P.C. with the latest developments.</strong></h3>



<p>The latest D.V.T PCB design is out for production. We expect the PCBs to arrive within 10-12 days.&nbsp; After that, we will be assembling 25 units.</p>



<p>The D.V.T. design brings with it a newly added SPI Flash which will allow <a href="https://pocket.popcorncomputer.com/" target="_blank" rel="noreferrer noopener">Pocket P.C. </a>to more easily boot multiple operating systems on the same <a href="https://pocket.popcorncomputer.com/" target="_blank" rel="noreferrer noopener">Pocket P.C.</a> We also changed the design to a 10-layer PCB stackup vs. 8-layers which will ensure better signal integrity for high-speed signals.</p>



<p>The keyboard layout has been tweaked incorporating feedback from community suggestions and from hands-on the 3D printed prototypes. Thank you to everyone who submitted feedback about our initial layout. The space bar has been extended to allow for it to be pressed from a comfortable hand position and a few other minor changes. You can view the latest layout in our community keyboard thread here: <a href="https://community.popcorncomputer.com/t/pocket-p-c-keyboard-layout-part-2/541" target="_blank" rel="noreferrer noopener">Pocket P.C. Keyboard Layout (Part 2)</a></p>



<p>We learned a lot from the last production run of Original Popcorn. We did not receive the level of support that we were promised from the USB-C IC manufacturer that we chose to handle the USB Power Delivery system. As such, we changed the <a href="https://pocket.popcorncomputer.com/" target="_blank" rel="noreferrer noopener">Pocket P.C.</a> design to incorporate a robust Texas Instruments single-chip solution. With this new solution, we added to the design dedicated port protector ICs with ESD protection and surge protection ICs also from Texas Instruments on every ports. This will make the design more robust to faulty power conditions.</p>



<p>Finally, to ensure that <a href="https://pocket.popcorncomputer.com/" target="_blank" rel="noreferrer noopener">Pocket P.C. </a>has great software support out of the box, we have requested embedded development help from the community. Our goal is to ensure that we get all aspects of our products mainlined so that custom kernels will not be required. In order to accomplish this, a community effort is required to review and test new solutions before submitting them to the Linux Kernel mailing list. If you are interested in following with our development efforts you can join the discussion here: <a href="https://community.popcorncomputer.com/t/embedded-linux-development-help-requested/559/15" target="_blank" rel="noreferrer noopener">Embedded Linux Development Help Requested</a></p>



<figure><img src="https://opensource.popcorncomputer.com/community/top-2lyr-pcb-twitter-resolution-scaled.jpg" alt=""></figure>



<h3>Visit the shop to pre-order your Pocket P.C. today!</h3>



<h4><a href="https://shop.popcorncomputer.com/" target="_blank" rel="noreferrer noopener"><strong>Pre-order Now</strong></a></h4>



<h3>Keep up to date on the latest developments in our community.</h3>



<p>In an effort to be more transparent with the latest on-goings with development and production, we have created a community thread where we will post updates as they happen.</p>



<h4><a href="https://community.popcorncomputer.com/t/pocket-p-c-development-updates/552" target="_blank" rel="noreferrer noopener"><strong>Community Website</strong></a></h4>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://blog.popcorncomputer.com/2020/08/05/pocket-p-c-open-sourced/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24078853</guid>
            <pubDate>Fri, 07 Aug 2020 06:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terminating a Frozen SSH Session]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24076656">thread link</a>) | @erredois
<br/>
August 6, 2020 | https://www.remembertheusers.com/2020/07/0668-terminating-a-frozen-ssh-session.html | <a href="https://web.archive.org/web/*/https://www.remembertheusers.com/2020/07/0668-terminating-a-frozen-ssh-session.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
   <div>
    

    <p>One of my observations about computer software is no matter how much I know there is something new to learn every day.</p>

    <p>I have been using SSH for many years. I use a local <code>config</code> file and multiple key pairs to connect to remote systems.</p>

    <p>Occasionally an SSH session times out or somehow freezes. Often this leaves the terminal window in a frozen state, requiring a forced closure.</p>

    <p>Except a forced closure might not be needed. There is a built-in SSH escape trigger.</p>

    <p>Press the <code>~</code> (tilde) key. Notice that the <code>~</code> won’t appear on screen when the character is the very first character typed. The character prints on screen normally when not the first character.</p>

    <p>To view a list of available options with this escape trigger type <code>~?</code>.</p>

    <p>To force terminate a frozen SSH session, press <code>~.</code>. The result is much the same as <code>Ctrl+C</code> or <code>Ctrl+D</code> to terminate a process.</p>

    <p>The escape character can be changed using the <code>-e</code> option.</p>

    <p>Posted: <span>July 19, 2020</span> Category: <span><a href="https://www.remembertheusers.com/categories/usability.html">Usability</a></span> Tagged: <span><a href="https://www.remembertheusers.com/tags/general.html">General</a></span></p>

    <p>Next: <span><a href="https://www.remembertheusers.com/2020/07/0669-resolving-problems.html">Resolving Problems</a></span></p>

    <p>Previous: <span><a href="https://www.remembertheusers.com/2020/07/0667-google-captchas.html">Google Captchas</a></span></p>
   </div>
  </div>
 </div></div>]]>
            </description>
            <link>https://www.remembertheusers.com/2020/07/0668-terminating-a-frozen-ssh-session.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24076656</guid>
            <pubDate>Thu, 06 Aug 2020 23:58:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Impressions of Rust]]>
            </title>
            <description>
<![CDATA[
Score 266 | Comments 180 (<a href="https://news.ycombinator.com/item?id=24076083">thread link</a>) | @jmillikin
<br/>
August 6, 2020 | https://john-millikin.com/first-impressions-of-rust | <a href="https://web.archive.org/web/*/https://john-millikin.com/first-impressions-of-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blog-article posted="2020-08-06T22:23:05Z"><p><img src="https://john-millikin.com/first-impressions-of-rust/crab.jpg"></p><p>I've been wanting to write a big project in <a href="https://www.rust-lang.org/">Rust</a> for a while as a learning exercise, and actually started one in late 2018 (a FUSE server implementation). But then life happened and I got busy and never went anywhere with it. Due to certain world circumstances I'm currently spending a lot of time indoors so <a href="https://github.com/jmillikin/rust-fuse">rust-fuse</a> (<a href="https://jmillikin.github.io/rust-fuse/fuse-v0.0.1-a6ad16d1127d36f80e6d02f36e48da56920ca693/fuse/">docs</a>) now exists and is good enough to write basic hello-world filesystems. I plan to polish it up a bit more with the goal of releasing a v1.0 that supports the same use cases as <a href="https://github.com/libfuse/libfuse">libfuse</a>.</p><p>I took some notes along the way about things that struck me as especially good or bad. Overall I quite like Rust the language, have mixed feelings about the quality of ancillary tooling, and have strong objections to some decisions made by the packaging system (Cargo + crates.io).</p><blog-section><h2 slot="title">Background</h2><p>I've been programming professionally for 15 years, primarily network servers and GUIs on Linux. Between roughly 2009 and 2015 I experimented with using Haskell for systems programming, writing several projects in pure Haskell (<a href="https://john-millikin.com/software/haskell-dbus">haskell-dbus</a>, <a href="https://john-millikin.com/software/anansi">Anansi</a>) and as bindings (<a href="https://john-millikin.com/software/haskell-ncurses">haskell-ncurses</a>, <a href="https://john-millikin.com/software/haskell-cpython">haskell-cpython</a>). However, I couldn't achieve the sorts of reliability improvements over bread-and-butter C++ that I had hoped for:</p><ul><li>Haskell has a lot of tools for reasoning about the structure of computation, notably monads for declarative I/O, but it doesn't do much to help the programmer with non-algorithmic concerns such as memory lifetimes. I spent a lot of time debugging dangling pointers and race conditions.</li><li>I found it very difficult to write Haskell code that could run as fast as C. Avoiding allocation, auto-boxing, etc felt like it required a deep knowledge of undocumented or unspecified GHC behavior.</li></ul><p>In late 2015 I started rough sketches for a new language, Funk, that would combine the type-safety of Haskell with the low-level precision of C/C++. Funk was strongly influenced by Google's internal dialect of C++, which uses smart pointers and sum types (e.g. <tt>StatusOr&lt;T&gt;</tt>) to improve memory safety – many of its features later became part of the C++11 and C++14 standards. To this foundation I bolted on Haskell-style typeclasses and modules, then started writing a Funk-to-C translator based on <a href="https://wiki.gnome.org/Projects/Vala/Documentation">Vala</a>.</p><p>At some point I was looking around for inspiration on how to handle memory allocation (I planned to use scoped arenas as the fundamental dynamic memory system) and I discovered Rust. Here was a language that was solving the same problems as Funk but (1) better designed (2) already implemented and (3) supported by an entire team of compiler experts. So that was that, Funk went to <tt>/dev/null</tt> and I logged a TODO to learn Rust.</p></blog-section><blog-section><h2 slot="title">The Rust language</h2><p>It shouldn't come as a surprise that someone looking for a cross between C++ and Haskell would like Rust, but I want to be clear: I really <i>really</i> enjoy using Rust. It is nearly everything I want in a systems programming language, and the few parts it's missing are due to legitimate technical difficulty. The amount of careful thought I've seen put into its design – crafting <tt>async/await</tt> to work in <tt>no_std</tt> environments, or the <a href="https://blog.rust-lang.org/inside-rust/2020/06/08/new-inline-asm.html">new inline assembly syntax</a> – has produced a language that is not only better than what I could have designed, it's better among axes I was not even aware existed prior to reading the Rust RFCs.</p><p>The "nightly" release channel is an excellent idea that I wish more infrastructure software made use of. Stabilizing individual features on their own schedules lets the compiler maintain a blistering release cadence (stable releases every <i>six weeks</i>!). Users are empowered to choose their own preferred point on the maintenance/velocity curve, opting in to higher upgrade costs in exchange for early access to new features. The "editions" system goes a bit further, derisking backwards-incompatible syntax changes that would have stymied C++ for decades (see: trigraphs).</p><blog-section><h3 slot="title">Type system</h3><p>Rust has a reasonable amount of Haskell-style type programming, though I wouldn't mind a <i>bit</i> more. Some parts of its type system are limited in non-intuitive ways – for example only lifetime-kinded type parameters can be universally quantified in a trait bound. I hit a lot of compiler errors that recognized exactly what I wanted to do but wouldn't let me do it.</p><p>I wish Rust's type system supported:</p><ul><li>Closed-world ("sealed") traits. Rust's rules against private types in the public API are good civilization but they make it difficult to define pseudo-private traits like <tt>Mount</tt> that I want users to name but not implement or call into.</li><li>Associated types in structs. Rust lets traits have associated types, and structs can have associated <i>values</i>, but there's no equivalent to the nested type names found in C++ or Java.</li><li>Very basic dependent typing, or maybe something like Eiffel's contracts, for the purpose of eliminating array bounds checks. I'd like to be able to say "this function accepts a <tt>&amp;[u8]</tt> of at least <tt>size_of&lt;SomeType&gt;</tt>" so I can do safe unchecked byte poking.</li></ul></blog-section><blog-section><h3 slot="title">Standard library</h3><p>There's a lot of standard UNIX functionality that's missing from the Rust standard library. Some of it is more-or-less available from separate packages like <a href="https://crates.io/crates/nix">nix</a>, but I shouldn't have to depend on four crates plus a C compiler to get access to <tt>getuid()</tt>. I shouldn't have to depend on <i>anything</i> to get the definition of <tt>ENOSYS</tt> or the size of <tt>c_ulong</tt>. Go is the gold standard here – it can cross-compile to a Linux target from macOS using its own copies of the Linux syscall table – and even Haskell has <a href="http://hackage.haskell.org/package/base-4.14.0.0/docs/Foreign-C-Types.html"><tt>Foreign.C.Types</tt></a>.</p><p>A <tt>std::os::unix</tt> without <tt>getuid()</tt> is incomplete but can be worked around with a small <tt>extern "C"</tt> block. Much worse is the lack of macro-dependent functions like <tt>recvmsg()</tt>, which is not a great API to begin with, or functions with OS-dependent arity like <tt>mount()</tt>. Rust is not averse to providing clean wrappers around the OS library – the <tt>std::fs</tt> and <tt>std::process</tt> modules contain little else – so it's frustrating to see these very basic functions left out.</p></blog-section></blog-section><blog-section><h2 slot="title">Tooling</h2><blog-section><h3 slot="title">rustdoc</h3><p>I categorize documentation generators into two basic groups:</p><ul><li>First is the <a href="https://www.sphinx-doc.org/">Sphinx</a> group, which consumes prose and uses embedded pragmas to reference symbols of the library being documented. The output layout tends to be textbook-like, containing long "chapters" that might cover entire modules in one HTML file. Sphinx-style docs are popular among Python programmers.</li><li>Second is the <a href="https://www.doxygen.nl/">Doxygen</a> group, which consumes source code and generates a rigidly-structured catalog of symbols with optional attached prose. The output feels more like an encyclopedia or reference manual.</li></ul><p><tt>rustdoc</tt> is obviously in the second category. It is designed to consume doc comments, which are special-cased by the Rust compiler, and produces output closely matching the structure of the exported API. At this task <tt>rustdoc</tt> does a reasonable job: the page layout is navigable, the markup format (<tt>rustdoc</tt> uses Markdown) isn't great but it could be worse, and it doesn't hardcode absolute file paths into the output like Haddock.</p><p>Some of its annotations, like whether a symbol is OS-specific (<a href="https://github.com/rust-lang/rust/issues/43781">rust-lang/rust#43781</a>), are gated to the Nightly toolchain. It's not obvious to me why they do this – it's a documentation generator, why does it care what version of the Rust compiler I'm using? What's more, some of its functionality is reserved for the standard library only. I can't mark fields as unstable (subject to change in future library versions) because that annotation is based on the <tt>#[unstable]</tt> attribute, which the compiler reserves for its own use. Ditto for annotations about which version a symbol was added in. If I'm going to use a Doxygen-group tool then I don't want it to get too fussy about what libraries it's documenting.</p></blog-section><blog-section><h3 slot="title">rustfmt</h3><p>Something like a cross between <tt>gofmt</tt>, <tt>clang-format</tt>, and GNU indent. It has a lot of configuration options but all the interesting ones are gated to Nightly, and most of those are much less useful than you might expect.</p><p>As a representative sample, consider <tt>rustfmt</tt>'s handling of hard tabs. Given the following input there are two basic ways you might use hard tabs to indent it, depending on whether struct value alignment should apply to nested structs:</p><blog-code><pre>MyStruct{
  field_with_long_name: (some_big_complex_variable_name + another_big_complex_variable_name),
  another_field: 123,
  nested_struct: &amp;NestedStruct{
    nested_struct_field: 456,
  },
  final_field: 123,
}
</pre></blog-code><p>The first is to treat the nested struct as a "break" in the alignment (<tt>gofmt</tt> does this). I've drawn the tabs as <span>████</span> for clarity:</p><blog-code><pre><code>MyStruct{
<span>████</span>field_with_long_name: (some_big_complex_variable_name
<span>████</span>                       + another_big_complex_variable_name),
<span>████</span>another_field:        123,
<span>████</span>nested_struct: &amp;NestedStruct{
<span>████████</span>nested_struct_field: 456,
<span>████</span>},
<span>████</span>final_field: 123,
}
</code></pre></blog-code><p>The second is to align all the values, including the nested struct, and introduce a nested layer of tabs:</p><blog-code><pre><code>MyStruct{
<span>████</span>field_with_long_name: (some_big_complex_variable_name
<span>████</span>                       + another_big_complex_variable_name),
<span>████</span>another_field:        123,
<span>████</span>nested_struct:        &amp;NestedStruct{
<span>████</span>                      <span>████</span>nested_struct_field: 456,
<span>████</span>                      },
<span>████</span>final_field:          123,
}
</code></pre></blog-code><p>But what <tt>rustfmt</tt> produces is an indecisive and poorly formatted combo of the two – it doesn't even properly align the parenthesized expression after line-breaking it:</p><blog-code><pre><code>MyStruct {
<span>████</span>field_with_long_name: (some_big_complex_variable_name
<span>████████</span>+ another_big_complex_variable_name),
<span>████</span>another_field:        123,
<span>████</span>nested_struct:        &amp;NestedStruct {
<span>████████</span>nested_struct_field: 456,
<span>████</span>},
<span>████</span>final_field:          123,
}
</code></pre></blog-code><p>I eventually gave up on trying to make the formatted rust-fuse code look pretty, and settled for "consistent".</p></blog-section></blog-section><blog-section><h2 slot="title">Cargo and crates.io</h2><p>While the Rust language feels carefully designed to combine the best parts of multiple popular and interesting languages, Rust's default build system (Cargo) and package repository (crates.io) are the opposite. They combine the worst parts of Cabal/Hackage and NPM, resulting in a user experience that is somehow inferior to both.</p><blog-section><h3 slot="title">Pa…</h3></blog-section></blog-section></blog-article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://john-millikin.com/first-impressions-of-rust">https://john-millikin.com/first-impressions-of-rust</a></em></p>]]>
            </description>
            <link>https://john-millikin.com/first-impressions-of-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24076083</guid>
            <pubDate>Thu, 06 Aug 2020 22:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surviving Django, if you care about databases]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 215 (<a href="https://news.ycombinator.com/item?id=24074520">thread link</a>) | @pauloxnet
<br/>
August 6, 2020 | https://www.varrazzo.com/blog/2020/07/25/surviving-django/ | <a href="https://web.archive.org/web/*/https://www.varrazzo.com/blog/2020/07/25/surviving-django/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div id="content"><p>Django is currently the most commonly used full-stack web framework for Python. It has
been around for a good 15 years, emerging as a winner from a period in which
Python was already mature, but its web development tools were comparatively
much more immature and fragmented.</p>
<p>Django allows the definition of objects in your program as "models" using the
<tt>Model</tt> base class. They behave largely like normal Python classes, with
added support to save into, and retrieve from, the relational database backing
your application. If you don't need such database support, you didn't
need a full-stack web framework in first place.</p>
<p>Django tries to be independent from the database you choose. It sounds like
a good idea, but only on paper. After working several years
with Django systems, both written from scratch or inherited and maintained, I
feel the "blessed" way of working with databases and
Django leads you to using your database in a sub-optimal way, and unnecessarily complicates
the development and maintenance cycle of your project.</p>
<p>I think the divergence between wishful thinking and reality starts from a
fundamental misunderstanding between you and Django, which is not written in
the contract you haven't signed with them anyway:</p>
<blockquote>
"independence from the relational database" is a feature needed by Django
as a framework, <em>not by the program you are writing</em>.</blockquote>
<p>Django needs it because a web framework not tied to a single database vendor
is more valuable than one tied to a specific one - and that's fair enough. <em>But you
don't:</em> your web program, most likely than not, will not have to switch from
one database to another. So, <a href="https://www.martinfowler.com/bliki/Yagni.html">You Ain't Gonna Need It™</a>. Portability at all costs
leads to at least two problems:</p>
<p>1) You will not able to use all the features offered by your relational
database.</p>
<p>2) Every change to your models, or to your database schema, will be more
complicated than it should be.</p>
<div id="you-ain-t-gonna-need-it">
<h3>You Ain't Gonna Need It</h3>
<p>How many times have you worked on a project and, after 1-2 years of
development, you have changed to a different database?</p>
<p>I can tell you how many times it happened to me, I counted them: exactly
never.</p>
<p>Replacing your database vendor is a major, traumatic occurrence, almost as
much as rewriting your program in a different language. If you replace your
database, more likely than not, it is because you are interested in the
features of the new databas. You need to use them so using the common
functionalities between the old and the new one will not solve any of your
problems.</p>
<p>Did you maybe start your project with SQLite and now your project grew enough
to need a bigger database? If so then you are still at the phase in
which your project is a toy: you haven't done anything yet that requires
thinking in terms of concurrency. Even if you have to rewrite a few things,
it's not going to be a lot.</p>
<p>Do you have a large MySQL project and now you have to migrate to PostgreSQL?
That's not gonna happen: you have probably tweaked MySQL, have expertise in
MySQL. Maybe PostgreSQL might be a better database in some aspects, but not so much
that you want to migrate all your data and start from scratch without
<a href="http://www.catb.org/jargon/html/F/frobnicate.html">frobbing, twiddling, tweaking</a> the database configuration. Did you say
you have High Availability and Disaster Recovery configured? That's to be
converted too of course.</p>
<p>In the above paragraph, replace the database vendor with all the permutations
of MySQL, PostgreSQL, MS SQL, Oracle. <em>That's not gonna happen</em>. Except maybe
if an Oracle salesman gets hold of someone in your project with a modicum of
decision making and talks them into buying some sort of expensive license, but
that's not a technical problem, it's a political one, and it's up to you to
decide if you are comfortable with it.</p>
<p>Have you got PostgreSQL in production, but you want to test with SQLite because
it's easier to set up? If so, your tests are just a tick-box exercise: you
are not testing anything remotely plausible and resembling your live system.</p>
<p>Choosing a database happens in the first days of your projects, it will not
happen when the project is mature. You may as well use all the features
available with your database, not only the ones common enough that Django
created a Python wrapper for it.</p>
</div>
<div id="use-all-the-features">
<h3>Use all the features</h3>
<p>Scanning the schema of a Django program I've written and maintained for a few
years I see:</p>
<ul>
<li>Schemas (as in the "directory of the tables", not all the other meanings)</li>
<li>Custom domains</li>
<li>Collations</li>
<li>Triggers</li>
<li>Permissions</li>
<li>Partial indexes</li>
<li>Constraint exclusions</li>
<li>Views</li>
<li>Stored procedures</li>
<li>Partitioned tables</li>
</ul>
<p>If these features were used, it's because they allowed to implement
certain features needed for the program in a simpler way than what possible in
the language (if even would have been possible there). Audit for
instance: Django doesn't have an audit feature except for the changes made in
the admin. Even if you added some form of manual auditing to each <tt>save()</tt>
method, it will not capture changes made outside Django. It wouldn't be very
secure either: Django uses a single user to access the database so if someone
manages to hijack that user, they would be able to change the data in the database
and alter the audit tables to hide their traces.</p>
<p>In PostgreSQL you can:</p>
<ul>
<li>Create an "audit" user: it will have different permissions than the user of
the Django application.</li>
<li>Create an "audit" schema: revoking write permission to all the objects it
will contain from the Django user.</li>
<li>Create a function to append a record to an audit table owned by the "audit"
user, but callable by the Django user.</li>
<li>Add a trigger to the tables to audit.</li>
</ul>
<p>This setup requires Postgres-specific knowledge, which is fair for a feature
that has to watch over the database data whichever the origin of the change
is. But being PostgreSQL extensible as it is, you can <a href="https://github.com/dvarrazzo/pgaudit">use an extension</a> to automate the creation and
maintenance of the audit triggers and functions.</p>
</div>
<div id="so-where-do-i-put-the-schema">
<h3>So where do I put the schema?</h3>
<p>Into an SQL file!</p>
<p>With its tiny <tt>.sql</tt> extension!</p>
<p>And with comments! Explaining why a certain index or constraint exist!</p>
<p>With constraints named meaningfully, available for manipulation, not
<tt>auth_group_permissions_group_id_b120cbf9_fk_auth_group_id</tt>.</p>
<p>Sounds civilised to me.</p>
<p>The nice thing of doing this is that, if you do things carefully enough, Django
will not notice anything at all.</p>
<p>Take the above audit examples: Django is not meant to interact with it:
everything will just happen under its nose. You can use views instead of
tables for read-only models, you can use domains instead of more basic data
types for your fields: Django won't see your triggers triggering, your
constraints constraining, your permissions permitting - except when things go
wrong, which will result in an error 500 and a Python traceback. This is at least
better than bad data in the database. Also it won't see your procedures
proceeding, your domains dominating...you get the idea.</p>
<p>Using psql to import the schema into an empty database means you can modularise the
code and use <tt>\i</tt> to import "submodules". A typical pattern for me is to have
a <tt>database.sql</tt> to create global objects (users, extensions, schemas),
set the basic permissions and import the details into target schemas.</p>
<pre><span>\</span><span>i</span> <span>users</span><span>.</span><span>sql</span>
<span>revoke</span> <span>create</span> <span>on</span> <span>schema</span> <span>public</span> <span>from</span> <span>public</span><span>;</span>     <span>-- safety
</span>
<span>--- create a schema for the django app tables
</span><span>create</span> <span>schema</span> <span>myapp</span><span>;</span>
<span>grant</span> <span>usage</span> <span>on</span> <span>schema</span> <span>myapp</span> <span>to</span> <span>myapp</span><span>,</span> <span>backup</span><span>;</span>

<span>--- set the default permissions for all the object that will be created there
</span><span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span>
    <span>grant</span> <span>select</span><span>,</span> <span>insert</span><span>,</span> <span>update</span><span>,</span> <span>delete</span> <span>on</span> <span>tables</span> <span>to</span> <span>myapp</span><span>;</span>
<span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span>
    <span>grant</span> <span>select</span> <span>on</span> <span>tables</span> <span>to</span> <span>view</span><span>,</span> <span>backup</span><span>;</span>
<span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span> <span>grant</span> <span>all</span> <span>on</span> <span>sequences</span> <span>to</span> <span>myapp</span><span>;</span>
<span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span> <span>grant</span> <span>select</span> <span>on</span> <span>sequences</span> <span>to</span> <span>backup</span><span>;</span>

<span>--- import the tables into the schema
</span><span>set</span> <span>search_path</span> <span>to</span> <span>myapp</span><span>,</span> <span>public</span><span>;</span>
<span>\</span><span>i</span> <span>django</span><span>.</span><span>sql</span>   <span>-- django objects - users, groups, permissions tables
</span><span>\</span><span>i</span> <span>myapp</span><span>.</span><span>sql</span>    <span>-- your app models
</span><span>reset</span> <span>search_path</span><span>;</span>
</pre>
<p>The <tt>database.sql</tt> doesn't create the database itself so you can create an
empty one anywhere it's needed, then you can use <tt>psql <span>-f</span> database.sql
<span>"postgres://connection/url"</span></tt> to populate it. The <tt>myapp.sql</tt> file
shouldn't contain any reference to the schema <tt>myapp</tt> where the objects are
created so the schama can be easily changed. Postgres doesn't have a statement like
<tt>CREATE USER ... IF NOT EXIST</tt>: in <tt>users.sql</tt> you can simulate it with:</p>
<pre><span>do</span> <span>$</span><span></span><span>$</span>
<span>begin</span>
    <span>perform</span> <span>1</span> <span>from</span> <span>pg_user</span> <span>where</span> <span>usename</span> <span>=</span> <span>'myapp'</span><span>;</span>
    <span>if</span> <span>not</span> <span>found</span> <span>then</span>
        <span>create</span> <span>user</span> <span>myapp</span><span>;</span>
    <span>end</span> <span>if</span><span>;</span>
<span>end</span>
<span>$</span><span></span><span>$</span> <span>language</span> <span>plpgsql</span><span>;</span>
</pre>
</div>
<div id="migrations">
<h3>Migrations</h3>
<p>Django has an amazingly complex system to <a href="https://docs.djangoproject.com/en/3.0/topics/migrations/">perform model migrations</a>. It is
complex amongst other reasons because:</p>
<ul>
<li><p>It actually migrates <em>Python models</em> not <em>database schemas</em>. Even if you change a field's help
text, it generates a migration.</p>
<pre><span>class</span> <span>Migration</span><span>(</span><span>migrations</span><span>.</span><span>Migration</span><span>):</span>

    <span>operations</span> <span>=</span> <span>[</span>
        <span>migrations</span><span>.</span><span>AlterField</span><span>(</span>
            <span>model_name</span><span>=</span><span>'foo'</span><span>,</span>
            <span>name</span><span>=</span><span>'bar'</span><span>,</span>
            <span>field</span><span>=</span><span>models</span><span>.</span><span>BooleanField</span><span>(</span><span>help_text</span><span>=</span><span>'I only changed this'</span><span>),</span>
        <span>),</span>
</pre>
<p>That's not useful at all for the database, but Django will create it for you
and if you remove it, it will add it back. Similarly, changing a <a href="https://docs.djangoproject.com/en/3.0/ref/models/fields/#choices">choices
list</a>, a display label, results in migrations with no database operation,
only a Python operation, and practically no SQL purpose.</p>
</li>
<li><p>It allows access to the state of the model at times intermediate between
migrations, using <a href="https://docs.djangoproject.com/en/3.0/ref/applications/#django.apps.AppConfig.get_models">get_model</a><tt>(appname, modelname)</tt> and with some
Python code in the returned model. But if that code also happens to use
any code inside your application, importing models with a normal Python
<tt>import</tt>, things will crash because of a mismatch between model
definitions and schema in the database. But they won't crash immediately: only
later when you will apply some unrelated migration. And not when that
migration is needed: only after it has already been applied and it doesn't
have anything more to do in its lifetime: it is implemented as a model that
Django will keep on importing over and over. In a …</p></li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.varrazzo.com/blog/2020/07/25/surviving-django/">https://www.varrazzo.com/blog/2020/07/25/surviving-django/</a></em></p>]]>
            </description>
            <link>https://www.varrazzo.com/blog/2020/07/25/surviving-django/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24074520</guid>
            <pubDate>Thu, 06 Aug 2020 19:28:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Busted retailers use bankruptcy to break leases by the thousands]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 265 (<a href="https://news.ycombinator.com/item?id=24074311">thread link</a>) | @finphil
<br/>
August 6, 2020 | https://www.bnnbloomberg.ca/busted-retailers-use-bankruptcy-to-break-leases-by-the-thousands-1.1476347 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/busted-retailers-use-bankruptcy-to-break-leases-by-the-thousands-1.1476347">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the pandemic intensifying the plight of U.S. retailers, companies from J. Crew Group Inc. to the owner of Ann Taylor are using Chapter 11 bankruptcy filings to quickly get out of costly, long-term leases and shutter thousands of stores.</p>

<p>By seeking court protection, firms like Neiman Marcus Group Inc. and the parent company of Menâ€™s Wearhouse avoid the headache of protracted negotiations with individual landlords. But the moves threaten to upend huge swaths of the real estate market and the half-trillion dollar market for commercial mortgage-backed securities.</p>

<p>â€œThis is now black-letter law -- a debtor can cram down a landlord,â€� said Melanie Cyganowski, a former bankruptcy judge whoâ€™s now a partner at law firm Otterbourg PC. â€œIf this becomes a tsunami of retailers rejecting their leases, itâ€™s going to trigger another part of the sea change -- the mortgages held by the landlords.â€�</p>

<p>As bankrupt firms like J.C. Penney Co. and Brooks Brothers Group Inc. look to jettison leases, landlords are already feeling the consequences. CBL &amp; Associates Properties Inc., owner of more than 100 shopping centers in the U.S., is preparing its own bankruptcy&nbsp;filing&nbsp;after rent collections cratered. And 16 per cent&nbsp;of retail property loans bundled into CMBS were delinquent in July, according to research firm Trepp.</p>

<p><strong>Filing Surge</strong></p>

<p>At least 25 major retailers have filed for bankruptcy this year, according to data compiled by Bloomberg. The most recent additions include Tailored Brands Inc., owner of Menâ€™s Wearhouse and Jos. A. Bank, which is seeking to&nbsp;close&nbsp;about a third of its more than 1,200 stores, and Lord &amp; Taylor parent company&nbsp;Le Tote, which said it could shut down all of the department storeâ€™s remaining locations.</p>

<p>â€œItâ€™s economical, itâ€™s efficient and it allows retailers to rationalize their footprint quickly,â€� said Fred Ringel, co-chair of the business finance and restructuring practice at the law firm Robinson Brog Leinwand Greene Genovese &amp; Gluck P.C. Ringel, who works for landlords, said heâ€™s busier than ever renegotiating leases and in some cases persuading tenants to forgo cancellations and stay under modified terms.</p>

<p><img alt="Embedded Image" height="750" src="https://www.bnnbloomberg.ca/polopoly_fs/1.1476348!/fileimage/httpImage/image.png_gen/derivatives/default/a-pedestrian-wearing-a-protective-mask-walks-past-a-boarded-up-j-crew-group-inc-store-on-14th-street-in-washington-d-c-u-s-on-thursday-april-16-2020-on-wednesday-mayor-muriel-bowser-announced-an-extension-of-the-shutdown-of-nonessential-businesses-until-may-15-after-the-original-date-of-april-24.png" width="1296"></p>

<p>Take vitamin retailer GNC Holdings Inc. It operates hundreds of stores across the country, mostly in strip malls. Since filing for bankruptcy in June, GNC has asked to reject at least 500 leases, along with more than 50 franchise agreements and subleases, according to court records.</p>

<p>Meanwhile, CEC Entertainment Inc., the parent company of Chuck E. Cheese, is negotiating with its landlords after its June bankruptcy filing. It won court approval this week to defer rent payments as it evaluates which locations it wants to keep open.</p>

<p>And the U.S. unit of Spanish retailer Desigual said it was forced to file after struggling to get rent abatements from its landlords. â€œUnfortunately, DUSA had little success in getting landlords to realize the new reality that most tenants -- especially those in retail -- cannot afford to pay pre-COVID-19 rent,â€� a representative for the firm said in court papers.</p>

<p>Landlords, in turn, have their own mortgages to worry about, which were also underwritten with pre-pandemic assumptions about rent collections. Amid the stress, Barry Sternlichtâ€™s Starwood Capital Group&nbsp;missed&nbsp;payments on securitized debt linked to five shopping malls, and Saks owner Hudsonâ€™s Bay Co. also&nbsp;skipped&nbsp;interest due on certain CMBS. Delinquencies on retail mortgages bundled into bonds climbed to 16 per cent&nbsp;in July, from 3.8 per cent&nbsp;in January, according to Trepp.</p>

<p><strong>Tenant Power</strong></p>

<p>Some retailers can work out rent abatements and other lease modifications including terminations without filing for bankruptcy. However, negotiating hundreds of deals outside of a court process can be challenging, especially for big retail chains that may have hundreds of landlords to deal with, said Navin Nagrani, an executive vice president at Hilco Real Estate.</p>

<p>Bankruptcy flips the power from landlords to tenants. Retailers can legally reject a swath of leases in court, sometimes leaving building owners to collect just pennies on the dollar. Firms can also sell off favorable contracts to other parties to help repay creditors.</p>

<p>â€œSometimes a bankruptcy is the most advantageous way to get out of those leases,â€� Nagrani said.</p>

<p>As many as 25,000 stores are expected to close in the U.S. in 2020, mostly in shopping malls, according to Coresight Research. Department stores and fashion boutiques are seen as the most endangered.</p>

<p><img alt="Embedded Image" height="675" src="https://www.bnnbloomberg.ca/polopoly_fs/1.1476623!/fileimage/httpImage/image.png_gen/derivatives/default/mall-landlords-get-mauled.png" width="1200"></p>

<p>More than half of mall department stores could close for good by the end of 2021, according to an April report from real estate research firm Green Street&nbsp;Advisors. J.C. Penney said last month that it would&nbsp;shutter&nbsp;more than 150 locations, while Neiman Marcus plans to pull out of New Yorkâ€™s Hudson Yards development and&nbsp;close&nbsp;three other U.S. locations.</p>

<p>The closures so far are â€œjust the tip of the iceberg,â€� said&nbsp;Garrick Brown, head of Americas retail research for Cushman &amp; Wakefield. Over the next two years, at least 1.2 billion of square feet -- 10% of already-occupied store real estate -- will go vacant, he said. â€œWorst-case scenario, that could double.â€�</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/busted-retailers-use-bankruptcy-to-break-leases-by-the-thousands-1.1476347</link>
            <guid isPermaLink="false">hacker-news-small-sites-24074311</guid>
            <pubDate>Thu, 06 Aug 2020 19:04:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin Maxima]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24073113">thread link</a>) | @FailMore
<br/>
August 6, 2020 | https://taaalk.co/t/bitcoin-maxima-other-crypto-things#veep | <a href="https://web.archive.org/web/*/https://taaalk.co/t/bitcoin-maxima-other-crypto-things#veep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK. What is hashing? Let's just take a look.Â&nbsp;</p></div><div><p>hash("thomas hartman") =&gt; b73d127e8e76ff01b5cb833980b9712cf1dbc92064b1d2fae700105c8227121b</p></div><div><p>This beast is a 64 digit hex number. Instead of the usual 10 digits 0-9, it has the 16 digits 0-9a-f. But, it's just a number. In decimal it would be</p></div><div><p>82881156605080050388863774003735601367246355697689529077366882559854056509979</p></div><div><p>You could also use 1s and 0s, in which case there would be 256 binary 0-1 digits (bits). I'm going to go back to using hex because it will make googling for historically important hashes easier, further on. </p></div><div><p>Hashing takes some some data, my name in this case, and applies some gnarly, but basic -- but tedious -- arithmetic and cut paste type transformations to produce a 256 bit numerical output. The transformation has a lot of steps but is <a href="https://en.bitcoinwiki.org/wiki/SHA-256">completely deterministic</a>. You could do it <a href="https://www.youtube.com/watch?v=y3dqhixzGVo">by hand</a> if you were extremely careful, and extremely patient. It takes 10 hours for a human to compute a hash using pen and graph paper. My MacBook computes a hash in microseconds. </p></div><div><p>There are hundreds of websites where you play around with hashing, and reproduce the hashes we will be discussing. Just google for "sha256 calculator".</p></div><div><p>You could think of a hash as a kind of fingerprint for some arbitrary data. It is theoretically possible, but in practice impossible, for two inputs to hash to the same result. And you can't reverse a hash. If I present you with f04b773b796ddb607c9c0df477b4738a690a626e49f59bc91a37dd0cd05b70eeÂ&nbsp; and ask you to come up with an input that hashes to that, you will never, ever, find one. Unless you have a multi trillion years life span and galactic core black hole level of energy. Then, I suppose, you would get it eventually. Or, I could tell you a secret...</p></div><div><p>hash("joshua summers") =&gt; f04b773b796ddb607c9c0df477b4738a690a626e49f59bc91a37dd0cd05b70eeÂ&nbsp; </p></div><div><p>Moving on, if you tweak the data in a tiny way, say by tacking on the string "123" at the end, you get a completely different result.</p></div><div><p>hash("joshua summers" + "123") =&gt; hash("joshua summers123") =&gt; 304d0d26fd5ebb3bd3f56fcb48f6fdc6c8b0dbf9be088b34835b3ec988be1ab7</p></div><div><p>Completely different looking from the original "joshua summers" hash. We call "123" a nonce. A bit of NONSEnse data that you tack onto some fixed data, that is, data that you care about. The nonce can change and it doesn't matter. The fixed data matters, so it can't change.</p></div><div><p>Hashing always produces a 64 hex digit output. What if we had some fixed data ("joshua summers"), and we wanted a nonce that would make the first digit of the resulting hash 0? "123" didn't work. The first digit of the resulting hash was 3. Let's keep looking... sitting at my macbook, I try nonces manually by incrementing 123 until...</p></div><div><p>hash("joshua summers" + "134") =&gt; hash("joshua summers134") =&gt; </p></div><div><p>0120353865b8576fc09988444bdeed6f44a1d9433a7058064911d66eafda43e3</p></div><div><p>Found one! Took eleven tries. (134-123)</p></div><div><p>And that is hash mining. By producing a nonce and a hash with zero in the first digit, I PROVED I did some WORK connected to the fixed data. The nonce with the hash is like a stamp of authenticity that proves that, for some reason, I care about sacrificing some work attached to the fixed data "joshua summers".</p></div><div><p>Work is another word for energy. Each hash costs my macbook battery a tiny bit of chemical energy. Recall, I could do this by hand instead of using a computer,Â&nbsp; taking 10 hours for each try. I would need feeding, since eleven hashes on graph paper would keep me busy (going slowly insane) for four days. Like my macbook, my body needs energy to hash. </p></div><div><p>On average, I would expect to have to try 16 nonces to get a hit. I got slightly lucky with 11 nonces. If you asked me for a hash that starts with 2 zeros, I would expect to have to try 16 times more nonces, 256 instead of 16. The more zeros, the more energy. </p></div><div><p>For all my hashes, you need to compute just one hash to convince yourself that my work was valid. The proof had better be cheaper than the work (and it is). Just as assaying gold to stop counterfeiters had better be cheaper than digging the gold itself up, or why bother. </p></div><div><p>Now let's talk about bitcoin. With bitcoin mining, instead of your name, the fixed data is an "unconfirmed" (ie unstamped) block. An unconfirmed block is a group of bitcoin ledger transactions, along with a hash of the previous confirmed (stamped) block. The link to the previous block, via that block's hash, is what forges individual blocks into a blockchain. Miners try nonces till they find a stamp (nonce + hash) for that unstamped block that proves they did some work. It is the same as in the example I gave before, just with more zeros. </p></div><div><p>Visually, the difficulty condition is a bunch of zeros at the beginning of the hash. The more zeros required, the more valuable the stamp. Each additional zero makes the search for the stamp 16 times harder. </p></div><div><p>In 2009, the very first bitcoin block, called the genesis block, hashed to </p></div><div><p>000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f (google this) </p></div><div><p>Satoshi mined this block. I picture him with a bunch of scavenged laptops in his mother's basement. He uses multiple laptops to try as many nonces as possible, all hashing at the same time, working in parallel. </p></div><div><p>There are ten zeros of difficulty required for this first block.</p></div><div><p>16*16*16*16*16*16*16*16*16*16 =&gt; 1,099,511,627,776</p></div><div><p>So, satoshi had to try a trillion more nonces than I just did to find a nonce that worked. It took satoshi and his little cluster of computers (his mine) about ten minutes to crack this first block. This is specified in the bitcoin protocol. Blocks should take ten minutes, on average.</p></div><div><p>The energy spent to to find the nonce makes the block precious. Like the diesel spent on earthmoving equipment to find gold makes gold precious. Gold is a precious metal. A bitcoin block hash is a precious number. The more zeros you see at the beginning of a block hash, the more precious the hash. </p></div><div><p>Now let's look at a recent hash, from today (2020)</p></div><div><p>0000000000000000000081f22162e5603c4349b66f12a6b4f4274dff14bdc3bc (you can google this too)</p></div><div><p>It doesn't look that different. It's just 20 zeros instead of 10. But, as we saw before, ten zeros means a trillion times harder. If modern miners were using the same hardware as satoshi, that would be a trillion times as many computers mining, to find the hash in the same ten minutes. A trillion times as much electricity. In fact it's a bit less than that. Modern miners use special single purpose computers, called asics, that are a lot more energy efficient than the general purpose CPUs satoshi started out with. But it's still an enormous amount of hardware and electricity, trying an enormous number of nonces, to solve the next block.</p></div><div><p>All these giant warehouses full of racks and racks of miners are hashing away, because if you solve a block stamp, you receive a block reward of 6.25 bitcoin (currently), plus some transaction fees. Altogether it's about $60k, up for grabs every ten minutes. So, mining is a lottery that pays $60k every ten minutes. If the price of bitcoin goes up, or even if people just expect it to, more miners join. Bitcoin starts to be found too quickly... nine minutes instead of ten minutes... eight minutes... then the protocol adjusts to require enough zerosÂ&nbsp; so he block time goes back to ten minutes. (Slightly hand waving there, but close enough.) This difficulty adjustment happens every two weeks. The increased difficulty (more zeros) means bitcoin got more secure, and this in turn drives price goes up. </p></div><div><p>This is the double ratchet effect that I believe will continue until bitcoin occupies its market niche and replaces money as a global utility in a decade or so. It's worked so far. Three more zeros in the difficulty (around 4000x increase in difficulty) and bitcoin has replaced printed fiat from central banks. ($10 million/bitcoin, as opposed to around $10k today.) It may feel like a lot of ground to cover, but if you just count zeros in the difficulty, bitcoin has practically already won.</p></div><div><p>As mentioned before, each block includes the hash of the previous block. This makes a sequence of blocks, that is, a chain. A blockchain is a chain of blocks. Blocks are expensive.Â&nbsp; So a blockchain is very expensive. </p></div><div><p>The bitcoin protocol says the most expensive blockchain in terms of physical energy, measured in total hashes,Â&nbsp; is the true gold. There can be only one most expensive chain. This is extremely important. <a href="https://www.youtube.com/watch?v=_J3VeogFUOs">There can be only one</a>. </p></div><div><p>An unconfirmed block has no proof of work, so you can't trust the transactions in it if someone just paid you with one of them. The miners haven't approved it. There is no work behind it. So, these expensive stamps of approvals that each block gets (the precious hashes) prevent cheating, that is, double spending the same bitcoin. Mining is a security system. Miners are the bodyguards of bitcoin. </p></div><div><p>You have toÂ&nbsp; pay your bodyguards, or they turn on you. In fact, the largest bitcoin miner, Bitmain, attacked bitcoin in 2017. As the whitepaper foretold, the attack failed. Hundreds of millions of dollars worth of hashes were sacrificed for nothing, and bitmain was nearly driven into bankruptcy. Bodyguards are not hired for their brains. </p></div><div><p>Anyways, miners are paid in block reward, which is newly minted bitcoin, plus transaction fees. The bitcoin supply is finite, with minting scheduled to end in the year 2140. The reward halves every 4 years. For bitcoin to succeed, the transaction fees have to be sufficiently high to motivate miners to keep working hard enough to make bitcoin safe after the block reward eventually goes away. Transaction fees may ultimately stabilize at thousands of dollars per transaction (pennies now). Only power users like banks and pension funds will then be able to afford the blockchain. </p></div><div><p>If this happens, and I think it will, most users will never touch the blockchain directly, but will use second layer systems such as lightning. So far, the gradual replacement of block rewards with transaction fees appears to be working …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://taaalk.co/t/bitcoin-maxima-other-crypto-things#veep">https://taaalk.co/t/bitcoin-maxima-other-crypto-things#veep</a></em></p>]]>
            </description>
            <link>https://taaalk.co/t/bitcoin-maxima-other-crypto-things#veep</link>
            <guid isPermaLink="false">hacker-news-small-sites-24073113</guid>
            <pubDate>Thu, 06 Aug 2020 17:19:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s New in Apache Kafka 2.6]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24073023">thread link</a>) | @drojas
<br/>
August 6, 2020 | https://www.confluent.io/blog/apache-kafka-2-6-updates | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/apache-kafka-2-6-updates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>On behalf of the Apache Kafka<sup>®</sup> community, it is my pleasure to announce the release of <a href="https://kafka.apache.org/downloads" target="_blank" rel="noopener noreferrer">Apache Kafka 2.6.0</a>. This another exciting release with many new features and improvements. We’ll highlight some of the more prominent features in this blog post, but see the <a href="https://dist.apache.org/repos/dist/release/kafka/2.6.0/RELEASE_NOTES.html" target="_blank" rel="noopener noreferrer">release notes</a> for the full list of changes.</p>
<p>We’ve made quite a few significant performance improvements in this release, particularly when the broker has larger partition counts. Broker shutdown performance is <a href="https://issues.apache.org/jira/browse/KAFKA-9373" target="_blank" rel="noopener noreferrer">significantly improved</a>, and performance is dramatically improved when producers use compression. Various aspects of ACL usage are faster and require less memory. And we’ve reduced memory allocations in several other places within the broker.</p>
<p>This release also adds support for Java 14. And over the past few releases, the community has switched to using Scala 2.13 by default and now recommends using Scala 2.13 for production.</p>
<p>Finally, these accomplishments are only one part of a larger active roadmap in the run up to Apache Kafka 3.0, which may be one of the most significant releases in the project’s history. The work to <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum" target="_blank" rel="noopener noreferrer">replace ZooKeeper</a> with built-in Raft-based consensus is well underway with eight KIPs in active development. Kafka’s new Raft protocol for the metadata quorum is already <a href="https://github.com/apache/kafka/pull/9130" target="_blank" rel="noopener noreferrer">available for review</a>. Tiered Storage unlocks infinite scaling and faster rebalance times via <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage" target="_blank" rel="noopener noreferrer">KIP-405</a> and is up and running in internal clusters at Uber.</p>
<h2 id="kafka-broker-producer-and-consumer"><a id="kafka-broker-producer-and-consumer"></a>Kafka broker, producer, and consumer</h2>
<h3 id="kip-546"><a id="kip-546"></a>KIP-546: Add Client Quota APIs to the Admin Client</h3>
<p>Managing quotas today in Kafka can be challenging because they can map to any combination of user and client. This feature adds a native API for managing quotas, making the process more intuitive and less error prone. A new <code>kafka-client-quotas.sh</code> command line tool lets users describe existing quotas, resolve the effective quotas for an entity with contextual information about how those quotas were derived, and modify a quota configuration entry by specifying which entries to add, update, and/or remove. For example:</p>
<pre>$ /bin/kafka-client-quotas.sh --bootstrap-server localhost:9092 \
						 --alter --names=client-id=my-client \
						 --defaults=user \
                              --add=consumer_byte_rate=2000000 \
                              --delete=producer_byte_rate</pre>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-546%3A+Add+Client+Quota+APIs+to+the+Admin+Client" target="_blank" rel="noopener noreferrer">KIP-546</a> for more details.</p>
<h3 id="KIP-551"><a id="KIP-551"></a>KIP-551: Expose disk read and write metrics</h3>
<p>Disk access on the Kafka broker machines may impact latency and throughput. This change adds metrics that track how many bytes Kafka is reading and writing from the disk.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-551%3A+Expose+disk+read+and+write+metrics" target="_blank" rel="noopener noreferrer">KIP-551</a> for more details.</p>
<h3 id="KIP-568"><a id="KIP-568"></a>KIP-568: Explicit rebalance triggering on the Consumer</h3>
<p>The Kafka consumer coordinates which topic partitions are assigned to each client in the same consumer group. This feature allows applications using the consumer to explicitly trigger a rebalance, such as if an application uses some system condition to determine whether it is ready to receive partitions.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-568%3A+Explicit+rebalance+triggering+on+the+Consumer" target="_blank" rel="noopener noreferrer">KIP-568</a> for more details.</p>
<h3 id="KIP-573"><a id="KIP-573"></a>KIP-573: Enable TLSv1.3 by default</h3>
<p>TLS 1.3 is now the default TLS protocol when using Java 11 or higher, and TLS 1.2 remains the default for earlier Java versions. As with Apache Kafka 2.5.0, TLS 1.0 and 1.1 are disabled by default due to known security vulnerabilities, though users can still enable them if required.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-573%3A+Enable+TLSv1.3+by+default" target="_blank" rel="noopener noreferrer">KIP-573</a> for more details.</p>
<h3 id="KIP-574"><a id="KIP-574"></a>KIP-574: CLI Dynamic Configuration with file input</h3>
<p>Kafka configs for the most part are defined by a single value that maps to a config name. Before this change, it was hard to set configs that are better defined by more complex structures such as nested lists or JSON. Kafka now supports using the<code> kafka-configs.sh</code> command line tool to set configs defined in a file. For example:</p>
<pre>$ bin/kafka-configs.sh --bootstrap-server localhost:9092 \
                       --entity-type brokers --entity-default \
                       --alter --add-config-file new.properties</pre>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-574%3A+CLI+Dynamic+Configuration+with+file+input" target="_blank" rel="noopener noreferrer">KIP-574</a> for more details.</p>
<h3 id="KIP-602"><a id="KIP-602"></a>KIP-602: Change default value for <code>client.dns.lookup</code></h3>
<p>Apache Kafka 2.1.0 and <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-302+-+Enable+Kafka+clients+to+use+all+DNS+resolved+IP+addresses" target="_blank" rel="noopener noreferrer">KIP-302</a> introduced the <code>use_all_dns_ips</code> option for the <code>client.dns.lookup</code> client property. With this change, the <code>use_all_dns_ips</code> option is now the default so that it will attempt to connect to the broker using all of the possible IP addresses of a hostname. The new default will reduce connection failure rates and is more important in cloud and containerized environments where a single hostname may resolve to multiple IP addresses.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-602%3A+Change+default+value+for+client.dns.lookup" target="_blank" rel="noopener noreferrer">KIP-602</a> for more details.</p>
<h2 id="kafka-connect"><a id="kafka-connect"></a>Kafka Connect</h2>
<h3 id="kip-158"><a id="kip-158"></a>KIP-158: Kafka Connect should allow source connectors to set topic-specific settings for new topics</h3>
<p>This widely requested feature allows Kafka Connect to automatically create Kafka topics for source connectors that write records, if those topics do not yet exist. This is enabled by default but does require connector configurations to define the rules used by Connect when creating these topics. For example, simply including the following will cause Connect to create any missing topics with <code>5</code> partitions and a replication factor of <code>3</code>:</p>
<pre>topic.creation.default.replication.factor=3
topic.creation.default.partitions=5</pre>
<p>Additional rules with topic matching expressions and topic-specific settings can be defined, making this a powerful and useful feature, especially when Kafka brokers have disabled topic auto creation.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics" target="_blank" rel="noopener noreferrer">KIP-158</a> for more details.</p>
<h3 id="KIP-605"><a id="KIP-605"></a>KIP-605: Expand Connect Worker Internal Topic Settings</h3>
<p>Speaking of creating topics, the Connect worker configuration can now specify additional topic settings, including using the Kafka broker defaults for partition count and replication factor, for the internal topics used for connector configurations, offsets, and status.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-605%3A+Expand+Connect+Worker+Internal+Topic+Settings" target="_blank" rel="noopener noreferrer">KIP-605</a> for more details.</p>
<h3 id="KIP-610"><a id="KIP-610"></a>KIP-610: Error Reporting in Sink Connectors</h3>
<p>Kafka Connect already had the ability to write records to a dead letter queue (DLQ) topic if those records could not be serialized or deserialized, or when a Single Message Transform (SMT) failed. Now Connect gives sink connectors the ability to send individual records to the DLQ if the connector deems the records to be invalid or problematic. Sink connectors need to explicitly make use of this feature, but doing so will allow sink connectors to continue operating even if some records in the consumed topics are somehow incompatible with the sink connector.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors" target="_blank" rel="noopener noreferrer">KIP-610</a> for more details.</p>
<h3 id="KIP-585"><a id="KIP-585"></a>KIP-585: Filter and Conditional SMTs</h3>
<p>Defining SMTs for connectors that use multiple topics can be challenging, since not every SMT may apply for every record on every topic. With this feature, each SMT can define a predicate with the conditions when that SMT should be applied. It also defines a “filter” SMT that works with the predicates to drop records that match certain conditions.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-585%3A+Filter+and+Conditional+SMTs" target="_blank" rel="noopener noreferrer">KIP-585</a> for more details.</p>
<h3 id="KIP-577"><a id="KIP-577"></a>KIP-577: Allow HTTP Response Headers to be Configured for Kafka Connect</h3>
<p>It is now possible to add custom headers to all Kafka Connect REST API responses. This allows users to ensure REST API responses comply with corporate security policies.</p>
<p>See<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP+577%3A+Allow+HTTP+Response+Headers+to+be+Configured+for+Kafka+Connect" target="_blank" rel="noopener noreferrer"> KIP-577</a> for more details.</p>
<h2 id="kafka-streams"><a id="kafka-streams"></a>Kafka Streams</h2>
<h3 id="KIP-441"><a id="KIP-441"></a>KIP-441: Smooth Scaling Out of Kafka Streams</h3>
<p>Prior to this change, when Kafka Streams assigns a stateful task, Streams had to catch it up to the head of its changelog before beginning to process it. This feature avoids stop-the-world rebalances by allowing the prior owner of a stateful task to keep it even if the assignment is unbalanced, until the new owner gets caught up, then changing ownership after the catch-up phase.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-441%3A+Smooth+Scaling+Out+for+Kafka+Streams" target="_blank" rel="noopener noreferrer">KIP-441</a> for more details.</p>
<h3 id="KIP-444"><a id="KIP-444"></a>KIP-444: Augment metrics for Kafka Streams</h3>
<p>This feature adds more out-of-the-box metrics and removes some that are not useful. It also improves the APIs that Streams applications use to register custom metrics.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-444%3A+Augment+metrics+for+Kafka+Streams" target="_blank" rel="noopener noreferrer">KIP-444</a> for more details.</p>
<h3 id="KIP-447"><a id="KIP-447"></a>KIP-447: Producer scalability for exactly once semantics</h3>
<p>This release adds additional work on this KIP to simplify the API for applications that read from and write to Kafka transactionally. Previously, this use case typically required separate producer instances for each input partition, but now there is no special requirement. This makes it much easier to build exactly-once semantics (EOS) applications that consume large numbers of partitions. This is foundational for a similar improvement in Kafka Streams in the next release.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics" target="_blank" rel="noopener noreferrer">KIP-447</a> for more details.</p>
<h3 id="KIP-557"><a id="KIP-557"></a>KIP-557: Add emit on change support for Kafka Streams</h3>
<p>This change adds an emit-on-change processing option to Kafka Streams and complements the existing emit-on-update and emit-on-window-close options. This new option drops idempotent updates where the prior and updated record have identical byte arrays. This feature helps eliminate high numbers of identical operations that forward an enormous number of unnecessary results down the topology.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-557%3A+Add+emit+on+change+support+for+Kafka+Streams" target="_blank" rel="noopener noreferrer">KIP-557</a> for more details.</p>
<h2 id="conclusion"><a id="conclusion"></a>Conclusion</h2>
<p>To learn more about what’s new in Apache Kafka 2.6 and to see all the KIPs included in this release, be sure to check out the <a href="https://dist.apache.org/repos/dist/release/kafka/2.6.0/RELEASE_NOTES.html" target="_blank" rel="noopener noreferrer">release notes</a> and highlights in the <a href="https://youtu.be/WOiL5kym_Us" target="_blank" rel="noopener noreferrer">video</a> below.</p>
<center><iframe src="https://www.youtube.com/embed/WOiL5kym_Us" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center>&nbsp;
<p>This was a huge community effort, so thank you to everyone who contributed to this release, including all of our users and the 127 people (according to git shortlog) that contributed code or documentation changes in this release:</p>
<p>17hao, A. Sophie Blee-Goldman, Aakash Shah, Adam Bellemare, Agam Brahma, Alaa Zbair, Alexandra Rodoni, Andras Katona, Andrew Olson, Andy Coates, Aneel Nazareth, Anna Povzner, Antony Stubbs, Arjun Satish, Auston, avalsa, Badai Aqrandista, belugabehr, Bill Bejeck, Bob Barrett, Boyang Chen, Brian Bushree, Brian Byrne, Bruno Cadonna, Charles Feduke, Chia-Ping Tsai, Chris Egerton, Colin Patrick McCabe, Daniel, Daniel Beskin, David Arthur, David Jacot, David Mao, dengziming, Dezhi “Andy” Fang, Dima Reznik, Dominic Evans, Ego, Eric Bolinger, Evelyn Bayes, Ewen Cheslack-Postava, fantayeneh, feyman2016, Florian Hussonnois, Gardner Vickers, Greg Harris, Gunnar Morling, Guozhang Wang, high.lee, Hossein Torabi, huxi, Ismael Juma, Jason Gustafson, Jeff Huang, jeff kim, Jeff Widman, Jeremy Custenborder, Jiamei Xie, jiameixie, jiao, Jim Galasyn, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/apache-kafka-2-6-updates">https://www.confluent.io/blog/apache-kafka-2-6-updates</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/apache-kafka-2-6-updates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24073023</guid>
            <pubDate>Thu, 06 Aug 2020 17:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A crash course on hacking satellites]]>
            </title>
            <description>
<![CDATA[
Score 402 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24072829">thread link</a>) | @PatrolX
<br/>
August 6, 2020 | https://nyan-sat.com/chapter0.html | <a href="https://web.archive.org/web/*/https://nyan-sat.com/chapter0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
            
            <p>We'll be guiding you through a crash course on satellites - their history, where in (well, around) the world they are, and how they send and receive data. Accompanying this guide (though not strictly required for it) is a set of equipment we've used ourselves to get everything going.</p>

            <p>If you have the means, we recommend buying the equipment yourself. If you don't, we've put together a kit that we'll send to you for a very reasonable price, though supplies are limited. The list of parts is below, or you can <a href="https://shoppe.redballoonsecurity.com/products/nyansat-kit">click here</a> to request a kit. We also have stickers and T-shirts <a href="https://shoppe.redballoonsecurity.com/collections/nyansat">here</a>. If you don't want a kit right now, you can continue on to the <a href="https://nyan-sat.com/chapter1.html">next section</a>.</p>

            <p><a href="https://nyan-sat.com/assets/pcbh_board.jpg"><img src="https://nyan-sat.com/assets/pcbh_board.jpg"></a>
            <span>Antenny v1</span></p>

            <p>For the kit, we custom-built a PCB in our kit that integrates multiple parts, allowing you to connect everything together on a single board with no wiring. This board is the hardware component of the RBS Antenny project. It combines the EPS32 (with Bluetooth and Wifi support), a 16 channel PWM driver, and a motor driver with a maximum output of maximum 27W at 6V. The RBS Antenny board can easily handle the movement control of NyanSat antenna gimbal, and you can load your own custom code to adjust it however you like. The onboard reserved I2C channel connectors allow you to extend the basic NyanSat setup with an RBS custom made IMU module, OLED screen and GPS module.</p>

            <p>The RBS Antenny board is designed using Altium Designer and Assembled by an in-house pick and place machine in Manhattan, New York. After DEF CON, you can even repurpose the board for your future projects requiring microcontrollers and motor drivers. You can read more about it <a href="https://github.com/RedBalloonShenanigans/antenny/">here</a>.</p>

            

            <p>After completing the Antenny v1 board, we found ways to enhance the board and designed the Antenny v2 which fixes bugs, improves functionality and reliability, and is now adaptable for future development on hardware.</p>

            <p><a href="https://nyan-sat.com/assets/pcbh_board2.jpg"><img src="https://nyan-sat.com/assets/pcbh_board2.jpg"></a>
            <span>Antenny v2</span></p><p>The main improvements to highlight from the Antenny v1 to the Antenny v2 are as follows.</p>

            <ol>
                <li>Reduced PCB size by 40%</li>
                <li>Breakout unused GPIO pins from ESP32 for future development</li>
                <li>Fixed I2C GPIO pull up bugs</li>
                <li>Enhanced power output of servo motor driver by 25%</li>
                <li>Added BeiDou/GPS (beitian bn-880) module connector pinout on PCB board</li>
            </ol>

            <p>For more information on Antenny v2 and general setup, please review <a href="https://github.com/RedBalloonShenanigans/antenny/blob/master/hardware/Antenny_board_hardware_setup_guide.pdf">this document</a> for pinouts and hardware requirements.</p>
            
            
            <p>These are covered in more detail in Chapter 4. Feel free to skip ahead. Not every part here is strictly required - feel free to only get the ones that interest you.</p>

            <h2>Pan/Tilt Gimbal</h2>
            <p><img src="https://nyan-sat.com/assets/gimbal.jpg"></p><p>This is a small gimbal we're using for pointing an antenna in a specific direction and track a satellite across the sky. They can be found multiple places. We have spare ones that we're selling at cost. Without one of these you can listen to geosynchronous satellites, but low orbit satellites will be whizzing across your antenna’s pickup area in seconds.</p>
            <p><a href="https://www.amazon.com/dp/B085HDYTCQ/">Product link</a></p>

            <h2>RTL-SDR</h2>
            <p><img src="https://nyan-sat.com/assets/rtl-sdr.jpg"></p><p>The cheapest and most flexible SDR available.</p>
            <p><a href="https://www.amazon.com/dp/B011HVUEME/">Product link</a></p>

            <h2>ESP32</h2>
            <p><img src="https://nyan-sat.com/assets/esp32.jpg"></p><p>Lots of features in a tiny package. This is the microcontroller that our software expects.</p>
            <p><a href="https://www.amazon.com/dp/B0718T232Z">Product link</a></p>

            <h2>IMU</h2>
            <p>This Inertial Measuring Unit tells the software which way the antenna is pointing, helping you to point it very precisely.</p>
            <p><a href="https://www.amazon.com/dp/B017PEIGIG/">Product link</a></p>

            <h2>Motor Driver</h2>
            <p><img src="https://nyan-sat.com/assets/driver.jpg"></p><p>The ESP32 isn't able to drive the motors directly, so an adapter board is needed.</p>
            <p><a href="https://www.amazon.com/dp/B01D9VNXEQ/">Product link</a></p>

            <h2>OLED Screen (optional)</h2>
            <p><img src="https://nyan-sat.com/assets/oled.jpg"></p><p>Super simple display for getting quick feedback from the device.</p>
            <p><a href="https://www.amazon.com/dp/B07X25T786/">Product link</a></p>

            <p><a href="https://nyan-sat.com/chapter1.html"><span>NEXT CHAPTER</span></a>
        </p></div>
    </article></div>]]>
            </description>
            <link>https://nyan-sat.com/chapter0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072829</guid>
            <pubDate>Thu, 06 Aug 2020 16:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coca-Cola Using Hyperledger and Ethereum]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24072238">thread link</a>) | @doener
<br/>
August 6, 2020 | https://cryptorandgroup.com/coca-cola-using-hyperledger-and-ethereum/ | <a href="https://web.archive.org/web/*/https://cryptorandgroup.com/coca-cola-using-hyperledger-and-ethereum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cryptorandgroup.com/coca-cola-using-hyperledger-and-ethereum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072238</guid>
            <pubDate>Thu, 06 Aug 2020 16:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CheerpX – x86 virtualization in browser using WebAssembly – Python Demo]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24072213">thread link</a>) | @apignotti
<br/>
August 6, 2020 | https://www.leaningtech.com/pages/pythondemo.html | <a href="https://web.archive.org/web/*/https://www.leaningtech.com/pages/pythondemo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="failure">

<p id="cxFailure">

<h6>CheerpX uses WebAssembly tail calls. Not all browsers support them out of the box (yet).</h6>
<br>
<h6>You can follow our tutorials below, to run your browser with tail cals, or watch a video of the demo if you prefer not to.</h6>
</p>
<div id="SVGmockupBg">

<div>
<h2>Want to interact with the demo yourself?</h2>

<ul id="pills-tab" role="tablist">
<li>
<a id="pills-one-example1-tab" data-toggle="pill" href="#pills-one-example1" role="tab" aria-controls="pills-one-example1" aria-selected="false">
<p><i></i>
Linux
</p>
</a>
</li>
<li>
<a id="pills-two-example1-tab" data-toggle="pill" href="#pills-two-example1" role="tab" aria-controls="pills-two-example1" aria-selected="false">
<p><i></i>
Mac OS
</p>
</a>
</li>
<li>
<a id="pills-three-example1-tab" data-toggle="pill" href="#pills-three-example1" role="tab" aria-controls="pills-three-example1" aria-selected="false">
<p><i></i>
Windows
</p>
</a>
</li>
</ul>


<div id="pills-tabContent">
<div id="pills-one-example1" role="tabpanel" aria-labelledby="pills-two-example1-tab">

<div>
<div>
<ul>

<li>
<span>
</span>
<p>
<h5>Open a Terminal/Command Prompt
</h5>
</p>
</li>


<li>
<span>
</span>
<p>
<h5>Enter the following command:</h5>
<h6>chromium --incognito --js-flags="--experimental-wasm-return-call"
</h6>
</p>
</li>


<li>
<span>
</span>
<p>
<h5>Navigate back to this page. That's it!</h5>
</p>
</li>

</ul>
</div>
</div>

</div>
<div id="pills-two-example1" role="tabpanel" aria-labelledby="pills-three-example1-tab">

<div>
<div>
<ul>

<li>
<span>
</span>
<p>
<h5>Open a Terminal/Command Prompt</h5>
</p>
</li>


<li>
<span>
</span>
<div>
<h5>
Enter the following command:
</h5>
<pre>/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --js-flags=“--experimental-wasm-return-call”</pre>
</div>
</li>


<li>
<span>
</span>
<p>
<h5>Navigate back to this page. That's it!</h5>
</p>
</li>

</ul>
</div>
</div>

</div>
<div id="pills-three-example1" role="tabpanel" aria-labelledby="pills-one-example1-tab">

<div>
<div>
<ul>

<li>
<span>
</span>

</li>


<li>
<span>
</span>
<p>
<h5> Go to the start menu,
and open 'Windows
PowerShell'
</h5>
</p>
</li>


<li>
<span>
</span>
<p>
<h5>Enter the following
command:
</h5><h6>Start-Process -FilePath
"$env:LOCALAPPDATA\Chromium\Application\chrome.exe"
-js-flags="--experimental-wasm-return-call"
</h6>

</p>
</li>


<li>
<span>
</span>
<p>
<h5>Navigate back to this page. That's it!</h5>
 </p>
</li>

</ul>
</div>
</div>

</div>

</div>
</div>

</div>
<h2>Want to see the demo in action?</h2>
<div id="pills-tabContent-1">
<div id="pills-result-1" role="tabpanel" aria-labelledby="pills-result-tab-1">
<div>

<div>

<div>
<p id="vimeoVideoIframeExample1" data-vimeo-initialized="true"><iframe src="https://player.vimeo.com/video/445194549" frameborder="0" allow="fullscreen;" allowfullscreen="" title="DESIGN DISRUPTORS Trailer #2 - A documentary from InVision" data-ready="true"></iframe></p>
</div>

</div>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.leaningtech.com/pages/pythondemo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072213</guid>
            <pubDate>Thu, 06 Aug 2020 16:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why not RocksDB for streaming storage?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24072097">thread link</a>) | @arjunnarayan
<br/>
August 6, 2020 | https://materialize.io/blog-rocksdb/ | <a href="https://web.archive.org/web/*/https://materialize.io/blog-rocksdb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>A roadmap for a storage engine for Materialize</h2>

<p>As my final task as an engineer at Cockroach Labs, I wrote a blog post titled “<a href="https://www.cockroachlabs.com/blog/cockroachdb-on-rocksd/">Why we built CockroachDB on top of RocksDB</a>”, where I discussed the extensive reasons that RocksDB was a good choice for CockroachDB’s storage engine at the time. So I suppose it was inevitable that I’d end up explaining why we chose a different approach for building state management in Materialize.</p>
<p>Materialize does not use RocksDB as its underlying storage engine. However, several other streaming frameworks do, such as Flink and Kafka Streams/KSQL (but not all: Spark Streaming uses the same Resilient Distributed Datasets storage layer as Spark, as it’s essentially Spark run in a micro-batched fashion). Given my past positive experience using RocksDB as a storage engine for an OLTP database, and <em>given that RocksDB is the default choice for state manager in streaming systems, why did we choose not to use it in Materialize</em>?</p>
<h3>A RocksDB Primer</h3>
<p>RocksDB is an embeddable storage engine that uses a log-structured merge tree of immutable flat files as the underlying index data structure. RocksDB maintains this indexed representation to efficiently perform point lookups, inserts, and range scans. RocksDB also provides support for strong isolation guarantees when performing those operations, and does so at high performance when there are multiple concurrent readers and writers accessing the same state, all while continuing LSM compaction in additional background threads.</p>
<p>This is an excellent storage engine to base OLTP workloads on top of, which is why several systems with primarily OLTP considerations all build on top of RocksDB: such as <a href="https://www.cockroachlabs.com/">CockroachDB</a>, <a href="https://www.yugabyte.com/">YugabyteDB</a>, and <a href="https://tikv.org/">TiKV</a> (and TiDB). Stream processors have followed this trend: <a href="http://flink.apache.org/">Flink</a>, <a href="https://kafka.apache.org/documentation/streams/">Kafka Streams</a>, and others. Why do we not repeat this (tried and tested) experience, thus saving valuable engineering time? My position is that while RocksDB is a great OLTP storage engine, it is not a great fit for <em>streaming</em>.</p>
<h3>The Timely Dataflow Computational Model</h3>
<h4>Timely Dataflow: Sharding and Scheduling</h4>
<p>Before we talk about this, we have to spend a little bit of time on <a href="http://timelydataflow.com/">Timely Dataflow</a>, the streaming engine at the heart of Materialize. Timely Dataflow is a radically different framework than other stream processing frameworks like Flink and Kafka Streams in its physical computational model. I describe these differences a bit in a talk I gave at Carnegie Mellon University (video and transcript <a href="https://materialize.io/blog-cmudb/">here</a>), but for a quick overview, there are a couple design choices that are relevant when it comes to persistent storage. While all the streaming engines mentioned are push-based dataflow engines (as opposed to a pull-based <a href="https://dl.acm.org/doi/10.1109/69.273032">Volcano</a> execution model used by several databases), there is a major design difference in the sharding pattern of the dataflow graph across distributed CPU cores.</p>
<p>A streaming dataflow graph is a set of operator nodes (intuitively, the familiar relational nodes like “join”, “reduce”, “map”, etc.), with streaming updates moving along the edges of the graph. When taking this logical dataflow graph and instantiating a physical set of operators, there comes an important decision in how to lay the operators out (and the inter-operator streams) across the available physical resources (the CPU cores, possibly across several machines).</p>
<p>Both Flink and Kafka Streams choose to divide work up by dedicating physical CPU cores to operators (the pink divider lines are separators between CPU cores, which are labeled “workers”), and sharding streams across a cluster of cores. If some logical operators require more CPUs, they can be replicated across several cores (e.g. the “count” operator in the graph below). This means that every edge flows between cores (and potentially between machines). This results in a large amount of cross-core data movement, at high cost even in the common case. These stream processors are thus severely memory bandwidth bound.</p>
<div id="attachment_1702"><p><img aria-describedby="caption-attachment-1702" src="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-1024x288.png" data-src="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-1024x288.png" alt="Figure 1: The Flink and Kafka Streams operator sharding pattern." width="800" height="225" data-srcset="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-1024x288.png 1024w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-300x84.png 300w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-768x216.png 768w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM.png 1188w" data-sizes="(max-width: 800px) 100vw, 800px" srcset="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-1024x288.png 1024w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-300x84.png 300w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM-768x216.png 768w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-9.48.34-AM.png 1188w"></p><p id="caption-attachment-1702">Figure 1: The Flink and Kafka Streams operator sharding pattern.</p></div>
<p>Flink and Kafka Streams use a core (or several) dedicated to each operator. In contrast, timely dataflow cores are sharded differently, intentionally to minimize cross-core data movement:</p>
<div id="attachment_1699"><p><img aria-describedby="caption-attachment-1699" src="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM.png" data-src="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM.png" alt="This diagram shows Timely Dataflow's sharding pattern" width="800" height="466" data-srcset="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM.png 910w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM-300x175.png 300w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM-768x447.png 768w" data-sizes="(max-width: 800px) 100vw, 800px" srcset="https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM.png 910w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM-300x175.png 300w, https://materialize.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-06-at-8.00.01-AM-768x447.png 768w"></p><p id="caption-attachment-1699">Figure 2: The Timely Dataflow operator sharding pattern.</p></div>
<p>Each core in a Timely Dataflow cluster has a complete copy of the logical dataflow plan, and every operator is partitioned across every core. In this sharding scheme, operators on a worker are cooperatively scheduled, and have to be carefully designed to yield eagerly, or they will block other operators from executing, potentially stalling the entire dataflow graph. While this is an additional programming burden, the benefits here are that when data does not have to be exchanged, operators can execute in a fused fashion, calling in directly into the next function, with little expensive data movement. While this is not the entirety of the reason for timely dataflow’s <a href="http://sigops.org/s/conferences/sosp/2013/papers/p439-murray.pdf">many</a> <a href="https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-mcsherry.pdf">performance</a> <a href="https://github.com/frankmcsherry/blog/blob/master/posts/2015-02-04.md">records</a>, this attentiveness to core-local data locality means that timely dataflow elides cross-core data transfer and the cache eviction that comes along with it in many common cases. And empirically, paying careful attention to the memory hierarchy <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">matters</a> when building high performance concurrent systems.</p>
<p>And therein lies the problem with RocksDB: RocksDB is designed for liberally using <em>background threads</em> to perform the computation for physical compaction. In an OLTP setting, this is exactly what you want – lots of concurrent writers pushing to the higher levels of the LSM tree, lots of readers accessing immutable SSTables of the entire tree with snapshot isolation semantics, and compaction proceeding in the background with additional cores. In a streaming setting, however, those cores are better used as additional concurrency units for the dataflow execution, which means compaction happens in the foreground. And thus, scheduling <em>when</em> the compaction happens cannot be outsourced, and must be considered alongside all other operators.</p>
<h4>Differential Dataflow: Arrangements and Index Maintenance</h4>
<p>Timely Dataflow provides the scheduling and execution layer for operators, but <a href="http://differentialdataflow.com/"><em>Differential Dataflow</em></a> is the library on top of Timely that has careful implementations of common relational operators. Some of these operators need to maintain large amounts of state – for instance, a JOIN on two input streams will need to maintain indexes over both streams, keyed on the join condition, to quickly do lookups.</p>
<p>This is where many other stream processors use a RocksDB instance to maintain these indexes, which would deploy its own cores as background threads in order to perform physical <a href="https://emmanuelbernard.com/blog/2017/01/10/lsm-tree-with-level-based-compaction/">compaction</a>. The work in maintaining an index is predominantly in the computation, not in the storage. RocksDB fits well in the paradigm where it can be viewed as another operator (“state manager”) sitting alongside the traditional relational operators (“join”, “group by”, and so on). While we have not measured the computation overhead in isolation, <a href="https://www.usenix.org/system/files/hotstorage20_paper_kalavri.pdf">a research paper</a> by Kalavri and Liagouris claims that while many stream processors use RocksDB, they “question the suitability of such general-purpose stores for streaming workloads and argue that they incur unnecessary overheads in exchange for state management capabilities”.</p>
<p>RocksDB is also optimized for the OLTP setting out-of-the-box, where reads typically outnumber writes 10:1. In the streaming setting, however, the read:write ratio is closer to 1:1, making the default compaction algorithms a poor fit. While in principle, this is fixable by writing a custom compaction algorithm optimized for streaming (I wrote <a href="https://ristret.com/s/gnd4yr/brief_history_log_structured_merge_trees">a brief history of RocksDB</a> on my personal blog a few years back, where I outline that compaction algorithms can largely tune LSM Trees for any read/write setting), none of the stream processors we are aware of go to this effort.</p>
<p>Differential Dataflow takes a different approach to building and maintaining indexes, with a custom LSM-like operator called arrange. Arrange takes immutable batches as inputs (just like RocksDB) and compacts them. The difference is that arrange is sharded by worker and cooperatively scheduled like any other timely dataflow operator, at the cost of being non-durable. The details of arrangements are covered in an upcoming <a href="https://people.csail.mit.edu/malte/pub/drafts/2019-kpg.pdf">VLDB paper</a>, but carefully controlling when compactions happen is a key part of maintaining consistent low latencies in streaming updates, while also maintaining a compact memory footprint.</p>
<h2>What about persistence?</h2>
<p>Arrangements are an in-memory data structure. Because each worker maintains its own dedicated memory space, it gracefully spills to disk via system paging, so it is not limited to the available RAM. However, upon system crash or restart, all this state is lost.</p>
<p>Note, however, that index maintenance and persisting streams are (subtly) orthogonal concerns! While using RocksDB as a durable index store can provide persistence, the high performance cost of using RocksDB and incurring cross-core data movement for every datum means that this is far from a free lunch. Second, there’s also considerable work in lining up the state across all the operators precisely to facilitate recovery! To do this, for instance, Flink uses the <a href="https://en.wikipedia.org/wiki/Chandy%E2%80%93Lamport_algorithm">Chandy-Lamport</a> global synchronization algorithm, incurring latency spikes when checkpointing periodically runs (<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/ops/state/checkpoints.html#unaligned-checkpoints">a new feature</a> removes this latency, but is currently not consistent). Kafka Streams <a href="https://www.jesse-anderson.com/2019/10/why-i-recommend-my-clients-not-use-ksql-and-kafka-streams/">does not</a> do checkpointing, meaning that state largely must be thrown away and recreated upon restart, or the details of reusing state is left as an “easy exercise for the microservice programmer”.</p>
<p>Our view is that if index building and maintenance is fast enough, checkpointing the indexes becomes a less important concern. Just rebuild the index on restart! This reduces persistence to the challenge of storing the raw streams, rather than storing the complex globally distributed snapshot of state, a much easier problem. Just writing down the streams to append-only files, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://materialize.io/blog-rocksdb/">https://materialize.io/blog-rocksdb/</a></em></p>]]>
            </description>
            <link>https://materialize.io/blog-rocksdb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072097</guid>
            <pubDate>Thu, 06 Aug 2020 15:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Auth is now available in Supabase (YC S20)]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24072051">thread link</a>) | @kiwicopple
<br/>
August 6, 2020 | https://supabase.io/blog/2020/08/05/supabase-auth | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/08/05/supabase-auth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Supabase is an open source Firebase alternative. We are building the features of Firebase using scalable, open source products. </p><p>Two months ago a developer discovered Supabase and (unexpectedly) <a href="https://news.ycombinator.com/item?id=23319901" target="_blank" rel="noopener noreferrer">launched us on Hacker News</a>. Although we had completed only 3 months of development the community support was both incredible and humbling.</p><p><img src="https://supabase.io/img/supabase-hn-launch.png" alt="This image shows all of the top dev tool launches on Hacker news. The most popular is Stripe, with 1249 upvotes, the next popular is Supabase with 1120 upvotes, and third is Fly.io with 626 upvotes."></p><p>Developers were obviously excited about the prospect of an open source Firebase alternative, but the comments were dominated by one emphatic feature request: Auth.</p><blockquote><p>" <em>Just FYI, making a good auth solution in Supabase will instantly make me a customer.</em> "<br><small>@pdimitar</small></p></blockquote><blockquote><p>" <em>For me the MVP, before I could use it for my commercial projects, would be: DB+auth. At that point, I could switch - and probably would.</em> "<br><small>@julianeon</small></p></blockquote><blockquote><p>" <em>This looks great, however at first peek it doesn't mention anything about auth. Do you have any plans for that? For me this is the topic I most want to just delegate to the service.</em> "<br><small>@2mol</small></p></blockquote><p>So we got to work, and today we're ecstatic to launch Supabase Auth. Let's dig into some of the features of the Auth system.</p><p>Supabase Auth provides all the backend services you need to authenticate and authorize your users.</p><h3>User management</h3><p>Supabase makes it simple to onboard your users with our new <code>supabase.auth.signup()</code> and <code>supabase.auth.login()</code> <a href="https://supabase.io/docs/library/user-management">functions</a>.</p><video width="99%" autoplay="autoplay" loop="" muted="" controls=""><source src="https://supabase.io/videos/auth-zoom.mp4" type="video/mp4"></video><h3>Row Level Security</h3><p>Authentication only gets you so far. When you need granular authorization rules, nothing beats PostgreSQL's <a href="https://www.postgresql.org/docs/current/ddl-rowsecurity.html" target="_blank" rel="noopener noreferrer">Row Level Security</a>. Supabase makes it simple to turn RLS on and off.</p><video width="99%" autoplay="autoplay" loop="" muted="" controls=""><source src="https://supabase.io/videos/rls-zoom.mp4" type="video/mp4"></video><h3>Policies</h3><p><a href="https://www.postgresql.org/docs/current/sql-createpolicy.html" target="_blank" rel="noopener noreferrer">Policies</a> are PostgreSQL's rule engine. They are incredibly powerful and flexible, allowing you to write complex SQL rules which fit your unique business needs. </p><video width="99%" autoplay="autoplay" loop="" muted="" controls=""><source src="https://supabase.io/videos/policies-zoom.mp4" type="video/mp4"></video><p>With policies, your database becomes the rules engine. Instead of repetitively filtering your queries, like this ...</p><div><div><div tabindex="0"><div><p><span>const</span><span> loggedInUserId </span><span>=</span><span> </span><span>'d0714948'</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> </span><span>await</span><span> supabase</span></p><p><span>    </span><span>.</span><span>from</span><span>(</span><span>'users'</span><span>)</span><span></span></p><p><span>    </span><span>.</span><span>select</span><span>(</span><span>'user_id, name'</span><span>)</span><span></span></p><p><span>    </span><span>.</span><span>eq</span><span>(</span><span>'user_id'</span><span>,</span><span> loggedInUserId</span><span>)</span><span></span></p></div></div></div></div><p>... you can simply define a rule on your database table, <code>auth.uid() = user_id</code>, and your request will return the rows which pass the rule, even when you remove the filter from your middleware:</p><div><div><div tabindex="0"><div><p><span>let</span><span> user </span><span>=</span><span> </span><span>await</span><span> supabase</span></p><p><span>    </span><span>.</span><span>from</span><span>(</span><span>'users'</span><span>)</span><span></span></p><p><span>    </span><span>.</span><span>select</span><span>(</span><span>'user_id, name'</span><span>)</span><span></span></p></div></div></div></div><h3>Open source</h3><p>Building an open source Firebase alternative is difficult task, made possible by an amazing suite of OSS tools that have forged the way for Supabase. We spent many weeks building Auth POC's with existing OSS tools. Notable mentions go to RedHat's <a href="https://www.keycloak.org/" target="_blank" rel="noopener noreferrer">KeyCloak</a>, and Ory's <a href="https://github.com/ory/kratos" target="_blank" rel="noopener noreferrer">Kratos</a>. </p><p>Ultimately we landed on a system which utilises three amazing open source products: </p><ul><li>Authorization: <a href="https://www.postgresql.org/" target="_blank" rel="noopener noreferrer">PostgreSQL</a> and <a href="http://postgrest.org/en/v7.0.0/auth.html" target="_blank" rel="noopener noreferrer">PostgREST</a>.</li><li>Authentication: Netlify's <a href="https://github.com/netlify/gotrue" target="_blank" rel="noopener noreferrer">GoTrue</a> server, which we forked and will continue to contribute to.</li></ul><h3>Next steps</h3><p>Supabase has a culture of shipping early and often. Our Auth release is another example of this, and we still have a lot of work to do. Next month we have more Auth features planned, including custom email templates and 3rd-party OAuth providers. We also plan to simplify the Policy interface, enabling non-technical users to get started with one of PostgreSQL's best features.</p><h3>Get started</h3><p>Supabase Auth is ready for you to start using today, free of charge: <a href="https://app.supabase.io/" target="_blank" rel="noopener noreferrer">app.supabase.io</a></p><p>To see the full power of our auth system, watch <a href="https://youtu.be/2oqIZW5S-lQ" target="_blank" rel="noopener noreferrer">this demo</a> where I deploy a secure, real-time slack clone to Vercel in less than 3 minutes.</p></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/08/05/supabase-auth</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072051</guid>
            <pubDate>Thu, 06 Aug 2020 15:50:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simon's Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24072037">thread link</a>) | @keyboardman
<br/>
August 6, 2020 | https://leimao.github.io/blog/Simon-Algorithm/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Simon-Algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Simon’s algorithm is a quantum computing algorithm invented to solve a contrived problem which is called Simon’s problem. Compared to one of the other quantum computing algorithms, <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>, which only requires to run once, Simon’s algorithm requires to run the algorithm multiple times, yet it is still able to solve Simon’s problem exponentially faster asymptotically running on quantum circuits than the best conventional probabilistic algorithm running on classical circuits.</p>



<p>In this blog post, I would like to discuss Simon’s problem and Simon’s algorithm in details.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="xor-properties">XOR Properties</h4>

<ul>
  <li><em>Commutativity</em>: $A \oplus B = B \oplus A$</li>
  <li><em>Associativity</em>: $A \oplus (B \oplus C) = (A \oplus B) \oplus C$</li>
  <li><em>Identity element</em>: $A \oplus 0 = A$</li>
  <li><em>Self-invertible</em>:  $A \oplus A = 0$</li>
</ul>

<h4 id="reducing-sum-or-difference-to-boolean">Reducing Sum or Difference to Boolean</h4>

<p>If $x$ and $y$ are binary values, $x, y \in \{0, 1\}$, we have</p><p>

\[\begin{align}
(-1)^{x + y} &amp;= (-1)^{x \oplus y} \\
(-1)^{x - y} &amp;= (-1)^{x \oplus y} \\
\end{align}\]

</p><p>where $\oplus$ is $\text{XOR}$ (binary addition modulo 2). This could be easily verified using truth table.</p>

<h4 id="inner-product-and-inner-product-space-for-binary-vector-space">Inner Product and Inner Product Space for Binary Vector Space</h4>

<p>In the previous <a href="https://leimao.github.io/blog/Inner-Product/">blog post</a>, we have defined the inner product and inner product space for complex vector space. Similarly, we could also define the inner product and inner product space for binary vector space.</p><p>

\[\begin{align}
\langle -, - \rangle : \{0,1\}^n \times \{0,1\}^n \rightarrow \{0,1\}
\end{align}\]

</p><p>Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$, the inner product of $\mathbf{x}$ and $\mathbf{y}$ is defined as</p><p>

\[\begin{align}
\langle \mathbf{x}, \mathbf{y} \rangle &amp;= (x_0 \wedge y_0) \oplus (x_1 \wedge y_1) \oplus \cdots \oplus (x_{n-1} \wedge y_{n-1}) \\
&amp;= \bigoplus_{i=0}^{n-1} (x_i \wedge y_i )
\end{align}\]

</p><p>which is somewhat similar to the inner product definition for real vector space.</p>



<p>The bitwise exclusive-or operation $\oplus$ was also defined for binary vectors $\mathbf{x}$ and $\mathbf{y}$ of the same length. Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$,</p><p>

\[\begin{align}
\mathbf{x} \oplus \mathbf{y} = \{x_0 \oplus y_0, x_1 \oplus y_1, \cdots, x_{n-1} \oplus y_{n-1}\}
\end{align}\]

</p><p>The following inner product properties are satisfied based on the above inner product definition.</p>



<p>Given $\mathbf{x}, \mathbf{x}^{\prime}, \mathbf{y}, \mathbf{y}^{\prime} \in \{0,1\}^n$, using the $\text{XOR}$ distributivity property we derived above,</p><p>

\[\begin{align}
\langle \mathbf{x} \oplus \mathbf{x}^{\prime}, \mathbf{y} \rangle &amp;= \big((x_0 \oplus x_0^{\prime})\wedge y_0\big) \oplus \big((x_1 \oplus x_1^{\prime}) \wedge y_1\big) \oplus \cdots \oplus \big((x_{n-1} \oplus x_{n-1}^{\prime}) \wedge y_{n-1}\big) \\
&amp;= \big((x_0 \wedge y_0) \oplus (x_0^{\prime} \wedge y_0) \big) \oplus \big((x_1 \wedge y_1) \oplus (x_1^{\prime} \wedge y_1) \big) \oplus \cdots \oplus \big((x_{n-1} \wedge y_{n-1}) \oplus (x_{n-1}^{\prime} \wedge y_{n-1}) \big) \\
&amp;= (x_0 \wedge y_0) \oplus (x_0^{\prime} \wedge y_0)  \oplus (x_1 \wedge y_1) \oplus (x_1^{\prime} \wedge y_1)  \oplus \cdots \oplus (x_{n-1} \wedge y_{n-1}) \oplus (x_{n-1}^{\prime} \wedge y_{n-1}) \\
&amp;= \big( (x_0 \wedge y_0) \oplus (x_1 \wedge y_1)  \oplus \cdots \oplus (x_{n-1} \wedge y_{n-1}) \big) \oplus  \big( (x_0^{\prime} \wedge y_0) \oplus (x_1^{\prime} \wedge y_1)  \oplus \cdots \oplus (x_{n-1}^{\prime} \wedge y_{n-1}) \big) \\
&amp;= \langle \mathbf{x}, \mathbf{y} \rangle \oplus \langle \mathbf{x}^{\prime}, \mathbf{y} \rangle   \\
\end{align}\]

</p><p>Similarly,</p><p>

\[\begin{align}
\langle \mathbf{x}, \mathbf{y} \oplus \mathbf{y}^{\prime} \rangle = \langle \mathbf{x}, \mathbf{y} \rangle \oplus \langle \mathbf{x}, \mathbf{y}^{\prime} \rangle \\
\end{align}\]

</p><p>Let $\mathbf{0} = \{ \underbrace{0, 0, \cdots, 0}_{n} \} =  0^n$, we have</p><p>

\[\begin{align}
\langle \mathbf{0}, \mathbf{y} \rangle = 0 \\
\langle \mathbf{x}, \mathbf{0} \rangle = 0 \\
\end{align}\]

</p><h4 id="hadamard-operator">Hadamard Operator</h4>

<p>Most of the important properties of Hadamard operator have been derived in the prerequisites section of my previous blog post on <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>. Unlike Deutsch-Jozsa algorithm, Simon’s algorithm is only going to use a small fraction of the Hadamard operator properties that Deutsch-Jozsa algorithm has used. I would just copy the properties useful for Simon’s algorithm algorithm. For the derivation, proof, and other properties of Hadamard operator, the reader should refer to my previous blog post.</p>



<p>To extract an arbitrary column $j$ from $H^{\otimes {n}}$, we prepared a one-hot quantum system basic state vector $| \mathbf{y} \rangle = [y_0, y_1, \cdots, y_{2^n-1}]^{\top}$, where $y_j = 1$ and $y_k = 0$ for $k \neq j$.</p><p>

\[\begin{align}
H^{\otimes {n}}_{:,j} &amp;= H^{\otimes {n}} | \mathbf{y} \rangle \\
&amp;= H^{\otimes n}[\mathbf{0}, \mathbf{j}] | \mathbf{x}_0 \rangle + H^{\otimes n}[\mathbf{1}, \mathbf{j}] | \mathbf{x}_1 \rangle + \cdots + H^{\otimes n}[\mathbf{2^n-1}, \mathbf{j}] | \mathbf{x}_{2^{n}-1} \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} (-1)^{\langle \mathbf{0}, \mathbf{j} \rangle} | \mathbf{x}_0 \rangle + \frac{1}{\sqrt{2^n}} (-1)^{\langle \mathbf{1}, \mathbf{j} \rangle} | \mathbf{x}_1 \rangle + \cdots + \frac{1}{\sqrt{2^n}} (-1)^{\langle \mathbf{2^n-1}, \mathbf{j} \rangle} | \mathbf{x}_{2^{n}-1} \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} (-1)^{\langle \mathbf{i}, \mathbf{j} \rangle} | \mathbf{x}_i \rangle\\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{ \mathbf{x} \in \{0,1\}^n } (-1)^{\langle \mathbf{x}, \mathbf{j} \rangle} | \mathbf{x} \rangle\\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{ \mathbf{x} \in \{0,1\}^n } (-1)^{\langle \mathbf{x}, \mathbf{y} \rangle} | \mathbf{x} \rangle\\
\end{align}\]

</p><p>where $| \mathbf{x}_i \rangle$ is a quantum system one-hot basic state vector,  $|\mathbf{x}_i\rangle = [x_0, x_1, \cdots, x_{2^{n}-1}]^{\top}$, where $x_i = 1$ and $x_k = 0$ for $k \neq i$.</p>



<p>Specifically, if $j = 0$, $| \mathbf{y} \rangle = [\underbrace{1, 0, 0, \cdots, 0}_{2^n} ]^{\top} = | \mathbf{0} \rangle$,</p><p>

\[\begin{align}
H^{\otimes {n}} | \mathbf{0} \rangle 
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} (-1)^{\langle \mathbf{i}, \mathbf{0} \rangle} | \mathbf{x}_i \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} (-1)^{0} | \mathbf{x}_i \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} | \mathbf{x}_i \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{ \mathbf{x} \in \{0,1\}^n } | \mathbf{x} \rangle \\
\end{align}\]

</p><h3 id="simons-problem">Simon’s Problem</h3>

<p>Simon’s problem is defined as the follows. Given a black box function $f: \{0,1\}^n \rightarrow \{0,1\}^n$, we are further assured that there exists a hidden binary string $\mathbf{c} \in \{0,1\}^n$, such that, for all $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$,</p><p>

\[f(\mathbf{x}) = f(\mathbf{y}) \Leftrightarrow \mathbf{y} = \mathbf{x} \oplus \mathbf{c}\]

</p><p>where $\oplus$ is (bit-wise) $\text{XOR}$ (binary addition modulo 2).</p>



<p>Our goal is to find out what $\mathbf{c}$ is.</p>

<h4 id="mapping-properties">Mapping Properties</h4>

<p>There are some properties of the mapping $f$. $f$ is either a one-to-one or two-to-one mapping.</p>



<p>$\mathbf{c} = \mathbf{0}$ $\Leftrightarrow$ $f$ is a one-to-one mapping</p>



<p><em>Proof</em></p>



<p>For $f$ is a one-to-one mapping $\Rightarrow$ $\mathbf{c} = \mathbf{0}$, it is too trivial to prove.</p>



<p>For $\mathbf{c} = \mathbf{0}$ $\Rightarrow$ $f$ is a one-to-one mapping, we would like to prove by contradiction.</p>



<p>If $\mathbf{c} = \mathbf{0}$ and $f$ is not a one-to-one mapping, there must exists $\mathbf{x}$ and $\mathbf{y}$, $\mathbf{x} \neq \mathbf{y}$, and $f(\mathbf{x}) = f(\mathbf{y})$. According to the assurance, $\mathbf{y} = \mathbf{x} \oplus \mathbf{c} = \mathbf{x} \oplus \mathbf{0} = \mathbf{x}$. This raises contradiction and therefore $f$ has to be a one-to-one mapping when $\mathbf{c} = \mathbf{0}$.</p>



<p>This concludes the proof.</p>



<p>$\mathbf{c} \neq \mathbf{0}$ $\Leftrightarrow$ $f$ is a two-to-one mapping.</p>



<p><em>Proof</em></p>



<p>For $f$ is a two-to-one mapping $\Rightarrow$ $\mathbf{c} \neq \mathbf{0}$, it is too trivial to prove.</p>



<p>For $\mathbf{c} \neq \mathbf{0}$ $\Rightarrow$ $f$ is a two-to-one mapping, we would like to prove by contradiction.</p>



<p>If $\mathbf{c} \neq \mathbf{0}$, for any $\mathbf{x}$, we must have $\mathbf{y}$, where $\mathbf{y} = \mathbf{x} \oplus \mathbf{c}$ and $\mathbf{x} \neq \mathbf{y}$, $f(\mathbf{x}) = f(\mathbf{y})$. So $f$ is at least a two-to-one mapping. Assuming there exists a tuple of $\mathbf{x}$, $\mathbf{y}$, and $\mathbf{z}$, where $\mathbf{y} = \mathbf{x} \oplus \mathbf{c}$, $\mathbf{z} \neq \mathbf{x}$, and $\mathbf{z} \neq \mathbf{y}$, and $f(\mathbf{x}) = f(\mathbf{y}) = f(\mathbf{z})$. According to the assurance, $\mathbf{z} = \mathbf{x} \oplus \mathbf{c}$. But $\mathbf{x} \oplus \mathbf{c} = \mathbf{y}$ so we have $\mathbf{z} = \mathbf{y}$. This raises contradiction and therefore $f$ has to be a two-to-one mapping when $\mathbf{c} \neq \mathbf{0}$.</p>



<p>This concludes the proof.</p>

<h4 id="trivial-solution">Trivial Solution</h4>

<p>Solving Simon’s problem could be trivial.</p>



<p>If we happen to know any $\mathbf{x}$ and $\mathbf{y}$, where $\mathbf{x} \neq \mathbf{y}$ and $f(\mathbf{x}) = f(\mathbf{y})$, we immediately know $\mathbf{c} \neq \mathbf{0}$ and $\mathbf{c} = \mathbf{x} \oplus \mathbf{y}$. This is because,</p><p>

\[\begin{align}
\mathbf{x} \oplus \mathbf{y} &amp;= \mathbf{x} \oplus ( \mathbf{x} \oplus \mathbf{c} ) \\
&amp;= ( \mathbf{x} \oplus \mathbf{x} ) \oplus \mathbf{c} \\
&amp;= \mathbf{0} \oplus \mathbf{c} \\
&amp;= \mathbf{c} \\
\end{align}\]

</p><p>If we have checked all $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$ and found there are no $\mathbf{x}$ and $\mathbf{y}$, where $\mathbf{x} \neq \mathbf{y}$ and $f(\mathbf{x}) = f(\mathbf{y})$, we immediately know $\mathbf{c} = \mathbf{0}$.</p>



<p>So the trivial solution for solving Simon’s problem is to evaluate $f$ using the values in $\{0,1\}^n$ one by one, and check if the newly …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Simon-Algorithm/">https://leimao.github.io/blog/Simon-Algorithm/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Simon-Algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072037</guid>
            <pubDate>Thu, 06 Aug 2020 15:49:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Terminal Jockey's Toolbelt]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24071608">thread link</a>) | @packetlost
<br/>
August 6, 2020 | https://packetlost.dev/the-terminal-jockeys-toolbelt | <a href="https://web.archive.org/web/*/https://packetlost.dev/the-terminal-jockeys-toolbelt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>How much do you think software <a href="https://packetlost.dev/tag:development" rel="nofollow"><span>#</span><span>development</span></a> has changed over the last 20 years? Many would say quite a bit. But, my opinion is that fundamentally not much has really changed. Many of us still use the tried and true method of telling a computer what to do: the terminal. While the <a href="https://packetlost.dev/tag:terminal" rel="nofollow"><span>#</span><span>terminal</span></a> has changed it's appearance a bit over the years, it's still fundamentally the same tool it was 50 years ago. But the terminal is really only the window, and the tools we use through it <em>have</em> changed over the years. At least for some of us. As someone who spends most of his day bashing away at my clicky mechanical keyboard, I'd like to share some of the modern tools that I use to do my job, many of which replace commonly installed *nix tools.</p>

<p>I'm always looking to improve and integrate new tools into my workflow. If you have any suggestions, feel free to email me at the address at the bottom of this post or message me on <a href="https://twitter.com/chiefnoah13" rel="nofollow">Twitter</a>.</p>

<hr>

<h2 id="hot-reload-all-the-things">🔥Hot🔥 Reload All the Things</h2>

<p><a href="http://eradman.com/entrproject/" rel="nofollow">entr(1)</a></p>

<blockquote><p>Edit → Compile → Test → Edit → Compile → Test → Edit → Compile → Test</p></blockquote>

<p>Have you ever found yourself in a loop of editing a file, executing/compiling it over and over and over again? Well here's the solution to your <em>home row →</em> ⬆️ RSI.</p>

<p>Well repeat no more! Enter <code>entr</code>, stage left. <code>entr</code> is a fairly simple command line utility that will execute a command whenever a file or list of files change. When combined with a utility like <code>find</code> or <code>fd</code> it becomes insanely powerful.</p>

<p>Some examples of what I use it for:</p>

<pre><code>fd ".+\.py" | entr python -m pytest some_test.py
fd -g "*.go" | entr -r go run cmd/server.go
</code></pre>

<p>My day job is primarily python, so a common use-case for me is in a <code>:term</code> using <code>neovim</code> with a similar command to run tests automatically after each file save, and similar for compiled languages such as Go.</p>

<p>Another common one is when developing a web server application. For example, in Go I use a command similar to the following:</p>

<pre><code>fd -g "*.go" | entr -r sh -c "go build cmd/server.go -o server &amp;&amp; ./server"
</code></pre>

<p>This rebuilds and runs the server after every file change. The <code>-r</code> flag sends a SIGINT to the process when a file change is detected, and then re-executes the command. Pretty neat, right?</p>

<p>It's worth calling out that this is a common feature in many IDEs. As an occasional user of PyCharm, I've used the built-in equivalent to achieve the same result. However, I prefer to work in vim, so this fills that role for me.</p>

<h2 id="what-was-that-flag-again">What was that flag again?</h2>

<p><a href="https://github.com/sharkdp/fd" rel="nofollow">fd(1)</a></p>

<p><code>find</code> has been a long-time tool for *nix users. But for someone who hasn't gotten used to the esoteric syntax of <code>find</code>, or is looking for something that requires typing a bit less (among many other really nice features), look no further than <code>fd</code>. You may have noticed I use <code>fd</code> in my previous example, <code>entr</code>.</p>

<p>I typically prefer glob patterns to regex for quick searches, so most of the time I add a <code>-g</code> to my commands to enable glob mode.</p>

<p>One of the areas that <code>fd</code> really shines is an improved templating syntax for the <code>--exec</code> / <code>-e</code> flag. The main GitHub readme has some pretty solid examples, so be sure to check out their <a href="https://github.com/sharkdp/fd/blob/master/README.md" rel="nofollow">README</a>.</p>

<h2 id="the-silver-searcher">The Silver Searcher</h2>

<p><a href="https://github.com/ggreer/the_silver_searcher" rel="nofollow">ag(1)</a></p>

<p>My life was changed the day I learned aboug <code>grep -r</code>. Recursively searching for text in a codebase is easily one my most common daily tasks. For my day job, we have... a <em>lot</em> of files, some rather large. The Silever Searcher, or just <code>ag</code> (the atomic symbol for Silver 🙂) is a simple replacement for <code>grep -r</code> that's more performant and has nice ANSI color coding in the terminal. The syntax is pretty similar to <code>grep</code> so it makes for a good drop-in replacement to speed up your workflow by those <em>crucial</em> few milliseconds.</p>

<p><img src="https://i.snap.as/U2HscOd.png" alt=""></p>

<h2 id="all-things-old-are-new-again-and-with-lua">All things old are new again, and with Lua</h2>

<p><a href="https://neovim.io/" rel="nofollow">nvim(1)</a></p>

<p><code>nvim</code> is a fork of the infamous <code>vim</code> project. Much of the project has focused on cleaning up the codebase, adding async support (which was subsequently added to <code>vim</code> for version 8), and Lua as a first-class language. The Lua API in particular allows for more robust and easy to maintain plugins (in theory). That being said, I'm not big on diving deep into customizing my editor, though I've made several shortcuts and rely on a handful of plugins. I generally tend to focus on memorizing the default keybindings so when moving from system to system I don't have to unlearn or mess up text entry. Check out my <a href="https://git.sr.ht/~chiefnoah/dotfiles/tree/master/dotfiles/config/nvim/init.vim" rel="nofollow">dotfiles</a>!</p>

<p>Regardless of which editor you use on the daily, it's worth learning the basics of <code>vim</code>, it's available on nearly every Linux or Unix system and is particularly fantastic at making quick edits to config files.</p>

<p><img src="https://i.snap.as/JyqcvJ8.png" alt=""></p>

<h2 id="email-for-the-20th-century">Email for the 20th century</h2>

<p><a href="https://aerc-mail.org/" rel="nofollow">aerc(1)</a></p>

<p><code>aerc</code> is one of <a href="https://drewdevault.com/" rel="nofollow">Drew DeVault</a>'s projects, and was originally built to suit his particular workflow. Despite this, it's actually a really nice modern implementation of an IMAP4/SMTP/POP3 client for the terminal (provided you primarily use <code>text/plain</code>). It's far more intuitive than <code>mutt</code> or other alternatives that I've tried, and it's <strong>fast</strong>. Well, usually. I've noticed some minor performance issues with a high latency connection to the mail server, but overall the experience is fantastic and it's my client of choice for email.</p>

<p><img src="https://i.snap.as/GjcsDLV.png" alt=""></p>

<h2 id="markdown-rendering-in-the-terminal">Markdown rendering... in the terminal!?</h2>

<p><a href="https://github.com/MichaelMure/mdr" rel="nofollow">mdr(1)</a></p>

<p>Have you ever been working on a <code>README.md</code> and somehow forgotten that you need a double newline for it to actually render properly in markdown? I know I have way more than is reasonable for someone in my profession. Well to help with markdown rendering woes, <code>mdr</code> renders markdown with color highlighting and rich text formatting! It even tries to render images!</p>

<p>Given that not all of markdown's output format (typically HTML) is compatible with rendering to a terminal, it does make some compromises, but I've found it's fine 99% of the time.</p>

<p><img src="https://i.snap.as/1KPbMlA.png" alt=""></p>

<p>For comparison on what this looks like rendered to HTML, check out that project's <a href="https://git.sr.ht/~chiefnoah/origin/tree/master/README.md" rel="nofollow">README.md</a>.</p>

<h2 id="honorable-mentions">Honorable Mentions</h2>

<p>Some other tools that I like to use when appropriate, but I didn't feel like including in the main list:</p>
<ul><li><a href="https://github.com/apenwarr/redo" rel="nofollow"><code>redo(1)</code></a> – <code>make</code> but much, <em>much</em> better
<ul><li>I prefer this to <code>make</code> as it lacks some of the strange formatting quirks of the Makefile, and it is generally easier to work with and understand</li></ul></li>
<li><a href="https://github.com/tmux/tmux/wiki" rel="nofollow"><code>tmux(1)</code></a> – terminal multiplexing, who needs a desktop?</li>
<li><a href="https://tldr.sh/" rel="nofollow"><code>tldr(1)</code></a> – <code>man</code> pages quick reference
<ul><li>I don't actually use this one as much yet, I just haven't integrated it into my workflow, but I appreciate the project and likely will get to it eventually</li></ul></li>
<li><a href="https://github.com/BurntSushi/ripgrep" rel="nofollow"><code>ripgrep</code>/<code>rg(1)</code></a> – similar to <code>ag(1)</code>, a faster more modern <code>grep -r</code> command
<ul><li>This one was added based on feedback. I don't use it, but many seem to prefer it</li></ul></li></ul>

<hr>

<p>Thanks for reading! If you have any questions or comments, shoot me an email at <a href="mailto:noah@packetlost.dev" rel="nofollow">noah@packetlost.dev</a> or <a href="https://twitter.com/intent/tweet?ref_src=twsrc%5Etfw&amp;screen_name=chiefnoah13" rel="nofollow">Tweet to @chiefnoah13</a></p>
</div></div>]]>
            </description>
            <link>https://packetlost.dev/the-terminal-jockeys-toolbelt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24071608</guid>
            <pubDate>Thu, 06 Aug 2020 15:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use the next-gen open-sourced .Avif image format, 50% smaller than JPEG]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24071431">thread link</a>) | @tomhanlon
<br/>
August 6, 2020 | https://reachlightspeed.com/blog/using-the-new-high-performance-avif-image-format-on-the-web-today/ | <a href="https://web.archive.org/web/*/https://reachlightspeed.com/blog/using-the-new-high-performance-avif-image-format-on-the-web-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>A More Optimal Image Format</h2><p><a href="http://aomedia.org/" title="AV1 (.avif) File Format"><svg width="220" viewBox="0 0 240 330" fill="none" xmlns="http://www.w3.org/2000/svg"><title>AV1 (.avif) File Format</title><path d="M9 10v310h221V69l-58-59H9zm163 0v59h58" fill="#fff"></path><path d="M172 10l58 59h-58V10z" fill="#fff"></path><path d="M230 69v251H9V10h163m58 59l-58-59m58 59h-58V10" stroke="#3B5EE2" stroke-width="8" stroke-linecap="round" stroke-linejoin="round"></path><path d="M211 190l-42-74-43 74h85z" fill="#FBAC30"></path><path d="M211 190l-16-19h-53l-16 19h85z" fill="#12B17D"></path><path d="M169 218l26-47h-53l27 47z" fill="#BB255C"></path><path d="M67 183H47l-2 7H28l19-53h20l20 53H69l-2-7zm-16-13h12l-6-19-6 19zm25-33h18l12 36 11-36h18l-19 53H96l-20-53" fill="#000"></path><path d="M165 150l-5 6-6-6 13-13h9v32h-11v-19" fill="#F1F4D4"></path><path d="M172 10l58 59h-58V10z" fill="#3B5EE2" stroke="#3B5EE2" stroke-width="8" stroke-linecap="round" stroke-linejoin="round"></path></svg></a></p><p>One of the upcoming technologies we're really excited about is the <a href="https://aomediacodec.github.io/av1-avif/">AV1 (.avif)</a> image file format. It's basically a super-compressed image type. <a href="https://netflixtechblog.com/avif-for-next-generation-image-coding-b1d75675fe4" title="AVIF for Next-Generation Image Coding">Netflix</a> has already considered .avif superior to the JPEG, PNG, and even the newer WebP image formats for its image quality to compressed file size ratio.</p><p>The format was developed by the <a href="http://aomedia.org/">Alliance for Open Media</a> in collaboration with Google, Cisco, and Xiph.org (who worked with Mozilla, creators of the Firefox browser). This format was created to be an open-sourced and royalty-free image format (unlike JPEG XR, which is a file format that compresses down very small but requires expensive licensing to implement).</p><h2>AVIF Compared to JPEG and WebP</h2><p>AVIF offers significant file size reduction for images compared with JPEG or WebP; <strong>~50% savings compared to JPEG</strong>, and <strong>~20% savings compared to WebP</strong>. Daniel Aleksandersen of <a href="https://www.ctrl.blog/">CTRL.Blog</a> has a great breakdown and deep dive into <a href="https://www.ctrl.blog/entry/webp-avif-comparison.html">AVIF comparison to JPEG and WebP</a>.</p><p><svg width="768" viewBox="0 0 768 216" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 16h380a4 4 0 014 4v44a4 4 0 01-4 4H0V16zM0 82h533.6a4 4 0 014 4v44a4 4 0 01-4 4H0V82zM0 148h764a4 4 0 014 4v44a4 4 0 01-4 4H0v-52z" fill="#3B5EE2"></path><text fill="#fff" style="white-space:pre" font-size="28" letter-spacing="0em"><tspan x="317.08" y="50.95">.avif</tspan></text><text fill="#fff" style="white-space:pre" font-size="20" font-weight="300" letter-spacing="0em"><tspan x="12" y="49.11">50% smaller than .jpeg</tspan></text><text fill="#fff" style="white-space:pre" font-size="20" font-weight="300" letter-spacing="0em"><tspan x="12" y="116.11">30% smaller than .jpeg</tspan></text><text fill="#fff" style="white-space:pre" font-size="28" letter-spacing="0em"><tspan x="449.21" y="116.95">.webp</tspan></text><text fill="#fff" style="white-space:pre" font-size="28" letter-spacing="0em"><tspan x="692.03" y="182.95">.jpeg</tspan></text></svg></p><p>The format is very flexible in that it supports any image codec, can be lossy or lossless, has the ability to use an alpha channel (transparency for UI and design elements), and even has the ability to store a series of animated frames (think lightweight high-quality animated GIFs).</p><p>It is also one of the first image formats to support HDR color support; offering higher brightness, color bit depth, and color gamuts.</p><h2>Using AVIF in Web Development Today</h2><p>AVIF is supposed to land in <a href="https://www.chromestatus.com/feature/4905307790639104">Chrome 85</a> and <a href="https://www.mozilla.org/en-US/firefox/80.0beta/releasenotes/">Firefox 80</a> on August 25, 2020; so we should start developing for it today!</p><p><picture><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-support.avif" type="image/avif"><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-no_support.jpg" type="image/jpeg"><img src="https://reachlightspeed.com/img/blog/post-using-avif-images-today-no_support.jpg" width="768" loading="lazy" alt="Does your browser support AVIF?"></picture></p><p>The AVIF image above likely doesn't show in your browser, but it can by using <a href="https://www.google.com/chrome/canary/">Chrome Canary</a> or by enabling AVIF in the Firefox advanced configuration preferences. You can do this by entering <code>about:config</code> in the URL bar, searching <code>image.avif.enabled</code>, and flipping this parameter to <code>true</code>.</p><p><picture><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-firefox-avif.webp" type="image/webp"><img src="https://reachlightspeed.com/img/blog/post-using-avif-images-today-firefox-avif.png" width="768" loading="lazy" alt="Enable AVIF within Firefox Advanced Configuration Preferences"></picture></p><h2>Create AVIF Files with Squoosh (AVIF Beta)</h2><p><a href="https://squoosh.app/">Squoosh</a> is an image compression web app that allows you to dive into the advanced options provided by various image compressors.</p><p>While Google Chrome Labs plans to add AVIF to the amazing Squoosh web app, <a href="https://squoosh-avif.netlify.app/">here is an early build with AVIF support</a> that is built from a more recent <a href="https://github.com/GoogleChromeLabs/squoosh/pull/722">Pull Request</a>. It might be a little buggy as expected, but definitely functions well. In my opinion, this is the best option right now for converting and creating .avif files.</p><p><a href="https://squoosh-avif.netlify.app/"><picture><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-squoosh-avif.avif" type="image/avif"><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-squoosh-avif.webp" type="image/webp"><img src="https://reachlightspeed.com/img/blog/post-using-avif-images-today-squoosh-avif.jpg" width="768" loading="lazy" alt="Use Squoosh to convert and encode AVIF files."></picture></a></p><p><a href="https://squoosh-avif.netlify.app/">Squoosh (AVIF Beta)</a></p><p>If you are comfortable in the command line, you can use the offical AOMedia library, <a href="https://github.com/AOMediaCodec/libavif">libavif</a>, to encode/decode AVIF files. Also, if you're a macOS user with <a href="https://brew.sh/">Homebrew</a>, you can quickly install a pre-built version using <code>brew install joedrago/repo/avifenc</code>, and <code>avifenc --help</code> for syntax and options.</p><h2>AVIF as Progressive Enhancement</h2><p>Even though AVIF isn't support everywhere yet, we can still use the format in native HTML with the <code>&lt;picture&gt;</code> element. The <code>&lt;picture&gt;</code> element allows for progressive support as we can list the image sources in the order in which we want loaded, and the browser will load the first that it supports. If browser doesn't support <code>&lt;picture&gt;</code> at all, it will fallback to using the default <code>&lt;img&gt;</code>.</p><pre><code><span><span><span>&lt;</span>picture</span><span>&gt;</span></span><br>	<span><span><span>&lt;</span>source</span> <span>srcset</span><span><span>=</span><span>"</span>img/photo.avif<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>image/avif<span>"</span></span><span>&gt;</span></span><br>	<span><span><span>&lt;</span>source</span> <span>srcset</span><span><span>=</span><span>"</span>img/photo.webp<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>image/webp<span>"</span></span><span>&gt;</span></span><br>	<span><span><span>&lt;</span>img</span> <span>src</span><span><span>=</span><span>"</span>img/photo.jpg<span>"</span></span> <span>alt</span><span><span>=</span><span>"</span>Description of Photo<span>"</span></span><span>&gt;</span></span><br><span><span><span>&lt;/</span>picture</span><span>&gt;</span></span></code></pre><h2>AVIF Content-Type Headers + Netlify</h2><p>An issue we noticed when using .avif files on <a href="https://www.netlify.com/">Netlify</a>, was that the image wasn't showing up in Firefox. It worked fine for Chrome, but not Firefox. We identified that the Response Headers were returning <code>Content-Type: application/octet-stream</code>, causing Firefox to display nothing. We fixed this by defining custom headers within the Netlify configuration file (<code>netlify.toml</code>).</p><pre><code><span>[</span><span>[</span>headers<span>]</span><span>]</span><br>  for = "<span>*.avif"</span><br>  <span>[</span>headers.values<span>]</span><br>    Content<span>-</span>Type = "image/avif"<br>    Content<span>-</span>Disposition = "inline"</code></pre><p>We also set the <code>Content-Disposition</code> to <code>inline</code> vs <code>attachment</code>, this way the browser will try to render the file within the browser rather than externally. A good example of this is when a PDF will open within the browser vs as a downloadable file. While <code>inline</code> should be default behavior, specifying won't hurt as this is a new filetype.</p><p>You can learn more about setting <a href="https://docs.netlify.com/routing/headers/">Custom Headers in Netlify</a> by checking out their docs.</p><h2>We're Excited</h2><p>We are super excited about what kind of awesome new experiences can be made with the flexibility and performance gains of this new format.</p></section></div>]]>
            </description>
            <link>https://reachlightspeed.com/blog/using-the-new-high-performance-avif-image-format-on-the-web-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24071431</guid>
            <pubDate>Thu, 06 Aug 2020 14:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Math of Card Shuffling (2018)]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24069999">thread link</a>) | @benibraz
<br/>
August 6, 2020 | https://fredhohman.com/card-shuffling/ | <a href="https://web.archive.org/web/*/https://fredhohman.com/card-shuffling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="idyll-mount"><div data-reactroot=""><div><div><div><h2>Riffling from factory order to complete randomness.</h2></div><p>You’ve probably seen a few ways to shuffle a deck of cards.
Sometimes the deck is split in half and the halves are switched.
Sometimes the deck is <em><a href="https://big.assets.huffingtonpost.com/smooshing.gif">smooshed</a></em> until it’s all mixed up.
But most of the time, a deck of cards is shuffled using a <em>riffle</em>.</p><p><img src="https://fredhohman.com/card-shuffling/static/images/riffle.gif" idyll="[object Object]"></p><p>Here’s a question: <em>how many times do you have to riffle a deck of cards before it is completely shuffled?</em>

It’s a tricky one, but math has us covered: <a href="https://en.wikipedia.org/wiki/Shuffling#Riffle">you need seven riffles</a>.</p><div><p>
We can calculate the number of orderings of a deck of cards using the notion of a <a href="https://en.wikipedia.org/wiki/Permutation">permutation</a>.
To find all arrangements of 52 cards in a deck, we compute <strong>5<!-- -->2<!-- -->!</strong>, which happens to be a <a href="https://www.wolframalpha.com/input/?i=52!">really big number</a>.</p></div><p>Riffle seven times and you’ll have a sufficiently random ordering of cards, an ordering that has likely <a href="http://www.murderousmaths.co.uk/cardperms.htm">never existed before</a>.
In other words, it’s unlikely you’ll ever shuffle two decks the same.</p><p>The card shuffling result appears in a <a href="https://www.youtube.com/watch?v=AxJubaijQbI">Numberphile video from 2015</a>, along with a number of other card shuffling facts.
Here’s another problem posed in that video: what if instead of a standard riffle using a deck roughly split in half, you were to only riffle <em>1<!-- --> card at a time</em>?</p><div><p><a href="https://projecteuclid.org/download/pdf_1/euclid.aoap/1177005705">This paper</a> shows a number of other interesting card shuffling results in all their gory details.</p></div><p>That is, using a standard deck of 52 cards, in one hand hold 51 cards and in the other hold the remaining single card.
Now riffle these together.
This is equivalent to taking one card and placing it at random inside of the deck.</p><p><strong>So here’s the question:</strong>
<br><em>How many single riffles do you have to do in order to have a completely shuffled deck?</em>

</p><h2>Theorem</h2><p>You could simulate this in a short program, which we will do towards the end, but first we can solve for the number of riffles explicitly.</p><p>Consider an ordered deck of cards. <a href="https://en.wikipedia.org/wiki/Without_loss_of_generality">Without loss of generality</a>, let’s say the suits are in the following order: <span suit="S">♠</span>, <span suit="C">♣</span>, <span suit="H">♥</span>, <span suit="D">♦</span>.
So our ordered deck looks like this.</p><p>The bottom suit is <span suit="D">♦</span>, which means the bottom card of our deck is the King of Diamonds (<span number="K" suit="D">K♦</span>).
Now perform the following iteration:</p><blockquote>Place the top card of the deck randomly inside the deck</blockquote><p>This means taking the <span number="A" suit="S">A♠</span> and placing it randomly somewhere in the deck.
The top card then becomes <span number="2" suit="S">2♠</span>.</p><p>If this procedure is repeated, eventually the top card will be placed at the very bottom of the deck, shifting the <span number="K" suit="D">K♦</span> to the penultimate position.
Since every riffled card has a <span><span> <span><span><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{52}</annotation></semantics></math></span></span> </span></span> chance of moving to any new position in the deck, that means, on average, after about 52 top card riffles, the top card will become the new bottom card.</p><div><div><p><strong>Note:</strong> notice the <span number="K" suit="D">K♦</span> can only rise in the deck.
There are two cases:</p><ol><li>The top card is placed above the <span number="K" suit="D">K♦</span>, therefore its position does not change.</li><li>The top card is placed underneath the <span number="K" suit="D">K♦</span>, therefore it rises one position closer to the top.</li></ol></div></div><p>Once the <span number="K" suit="D">K♦</span> moves up one position, upon subsequent riffles there are now two spots for the new top card to be placed underneath it.
That means there is now a <span><span> <span><span><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{52}+\frac{1}{52}=\frac{2}{52}</annotation></semantics></math></span></span> </span></span> chance of a riffled card going underneath the <span number="K" suit="D">K♦</span>.</p><p>Continuing this procedure, the original bottom card, the <span number="K" suit="D">K♦</span>, will eventually rise to the top of the deck and be riffled.
Once this happens, the deck is randomly shuffled: the order we’re left with is equally as likely as any other order.</p><p>So, how many single card riffles does this take?
Recall each time a card is placed underneath the <span number="K" suit="D">K♦</span>, our chances of placing another card increases by <span><span> <span><span><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{52}</annotation></semantics></math></span></span> </span></span>.
We can calculate the number of riffles this would take.</p><p><span><span> <span><span><span><math><semantics><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></munderover><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mi>i</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>1</mn></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>2</mn></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac><mo>≈</mo><mn>2</mn><mn>3</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">\sum_{i=1}^{52} \frac{52}{i} = \frac{52}{1} + \frac{52}{2} + \frac{52}{3} + ... + \frac{52}{52} \approx 236</annotation></semantics></math></span></span></span> </span></span></p><p>On average, 236 single card riffles will randomly shuffle a deck of cards.</p><h2>Let’s Riffle</h2><p>Equations are great, but let’s visualize this!
Below is the same ordered deck of cards from before, except the <span number="K" suit="D">K♦</span> has been highlighted red so we can follow its journey to the top of the deck.</p><p>Click the <strong>Riffle</strong> button to move the top card somewhere else in the deck randomly.</p><p>Did you see where it went? Click again.</p><p>Click a bunch more really fast.</p><p>Now I could tell you to keep clicking until the highlighted <span number="K" suit="D">K♦</span> rises to the top, but as we have already shown, that would take about 236 clicks.
Instead, click the <strong>Riffle (x<!-- -->1<!-- -->0<!-- -->)</strong> button to riffle 10 times.
Keep riffling until the <span number="K" suit="D">K♦</span> moves to the top.</p><div><p>
You have riffled <strong><span>0</span></strong> times.<br></p></div><p>Here is a chart of the <span number="K" suit="D">K♦</span>’s position in the deck for each riffle.
Notice how it takes many riffles to move the <span number="K" suit="D">K♦</span> up just a few positions, but once the <span number="K" suit="D">K♦</span> starts rising towards the top of the deck, it accelerates.</p><div><p>
Once the <span number="K" suit="D">K♦</span> is the top card, click the <strong>Clear</strong> button to try again.</p></div><p>On average, the <span number="K" suit="D">K♦</span> will reach the top position somewhere around 236 riffles.
Since this is the <em>average</em> result, there is a chance your first shuffled deck of cards took less riffles (or many more!).
To try again, click the <strong>Clear</strong> button and get riffling.</p><h3>Acknowledgements</h3><ul><li>This article was created using <a href="https://idyll-lang.org/">Idyll</a>.</li><li>Shoutout to <a href="https://twitter.com/mathisonian">@mathisonian</a> <!-- -->for help and feedback.</li><li>The source code is available on <a href="https://github.com/fredhohman/card-shuffling/">Github</a>.</li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://fredhohman.com/card-shuffling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24069999</guid>
            <pubDate>Thu, 06 Aug 2020 11:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with RISC-V Vector Instructions]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 35 (<a href="https://news.ycombinator.com/item?id=24069793">thread link</a>) | @pantalaimon
<br/>
August 6, 2020 | https://gms.tf/riscv-vector.html | <a href="https://web.archive.org/web/*/https://gms.tf/riscv-vector.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <header>
        
      </header>
      
<!-- content -->
<p>Perhaps the most interesting part of the open <a href="https://en.wikipedia.org/wiki/RISC-V">RISC-V</a> <a href="https://en.wikipedia.org/wiki/Instruction_set_architecture">instruction set architecture (ISA)</a> is the vector extension (RISC-V "V").
In contrast to the average <a href="https://en.wikipedia.org/wiki/SIMD">single-instruction multipe-data (SIMD)</a> instruction set, RISC-V vector instructions are vector length agnostic (VLA).
Thus, a RISC-V "V" CPU is flexible in choosing a vector register size while RISC-V "V" binary code is portable between different CPU implementations.</p>
<p>This articles compares the two main different styles of vector ISAs, discusses a string processing  example that is implemented using <a href="https://github.com/riscv/riscv-v-spec/releases/tag/0.8">RISC-V "V" draft version 0.8</a> (current as of early 2020) vector instructions and details how to set up a RISC-V "V" development environment under Linux.</p>

<section id="simd-challenges">
<h2><a href="#id13">SIMD Challenges</a></h2>
<p>With a vector length specific (VLS) <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a> instruction set the main problem is to pick the right vector register size.
Of course there is a trade-off between the amount of data-level parallelism and hardware costs.
Due to <a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore's law</a>, vector register sizes can be increased over time without making the CPU chip more expensive.
Also, some users are interested in powerful CPUs with wider vector registers while the average user is fine with averagely sized register.
Thus, there is no one right vector register size.
This shows for example with x86, where the answer is to provide one VLS ISA after the other, such as <a href="https://en.wikipedia.org/wiki/MMX_(instruction_set)">MMX</a> (64 bit registers), <a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a> (128 bit), <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a> (256 bit) and <a href="https://en.wikipedia.org/wiki/AVX-512">AVX512</a> (512 bit).</p>
<p>Because of <a href="https://en.wikipedia.org/wiki/Backward_compatibility">backward compatibility</a>, each CPU that adds a new VLS ISA also has to support all existing ones.
This leads to a waste of <a href="https://en.wikipedia.org/wiki/Opcode">opcode</a> space and increases the complexity of the CPU's <a href="https://en.wikipedia.org/wiki/Instruction_cycle#Decode_stage">instruction decoder</a>.
Of course this also increases the complexity for the programmer who has then remember (or look up all the time) syntactic and functional differences between all the VLS ISAs.</p>
<p>That means that while VLS code written for smaller vector registers runs on newer CPUs, it can't make use of the wider vector registers.
Thus, existing code has to be reimplemented again and again to make use of new VLS ISAs.
Similarly, code written for high-end CPUs doesn't run on middle-end CPUs (because it requires the VLS-ISA with wider vector registers).
Thus one either has to target some older (hopefully widely available) VSL-ISA or has to provide multiple implementations for different VSL-ISAs.</p>
</section>
<section id="the-solution-agnosticism">
<h2><a href="#id14">The Solution: Agnosticism</a></h2>
<p>The solution to all this is to design a variable length vector instruction set.
In that way the instructions are then agnostic to the vector register size of a concrete CPU implementation.
Thus, the binary code is portable between low, middle and high-end CPUs, and automatically makes use of wider registers in newer CPUs.</p>
<p>The <a href="https://github.com/riscv/riscv-v-spec/releases/tag/0.8">RISC-V vector extension "V"</a> implements such vector instruction set.
As of early 2020, the <a href="https://github.com/riscv/riscv-v-spec/releases/tag/0.8">RISC-V "V" specification</a> is at version 0.8 and has draft status.</p>
<p>RISC-V "V" adds 32 vector registers, where the first register can be used as mask register and up to 8 registers can be grouped together.
The operands of a vector instruction such as <code>vadd.vv</code> are single vector registers or vector register groups.</p>
<p>Since vector registers are of variable length, RISC-V "V" code has to indicate the maximum vector length it wants to work with, e.g.:</p>
<pre><span>vsetvli</span> <span>t0</span><span>,</span> <span>a2</span><span>,</span> <span>e8</span></pre>
<p>Meaning that a vector length (vl) of up to <code>a2</code> 8 bit wide (<code>e8</code>) elements is requested while the instruction returns the resulting length in register <code>t0</code>.
Thus, if the <code>a2</code> register is set to - say - <code>4096</code>, on a CPU with a vector register length (VLEN) of 128 bits, the following vector instructions work on 16 element wide vectors and <code>t0</code> is thus set to <code>16</code>, while on a CPU with 512 bit registers the vectors are configured to be 64 elements wide and <code>t0</code> is set to <code>64</code>.</p>
<p>This approach also simplifies loops that iterate over an input array in vector length chunks.
For example (where <code>a1</code> contains the address of an array of <code>a2</code> times 4 bytes):</p>
<pre><span>.Loop:</span>                        <span># local symbol name because of .L prefix</span>
    <span>vsetvli</span> <span>t0</span><span>,</span> <span>a2</span><span>,</span> <span>e32</span>       <span># configure vectors of 32 bit elements</span>

    <span>vlw.v</span>   <span>v4</span><span>,</span> <span>(</span><span>a1</span><span>)</span>          <span># Load t0 elements into v4,</span>
                              <span># starting at the address stored in a1</span>

    <span>...</span>                       <span># work with that chunk</span>

    <span>slli</span>    <span>t1</span><span>,</span> <span>t0</span><span>,</span> <span>2</span>         <span># shift-left logical, i.e. times 4</span>
    <span>add</span>     <span>a1</span><span>,</span> <span>a1</span><span>,</span> <span>t1</span>        <span># increment src by read elements</span>
    <span>sub</span>     <span>a2</span><span>,</span> <span>a2</span><span>,</span> <span>t0</span>        <span># decrement n</span>
    <span>bnez</span>    <span>a2</span><span>,</span> <span>.Loop</span>         <span># branch to loop head if not equal to zero</span>

    <span>...</span>                       <span># continue</span></pre>
<p>In cases where <code>a2</code> isn't a multiple of the maximum vector length, the last iteration
sets the vector length to a smaller value and the following vector instructions ignore
the unused trailing elements.
This implicit masking mechanism is orthogonal to the optional mask operand that is supported by most RISC-V vector instructions.</p>
<p>In contrast to that, with a vector length specific ISA, the main loop usually has to be followed by some finalization code block to explicitly deal with the last elements that don't fill a complete register, e.g.:</p>
<pre><span>const</span> <span>unsigned</span> <span>char</span> <span>*</span><span>p</span> <span>=</span> <span>inp</span><span>;</span>
<span>size_t</span> <span>l</span> <span>=</span> <span>n</span> <span>/</span> <span>(</span><span>VECTOR_LENGTH</span> <span>*</span> <span>ELEMENT_BYTES</span><span>);</span>
<span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>l</span><span>;</span> <span>++</span><span>i</span><span>,</span> <span>p</span> <span>+=</span> <span>VECTOR_LENGTH</span> <span>*</span> <span>ELEMENT_BYTES</span><span>)</span> <span>{</span>
    <span>...</span> <span>// load p into a vector register</span>
    <span>...</span> <span>// execute some vector instructions</span>
<span>}</span>
<span>// deal with some remaining bytes</span>
<span>// e.g. by setting up a mask or work on single elements</span>
<span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>l</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n</span><span>;</span> <span>++</span><span>i</span><span>,</span> <span>p</span> <span>+=</span> <span>ELEMENT_BYTES</span><span>)</span> <span>{</span>
    <span>...</span> <span>// work on the next element located at p</span>
<span>}</span></pre>
</section>
<section id="example">
<h2><a href="#id15">Example</a></h2>
<p>To illustrate RISC-V "V" with a real example, this section shows how to implement a vectorized function that converts a string of <a href="https://en.wikipedia.org/wiki/Binary-coded_decimal">binary coded decimals (BCD)</a> into an <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> string.
Why BCD to ASCII conversion?
The task is complex enough such that most of the different vector instructions are used.
On the other hand, it's simple enough to fit into a small article and doesn't require domain specific knowledge.
It also demonstrates some perhaps not entirely obvious ways how vector instructions are used for string processing where those instruction could be assumed to only be useful for calculations.</p>
<p>With BCD, a byte (8 bits) is divided into two <a href="https://en.wikipedia.org/wiki/Nibble">nibbles</a> (4 bits) such that each nibble stores a (hexa-)decimal digit.
Note that 4 bits allow to exactly encode <span>2<sup>4</sup></span> values, thus when using it just for storing decimal digits it's not a very efficient encoding.</p>
<p>For the purpose of our example, the exercise is to write vector code that efficiently converts a BCD string such as <code>{ 0x12, 0x34, ..., 0xcd, 0xef }</code> to a corresponding ASCII string (e.g. <code>{ '1', '2', '3', '4', ..., 'c', 'd', 'e', 'f' }</code>). On a high-level, a solution involves separating the nibbles into single bytes and then converting each byte to the matching ASCII value.</p>
<p>The complete example source code is available in <a href="https://github.com/gsauthof/riscv">my github repository</a>.</p>
<section id="shuffling-nibbles">
<h3><a href="#id16">Shuffling Nibbles</a></h3>
<p>Our function has the following function signature:</p>
<pre><span>void</span> <span>bcd2ascii</span><span>(</span><span>void</span><span>*</span> <span>dst</span><span>,</span> <span>void</span> <span>const</span> <span>*</span> <span>src</span><span>,</span> <span>size_t</span> <span>n</span><span>);</span></pre>
<p>Meaning that <code>n</code> input bytes are read from <code>src</code> and the conversion writes <code>2*n</code> bytes into the <code>dst</code> output buffer.
Under the RISC-V calling conventions, <code>dst</code> is passed in register <code>a0</code>, <code>src</code> in register <code>a1</code> and <code>n</code> in register <code>a2</code>.</p>
<pre><span>.Loop:</span>                        <span># local symbol name because of .L prefix</span>
    <span>vsetvli</span> <span>a3</span><span>,</span> <span>a2</span><span>,</span> <span>e16</span><span>,</span> <span>m8</span>   <span># switch to 16 bit element size,</span>
                              <span># 4 groups of 8 registers</span>
    <span># --&gt; a3 = min(a2, 8*vlenb/2)</span>
    <span>vlbu.v</span> <span>v16</span><span>,</span> <span>(</span><span>a1</span><span>)</span>          <span># Load a3 unsigned bytes,</span>
                              <span># one byte per 16 bit element, zero-extend,</span>
                              <span># starting at addr stored in a1</span>
    <span># --&gt; v16 = | 0, a1[vlenb/2-1], ..., 0, a1[1], 0, a1[0] |, ...,</span>
    <span>#     v23 = | 0, a1[a3-1],       ...,  0, a1[7*vlenb/2] |</span>
    <span># --&gt; v16 = | ... 00mn 00kl 00ij 00gh |</span>

    <span>add</span> <span>a1</span><span>,</span> <span>a1</span><span>,</span> <span>a3</span>            <span># increment src by read elements</span>
    <span>sub</span> <span>a2</span><span>,</span> <span>a2</span><span>,</span> <span>a3</span>            <span># decrement n</span></pre>
<p>The main loop starts with configuring a vector element size of 16 bit (<code>e16</code>), grouping 8 registers together (<code>m8</code>) and requesting a vector length that equals the number of remaining source bytes or the CPU maximum.
With this grouping, each register group is accessed by using a vector register with a number that is dividable by 8.
That means <code>v0</code> identifies the group consisting of <code>v0, v1, ..., v7</code>, <code>v8</code> identifies <code>v8, ..., v15</code>, etc.</p>
<p>The <code>vl*.v</code> load instruction comes in different variants.
Here, the <code>vlbu.v</code> variant zero extends each input byte per 16 bit element which is useful in our example because this directly leaves room for shuffling the nibbles.
In other words, it's a widening load and thus saves a separate widening operation such as <code>vwaddu.vx</code>.</p>
<p>That means on CPUs with 256 bit vector registers, this code loads up to 128 input bytes into the <code>v16</code> register group.</p>
<p>Note that register content in the comments is enclosed in <code>| |</code> and written right to left, starting with the least significant element.
Arbitrary nibbles are denoted sometimes by placeholder variables such as <code>g, h, ...</code>.</p>
<p>The actual nibble shuffling:</p>
<pre><span>vsll.vi</span> <span>v24</span><span>,</span> <span>v16</span><span>,</span> <span>8</span>       <span># shift-left-logical each element by 8 bits</span>
<span># --&gt; v24 = | ... mn00 kl00 ij00 gh00 |</span>

<span>vsrl.vi</span> <span>v16</span><span>,</span> <span>v16</span><span>,</span> <span>4</span>       <span># shift-right-logical each element by 4 bits</span>
<span># --&gt; v16 = | ... 000m 000k 000i 000g |</span>

<span>slli</span> <span>a3</span><span>,</span> <span>a3</span><span>,</span> <span>1</span>            <span># shift left logical by immediate,</span>
                          <span># i.e. to double the number of vector elements</span>
<span>vsetvli</span> <span>t4</span><span>,</span> <span>a3</span><span>,</span> <span>e8</span><span>,</span> <span>m8</span>    <span># switch to 8 bit element size,</span>
                          <span># 4 groups of 8 registers</span>

<span>vand.vx</span> <span>v24</span><span>,</span> <span>v24</span><span>,</span> <span>t2</span>      <span># and each element with 0x0f,</span>
                          <span># i.e. zero-out the high nibbles</span>
<span># --&gt; v24 = | ... 0n 00 0l 00 0j 00 0h 00 |</span>
<span>vor.vv</span>  <span>v16</span><span>,</span> <span>v16</span><span>,</span> <span>v24</span>     <span># or each element</span>
<span># --&gt; v16 = | ... 0n 0m 0l 0k 0j 0i 0h 0g |</span></pre>
<p>So far the example shows most of the syntactic conventions of the "V" ISA.
Vector instructions start with <code>v</code> and a suffix such as <code>.vi</code>, <code>.vx</code> and <code>.vv</code> describe the source operand types, i.e. vector-immediate, vector-scalar and vector-vector.</p>
<p>The bit-shift instructions don't cross element boundaries.
Thus, just vector group <code>v24</code> has to be zero-masked and not <code>v16</code>.</p></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gms.tf/riscv-vector.html">https://gms.tf/riscv-vector.html</a></em></p>]]>
            </description>
            <link>https://gms.tf/riscv-vector.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24069793</guid>
            <pubDate>Thu, 06 Aug 2020 10:52:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Features of JavaScript that you might not know]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24069444">thread link</a>) | @illuminated
<br/>
August 6, 2020 | https://www.monkwhocode.com/2020/06/javascriptnodejs-2-features-that-you.html | <a href="https://web.archive.org/web/*/https://www.monkwhocode.com/2020/06/javascriptnodejs-2-features-that-you.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-5960135948766008378">
<div dir="ltr" trbidi="on">
<p><a href="https://1.bp.blogspot.com/-eUGp0l2lGGI/Xu8IjGPaWoI/AAAAAAAAWPw/t1PSsuhsUMUErg6Pqodr1mFqR8_Y1pNQgCLcBGAsYHQ/s1600/LEARN%2BeXPLORE%2Bgrow%2B%25288%2529.png" imageanchor="1"><img data-original-height="500" data-original-width="500" height="320" src="https://1.bp.blogspot.com/-eUGp0l2lGGI/Xu8IjGPaWoI/AAAAAAAAWPw/t1PSsuhsUMUErg6Pqodr1mFqR8_Y1pNQgCLcBGAsYHQ/s320/LEARN%2BeXPLORE%2Bgrow%2B%25288%2529.png" width="320"></a></p>

<p>
This is a very short article where we will be discussing two Javascript features that you may not know.</p>


<p>
So let's start,</p>

<p><b>1)Exponentiation operator(**):</b></p>
<p>
This operator was added in ES6 and is supported by most of the browsers but excluding internet explorer.</p>
<p>
It is also called an Infix operator for Exponentiation.</p>
<p>
Before for exponentiation, we have to use Math.pow(x,y).</p>
<p>
But now you can use x**y.</p>

<p>
For example: 2**5 //returns 32</p>

<p><b>2)Numeric Separators:</b></p>
<p>
Large numeric literals are difficult for the human eye to parse quickly,</p>
<p>
especially when there are lots of repeating digits. To improve readability, you can use</p>
<p>
underscores as separators in numeric literals.</p>

<p>
For example:</p>
<p>
let value= 100_000_000_00 //Is same as 10000000000</p>

<p>
As of May 2020, It is supported by all major browsers (Chrome[75+], Firefox[70+], Edge, Safari[13+], Opera) (<a href="https://caniuse.com/#feat=mdn-javascript_grammar_numeric_separators">source 1</a>, <a href="https://v8.dev/features/numeric-separators">source 2</a> for more details about different browsers and versions supporting it)&nbsp;</p>

<p>
Interesting note: although supported by all browsers, this is not part of any ECMAScript version yet.</p>



<p>
I hope you like this article and if any doubts please let me know in the comment section.</p>
<p>
Subscribe&nbsp;this blog for more articles on&nbsp;Node.js&nbsp;and&nbsp;JavaScript.<br>
You can also follow me on&nbsp;<b><a href="https://twitter.com/joshiisaurabh">Twitter</a></b>&nbsp;or&nbsp;<b><a href="https://www.linkedin.com/in/saurabh-joshi-b16b05b4/">Linkedin</a>&nbsp;</b>for<b>&nbsp;</b>the<b>&nbsp;</b>latest updates.</p><p>

Written By:<br>
<b>Saurabh Joshi</b></p>




<br></div>
</div>
</div></div>]]>
            </description>
            <link>https://www.monkwhocode.com/2020/06/javascriptnodejs-2-features-that-you.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24069444</guid>
            <pubDate>Thu, 06 Aug 2020 09:37:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discovering over 13M leaked records from unsecured Firebase Databases]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24068577">thread link</a>) | @bharatsb
<br/>
August 5, 2020 | https://goonsecurity.com/discovering-unsecured-firebase-databases/ | <a href="https://web.archive.org/web/*/https://goonsecurity.com/discovering-unsecured-firebase-databases/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
												<h3><a href="https://goonsecurity.com/" rel="home">Goon Security</a></h3>
					<h4>Information security research and vulnerability remediation</h4>
					
							
		</div></div>]]>
            </description>
            <link>https://goonsecurity.com/discovering-unsecured-firebase-databases/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24068577</guid>
            <pubDate>Thu, 06 Aug 2020 06:22:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Epic Systems workers are organizing]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24068201">thread link</a>) | @mgerdts
<br/>
August 5, 2020 | https://www.tonemadison.com/articles/epic-workers-arent-just-mad-theyre-organizing | <a href="https://web.archive.org/web/*/https://www.tonemadison.com/articles/epic-workers-arent-just-mad-theyre-organizing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1596655167481" id="item-5f2b05c776829d20055ef8a0"><div><div><div data-block-type="2" id="block-b9ef3d0cb4832dbe6ac8"><div><p><strong><em>The Madison-area tech company's botched COVID-19 response has spurred some employees to pursue unionization.</em></strong></p><p><strong><em>John McCracken contributed additional reporting for this story.</em></strong></p><p><strong><em>Photo by </em></strong><a href="https://www.flickr.com/photos/gas_station_sushi/7261830974" target="_blank"><strong><em>E. Nekervis on Flickr</em></strong></a><strong><em>.</em></strong></p><p>Epic Systems is putting Madison back in the tech-industry spotlight, this time for its troubling public health and labor practices. As COVID-19 cases mount in Wisconsin, Dane County’s second-largest employer is set to send workers back to its sprawling Verona campus in stages, starting on August 10.&nbsp;</p><p>Employee fears and anger surrounding the return-to-work plan are, at this point, well-established: national and local reporters have <a href="https://twitter.com/lkwhite/status/1290677520078196736?s=20" target="_blank">noted</a> the dozens of messages, calls, and emails they received in response to requests for comment. But employee dissatisfaction has manifested in more than complaints. It has also cracked open an opportunity for collective action in the Madison area’s biggest, most ostentatiously anti-labor private employer.&nbsp;</p><p>Many of the Epic employees facing down the return-to-work date say they are scared about the health implications of heading back to share physical space with thousands of their co-workers.</p><p>“There’s a person in my household who is at high risk for serious complications from COVID-19 and I am very cognizant of the fact that my actions affect more than just myself,” says one employee, who also has two school-aged kids. Like many Epic workers speaking to the press this week, this employee asked to be cited anonymously, due to fears about retaliation or firing.</p><p>In an August 3 email, company executives addressed people who are parents or facing higher risks of coronavirus-related complications to offer an extended work-from-home period—but only until November 2, at which point employees are told to take a leave of absence without a guarantee of getting their jobs back. In an earlier message, sent on July 1, executives told employees: "If you’re a parent with young children, you will need to use the time between now and your return to campus to make arrangements for childcare so that you can be on campus full-time."</p><p>Of the Epic employees who spoke with <em>Tone Madison</em> this week, even those who are not at personally heightened risk for COVID-19&nbsp; expressed concern on behalf of the community at large.</p><p>“I’m a software developer at Epic, I’ve worked there for over 8 years...it’s disrespectful and risking the health of the entire community,” says another concerned employee, who remained anonymous for fear of reprisal. “We should all understand&nbsp; that personal risk is community risk. And so Epic, by forcing 10,000 people to increase their personal risk, it does risk the whole community.”</p><p>The scheduled plan will have workers populating the medical software company’s sprawling campus over the same period that University of Wisconsin-Madison students prepare to return to their dorms and downtown housing. To justify the rapid return to work, Epic CEO Judy Faulkner has cited the “culture” of the company: “It’s hard (actually, it’s impossible) to retain our culture when we’re working from our homes,” wrote Faulkner in an all-staff email on July 1.&nbsp;</p><p>Workers argue that given the projected course of the virus, there’s no way the company can provide for a safe return to work.</p><p>In Faulkner’s communications with Epic staff, she emphasized the role of individual employees in preventing the spread of COVID-19 on campus: “We ask you to do your part by avoiding bars, attending crowded gatherings, or other places where physical distancing can’t be easily observed.” By placing the responsibility of limiting exposure on individual workers, the company rhetorically absolves itself of the possibility of an outbreak: after all, Faulkner—Epic's <a href="https://www.nytimes.com/2018/12/20/business/epic-systems-campus-verona-wisconsin.html" target="_blank">eccentric billionaire</a> founder —claimed in the same&nbsp; email, “we’ve been told by many that our campus looks specifically designed to weather an epidemic.”&nbsp;</p><p>Epic is notorious for preventing employees from coming together to advocate for themselves as a group. In the 2018 ruling <em>&nbsp;</em><a href="https://www.oyez.org/cases/2017/16-285" target="_blank"><em>Epic Systems Corp. v. Lewis</em></a>, the United States Supreme Court enshrined the right of employers to force workers into individual arbitration. To work for Epic, employees sign away their rights to file class-action lawsuits against the company. It's now easier for other employers around the country to enforce those kinds of terms: In May 2018, <a href="https://www.jdsupra.com/legalnews/new-jersey-supreme-court-confirms-20004/" target="_blank">citing the </a><a href="https://www.jdsupra.com/legalnews/new-jersey-supreme-court-confirms-20004/"><em>Epic v. Lewis</em> SCOTUS ruling, </a>the New Jersey Supreme Court ruled that truck drivers attempting to file a collective suit against their employer could be prohibited from doing so.&nbsp;</p><p>In mid-July, a coalition of Epic workers, concerned about the company’s plan to reopen offices, circulated a survey to demonstrate collective disapproval of the plan. The poll yielded hundreds of responses condemning the company’s response to the coronavirus pandemic—but an Epic employee familiar with the survey, who prefers to remain anonymous for fear of reprisal, says that the company ignored the survey results. <a href="https://www.cbsnews.com/video/employees-raise-safety-concerns-with-return-to-work-plans/">In a </a><a href="https://www.cbsnews.com/video/employees-raise-safety-concerns-with-return-to-work-plans/" target="_blank"><em>CBS News</em></a><a href="https://www.cbsnews.com/video/employees-raise-safety-concerns-with-return-to-work-plans/"> segment that aired Tuesday morning</a>, Epic’s Chief Administrative Officer Sverre David Roang evaded questions about the survey, claiming that he was unaware of complaints surrounding the plan to reopen.&nbsp;</p><p>The pandemic, and Epic’s disregard for workers’ concerns, have occasioned a sudden flurry of labor activism at the company. Groups of workers have started organizing with the International Association of Sheet Metal, Air, Rail and Transportation Workers (SMART) Local 565. The local represents workers at several Madison-area companies, including Sub-Zero and Trachte Building Systems, and at a few companies in the Wausau area. IWW, a political affiliation group emphasizing direct action, has likewise supported workers in their fight for better conditions at Epic. The IWW's local activities of late have included <a href="http://captelunion.org/2020/03/18/captel-workers-union-calls-sickout/" target="_blank">working to organize employees at CapTel's call centers</a> in Madison and Milwaukee, and <a href="https://www.tonemadison.com/articles/the-grassroots-response-to-covid-19-in-madison-puts-our-institutions-to-shame" target="_blank">spearheading mutual-aid efforts during the pandemic</a>.</p><p>One first-time organizer among Epic's workers reached a boiling point after the usual channels available to Epic employees failed. “The reason that we reached out to the IWW,” says the worker, who requested anonymity, “is that we basically tried all of the internal avenues to have things change for the better, the work-from-home policies, the response to Black Lives Matter. Epic tells us that we’re supposed to be able to give feedback to whomever we want, and it doesn’t seem to have gone anywhere.”</p><p>“The only reason I am doing something is that it got to a point where my fear of getting fired was outweighed by 'I have to do something,'" this worker says.&nbsp;</p><p>This worker and organizer provided internal emails that outline the supposed benefits of coming back to work. One email that Faulkner sent to staff argues that employees who return to campus will have a better connection to Epic's software and internal employees. “Personally, I’m not willing to go back to work and possibly get sick for a better internet connection,” the worker says.&nbsp;</p><p>One employee in the company’s hosting sector, who has looked into the various union organizing drives, says that organizing at Epic will be a challenge, given the company’s hiring practices and labor structure.&nbsp;</p><p>“It is a little bit harder to organize than other places because there’s so many people that are young, straight out of college . . . without any frame of reference for their workplace conditions,” he says. “And there's a lot of&nbsp; anti-union or anti-collective sentiments that the company will work very hard to enforce.”</p><p>In addition to the 2018 SCOTUS ruling, Epic has, in the past several weeks, quashed workers’ attempts to act collectively. In an email obtained by <em>Tone Madison</em>, a company representative explained that an employee’s post questioning the return-to-work plan had been removed from an internal discussion board “per request by upper management.” <a href="https://madison.com/ct/news/local/health-med-fit/epic-employees-say-coronavirus-concerns-met-with-retaliation-demotions/article_7a7ce63e-4e56-5b57-a7f4-8c4dba286094.html#tracking-source=home-top-story" target="_blank">Employees also told </a><a href="https://madison.com/ct/news/local/health-med-fit/epic-employees-say-coronavirus-concerns-met-with-retaliation-demotions/article_7a7ce63e-4e56-5b57-a7f4-8c4dba286094.html#tracking-source=home-top-story"><em>The Capital Times </em>this week</a> that on multiple occasions, managers who had expressed concern about the company’s COVID-19 plan faced demotions.&nbsp;</p><p>The company has taken precautions to enable physical distancing on the premises, installing the same airflow systems used in hospitals, and rearranging the main cafeteria to preclude the daily mass gatherings characteristic of pre-pandemic lunchtime at the software company. But Epic's coronavirus response diverges significantly from those of other tech companies, including Alphabet, Google’s parent company, <a href="https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201" target="_blank">which will not require workers to return to its Mountain View, California offices until July of next year</a>.&nbsp;</p><p>Before the sudden spate of labor coverage at Epic, the medical software company had mostly <a href="https://madison.com/wsj/news/local/govt-and-politics/epic-systems-draws-on-literature-greats-for-its-next-expansion/article_4d1cf67c-2abf-5cfd-8ce1-2da60ed84194.html" target="_blank">drawn attention for its themed campus</a>—an oversized playground paying homage to storybook figures like Alice in Wonderland, Humpty Dumpty, and Harry Potter.&nbsp;</p><p>But with COVID-19 spreading quickly <a href="https://www.dhs.wisconsin.gov/covid-19/local.htm" target="_blank">in 61 of Wisconsin’s 72 counties</a>, the pandemic highlights the contradiction between Epic’s friendly workplace aesthetic and its disregard for worker safety. </p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.tonemadison.com/articles/epic-workers-arent-just-mad-theyre-organizing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24068201</guid>
            <pubDate>Thu, 06 Aug 2020 04:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiler numbers, and why they don't matter]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24068180">thread link</a>) | @todsacerdoti
<br/>
August 5, 2020 | https://briancallahan.net/blog/20200806.html | <a href="https://web.archive.org/web/*/https://briancallahan.net/blog/20200806.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	<a name="top"></a>
	<div id="main">
	    
	    <p>academic, developer, with an eye towards a brighter techno-social life</p>
	    <hr>
		
	    <hr>
	</div>
<h5 id="prev"><a href="https://briancallahan.net/blog/20200803.html">[prev]</a></h5>
<h5 id="next"><a href="https://briancallahan.net/blog/20200808.html">[next]</a></h5>
    <h2 id="title">2020-08-06: Compiler numbers, and why they don't matter</h2>
<p><a href="https://www.openbsd.org/">OpenBSD</a> recently upgraded their in-base compiler from clang 8.0.1 to <a href="https://marc.info/?l=openbsd-cvs&amp;m=159646514207723&amp;w=2">clang 10.0.0</a>. Neat.</p>
<p>One of the things that make measuring binary sizes so difficult (and why, despite using it as a rough metric for <a href="https://github.com/ibara/snakeqr">SnakeQR</a>, I don't consider it a comparative metric) is that your compiler can do a lot behind the scenes that can cause binary sizes to differ. Fortunately for us, we no longer have to worry much about the size of our binaries. But let's compare things just for fun.</p>
We will compare clang 8.0.1 to clang 10.0.0. And because I have the compilers on this machine, let's add in gcc 4.2.1, gcc 8.3.0, gcc 11.0.0.20200723, <a href="http://pcc.ludd.ltu.se/">pcc 1.2.0 DEVEL 20200630</a>, and <a href="https://github.com/larmel/lacc">lacc 0.0.1</a>. That should give us a wide array of comparisons, though again this should not be considered scientific in any way.<sup id="inline-1"><a href="#footnote-1">1</a></sup> We will use total size in hex as our comparator.
<p>Let's start with crt.o.</p>
<table>
  <tbody><tr>
    <th>clang 10.0.0</th>
    <th>clang 8.0.1</th>
    <th>gcc 11.0.0.20200723</th>
    <th>gcc 8.3.0</th>
    <th>gcc 4.2.1</th>
    <th>pcc 1.2.0 DEVEL 20200630</th>
    <th>lacc 0.0.1</th>
  </tr>
  <tr>
    <td>3b</td>
    <td>3b</td>
    <td>3b</td>
    <td>3b</td>
    <td>3b</td>
    <td>3b</td>
    <td>N/A<sup id="inline-2"><a href="#footnote-2">2</a></sup></td>
  </tr>
</tbody></table>
<p>All the same. That's good. That means our assemblers are not doing anything fancy behind the scenes. There are four different assemblers being used here: clang 10.0.0 and clang 8.0.1 each have their own built-in assembler, gcc 11.0.0.20200723 and pcc are using GNU as 2.35.50.20200723, and gcc 8.3.0 and gcc 4.2.1 are using GNU as 2.17.</p>
<p>Now let's look at snakeqr.o.</p>
<table>
  <tbody><tr>
    <th>clang 10.0.0</th>
    <th>clang 8.0.1</th>
    <th>gcc 11.0.0.20200723</th>
    <th>gcc 8.3.0</th>
    <th>gcc 4.2.1</th>
    <th>pcc 1.2.0 DEVEL 20200630</th>
    <th>lacc 0.0.1</th>
  </tr>
  <tr>
    <td>15e2</td>
    <td>15d0</td>
    <td>16a1</td>
    <td>16dd</td>
    <td>178d</td>
    <td>1bd0</td>
    <td>2509</td>
  </tr>
</tbody></table>
<p>Interestingly, clang 8.0.1 generates a smaller object file than clang 10.0.0. Newer versions of gcc produce smaller object code than older versions. pcc is not too terribly behind. And lacc brings up the rear and is noticably worse at producing small object code than the other compilers.<sup id="inline-3"><a href="#footnote-3">3</a></sup>
</p><p>So what can we draw from this? Probably not much.</p>
<p>clang 10.0.0 is a superior compiler to clang 8.0.1 and brings in support for newer versions of C++ and that is more than worth the potential for larger binaries, which if we're being honest here the 18 byte increase is effectively noise. Newer compilers are able to generate better code, but that had better be true or else there would be little reason to be using a newer compiler. clang and especially gcc have had the benefit of decades of time and generations of programmers and corporations throwing money at them to create high-quality, production-ready compilers. That hardly seems revelatory.</p>
<p>pcc, which has been around since the 1970s, can still hold its own against clang and gcc when it comes to standard C code. That might actually be the big take-away here for me.</p>
<p>And lacc shows us that C is a language small enough and versatile enough that a single person can produce a compiler that honestly puts up respectable numbers against the bigger compilers. That's the other big take-away. If you've ever wanted to write your own C compiler, producing something that you can be proud of and can produce good enough code for modern machines is within the reach of a single person.<sup id="inline-4"><a href="#footnote-4">4</a></sup></p>
<p>These comparisons might be interesting to look at but remember not to put any stock in them. Very few of us live in a world where these binary sizes would make or break our systems. There is no "best" compiler and the endeavor to crown one is little more than a distraction. The best compiler is the one that compiles the code you want to run in a time you can live with. Don't be blinded by shiny numbers; you'll no longer be able to see what really matters.</p>

<p><a href="#top"><img alt="Top" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA4AAAAICAYAAADJEc7MAAAABmJLR0QA/wD/AP+gvaeTAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAB3RJTUUH4wkWDyUKJxzXegAAAB1pVFh0Q29tbWVudAAAAAAAQ3JlYXRlZCB3aXRoIEdJTVBkLmUHAAAAUklEQVQY02Ocd/j/fwY0kGjDwMhACPz//5/h////DPMO//8PYxODWXAZOP8Iw39k22F8uBg2G7Gx0cWYGMgEWJ2aaMPAiO5UDOcTGxjogUe2UwHwdJDZUucW5QAAAABJRU5ErkJggg=="></a></p>
<a href="https://briancallahan.net/blog/feed.xml"><img src="https://briancallahan.net/blog/media/pic_rss.gif"></a>
	<br>
	<hr>
	
    

</div>]]>
            </description>
            <link>https://briancallahan.net/blog/20200806.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24068180</guid>
            <pubDate>Thu, 06 Aug 2020 04:44:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node Modules at War: Why CommonJS and ES Modules Can’t Get Along]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 143 (<a href="https://news.ycombinator.com/item?id=24067748">thread link</a>) | @dfabulich
<br/>
August 5, 2020 | https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1 | <a href="https://web.archive.org/web/*/https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="4131">Interop between them is possible, but it’s a hassle</h2><div><div><div><p><a href="https://redfin.engineering/@danfabulich?source=post_page-----9617135eeca1----------------------" rel="noopener"><img alt="Dan Fabulich" src="https://miro.medium.com/fit/c/96/96/0*3NuQy3oh1ckOGP-9." width="48" height="48"></a></p></div></div></div><p id="38db"><em>Dan Fabulich is a Principal Engineer at Redfin. (</em><a href="https://www.redfin.com/about/jobs?utm_source=engblog" target="_blank" rel="noopener"><em>We’re hiring</em></a><em>!)</em></p><p id="65d7">In Node 14, there are now two kinds of scripts: there are old-style CommonJS (CJS) scripts and new-style ESM scripts (aka MJS). CJS scripts use <code>require()</code> and <code>module.exports</code>; ESM scripts use <code>import</code> and <code>export</code>.</p><p id="4684"><strong>ESM and CJS are completely different animals.</strong> Superficially, ESM looks very similar to CJS, but their implementations couldn’t be more different. One of them is a honey bee, and the other is a murder hornet.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3436/1*ljab8kLJtGC-o36VQ7vBZg.jpeg" width="1718" height="581" srcset="https://miro.medium.com/max/552/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 276w, https://miro.medium.com/max/1104/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 552w, https://miro.medium.com/max/1280/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 640w, https://miro.medium.com/max/1400/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ljab8kLJtGC-o36VQ7vBZg.jpeg?q=20"></p></div></div></div><figcaption>A hornet and a honey bee. One of these is like ESM and the other is like CJS, but I can never remember which one is which. Credit: <a href="https://en.wikipedia.org/wiki/File:Hornet-vespa.jpg" target="_blank" rel="noopener">wikimedia</a>, <a href="https://commons.wikimedia.org/wiki/File:Honey_bee_(Apis_mellifera).jpg" target="_blank" rel="noopener">wikimedia</a></figcaption></figure><p id="c5d2"><strong>Calling CJS from ESM and vice versa is possible, but it’s a hassle.</strong></p><p id="4a03">Here are the rules, which I’ll explain in more detail below:</p><ol><li id="0fb2">You can’t <code>require()</code> ESM scripts; you can only <code>import</code> ESM scripts, like this: <code>import {foo} from 'foo'</code></li><li id="e91d">CJS scripts can’t use static <code>import</code> statements like the one above.</li><li id="ad90">CJS scripts <em>can</em> use asynchronous dynamic <code>import()</code> to use ESM, but that's a hassle, compared to synchronous <code>require</code>.</li><li id="d3b7">ESM scripts <em>can</em> <code>import</code> CJS scripts, but only by using the “default import” syntax <code>import _ from 'lodash'</code>, not the “named import” syntax <code>import {shuffle} from 'lodash'</code>, which is a hassle if the CJS script uses named exports.</li><li id="a767">ESM scripts <em>can</em> <code>require()</code> CJS scripts, even with named exports, but it’s typically not worth the trouble, because it requires even more boilerplate, and, worst of all, bundlers like Webpack and Rollup don’t/won’t know how to work with ESM scripts that use <code>require()</code>.</li><li id="3a5c">CJS is the default; you have to opt-in to ESM mode. You can opt-in to ESM mode by renaming your script from <code>.js</code> to <code>.mjs</code>. Alternately, you can set <code>"type": "module"</code> in <code>package.json</code>, and then you can opt-out of ESM by renaming scripts from <code>.js</code> to <code>.cjs</code>. (You can even tweak just an individual subdirectory by putting a one-line <code>{"type": "module"}</code> <code>package.json</code> file in there.)</li></ol><p id="1641">These rules are <em>painful</em>. Worse, for many users, especially newbies to Node, these rules are <em>incomprehensible</em>. (Fear not, I’ll explain them all here in this article.)</p><p id="5fb5">Many observers of the Node ecosystem have speculated that these rules are due to a failure of leadership, or even hostility toward ESM. But, as we’ll see, all of these rules are here for a good reason, which will make it very difficult to break these rules in the future.</p><p id="1121">I’ll conclude with three guidelines for library authors to follow:</p><ul><li id="fc38">Provide a CJS version of your library</li><li id="6dae">Provide a thin ESM wrapper for your CJS</li><li id="4ca9">Add an <code>exports</code> map to your <code>package.json</code></li></ul><p id="7269"><strong>It’s all gonna be OK.</strong></p><p id="2f7d"><a href="https://www.reddit.com/r/node/comments/i4jwb7/node_modules_at_war_why_commonjs_and_es_modules/" target="_blank" rel="noopener">Discuss on Reddit</a><br><a href="https://news.ycombinator.com/item?id=24067748" target="_blank" rel="noopener">Discuss on Hacker News</a></p><p id="8d2e">Since the dawn of Node, Node modules were written as CommonJS modules. We use <code>require()</code> to import them. When implementing a module for other people to use, we can define <code>exports</code>, either “named exports” by setting <code>module.exports.foo = 'bar'</code> or a “default export” by setting <code>module.exports = 'baz'</code>.</p><p id="a362">Here’s a CJS example using <strong>named exports</strong>, where <code>util.cjs</code> has an export named <code>sum</code>.</p><pre><span id="36d6">// @filename: util.cjs<br>module.exports.sum = (x, y) =&gt; x + y;</span><span id="b41b">// @filename: main.cjs<br>const {sum} = require('./util.cjs');<br>console.log(sum(2, 4));</span></pre><p id="d017">Here’s a CJS example where <code>util.cjs</code> sets a <strong>default export</strong>. The default export has no name; modules using <code>require()</code> define their own name.</p><pre><span id="6577">// @filename: util.cjs<br>module.exports = (x, y) =&gt; x + y;</span><span id="eeec">// @filename: main.cjs<br>const whateverWeWant = require('./util.cjs');<br>console.log(whateverWeWant(2, 4));</span></pre><p id="b405">In ESM scripts, <code>import</code> and <code>export</code> are part of the language; like CJS, they have two different syntaxes for named exports and the default export.</p><p id="e73c">Here’s an ESM example with <strong>named exports</strong>, where <code>util.mjs</code> has an export named <code>sum</code>.</p><pre><span id="4112">// @filename: util.mjs<br>export const sum = (x, y) =&gt; x + y;</span><span id="3c49">// @filename: main.mjs<br>import {sum} from './util.mjs'<br>console.log(sum(2, 4));</span></pre><p id="d0ee">Here’s an ESM example where <code>util.mjs</code> sets a <strong>default export</strong>. Just like in CJS, the default export has no name, but the module using <code>import</code> defines its own name.</p><pre><span id="ab2d">// @filename: util.mjs<br>export default (x, y) =&gt; x + y;</span><span id="0916">// @filename: main.mjs<br>import whateverWeWant from './util.mjs'<br>console.log(whateverWeWant(2, 4));</span></pre><p id="bfb3"><strong>In CommonJS, </strong><code><strong>require()</strong></code><strong> is synchronous</strong>; it doesn't return a promise or call a callback. <code>require()</code> reads from the disk (or perhaps even from the network), and then immediately runs the script, which may itself do I/O or other side effects, and then returns whatever values were set on <code>module.exports</code>.</p><p id="5eb2"><strong>In ESM, the module loader runs in asynchronous phases.</strong> In the first phase, it parses the script to detect calls to <code>import</code> and <code>export</code> without running the imported script. In the parsing phase, the ESM loader can immediately detect a typo in named imports and throw an exception without ever actually running the dependency code.</p><p id="d291">The ESM module loader then asynchronously downloads and parses any scripts that you imported, and then scripts that your scripts imported, building out a “module graph” of dependencies, until eventually it finds a script that doesn’t import anything. Finally, that script is allowed to execute, and then scripts that depend on that are allowed to run, and so on.</p><p id="8815">All of the “sibling” scripts in the ES module graph download in parallel, but they execute in order, guaranteed by the loader specification.</p><p id="6f7b">ESM changes a bunch of stuff in JavaScript. ESM scripts use Strict Mode by default (<code>use strict</code>), their <code>this</code> doesn't refer to the global object, scoping works differently, etc.</p><p id="8a61">This is why, even in browsers, <code>&lt;script&gt;</code> tags are non-ESM by default; you have to add a <code>type="module"</code> attribute to opt into ESM mode.</p><p id="e76a">Switching the default from CJS to ESM would be a big break in backwards compatibility. (<a href="https://deno.land/" target="_blank" rel="noopener">Deno</a>, the hot new alternative to Node, makes ESM the default, but as a result, its ecosystem is starting from scratch.)</p><p id="03c6">The simplest reason that CJS can’t <code>require()</code> ESM is that ESM can do top-level <code>await</code>, but CJS scripts can't.</p><p id="a892"><a href="https://v8.dev/features/top-level-await" target="_blank" rel="noopener">Top-level </a><code><a href="https://v8.dev/features/top-level-await" target="_blank" rel="noopener">await</a></code> lets us use the <code>await</code> keyword outside of an <code><a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await" target="_blank" rel="noopener">async</a></code><a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await" target="_blank" rel="noopener"> function</a>, at the “top level.”</p><p id="1b27">ESM’s multi-phase loader makes it possible for ESM to implement top-level await without making it a “footgun.” Quoting from the <a href="https://v8.dev/features/top-level-await" target="_blank" rel="noopener">V8 team’s blog post</a>:</p><blockquote><p id="368f">Perhaps you have seen the <a href="https://gist.github.com/Rich-Harris/0b6f317657f5167663b493c722647221" target="_blank" rel="noopener">infamous gist</a> by <a href="https://twitter.com/Rich_Harris" target="_blank" rel="noopener">Rich Harris</a> which initially outlined a number of concerns about top-level <code>await</code> and urged the JavaScript language not to implement the feature. Some specific concerns were:</p><p id="d5f0">• Top-level <code>await</code> could block execution.<br>• Top-level <code>await</code> could block fetching resources.<br>• There would be no clear interop story for CommonJS modules.</p><p id="9ad3">The stage 3 version of the proposal directly addresses these issues:</p><p id="81b7">• As siblings are able to execute, there is no definitive blocking.<br>• Top-level <code>await</code> occurs during the execution phase of the module graph. At this point all resources have already been fetched and linked. There is no risk of blocking fetching resources.<br>• Top-level <code>await</code> is limited to [ESM] modules. There is explicitly no support for scripts or for CommonJS modules.</p></blockquote><p id="a0c0">(Rich now approves of the current top-level <code>await</code> implementation.)</p><p id="8cd5">Since CJS doesn’t support top-level <code>await</code>, it’s not even possible to <em>transpile</em> ESM top-level <code>await</code> into CJS. How would you rewrite this code in CJS?</p><pre><span id="1969">export const foo = await fetch('./data.json');</span></pre><p id="1c9b">It’s frustrating, because the vast majority of ESM scripts don’t use top-level <code>await</code>, but, as one commenter wrote in that thread, “I don’t think designing a system with the blanket assumption that some feature just won’t get used is a viable path.”</p><p id="445d"><a href="https://github.com/nodejs/modules/issues/454" target="_blank" rel="noopener">There’s an active debate on how to </a><code><a href="https://github.com/nodejs/modules/issues/454" target="_blank" rel="noopener">require()</a></code><a href="https://github.com/nodejs/modules/issues/454" target="_blank" rel="noopener"> ESM in this thread.</a> (Please read the whole thread and the linked discussions before commenting. If you dive in, you’ll find that top-level <code>await</code> isn’t even the only problematic case… what do you think happens if you synchronously <code>require</code> ESM which can asynchronously <code>import</code> some CJS which can synchronously <code>require</code> some ESM? What you get is a sync/async zebra stripe of <em>death</em>, that’s what! Top-level <code>await</code> is just the last nail in the coffin, and the easiest to explain.)</p><p id="d83f">Reviewing that conversation, it doesn’t look like we’re going to be able to <code>require()</code> ESM any time soon!</p><h2 id="3acf">CJS Can import() ESM, but It’s Not Great</h2><p id="b19b">For now, if you’re writing CJS and you want to <code>import</code> an ESM script, you’ll have to use asynchronous dynamic <code>import()</code>.</p><pre><span id="69f7">(async () =&gt; {<br>    const {foo} = await import('./foo.mjs');<br>})();</span></pre><p id="dcae">It’s… fine, I guess, as long as you don’t have any <code>exports</code>. If you do need to do some <code>exports</code>, you’ll have to export a Promise instead, which may be <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/" target="_blank" rel="noopener">a huge inconvenience to your users</a>:</p><pre><span id="ad31">module.exports.foo = (async () =&gt; {<br>    const {foo} = await import('./foo.mjs');<br>    return foo;<br>})();</span></pre><p id="94bc">You can do this:</p><pre><span id="6859">import _ from './lodash.cjs'</span></pre><p id="3b2c">But you can’t do this:</p><pre><span id="c06a">import {shuffle} from './lodash.cjs'</span></pre><p id="7e7b">That’s because CJS scripts compute their named exports as they <em>execute</em>, whereas ESM’s named exports must be computed during the <em>parsing</em> phase.</p><p id="2899">Fortunately for us, there’s a workaround! The workaround is annoying, but totally doable. We just have to import CJS scripts like this:</p><pre><span id="bccb">import _ from './lodash.cjs';<br>const {shuffle} = _;</span></pre><p id="7e2f">There are no real downsides to this, and ESM-aware CJS libraries can even provide their own ESM wrappers that encapsulate this boilerplate for us.</p><p id="7fd3">This is totally fine! I just… wish it were better.</p><h2 id="6069">Out-of-order execution would work, but it might be even worse</h2><p id="6455">A number of people have proposed executing CJS imports before ESM imports, out of order. That way, the CJS named exports could be computed at the same time as ESM named exports.</p><p id="ab6c">But that would <a href="https://github.com/nodejs/modules/issues/81#issuecomment-391348241" target="_blank" rel="noopener">create a new problem</a>.</p><pre><span id="34c8">import {liquor} from 'liquor';<br>import {beer} from 'beer';</span></pre><p id="69a1">If <code>liquor</code> and <code>beer</code> are both initially CJS, changing <code>liquor</code> from CJS to ESM would change the ordering from <code>liquor, beer</code> to <code>beer, liquor</code> , which would be nauseatingly problematic if <code>beer</code> relied on something from <code>liquor</code> being executed first.</p><p id="b454"><a href="https://github.com/nodejs/modules/issues/509" target="_blank" rel="noopener">Out-of-order execution is still under debate</a>, though the conversation seems to have mostly fizzled out a few weeks ago.</p><h2 id="59b5">Dynamic Modules could save us, but their star is poisoned</h2><p id="79d1">There’s an alternative proposal that doesn’t require out-of-order execution or wrapper scripts, called <a href="https://github.com/nodejs/dynamic-modules" target="_blank" rel="noopener">D…</a></p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1">https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1</a></em></p>]]>
            </description>
            <link>https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067748</guid>
            <pubDate>Thu, 06 Aug 2020 03:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is insurance more expensive in Black neighborhoods?]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24067408">thread link</a>) | @ddispaltro
<br/>
August 5, 2020 | https://www.goodcover.com/blog/is-insurance-more-expensive-in-black-neighborhoods/ | <a href="https://web.archive.org/web/*/https://www.goodcover.com/blog/is-insurance-more-expensive-in-black-neighborhoods/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>Black neighborhoods pay 20% more in renters insurance.</em></p><p>With the recent Black Lives Matter protests much of society has been re-examining explicit and implicit sources of discrimination against Blacks in America. What are the ways our society and economy has set up harmful policies towards Black citizens?</p><p>Housing and its associated cost has historically played a critical role in institutionalizing racism and segregation. Even insurance companies have historically discriminated against Blacks through processes like <a href="https://en.wikipedia.org/wiki/Redlining">redlining</a> where by they refused to write policies in certain neighborhoods, thus making housing more expensive or challenging to acquire.</p><p>As an insurance provider ourselves, we wanted to examine data to see how race impacts the price of insurance. We asked: is renters insurance more expensive if you live in a predominantly Black neighborhood than if you live in a predominantly white one?</p><p>We analyzed public data from the California Department of Insurance on how much companies charge for renters insurance in cities across the state. We also analyzed our own pricing for those locations.</p><p>We found the higher the percentage of Blacks living in a zip code or city, the higher the price of insurance on average. Across the industry renters insurance annual premiums were about 20% higher in predominantly Black neighborhoods than predominantly white ones. While we did not find such a correlation in our own prices, we recognize there is a lot of work left to do.</p><h3 id="the-data-and-methodology">The data and methodology</h3><p>Before diving into the results, it’s worth spending a moment on methodology. The <a href="http://www.insurance.ca.gov/">California Department of Insurance</a> requires all insurance companies operating in the state to publicly file the rates they would charge for a set coverage level in a given area. We analyzed this public data using defined coverage limits ($100k liability, $30k personal property, $500 deductible) for the top <a href="https://www.iii.org/table-archive/23446">10 most popular companies</a> in the state and analyzed how much they charged in different zip codes and cities for renters insurance. Using US census data, we’re able to calculate the percentage of the population in those areas that is Black, and see how that correlates with prices.</p><p>This analysis is focused on showing the difference in insurance prices for the same kind of housing that’s in a mostly Black neighborhood versus a mostly white one. Housing discrimination spans all races and ethnicities across our country, however for this research our primary focus is on Black communities in the state of California. </p><p>In this analysis we haven’t identified any causal factors; It’s meant more as a jumping off point for further analysis examining potential causal factors which can range from discriminatory practices based on the racial composition of a neighborhood (i.e. redlining), to other factors that impact pricing like proximity to a fire station.</p><p>So, there’s definitely more work to be done – but we thought it’s important to make a best effort with the messy data we have to start the discussion.</p><h3 id="cost-of-renters-insurance-in-california">Cost of renters insurance in California</h3><p>To begin, let’s look at the average price of renters insurance in California and how much it varies according to the percentage of the population in a zip code that is Black. For context, in California 5.9% of the population is Black, and across the state the average renters insurance policy costs $183 per year.</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/bar-chart.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/bar-chart.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/bar-chart.png 1000w, https://goodcover.ghost.io/content/images/2020/08/bar-chart.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>As shown above, companies charge more for renters insurance in zip codes where there’s a higher percentage of Black residents. If your zip code has more than 20% Black population, the expected annual price for renters insurance would be $210, which is around 20% more expensive than in zip codes where less than one percent of the population is Black.</p><p>Next, let’s turn our attention to the average price of renters insurance across various cities in California and how it varies by the percentage of residents who are Black. The chart below ranks cities in California from most to least expensive annual policies and also shows the percentage of Black residents in that city. (One column represents the average price for the top 10 insurance providers, and next column are average Goodcover prices for those cities. Only cities with over 100k residents where the CA Department of Insurance publishes rates are included.)</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/table.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/table.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/table.png 1000w, https://goodcover.ghost.io/content/images/2020/08/table.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Across California, renters insurance is most expensive in Berkeley, followed by Oakland and Los Angeles. Each of the top five cities with most expensive renters insurance policies in California have a substantially higher percentage of Black residents than the state average of 5.9%.</p><p>Is there any correlation between the percentage of Black residents in a city and companies charging more for renters insurance?</p><p>Let’s see, the following chart plots renters insurance prices versus percent of population that is Black from the same list of cities as above.</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/scatterplot-wm-1.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/scatterplot-wm-1.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/scatterplot-wm-1.png 1000w, https://goodcover.ghost.io/content/images/2020/08/scatterplot-wm-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>The chart above shows some correlation between higher prices for renters insurance and the percentage of Blacks living in the city. Virtually every city with a higher rate of Black residents have insurance policies that cost more than the state average.</p><h3 id="examining-our-own-rates">Examining our own rates</h3><p>Our analysis would not be complete if we didn’t also specifically analyze our own rates in the same way. So we looked at how Goodcover would rate for the same policy and location compared to the top 10 insurance companies in the state using the government pricing data. We found a far lower correlation as shown below.</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/scatterplot-with-gc-wm-1.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/scatterplot-with-gc-wm-1.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/scatterplot-with-gc-wm-1.png 1000w, https://goodcover.ghost.io/content/images/2020/08/scatterplot-with-gc-wm-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Furthermore, doing the same population segment analysis as earlier, our average annual pricing was $91, $91, $94, $92, for zip codes with percentage of Black population of &lt;1%, 1-5%, 5-20%, and 20%+ respectively – a different trend than the increase of price seen for the top 10 companies which resulted in a 20% higher price for areas with the largest Black population. </p><p>Goodcover’s rates were computed and filed with the State of California in 2019, so we were able to evaluate risk as we see it now, rather than inheriting old rating structures and any potential biases. This modern structure has also allowed us to offer significantly better pricing making financial security more accessible and affordable for more people. </p><p>We’re not sure of the causal factors that make renters insurance more expensive for Black neighborhoods. All we can be sure of is that in our own analysis of risk and causal factors of loss we don’t have an answer for why this correlation would exist.</p><h3 id="closing-thoughts">Closing thoughts</h3><p>In this analysis, we have shown that there’s a wide variation in how much renters insurance costs across California and that prices tend to be significantly higher in predominantly Black neighborhoods.</p><p>However we’ve also shown that from our own analysis of risk, which resulted in Goodcover’s rating, there is no readily evident reason why this correlation exists. Further study is warranted to understand why this is so.</p><p>At Goodcover, we believe it is our responsibility both as a company and as an industry to understand and address our systemic biases. This begins internally – Goodcover is committed to diversity, equity and inclusion in our hiring practices, service and pricing. And then there’s more to be done in our industry – we must further examine rating for bias, increase use of digital servicing to remove biases such as <a href="https://journals.sagepub.com/doi/10.1177/1078087405281064">linguistic profiling</a>, reduce or eliminate installment fees that penalize policyholders living paycheck to paycheck, and simply lower the cost of renters insurance to make it more accessible for the 56% of Californians who still don’t have it.</p><p>Eliminating pricing disparities because of the composition of a community is attainable, and a right. Our industry needs to keep vigilant in rexaming our processes so we banish discrimination from the ways we serve our policyholders and the public.</p></div></div></div>]]>
            </description>
            <link>https://www.goodcover.com/blog/is-insurance-more-expensive-in-black-neighborhoods/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067408</guid>
            <pubDate>Thu, 06 Aug 2020 01:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$250k books sold, to save lives]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24067365">thread link</a>) | @gregalbritton
<br/>
August 5, 2020 | https://sive.rs/250k | <a href="https://web.archive.org/web/*/https://sive.rs/250k">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2020-08-06</small>
</header>

<p>
	Six weeks ago I emailed my <a href="https://sive.rs/list">private email list</a> with a secret link to buy my new books.
</p><p>
	They’re not even officially released yet, but they’ve already sold over $250,000.
</p><p>
	I made 5000 limited edition hardcover copies of each, but those have sold out now.
</p><p>
<strong>
	I’ll admit, it made me ridiculously happy to make $250,000.
</strong>
	I was expecting way less than that, so it was a big surprise.
	I had a spring in my step for days.
</p><p>
	Then I thought about what to do with the money.
	There’s nothing I want to buy.
	Should I put it in an investment account?
	Eh.
	For what purpose?
	I <a href="https://sive.rs/full">don’t want more money</a>.
</p><p>
	So, I decided to donate it to charity.
	Which charity?
	I want to save the most lives.
	So I let <a href="https://www.givewell.org/">GiveWell</a> decide.
</p><p>
<strong>
	Yesterday I wired the entire $250,000 to the <a href="https://www.againstmalaria.com/">Against Malaria Foundation</a>.
</strong>
	That will buy 125,000 malaria nets, protecting ~225,000 people, averting ~65,000 cases of malaria, preventing ~125 deaths.
</p><p>
	Yeah.
	That’s <a href="https://sive.rs/n">worth doing</a>.
</p><p>
	Afterwards, a friend reminded me that I had just repeated my “<a href="https://sive.rs/232">232 sand dollars</a>” story, so <a href="https://sive.rs/232">go read that</a> if interested.
</p><p>
	You can buy the books now, directly from me.
	They won’t be available anywhere else for a couple more months.
</p>
<ul><li>
	“<strong><a href="https://sive.rs/m">Your Music and People</a></strong>” is a philosophy of getting your work to the world by being creative, considerate, resourceful, and connected.
</li><li>
	“<strong><a href="https://sive.rs/n">Hell Yeah or No</a></strong>” is a collection of thoughts around what’s worth doing, fixing faulty thinking, and making things happen.
</li></ul>
<img src="https://sive.rs/images/DerekSivers-cover-YourMusicAndPeople-400x492.png" alt="Your Music and People">
<br>
<img src="https://sive.rs/images/DerekSivers-cover-HellYeahOrNo-400x492.png" alt="Hell Yeah or No">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/250k</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067365</guid>
            <pubDate>Thu, 06 Aug 2020 01:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Not Trust Google]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24067162">thread link</a>) | @DlSGUSTING
<br/>
August 5, 2020 | https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google | <a href="https://web.archive.org/web/*/https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main><div><article><div><p>Posted by <!-- -->Luke Boyle<!-- --> on the<!-- --> <time datetime="Sat Aug 01 2020 00:00:00 GMT+0000 (Coordinated Universal Time)">1st of August, 2020</time></p><p><img src="https://lukeboyle.com/static/google-fasc-6d23fd163ac10360abb4467ecdb9645a.jpg" alt="" data-identifier="google-fasc"></p><p>I realise that this is one of the most well-explored topics on the privacy-conscious edges of the internet, but seriously... Do not trust Google. Facebook seems to be our current punching bag of choice because of their supposed ability to manipulate political opinion, but in my opinion Google is a much more insidious company with far greater potential for abuse. Google is the <a href="https://www.investopedia.com/news/facebook-google-digital-ad-market-share-drops-amazon-climbs/" target="_blank" rel="noreferrer noopener">largest advertising platform</a> by a significant margin (accounting for 36.3% of advertising in the U.S. with Facebook trailing at 19.3%). At the end of the day, if you delete your Facebook account, what are you really missing out on?</p><p>Google (or more specifically Alphabet Inc.) owns the largest search engine (Google.com), the largest video streaming platform (Youtube), and the most-used smartphone operating system (Android). You might ask, "What's wrong with that? Sounds like they're just very successful at what they do". Well, let's break down those three markets (Search, Streaming, Mobile).</p><p><img src="https://lukeboyle.com/static/do-be-evil-6ba993531a7046106f481b038b7ed98b.jpg" alt="The classic Google slogan &quot;Don't be evil&quot;, except the end of the &quot;don't&quot; is crossed out so it says &quot;Do be evil&quot;" data-identifier="do-be-evil"></p><h2>Search</h2><p>Google's estimated market share for search traffic globally is 92.16% <a href="https://gs.statcounter.com/search-engine-market-share" target="_blank" rel="noreferrer noopener">source</a>. As people increasingly are using search to navigate the web (as opposed to typing a URL into the address bar), this traffic increases, those people see more ads, Google makes more money. Google then uses this money to purchase exclusivity agreements with the likes of Apple (just two years ago it was announce that Google would be paying $12 billion US to Apple to remain the default search engine on Safari in 2019 <a href="https://fortune.com/2018/09/29/google-apple-safari-search-engine/" target="_blank" rel="noreferrer noopener">source</a> at a cost of roughly $10 per user).</p><h3>How does Google abuse Search?</h3><p>If you ask the average user how Google search works, they'd probably say "it just searches for your search term across the web", but what they probably don't know is that is just the tip of the iceberg. Other dimensions of search include:</p><ul><li>what kind of users go to that websites (and does the user searching fit that profile)?</li><li>how much traffic does the website get?</li><li>how relevant the content is to the search term (SEO magic)?</li><li>and, most importantly, does this website fit an acceptable narrative?</li></ul><p>There's certainly an argument to be made for suppressing some search results, such as pro-authoritarian sites (e.g. communist or fascist), extremely fringe conspiracy, illegal pornography, or bomb-making instructions. Advertisers probably don't want their ads next to those results. Rightly or wrongly, Google is already suppressing content from such websites (though, they're probably still indexing them).</p><p>If Google can suppress fascist content from sites like Stormfront (prominent white-supremacy forum), then who is to say which content they can or cannot suppress? Breitbart is a well-known right wing news site that has had their content <a href="https://www.breitbart.com/tech/2020/07/28/election-interference-google-purges-breitbart-from-search-results/" target="_blank" rel="noreferrer noopener">almost entirely purged</a> from Google search results (as evidenced by the "search engine visibility" chart below).</p><p><img src="https://lukeboyle.com/static/breitbart-visibility-index-7479c89645b960fee2d841dfa4f1574d.jpg" alt="Search engine visibility index for Breitbart.com shows significant increase in visibility leading up to the 2016 presidential election with a sharp drop in mid 2017" data-identifier="breitbart-visibility-index"></p><p>You don't have to agree with them politically to see that Google is applying different standards to conservative content than to more liberal content. I don't visit Breitbart, I don't read their articles, and frankly I don't give a shit what they have to say, but I believe in a free and open internet. If you believe in a free and open internet then you have to agree this is wrong. During the cold war, anyone who didn't follow the extreme protectionist beliefs of the time <a href="https://www.history.com/topics/cold-war/red-scare" target="_blank" rel="noreferrer noopener">were shouted down as communists</a> (Even Martin Luther King Jr. was dismissed as a communist by J. Edgar Hoover). This same thing is happening now, but the buzz word is different. The new weaponised word is "Nazi". If time had elapsed differently, I have no doubt that it would be left-wing websites suppressed in search results, and that still wouldn't be okay.</p><p>There's plenty of evidence to suggest that Google is manually making these decisions to block conservative websites, however, Alphabet CEO Sundar Pichai denied that they manually censor websites at the recent <a href="https://www.theguardian.com/technology/2020/jul/29/tech-hearings-facebook-mark-zuckerberg-amazon-jeff-bezos-apple-tim-cook-google-sundar-pichai-congress" target="_blank" rel="noreferrer noopener">Congressional antitrust hearing</a> except for in cases where there are legal requirements or copyright issues. I don't buy that, personally.</p><h2>Streaming</h2><p>When YouTube was founded it was facing severe scaling problems (because video processing and streaming is extremely expensive). Fortunately for them, Google saw potential in the platform and purchased the company for $1.65bn in Google stock, and their money issues were over. Google was throwing money into scaling the platform, and it was experiencing great growth. This success turned out to be a major problem for the YouTube, because, from the time it was purchased it has been making a loss. In recent years, YouTube has become profitable, however, without the bottomless pockets of Google behind it, they never would have been able to accomplish this. What incentive could Google have to take losses year after year on YouTube? Well, it turns out user data is particularly delicious. Mastercard's CEO has infamously said <a href="https://www.cnbc.com/2017/10/24/mastercard-boss-just-said-data-is-the-new-oil.html" target="_blank" rel="noreferrer noopener">"data is the new oil"</a>. I personally can't wait for Facebook, Amazon, and Google to become para-military organisations in the up-coming data wars.</p><p>YouTube has essentially bullied their way into market dominance using Google's bottomless pit of money. This is problematic because it allows failing companies to cheat death. Just like a bottom-feeding fish,latching onto a whale shark and hitching a ride. As I mentioned before, video streaming is extremely expensive, so it makes sense that great cloud infrastructure is a prerequisite to success. Well, big surprise, Google offers world-class commercial cloud infrastructure with Google Cloud Platform (GCP)! Do you suppose YouTube is paying full price for their infra?</p><p><img src="https://lukeboyle.com/static/google-shark-ad4f1bd39e618a72413dc9456fb01ebc.jpg" alt="A whale shark with small fish adhered to the top of it. YouTube, Google Play, and Google Plus logos are superimposed on the small fish heads" data-identifier="google-shark"></p><p>So, when you see a headline that says "<a href="https://bgr.com/2020/07/30/google-one-free-phone-backup-ios-android/" target="_blank" rel="noreferrer noopener">Stop paying for iCloud – Google One will now back up your iPhone for free</a>". Before obeying the shill who wrote it, you should ask yourself, "How can a company afford to give away so much storage space for free?". Well, they can't. Google simply obscures their losses with the immense revenue from Google Ads in the profit/loss statement at the end of each quarter. For more reading about this topic, Tim Bray has a fantastic article called <a href="https://www.tbray.org/ongoing/When/202x/2020/06/25/Break-Up-Google" target="_blank" rel="noreferrer noopener">"Break up Google"</a>.</p><h2>Mobile</h2><p>This article is already becoming too long, so I'm just going to cover mobile quickly. As Tim Bray mentions in the article above, Android isn't really a business. The only real non-ad revenue they have is from the commission they get from app purchases and licensing fees from OEMs (e.g. Samsung, Huawei, LG). How, then, are they able to sustain hundreds of highly paid engineers and all the other non-technical staff required to support the system?</p><p><img src="https://lukeboyle.com/static/android-ios-market-share-aa0b256bae300e426ecb38c8ef842165.jpg" alt="A map of the world with Android vs iOS market share. iOS is most dominant in first-world countries, whereas Android dominates emerging nations" data-identifier="android-ios-market-share"></p><p>Above is a map of Android vs iOS market shares. You can see that iOS pretty much only has the dominant market share in first world countries (like USA, Canada, Australia, UK, Japan). Most of the emerging countries in the world are strongly in favour of Android because, unlike Apple, the OS is not restricted to a particular device. So, countries like India (where the number of smart-phone users has increased sharply from 199 million in 2015 to 401 million in 2020 <a href="https://www.statista.com/statistics/467163/forecast-of-smartphone-users-in-india/" target="_blank" rel="noreferrer noopener">source</a>) that mostly purchase low-cost phones (e.g. Huawei, Xiaomi, Oppo). Emerging markets are extremely important to companies like Google partly because these countries are easier to exploit because they don't have strong legislation to protect users from predatory advertising, anticompetitive tactics, or data privacy. This is why I speculate that Mastercard is scrambling to <a href="https://www.forbes.com/sites/tomgroenfeldt/2020/05/06/financial-inclusion-helps-refugees-move-from-aid-recipients-to-earners-and-tax-payers" target="_blank" rel="noreferrer noopener">connect refugees to the global payment network</a> (Remember that quote from the Mastercard CEO: "Data is the new oil") and, indeed, why Mastercard <a href="https://www.jihadwatch.org/2018/08/patreon-and-mastercard-ban-robert-spencer-without-explanation" target="_blank" rel="noreferrer noopener">forced Patreon to ban Robert Spencer for his anti-refugee sentiment</a>.</p><p>Again, regardless of whether you agree with someone's political leaning or rhetoric, I shouldn't have to explain why it's ludicrous for people to believe that faceless, soulless corporations such as MasterCard or Google give two fucks about moral righteousness when their only servant is a number ticker on the Nasdaq website.</p><h2>Closing thoughts</h2><p>So, after reading all of that, I have to ask:</p><p>Why don't you route all of your web traffic through Google Servers?</p><p><img src="data:image/jpeg;base64,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" alt="Google DNS logo" data-identifier="google-dns"></p><p>To be clear, I'm not accusing Google of storing DNS logs or associating that with specific users (they claim that they don't in their terms of service), however, I think it's unreasonable to think that they wouldn't be capable of that. I also wouldn't put it past them to lie in terms of service considering their recent run-ins with the law (<a href="https://www.cbsnews.com/news/google-eu-fines-google-1-7-billion-for-blocking-advertising-rivals/" target="_blank" rel="noreferrer noopener">$1.7bn fine for anti-competitive behaviour</a>, <a href="https://www.nytimes.com/2019/09/04/technology/google-youtube-fine-ftc.html" target="_blank" rel="noreferrer noopener">$170m for violating children's privacy on YouTube</a>, <a href="https://www.theverge.com/2019/1/21/18191591/google-gdpr-fine-50-million-euros-data-consent-cnil" target="_blank" rel="noreferrer noopener">50 million euro fine for GDPR violations</a>).</p><p>$2bn doesn't matter to Google. It's a drop in the bucket, especially considering they would probably be able to freely harvest user data for months or even years before they're caught and slapped on the wrist. If a single user's search data is worth upwards of $10 a year (see the Safari Google default search engine deal) for Google, then the complete logs of their browsing history would be quite juicy indeed.</p><p>Okay, so that's verging on conspiracy theory I suppose. Maybe Google DNS will remain clean. How about you get a Google® Nest™ WiFi mesh router and let them inspect all of your web traffic that way?</p><p><img src="https://lukeboyle.com/static/nest-c6cc34d5b4043b24d7c12a3223cc9ae4.jpg" alt="Google Nest Wifi Router product photo" data-identifier="nest"></p><p>Or perhaps you want to buy the new Pixel and give them advanced analytics about how you use your phone (<a href="https://www.searchenginejournal.com/google-privacy-lawsuit-android-apps/374952/" target="_blank" rel="noreferrer noopener">privacy class action lawsuit</a>), everywhere you go (Location History), how much physical activity you do (Google Fit), every article/video you engage with (Chrome), everything you buy (Google Pay - and incidentally, how much disposable income you have, so they can better target more relevant ads to you). All of these "services" are simply a ruse so that Google can build an extremely accurate profile about the type of consumer you are and target you with more advertising to turn you into a soulless consumer.</p><p>I don't want these people to also be the arbiters of what content I should or should not be able to see online.</p><h2>Actual closing thoughts</h2><p>Well that was pretty depressing. So, how can you reclaim a shred of your privacy?</p><h3>Search</h3><p>There's a swathe of …</p></div></article></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google">https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google</a></em></p>]]>
            </description>
            <link>https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067162</guid>
            <pubDate>Thu, 06 Aug 2020 00:49:46 GMT</pubDate>
        </item>
    </channel>
</rss>
