<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 08 Jul 2020 16:16:30 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 08 Jul 2020 16:16:30 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: I built a desktop radiation monitor with Raspberry Pi, brass and wood]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23756964">thread link</a>) | @chrisys
<br/>
July 7, 2020 | https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/ | <a href="https://web.archive.org/web/*/https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <p>I was always a fan of the steampunk style, and having also had experience building steam engines in the past, there was only one real direction this project could go. Once I had my radiation detector kit hooked up to my Raspberry Pi running InfluxDB and Grafana, I found myself woodworking, machining, and fabricobbling an enclosure out of mahogany, brass, copper, toggle switches and, because it just had to be done, nixie tubes.</p>

<p>Read the story of the almost year-long journey (<em>cough</em> some other stuff cropped up…) I went on to make my steampunk vision a reality below, and if you want to get up and running quickly, find out how to <a href="https://www.balena.io/blog/build-a-simple-radiation-monitor-using-a-raspberry-pi-influxdb-and-grafana/">build your own simple version right here</a>!</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/geiger-main.jpg" onclick="openModal();currentSlide(56)">  
</p>

<iframe width="100%" height="500" src="https://www.youtube.com/embed/lEL_XkN69n8" frameborder="0" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<hr>

<h2 id="contents">Contents</h2>

<ul>
<li><a href="#intro">Introduction</a></li>
<li><a href="#inspiration">Inspiration &amp; Design</a></li>
<li><a href="#build">The build</a>
<ul><li><a href="#panel">The front panel</a></li>
<li><a href="#wood">Working with wood</a></li>
<li><a href="#brass">Top brass</a></li>
<li><a href="#dekatrons">Imitation Dekatrons</a></li>
<li><a href="#fasteners">Fussy about fasteners</a></li>
<li><a href="#pi">Plumbing in a Pi project</a></li>
<li><a href="#nixie">Nixie tubes</a></li>
<li><a href="#counter">Electrifying a mechanical counter</a></li>
<li><a href="#electronics">Electronics</a></li>
<li><a href="#geiger">Relocating the Geiger tube</a></li></ul></li>
<li><a href="#final">Final assembly</a></li>
<li><a href="#software">Programming and software</a></li>
<li><a href="#end">You have come to the end of your journey</a></li>
</ul>

<hr>

<h2 id="introductionspanidintrospan">Introduction <span id="intro"></span></h2>

<p>Low cost radiation monitors and Geiger counter kits have been available online for around $30-50US/£25-45 for a while, but standing alone they don’t do much other than make the recognizable “clicking” sound we all know from movies and TV. I decided to up the ante by connecting one to a Raspberry Pi, storing the data with InfluxDB, and showing the readings with a Grafana dashboard.</p>



<p>I updated the tech, gave it a web interface, added remote management, and built a custom mahogany housing with brass and copper fittings to show everything off, because it’s important to look suitably <em>hip</em> when sitting on the desk next to your <a href="https://www.balena.io/blog/build-a-raspberry-pi-powered-train-station-oled-sign-for-your-desk/">train sign</a>… right?</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/header.jpg" onclick="openModal();currentSlide(58)">  
</p>

<p>Anyway, I’m gonna show what I built to hopefully provide some inspiration, then show you how to get up and running with a simpler version of the project that anyone can build at home without any special tools. Let’s hit this.</p>

<hr>

<h2 id="inspirationdesignspanidinspirationspan">Inspiration &amp; design <span id="inspiration"></span></h2>

<p>I’ve always found the idea of radiation fascinating; how there are invisible particles moving around at incredibly high speeds, crashing into things and flipping bits all around us. Due to my fascination, it doesn’t take a lot to capture my interest when it comes to this field.</p>

<p>One day last year I was reminiscing over the <a href="https://www.bbc.co.uk/news/business-44606771">now defunct</a> UK-based electronics retailer Maplin, and how they sold all sorts of interesting kits for the aspiring engineer. This led me to <a href="https://www.richardmudhar.com/blog/2019/09/maplin-geiger-counter/">Richard Mudhar’s blog</a> where he tells the story of the <em>Maplin Geiger Counter</em>.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/mudhar-example.png" alt="An excerpt and image from Richard Mudhar's post"></p>

<figure>  
The original Maplin Geiger Counter. Perhaps some of the design cues are visible here?! (Credit: <a href="https://www.richardmudhar.com/blog/2019/09/maplin-geiger-counter/">Richard Mudhar</a>)  
</figure>

<p>The kit that Richard has built above features both an electromechanical counter on the left, and two rings of LEDs reminiscent of <a href="https://en.wikipedia.org/wiki/Dekatron">dekatron tubes</a> on the right. This display has the neat design feature that as the rate of count increases, the display becomes more noticeable.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/dekatron.gif" alt=""></p>

<figure>  
The spinning light effect of the Dekatron is something I wanted to replicate. By Hellbus - Own work, CC BY-SA 3.0, <a href="https://commons.wikimedia.org/w/index.php?curid=4741470">https://commons.wikimedia.org/w/index.php?curid=4741470</a>.  
</figure>

<p>I liked the idea of combining the modern technology on the inside (Raspberry Pi, Grafana, etc.) with the timeless look of brass, copper, toggle switches, dark hardwood, and glass on the outside. The idea was now to build something that looked old and had that distinctive steampunk style, but was up to date and Internet-connected.</p>

<p>In addition to the total absolute count like the old Maplin counter, I wanted to offer a live display of the counts per minute (CPM) reading, and what better way to do this than with <a href="https://en.wikipedia.org/wiki/Nixie_tube">Nixie tubes</a>, to get that nice warm orange glow and keep things looking cosy.</p>

<p>I started scribbling down ideas and thoughts of materials I wanted to use alongside shopping lists for parts, and possible designs for the case.</p>

<p><img src="https://www.balena.io/blog/content/images/2020/07/notes.jpg" alt="Original shop notes!"></p>

<figure>  
Notes don’t survive well in a machine shop, but these are what’s left of my original sketches.  
</figure>

<p>This process was very much led by an image I had in my mind about how the thing should look and feel and so I just had to make it real… somehow.</p>

<hr>

<h2 id="thebuildspanidbuildspan">The build <span id="build"></span></h2>

<p>With some thoughts and ideas scribbled down it was time to get started. As this is for the most part going to be a bespoke, hand-built item, and made up as I go along, it’s not necessary to put everything in CAD. There are of course some core items that exist already and cannot change size; the Raspberry Pi and radiation detector board, for example. These are off-the-shelf parts that have to fit in the box no matter what, and start to dictate the size of the final unit.</p>

<p>Almost all other parts are completely hand made, machined and fabricated. This was necessitated by the desire to make everything authentic; I didn’t want to build things just for looks, I wanted any design choices made for aesthetic reasons to also be functional; by this I mean when I put 18 screws in something to make it look good, they are going to be 18 <em>real</em> screws that you have to take out to gain access!</p>

<p><strong>NOTE:</strong> Each of the build log images link to a separate gallery when clicked. You can look through the images that way if you prefer, or read on in full detail.</p>

<h3 id="thefrontpanelspanidpanelspan">The front panel <span id="panel"></span></h3>

<p>I started with the front panel of the housing, I knew I wanted two toggle switches; one for power and one for sound (to disable the clicking noise), along with 3 nixie tubes to display the CPM up to 999. Normal background radiation is in the range of about 25-75 CPM, so I figured if background radiation is above 999 CPM, we have bigger problems than worrying about enough digits on the counter.</p>



<p>The two front panel pieces are made from 6mm thick mild steel plate, cut to size with an angle grinder and then milled to dimension with the help of Bridget, the Bridgeport. Holes are then cut for the nixies and the toggle switches.</p>



<p>I manufactured labels for each by hand-punching lettering into 0.5mm thick brass sheet, polishing and fixing with M2 screws. The steel pieces are coated with a clear lacquer to prevent corrosion.</p>

<h3 id="workingwithwoodspanidwoodspan">Working with wood <span id="wood"></span></h3>

<p>Wood isn’t my favourite material to work with, I mean it just changes shape of its own accord! Who can work with that?! Anyhow, it’s very pretty, and so it was decided that the outer box should be made of hardwood. I started with a scrap piece of mahogany, cut it to halve the thickness on the bandsaw, and then set about planing and shaping the sides of the box to fit the dimensions of the Raspberry Pi (3A+) and the radiation detector.</p>



<p>The dimensions of the front panel along with the steel faceplates were planned out in Fusion 360 so that I could print a cutting and drilling template. This was taped onto the planed piece of mahogany, the holes for screws were drilled, and the openings for components cut out.</p>



<p>The pieces were cut at 45 degree angles to enable a mitre joint in each corner. The joints were reinforced with biscuits (mmm biscuits), and then the 4 sides were glued and clamped and allowed to cure overnight.</p>



<p>The top and bottom of the case are made from the same scrap mahogany, but planed a lot thinner - approximately 6mm, the same as the steel plate.</p>

<h3 id="topbrassspanidbrassspan">Top brass <span id="brass"></span></h3>

<p>I had the idea that it would look good to hold the box together with a totally unnecessary amount of screws, 36 to be exact; 18 on top and 18 on the bottom. To prevent the screws damaging the wood surface and to add some extra detail to the top of the case I decided to make a brass plate that the screws all go through to clamp the top cover down.</p>



<p>Some pieces of 2mm brass strip were cut, mitred on the corners and soldered together. Once soldered, sanded and polished, the joints are barely visible.</p>



<p>Holes for screws were then drilled, and the brass plate used to secure the oversize lid to the box whilst it was sanded to size on a drum sander. I later learned that using a drum sander for this was a mistake as it marked the sides of the box, but you live and learn!</p>

<div>  
    <p><img src="https://www.balena.io/blog/content/images/2020/07/top-brass-7.jpg" onclick="openModal();currentSlide(22)"></p><figure>  
Finished case and lid woodwork with brass frame temporarily fitted  
</figure>

</div>

<h3 id="imitationdekatronsspaniddekatronsspan">Imitation Dekatrons <span id="dekatrons"></span></h3>

<p>My attempt at imitating the Dekatron tube effect starts with a piece of 50mm stainless steel (or aluminium) bar. The bar is turned on a lathe down to 40mm, and to have a cavity for the electronics. The work is removed from the lathe and parted off on a bandsaw before being returned to the lathe to have a hole drilled in the rear for cabling to drive the LEDs.</p>



<p>The part is then put on the milling machine to have 10 holes drilled and M2 <del>taps snapped off in the holes</del> threaded ready to fasten the faceplate.</p>



<p>The brass faceplate is made from the same 0.5mm thick brass sheet as the labels from the faceplates. Each piece is drilled with 20 holes (10 for LEDs, 10 for fasteners), and then hand stamped with the numbering for each LED.</p>

<div>  
    <p><img src="https://www.balena.io/blog/content/images/2020/07/dekatrons-7.jpg" onclick="openModal();currentSlide(29)"></p><figure>  
The wired LED faceplate ready to be screwed into the housing.  
</figure>  
</div>

<p>The LEDs are wired with a common ground and connected using a piece of recycled floppy disk drive ribbon cable. All the work is then carried out a second time for the ‘X10’ display. The eagle-eyed readers will notice that the second display is made from a different material than the first - this is due to the fact I snapped both a drill bit and a tap off in the M2 holes - working with stainless steel with these small tools is very difficult! I ended up making the second from aluminium, which machines like butter, in comparison.</p>



<p>Throughout the development of this project I found myself continually swapping fasteners and trying different combinations to see what looks best. The end result is a mix of M2 and M3 metric machine screws in both brass and stainless steel, cheese head and countersunk head, all slotted. You may notice that in earlier photos some of the parts were assembled with Allen-head cap screws but these were later swapped out. Ebay is usually a great place to get small quantities of fasteners of all different shapes and sizes.</p>

<div>  
    <p><img src="https://www.balena.io/blog/content/images/2020/07/screws.jpg" onclick="openModal();currentSlide(30)"></p><figure>  
A mix of fastener types used for this project - various M3 and M2 machine screws.  
</figure>  
</div>

<p>The wood screws used for the top and …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/">https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/</a></em></p>]]>
            </description>
            <link>https://www.balena.io/blog/show-tell-a-steampunk-desktop-background-radiation-monitor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23756964</guid>
            <pubDate>Tue, 07 Jul 2020 08:33:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google offers free fabbing for 130nm open-source chips]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 104 (<a href="https://news.ycombinator.com/item?id=23755693">thread link</a>) | @tomcam
<br/>
July 6, 2020 | https://fossi-foundation.org/2020/06/30/skywater-pdk | <a href="https://web.archive.org/web/*/https://fossi-foundation.org/2020/06/30/skywater-pdk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Did you ever dream about creating your own chip?
I mean, a physical chip.
One which you can hold in your hand, and which does exactly what you’ve designed it to do?</p>

<p>Until today, there were two major road blocks: you had to get access to a process design kit (PDK) from a chip manufacturing house (a foundry), and you had to have enough money to actually pay for the manufacturing.
These times are over.
Today.</p>

<p>Today, in a FOSSi Dial-Up talk, Tim Ansell of Google announced <a href="https://github.com/google/skywater-pdk">SkyWater PDK</a>, the first manufacturable, open source <a href="https://en.wikipedia.org/wiki/Process_design_kit">process design kit</a>.
What differentiates this PDK from previous attempts is the fact that it is manufacturable: with this PDK, you can actually produce chips with the <a href="https://www.skywatertechnology.com/">SkyWater foundry</a> in the 130nm node.</p>

<p>That leaves you as chip designer only with one road block: money.
Manufacturing chips is expensive – even for more than a decade old nodes like the 130nm node, you need to spend at least a couple thousand dollars.</p>

<p>You know what?
Don’t worry – Google and efabless have got you covered!
They are providing <strong>completely free of cost</strong> chip manufacturing runs: one in November this year, and multiple more in 2021.
All open source chip designs qualify, no further strings attached!</p>

<p>Learn more about all of that by re-watching <a href="https://www.youtube.com/watch?v=EczW2IWdnOM">Tim’s Dial-Up talk</a> or click through the <a href="https://docs.google.com/presentation/d/e/2PACX-1vRtwZPc8ykkkgtUkHkoJZrP9jKOo3FYdKqbg-So0ic6_kx7ha1vHnxrWmuxWkTc9GfC8xl0TfEpMLwK/pub?start=false&amp;loop=false&amp;delayms=3000">slides</a>.</p>

<p>This is certainly a dream come true for us at the FOSSi Foundation.
We helped the Free and Open Source Silicon community, our community, grow and tackle huge challenges over the years.
An open, manufacturable PDK was the main blocker in a fully open flow between RTL and a physical chip, and we’re extremely excited to see that blocker removed.</p>

<p>As always, removing one roadblock only highlights more challenges:
RAM, ROM and flash compilers, analog blocks, optimizations to various tools, and much, much more.
Now is the perfect time to get involved in the Free and Open Source Silicon ecosystem – or learn more about the accomplishments and challenges ahead of us.
A good starting point are the next Dial-Up talks.</p>

<p>Head over to the <a href="https://fossi-foundation.org/dial-up/">Dial-Up web site</a> for a listing of the upcoming talks on OpenROAD, cell design, OpenRAM, and Magic, an old, but surprisingly up-to-date tool!
To stay up-to-date with the latest developments in the FOSSi ecosystem <a href="https://librecores.us17.list-manage.com/subscribe?u=5d525b453672149a60c198960&amp;id=1241c8638b">subscribe to El Correo Libre</a>, our monthly newsletter bringing all the important news bits directly to your inbox (or <a href="https://medium.com/librecores">read it online</a>).</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/EczW2IWdnOM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

  </div>

</article>

	</div></div>]]>
            </description>
            <link>https://fossi-foundation.org/2020/06/30/skywater-pdk</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755693</guid>
            <pubDate>Tue, 07 Jul 2020 04:26:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Faces of Microsoft (2017)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23755238">thread link</a>) | @beefhash
<br/>
July 6, 2020 | https://www.typemag.org/post/the-faces-of-microsoft | <a href="https://web.archive.org/web/*/https://www.typemag.org/post/the-faces-of-microsoft">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

		
			<figure data-blockname="pull_quote">
				<p>‘Why do we need more fonts?’ asked Bill Gates. ‘We’ve got a	serif, a sans, and a monospace font. Why do we need more?’...</p>
				
			</figure>
			
			<header data-blockname="article_title">

				
				<h2><a href="https://www.typemag.org/category/3">History of type</a></h2>
				

				

				<p>The people and the rich story of type at the first big tech company.</p>

			</header>
			
			
			
			<figure data-blockname="single_image">
				<a data-lightbox="type-mag-slideshow" data-title="Steven Shaiman, the first program manager for type at Microsoft. He’s been on his own since 2010, living in the Pacific Northwest and working on family enterprises with his wife and five children." href="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-05-Shaiman-Steve-47.jpg"><img data-src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-05-Shaiman-Steve-47.jpg" alt="" src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-05-Shaiman-Steve-47.jpg"></a>
				
				<figcaption>Steven Shaiman, the first program manager for type at Microsoft. He’s been on his own since 2010, living in the Pacific Northwest and working on family enterprises with his wife and five children.</figcaption>
			</figure>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-datetime.png" alt="" height="300" width="300"></span>Gates was having an informal meeting with Steve Shaiman, a cheerful gnome of a man with a head of frizzy hair who was general manager of Microsoft’s hardware division, and with Raleigh Roark one of the two people who had started the division. They were talking about fonts and applications, especially Word.</p>

<p>Roark gave Gates his answer: For printers, basically. This was the era of desktop publishing and proliferating office applications, and users needed more than just the bitmapped system fonts on their computers to get their work done. Courier, Tms Rmn, and Helv were not going to be enough. </p>

<p>Bill Gates is known for asking hard questions, but also for accepting hard answers and acting on them. As soon as he got his answer, he pointed at Steve and told him: “Now you run type!”</p>

<p>That’s the way things worked at Microsoft in those days, says Shaiman: whoever knew the most about a subject tended to end up in charge of it. So he ended up starting Microsoft’s first fonts group. It was Spring, 1989.</p>
			</section>
			

			





			
			<section data-blockname="sub_heading_1">
				<h2>The conquest of TrueType</h2>
			</section>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-phone.png" alt="" height="300" width="300"></span>STEVE SHAIMAN was on a business trip to Atlanta with Nathan Myhrvold, Microsoft’s celebrated head of advanced technology, when they got an unexpected phone call. Myhrvold had with him a satellite phone—an early mobile phone, “which in those days,” as Shaiman put it, “meant something you’d carry in a suitcase.” The unexpected call was from Apple.</p>

<p>At that time, Adobe Systems dominated the digital font market, with its PostScript technology built into Apple’s LaserWriter printers, and with PostScript firmly established as the preferred format for high-quality fonts. Microsoft needed to find its own format and its own fonts if it didn’t want to be dependent on Adobe.</p>

<p>Like Microsoft, Apple was trying to find ways to license the PostScript language from Adobe, or to find an alternative. The Apple call was about font technology: Apple was developing its own font format, TrueType, as an alternative to PostScript, while Microsoft acquired a program called TrueImage, a potential PostScript clone, which Apple was interested in. How about a trade?</p>

<p>Shaiman says that his and Nathan Myhrvold’s reaction was immediate: “Sure!”</p>

<p>Ironically, once Microsoft got hold of TrueType, they loved the concept but didn’t like the way it was implemented. Although they ended up only making slight modifications to the version that shipped with Windows 3.1, when it came time for the next version of Windows, they ended up “throwing out Apple’s code and rewriting it from scratch.”</p>

<p>When Microsoft and Apple publicly announced their collaboration on TrueType at the Seybold conference in September 1989, the announcement was handled in a contentious and aggressive manner that antagonized Adobe and famously brought Adobe’s John Warnock to tears of frustration. Steve Shaiman feels now that it was a poor way to do it: “We couldn’t have done worse.” Although they were demonstrating what they felt was better technology, they made the mistake of shoving it in Adobe’s face. “What we really needed,” he says, “was a good PR person who could have helped us come up with a less aggressive approach.” But the deed was done. The “font wars” were in full swing.</p>

<p>The key developer of Microsoft’s new code was Eliyezer Kohen, whom Myhrvold met at a conference in Switzerland. Eliyezer was, as Steve Shaiman put it, “really, really smart.” He had a PhD from ETH Zurich, where he studied with Hans Eduard Meyer, the designer of the font Syntax, and Niklaus Wirth, designer of the Pascal language; and he developed his own technology for creating scalable fonts. Eliyezer, according to Shaiman, was “a Turkish Jew with a German wife, who wanted to move to the United States, as one or the other of them wasn’t welcome in any country in Europe where they might find decent working conditions.” Microsoft happily brought him in.</p>
			</section>
			
			<figure data-blockname="single_image">
				<img data-src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-03-Hitchcock-Greg-135.jpg" alt="" src="https://www.typemag.org/images/uploads/MS-Type-Mag-2017-03-Hitchcock-Greg-135.jpg">
				<figcaption>Greg Hitchcock’s journey to Microsoft was a bit circuitous —he studied geography with a focus on computer cartography, and immersed himself in computer science.</figcaption>
			</figure>
			
			<section data-blockname="sub_heading_1">
				<h2>Even a DOS screen needs a font</h2>
			</section>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-dosscreen.png" alt="" height="300" width="300"></span>GREG HITCHCOCK was one of the early members of what he calls the “virtual team” that Shaiman and Dennis Adler put together in early 1990 to deal with fonts. Hitchcock is tall, blond, and slow-spoken; he doesn’t fit the image of the high-energy Microsoft employee, and he may seem unassertive, almost tentative, if you see him only in a neutral context. But when you see his attention snap to the subjects he knows and cares about, he is forceful and precise, and very, very knowledgeable. His memory is encyclopedic, and he has been at the heart of Microsoft’s typographic development for more than a quarter century. Today he manages Microsoft’s Advanced Reading Technologies (ART) team.</p>

<p>Although Microsoft had been dealing with fonts in one way or another from the very beginning (even a DOS screen needs a font to display its text), Hitchcock feels that the story of typography at Microsoft really begins here: When the first outline fonts were created for Windows 3.1, in 1990.</p>

<p>It was all brand-new technology. All fonts up until then had been bitmap fonts, crude forms made up of coarse screen pixels in a vague approximation of what real letters looked like. Although Microsoft’s new effort was driven by purely practical needs—mapping the screen fonts on a computer system to the fonts available on a printer—Hitchcock feels that it was also the beginning of thinking about screen fonts as something useful and readable in themselves.</p>

<p>The members of the virtual team came from all over Microsoft: Dennis Adler (Fonts), Jean-François Peyroux (OS/2, and later Windows), Michel Suignard (Windows International), Greg Hitchcock (OS/2), Eliyezer Kohen (Fonts), David Weise (Windows), Tim McCaffery (Windows), Raleigh Roark (Hardware), Gabe Newell (Printing), and later Ben Bauermeister, an outside consultant, whose “PANOSE system” for classifying typefaces by their visual characteristics (rather than their historical roots) might provide a roadmap between screen and print.</p>
			</section>
			
			<section data-blockname="sub_heading_1">
				<h2>Monotype send out S.O.S.</h2>
			</section>
			
			<section data-blockname="body_copy">
				<p><span><img src="https://www.typemag.org/images/uploads/win31-shake.png" alt="" height="300" width="300"></span>STEVE SHAIMAN hired Dennis Adler to manage the fonts groups.&nbsp; Together, they talked with several potential sources of font libraries and font technologies, including most of the big guns in the field. Linotype, the venerable manufacturer of hot-metal typesetting equipment, which owned the rights to, among others, the very popular typeface Helvetica, was being hard-nosed. “Fonts were seen as incredibly valuable at the time,” says Shaiman, “and Linotype’s attitude was, ‘What’s Microsoft going to do for us?’” So they were asking an enormous price for licensing the fonts. And Microsoft didn’t want to license the fonts; it wanted to own the rights. (When Shaiman told me this, he laughed and proclaimed: “Microsoft doesn’t rent things!”)</p>

<p>Monotype, on the other hand, was much more receptive. Monotype was Linotype’s great rival; between them, the two companies had essentially created the business of mechanical typesetting in the late 19th century, with their competing hot-metal composition machines. But the Monotype Corporation had fallen on hard times. The typography division, the only part of the company working on digital fonts, was making money, but the larger machinery business was hemorrhaging cash, and the parent company was about to declare bankruptcy.</p>

<p>Out of that debacle rose a new type-only company, Monotype Typography Ltd, which was essentially the old typography division reconstituted as an independent business.</p>

<p>The new company, with its focus on digital fonts and information technology, was headed by a German, Rene Kerfante, who had joined Monotype in 1987 to head up the typography division, and an American, Ira Mirochnik, who had been Monotype’s chief financial officer. They were both quite ready to negotiate a deal with Microsoft.</p>

<p>So it was Monotype that began developing a set of “core fonts” for Microsoft: Scalable TrueType fonts that could be shipped with Windows and used freely by every Windows customer. The new fonts had to mimic the established core set of PostScript fonts, which included Times Roman and Helvetica. Since Monotype had originally developed the Times fonts back in the hot-metal days, that part was easy. To compete with Helvetica, though, they chose to adapt an earlier Monotype design with similar characteristics, called Arial.</p>

<p>Designing the outlines for these typefaces was the kind of task that the Monotype drawing office excelled at. The hard part was the hinting, the software instructions that control the rendering on various devices. That was what would make the fonts look good on screen.</p>

<p>Monotype had a team in the UK working on font hinting, but they were running into trouble. Although they had an auto-hinting program, called TypeMan, developed by Apple’s principal TrueType developer, Sampo Kaasila, the process was proving to be long, slow, and laborious. As Greg Hitchcock describes it, Monotype in desperation Monotype “sent out the bat signal.” In response, in September 1990, he and Eliyezer made the first of many trips to the UK to provide hands-on help and supervision. This was the start of a back-and-forth pattern for Greg—three weeks in the UK, one week in Redmond—that lasted for the next nine months. Their main job was hinting type, working in little rooms in archaic buildings at the old Monotype works. …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.typemag.org/post/the-faces-of-microsoft">https://www.typemag.org/post/the-faces-of-microsoft</a></em></p>]]>
            </description>
            <link>https://www.typemag.org/post/the-faces-of-microsoft</link>
            <guid isPermaLink="false">hacker-news-small-sites-23755238</guid>
            <pubDate>Tue, 07 Jul 2020 02:53:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's Talos all the way down]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23754536">thread link</a>) | @classichasclass
<br/>
July 6, 2020 | https://www.talospace.com/2020/06/its-talos-all-way-down.html | <a href="https://web.archive.org/web/*/https://www.talospace.com/2020/06/its-talos-all-way-down.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-6179143665681918893"><p>
Still can't bear the sticker shock of your very own Talos II, or even a itty bitty Blackbird? Why not do what we all do for the machines we can't own and emulate one instead? (And then decide you like it a lot, and save your pennies?)
</p><p>
QEMU 5.0.0 offers a machine model for the bare-metal PowerNV profile, to which the Raptor systems and other OpenPOWER POWER8 and POWER9 designs intended for Linux (i.e., not PowerVM machines) belong. Using the Talos II firmware image (mostly: one snag to be mentioned), you can boot the machine in QEMU and from there bring up an operating system in emulation. In this article we'll prove it works by bringing up <a href="https://voidlinux-ppc.org/">Void Linux for Power</a> (hi, Daniel!) in a variety of configurations. A set-up like this might be enough to test that your software or open-source package builds and runs on OpenPOWER, even if you don't own one yet. In a future article we'll talk about how you can boot your own code on the metal so you can port your favourite OS or build a unikernel.
</p><p>
(For the purposes of this article I'll assume an audience that isn't as familiar with OpenPOWER terminology as our usual readership. Kindly humour me.)
</p><p>
The emulation is imperfect, both if you're emulating it on a real Raptor family system or on an icky PC. While QEMU can emulate an AST2500 (i.e., the ARM-based Baseboard Management Controller, which acts as the service processor and provides the video framebuffer), and QEMU can also emulate a PowerNV system, it doesn't do both at the same time. That means the very lowest levels are actually being simulated here -- you can't watch Raptor's pretty Hostboot display, for example, and only the barest functions of the BMC are simulated enough to allow bring-up, not including the framebuffer. In fact, the hardware profiles we will use here do not in general match a real Raptor system either: we're just virtually plugging in PCI devices that give us necessary functionality, though of course none of the peripheral devices in a Raptor system is Raptor-proprietary. Finally, even though I have tagged this entry with KVM, KVM currently doesn't work right with the QEMU PowerNV machine model even though I'm pretty sure it should be technically possible. Sadly, I tried in vain to do so, could never get KVM-HV to be happy, and ended up kernel panicking the machine with KVM-PR. <a href="https://gist.github.com/classilla/0b95d7bea3e9a270385a2360fbcf7f40">See if you can triumph where I have failed</a>. In the meantime, naturally you can do everything here on a T2 or Blackbird as well because that's how I did it writing this article, but there is no special acceleration for those systems right now.
</p><p>
The first order of business is the first order of business with any emulator: get the ROMs. Fortunately, no one is going to bust you for pirating a set of these because we're an open platform, remember?
</p><p>
The two pieces required are Skiboot and Petitboot, both of which live in the system's PNOR flash. <a href="https://github.com/open-power/skiboot">Skiboot</a> contains OPAL, the OpenPOWER Abstraction Layer. It comes in after the BMC has turned on main power and started the Power CPUs' self-boot engines, which then IPL ("initial program load") Hostboot for the second-stage power-on sequence. When Hostboot completes, it chains into Skiboot, which initializes the PCIe host bus controllers (PHBs) and provides all the basic hardware calls needed by a guest kernel to support the platform. You can think of it as something like an overgrown BIOS. This is the lowest firmware level of an OpenPOWER system that QEMU currently supports emulating.
</p><p>
Skiboot lives only to service a kernel, so it immediately starts one. This initial payload is the bootloader for <a href="https://github.com/open-power/petitboot">Petitboot</a>, which is also stored in firmware. Petitboot has a small Linux root (Skiroot) and acts as a boot menu, finding bootable volumes on attached devices or over the network. Having found one (or you select one), it chains into it to start the main OS, and from then on Skiboot will provide platform services via OPAL for this final guest until the system is shut down or restarted. Because it's in firmware, Petitboot is always available, which can come in really handy when you're trying to do system recovery.
</p><p>
The first, best and most dedicated way is to <a href="https://github.com/open-power/op-build">build Skiboot and Petitboot yourself</a>. They are open-source and the process is relatively well documented and automated, and you should know how to do this if you own an OpenPOWER machine anyhow. If you aren't doing this on a real OpenPOWER machine you'll need a cross-compiler, but most Linux distros offer such a package nowadays. Do keep in mind that if it looks like you're building a tiny Linux distro, well, that's because that's exactly what you're doing. The advantage here is you can fool around with the firmware at your leisure, but it requires a bit of an investment in disk space and time.
</p><p>
The second way assumes you have a more casual interest and would prefer to go with something prefab. It's possible if you (or, you know, your "friend") has a Raptor-family system to extract the necessary components right from the BMC prompt. Log into the BMC over SSH (or via <a href="https://www.talospace.com/2020/04/what-to-do-when-bmc-wont-talk-to-you.html">direct serial connection</a>) and type <tt>pflash -i</tt>. You'll see a list of all the partitions stored in the PNOR flash. The ones we want are <tt>PAYLOAD</tt> (which contains Skiboot) and <tt>BOOTKERNEL</tt> (which contains Skiroot and Petitboot). The exact addresses may vary from system to system and firmware to firmware.
</p><p>
<tt>root@bmc:~# pflash -P PAYLOAD -r /tmp/pnor.PAYLOAD --skip=4096<br>
Reading to "/tmp/pnor.PAYLOAD" from 0x021a1000..0x022a1000 !<br>
[==================================================] 100%<br>
root@bmc:~# pflash -P BOOTKERNEL -r /tmp/pnor.BOOTKERNEL --skip=4096<br>
Reading to "/tmp/pnor.BOOTKERNEL" from 0x022a1000..0x03821000 !<br>
[==================================================] 100%
</tt></p><p>
We skip the first 4K page to avoid the wrapping around each partition. <tt>pnor.PAYLOAD</tt> is actually compressed and needs to be uncompressed prior to use, so:
</p><p>
<tt>root@bmc:~# cd /tmp<br>
root@bmc:/tmp# xz -d &lt; pnor.PAYLOAD &gt; skiboot.lid</tt>
</p><p>
Finally, <tt>scp</tt> both <tt>skiboot.lid</tt> and <tt>pnor.BOOTKERNEL</tt> to your desired system from the BMC.
</p><p>
Admittedly we just talked at length about the two ways most of you <em>won't</em> get the firmware, so let's talk about the third method and the way most of you will, i.e., you'll just download it. Currently there is an irregularity about Raptor's present Skiboot build for this purpose: it only boots if you are emulating a single <em>POWER8</em>. That's not a typo. If you use it to boot an emulated POWER9, the guest will simply panic, and the guest will go into a bootloop if you are emulating multiple POWER8 CPUs (necessary if you need a larger number of PCIe devices). This is undoubtedly a QEMU deficiency which will be corrected in future releases. In the meantime, if you just care about playing around using a single POWER8 on a terminal, then Raptor's builds (either from BMC flash or downloaded) will suffice. However, if you intend to emulate a POWER9 or SMP POWER8 system, <a href="https://github.com/qemu/qemu/blob/master/pc-bios/skiboot.lid">download QEMU's own pre-built <tt>skiboot.lid</tt></a> and use that instead.
</p><p>
For Petitboot, we will extract that directly from Raptor's PNOR images. Assuming you didn't get it using the process above, <a href="https://wiki.raptorcs.com/wiki/Talos_II/Firmware">download the current Talos II PNOR image</a> and decompress it. In the <tt>shell_upgrade</tt> directory you will see the <tt>bzip2</tt>-compressed PNOR image. Uncompress that, leaving you with a filename like <tt>talos-ii-v2.00.pnor</tt>. <a href="https://gist.github.com/classilla/4a2c907d0acec5b537cd4992a00801c3">Download my <tt>pnorex</tt> extractor tool</a> (it's in Perl, because I'm one of <em>those</em> people) and run it on the PNOR image:
</p><p>
<tt>% pnorex talos-ii-v2.00.pnor<br>
Version 1 PNOR archive with 33 entries.<br>
Extracting PAYLOAD at offset 8601.<br>
This is a xz format image.<br>
Wrote 1020K successfully.<br>
Extracting BOOTKERNEL at offset 8857.<br>
This is an ELF executable image.<br>
Wrote 22012K successfully.<br>
Extracted 2 partitions successfully.
</tt>
</p><p>
If you will be using Raptor's Skiroot, then uncompress <tt>pnor.PAYLOAD</tt> to <tt>skiroot.lid</tt> as above: <tt>xz -d &lt; pnor.PAYLOAD &gt; skiboot.lid</tt>
</p><p>
Now, with <tt>skiroot.lid</tt> (for this first example, either Raptor's or QEMU's) and <tt>pnor.BOOTKERNEL</tt> in the same folder, grab an ISO you want to boot. I used the prefab one Daniel offers on the <a href="https://voidlinux-ppc.org/">Void Linux for Power site</a> since I know it boots fine on OpenPOWER hardware. For our first example let's do a simple example of booting Void from a CD image on a POWER8 using the serial port. Our QEMU command line:
</p><p>
<tt>
qemu-system-ppc64 -M powernv8 -m 4G -cpu power8 \<br>
        -nographic \<br>
        -bios ./skiboot.lid \<br>
        -kernel ./pnor.BOOTKERNEL \<br>
        -device ich9-ahci,id=ahci0 \<br>
        -drive id=cd0,media=cdrom,file=void-live-ppc64le-musl-20200411.iso,if=none \<br>
        -device ide-cd,bus=ahci0.0,drive=cd0
</tt>
</p><p>
This configures a single-processor POWER8 system with 4GB of RAM, no graphics, and an Intel AHCI host controller with a single CD-ROM drive attached. The serial output should go to your terminal. It goes a little like this:
</p><p><a href="https://3.bp.blogspot.com/-3VII_RkIwcE/XvFb7tRycOI/AAAAAAAABs0/yyvLDu_1liEFaU2wpoZWtrf-au1P1YiDACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-44-48.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://3.bp.blogspot.com/-3VII_RkIwcE/XvFb7tRycOI/AAAAAAAABs0/yyvLDu_1liEFaU2wpoZWtrf-au1P1YiDACLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-44-48.png" width="287"></a></p>
<p>
Here we are with Skiboot chaining into Petitboot. You can ignore the errors; there will be a lot of them since the platform is still incomplete. It will take a little bit of time to decompress the kernel (much slower than it would be on a regular system). You will notice a single device attached to the three available PCIe host bridges on the single POWER8 CPU, i.e., the host controller itself. Don't you just love that the vendor code for Intel is <tt>8086</tt>?
</p><p><a href="https://4.bp.blogspot.com/-3IKOOE6kD80/XvFb7uxi8sI/AAAAAAAABss/yKU2WHvBCbgDmXPvyFdSvsCu7yLHnnGuACLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-45-08.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://4.bp.blogspot.com/-3IKOOE6kD80/XvFb7uxi8sI/AAAAAAAABss/yKU2WHvBCbgDmXPvyFdSvsCu7yLHnnGuACLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-45-08.png" width="287"></a></p>
<p>
This is Petitboot. When the bootable choices appear, cursor up to the starred option and press E before it autoboots, because we need to tell Void its console is the on-board serial port (otherwise it uses a VGA console: not sure whose bug that is).
</p><p><a href="https://2.bp.blogspot.com/--dDE00hPAsk/XvFb7k5ug4I/AAAAAAAABsw/KD1kofJkAdIusk9rtl8WyjlknApxQRouQCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-45-43.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://2.bp.blogspot.com/--dDE00hPAsk/XvFb7k5ug4I/AAAAAAAABsw/KD1kofJkAdIusk9rtl8WyjlknApxQRouQCLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-45-43.png" width="287"></a></p>
<p>
Add <tt>console=hvc0</tt> at the end, cursor down to <tt>OK</tt> and hit RETURN/ENTER a couple times to boot.
</p><p><a href="https://2.bp.blogspot.com/-h6UHepGrXLo/XvFb8GHW5jI/AAAAAAAABs4/STBtGNaljU4-3EvsmhlstoBbIpU0aLaKgCLcBGAsYHQ/s1600/Screenshot%2Bfrom%2B2020-06-22%2B16-47-38.png" imageanchor="1"><img data-original-height="645" data-original-width="578" height="320" src="https://2.bp.blogspot.com/-h6UHepGrXLo/XvFb8GHW5jI/AAAAAAAABs4/STBtGNaljU4-3EvsmhlstoBbIpU0aLaKgCLcBGAsYHQ/s320/Screenshot%2Bfrom%2B2020-06-22%2B16-47-38.png" width="287"></a></p>
<p>
A successful login on your emulated baby POWER8. Ta-daa! To rudely pull the plug on the QEMU session, press Ctrl-A, and then X (<tt>QEMU: Terminated</tt>).
</p><p>
Let's now load out the POWER8. We would like to add a video card, an Ethernet card and a USB controller to our existing system, but POWER8 Turismo chips only offer enough PHBs for three PCI endpoints. How do we solve this problem? Easy: we'll add another processor!
</p><p>
At this point …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.talospace.com/2020/06/its-talos-all-way-down.html">https://www.talospace.com/2020/06/its-talos-all-way-down.html</a></em></p>]]>
            </description>
            <link>https://www.talospace.com/2020/06/its-talos-all-way-down.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23754536</guid>
            <pubDate>Tue, 07 Jul 2020 01:03:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achaemenid Shields Are a Puzzle]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23753604">thread link</a>) | @diodorus
<br/>
July 6, 2020 | https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/ | <a href="https://web.archive.org/web/*/https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- end .post-extras -->

		<div>
			<div data-shortcode="caption" id="attachment_7331"><p><a href="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg"><img aria-describedby="caption-attachment-7331" data-attachment-id="7331" data-permalink="https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/fig_6_2_six_shields/" data-orig-file="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg" data-orig-size="1600,2400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fig_6_2_six_shields" data-image-description="" data-medium-file="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=200" data-large-file="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=529" src="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=529&amp;h=794" alt="" width="529" height="794" srcset="https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=529&amp;h=794 529w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=1058&amp;h=1588 1058w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=100&amp;h=150 100w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=200&amp;h=300 200w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=768&amp;h=1152 768w, https://bookandsword.files.wordpress.com/2020/04/fig_6_2_six_shields.jpg?w=683&amp;h=1024 683w" sizes="(max-width: 529px) 100vw, 529px"></a></p><p id="caption-attachment-7331">Figure 6-2 from my forthcoming book from Franz Steiner Verlag.  Some types of <em>gerron</em> (wicker shield) used in the Achaemenid empire in the time of Darius I and Xerxes.  Top: <em>peltē</em> and wooden imitation of a sticks-and-leather shield from Tuekta in the Altai (different sections of ‘sticks’ are painted red, white, and black; similar shields appear in Neo-Assyrian art). Middle: rectangular wicker shields.  Bottom: violin-shaped or figure-eight shields.  Note that they are worn on the arm like a <em>peltē</em> or an Argive shield, not held in the fist like the Tuekta shield.  Source: The J. Paul Getty Museum, Malibu CA, no. 83.AE.247 (digital image courtesy of the Getty’s Open Content Program), State Hermitage Museum, St. Petersburg, no. 2179/96 (photo by author); Gerhard 1847: Taf. CLXVI; western entrance of the Tachara of Darius (sketch by author), Persepolis; two reliefs on the Apadana, Persepolis (photo by author)</p></div>
<p>  If you look at modern paintings and miniatures, you would think we have a good idea of the type of shield used by Achaemenid infantry in the time of Darius and Xerxes.  They cite <a href="http://www.perseus.tufts.edu/hopper/text?doc=Hdt.+7.61&amp;fromdoc=Perseus%3Atext%3A1999.01.0126">Herodotus book 7 chapter 61</a> and show the large rectangular kind on the middle row of the picture above.  But as I argue in chapter 6.5.2 of my forthcoming book from Franz Steiner Verlag, things are more complicated.  These large rectangular shields appear on the doorposts of two buildings at Persepolis and on two or three vases from Athens (out of thousands of soldiers at Persepolis and Susa and thousands of Red Figure vases). The person who published the sketch on the middle left thought it showed a battle against the Phrygian allies of the Amazons.  And this type of shield does not agree with Herodotus’ words that quivers were hanging beneath the shields, unless we understand ‘beneath’ quite loosely.<br>
<span id="more-7332"></span></p>
<p>  The type in the top row is also popular with artists, but it seems specific to the Aegean/Sea of Marmara/Black Sea region.  Warriors of all the different nations in this region used small round, rectangular, or crescent-shaped shields, often made of wicker or covered with goatskin, but we do not see these shields in artwork from the heart of the empire.  Its also hard to imagine these forming a barrier which needed to be knocked over after a long struggle, like Herodotus describes.  But they are the type of shield which artists from Athens most often put in the hands of foreigners, probably because the Athenians were a bit provincial and Thracians and Scythians were the most exotic warriors they were familiar with.</p>
<p>  The type in the bottom row is the most common type at Persepolis, but it does not show up in Greek art at all.  This might be because it was too similar to the Boeotian or dipylon or figure-eight shield and Greek artists felt that it did not say ‘barbarian.’  A bronze boss for such a shield was found at Samos.  It is easy to imagine quivers hanging beneath such a shield, but hard to imagine them forming a solid barrier which needed to be pushed over.  </p>
<p>  We see even more types of shield in art from the empire, such as the small round center-grip shield on the Çan sarcophagus or the big deep round wicker shields carried by ?Thracians? at Persepolis.  But these three types in the three rows are the ones people today are most interested in.</p>
<p>  Diodorus describes the Persian shields at Thermopylae a bit differently than Herodotus describes them at Plataia (11.7.3, my translation) “For the barbarians used small <em>aspides</em> and <em>peltai</em> which were advantageous in broad open spaces, being easy to move, so because of the narrow space they were not able to harm their enemies very well because they were packed close together with their whole bodies covered with the great <em>aspides</em>, while being at a disadvantage because of the lightness of their defensive arms, they suffered wound after wound.”  He seems to imagine Persian warriors using <em>peltai</em> like the barbarians in paintings (Xen. Cyr. 1.2.13)</p>
<p>  People in my lifetime have written a lot of nonsense about wicker shields supposedly being ‘light’ or ‘weak.’  I don’t know of any tests of this, and traditional wooden shields tend to be thinner and lighter than people expect (like 8 mm thick wood plus a layer of linen or parchment in the centre, and 3-5 mm thick wood plus a layer of linen or parchment at the edge).  Modern wooden shields often use heavy plywood and rawhide so the shield can stand up to pounding with blunt weapons: the fact that these shields are unnecessarily heavy is not important because the owners don’t have to march 20 miles with them on their backs, camp, cook dinner, and march 20 miles again.  Tough warriors like the Ottoman Turks used wicker shields and I don’t know of any of their opponents who said that these were poor protection.  Also, until about the time of Xerxes’ punitive expedition against the Ionians-beyond-the-sea, Greek art often shows spearmen with a light figure-eight shields (Dipylon shields, Boeotian shields) which may well have been made of leather or wicker.  Neither art not archaeology shows that all Greek “bearers of spear and shield” in 480 BCE carried a heavy Argive shield and a single long thrusting lance.</p>
<p>  The type of shield in the middle row is the best fit for Herodotus’ descriptions of combat, but not the most common type in art, and it does not match his description of how Persian soldiers were armed.  And as we saw, <a href="https://bookandsword.com/2019/07/06/provisions-loin-girdling-and-battle-gear-in-the-long-sixth-century/">lists of equipment for soldiers in Babylonia</a> do not seem to mention shields at all.  So like a lot of things in ancient history, the idea that Xerxes’ men carried large rectangular wicker shields is our best guess based on pretty thin evidence, not something certain.</p>
<p><em>Further Reading:</em> There are tests of arrows against reproductions of sticks-through-rawhide shields based on artefacts from Dura Europos and Pazyrzk in Barry Molloy’s <em>The Cutting Edge</em> (Tempus: Stroud, 2007) [ISBN 9780752441696 on <a href="https://www.bookfinder.com/search/?isbn=9780752441696&amp;st=xl&amp;ac=qr">Bookfinder</a>]</p>
<p><strong>Don’t leave my sites naked against a hail of financial arrows!  Support them on <a href="https://www.patreon.com/bookandswordblog">Patreon</a> or <a href="https://www.paypal.me/bookandswordblog">paypal.me</a> or even <a href="https://liberapay.com/bookandswordblog/">liberapay</a></strong></p>
<p><em>Edit 2020-07-08:</em> Hi Hacker News!  <a href="https://news.ycombinator.com/item?id=23753604" rel="nofollow">https://news.ycombinator.com/item?id=23753604</a><br>
<a href="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png"><img data-attachment-id="7751" data-permalink="https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/2020-07-08_traffic_cropped/" data-orig-file="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png" data-orig-size="989,236" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-07-08_traffic_cropped" data-image-description="" data-medium-file="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=300" data-large-file="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=529" src="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=529&amp;h=126" alt="a bar chart of one month's traffic where half of all hits are on one day towards the end" width="529" height="126" srcset="https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=529&amp;h=126 529w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=150&amp;h=36 150w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=300&amp;h=72 300w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png?w=768&amp;h=183 768w, https://bookandsword.files.wordpress.com/2020/07/2020-07-08_traffic_cropped.png 989w" sizes="(max-width: 529px) 100vw, 529px"></a></p>
					</div><!-- end .post-entry -->
	</div></div>]]>
            </description>
            <link>https://bookandsword.com/2020/06/06/achaemenid-shields-are-a-puzzle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23753604</guid>
            <pubDate>Mon, 06 Jul 2020 22:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abusing linear regression to make a point]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 43 (<a href="https://news.ycombinator.com/item?id=23752561">thread link</a>) | @furcyd
<br/>
July 6, 2020 | http://www.goodmath.org/blog/2020/07/06/abusing-linear-regression-to-make-a-point/ | <a href="https://web.archive.org/web/*/http://www.goodmath.org/blog/2020/07/06/abusing-linear-regression-to-make-a-point/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>A bunch of people have been sending me links to a particularly sloppy article that (mis)uses linear regression to draw an incorrect conclusion from some data. So I guess I’ve got to got back to good-old linear regression, and talk about it a bit.</p>



<p>Let’s start with the basics. What is linear regression?</p>



<p>If you have a collection of data – typically data with one independent variable, and one dependent variable (that is, the first variable can vary any way it wants; changing it will change the second variable), then you’re probably interested in how the dependent variable relates to the independent. <em>If</em> you have reason to believe that they should have a linear relationship, then you’d like to know just what that linear relationship is.</p>



<p>If your data were perfect, then you’d just need to plot all of the data points on a graph, with the independent variable on the X axis, and the dependent on the Y, and then your graph would be a line, and you could get its slope and Y intercept, and thus completely capture the relationship.</p>



<p>But data is never perfect. There’s a lot of reasons for that, but no real set of collected data is ever perfect. No matter how perfect the real underlying linear relationship is, real measured data will always show some scatter. And that means that you can draw a lot of possible lines through the collected data. Which one of them represents the best fit?</p>



<p>Since that’s pretty abstract, I’m going to talk a bit about an example – the very example that was used to ignite my interest in math!</p>



<p>Back in 1974 or so, when I was a little kid in second grade, my father was working for RCA, as a physicist involved in manufacturing electronics for satellite systems. One of the important requirements for the products they were manufacturing was that they be <em>radiation hard</em> – meaning that they could be exposed to quite a bit of radiation before they would be damaged enough to stop working.</p>



<p>Their customers – NASA, JPL, and various groups from the U. S. Military, had very strong requirements. They had to show, for a manufacturing setup of a particular component, what the failure profile was.</p>



<p>The primary failure mode of these chips they were making was circuit trace failure. If a sufficiently energetic gamma ray hit one of the circuit traces, it was possible that the trace would burn out – breaking the circuit, and causing the chip to fail.</p>



<p>The test setup that that they used had a gamma ray emitter. So they’d make a manufacturing run to produce a batch of chips from the setup. Then they’d take those, and they’d expose them to increasing doses of radiation from the gamma emitter, and detect when they failed.</p>



<p>For trace failure, the probability of failure is linear in the size of the radiation dose that the chip is exposed to. So to satisfy the customer, they had to show them what the slope of the failure curve was. “Radiation hard” was defined as being able to sustain exposure to some dose of radiation with a specified probability of failure.</p>



<p>So, my dad had done a batch of tests, and he had a ton of little paper slips that described the test results, and he needed to computer the slop of that line – which would give the probability of failure as a multiple of the radiation dose.</p>



<p>I walked into the dining room, where he was set up doing this, and asked what he was doing. So he explained it to me. A lot like I just explained above – except that my dad was a much better teacher than me. I couldn’t explain this to a second or third grader the way that he did!</p>



<p>Anyway… The method that we use to compute the best line is called <em>least squares</em>. The intuition behind it is that you’re trying to find the line where the average distance of all of the datapoints from that line is the smallest. But a simple average doesn’t work well – because some of the data points are above the line, and some are below. Just because one point is, say, above a possible fit by 100, and another is below by 100 doesn’t mean that the two should cancel. So you take the distance between the data points and the line, and you square them – making them all positive. Then you find the line where that total is the smallest – and that’s the best fit.</p>



<p>So let’s look at a real-ish example.</p>



<p>For example, here’s a graph that I generated semi-randomly of data points. The distribution of the points isn’t really what you’d get from real observations, but it’s good enough for demonstration.<img src="http://www.goodmath.org/blog/wp-content/uploads/2013/01/graph.png" alt="scatter plot of randomly skewed data" srcset="http://www.goodmath.org/blog/wp-content/uploads/2013/01/graph.png 346w, http://www.goodmath.org/blog/wp-content/uploads/2013/01/graph-300x212.png 300w" sizes="(max-width: 346px) 100vw, 346px"></p>



<p>The way that we do that is: first we compute the means of <img src="http://l.wordpress.com/latex.php?latex=x&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="x" alt="x"> and <img src="http://l.wordpress.com/latex.php?latex=y&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="y" alt="y">, which we’ll call <img src="http://l.wordpress.com/latex.php?latex=%5Coverline%7Bx%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\overline{x}" alt="\overline{x}"> and <img src="http://l.wordpress.com/latex.php?latex=%5Coverline%7By%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="\overline{y}" alt="\overline{y}">. Then using those, we compute the slope as:</p>



<p><img src="http://l.wordpress.com/latex.php?latex=%20m%20%3D%20%5Cfrac%7B%5CSigma_%7Bi%3D1%7D%5En%20%28x-%5Chat%7Bx%7D%29%28y-%5Chat%7By%7D%29%7D%7B%5CSigma_%7Bi%3D1%7D%5E%7Bn%7D%20%28x-%5Chat%7Bx%7D%29%5E2%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title=" m = \frac{\Sigma_{i=1}^n (x-\hat{x})(y-\hat{y})}{\Sigma_{i=1}^{n} (x-\hat{x})^2}" alt=" m = \frac{\Sigma_{i=1}^n (x-\hat{x})(y-\hat{y})}{\Sigma_{i=1}^{n} (x-\hat{x})^2}"></p>



<p>Then for the y intercept: <img src="http://l.wordpress.com/latex.php?latex=b%20%3D%20%5Chat%7By%7D%20-%20m%5Chat%7Bx%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="b = \hat{y} - m\hat{x}" alt="b = \hat{y} - m\hat{x}">.</p>



<p>In the case of this data: I set up the script so that the slope would be about 2.2 +/- 0.5. The slope in the figure is 2.54, and the y-intercept is 18.4.</p>



<p>Now, we want to check how good the linear relationship is. There’s several different ways of doing that. The simplest is called the correlation coefficient, or <img src="http://l.wordpress.com/latex.php?latex=r&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title="r" alt="r">.</p>



<p><img src="http://l.wordpress.com/latex.php?latex=%20r%20%3D%20%5Cfrac%7B%5Cleft%28%5CSigma%20%28x-%5Chat%7Bx%7D%29%5Cright%29%20%5Cleft%28%5CSigma%20%28y%20-%20%5Chat%7By%7D%29%5Cright%29%7D%7B%5Csqrt%7B%20%5Cleft%28%5CSigma%20%28x-%5Chat%7Bx%7D%29%5E2%5Cright%29%20%5Cleft%28%5CSigma%20%28y%20-%20%5Chat%7By%7D%29%5E2%5Cright%29%20%7D%7D&amp;bg=FFFFFF&amp;fg=000000&amp;s=0" title=" r = \frac{\left(\Sigma (x-\hat{x})\right) \left(\Sigma (y - \hat{y})\right)}{\sqrt{ \left(\Sigma (x-\hat{x})^2\right) \left(\Sigma (y - \hat{y})^2\right) }}" alt=" r = \frac{\left(\Sigma (x-\hat{x})\right) \left(\Sigma (y - \hat{y})\right)}{\sqrt{ \left(\Sigma (x-\hat{x})^2\right) \left(\Sigma (y - \hat{y})^2\right) }}"></p>



<p>If you look at this, it’s really a check of how well the variation between the measured values and the expected values (according to the regression) match. On the top, you’ve got a set of products; on the bottom, you’ve got the square root of the same thing squared. The bottom is, essentially, just stripping the signs away. The end result is that if the correlation is perfect – that is, if the dependent variable increases linearly with the independent, then the correlation will be 1. If the dependency variable decreases linearly in opposition to the dependent, then the correlation will be -1. If there’s no relationship, then the correlation will be 0.</p>



<p>For this particular set of data, I generated it with a linear equation with a little bit of random noise. The correlation coefficient is slighly greater than 0.95, which is exctly what you’d expect.</p>



<p>Ok, so that’s the basics of linear regression. Let’s get back to the bozo-brained article that started this.</p>



<figure><img src="http://www.goodmath.org/blog/wp-content/uploads/2020/07/EcCqXojUMAEBFnp.jpg" alt=""></figure>



<p>They featured this graph:</p>



<p>You can see the scatter-plot of the points, and you can see the line that was fit to the points by linear regression. How does that fit look to you? I don’t have access to the original dataset, so I can’t check it, but I’m guessing that the correlation there is somewhere around 0.1 or 0.2 – also known as “no correlation”.</p>



<p>You see, the author fell into one of the classic traps of linear regression. Look back at the top of this article, where I started explaining it. I said that <em>if</em> you had reason to believe in a linear relationship, then you could try to find it. That’s the huge catch to linear regression: no matter what data you put in, you’ll always get a “best match” line out. If the dependent and independent variables don’t have a linear relation – or don’t have any actual relation at all – then the “best match” fit that you get back as a result is garbage.</p>



<p>That’s what the graph above shows: you’ve got a collection of data points that to all appearances has no linear relationship – and probably no direct relationship at all. The author is interpreting the fact that linear regression gave him an answer with a positive slope as if that positive slope is meaningful. But it’s only meaningful <em>if</em> there’s actually a relationship present.</p>



<p>But when you look at the data, you don’t see a linear relationship. You see what looks like a pretty random scatterplot. Without knowing the correlation coefficient, we don’t know for sure, but that line doesn’t look to me like a particularly good fit. And since the author doesn’t give us any evidence beyond the existence of that line to believe in the relationship that they’re arguing for, we really have no reason to believe them. All they’ve done is demonstrate that they don’t understand the math that they’re using.</p>
					</div></div>]]>
            </description>
            <link>http://www.goodmath.org/blog/2020/07/06/abusing-linear-regression-to-make-a-point/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752561</guid>
            <pubDate>Mon, 06 Jul 2020 20:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a 486 from floppy with the most up-to-date stable Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 142 (<a href="https://news.ycombinator.com/item?id=23752284">thread link</a>) | @LeoPanthera
<br/>
July 6, 2020 | https://www.insentricity.com/a.cl/283 | <a href="https://web.archive.org/web/*/https://www.insentricity.com/a.cl/283">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>
	<iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="400" src="https://www.youtube.com/embed/oBeE_z4HTwg" width="600"></iframe></p>
<div>
	<p>
		Back in August of 2019 I had a&nbsp;<a href="https://www.reddit.com/r/retrobattlestations/comments/cr6x9a/contest_singalong_week_until_aug_25/">Sing-Along Week contest on RetroBattlestations</a>&nbsp;with the challenge of playing a MIDI file synchronized to a speech synthesizer singing the lyrics. In my stash of cards I found an MQX-32M MIDI card (Roland MPU-401 clone) which I wanted to use for converting MIDI signals to interface to an Apple II+ with an Echo II speech synthesizer, but ended up using a laptop with a USB MIDI interface. The&nbsp;<a href="https://www.reddit.com/r/retrobattlestations/comments/fz6is8/contest_pizza_week_through_april_19th/">Pizza Week contest</a>&nbsp;made me more interested in finding a 486 in a pizza box case and so my search began for a suitable case.</p>
	
	<p>
		Searching eBay wasn't easy because there's not really a good search term that would find the kind of case I wanted. I didn't bother trying to make a saved search since this project wasn't a high priority. Instead every once in a while something would inspire to go hit eBay and try some other search terms. A couple of weeks ago I spotted this 486 and made a guess of the size based on the size of the 5.25" bay. It's fairly slim, it has a riser card to turn the cards sideways and the case <em>is</em> shorter than an ISA card, but I don't feel like it's slim enough to call it a pizza box. It's close though!</p>
	
	<p>
		The motherboard is a <a href="https://stason.org/TULARC/pc/motherboards/T/TMC-RESEARCH-CORPORATION-486-PAT48PG4-VER-1-2A.html">TMC PAT48PG4</a> and it came with 32MB of RAM (technically 36MB, it had four 30 pin SIMMs in it too) and 4 cards: VGA, SoundBlaster, modem, and multi-function IO. The seller had tested it and was sold as non-working, won't POST, although he said the cards all worked. I mostly wanted it for the case so I wasn't concerned. Of course when I got it I had to see if the motherboard was really dead. It didn't work for me either but then I discovered if I hit the reset button it would give me some error beeps. I tried another power supply and it came up after hitting reset! It still doesn't cold boot when powered on, not sure if there's a bad cap or if the very slight battery damage (battery was removed before I got it) is preventing the reset line from being pulled after power on. Nonetheless it was working enough that I needed to explore its capabilities more.</p>
	
	<p>
		My ultimate goal is to get a <em>very recent</em>&nbsp;Linux distro and Python 3 installed to a "large" hard drive, but being that this is a 486 installing a current Linux distro isn't trivial. The only Linux distros that still support installing from floppy media are quite dated. Normally I would bypass a floppy install entirely and just boot an older computer via PXE and then install over the network. I thought I could <a href="https://ipxe.org/appnote/buildtargets">put iPXE on a floppy</a> and stick in an ISA NIC but iPXE just hangs without any error messages right after it's loaded from floppy.&nbsp;</p>
	
	<p>
		The BIOS is ancient and struggles with handling the "large" hard drive I hooked up. The drive is 8.45GB and the BIOS can only see it as an 8.0GB drive. Enabling LBA in the BIOS causes the computer to hang during POST after it detects the drive. Win98 fdisk insists the drive is only 504MB. FreeDOS can't see the drive at all. I tried sticking in a NIC with XTIDE ROM on the socket and XTIDE also insists there's no drive connected.</p>
	
	<p>
		Since I wanted to see how Linux would detect the drive that meant I needed to find a way to boot Linux. After a bit of googling I discovered the <a href="http://tiny.wiki.kernel.org/">make tinyconfig option</a> which makes a very small (but useless) kernel, small enough to fit on a floppy. <a href="https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d">I enabled a couple of other options</a>, found a small enough initramfs, and was able to get it to boot on the 486. And as expected Linux has no problem with seeing that the drive is connected and the drive's full capacity.</p>
	
	<p>
		Next step is to actually get Linux installed to the hard drive. I'd rather not roll my own distro but maybe I'll have to. Another possibility is to boot Linux from floppy and then download a kernel and initrd from a current distro and kexec over to it. But that feels to me like reinventing iPXE.</p>
	<h4>
		Compiling the Linux Kernel From Source</h4>
	<p>
		A quick rundown of the steps to build the floppy image:</p>
</div>
<ul>
	<li>
		git clone https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git
		<ul>
			<li>
				v5.8-rc2-1-g625d3449788f&nbsp;at the time of writing</li>
		</ul>
	</li>
	<li>
		make ARCH=x86 tinyconfig</li>
	<li>
		make ARCH=x86 menuconfig
		<ul>
			<li>
				Set processor to 486: CONFIG_M486=y
				<ul>
					<li>
						Processor type and features &gt; Processor family &gt; 486</li>
				</ul>
			</li>
			<li>
				Enable tty: CONFIG_TTY=y
				<ul>
					<li>
						Device Drivers &gt; Character devices &gt; Enable TTY</li>
				</ul>
			</li>
			<li>
				Enable printk: CONFIG_PRINTK=y
				<ul>
					<li>
						General Setup &gt; Configure standard kernel features (expert users) &gt; Enable support for printk</li>
				</ul>
			</li>
			<li>
				Enable initramfs: CONFIG_INITRAMFS_COMPRESSION_GZIP=y
				<ul>
					<li>
						General Setup &gt;&nbsp;Initial RAM filesystem and RAM disk (initramfs/initrd) support &gt;&nbsp;Support initial ramdisk/ramfs compressed using gzip</li>
				</ul>
			</li>
			<li>
				Enable ELF: CONFIG_BINFMT_ELF=y
				<ul>
					<li>
						Executable file formats &gt;&nbsp;Kernel support for ELF binaries</li>
				</ul>
			</li>
		</ul>
	</li>
	<li>
		make ARCH=x86 bzImage</li>
</ul>


<p>
	Test boot with qemu:</p>
<div>
	<pre>qemu-system-i386 -kernel arch/x86/boot/bzImage -initrd ../system-image-486/rootfs.cpio.gz</pre>
</div>
<p>
	Create a blank floppy image:</p>
<div>
	<pre>dd if=/dev/zero of=linux-boot.img bs=1k count=1440
mkdosfs linux-boot.img
syslinux --install linux-boot.img
mount -o loop linux-boot.img /mnt
cp arch/x86/boot/bzImage /mnt
cp rootfs.cpio.gz /mnt</pre>
</div>
<p>
	Create /mnt/syslinux.cfg:</p>
<div>
	<pre>DEFAULT linux
LABEL linux
 SAY Now booting the kernel from SYSLINUX...
 KERNEL bzImage
 APPEND initrd=rootfs.cpio.gz
</pre><p>
	Write the image to a floppy:
	</p><pre>umount /mnt
fdformat /dev/fd0
ddrescue -f -D linux-boot.img /dev/fd0
</pre>
	
</div>

</div></div>]]>
            </description>
            <link>https://www.insentricity.com/a.cl/283</link>
            <guid isPermaLink="false">hacker-news-small-sites-23752284</guid>
            <pubDate>Mon, 06 Jul 2020 20:20:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buying and Selling stocks with maximum profit]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23750763">thread link</a>) | @codingifmycraft
<br/>
July 6, 2020 | http://codingismycraft.com/index.php/2020/07/05/buying-and-selling-stocks-with-maximum-profit/ | <a href="https://web.archive.org/web/*/http://codingismycraft.com/index.php/2020/07/05/buying-and-selling-stocks-with-maximum-profit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://codingismycraft.com/index.php/2020/07/05/buying-and-selling-stocks-with-maximum-profit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23750763</guid>
            <pubDate>Mon, 06 Jul 2020 18:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1:60 scale Boeing 777 made from manila folders]]>
            </title>
            <description>
<![CDATA[
Score 785 | Comments 176 (<a href="https://news.ycombinator.com/item?id=23749821">thread link</a>) | @chha
<br/>
July 6, 2020 | https://www.lucaiaconistewart.com/model-777 | <a href="https://web.archive.org/web/*/https://www.lucaiaconistewart.com/model-777">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">

      
      



      <div id="content">

        
        
          
            

  


          
        

        <main id="page" role="main">

          

          <div data-content-field="main-content">
            
            <div data-type="page" data-updated-on="1561691883296" id="page-5cef0d874437940001629f3f"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559268252785_9085"><p><h2><em>1:60 SCALE MODEL OF AN AIR INDIA BOEING 777-300ER, MADE ENTIRELY FROM MANILA FOLDERS</em></h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1559266243734_6718"><div><p>This project traces its beginnings to an <a href="https://www.lucaiaconistewart.com/architecture"><span>architecture class</span></a> in high school where we learned to use manila file folders to roughly model our building ideas. The more I worked with paper, the more I fell in love with its versatility. At some point, I got the idea to make a model of an airplane as a way of challenging myself with an unconventional shape.</p><p>Though the project began on a much smaller and simpler scale in mid-2008, it has since evolved through multiple revisions to become a highly detailed, true-to-life representation of a Boeing 777. I originally drew my plans by hand, but my desire to increase the accuracy and amount of detail led me to start using Adobe Illustrator to design and print increasingly intricate parts directly onto the folder.</p><p><em>The project has been in progress since May 2008</em></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_11179"><div><h2>RESEARCH</h2><p>I start with as much source material as I can. Often that means photos and videos found on the web, but sometimes I’m lucky enough to get my hands on technical drawings as well. I study these materials to form an understanding of the intrinsic shape and function of the particular section I’m working on. Once I feel confident in my basic understanding of the part, I can begin the design process.</p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_13965"><div><h2>DESIGN</h2><p>Much of my work consists of figuring out how to flatten 3-D shapes into 2-D slices that can be printed onto paper and assembled. I work in Adobe Illustrator to create 2-D plans for all the parts of which the final product will be comprised. I typically start the process by working out the general shape and dimensions of the piece, then I drill down, adding more detail and functionality. Once the design has been “frozen,” I work to break it down into individual pieces and arrange them for printing. Often, if a piece is complex and I’m unsure of how well it will function in reality, I build a small test section to verify my designs.</p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1559711406501_16684"><div><h2>PRINTING &amp; ASSEMBLY</h2><p>This stage is as time-consuming as the design process. I cut folders down to printer-friendly sizes and print my plans directly onto them. Then, I cut out the individual pieces using an <a href="http://www.xacto.com/products/cutting-solutions/knives/detail/X3201" target="_blank"><span>Xacto knife</span></a>, arrange them into sections, and glue them together with <a href="https://www.aleenes.com/aleenes-clear-gel-tacky-glue" target="_blank"><span>Tacky Glue</span></a>. Often, a complex piece is actually a collection of much smaller sub-sections that each needs to be assembled separately before being joined together; this is especially true of something like the wing, which contains many articulating functions and thousands of parts.</p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1561353870131_383468"><div><h2>TOOLS</h2><p>My tools of choice include the aforementioned Xacto knife, a cutting mat, straight edges, squares, and a toothpick for the precise application of glue.</p></div></div></div></div><div data-block-json="{&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;url&quot;:&quot;https://www.youtube.com/watch?v=77oRSCxGmYA&quot;,&quot;html&quot;:&quot;<iframe src=\&quot;//www.youtube.com/embed/77oRSCxGmYA?wmode=opaque&amp;amp;enablejsapi=1\&quot; height=\&quot;480\&quot; width=\&quot;854\&quot; scrolling=\&quot;no\&quot; frameborder=\&quot;0\&quot; allowfullscreen=\&quot;\&quot;>\n</iframe>&quot;,&quot;resolveObject&quot;:&quot;Video&quot;,&quot;resolvedBy&quot;:&quot;youtube&quot;,&quot;resolved&quot;:true,&quot;description&quot;:&quot;Many people have asked how I design and build the parts for the manila folder 777 I'm putting together, and this video is perhaps the best answer yet. This covers the design and build process for the main landing gear, and was made from almost 130 hours of raw footage.&quot;,&quot;title&quot;:&quot;Manila Folder 777 - Main Landing Gear - Design+Build Time-lapse with Info! **60FPS**&quot;,&quot;height&quot;:480,&quot;thumbnail_width&quot;:480,&quot;width&quot;:854,&quot;version&quot;:&quot;1.0&quot;,&quot;type&quot;:&quot;video&quot;,&quot;thumbnail_height&quot;:360,&quot;authorName&quot;:&quot;Luca Iaconi-Stewart&quot;,&quot;authorUrl&quot;:&quot;https://www.youtube.com/user/lucaiaconistewart&quot;,&quot;providerName&quot;:&quot;YouTube&quot;,&quot;providerUrl&quot;:&quot;https://www.youtube.com/&quot;,&quot;thumbnailUrl&quot;:&quot;https://i.ytimg.com/vi/77oRSCxGmYA/hqdefault.jpg&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1559834399264_13753"><div><div><p><iframe scrolling="no" data-image-dimensions="854x480" allowfullscreen="" src="//www.youtube.com/embed/77oRSCxGmYA?wmode=opaque&amp;enablejsapi=1" width="854" data-embed="true" frameborder="0" height="480">
</iframe></p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1559269142757_26027"><p><h3>CLICK BELOW FOR MORE INFO ON EACH SECTION</h3></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1559870775542_20405"><div><p>Check out an expansive catalog of photos and videos about the project, and stay tuned for further updates!</p></div></div></div></div></div>
          </div>

          

          

        </main>

        

      </div>
    </div></div>]]>
            </description>
            <link>https://www.lucaiaconistewart.com/model-777</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749821</guid>
            <pubDate>Mon, 06 Jul 2020 16:57:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code only says what it does]]>
            </title>
            <description>
<![CDATA[
Score 152 | Comments 107 (<a href="https://news.ycombinator.com/item?id=23749676">thread link</a>) | @mjb
<br/>
July 6, 2020 | http://brooker.co.za/blog/2020/06/23/code.html | <a href="https://web.archive.org/web/*/http://brooker.co.za/blog/2020/06/23/code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">


<p>Only loosely related to what it should do.</p>


<p>Code says what it does. That's important for the computer, because code is the way that we ask the computer to do something. It's OK for humans, as long as we never have to modify or debug the code. As soon as we do, we have a problem. Fundamentally, debugging is an exercise in changing what a program does to match what it should do. It requires us to know what a program should do, which isn't captured in the code. Sometimes that's easy: What it does is crash, what it should do is <em>not crash</em>. Outside those trivial cases, discovering intent is harder.</p>

<p>Debugging when <em>should do</em> is subtle, such as when building distributed systems protocols, is especially difficult. In our <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a> paper, we say:</p>

<blockquote><p>Our code reviews, simworld tests, and design meetings frequently referred back to the TLA+ models of our protocols to resolve ambiguities in Java code or written communication.</p></blockquote>

<p>The problem is that the implementation (in Physalia's case the Java code) is both an imperfect implementation of the protocol, and an overly-specific implementation of the protocol. It's overly-specific because it needs to be fully specified. Computers demand that, and no less, while the protocol itself has some leeway and wiggle room. It's also overly-specific because it has to address things like low-level performance concerns that the specification can't be bothered with.</p>

<p><em>Are those values in an ArrayList because order is actually important, or because O(1) random seeks are important, or some other reason? Was it just the easiest thing to write? What happens when I change it?</em></p>

<p>Business logic code, while lacking the cachet of distributed protocols, have even more of these kinds of problems. Code both over-specifies the business logic, and specifies it inaccurately. I was prompted to write this by a tweet from @mcclure111 where she hits the nail on the head:</p>

<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">Since most software doesn't have a formal spec, most software "is what it does", there's an incredible pressure to respect authorial intent when editing someone else's code. You don't know which quirks are load-bearing.</p>— mcc 🏳️‍⚧️🏳️‍🌈 (@mcclure111) <a href="https://twitter.com/mcclure111/status/1274422600236765186?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>




<p>This is a major problem with code: <em>You don't know which quirks are load-bearing.</em> You may remember, or be able to guess, or be able to puzzle it out from first principles, or not care, but all of those things are slow and error-prone. What can we do about it?</p>

<p><strong>Design Documentation</strong></p>

<p>Documentation is uncool. Most software engineers seem to come out of school thinking that documentation is below them (<em>tech writer work</em>), or some weird thing their SE professor talked about that is as archaic as Fortran. Part of this is understandable. My own software engineering courses emphasized painstakingly documenting the implementation in UML. No other mention of documentation was made. Re-writing software in UML helps basically nobody. I finished my degree thinking that documentation was unnecessary busywork. Even the <a href="https://agilemanifesto.org/">Agile Manifesto</a> agreed with me<sup><a href="#foot1">1</a></sup>:</p>

<blockquote><p>Working software over comprehensive documentation</p></blockquote>

<p>What I discovered later was that design documentation, encoding the intent and decisions made during developing a system, helps teams be successful in the short term, and people be successful in the long term. Freed from fitting everything in my head, emboldened by the confidence that I could rediscover forgotten facts later, I could move faster. The same applies to teams.</p>

<p>One thing I see successful teams doing is documenting not only the <em>what</em> and <em>why</em> behind their designs, but the <em>how they decided</em>. When it comes time to make changes to the system—either for debugging or in response to changing requirements—these documents are invaluable. It's hard to decide whether its safe to change something, when you don't know why it's like that in the first place. The record of how you decided is important because you are a flawed human, and understanding how you came to a decision is useful to know when that decision seems strange, or surprising.</p>

<p>This documentation process doesn't have to be heavyweight. You don't have to draw painstaking <a href="https://en.wikipedia.org/wiki/Entity%E2%80%93relationship_model">ER diagrams</a> unless you think they are helpful. You should probably ignore UML entirely. Instead, describe the system in prose as clearly and succinctly as you can. One place to start is by building an RFC template for your team, potentially inspired by one that you find on the web. <a href="https://static1.squarespace.com/static/56ab961ecbced617ccd2461e/t/5d792e5a4dac4074658ce64b/1568222810968/Squarespace+RFC+Template.pdf">SquareSpace</a>'s template seems reasonable. Some designs will fit well into that RFC format, other's won't. Prefer narrative writing where you can.</p>

<p>Then, keep the documents. Store them somewhere safe. Soak them in vinegar <a href="https://www.almanac.com/content/home-remedies-cough-relief">and tie them around your chest</a>. You're going to want to make sure that the people who need to maintain the system can find them. As they are spelunking through history, help them feel more like a library visitor and less like Lara Croft.</p>

<p>I'm not advocating for Big Design Up Front. Many of the most important things we learn about a project we learn during the implementation. Some of the most important things we learn years after the implementation is complete. Design documentation isn't a static one-time ahead-of-time deliverable, but an ongoing process. Most importantly, design documentation is not a commitment to bad ideas. If it's wrong, fix it and move forward. Documentation is not a deal with the devil.</p>

<p><strong>Comments</strong></p>

<p>Few topics invite a programmer flame war like comments. We're told that comments are silly, or childish, or make it hard to show how manly you are in writing that convoluted mess of code. If it was hard to write, it should be hard to read. After all, you're the James Joyce of code.</p>

<p>That silliness aside, back to @mcclure111's thread:</p>

<blockquote data-conversation="none" data-dnt="true"><p lang="en" dir="ltr">This means comments that *reveal* authorial intent are valuable, and comments that reveal *there was no authorial intent* are even more valuable. Without those hints, you're left editing superstitiously, preserving quirks even when you don't know why. <a href="https://t.co/YhvWnXjp9i">https://t.co/YhvWnXjp9i</a></p>— mcc 🏳️‍⚧️🏳️‍🌈 (@mcclure111) <a href="https://twitter.com/mcclure111/status/1274422825831596039?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>




<p>Comments allow us to encode <em>authorial intent</em> into our code in a way that programming languages don't always. Types, traits, interfaces, and variable names do put intent into code, but not completely (I see you, type system maximalists). These same things allow us to communicate a lack of intent—consider <a href="https://docs.oracle.com/javase/8/docs/api/java/util/RandomAccess.html">RandomAccess</a> vs <a href="https://docs.oracle.com/javase/8/docs/api/java/util/ArrayList.html">ArrayList</a>—but are also incomplete. Well-commented code should make the intent of the author clear, especially in cases where that intent is either lost in the translation to code, or where implementation constraints hide the intent of the design. Code comments that link back to design documents are especially useful.</p>

<p>Some languages need comments more than others. Some, like SQL, I find to nearly always obscure the intent of the design behind implementation details.</p>

<p><strong>Formal Specification</strong></p>

<p>In <a href="https://cacm.acm.org/magazines/2015/4/184705-who-builds-a-house-without-drawing-blueprints/fulltext">Who Builds a House Without Drawing Blueprints?</a> Leslie Lamport writes:</p>

<blockquote><p>The need for specifications follows from two observations. The first is that it is a good idea to think about what we are going to do before doing it, and as the cartoonist Guindon wrote: "Writing is nature's way of letting you know how sloppy your thinking is."</p>

<p>The second observation is that to write a good program, we need to think above the code level.</p></blockquote>

<p>I've found that specification, from informal specification with narrative writing to formal specification with TLA+, makes writing programs faster and helps reduce mistakes. As much as I like that article, I think Lamport misses a key part of the value of formal specification: it's a great communication tool. In developing some of the trickiest systems I've built, I've found that heavily-commented formal specifications are fantastically useful documentation. Specification languages are all about <em>intent</em>, and some make it easy to clearly separate intent from implementation.</p>

<p>Again, from our <a href="https://www.usenix.org/conference/nsdi20/presentation/brooker">Millions of Tiny Databases</a> paper:</p>

<blockquote><p>We use TLA+ extensively at Amazon, and it proved exceptionally useful in the development of Physalia.  Our team used TLA+ in three ways: writing specifications of our protocols to check that we understand them deeply, model checking specifications against correctness and liveness properties using the TLC model checker, and writing extensively commented TLA+ code to serve as the documentation of our distributed protocols. While all three of these uses added value, TLA+’s role as a sort of automatically tested (via TLC),and extremely precise, format for protocol documentation was perhaps the most useful.</p></blockquote>

<p>Formal specifications make excellent documentation. Like design docs, they aren't immutable artifacts, but a reflection of what we have learned about the problem.</p>

<p><strong> Conclusion </strong></p>

<p>Building long-lasting, maintainable, systems requires not only communicating with computers, but also communicating in space with other people, and in time with our future selves. Communicating, recording, and indexing the intent behind our designs is an important part of that picture. Make time for it, or regret it later.</p>

<p><strong>Footnotes</strong></p>

<ol>
<li><a name="foot1"></a> To be charitable to the Agile folks, <em>comprehensive</em> does seem to be load-bearing.</li>
</ol>


</div></div>]]>
            </description>
            <link>http://brooker.co.za/blog/2020/06/23/code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749676</guid>
            <pubDate>Mon, 06 Jul 2020 16:41:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Concurrency Cost Hierarchy]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23749172">thread link</a>) | @benaadams
<br/>
July 6, 2020 | https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<!-- boilerplate 
page.assets: /assets/concurrency-costs
assetpath: /assets/concurrency-costs
tablepath: /misc/tables/concurrency-costs
-->

<h2 id="introduction">Introduction</h2>

<p>Concurrency is hard to get <em>correct</em>, at least for those of us unlucky enough to be writing in languages which expose directly the guts of concurrent hardware: threads and shared memory. Getting concurrency correct <em>and</em> fast is hard, too. Your knowledge about single-threaded optimization often won’t help you: at a micro (instruction) level we can’t simply apply the usual rules of μops, dependency chains, throughput limits, and so on. The rules are different.</p>

<p>If that first paragraph got your hopes up, this second one is here to dash them: I’m not actually going to do a deep dive into the very low level aspects of concurrent performance. There are a lot of things we just don’t know about how atomic instructions and fences execute, and we’ll save that for another day.</p>

<p>Instead, I’m going to describe a higher level taxonomy that I use to think about concurrent performance. We’ll group the performance of concurrent operations into six broad <em>levels</em> running from fast to slow, with each level differing from its neighbors by roughly an order of magnitude in performance.</p>

<p>I often find myself thinking in terms of these categories when I need high performance concurrency: what is the best level I can practically achieve for the given problem? Keeping the levels in mind is useful both during initial design (sometimes a small change in requirements or high level design can allow you to achieve a better level), and also while evaluating existing systems (to better understand existing performance and evaluate the path of least resistance to improvements).</p>

<h3 id="a-real-world-example">A “Real World” Example</h3>

<p>I don’t want this to be totally abstract, so we will use a real-world-if-you-squint<sup id="fnref:realworld"><a href="#fn:realworld">1</a></sup> running example throughout: safely incrementing an integer counter across threads. By <em>safely</em> I mean without losing increments, producing out-of-thin air values, frying your RAM or making more than a minor rip in space-time.</p>

<h3 id="source-and-results">Source and Results</h3>

<p>The source for every benchmark here is <a href="https://github.com/travisdowns/concurrency-hierarchy-bench">available</a>, so you can follow along and even reproduce the results or run the benchmarks on your own hardware. All of the results discussed here (and more) are available in the same repository, and each plot includes a <code>[data table]</code> link to the specific subset used to generate the plot.</p>

<h3 id="hardware">Hardware</h3>

<p>All of the performance results are provided for several different hardware platforms: Intel Skylake, Ice Lake, Amazon Graviton and Graviton 2. However except when I explicitly mention other hardware, the prose refers to the results on Skylake. Although the specific numbers vary, most of the qualitative relationships hold for the hardware too, but <em>not always</em>. Not only does the hardware vary, but the OS and library implementations will vary as well.</p>

<p>It’s almost inevitable that this will be used to compare across hardware (“wow, Graviton 2 sure kicks Graviton 1’s ass”), but that’s not my goal here. The benchmarks are written primarily to tease apart the characteristics of the different levels, and <em>not</em> as a hardware shootout.</p>

<p>Find below the details of the hardware used:</p>

<table>
  <thead>
    <tr>
      <th>Micro-architecture</th>
      <th>ISA</th>
      <th>Model</th>
      <th>Tested Frequency</th>
      <th>Cores</th>
      <th>OS</th>
      <th>Instance Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Skylake</td>
      <td>x86</td>
      <td>i7-6700HQ</td>
      <td>2.6 GHz</td>
      <td>4</td>
      <td>Ubuntu 20.04</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Ice Lake</td>
      <td>x86</td>
      <td>i5-1035G4</td>
      <td>3.3 GHz</td>
      <td>4</td>
      <td>Ubuntu 19.10</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Graviton</td>
      <td>AArch64</td>
      <td>Cortex-A72</td>
      <td>2.3 GHz</td>
      <td>16</td>
      <td>Ubuntu 20.04</td>
      <td>a1.4xlarge</td>
    </tr>
    <tr>
      <td>Graviton 2</td>
      <td>AArch64</td>
      <td>Neoverse N1</td>
      <td>2.5 GHz</td>
      <td>16<sup id="fnref:g2cores"><a href="#fn:g2cores">2</a></sup></td>
      <td>Ubuntu 20.04</td>
      <td>c6g.4xlarge</td>
    </tr>
  </tbody>
</table>

<h2 id="level-2-contended-atomics">Level 2: Contended Atomics</h2>

<p>You’d probably expect this hierarchy to be introduced from fast to slow, or vice-versa, but we’re all about defying expectations here and we are going to start in the <em>middle</em> and work our way outwards. The middle (rounding down) turns out to be <em>level 2</em> and that’s where we will jump in.</p>

<p>The most elementary way to safely modify any shared object is to use a lock. It mostly <em>just works</em> for any type of object, no matter its structure or the nature of the modifications. Almost any mainstream CPU from the last thirty years has some type of locking<sup id="fnref:parisc"><a href="#fn:parisc">3</a></sup> instruction accessible to userspace.</p>

<p>So our baseline increment implementation will use a simple mutex of type <code>T</code> to protect a plain integer variable:</p>

<div><div><pre><code><span>T</span> <span>lock</span><span>;</span>
<span>uint64_t</span> <span>counter</span><span>;</span>

<span>void</span> <span>bench</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>holder</span><span>(</span><span>lock</span><span>);</span>
        <span>counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We’ll call this implementation <em><abbr title="Uses a std::mutex and std::lock_guard to protect a plain integer counter.">mutex add</abbr></em>, and on my 4 CPU Skylake-S i7-6700HQ machine, when I use the vanilla <code>std::mutex</code> I get the following results for 2 to 4 threads:</p>



<p>The reported value is the median of all trials, and the vertical black error lines at the top of each bar indicate the <em>interdecile range</em>, i.e., the values at the 10th and 90th percentile. Where the error bars don’t show up, it means there is no difference between the p10 and p90 values at all, at least within the limits of the reporting resolution (100 picoseconds).</p>

<p>This shows that the baseline contended cost to modify an integer protected by a lock starts at about 125 nanoseconds for two threads, and grows somewhat with increasing thread count.</p>

<p>I can already hear someone saying: <em>If you are just modifying a single 64-bit integer, skip the lock and just directly use the atomic operations that most ISAs support!</em></p>

<p>Sure, let’s add a couple of variants that do that. The <code>std::atomic&lt;T&gt;</code> template makes this easy: we can wrap any type meeting some basic requirements and then manipulate it atomically. The easiest of all is to use <code>std::atomic&lt;uint64&gt;::operator++()</code><sup id="fnref:post"><a href="#fn:post">4</a></sup> and this gives us <em><abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>atomic_counter</span><span>{};</span>

<span>void</span> <span>atomic_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>atomic_counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The other common approach would be to use <a href="https://en.wikipedia.org/wiki/Compare-and-swap">compare and swap (<abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr>)</a> to load the existing value, add one and then <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> it back if it hasn’t changed. If it <em>has</em> changed, the increment raced with another thread and we try again.</p>

<p>Note that even if you use increment at the source level, the assembly might actually end up using <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> if your hardware doesn’t support atomic increment<sup id="fnref:atomicsup"><a href="#fn:atomicsup">5</a></sup>, or if your compiler or runtime just don’t take advantage of atomic operations even though they are available (e.g., see what even the newest version of <a href="https://godbolt.org/z/5h4K7y">icc does</a> for atomic increment, and what Java did for years<sup id="fnref:java"><a href="#fn:java">6</a></sup>). This caveat doesn’t apply to any of our tested platforms, however.</p>

<p>Let’s add a counter implementation that uses <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> as described above, and we’ll call it <em><abbr title="Uses a CAS loop to increment a single shared counter.">cas add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>cas_counter</span><span>;</span>

<span>void</span> <span>cas_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>uint64_t</span> <span>v</span> <span>=</span> <span>cas_counter</span><span>.</span><span>load</span><span>();</span>
        <span>while</span> <span>(</span><span>!</span><span>cas_counter</span><span>.</span><span>compare_exchange_weak</span><span>(</span><span>v</span><span>,</span> <span>v</span> <span>+</span> <span>1</span><span>))</span>
            <span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Here’s what these look like alongside our existing <code>std::mutex</code> benchmark:</p>



<p>The first takeaway is that, at least in this <em>unrealistic maximum contention</em> benchmark, using <abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr> (<a href="https://www.felixcloutier.com/x86/xadd"><code>lock xadd</code></a> at the hardware level) is significantly better than <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr>. The second would be that <code>std::mutex</code> doesn’t come out looking all that bad on Skylake. It is only slightly worse than the <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs">CAS</abbr> approach at 2 cores and beats it at 3 and 4 cores. It is slower than the atomic increment approach, but less than three times as slow and seems to be scaling in a reasonable way.</p>

<p>All of these operations are belong to <em>level 2</em> in the hierarchy. The primary characteristic of level 2 is that they make a <em>contended access</em> to a shared variable. This means that at a minimum, the line containing the data needs to move out to the caching agent that manages coherency<sup id="fnref:l3"><a href="#fn:l3">7</a></sup>, and then back up to the core that will receive ownership next. That’s about 70 cycles minimum just for that operation<sup id="fnref:inter"><a href="#fn:inter">8</a></sup>.</p>

<p>Can it get slower? You bet it can. <em>Way</em> slower.</p>

<h3 id="level-3-system-calls">Level 3: System Calls</h3>

<p>The next level up (“up” is not good here…) is level 3. The key characteristic of implementations at this level is that they make a <em>system call on almost every operation</em>.</p>

<p>It is easy to write concurrency primitives that make a system call <em>unconditionally</em> (e.g., a lock which always tries to wake waiters via a <code>futex(2)</code> call, even if there aren’t any), but we won’t look at those here. Rather we’ll take a look at a case where the fast path is written to avoid a system call, but the design or way it is used implies that such a call usually happens anyway.</p>

<p>Specifically, we are going to look at some <em>fair locks</em>. Fair locks allow threads into the critical section in the same order they began waiting. That is, when the critical section becomes available, the thread that has been waiting the longest is given the chance to take it.</p>

<p>Sounds like a good idea, right? Sometimes yes, but as we will see it can have significant performance implications.</p>

<p>On the menu are three different fair locks.</p>

<p>The first is a <a href="https://en.wikipedia.org/wiki/Ticket_lock">ticket lock</a> with a <code>sched_yield</code> in the spin loop. The idea of the yield is to give other threads which may hold the lock time to run. This <code>yield()</code> approach is publicly frowned upon by concurrency experts<sup id="fnref:notwhat"><a href="#fn:notwhat">9</a></sup>, who then sometimes go right ahead and use it anyway.</p>

<p>We will call it <abbr title="A ticket lock that calls sched_yield in a spin loop while waiting for its turn.">ticket yield</abbr> and it looks like this:</p>



<div><div><pre><code><span>/**
 * A ticket lock which uses sched_yield() while waiting
 * for the ticket to be served.
 */</span>
<span>class</span> <span>ticket_yield</span> <span>{</span>
    <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>dispenser</span><span>{},</span> <span>serving</span><span>{};</span>

<span>public:</span>
    <span>void</span> <span>lock</span><span>()</span> <span>{</span>
        <span>auto</span> <span>ticket</span> <span>=</span> <span>dispenser</span><span>.</span><span>fetch_add</span><span>(</span><span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_relaxed</span><span>);</span>

        <span>while</span> <span>(</span><span>ticket</span> <span>!=</span> <span>serving</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>))</span>
            <span>sched_yield</span><span>();</span>
    <span>}</span>

    <span>void</span> <span>unlock</span><span>()</span> <span>{</span>
        <span>serving</span><span>.</span><span>store</span><span>(</span><span>serving</span><span>.</span><span>load</span><span>()</span> <span>+</span> <span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_release</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre></div></div>

<p>Let’s plot the performance results for this lock alongside the existing approaches:</p>



<p>This is level 3 visualized: it is an order of magnitude slower than the level 2 approaches. The slowdown comes from the <code>sched_yield</code> call: this is a system call and these are generally on the order of 100s of nanoseconds<sup id="fnref:spectre"><a href="#fn:spectre">10</a></sup>, and it shows in the results.</p>

<p>This lock <em>does</em> have a fast path where <code>sched_yield</code> isn’t called: if the lock is available, no spinning occurs and <code>sched_yield</code> is never called. However, the combination of being a <em>fair</em> lock and the high contention in this test means that a lock convoy quickly forms (we’ll describe this in more detail later) and so the spin loop is entered basically …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23749172</guid>
            <pubDate>Mon, 06 Jul 2020 15:53:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made a macro keypad with 3D-printed switches]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23748660">thread link</a>) | @jstanley
<br/>
July 6, 2020 | https://incoherency.co.uk/blog/stories/3pct-keyboard.html | <a href="https://web.archive.org/web/*/https://incoherency.co.uk/blog/stories/3pct-keyboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>I made a macro keypad with 3d-printed switches</h3>
<p><i>Mon  6 July 2020</i></p>
<p><i>Tagged: <a href="https://incoherency.co.uk/blog/tags/electronics.html">electronics</a>, <a href="https://incoherency.co.uk/blog/tags/3dprinting.html">3dprinting</a></i></p>
<p>Latest on the 3d-printed keyboard switch project: I've reached a switch design that I think is probably reliable enough,
and I've put 3 of them together to form a macro keypad just to see how it all goes together before I commit to a
full keyboard. I don't have a number for how many presses the switch lasts, other than to say that
the motor on the testing machine stopped working before the switch did (after about 250,000 presses).</p>
<p><a href="https://img.incoherency.co.uk/2745"><img src="https://img.incoherency.co.uk/2745"></a></p>
<p>You can <a href="https://www.youtube.com/watch?v=uHkOPBxnLtM">watch my short demo video</a> if you want.</p>
<p>"80%" and "60%" keyboard layouts are quite popular, which are correspondingly reduced versions of a full keyboard layout.
I like to think of this keypad as a "3%" keyboard, it's fine as long as you only want to type "jes".</p>
<p><a href="https://img.incoherency.co.uk/2746"><img src="https://img.incoherency.co.uk/2746"></a></p>
<p>It's controlled by an Arduino Pro Micro. It's hard to tell from the pic because of the hot glue, but the switches are wired up to pins 2, 3, and 4, from
the other side of the board.</p>
<p>For the software side of it, I used the <a href="https://www.arduino.cc/reference/en/language/functions/usb/keyboard/">Arduino Keyboard library</a>,
using <a href="https://gist.github.com/jes/fe1aeb18457a06562516372684d1bd47">this quick and dirty Arduino code</a>.
Approximately all of the code is just related to the debounce logic.</p>
<p><a href="https://img.incoherency.co.uk/2748"><img src="https://img.incoherency.co.uk/2748"></a></p>
<p>The switches are printed in some generic no-name clear PETG.
The case and keycaps are printed in <a href="https://shop.prusa3d.com/en/prusament/711-prusament-pla-prusa-galaxy-black-1kg.html">Prusament Galaxy Black PLA</a>.
I'm a big fan of this filament. The glittery effect means the layer lines almost completely disappear. It's basically the same effect you get when printing with
carbon fibre-filled nylon, but with none of the difficulties of printing carbon fibre-filled nylon.</p>
<p>All of these parts, including the switches, were printed on my new <a href="https://www.prusa3d.com/original-prusa-mini/">Prusa Mini</a> printer, which arrived last week and I'm very pleased
with so far.</p>
<h2>Switches</h2>
<p>The problem with the switch design <a href="https://incoherency.co.uk/blog/stories/keyswitch-update.html">from last time</a> was that the copper tape was splitting apart, which prevents it from conducting along
its full length. I initially thought I had
solved this by applying a 2nd layer of copper tape, but that turned out not to be a workable solution. I did a bunch of tests of various combinations of 50% and 75% activation position, and 1 or 2 layers of copper
tape, and found no significant correlation between either of those 2 variables and how long the switch lasts. The switches lasted between 225 presses and 330,000 presses before
failure. 7 failed by the copper tape splitting, 2 failed by the PETG spiral spring breaking (both after more than 200,000 presses), and 1 didn't seem to have any broken parts, it just wasn't reliably working any more.</p>
<p>This is the CAD model of the latest design:</p>
<p><a href="https://img.incoherency.co.uk/2749"><img src="https://img.incoherency.co.uk/2749"></a></p>
<p>The "leaf spring" has that funny shape in its bend so that it can tilt easily, which ensures that it makes reliable contact with <i>both</i> contact wires, instead of
just the first one it happens to touch.</p>
<p>And here's a slow-motion video showing how it works (a slightly earlier iteration, but the same concept):</p>
<p><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/peXFqVMugO4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Also, just for fun, I did some <a href="https://incoherency.co.uk/blog/stories/freecad-fea.html">FEA</a> on the spiral spring
design, and it behaved just like the real version:</p>
<p><a href="https://img.incoherency.co.uk/2724"><img src="https://img.incoherency.co.uk/2724"></a></p>
<p>The red areas show the areas of highest stress, and indeed the springs tend to break around
the middle of the spiral.</p>
<h2>Print your own</h2>
<p>I consider this a "release candidate" rather than a finished design, because there is still
some work to do on it (in particular, I want to make it a bit less tall). But you can have it if you want it.</p>
<p>You will need:</p>
<ul>
<li>FDM 3D printer (although I'd also be interested to see results from resin printers!)</li>
<li>PETG filament. You can try other materials. PLA works but makes for a heavier feel and breaks more quickly.</li>
<li>1.0 mm diameter copper wire, 90 mm length per switch should be more than enough</li>
</ul>
<p><a href="https://incoherency.co.uk/interest/3dpswitch-rc1.tar.gz">Download the STL files</a> and arrange them on the build plate something like this (you'll probably have to rotate the spiral spring):</p>
<p><a href="https://img.incoherency.co.uk/2750"><img src="https://img.incoherency.co.uk/2750"></a></p>
<p>I suggest printing more than 1 of the "leafspring" part as it is a small part quite likely to
have defects in the print. Make sure you're printing at
a fine enough quality level to include all the features. In particular, make sure (both) the spirals on
the spring are connected all the way around, and that the leaf spring is connected all the way
along. I use the "0.15mm QUALITY" setting in PrusaSlicer. You shouldn't need any support material.
You might need to enable "detect thin walls".</p>
<p>You might need to add up to -0.3mm of X/Y size compensation. I have found that when printing
this on the Prusa Mini, optimal clearance is achieved when the 3.0 mm plunger rides inside
a 3.0 mm hole. On previous printers I've owned, this wouldn't even fit together. I'm not sure
what's going on, but obviously I modeled it to print on my machine, so you might need to apply X/Y
compensation on yours.</p>
<p><b>Step 1:</b> Print the parts. It takes about 40 minutes for me.</p>
<p><b>Step 2:</b> Clean up any stringing inside the case from the PETG. I use a lighter to burn off the worst of it,
and then a Stanley knife to trim off what remains.</p>
<p><b>Step 3:</b> Examine the spiral spring and ensure that it moves freely. You might need to cut any
stringing between the spirals with a knife, or re-print with different X/Y compensation, depending on whether it is a few small
tight spots or bad clearance all the way along.</p>
<p><b>Step 4:</b> Slide the spiral spring into the shelf at the top of the case. The orientation is not
critical, I tend to slide it in with the smoothest sides against the case just to make life easy
for myself.</p>
<p><b>Step 5:</b> Push the plunger through the top hole in the case, through the hole in the spiral
spring, and through the middle hole in the case. Verify that it moves up and down freely and that
the spring reliably returns it to the top. If not, take it back out and trim the tight spots with
a knife.</p>
<p><b>Step 6:</b> Cut off about a 13mm length of the copper wire. Slide it into the hole in the
leaf spring. If you can't get it through, you might need to widen the hole with a pin or sharp tool of
some kind. Use whatever you have.</p>
<p><b>Step 7:</b> Press the plunger down slightly to expose the attachment end inside the lower
chamber of the switch. Using a small pair of pliers or tweezers, push the attachment part of the
leaf spring onto the end of the plunger. Make sure it is pushed home. Looking in the big hole
at the bottom of the case, you should see the leaf spring roughly centred. When you let go
of the plunger, the spiral spring should still be stretched out slightly. This is desired, without
this preload the switch would start moving at 0 force.</p>
<p><b>Step 8:</b> Cut off 2x roughly 35mm lengths of copper wire. Using a pair of pliers, put a bend about
5mm from
one end. Insert the non-bent end through 1 of the wire holes and out the other side. Bend the wire
down the other side, and then in whatever direction you want your contacts to point. Repeat for
the second wire.</p>
<p>You should now have something that looks a bit like this:</p>
<p><a href="https://img.incoherency.co.uk/2752"><img src="https://img.incoherency.co.uk/2752"></a></p>
<p>And that should be it! Manually press the switch a few times and visually verify that the middle
copper wire appears to be making good contact with the other 2 wires, and then you're ready to
assemble it into a circuit! If you want it mechanically attached to a PCB, you could leave a longer
length of wire coming out of the first side, and you'd then have 4 soldering points. Otherwise,
mount it inside a 14mm square hole. You'll probably need cut-outs in the corners to accommodate
the wires sticking out, like this:</p>
<p><a href="https://img.incoherency.co.uk/2753"><img src="https://img.incoherency.co.uk/2753"></a></p>
<p>If you make one (or more!) I'd be really interested to hear your opinion on what could be designed
better, and to see pictures of your results. Email me: <a href="mailto:james@incoherency.co.uk">james@incoherency.co.uk</a>.</p>
<h2>Next steps</h2>
<p>We're getting pretty close to being able to put together a finished keyboard. I still
have the following things to do:</p>
<h3>Testing</h3>
<p>It would be good to get an accurate value for the number of presses that the switches can take. I
think currently a lot of the variability comes from the height at which the switch is positioned
relative to the tester. If it's doing 0.1mm short of a full stroke, the switch is likely to last
significantly longer than if it is being hammered 0.1mm longer than a full stroke. This is hard to
configure as I have only very coarse control of the height.</p>
<p>I watched the Linus Tech Tips tours of <a href="https://www.youtube.com/watch?v=Pu1gP4PfqCQ">the
Cherry MX factory</a> and <a href="https://www.youtube.com/watch?v=9fNiJKh6q-E">the Omron factory</a>. They're both interesting and worth watching. I took a screenshot of this testing machine in the
Omron video:</p>
<p><a href="https://img.incoherency.co.uk/2712"><img src="https://img.incoherency.co.uk/2712"></a></p>
<p>So there we have a single motor raising a platform up and down which is pressing 10 switches
at once. The platform glides on a pair of linear rails, and the exact vertical position of the press
is finely adjusted with a separate screw for each switch. The moving platform also has
a spring at each end, I am not completely sure why, I think just to take up some of its weight, to
reduce the load on the motor.</p>
<p>But this is a much better way to gang-test switches than what I have at the moment, which involves
wiring up a separate motor for each switch and gets messy quickly:</p>
<p><a href="https://img.incoherency.co.uk/2755"><img src="https://img.incoherency.co.uk/2755"></a></p>
<p>I'm past the point where more testing is critical (famous last words, I know), but it would be good
to do anyway, so I'd like to make a small-scale copy of the Omron testing machine.</p>
<h3>Switches</h3>
<p>The switch fits in a 14mm square hole (apart from the protruding wires), which is the same size
as a Cherry MX switch, but the total height from the bottom of the switch to the top of the keycap
is almost twice as large, about 45 mm vs 25 mm:</p>
<p><a href="https://img.incoherency.co.uk/2757"><img src="https://img.incoherency.co.uk/2757"></a></p>
<p>This directly translates to increased keyboard height, so it would be good to cut this down
as much as possible. I should be able to lose 2 mm from the wire support at the bottom of the switch,
and another 1 or 2 mm in the height of the leaf spring attachment, but there's no way it's going to be
as thin as the Cherry MX.</p>
<p>I'd like to find a way to add a tactile bump (ideally with a clicky noise) to the motion of
the plunger. I did try simply adding a bump to the side of the casing that would catch on the
leaf spring, but it didn't work very reliably.</p>
<h3>Keycaps</h3>
<p>Currently my keycaps are based on the one I designed in <a href="https://incoherency.co.uk/blog/cad-dojo/stories/keycap.html">my
CAD Dojo project</a>. This is suboptimal for several reasons:</p>
<ol>
<li>adding text in FreeCAD is extremely time-consuming, and it can't be edited without deleting it …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://incoherency.co.uk/blog/stories/3pct-keyboard.html">https://incoherency.co.uk/blog/stories/3pct-keyboard.html</a></em></p>]]>
            </description>
            <link>https://incoherency.co.uk/blog/stories/3pct-keyboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748660</guid>
            <pubDate>Mon, 06 Jul 2020 15:03:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Addio Redis, I'm leaving Redis Labs]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23748190">thread link</a>) | @kristoff_it
<br/>
July 6, 2020 | https://kristoff.it/blog/addio-redis/ | <a href="https://web.archive.org/web/*/https://kristoff.it/blog/addio-redis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Thanks Antirez for the code, the Redis manifesto, and for the free karma especially.</p><div><p>Last week I resigned from my position as developer advocate at Redis Labs.</p>
<p>I’ve never talked much about Redis on this blog because I made a point of trying to write interesting posts about different topics, and also to avoid any form of conflict of interest: I didn’t want people to think this blog was being used as a marketing outlet by Redis Labs.</p>
<p>Now that I’m not with the company anymore, I’m looking forward to sharing some of my thoughts on open-source software and related topics, using the direct and energetic tone that I always employ here. </p>
<p>This was the first job I took that wasn’t strictly about programming. It taught me a lot about communication, how information flows between groups of people, and how companies try to shape that flow.</p>
<p>While Redis Labs as a company isn’t perfect — I wouldn’t have left otherwise, and it wouldn’t have hired me in the first place, as I’m not perfect either — I’m happy with my experience overall. The one regret I have is that my position was in part meant to help the community better understand Redis, and I’m leaving behind me basically the same level of confusion that was there when I joined 1.5 years ago.</p>
<p>Redis is less obvious to describe than other tools in the same space, but that alone is not enough to explain why no one seems to agree on what Redis is good at, or what even is Redis. To me, the current situation seems caused by an ongoing turf war between tech companies, starting from the direct competitors of Redis Labs, up to the Cloud giants, who see themselves as the ultimate gatekeepers of modern software architecture.</p>
<p>Each of these factions wants Redis to be a different thing, and so they spend their budget accordingly, starting from developer advocates like me, up to de-facto astroturfers that I’ll leave unnamed. While you and I, dear reader, are surely immune to marketing and scummy tactics, those techniques do work wonders on the public, and the strength of true statements is only used as a way of making marketing spend more efficient.</p>
<p>This is where I imagined I would spell out my take on Redis, but <a href="http://antirez.com/news/133" target="_blank" rel="nofollow noopener noreferrer">now that Antirez has left the project</a>, it doesn’t matter anymore. Whatever Redis is going to be in the future, it will be shaped by sales tactics, whatever the Clouds are going to do next, and other uninspired metrics.</p>
<p>Since this is my goodbye post to Redis, let me add an over-the-top Italian skit before jumping into the lessons learned.</p>
<h2 id="if-redis-were-pasta"><a href="#if-redis-were-pasta" aria-label="if redis were pasta permalink"></a>If Redis were pasta</h2>
<p>If Redis were pasta, it would be served in a restaurant called Salvatore’s. It would be a plate of spaghetti with tomato sauce and a single leaf of basil on top; basically the Italian symbol for a simple, versatile meal. </p>
<p>Big tech would be like McDonald’s and Burger King: convinced that the future of nutrition is fast-food and constantly screaming that Redis can’t be considered a real meal as it doesn’t contain any bacon: “Come eat our new burger, which now contains an extra 4th layer of meat, exquisitely designed to make it easier to digest the meal!”</p>
<p>On a table you would find Jepsen, essentially the equivalent of Yelp, ideally meant to keep restaurants honest, generally correct, but ultimately not that different from other tech companies, and thus well deserving of <a href="https://www.youtube.com/watch?v=pDlR_ccnZww" target="_blank" rel="nofollow noopener noreferrer">boogers and cum</a>.</p>
<p>Antirez, largely preferring cooking over serving, would end up selling the restaurant to the waiters, who at that point would make their priority to turn the restaurant into an Olive Garden.</p>
<h2 id="lessons-learned"><a href="#lessons-learned" aria-label="lessons learned permalink"></a>Lessons learned</h2>
<p>So where’s the Redis community in this story? Well, those are just the silent, mostly anonymous regulars that come, eat, and then go on with their lives. </p>
<p>It’s the people that occasionally show up on HN and point out that they’re happy with what Redis does for them, and that they rarely think about it even, as the software tends to chug along nicely. As much as I sympathize with them, the ultimate lesson I learned is that a passive community will inevitably lead to the death of a project.</p>
<p>While the “<a href="https://news.ycombinator.com/item?id=23690123" target="_blank" rel="nofollow noopener noreferrer">spontaneus software</a>” world is busy infighting, big tech is systematically strip-mining it of any value, even when 99% of the value gets lost in the process. Tech companies are willing to go to any length to capture that 1%, and over time have learned to use Free software arguments against Free software itself, to ensure nobody would stop them.</p>
<p>The future of what we call today open-source software needs to learn to be in equal parts principled and pragmatic. The principles of human spontaneity must be preserved, to ensure we don’t turn in yet another fast-food chain, but we must understand that sophisticated ethical arguments require an equally sophisticated infrastructure beneath them, as without the latter the former can’t materialize into reality.</p>
<p>We need to keep our communities as much as possible engaged and invested in the success of our projects. The flow of information must be kept open and at high pressure, to ensure that our values and goals are well-understood by the majority of the community. Failing to do that means becoming servants of large donors and opening the community to all kinds of manipulations.</p>
<p>We need to reinvent the way we approach spontaneous collaboration in software and we must understand that it’s not going to be a peaceful process. Maybe it’s my native-american blood talking, but I feel I’m ready to get up close and personal with the world I dealt with for the last 1.5 years, except this time I won’t be wearing formal attire.</p>
<p><strong>I’m joining the Zig Software Foundation as VP of Community and it’s going to be my honor and pleasure to try to make all of this a reality for at least one project.</strong> If you want to follow us on this journey, <a href="https://zig.show/" target="_blank" rel="nofollow noopener noreferrer">join us Saturday 11th on Twitch for the live announcement and first fundraising</a>. It’s going to be fun and, if we hit the corresponding donation goal, I will reveal my (until now) secret recipe for a nice summer pasta. Not as simple as Salvatore’s, but pretty good nevertheless.</p>
<p>You can find more info at <a href="https://zig.show/" target="_blank" rel="nofollow noopener noreferrer">https://zig.show</a>.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/fb329/IMG_5653.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/f5e3c/IMG_5653.webp 100w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/f2fbe/IMG_5653.webp 200w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/e227a/IMG_5653.webp 400w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/965c5/IMG_5653.webp 600w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/0cbce/IMG_5653.webp 800w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/34ef4/IMG_5653.webp 1920w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/5fb09/IMG_5653.jpg 100w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/f544b/IMG_5653.jpg 200w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/41689/IMG_5653.jpg 400w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/82472/IMG_5653.jpg 600w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/a296c/IMG_5653.jpg 800w,
https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/fb329/IMG_5653.jpg 1920w" sizes="(max-width: 400px) 100vw, 400px" type="image/jpeg">
        <img src="https://kristoff.it/static/7ffb8dd2d51fdeda298fa5f212e48bbe/41689/IMG_5653.jpg" alt="A photo I took at the last AWS reinvent." title="Fuck you AWS.">
      </picture>
  </a>
    </span>
    <figcaption>Fuck you AWS.</figcaption>
  </figure></div></div>]]>
            </description>
            <link>https://kristoff.it/blog/addio-redis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23748190</guid>
            <pubDate>Mon, 06 Jul 2020 14:23:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[H.266/Versatile Video Coding (VVC)]]>
            </title>
            <description>
<![CDATA[
Score 434 | Comments 382 (<a href="https://news.ycombinator.com/item?id=23747626">thread link</a>) | @caution
<br/>
July 6, 2020 | https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1 | <a href="https://web.archive.org/web/*/https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://newsletter.fraunhofer.de/-viewonline2/17386/465/11/14SHcBTt/V44RELLZBp/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747626</guid>
            <pubDate>Mon, 06 Jul 2020 13:28:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[M60 – Open-Source USB&BLE, Hot-Swappable Mechanical Keyboard Powered by Python]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23747255">thread link</a>) | @kfihihc
<br/>
July 6, 2020 | https://makerdiary.com/pages/m60-mechanical-keyboard | <a href="https://web.archive.org/web/*/https://makerdiary.com/pages/m60-mechanical-keyboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="PageContainer">

    <main id="MainContent" role="main" tabindex="-1">
      <div id="shopify-section-landing-page-hero"><div data-section-id="landing-page-hero" data-section-type="hero-section">
  
     <a href="https://github.com/makerdiary/python-keyboard" aria-label="View source on GitHub"></a>
  
<div id="Hero-landing-page-hero" data-layout="full_width" data-bg="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_300x300.jpg?v=1593771860" data-bgset="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_180x.jpg?v=1593771860 180w 120h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_360x.jpg?v=1593771860 360w 240h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_540x.jpg?v=1593771860 540w 360h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_720x.jpg?v=1593771860 720w 480h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_900x.jpg?v=1593771860 900w 600h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1080x.jpg?v=1593771860 1080w 720h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1296x.jpg?v=1593771860 1296w 864h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1512x.jpg?v=1593771860 1512w 1008h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1728x.jpg?v=1593771860 1728w 1152h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0_1950x.jpg?v=1593771860 1950w 1300h,
    
    
    
    
    
    
    
    
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60_hero_2048x_168dcced-db74-498b-94f3-01b98f24ada0.jpg?v=1593771860 2048w 1365h" data-sizes="auto" data-parent-fit="cover"><div>
        <div><h2>M60 Mechanical Keyboard</h2><p>An Open Source, USB &amp; BLE 5.0, Modular, Hot-Swappable, 60% Keyboard powered by Python</p><p><a href="https://makerdiary.com/products/m60-mechanical-keyboard-pcba" aria-label="Pre-Order PCBA: M60 Mechanical Keyboard PCBA (Pre-Order)">Pre-Order PCBA</a></p></div>
      </div>
    </div>
    </div>



</div>





<div id="shopify-section-landing-page-map">

<div id="MapSection--landing-page-map" data-section-id="landing-page-map" data-section-type="map">
  <div>
    <div>
      <div>
        
        
          <h3>The Story of M60</h3>
        
        
          <p>A few months ago, we made a hand-wired keyboard and brought Python to it. This project received plenty of attention, but it is difficult for most people to make such a keyboard. We believe that a Python powered keyboard will make a big difference. We'd really like to take this work further, so we start to design a new keyboard hardware. It is called <em>M60</em>.</p>
          
        
      </div>
    </div>
    
  </div>
</div>




</div>

<div>

<div id="shopify-section-landing-page-feature-row">
<div>
  

  <div>
    
      
    <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-connectivity-1_1080x_5c2254bf-6f4a-41b8-a449-1c0f4088f20a_600x600@2x.jpg?v=1593785687" alt="" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-connectivity-1_1080x_5c2254bf-6f4a-41b8-a449-1c0f4088f20a_200x200.jpg?v=1593785687" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-connectivity-1_1080x_5c2254bf-6f4a-41b8-a449-1c0f4088f20a_{width}x.jpg?v=1593785687">

        
      
    </p>
  
    

    <div>
      
        <h2>USB Type-C &amp; BLE 5.0 Connectivity</h2>
      
      
        <p>M60 uses Nordic’s nRF52840 SoC to provide USB Type-C wired and Bluetooth LE 5.0 wireless connectivity. It can easily pair to your PC, laptop, smartphone, or tablet with Bluetooth LE.</p>
      
      
    </div>

    
  </div>
</div>


</div>

<div id="shopify-section-landing-page-feature-row-1">
<div>
  

  <div>
    

    <div>
      
        <h2>Powered by Python</h2>
      
      
        <p>It's not just a keyboard but also a USB drive containing Python files. Its Python code can be changed with any text editor and executed simultaneously, which makes it super easy to customize the keyboard or to add a new function. No need to download any software or setup a development environment.</p>
      
      
    </div>

    
      
    <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-2-python_1_600x600@2x.jpg?v=1593761089" alt="" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-2-python_1_200x200.jpg?v=1593761089" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-2-python_1_{width}x.jpg?v=1593761089">

        
      
    </p>
  
    
  </div>
</div>




</div>

<div id="shopify-section-landing-page-feature-row-2"><div>
  

  <div>
    
      
    <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-3_600x600@2x.jpg?v=1593752688" alt="" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-3_200x200.jpg?v=1593752688" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-feature-row-3_{width}x.jpg?v=1593752688">

        
      
    </p>
  
    

    <div>
      
        <h2>Modular, Hot-Swappable &amp; Solder-Free</h2>
      
      
        <p>To take advantage of the <a href="https://makerdiary.com/products/nrf52840-m2-module" title="nRF52840 M.2 Module w/ PCB Antennas">removable M.2 module</a> and hot-swap sockets, assembly made easy. Everyday we find innovative assembly solutions to make things even easier for you because we care about the quality of our products.</p>
      
      
    </div>

    
  </div>
</div>




</div>



</div>

<div id="shopify-section-landing-page-logo-list">

<div>
  
    
  

  
    <ul>
      
        <li>
          
          
              
          
          
          
            <p>GitHub</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Cross-platform</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Multi-connections</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Python</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>60% Layout</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Multi-layers</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Highly configurable</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>RGB Lighting</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Battery</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>NKRO - Anti-ghost</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Productivity</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Modular Design</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>BLE 5.0</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>USB Type-C</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>NFC</p>
          
        </li>
      
        <li>
          
          
              
          
          
          
            <p>Hot-swappable</p>
          
        </li>
      
    </ul>
  

  
</div>




</div>

<div id="shopify-section-landing-page-hero-small">


<div data-section-id="landing-page-hero-small" data-section-type="hero-section"><div id="Hero-landing-page-hero-small" data-layout="full_width" data-bg="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_300x300.jpg?v=1593684925" data-bgset="//cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_180x.jpg?v=1593684925 180w 65h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_360x.jpg?v=1593684925 360w 130h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_540x.jpg?v=1593684925 540w 194h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_720x.jpg?v=1593684925 720w 259h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_900x.jpg?v=1593684925 900w 324h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1080x.jpg?v=1593684925 1080w 389h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1296x.jpg?v=1593684925 1296w 466h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1512x.jpg?v=1593684925 1512w 544h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1728x.jpg?v=1593684925 1728w 622h,
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x_1950x.jpg?v=1593684925 1950w 702h,
    
    
    
    
    
    
    
    
    //cdn.shopify.com/s/files/1/0066/0865/0355/files/m60-sample-2048x.jpg?v=1593684925 2048w 737h" data-sizes="auto" data-parent-fit="cover"><div>
        <div><p>We have prepared a few M60 PCBAs for developers before launch. If you really want to get involved early in the process, you can apply for an engineering sample.</p><p><a href="https://forms.office.com/Pages/ResponsePage.aspx?id=DQSIkWdsW0yxEjajBLZtrQAAAAAAAAAAAAa__aO1qn1UQktDRjFSN1FWRFRFRU0yRzhOT0xIUlNKSi4u" aria-label="Request a Sample">Request a Sample</a></p></div>
      </div>
    </div>
    </div>



</div>



<div id="shopify-section-landing-page-feature-update">
<div>
  
    
  

    <ul>
      
        <li>
          <article aria-labelledby="FeaturedBlogTitle-0-landing-page-feature-update">
            <header>
              <a href="https://makerdiary.com/blogs/mechanical-keyboards/the-story-of-m60-mechanical-keyboard">
                
                  
                  


                  <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/articles/m60-feature-row-1-1080x_1024x1024_45ae6d5b-e37c-4137-a179-bf1f89d42730_345x345@2x.jpg?v=1593768689" alt="M60 Mechanical Keyboard - from Prototype to Production" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/m60-feature-row-1-1080x_1024x1024_45ae6d5b-e37c-4137-a179-bf1f89d42730_300x300.jpg?v=1593768689" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/m60-feature-row-1-1080x_1024x1024_45ae6d5b-e37c-4137-a179-bf1f89d42730_{width}x.jpg?v=1593768689">
                    </p>
                  
                

                <h3 id="FeaturedBlogTitle-0-landing-page-feature-update">
                  M60 Mechanical Keyboard - from Prototype to Production
                </h3>
              </a>

              

              
                <span>
                  <time datetime="2020-07-03T08:49:00Z">July 3, 2020</time>
                </span>
              
            </header>

            <div>
              <p><span>A few months ago, we made a hand-wired keyboard powered by Python. It's a typical prototype, which got a lot of feedback. So we decided to turn the prototype into production, to make a new keyboard called M60.</span>
                
              </p>

              

              <ul>
                <li>
                  <a href="https://makerdiary.com/blogs/mechanical-keyboards/the-story-of-m60-mechanical-keyboard" aria-label="Read more: M60 Mechanical Keyboard - from Prototype to Production">
                    Read more
                  </a>
                </li>

                
              </ul>
            </div>
          </article>
        </li>
      
        <li>
          <article aria-labelledby="FeaturedBlogTitle-1-landing-page-feature-update">
            <header>
              <a href="https://makerdiary.com/blogs/mechanical-keyboards/a-hand-wired-usb-bluetooth-keyboard-powered-by-python">
                
                  
                  


                  <p><img src="https://cdn.shopify.com/s/files/1/0066/0865/0355/articles/python-inside-keyboard_345x345@2x.png?v=1593765150" alt="Hand-wiring a USB &amp; Bluetooth keyboard powered by Python" data-old-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/python-inside-keyboard_300x300.png?v=1593765150" data-src="//cdn.shopify.com/s/files/1/0066/0865/0355/articles/python-inside-keyboard_{width}x.png?v=1593765150">
                    </p>
                  
                

                <h3 id="FeaturedBlogTitle-1-landing-page-feature-update">
                  Hand-wiring a USB &amp; Bluetooth keyboard powered by Python
                </h3>
              </a>

              

              
                <span>
                  <time datetime="2020-05-04T11:39:00Z">May 4, 2020</time>
                </span>
              
            </header>

            <div>
              <p>Before making this keyboard, I knew Python can be used in a microcontroller thanks to MicroPython and its variant CircuitPython. But I did not know Python can work so well and be so powerful in a keyboard. It's beyond my expectation.</p>

              

              <ul>
                <li>
                  <a href="https://makerdiary.com/blogs/mechanical-keyboards/a-hand-wired-usb-bluetooth-keyboard-powered-by-python" aria-label="Read more: Hand-wiring a USB &amp; Bluetooth keyboard powered by Python">
                    Read more
                  </a>
                </li>

                
              </ul>
            </div>
          </article>
        </li>
      
    </ul>
  

  
    
    
  
</div>




</div>


    </main>

    

    

  </div></div>]]>
            </description>
            <link>https://makerdiary.com/pages/m60-mechanical-keyboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-23747255</guid>
            <pubDate>Mon, 06 Jul 2020 12:42:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How People Learn – The Brain Basics]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23746896">thread link</a>) | @iuliangulea
<br/>
July 6, 2020 | https://iuliangulea.com/blog/how-people-learn-the-brain-basics/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>Have you ever thought about how people learn? What happens inside your brain when you learn some new information or practice a novel skill? And is there a way to enhance the outcomes of learning?</p>
<p>This article is the first in the series on “How People Learn,” in which I invite you to embark on a journey toward a better understanding of the most sophisticated construct in the Universe—the human brain.</p>
<p>And I would like to start with and exercise. You will need a piece of paper and something to write with. When you have them ready, write down the following sentence:</p>
<blockquote>
<p><strong>I can write fast and beautiful.</strong></p>
</blockquote>
<p>It should be pretty easy, if not effortless, isn’t it?</p>
<p>Now, I would like you to write the same sentence one more time, below the first one, but at this time, use the opposite hand (let’s call it the inexperienced hand). Therefore, if you initially wrote the sentence with your right hand, switch your pen to the left side and vice-versa.</p>
<p>Think about how was it now? Unless you are a person that learned to write with both hands, I bet your second sentence is not that beautiful, and you wrote it not that fast either. When I was lecturing at the university and doing this exercise with my students, it took them somewhere between 3 to 10 times longer to write down the second sentence than the first one.</p>
<p>If you did follow through and write the two sentences, I highly encourage you to write it with the inexperienced hand for the third (and last) time below the first two sentences. It should be slightly easier to write it now, but there will still be inadvertent trembling and awkward lines.</p>
<p>How do you explain this? You know how each letter should look, how it should be tilted, and how curved it should be—you possess the theory at 100%. Yet very few can draw a well-rounded letter ‘a’ or ‘o’ with their inexperienced hand. It is very likely that you are also holding your pen as though it weighs 5kg, and your hand is trembling in the process.</p>
<h2 id="a-primer-on-brain-structure">A Primer On Brain Structure</h2>
<p>The answer resides in the structure of the brain. As you might know, the brain consists of brain cells called “neurons.” Let’s represent a neuron as in the next image.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/one-neuron.png" alt="A Conceptual Representation Of A Neuron"></p>
<p>Neurons connect to other neurons, forming a complex net of interconnected brain cells. According to the latest plausible estimates,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> there are 86 billion neurons in a human brain. And each cell can connect to up to ten thousand other neurons. That is an astounding amount!</p>
<p>I will not attempt to draw such a complex, interconnected set of neurons as in a human brain. I will not try to represent even the 302 neurons with its ~7,500 connections of a roundworm.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> Instead, I will rely on this <em>extremely</em> simplified version of a <strike>brain</strike> group of interconnected neurons to describe some essential events that take place inside one’s brain.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/many-interconnected-neurons.png" alt="A Conceptual Representation Of Many Interconnected Neurons"></p>
<p>All our memories, experiences, skills, thoughts, sensations, etc. are encoded and stored within those interconnected brain cells.</p>
<h2 id="neural-patterns">Neural Patterns</h2>
<p>Neurons communicate with each other through electric pulses and chemical neurotransmitters. Whenever we do something or think about something, specific neurons responsible for that action or thought get activated by sending impulses to each other. For instance, when you raise your right hand, a particular group of neurons gets activated simultaneously:</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-raise-hand.png" alt="A conceptual representation of the neural pattern responsible for raising your right hand"></p>
<p>When you write, another group of neurons fires together:</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-write.png" alt="A conceptual representation of the neural pattern responsible for writing"></p>
<p>These groups of neurons that fire together are called <em>neural patterns.</em> When activated, they are responsible for specific actions or thoughts. Keep in mind that the examples above are extremely simplified. Real patterns spread throughout large portions of the brain and can incorporate billions of neurons.</p>
<p>Note that these patterns can overlap, meaning that the same neuron or even huge chunks of neurons can be part of several patterns. Below you can see that <em>“writing”</em> and <em>“raising hand”</em> share some of their neurons.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-common-neurons.png" alt="A conceptual representation of the neurons that participate in both raising hand and speaking"></p>
<p>This explains the associative nature of memory and our experiences—as you are thinking about something specific (i.e., your favorite childhood cartoon), parts of the neural patterns that get activated are also parts of circuits related to other memories. That gives you the possibility to “hop” from one memory to the other. Just try to recall an instance of when you watched that cartoon and let your mind wander for some time. You’ll be pleasantly surprised with where it might lead you.</p>
<h2 id="it-is-not-only-about-the-number-of-connections">It Is Not Only About The Number Of Connections</h2>
<p>Besides the number of neurons, one essential thing that characterizes a pattern is the strength of its connections. A connection can be strong or can be weak, and it represents the relationship between two neurons.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-strong-connections.png" alt="A conceptual representation of a neural pattern with different connection strengths between neurons"></p>
<p>In the image above, the thicker lines represent more durable links. The stronger a bond is, the easier it is to communicate between neurons through it, and the harder and longer it takes to break it apart. We’ll see the implications of this in the next section below.</p>
<p>Therefore, activities that we know how to do and with which we have experience and thoughts that we think about often have strong links between neurons in their associated patterns. Conversely, skills we have just begun to practice, or thoughts we rarely think about have weak circuits.</p>
<p>To make an analogy, think of a link between two neurons as a pathway during winter.</p>
<figure>
    <img src="https://storage.needpix.com/rsynced_images/trace-3438236_1280.jpg" alt="Snow Trail"> <figcaption>
            <p>Source:
                    <a href="https://www.needpix.com/photo/download/1618289/trace-snow-background-mood-wintry-snow-tramp-footprints-snow-lane-deep-snow">Needpix.com</a></p>
        </figcaption>
</figure>

<p>Initially, when you have to go from point A to B, there is no path, so you have to walk through deep snow, leaving a narrow trail in the process. Have you ever walked in deep snow? That is exhausting, and so forming new circuits is. But the more you travel along that path, the more trodden it becomes, and the easier it is to walk it. Eventually, it will become a wide sidewalk that you can use to travel between point A and B effortlessly. But if you will abandon that path, the snow will gradually claim it back, until one day it will just disappear.</p>
<h2 id="the-process-of-forming-new-circuits">The Process Of Forming New Circuits</h2>
<p>Thus, all the information we know and skills we possess are encoded in our brains’ neural patterns. It is time to discuss the process of brain circuits administration. Research from the last 100 years has incredibly advanced the understanding of how the brain rewires itself. This process is called  <em>Neuroplasticity.</em></p>
<blockquote>
<p><strong>Neuroplasticity,</strong> also known as <strong>brain plasticity,</strong> is the ability of the brain to undergo biological changes ranging from the cellular level (i.e., individual neurons) all the way to large-scale changes involving cortical remapping.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
</blockquote>
<p>One of the fundamental principles of how neuroplasticity functions is the idea that individual connections within the brain are continually being created, strengthened, or removed, largely dependent upon how they are used.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Thus, neurons that are in close proximity and fire at the same time tend to form new connections (or, if they are already connected, the link strengthens). But in case a relationship is not used, it weakens over time, and eventually, it disappears, leaving the two neurons disconnected.</p>
<p>This theory was first introduced by Donald Hebb in 1949, and it is often summarized as <em>“neurons that fire together, wire together."</em></p>
<h2 id="going-back-to-writing">Going Back To Writing</h2>
<p>Knowing all that about our brain circuits and how they function, let’s analyze the previous writing exercise and describe it using our freshly acquired information.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/neurons-write-strong-connections.png" alt="Strong neural circuit responsible for writing with the experienced hand"></p>
<p>When you first wrote the sentence with your “regular” hand, you have used your existing, robust neural pattern responsible for writing with that hand. That’s why it felt natural and seamless.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/2-hands-with-question-mark.png" alt="Inexistent neural circuit responsible for writing with the inexperienced hand"></p>
<p>But when you switched to the other hand, no pattern was found responsible for writing with that hand, so a new one started to emerge.</p>
<p><img src="https://iuliangulea.com/images/how-people-learn/2-hands-with-both-patterns.png" alt="Emerging neural circuit responsible for writing with the experienced hand"></p>
<p>Different neurons fired together while you were striving to write each letter, and new links started to form. In case you followed my advice and wrote the sentence for the third time, the writing process should have flown more easygoing. That’s because the new pattern is strengthening in the brain! The more you will practice writing with that hand, the easier it will become for you.</p>
<p>This simple exercise demonstrated a fundamental truth that we sometimes ignore:</p>
<blockquote>
<p><strong>Knowledge != Skills</strong></p>
</blockquote>
<p>We have a sound pattern responsible for the knowledge about each individual letter and another circuit that is responsible for writing those letters. If you would take one thing out of this article, please remember this: <strong>knowledge</strong> does not necessarily mean <strong>skills.</strong> You might know something (the alphabet), but this does not imply than you will be able to write those letters.</p>
<p>This principle applies to many areas of our lives. For instance, reading a book on self-improvement, sales, public speaking, or anything else, does not magically teach you the skills described in those books. Reading those books will strengthen your neuronal pattern related to knowing. It’s like learning the shape of letters, the theory. Only when you begin to write, when you apply the theory into practice, then you start developing the patterns responsible for the actual skills.</p>
<p>There is much more to possessing an ability than just knowing the theory:</p>
<ul>
<li>Knowing the shape of the letters is not enough to be able to write. You need to develop proper muscle movement to hold the pen and draw the lines that form the letters.</li>
<li>Knowing some five steps to efficient sales is not enough to be a salesman. You need to learn to listen to customers, understand what relevant questions to ask, process the information you receive, formulate correct benefits that solve their problems, etc.</li>
<li>Knowing how to write code does is not enough to be a programmer. You need to understand how to define the architecture of a project based on the requirements, how to organize and structure your code, how to test it, etc.</li>
</ul>
<p>It does not mean that the theory is not essential. Conversely, knowledge about a domain helps you gain experience faster since you can interpret how good or bad the outcome of your practice is. As described in <a href="https://iuliangulea.com/blog/the-path-toward-mastery-how-to-become-an-expert/">The Pyramid Of Mastery</a>, knowledge and skills are complementary. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iuliangulea.com/blog/how-people-learn-the-brain-basics/">https://iuliangulea.com/blog/how-people-learn-the-brain-basics/</a></em></p>]]>
            </description>
            <link>https://iuliangulea.com/blog/how-people-learn-the-brain-basics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746896</guid>
            <pubDate>Mon, 06 Jul 2020 11:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Industrial Society and its Future”: the writings of the Unabomber]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 167 (<a href="https://news.ycombinator.com/item?id=23746087">thread link</a>) | @roelp_be
<br/>
July 6, 2020 | https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/ | <a href="https://web.archive.org/web/*/https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Preface to this blog post</h2>



<p>Why review a book from the hand of a notorious terrorist who killed three and maimed dozens of people? That seems like the right question to answer before continuing this blog post. <a href="https://en.wikipedia.org/wiki/Ted_Kaczynski">Theodore J. Kaczynski</a> is an extremely intelligent yet wounded man. He’s been a victim of cold-war era social experiments and, throughout his life, has always been an outsider. He retreated from society and lived like a hermit in the woods in Montana. Nevertheless, he was an activist in search of attention for his ideology and manifesto.</p>



<p>Numerous human lives have been sacrificed on the altars of freedom, ideology, and a better world. Wherever you position yourself on the political spectrum, from left to right, your heroes have blood on their hands. Reagan, Lenin, Bush, Mao, Napoleon, Robespierre, Obama, Chavez, Macron, Selassie, and Guevara, in one way or another, are responsible for the death and suffering of many. Yet we read their memoirs, manifestoes, and biographies. We have their posters on the walls of our children’s rooms. In this light, <strong>the refusal to read and review <em>Industrial Society and its Future</em> would be an act of hypocrisy. </strong></p>



<p>Finally, the central claim that technology is inherently bad for society is of relevance to this blog. I completely distance myself from the man’s actions, but his manifesto definitely struck a chord. I currently cannot think of a better way to scrutinize my techno-optimism than to write about it.</p>



<h2>The Power Process</h2>



<p><em>Industrial Society and its Future</em> is an essay of 232 numbered paragraphs in which Kaczynski explains what’s wrong with society, how it should be, and how we can get there. The most interesting parts of the essay describe the core concept of the <em>Power Process</em>, its consequences, and how technology has an impact on it.</p>



<p><strong>Human drives</strong> can be classified in three broad categories:</p>



<ul><li>Drives that can be satisfied with minimal effort: a walk around the block.</li><li>Drives that can be satisfied at the cost of serious effort: chopping down a tree for burning wood.</li><li>Drives that cannot be satisfied, no matter the effort one puts in it: somersault from a high cliff and survive it</li></ul>



<p>Kaczynski claims that <strong>all humans need a power process</strong>: (1) we all need goals, (2) effort to attain them, and (3) the attainment of some of these goals. Finally, it requires a degree of (4) autonomy. Consequently, the power process is part of the second category of human drives.</p>



<p>If unattained goals result in death, they are important. If the non-attainment of one’s goals is compatible with survival (i.e. not important), it will lead to defeatism, low self-esteem, and depression (as I explain later on). In the Western world, one only needs minimum effort to survive. Satisfying biological needs has been reduced to triviality. One can live off welfare checks, or have a bullshit job to satisfy physical needs. The only thing required is a minimal degree of obedience. Humans have given up autonomy and effort to attain the needs to survive — the important goals.  That’s why humans artificially create the four components of the power process for themselves: they are involved in <strong>surrogate activities</strong>: long-distance running, blogging, collecting stamps, gardening and even pursuing an academic career. </p>



<h2>Technology messes with the power process</h2>



<p>Kaczynski distinguishes between <strong>two kinds of technology</strong>: The first one is <strong>small-scale technology</strong>, like a mill or a water wheel. The second kind is <strong>organization-dependent technology</strong> that requires large-scale social organization: A refrigerator depends on complicated and industrially created parts and requires electricity. The first kind can produce real progress and freedom. The second kind has a negative impact on our freedom: the externalities outweigh the benefits. It’s <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">the prisoner’s dilemma</a> on a global scale.</p>



<p>Since the Industrial Revolution, most new technologies are of the second kind. The wave of <em>smart</em> and <em>connected</em> devices and software that’s heading our way is no different. Algorithms can curate all available information on our timelines, only inviting more and more (fake?) articles to be produced. Autonomous cars are safer and offer the freedom to keep the hands of the wheel. Yet as self-driving cars are simply sensors on wheels, you will have zero privacy regarding your location. Self-service checkouts are supposed to be faster. Yet as supermarket customers more often use them, fewer registers with cashiers will be available, reducing human personal contact. Oh, and you need a loyalty card, which is digital-only, for which you need a smartphone.</p>



<p>Social and psychological problems arise when humans cannot go through the power process. <strong>In modern society, technology (especially of the second kind) tends to push drives into the first group</strong>: gathering food is now <a href="https://www.ubereats.com/">one tap away</a>.  Intimacy can be achieved by <a href="https://tinder.com/">swiping</a> or paying a <a href="https://www.pornhub.com/live">minimum fee</a>. Leisure can be found on <a href="https://www.netflix.com/be-en/">Netflix</a> or <a href="https://store.steampowered.com/">Steam</a>. Turn up the heat by asking your <a href="https://store.google.com/us/magazine/compare_thermostats">Nest</a>. </p>



<p>On the other hand,<strong> technology also moved other drives into the third category</strong>. With urbanization reaching record numbers; experiencing authenticity, harmony, nature, silence, and clean air is nearly impossible for many inhabitants of this planet.</p>



<p><strong>Some important goals that remain in the second category, like achieving status, can no longer be done autonomously</strong>. To reach the highest echelons of the corporate ladder, one needs to adhere to company culture, engage in networking, and pass opaque assessments. A management position is often at the goodwill of another manager, higher up.</p>



<p>The primitive man only had to fear disease and certain aspects of the environment. He could accept this stoically, or invent gods and demons. But these problems weren’t man-made, imposed on them by someone’s decision which he had no impact on. Although many of us create them for themselves, for others,<strong> surrogate activities do not suffice. The results are aggression, mental breakdowns, burnouts, depressions, mid-life crises, and declining fertility.</strong> As decisions are increasingly outsourced to <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"><em>trustworthy </em>and <em>unbiased</em> machines</a> — think<a href="https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html"> facial recognition by police departments</a>, or <a href="https://www.technologyreview.com/2019/01/21/137783/algorithms-criminal-justice-ai/">algorithms sending people to jail</a> — hopelessness and rebellion will only increase.</p>



<p>In modern society, mental health is defined by how one behaves in accord with the needs of the system.</p>



<h2>Technology is a rational response to problems</h2>



<p>A compromise between freedom and technology is impossible because technology is a more powerful social force than the aspiration for freedom. That’s because each new technology appears to be desirable<strong> and only threatens our freedom later on</strong>. Motorized transport allows us to travel a lot farther. Yet once the adoption of cars reaches a critical threshold, one is <em>expected</em> to own a car: Local shops and public services disappear and become centralized in malls and government buildings. The internet allowed us to communicate with each other faster than ever. As companies adopted the internet, one can no longer apply for a job without an internet connection. Technology changes society as to make itself indispensable.</p>



<p>The following words read like a prophecy: “<em>Generally speaking, <strong>technological control over human behavior will probably not be introduced with a totalitarian intention</strong> or even through a conscious desire to restrict human freedom. Each new step in the assertion of control over the humankind will be taken as a rational response to a problem that faces society…”</em></p>



<p>For example, society has given up privacy to battle COVID-19 with apps and track&amp;trace strategies. Facebook promised us freedom of speech and unlimited reach, but without the financial means, you’re <a href="https://blog.hootsuite.com/facebook-algorithm/">shouting in a vacuum</a>. The Patriot Act (and the <a href="https://www.aclu.org/issues/national-security/privacy-and-surveillance/surveillance-under-patriot-act">mass surveillance technology</a> that came with it) was designed to battle terrorism but introduced legal arbitrariness. These three examples were all <strong>rational responses to existing problems but produced unforeseen externalities</strong>.</p>



<p>As technology makes itself indispensable, machines will take care of more and more tasks and “<em>on those who are employed, ever-increasing demands will be placed: the will need more training, more and more ability, and will have to be ever more reliable, conforming and docile, because they will be more and more like cells of a giant organism.</em>“</p>



<p>Think of the swarm of Uber or Lyft drivers who took a short training on how to use the app and are now driving people around in servile silence. Their data feeds the algorithm, and the algorithm thinks for them. <strong>The only thing left is to abide by the system.</strong></p>



<h2>Revolution</h2>



<p>Which brings us to Kaczynski’s “solution”. This topic lacks the depth and cunning analogies that can be found in the earlier chapters. His recipes aren’t new: one can find elements of <a href="https://en.wikipedia.org/wiki/Mikhail_Bakunin">Bakunist</a>, <a href="https://en.wikipedia.org/wiki/Cultural_hegemony">Gramscist</a>, and <a href="https://en.wikipedia.org/wiki/Foco">Debrayist</a> thinking.</p>



<p>Because technology is the strongest social force, <strong>gradual change is impossible</strong>. The only way to break this circle, this slippery slope to servitude to the machine, is a revolution. While the system might collapse under its own internal difficulties, Kaczynski claims we should promote social stress and instability in industrial society. Humanity should return to nature to live in small groups and to be in control of life-and-death issues: food, clothing, shelter, and defense. This is true freedom: the power to control the circumstances of one’s own life. It’s not an ideology, it’s Nature with a big N:</p>



<p><em>“We have no illusions about the feasibility of creating a new, ideal form of society. Our goal is only to destroy the existing form of society.”</em></p>



<h2>Final thoughts</h2>



<p>Manifestos are always dull, so I didn’t expect this book to be an enjoyable read. But quite a lot of insights were so masterfully crafted, that I often had to allow my mind to wander off in a quest to find (counter-)examples and arguments to what I just read. If you’re into political theory, this will be a treat.</p>



<p>Nevertheless, the structure of the book and the order of the chapters seemed strange to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/">https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</a></em></p>]]>
            </description>
            <link>https://www.roelpeters.be/industrial-society-and-its-future-the-intelligent-yet-angry-writings-of-a-terrorist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23746087</guid>
            <pubDate>Mon, 06 Jul 2020 09:26:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker News Design Is Ugly]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23745595">thread link</a>) | @neilpanchal
<br/>
July 6, 2020 | https://neil.computer/notes/hacker-news-design-is-ugly/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/hacker-news-design-is-ugly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        <h2>Hacker News Design is Ugly</h2>
        <p>This thing is straight up ugly. It is too simple, useful, pragmatic, dense and practical. Boring. These days the cool things are purple gradients, lots of negative space and loss of contrast. People on HN keep <a href="https://news.ycombinator.com/item?id=23199603">raving</a> about this design thing but boy they are so wrong.</p><p>Let's fix it.</p><h2 id="current-state">Current State</h2><p>This is what HN front-page looks like when you login. It has absolutely zero pop. Typical engineers, what do they know about design?</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.01-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>Let's make it pop, shall we?</p><h2 id="fixing-hn-design">Fixing HN Design</h2><p>First things first. <em>Padding</em>. When I am bored, running out of ideas, I like to do one thing that usually makes things 10x better. Padding is like a chef's knife in the kitchen. Know how to use it well and you'll be cutting through information rich UI like butter. It is what sets professional designers from these gray-beard types.</p><p>It is difficult to do it right, so please allow me to exemplify the process. First, add padding to the <code>body</code> tag.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.35.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>See the difference? Holy crap. The UI just suddenly started <em>breathing</em>.</p><p>Let's add more spacing between this conjested highly dense information rich piece of shit.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png" alt="" width="1938" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1600w, https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.37.35-PM.png 1938w" sizes="(min-width: 720px) 720px"></figure><p>The color orange is fine with me but it is not gonna get you through the design school and into the real world. The world today demands magenta. Magenta/Purple/Cyan all inspired by Stripe UI since 2015 or so and it really set the standard for a modern color palette. Throw your creativity and objectivity away, the trend dictates what we should choose<em>.</em> May be it PANTONE will come up with a <a href="https://www.pantone.com/color-intelligence/color-of-the-year/color-of-the-year-2020">color of the year</a> and it will change. But as per current design trends, purple is the safe choice.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.53.20-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>BAM. What you didn't notice is I also got rid of all background colors to flatten things a bit. I hate borders which are a graphical device invented to create logical spatial layouts but those things are for boring websites for techy folks.</p><p>Next up. Pro tip: Border-radius. It is not as complicated as it sounds. Simply put, we like to make things rounded as allows us to compete for a one of those web design <a href="https://www.awwwards.com/">awwwards</a> and border-radius is a mandatory requirement before creating a <a href="https://dribbble.com/">dribbble</a> account. So we must comply without the thought of originality.</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.54.51-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>See? It really ties the web page together.</p><p>Those pesky informative sub-titles are jarring as it helps the user too much. Let's make it so that it loses contrast and fades away in the background. As a side effect, it makes the whole thing more minimal. Minimalism at all costs. Try to make things minimal by removing features and neutring functionality - no one will ever notice. </p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png" alt="" width="2598" height="2254" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-05-at-11.55.33-PM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>It looks minimal af.</p><p>That's all folks. Hacker News redesigned. These are the basics but if there is enough interest, I can probably make another tutorial on how to do <em>this</em>:</p><figure><img src="https://neil.computer/content/images/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png" alt="" width="2510" height="2166" srcset="https://neil.computer/content/images/size/w600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 600w, https://neil.computer/content/images/size/w1000/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1000w, https://neil.computer/content/images/size/w1600/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 1600w, https://neil.computer/content/images/size/w2400/2020/07/Screen-Shot-2020-07-06-at-12.05.17-AM.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Until then, go here and browse some more trends to follow at the cost of authenticity, objectivity, originality, reasoning and fundamental understanding of how to design user interfaces: <a href="https://www.google.com/search?q=design+trends+2020">https://www.google.com/search?q=design+trends+2020</a></p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/hacker-news-design-is-ugly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745595</guid>
            <pubDate>Mon, 06 Jul 2020 07:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to process more than 350K requests per month free using 3 free ETA services]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23745223">thread link</a>) | @Gen1us
<br/>
July 5, 2020 | https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.maddevs.io/@meder33kg?source=post_page-----6edc6affface----------------------" rel="noopener"><img alt="Akkozov Meder" src="https://miro.medium.com/fit/c/96/96/2*87H69ujCEx7VLZYSZPQyig.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Estimated time of arrival." src="https://miro.medium.com/max/8000/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg" width="4000" height="2172" srcset="https://miro.medium.com/max/552/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 276w, https://miro.medium.com/max/1104/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 552w, https://miro.medium.com/max/1280/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 640w, https://miro.medium.com/max/1400/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*q9EOHqrYhaLpY1ZIL0C4Qw.jpeg?q=20"></p></div></div></div><figcaption>Estimated time of arrival</figcaption></figure><p id="cce6">This is a story on how to not spend even a penny by using three ETA (estimated time of arrival) services instead of one. Everything is based on my personal experience working as a back-end developer at GoDee project. GoDee is a start-up project that offers booking seats on a bus online. You could find more information about this project here:</p><p id="e338">GoDee is a public transportation service. Bus transportation by GoDee is more convenient than motorbikes common for Southeast Asia and cheaper than a taxi. The app-based system allows users to find an appropriate route, select the time, book the seat, and pay for the ride online. And one of the problems of GoDee is traffic jams that severely impact the user experience. Users get tired of waiting and get annoyed by trying to guess the bus arrival time. So, to make the commuting more convenient, it needed service to calculate the bus’s approximate arrival time, aka ETA.</p><p id="5226">Developing ETA from scratch would take at least a year. So, to speed up the process, GoDee decided to implement the Google Distance Matrix API tool. Later they developed their own Pifia micro-service.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/500/1*vq9Ao08BtAdAMx5OYhbSlA.gif" width="250" height="429" data-old-src="https://miro.medium.com/freeze/max/34/1*vq9Ao08BtAdAMx5OYhbSlA.gif?q=20"></p></div></div></figure><p id="b97d">Over time, the business grew, and the user base increased. We encountered a problem with increasing requests in the Google Distance Matrix API.</p><h2 id="8971">Why is this a problem?</h2><p id="2a4f">Because every request costs money, Google API provides 10.000 free queries per month, after which every 1.000 queries are charged $20. At that time, we had about 150,000 requests per month.</p><p id="7492">My mentor was very dissatisfied with that. And said that system should change caching to store ETA every 30 minutes. At that time, the system sent requests to the Google API every 3 seconds to get fresh data. However, such a caching algorithm wasn’t efficient, since minibuses were stuck in traffic. And so the distance only changed once every ten minutes. There was another nuance. For example, five users are asking for information about the same bus, and this is the same request. The cache solved this type of problem.</p><figure><div></div><figcaption>Сache Code</figcaption></figure><p id="8a43">The cache worked, but not for long since GoDee grew even further and faced the same problem — the number of queries has increased again.</p><p id="9a57">It was decided to replace the Google API with OSRM. Basically, OSRM is a service for building a route based on ETA (this is a rough but the short description, if you need details, here is the <a href="http://project-osrm.org/" target="_blank" rel="noopener">link</a>).</p><blockquote><p id="113f">The Open Source Routing Machine or OSRM is a C++ implementation of a high-performance routing engine for the shortest paths in road networks.</p><p id="15be">Wikipedia.</p></blockquote><p id="97d4">OSRM has one problem: it builds routes and calculates ETA without taking traffic into account. To solve this problem, I started looking for services that can provide information about traffic in the specified part of the city. HERE Traffic was providing the data I needed. After a little study of the documentation, I wrote a small code that gets traffic information every 30 minutes. And to upload traffic information to OSRM, I wrote a small script with the command <code>./osrm-contract data.osrm --segment-speed-file updates.csv</code> (more details <a href="https://github.com/Project-OSRM/osrm-backend/wiki/Traffic" target="_blank" rel="noopener">here</a>).</p><p id="cbda">Math time: every half of the hour, there is a request to HERE to get traffic information this are two requests per hour, that is, a day is 48 requests (24 * 2 = 48) and a month is about ≈ 1.488 (48*31 = 1.488) a year 17.520. Yes, we have these free requests from HERE for 15 years would be enough.</p><figure><div></div><figcaption>Code for getting traffic</figcaption></figure><p id="b1d9">Preliminary tests showed that the service works perfectly, but there is a problem, HERE gives traffic information in “gibberish” and the data does not match the OSRM format. In order for the information to fit, you need to use another service HERE for geocoding + OSRM (for getting points on the map). This is approximately 450.000 requests per month. Later, OSRM was abandoned because the number of requests exceeded the free limit. We didn’t give up and enabled the HERE Distance Matrix API and temporarily removed the Google Distance Matrix API. The logic HERE is simple: we send coordinates from point A to point B and get the bus arrival time.</p><figure><div></div></figure><p id="2e81">After we installed everything on the test server and started checking, we received the first feedback from the testers. They said that ETA reads the time incorrectly. We started looking for the problem, looked at logs (we used Data dog for logs), logs, and tests showed that everything works perfectly. We decided to ask about the problem in a little more detail, and it turned out that if the car is in traffic for 15 minutes, ETA shows the same time. We decided that this is because of the cache because it stores the original time and does not update it for 30 minutes.</p><p id="1d5a">We started looking for the problem, at the beginning we checked the data on the web version of the HERE Distance Matrix API (which is called we go here), everything worked fine, we received the same ETA. This problem was also checked on the google map service. There was no problem. The services themselves show this ETA. We explained everything to testers and businesses, and they accepted everything.</p><p id="18ce">Our team lead suggested connecting another ETA service and returning the Google API as a backup option and writing code with the logic of switching services (the switch was needed if the requests pass the free number of requests).</p><p id="e9c2">The code works the following way:</p><pre><span id="b4e7">val = getCount() // getting the number of queries used</span><span id="9ff9"><em>if</em> getMax() &lt;= val { // checking for the limit of free requests for the service used</span><span id="e935">newService = switchService(s) // // if the limit is reached, switch the service return</span><span id="cae7"><em>return</em> newService(from, to) // giving the logic of the new service </span></pre><p id="054f">We found the following Mapbox service, connected it, installed it, and it worked. As a result, our ETA had:</p><blockquote><p id="625d">“Here” — 250,000 free requests per month<br>Google — 10,000 free requests per month<br>Mapbox — 100,000 free requests per month</p></blockquote><p id="4def">Always look for alternatives, sometimes it happens that the business doesn't want to pay the money for the service and refuses it. As a developer who has worked hard on the service, you should bring the task to real use. This article describes how we were trying to connect more services for the free use of ETA because the business did not want to pay for the service.</p><p id="4330">P.S. As a developer, I believe that if the tool is good and does its job well, then you can pay for the tool’s services (or find Open source projects :D).</p><figure><div></div></figure></div></div></section></div></div>]]>
            </description>
            <link>https://blog.maddevs.io/how-to-make-three-paid-eta-services-one-free-6edc6affface</link>
            <guid isPermaLink="false">hacker-news-small-sites-23745223</guid>
            <pubDate>Mon, 06 Jul 2020 06:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CoreBGP – Plugging in to BGP]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23744167">thread link</a>) | @jordanwhited
<br/>
July 5, 2020 | https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/ | <a href="https://web.archive.org/web/*/https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<hr>
<p><img src="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/cover.png" alt="cover"></p>
<hr>

<p><a href="https://tools.ietf.org/html/rfc4271" target="_blank">BGP</a> is one of many protocols that powers the Internet. Chances are you have heard of it, even if you don’t work in or around the computer networking space. If you aren’t familiar, I’ll try to provide some quick background:</p>
<ul>
<li>BGP is a <a href="https://en.wikipedia.org/wiki/Distance-vector_routing_protocol" target="_blank">distance-vector routing protocol</a> used to disseminate routing information.</li>
<li>A BGP speaker implements a <a href="https://en.wikipedia.org/wiki/Finite-state_machine" target="_blank">finite state machine</a> with 6 states:
<ul>
<li>Idle</li>
<li>Active</li>
<li>Connect</li>
<li>OpenSent</li>
<li>OpenConfirm</li>
<li>Established</li>
</ul>
</li>
<li>Inputs to the BGP FSM include messages, timer events, and administrative events.</li>
<li>Routing information is exchanged via UPDATE messages in the Established state.</li>
<li>BGP is extensible; speakers communicate their capabilities via OPEN messages.</li>
</ul>
<p>Expanding on that last bullet point, it’s difficult to summarize exactly how/where BGP is used due to its flexibility and extensibility. Various <a href="https://ietf.org/about/" target="_blank">IETF</a> Working Groups continue to publish BGP-related RFCs for a protocol that took shape in the early 90s. As the BGP landscape and application widens, we need software that enables us to keep up.</p>
<p>In this post I’ll provide some of my personal experience and history working with BGP, and introduce a new BGP library, <a href="https://github.com/jwhited/corebgp" target="_blank">CoreBGP</a>, which can be used to build the next generation of BGP-enabled applications.</p>

<p>In October of 2010 I attended my first <a href="https://www.nanog.org/" target="_blank">NANOG</a> meeting in Atlanta, GA after accidentally falling into the position of Network Operations Engineer at work. I worked for a modest-sized hosting provider at the time, and was intrigued with BGP. Upon arriving in Atlanta, I vaguely remember some confusion after telling a cab driver that the hotel I needed to be dropped at was on Peachtree St. I later learned that there are 71 streets in Atlanta with a variant of “Peachtree” in their name, according to <a href="https://en.wikipedia.org/wiki/Peachtree_Street#Nomenclature" target="_blank">Wikpedia</a>.</p>
<p>I got where I needed to go, eventually, and the first talk I attended was <a href="https://archive.nanog.org/meetings/nanog50/presentations/Sunday/NANOG50.Talk33.NANOG50-BGP-Techniques.pdf" target="_blank">BGP techniques for Internet Service Providers</a> by <a href="http://www.bgp4all.com.au/" target="_blank">Philip Smith</a>. Philip started with the basics before getting into the techniques used at ISPs. So many light bulbs went off for me during this talk. I have yet to see any other BGP presentation cover such a breadth of information but still do it in a way that is beginner-friendly, useful as a refresher for any expert, and just downright interesting.</p>
<p>Fast-forward 10 years and I’ve gained a fair share of experience operating networks that use BGP. In more recent years I’ve shifted to software engineering where I’ve had the opportunity to implement various BGP-enabled applications for network observability, data analytics, and SDN purposes.</p>
<p>Each time I started a new BGP-enabled app, I had to answer the following question – which existing BGP implementation should be its foundation?</p>

<p>Of the handful of open source BGP implementations out there, I’ve had hands-on experience with projects making use of:</p>
<ul>
<li><a href="https://bird.network.cz/" target="_blank">BIRD</a></li>
<li><a href="https://osrg.github.io/gobgp/" target="_blank">GoBGP</a></li>
<li><a href="https://www.opendaylight.org/what-we-do/odl-platform-overview" target="_blank">OpenDaylight</a></li>
<li><a href="https://www.quagga.net/" target="_blank">Quagga</a></li>
</ul>
<p>BIRD shines where a <a href="https://bird.network.cz/?get_doc&amp;v=20&amp;f=bird-5.html" target="_blank">rich policy language</a> is needed. GoBGP has a <a href="https://github.com/osrg/gobgp/tree/master/api" target="_blank">feature-rich gRPC API</a>, and can be embedded as a library. OpenDaylight’s BGP implementation is part of a larger SDN controller solution and has extensive support for <a href="https://docs.opendaylight.org/en/stable-oxygen/user-guide/bgpcep-guide/bgp/bgp-user-guide-linkstate-family.html" target="_blank">BGP-LS</a>. Quagga can reliably produce <a href="https://tools.ietf.org/html/rfc6396" target="_blank">MRT</a> dumps and has been around a long time, though I believe <a href="https://frrouting.org/" target="_blank">FRRouting</a> is now considered its successor.</p>
<p>These are all mature, established implementations. Some of them are in production at large ISPs, <a href="https://www.digitalocean.com/blog/scaling-droplet-public-networking/" target="_blank">Cloud Providers</a>, and <a href="https://joinup.ec.europa.eu/collection/open-source-observatory-osor/document/bird-manages-routing-worlds-largest-internet-exchanges-bird" target="_blank">Internet Exchange Points</a>. They are purpose-built and make various tradeoffs to suit their use cases (programming language, threading model, data structures, API, etc…).</p>
<p>But what if we are building something that doesn’t line up with the primary use cases of these widely used implementations? We may be locked in to decisions that are ultimately burdensome if we choose to build around them. Swapping in our own data structures for routing tables, or adding a new NLRI is non-trivial. Even if an implementation is intended to be embedded as library, it can still back us into a corner with resource consumption. There’s clearly a need to plug in or hook into specific parts of the BGP FSM, without inheriting decisions that went into a full-blown BGP daemon.</p>
<p>At the 27th IEEE International Conference On Network Protocols (ICNP), a group from the Université catholique de Louvain presented a paper on <code>The Case for Pluginized Routing Protocols</code>:</p>
<blockquote>
<p>Abstract—Routing protocols such as BGP and OSPF are key components of Internet Service Provider (ISP) networks. These protocols and the operator’s requirements evolve over time, but it often takes many years for network operators to convince their different router vendors and the IETF to extend routing protocols. Some network operators, notably in enterprise and datacenters have adopted Software Defined Networking (SDN) with its centralised control to be more agile. We propose a new approach to implement routing protocols that enables network operators to innovate while still using distributed routing protocols and thus keeping all their benefits compared to centralised routing approaches. We extend a routing protocol with a virtual machine that is capable of executing plugins. These plugins extend the protocol or modify its underlying algorithms through a simple API to meet the specific requirements of operators. We modify the OSPF and BGP implementations provided by FRRouting and demonstrate the applicability of our approach with several use cases.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>In their paper they present a method for plugging into a previously mentioned open-source BGP implementation, FRRouting. Plugins exist at a function level, either prior to invocation (PRE), as a replacement (REPLACE), or just before returning (POST). Much of their BGP plugin focus is around the reception of messages, and decisions made shortly after:</p>
<blockquote>
<p>The BGP daemon is also extended similarly. We add insertion points on functions receiving BGP messages from neighbours, on filters and inside the decision process. We also expose specific functions to the plugins that are executed by the uBPF VM.</p>
<p>— <!-- raw HTML omitted -->The Case for Pluginized Routing Protocols<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><!-- raw HTML omitted --></p>
</blockquote>
<p>They take a clever approach with plugin sandboxing by leveraging a user space eBPF VM (<a href="https://github.com/iovisor/ubpf" target="_blank">uBPF</a>) linked to the FRRouting protocol implementation. Each plugin compiles to eBPF bytecode and runs inside of said VM. Plugins can be loaded and unloaded without impacting the primary protocol implementation. Using an eBPF VM also allowed them to utilise all the pre-existing Linux Kernel tooling.</p>
<p>I found this approach inspiring, but still not quite a match for my use cases:</p>
<ul>
<li>Plugins appear to be built around “incoming” events, or messages. What if I want to inject an UPDATE message to a peer irrespective of what FRRouting wants to send?</li>
<li>FRRouting was not built with this plugin model in mind. Changes/Updates to FRRouting will result in a maintenance headache for the VM hook points.</li>
<li>eBPF bytecode is typically compiled from C. Writing C can be time-consuming in comparison to more modern languages.</li>
<li>I need to be an FRRouting expert to do anything non-trivial.</li>
</ul>
<p>This experience and research led me to create CoreBGP, a BGP library that I could re-use across my BGP-enabled applications.</p>

<p>CoreBGP is a BGP library written in Go that implements the BGP FSM with an event-driven, pluggable model. It exposes an API that empowers the user to:</p>
<ul>
<li>send and validate OPEN message capabilities</li>
<li>handle “important” state transitions</li>
<li>handle incoming UPDATE messages</li>
<li>send outgoing UPDATE messages</li>
</ul>
<p>CoreBGP does not decode UPDATE messages (besides header validation), manage a routing table, or send its own UPDATE messages. These responsibilities are all passed down to the user. Therefore, the intended user is someone who wants that responsibility.</p>
<p>The primary building block of CoreBGP is a Plugin, defined by the following interface:</p>
<div><pre><code data-lang="go"><span>// Plugin is a BGP peer plugin.
</span><span></span><span>type</span> Plugin <span>interface</span> {
	<span>// GetCapabilities is fired when a peer's FSM is in the Connect state prior
</span><span></span>	<span>// to sending an Open message. The returned capabilities are included in the
</span><span></span>	<span>// Open message sent to the peer.
</span><span></span>	<span>GetCapabilities</span>(peer <span>*</span>PeerConfig) []<span>*</span>Capability

	<span>// OnOpenMessage is fired when an Open message is received from a peer
</span><span></span>	<span>// during the OpenSent state. Returning a non-nil Notification will cause it
</span><span></span>	<span>// to be sent to the peer and the FSM will transition to the Idle state.
</span><span></span>	<span>//
</span><span></span>	<span>// Per RFC5492 a BGP speaker should only send a Notification if a required
</span><span></span>	<span>// capability is missing; unknown or unsupported capabilities should be
</span><span></span>	<span>// ignored.
</span><span></span>	<span>OnOpenMessage</span>(peer <span>*</span>PeerConfig, capabilities []<span>*</span>Capability) <span>*</span>Notification

	<span>// OnEstablished is fired when a peer's FSM transitions to the Established
</span><span></span>	<span>// state. The returned UpdateMessageHandler will be fired when an Update
</span><span></span>	<span>// message is received from the peer.
</span><span></span>	<span>//
</span><span></span>	<span>// The provided writer can be used to send Update messages to the peer for
</span><span></span>	<span>// the lifetime of the FSM's current, established state. It should be
</span><span></span>	<span>// discarded once OnClose() fires.
</span><span></span>	<span>OnEstablished</span>(peer <span>*</span>PeerConfig, writer UpdateMessageWriter) UpdateMessageHandler

	<span>// OnClose is fired when a peer's FSM transitions out of the Established
</span><span></span>	<span>// state.
</span><span></span>	<span>OnClose</span>(peer <span>*</span>PeerConfig)
}
</code></pre></div><p>Here’s an example Plugin that logs when a peer enters/leaves an established state and when an UPDATE message is received:</p>
<div><pre><code data-lang="go"><span>type</span> plugin <span>struct</span>{}

<span>func</span> (p <span>*</span>plugin) <span>GetCapabilities</span>(c <span>*</span>corebgp.PeerConfig) []<span>*</span>corebgp.Capability {
	caps <span>:=</span> <span>make</span>([]<span>*</span>corebgp.Capability, <span>0</span>)
	<span>return</span> caps
}

<span>func</span> (p <span>*</span>plugin) <span>OnOpenMessage</span>(peer <span>*</span>corebgp.PeerConfig, capabilities []<span>*</span>corebgp.Capability) <span>*</span>corebgp.Notification {
	<span>return</span> <span>nil</span>
}

<span>func</span> (p <span>*</span>plugin) <span>OnEstablished</span>(peer <span>*</span>corebgp.PeerConfig, writer corebgp.UpdateMessageWriter) corebgp.UpdateMessageHandler {
	log.<span>Println</span>(<span>"peer established"</span>)
	<span>// send End-of-Rib
</span><span></span>	writer.<span>WriteUpdate</span>([]<span>byte</span>{<span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>})
	<span>return</span> p.handleUpdate
}

<span>func</span> (p <span>*</span>plugin) <span>OnClose</span>(peer <span>*</span>corebgp.PeerConfig) {
	log.<span>Println</span>(<span>"peer closed"</span>)
}

<span>func</span> (p <span>*</span>plugin) <span>handleUpdate</span>(peer <span>*</span>corebgp.PeerConfig, u []<span>byte</span>) <span>*</span>corebgp.Notification {
	log.<span>Printf</span>(<span>"got update message of len: %d"</span>, <span>len</span>(u))
	<span>return</span> <span>nil</span>
}
</code></pre></div><p>Plugins are attached to peers when they are added to the Server, which manages their lifetime:</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/">https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</a></em></p>]]>
            </description>
            <link>https://www.jordanwhited.com/posts/corebgp-plugging-in-to-bgp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23744167</guid>
            <pubDate>Mon, 06 Jul 2020 02:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What should we do about network-effect monopolies]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23743610">thread link</a>) | @dmnd
<br/>
July 5, 2020 | https://www.benkuhn.net/nwe/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/nwe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Many large companies today are software monopolies that give their product away for free to get monopoly status, then do <a href="https://github.com/uBlockOrigin/uBlock-issues/issues/338#issuecomment-496009417" target="_blank">the</a> <a href="http://www.fbpurity.com/news/important-news-facebooks-legal-team-have-told-me-i-am-banned-from-facebook-because-of-f-b-purity/" target="_blank">most</a> <a href="https://www.theverge.com/2019/6/28/19154220/grubhub-seamless-fake-restaurant-domain-names-commission-fees" target="_blank">horrible</a> <a href="https://www.nytimes.com/wirecutter/blog/amazon-counterfeit-fake-products/" target="_blank">things</a> <a href="https://www.theverge.com/2020/6/16/21293419/hey-apple-rejection-ios-app-store-dhh-gangsters-antitrust" target="_blank">once</a> <a href="https://www.polemicdigital.com/google-amp-go-to-hell/" target="_blank">they’ve</a> <a href="https://thetechnoskeptic.com/yelp-extortion-starring-role/" target="_blank">won</a>. (<a href="https://www.benkuhn.net/skinner/">Previously</a>, <a href="https://www.benkuhn.net/product/">previously</a>.) Can we do anything about this?</p><p>Unfortunately, “you’re the product” is a popular business model for a reason: businesses like Facebook would be really hard to support without them.</p><p>Facebook would be suicidal to charge its users money, because its entire selling point is that everyone uses it, and “everyone” <em>hates</em> paying money. In the US, Facebook makes over $25 per person on ads (<a href="https://www.statista.com/statistics/251328/facebooks-average-revenue-per-user-by-region/" target="_blank">source</a>). Can you imagine if instead of ads they tried to charge people $25 a year?</p><p>Even on the margin, anything that costs Facebook users also makes it less valuable for its remaining users—it’s a negative feedback loop. The same goes for any other site where users create value for other users, like Twitter or Craigslist or Yelp or Wikipedia. (It’s not an accident that these are some of the most stagnant popular websites!)</p><p>In fact, this is a fundamental problem with <a href="https://en.wikipedia.org/wiki/Network_effect" target="_blank">network effects</a> and low marginal costs. If a company wants to maintain a network effect, they need as many users as possible. If their marginal cost is low, then the easiest way to get users is to give the product away. To do that, they have to get paid by someone else. And when they start getting paid by someone else, they’ll inevitably start prioritizing that person’s interests.</p><p>Historically with other network-effect businesses, we’ve addressed this in a few different ways:</p><ul><li><p>regulation (e.g. local utilities)</p></li><li><p>breakups (e.g. Bell)</p></li><li><p>standardization and interoperability (e.g. email, the Web, cryptocurrency)</p></li></ul><p>So far for tech monopolies, people seem to be focused mostly on breakups—e.g. Facebook from Instagram/Whatsapp—but standardization seems to have produced much better outcomes in the past. (I like email and the Web a lot more than National Grid…) I’d be interested to see more exploration of that option!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/nwe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743610</guid>
            <pubDate>Mon, 06 Jul 2020 00:46:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust for JavaScript Developers – Functions and Control Flow]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 73 (<a href="https://news.ycombinator.com/item?id=23743363">thread link</a>) | @rkwz
<br/>
July 5, 2020 | http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/ | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is the third part in a series about introducing the Rust language to JavaScript developers. Here are the past chapters:</p>
<ol>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-tooling-ecosystem-overview/">Tooling Ecosystem Overview</a></li>
<li><a href="http://www.sheshbabu.com/posts/rust-for-javascript-developers-variables-and-data-types/">Variables and Data Types</a></li>
</ol>
<h2 id="Functions"><a href="#Functions" title="Functions"></a>Functions</h2><p>Rust’s function syntax is pretty much similar to the one in JavaScript.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>return</span> income <span>*</span> <span>90</span> <span>/</span> <span>100</span><span>;</span>
<span>}</span></code></pre>
<p>The only difference you might see above is the type annotations for arguments and return values.</p>
<p>The <code>return</code> keyword can be skipped and it’s very common to see code without an explicit return. If you’re returning implicitly, make sure to remove the semicolon from that line. The above function can be refactored as:</p>
<pre><code>fn main() {
  let income = 100;
  let tax = calculate_tax(income);
  println!("{}", tax);
}

fn calculate_tax(income: i32) -&gt; i32 {
<span>- return income * 90 / 100;</span>
<span>+ income * 90 / 100</span>
}</code></pre>
<h2 id="Arrow-Functions"><a href="#Arrow-Functions" title="Arrow Functions"></a>Arrow Functions</h2><p>Arrow functions are a popular feature in modern JavaScript - they allow us to write functional code in a concise way.</p>
<p>Rust has something similar and they are called “Closures”. The name might be a bit confusing and would require getting used to because in JavaScript, closures can be created using both normal and arrow functions.</p>
<p>Rust’s closure syntax is very similar to JavaScript’s arrow functions:</p>
<p><strong>Without arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span><span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>||</span> <span>println!</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>

<span>greet</span><span>(</span><span>)</span><span>;</span> </code></pre>
<p><strong>With arguments:</strong></p>
<pre><code>
<span>let</span> greet <span>=</span> <span>(</span>msg<span>)</span> <span>=</span><span>&gt;</span> console<span>.</span><span>log</span><span>(</span>msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> greet <span>=</span> <span>|</span>msg<span>:</span> <span>&amp;</span>str<span>|</span> <span>println!</span><span>(</span><span>"{}"</span><span>,</span> msg<span>)</span><span>;</span>

<span>greet</span><span>(</span><span>"good morning!"</span><span>)</span><span>;</span> </code></pre>
<p><strong>Returning values:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> a <span>+</span> b<span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> a <span>+</span> b <span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p><strong>Multiline:</strong></p>
<pre><code>
<span>let</span> add <span>=</span> <span>(</span>a<span>,</span> b<span>)</span> <span>=</span><span>&gt;</span> <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<pre><code>
<span>let</span> add <span>=</span> <span><span>|</span>a<span>:</span> i32<span>,</span> b<span>:</span> i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span>
  <span>let</span> sum <span>=</span> a <span>+</span> b<span>;</span>
  <span>return</span> sum<span>;</span>
<span>}</span><span>;</span>

<span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span> </code></pre>
<p>Here’s a cheatsheet:<br><img src="http://www.sheshbabu.com/images/2020-rust-for-javascript-developers-3/image-2.png" alt=""></p>
<p>Closures don’t need the type annotations most of the time, but I’ve added them here for clarity.</p>
<h2 id="If-Else"><a href="#If-Else" title="If Else"></a>If Else</h2><pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> income <span>=</span> <span>100</span><span>;</span>
  <span>let</span> tax <span>=</span> <span>calculate_tax</span><span>(</span>income<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> tax<span>)</span><span>;</span>
<span>}</span>

<span>fn</span> <span>calculate_tax</span><span>(</span>income<span>:</span> i32<span>)</span> <span>-&gt;</span> i32 <span>{</span>
  <span>if</span> income <span>&lt;</span> <span>10</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span> <span>else</span> <span>if</span> income <span>&gt;=</span> <span>10</span> <span>&amp;&amp;</span> income <span>&lt;</span> <span>50</span> <span>{</span>
    <span>return</span> <span>20</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>return</span> <span>50</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Loops"><a href="#Loops" title="Loops"></a>Loops</h2><p>While loops:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> <span>mut</span> count <span>=</span> <span>0</span><span>;</span>

  <span>while</span> count <span>&lt;</span> <span>10</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> count<span>)</span><span>;</span>
    count <span>+=</span> <span>1</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Normal <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for" target="_blank" rel="noopener">for loops</a> don’t exist in Rust, we need to use <code>while</code> or <code>for..in</code> loops. <code>for..in</code> loops are similar to the <code>for..of</code> loops in JavaScript and they loop over an iterator.</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>for</span> n <span>in</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<p>Notice that we’re not iterating directly over the array but instead using the <code>iter</code> method of the array.</p>
<p>We can also loop over <a href="https://doc.rust-lang.org/reference/expressions/range-expr.html" target="_blank" rel="noopener">ranges</a>:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>for</span> n <span>in</span> <span>1</span><span>..</span><span>5</span> <span>{</span>
    <span>println!</span><span>(</span><span>"{}"</span><span>,</span> n<span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre>
<h2 id="Iterators"><a href="#Iterators" title="Iterators"></a>Iterators</h2><p>In JavaScript, we can use array methods like map/filter/reduce/etc instead of <code>for</code> loops to perform calculations or transformations on an array.</p>
<p>For example, here we take an array of numbers, double them and filter out the elements that are less than 10:</p>
<pre><code><span>function</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>*</span> <span>2</span><span>;</span>
  <span>let</span> less_than_ten <span>=</span> <span>(</span>n<span>)</span> <span>=</span><span>&gt;</span> n <span>&lt;</span> <span>10</span><span>;</span>

  <span>let</span> result <span>=</span> numbers<span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_ten<span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>In Rust, we can’t directly use map/filter/etc over vectors, we need to follow these steps:</p>
<ol>
<li>Convert the vector into an iterator using <code>iter</code>, <code>into_iter</code> or <code>iter_mut</code> methods</li>
<li>Chain <code>adapters</code> such as map/filter/etc on the iterator</li>
<li>Finally convert the iterator back to a vector using <code>consumers</code> such as <code>collect</code>, <code>find</code>, <code>sum</code> etc</li>
</ol>
<p>Here’s the equivalent Rust code:</p>
<pre><code><span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> numbers <span>=</span> <span>vec!</span><span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>,</span> <span>5</span><span>]</span><span>;</span>

  <span>let</span> double <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> i32 <span>{</span> n <span>*</span> <span>2</span> <span>}</span><span>;</span>
  <span>let</span> less_than_10 <span>=</span> <span><span>|</span>n<span>:</span> <span>&amp;</span>i32<span>|</span></span> <span>-&gt;</span> bool <span>{</span> <span>*</span>n <span>&lt;</span> <span>10</span> <span>}</span><span>;</span>

  <span>let</span> result<span>:</span> Vec<span>&lt;</span>i32<span>&gt;</span> <span>=</span> numbers<span>.</span><span>iter</span><span>(</span><span>)</span><span>.</span><span>map</span><span>(</span>double<span>)</span><span>.</span><span>filter</span><span>(</span>less_than_10<span>)</span><span>.</span><span>collect</span><span>(</span><span>)</span><span>;</span>

  <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> result<span>)</span><span>;</span> 
<span>}</span></code></pre>
<p>You should be able to understand most of the code above but you might notice few things off here:</p>
<ul>
<li>The usage of <code>&amp;</code> and <code>*</code> in the closure</li>
<li>The <code>Vec&lt;i32&gt;</code> type annotation for the <code>result</code> variable</li>
</ul>
<p>The <code>&amp;</code> is the reference operator and the <code>*</code> is the dereference operator. The <code>iter</code> method instead of copying the elements in the vector, it passes them as references to the next adapter in the chain. This is why we use <code>&amp;i32</code> in the map’s closure (double). This closure returns <code>i32</code> but <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.filter" target="_blank" rel="noopener">filter</a> calls its closure (less_than_10) with reference so that’s why we need to use <code>&amp;i32</code> again. To dereference the argument, we use the <code>*</code> operator. We’ll cover this in more detail in future chapters.</p>
<p>Regarding <code>Vec&lt;i32&gt;</code>, so far we haven’t added type annotations to variables as Rust can infer the types automatically, but for <code>collect</code>, we need to be explicitly tell Rust that we expect a <code>Vec&lt;i32&gt;</code> output.</p>
<p>Aside from map and filter, there are ton of other <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html" target="_blank" rel="noopener">useful adapters</a> that we can use in iterators.</p>
<p>Thanks for reading! Feel free to follow me in <a href="https://twitter.com/sheshbabu" target="_blank" rel="noopener">Twitter</a> for updates :)</p>
</div></div>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-for-javascript-developers-functions-and-control-flow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743363</guid>
            <pubDate>Mon, 06 Jul 2020 00:07:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I’m Writing a Book on Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23743218">thread link</a>) | @gedigi
<br/>
July 5, 2020 | https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/ | <a href="https://web.archive.org/web/*/https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I’ve now been writing a book on <strong>applied cryptography</strong> for a year and a half.
I’m nearing the end of my journey, as I have one last ambitious chapter left to write: next-generation cryptography (a chapter that I’ll use to talk about cryptography that will become more and more practical: post-quantum cryptography, homomorphic encryption, multi-party computation, and zk-SNARKs).</p>
<p>I’ve been asked multiple times <strong>why write a new book about cryptography?</strong> and <strong>why should I read your book?</strong>.
To answer this, you have to understand when it all started…</p>
<h2>Diagrams are everything</h2>
<p>Today if you want to learn about almost anything, you just google it.
Yet, for cryptography, and depending on what you're looking for, resources can be quite lacking.</p>
<p>It all started a long time ago.
For a class, I had to implement a <a href="https://www.paulkocher.com/doc/DifferentialPowerAnalysis.pdf">differential power analysis attack</a>, a breakthrough in cryptanalysis as it was the first side-channel attack to be published.
A differential power analysis uses the power consumption of a device during an encryption to leak its private key.
At the time, I realized that great papers could convey great ideas with very little emphasis on understanding.
I remember banging my head against the wall trying to figure out what the author of the white paper was trying to say.
Worse, I couldn’t find a good resource that explained the paper.
So I banged my head a bit more, and finally I got it.
And then I thought I would help others.
So I drew some diagrams, animated them, and recorded myself going over them.
That was <a href="https://www.youtube.com/watch?v=gbqNCgVcXsM">my first screencast</a>.</p>
<p>This first step in education was enough to make me want to do more.
I started making more of these videos, and started writing more articles about cryptography on this blog (today totaling more than 500 articles).</p>
<p><img alt="we want to know" src="https://www.cryptologie.net/upload/we_want_to_know.png"></p>
<p>I realized early that diagrams were extremely helpful to understand complicated concepts, and that strangely most resources in the field shied away from them.</p>
<p>For example, anyone in cryptography who thinks about AES-CBC would immediately think about the following wikipedia diagram:</p>
<p><img alt="aes cbc" src="https://www.cryptologie.net/upload/600px-CBC_encryption.svg_.png"></p>
<p>So here I was, trying to explain everything I learned, and thinking hard about what sorts of simple diagrams could easily convey these complex ideas.
That’s when I started thinking about a book, years and years before <a href="https://manning.com/">Manning Publications</a> would reach out to me with a book deal.</p>
<h2>The applied cryptographer curriculum</h2>
<p> I hadn’t started cryptography due to a long-life passion.
I had finished a bachelor in theoretical mathematics and didn’t know what was next for me.
I had also been programming my whole life, and I wanted to reconcile the two.
Naturally, I got curious about cryptography, which seemed to have the best of both world, and started reading the different books at my disposal.
I quickly discovered my life's calling.</p>
<p>Some things were annoying me though. In particular, the long introductions that would start with history.
I was only interested in the technicalities, and always had been.
I swore to myself, if I ever wrote a book about cryptography, I would not write a single line on Vigenère ciphers, Caesar ciphers, and others.</p>
<p>And so after applying to the masters of Cryptography at the university of Bordeaux, and obtaining a degree in the subject, I thought I was ready for the world.
Little did I know.
What I thought was a very applied degree actually lacked a lot on the real world protocols I was about to attack.
I had spent a lot of time learning about the mathematics of elliptic curves, but nothing about how they were used in cryptographic algorithms.
I had learned about LFSRs, and ElGamal, and DES, and a series of other cryptographic primitives that I would never see again.</p>
<p>When I started working in the industry at Matasano, which then became NCC Group, my first gig was to audit <a href="https://www.openssl.org/">OpenSSL</a> (the most popular TLS implementation).
Oh boy, did it hurt my brain.
I remember coming back home every day with a strong headache.
What a clusterfuck of a library.
I had no idea at the time that I would years later become a co-author of TLS 1.3.</p>
<p><img alt="sign" src="https://www.cryptologie.net/upload/7._Note_that_digital_signatures_are_specified_with_a_hash_function,_allowing_you_to_.png"></p>
<p>But at that point I was already thinking: this is what I should have learned in school.
The knowledge I’m getting now is what would have been useful to prepare me for the real world.
After all, I was now a security practitioner specialized in cryptography.
I was reviewing real-world cryptographic applications.
I was doing the job that one would wish they had after finishing a cryptography degree.
I implemented, verified, used, and advised on what cryptographic algorithms to use.</p>
<p>This is the reason I’m the first reader of the book I’m writing.
This is what I would have written to my past self in order to prepare me for the real world.</p>
<h2>The use of cryptography is where most of the bugs are</h2>
<p>My consulting job led me to audit many real world cryptographic applications like the <a href="https://www.nccgroup.com/us/about-us/newsroom-and-events/blog/2015/may/openssl-audit/">OpenSSL</a>, the <a href="https://www.nccgroup.trust/globalassets/our-research/us/public-reports/2018/final_public_report_ncc_group_google_encryptedbackup_2018-10-10_v1.0.pdf">encrypted backup system of Google</a>, the <a href="https://blog.cloudflare.com/ncc-groups-cryptography-services-audit-of-tls-1-3/">TLS 1.3 implementation of Cloudflare</a>, the <a href="https://letsencrypt.org/2015/04/14/ncc-group-audit.html">certificate authority protocol of Let’s Encrypt</a>, the <a href="https://www.nccgroup.com/us/our-research/zcash-overwinter-consensus-and-sapling-cryptography-review/">sapling protocol of Zcash</a>, the <a href="https://blog.nucypher.com/security-audits--round-1--3/">threshold proxy re-encryption scheme of NuCypher</a> and dozens and dozens of other real-world cryptographic applications that I unfortunately cannot mention publicly.</p>
<p>Early in my job, I was tasked to audit the custom protocol a big corporation (that I can’t name) had written to encrypt their communications.
It turns out that, they were signing everything but the ephemeral keys, which completely broke the whole protocol (as one could have easily replaced the ephemeral keys).
A rookie mistake from anyone with some experience with secure transport protocols, but something that was missed by people who thought they were experienced enough to roll their own crypto.
I remember explaining the vulnerability at the end of the engagement, and a room full of engineers turning silent for a good 30 seconds.</p>
<p>This story repeated itself many times during my career.
There was this time where while auditing a cryptocurrency for another client, I found a way to forge transactions from already existing ones (due to some ambiguity of what was being signed).
Looking at TLS implementations for another client, I found some subtle ways to break an RSA implementation, which in turned transformed into a white paper (with one of the inventor of RSA) leading to a number of <a href="https://eprint.iacr.org/2018/1173">Common Vulnerabilities and Exposures (CVEs) reported to a dozen of open source projects</a>.
More recently, reading about Matrix as part of writing my book, I realized that their authentication protocol was completely broken, <a href="https://matrix.org/security-disclosure-policy/">leading to a complete break of their end-to-end encryption</a>.</p>
<p><img alt="comic" src="https://www.cryptologie.net/upload/HEY_MERE_S_AN.png"></p>
<p>There’s so many details that can unfortunately collapse under you, when making use of cryptography.
At that point, I knew I had to write something about it.
This is why my book contains many of these anecdotes.</p>
<p>As part of the job, I would review cryptography libraries and applications in a multitude of programming languages.
I discovered bugs (for example <a href="https://cryptologie.net/article/347/my-first-cve-o/?utm_content=buffer5c408&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">CVE-2016-3959</a> in Golang’s standard library), I researched ways that libraries could fool you into misusing them (for example see my paper <a href="https://eprint.iacr.org/2016/644">How to Backdoor Diffie-Hellman</a>), and I advised on what libraries to use.
Developers never knew what library to use, and I always found the answer to be tricky.</p>
<p>I went on to invent the <a href="https://discocrypto.com/">disco protocol</a>, and wrote a fully-featured cryptographic library in less than 1,000 lines of code in several languages.
Disco only relied on two cryptographic primitives: the permutation of SHA-3 and curve25519.
Yes, from only these two things in 1,000 lines of code a developer could do any type of authenticated key exchange, signatures, encryption, MACs, hashing, key derivation, etc.
This gave me a unique perspective as to what a good cryptographic library was supposed to be.</p>
<p>I wanted my book to contain these kind of practical insights.
So naturally, the different chapters contain examples on how to do crypto in different programming languages, using well-respected cryptographic libraries.</p>
<h2>A need for a new book?</h2>
<p>As I was giving <a href="https://www.blackhat.com/us-17/training/beyond-the-beast-a-broad-survey-of-crypto-vulnerabilities.html">one of my annual cryptography training at Black Hat</a>, one student came to me and asked if I could recommend a good book or online course on cryptography.
I remember advising the student to read <a href="http://toc.cryptobook.us/">the book from Boneh &amp; Shoup</a> and <a href="https://crypto.stanford.edu/~dabo/courses/OnlineCrypto/">Cryptography I from Boneh on Coursera</a>.</p>
<p>The student told me “<em>Ah, I tried, it’s too theoretical!</em>”.
This answer stayed with me.
I disagreed at first, but slowly realized that they were right.
Most of these resources were pretty heavy in math, and most developers interacting with cryptography don’t want to deal with math.
 What else was there for them?
The other two somewhat respected resources at the time were Applied Cryptography and Cryptography Engineering (both from Schneier).
But these books were starting to be quite outdated.
Applied Cryptography spent 4 chapters on block ciphers, with a whole chapter on cipher modes of operation but none on authenticated encryption.
Cryptography Engineering had a single mention of elliptic curve cryptography (in a footnote).</p>
<p>On the other hand, many of my videos or blog posts were becoming good primary references for some cryptographic concepts.</p>
<p><strong>I knew I could do something special</strong>.</p>
<p>Gradually, many of my students started becoming interested in cryptocurrencies, asking more and more questions on the subject.
At the same time, I started to audit more and more cryptocurrency applications.
I finally moved to a job at Facebook to work on <a href="https://libra.org/">Libra</a>.
Cryptocurrency was now one of the hottest field to work on, mixing a multitude of extremely interesting cryptographic primitives that so far had seen no real-world use case (zero knowledge proofs, aggregated signatures, threshold cryptography, multi-party computations, consensus protocols, cryptographic accumulators, verifiable random functions, verifiable delay functions, ... the list goes on)</p>
<p><strong>I was now in a unique position</strong>.</p>
<p>I knew I could write something that would tell students, developers, consultants, security engineers, and others, what modern applied cryptography was all about.</p>
<p><img alt="book" src="https://www.cryptologie.net/upload/needs_to_send_a_let.png"></p>
<p>This was going to be a book with very little …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/">https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</a></em></p>]]>
            </description>
            <link>https://www.cryptologie.net/article/504/why-im-writing-a-book-on-cryptography/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743218</guid>
            <pubDate>Sun, 05 Jul 2020 23:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summary: Designing Data-Intensive Applications by Martin Kleppmann]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23743185">thread link</a>) | @hoanhan101
<br/>
July 5, 2020 | https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps | <a href="https://web.archive.org/web/*/https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Principles and practicalities of data systems and how to build data-intensive applications.</p><time datetime="2020-07-05T00:00:00-04:00"> July 5, 2020 · 30 mins read · <a href="https://hoanhan101.github.io/category/System-design-notes">System design notes</a><hr> </time><h2 id="i-4-fundamental-ideas-that-we-need-in-order-to-design-data-intensive-applications">I. 4 fundamental ideas that we need in order to design data-intensive applications.</h2><ul><li>Reliable, scalable, maintainable applications.<ul><li>Reliability means continuing to work correctly, even when things go wrong. Common faults and preventions include:<ul><li>Hardware faults: hard disks crash, blackout, incorrect network configuration,…<ul><li>Add redundancy to individual hardware components to reduce the failure rate.</li><li>As long as we can restore a backup onto a new machine quickly, the downtime is not fatal.</li></ul></li><li>Software faults: bug, out of shared resources, unresponsive service, cascading failure,…<ul><li>There’s no quick solution other than thorough testing, measuring, monitoring, analyzing.</li></ul></li><li>Human errors: design error, configuration error,…<ul><li>Enforce good design, good practice and training.</li><li>Decouple the places where people make the most mistake.</li><li>Automate testing: unit test, integration test, end-to-end test.</li><li>Allow quick recovery rollback strategy.</li><li>Set up details monitoring</li></ul></li></ul></li><li>Scalability describes a system’s ability to cope with increased load.<ul><li>Describing load: requests per second, read/write radio, active users, cache hit rate,…</li><li>Describing performance:<ul><li>When you increase a load parameter, keep system resources unchanged, how is performance affected?</li><li>When you increase a load parameter, how much do you increase the resources if you want to keep performance unchanged?</li></ul></li><li>Approaches for coping with load:<ul><li>Scaling up (vertical scaling): move to a more powerful machine.</li><li>Scaling out (horizontal scaling): distribute the load across different machines.</li></ul></li></ul></li><li>Maintainability focuses on 3 design principles:<ul><li>Operability: make it easy for operation teams to keep the system running smoothly.<ul><li>Provide monitoring system health.</li><li>Support for automation and integration tools.</li><li>Have Good documentation.</li></ul></li><li>Simplicity: make it easy for new engineers to understand the system.<ul><li>Provide good abstraction layers that allow us to extract parts of a large system into well-defined, reusable components.</li></ul></li><li>Evolvability: make it easy for engineers to make changes.<ul><li>Follow agile approach.</li></ul></li></ul></li></ul></li><li>Data models and query languages.<ul><li>Data started out being represented as one big tree, though it wasn’t good for representing many-to-many relationships models, so the relational model was invented.</li><li>However, some applications didn’t fit well into the relational model, non-relational NoSQL was born:<ul><li>Document database: self-contained documents, rare relationships between one model and another.</li><li>Graph database: anything is related to everything.</li></ul></li></ul></li><li>Storage and retrieval.<ul><li>Data structres that power your database:<ul><li>Hash indexes:<ul><li>Basically key-value pairs where each key is mapped to a byte offset in the data file.</li><li>Can also split it into smaller chunks/segments for easy storing.</li><li>Even though it’s easy to understand and implement, it has memory constrains that the hash table must fit in memory. Also range queries are not efficient since hashed keys are not put next to each other.</li></ul></li><li>Sorted String Table (SSTable) and Log-Structured Merge-Tree (LSM-trees):<ul><li>SSTable maintains a list of key-value pairs that is sorted by key.</li><li>The table can also be split into smaller segments and merging is simple as it is sorted.</li><li>Maintaining a sorted structure on disk is possible, though keeping it in memory is easy as we can use a tree data structure such as Red-Black trees or AVL trees (memtable).</li><li>If the database crashes, memtable might be lost though we can keep a separate log for it, inspired by LSM-tree indexing structure.</li></ul></li><li>B-trees:<ul><li>Like SSTables, B-trees keep key-value pairs sorted by key, which allows efficient key-value lookups and range queries.</li><li>Instead of breaking down the database into variable-size segments and always writing sequentially, B-trees break into fixed-size blocks/pages and reading/writing one page at a time.</li><li>Every modification is first written to a write-ahead log (WAL) so that the index can be restored to a consistent state after a crash.</li></ul></li></ul></li><li>Transactional processing or analytic?<ul><li>The basic database access pattern is similar to processing business transaction (create, read, update, delete record), as known as online transaction processing (OLTP).</li><li>Since OLTP are expected to be highly available as they’re critical to the operation of the business, they’re reluctant to let business analysts run ad-hoc analytic queries.</li><li>A data warehouse is a separate database that analysts can query without affecting OLTP operations.<ul><li>Data is extracted from OLTP databases, transformed into an analysis-friendly schema, cleaned up, and then loaded into the data warehouse.</li><li>A big advantage of using a separate data warehouse is that the data warehouse can be optimized for analytic access patterns.</li><li>2 popular schemas that data are stored in are star schema, snowflake schema.</li></ul></li></ul></li><li>Column-oriented storage:<ul><li>In most OLTP databases, storage is laid out in a row-oriented fashion: all the values from one row of a table are stored next to each other. In the column-oriented storage, all the values are stored from each column together instead.</li><li>Since the sequences of values for each column are often look repetitive (distinct values are small), they often lend themselves well to compression.</li></ul></li><li>Aggregation:<ul><li>Since data warehouse queries often involve an aggregate function, such as COUNT, SUM, AVG, MIN or MAX, we can cache these aggregated values that are used often.</li><li>One way of creating such a cache is a materialized view, while data cube is a special case.</li></ul></li></ul></li><li>Encoding and evolution.<ul><li>Formats for encoding data.<ul><li>Many languages come with built-in support for encoding in-memory objects to byte sequences though they are not used because it’s language-specific and don’t show good performance.</li><li>JSON, XML are widely known, supported due to the fact that they are simple, can be used by many languages and have built-in support for web browser. However, there are a lot of ambiguity around the encoding of numbers and they also don’t support binary encoding (compact, efficient encoding). Hence the development of MessagePack, BSON, BJSON, and so on.</li><li>Thrift and Protocol Buffers are binary encoding libraries that require a schema for any data that is encoded, that is clearly defined forward and backward compatibility semantics. They come with a code generation tool that produces classes that implement the schema in various programming languages.</li><li>There’s is also a binary encoding library Avro that is good for processing large files as in Hadoop’s use cases.</li></ul></li><li>Modes of data flow (from one process to anther).<ul><li>Databases: the process writing to the database encodes the data, and the process reading from the database decodes it.</li><li>Calls to services, REST and RPC (gRPC): client encodes a request, server decodes the request and encodes a response, and client finally decodes the response.</li><li>Asynchronous message-passing (RabbitMQ, Apache Kafka): nodes send each other messages that are encoded by the sender and decoded by the recipient.</li></ul></li></ul></li></ul><h2 id="ii-replication-partitioningsharding-transactions-and-what-it-means-to-achieve-consistency-and-consensus-in-a-distributed-system">II. Replication, partitioning/sharding, transactions, and what it means to achieve consistency and consensus in a distributed system.</h2><ul><li>Replication.<ul><li>Why would you want to replicate data?<ul><li>Reduce latency by keeping data geographically close to users.</li><li>Increase availability.</li><li>Increase throughput.</li></ul></li><li>2 types of algorithms are leader-based replication and leaderless replication.</li><li>Leader-based replication:<ul><li>Workflow:<ul><li>One of the replicas is designed as the leader while others are followers.</li><li>Client must send write request to the leader though can send read request to both leader and followers.</li><li>After the leader writes data to its local storage, it sends the changes to all of its followers so that they can self apply accordingly.</li></ul></li><li>An important detail of a replicated system is whether the replication happens synchronously or asynchronously.<ul><li>Even though the advantage of synchronous replication is that followers is that the follower is guaranteed to have an up-to-date data, if the synchronous follower doesn’t respond, the write cannot be processed, thus the leader must block all writes and wait until one is available again.</li><li>It is impractical for all followers to be synchronous so leader-based replication is often configured to be completely asynchronous.</li></ul></li><li>From time to time, you need to set up new followers to increase the number of replicas, or to replace failed nodes. This can usually be done without downtime by maintaining a consistent snapshot of the leader’s database.</li><li>If the follower goes down, it can recover quite easily from its logs that it has received from the leader. Later when it’s able to talk to the leader again, it can request all the missing data and catch up to the leader.</li><li>If the leader goes down, a possible approach is failover: one of the followers needs to be promoted to be the new leader using a consensus algorithm, clients and followers need to be configured to talk to the new leader. However, failover can go wrong as well (two leaders, choosing the right timeout before the leader is declared dead,…) as there are no easy solutions to these.</li><li>Different implementation of replication logs:<ul><li>Statement-based replication: the leader logs every write request that it executes, and sends that statement log to its followers. Even though it seems reasonable, non-deterministic function, such as NOW() to get current date and time, is likely to generate a different value on each replica.</li><li>Write-ahead log (WAL) shipping: similar to B-tree’s approach where every modification is first written to a WAL, besides writing the log to disk, the leader also sends it to its followers so that they can build a copy of the exact same data structures as found on the leader.</li><li>Logical log replication: allow the replication log to be decoupled from the storage engine by using different log formats.</li><li>Trigger-based replication: register a trigger to only replicate subset of the data, or from one kind of database to another and so on.</li></ul></li><li>Replication lags:<ul><li>If the user view the data shortly after making the write, new data may have not yet reach the replica. In this case, we need …</li></ul></li></ul></li></ul></li></ul></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps">https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</a></em></p>]]>
            </description>
            <link>https://hoanhan101.github.io/2020/07/05/design-data-intensive-apps</link>
            <guid isPermaLink="false">hacker-news-small-sites-23743185</guid>
            <pubDate>Sun, 05 Jul 2020 23:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Object Pascal Introduction for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 67 (<a href="https://news.ycombinator.com/item?id=23742999">thread link</a>) | @eatonphil
<br/>
July 5, 2020 | http://newpascal.org/assets/modern_pascal_introduction.html | <a href="https://web.archive.org/web/*/http://newpascal.org/assets/modern_pascal_introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div>
<h2 id="_why">1. Why</h2>
<div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
This is a modified version of the original document from Michalis, because we (authors of <a href="http://newpascal.org/">http://newpascal.org/</a> and <a href="http://synopse.info/">http://synopse.info/</a> ) prefer the "mode delphi" without the "generic" / "specialize" keywords.
</td>
</tr>
</tbody></table>
</div>
<p>There are many books and resources about Pascal out there, but too many of them talk about the old Pascal, without classes, units or generics.</p>
<p>So I wrote this quick introduction to what I call <strong>modern Object Pascal</strong>. Most of the programmers using it don’t really call it <em>"modern Object Pascal"</em>, we just call it  <em>"our Pascal"</em>. But when introducing the language, I feel it’s important to emphasize that it’s a modern, object-oriented language. It evolved a <strong>lot</strong> since the old (Turbo) Pascal that many people learned in schools long time ago. Feature-wise, it’s quite similar to C++ or Java or C#.</p>
<div>
<ul>
<li>
<p>It has all the modern features you expect — classes, units, interfaces, generics…​</p>
</li>
<li>
<p>It’s compiled to a fast, native code,</p>
</li>
<li>
<p>It’s very type safe,</p>
</li>
<li>
<p>High-level but can also be low-level if you need it to be.</p>
</li>
</ul>
</div>
<p>It also has excellent, portable and open-source compiler called the <em>Free Pascal Compiler</em>, <a href="http://freepascal.org/">http://freepascal.org/</a> . And an accompanying IDE (editor, debugger, a library of visual components, form designer) called <em>Lazarus</em> <a href="http://lazarus.freepascal.org/">http://lazarus.freepascal.org/</a> . Myself, I’m the creator of <em>Castle Game Engine</em>, <a href="https://castle-engine.io/">https://castle-engine.io/</a> , which is a cool portable 3D and 2D game engine using this language to create games on many platforms (Windows, Linux, MacOSX, Android, iOS, web plugin).</p>
<p>This introduction is mostly directed at programmers who already have experience in other languages. We will not cover here the meanings of some universal concepts, like <em>"what is a class"</em>, we’ll only show how to do them in Pascal.</p>
</div>
</div>
<div>
<h2 id="_basics">2. Basics</h2>
<div>
<div>
<h3 id="__hello_world_program">2.1. "Hello world" program</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span> 

<span>program</span> MyProgram; 
<span>begin</span>
  Writeln(<span><span>'</span><span>Hello world!</span><span>'</span></span>);
<span>end</span>.</code></pre>
</div>
</div>
<p>This is a complete program that you can <em>compile</em> and <em>run</em>.</p>
<div>
<ul>
<li>
<p>If you use the command-line FPC, just create a new file <code>myprogram.lpr</code> and execute <code>fpc myprogram.lpr</code>.</p>
</li>
<li>
<p>If you use <em>Lazarus</em>, create a new project (menu <em>Project</em> → <em>New Project</em> → <em>Simple Program</em>). Save it as <code>myprogram</code> and paste this source code as the main file. Compile using the menu item <em>Run → Compile</em>.</p>
</li>
<li>
<p>This is a command-line program, so in either case — just run the compiled executable from the command-line.</p>
</li>
</ul>
</div>
<p>The rest of this article talks about the Object Pascal language, so don’t expect to see anything more fancy than the command-line stuff. If you want to see something cool, just create a new GUI project in <em>Lazarus</em> (<em>Project</em> → <em>New Project</em> → <em>Application</em>).
Voila — a working GUI application, cross-platform, with native look everywhere, using a comfortable visual component library. The <em>Lazarus</em> and <em>Free Pascal Compiler</em> come with lots of ready units for networking, GUI, database, file formats (XML, json, images…​), threading and everything else you may need. I already mentioned my cool <em>Castle Game Engine</em> earlier:)</p>
</div>
<div>
<h3 id="_functions_procedures_primitive_types">2.2. Functions, procedures, primitive types</h3>
<div>
<div>
<pre><code data-lang="pascal"><span>{$mode delphi}</span>

<span>program</span> MyProgram;

<span>procedure</span> MyProcedure(<span>const</span> A: Integer);
<span>begin</span>
  Writeln(<span><span>'</span><span>A + 10 is: </span><span>'</span></span>, A + <span>10</span>);
<span>end</span>;

<span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>strings are automatically managed</span><span>'</span></span>;
<span>end</span>;

<span>var</span>
  X: Single;
<span>begin</span>
  Writeln(MyFunction(<span><span>'</span><span>Note: </span><span>'</span></span>));
  MyProcedure(<span>5</span>);

  
  X := <span>15</span> / <span>5</span>;
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X); 
  Writeln(<span><span>'</span><span>X is now: </span><span>'</span></span>, X:<span>1</span>:<span>2</span>); 
<span>end</span>.</code></pre>
</div>
</div>
<p>To return a value from a function, assign something to the magic <code>Result</code> variable. You can read and set the <code>Result</code> freely, just like a local variable.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> MyFunction(<span>const</span> S: <span>string</span>): <span>string</span>;
<span>begin</span>
  Result := S + <span><span>'</span><span>something</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> something more!</span><span>'</span></span>;
  Result := Result + <span><span>'</span><span> and more!</span><span>'</span></span>;
<span>end</span>;</code></pre>
</div>
</div>
<p>You can also treat the function name (like <code>MyFunction</code> in example above) as the variable, to which you can assign. But I would discourage it in new code, as it looks "fishy" when used on the right side of the assignment expression. Just use <code>Result</code> always when you want to read or set the function result.</p>
<p>If you want to call the function itself recursively, you can of course do it. If you’re calling a parameter-less function recursively, be sure to specify the parenthesis (even though in Pascal you can usually omit the parentheses for a parameter-less function), this makes a recursive call to a parameter-less function different from accessing this function’s current result. Like this:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> ReadIntegersUntilZero: <span>string</span>;
<span>var</span>
  I: Integer;
<span>begin</span>
  Readln(I);
  Result := IntToStr(I);
  <span>if</span> I &lt;&gt; <span>0</span> <span>then</span>
    Result := Result + <span><span>'</span><span> </span><span>'</span></span> + ReadIntegersUntilZero();
<span>end</span>;</code></pre>
</div>
</div>
<p>You can call <code>Exit</code> to end the execution of the procedure or function before it reaches the final <code>end;</code>. If you call parameter-less <code>Exit</code> in a function, it will return the last thing you set as <code>Result</code>. You can also use <code>Exit(X)</code> construct, to set the function result and exit <strong>now</strong> — this is just like <code>return X</code> construct in C-like languages.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>function</span> AddName(<span>const</span> ExistingNames, NewName: <span>string</span>): <span>string</span>;
<span>begin</span>
  <span>if</span> ExistingNames = <span><span>'</span><span>'</span></span> <span>then</span>
    Exit(NewName);
  Result := ExistingNames + <span><span>'</span><span>, </span><span>'</span></span> + NewName;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_testing_if">2.3. Testing (if)</h3>
<p>Use <code>if .. then</code> or <code>if .. then .. else</code> to run some code when some condition is satisfied. Unlike in the C-like languages, in Pascal you don’t have to wrap the condition in parenthesis.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A: Integer;
  B: boolean;
<span>begin</span>
  <span>if</span> A &gt; <span>0</span> <span>then</span>
    DoSomething;

  <span>if</span> A &gt; <span>0</span> <span>then</span>
  <span>begin</span>
    DoSomething;
    AndDoSomethingMore;
  <span>end</span>;

  <span>if</span> A &gt; <span>10</span> <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;

  
  B := A &gt; <span>10</span>;
  <span>if</span> B <span>then</span>
    DoSomething
  <span>else</span>
    DoSomethingElse;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> is paired with the last <code>if</code>. So this works as you expect:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;</code></pre>
</div>
</div>
<p>While the example with nested <code>if</code> above is correct, it is often better to place the nested <code>if</code> inside a <code>begin</code> …​ <code>end</code> block in such cases. This makes the code more obvious to the reader, and it will remain obvious even if you mess up the indentation. The improved version of the example is below. When you add or remove some <code>else</code> clause in the code below, it’s obvious to which condition it will apply (to the <code>A</code> test or the <code>B</code> test), so it’s less error-prone.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> A &lt;&gt; <span>0</span> <span>then</span>
<span>begin</span>
  <span>if</span> B &lt;&gt; <span>0</span> <span>then</span>
    AIsNonzeroAndBToo
  <span>else</span>
    AIsNonzeroButBIsZero;
<span>end</span>;</code></pre>
</div>
</div>
</div>
<div>
<h3 id="_logical_relational_and_bit_wise_operators">2.4. Logical, relational and bit-wise operators</h3>
<p>The <em>logical operators</em> are called <code>and</code>, <code>or</code>, <code>not</code>, <code>xor</code>. Their meaning is probably obvious (search for <em>"exclusive or"</em> if you’re unsure what <em>xor</em> does:). They take <em>boolean arguments</em>, and return a <em>boolean</em>. They can also act as <em>bit-wise operators</em> when both arguments are integer values, in which case they return an integer.</p>
<p>The <em>relational (comparison)</em> operators are <code>=</code>, <code>&lt;&gt;</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;=</code>. If you’re accustomed to C-like languages, note that in Pascal you compare two values (check are they equal) using a single equality character <code>A = B</code> (unlike in C where you use <code>A == B</code>). The special <em>assignment</em> operator in Pascal is <code>:=</code>.</p>
<p>The <em>logical (or bit-wise) operators have a higher precedence than relational operators</em>. So you may need to use parenthesis around some expressions.</p>
<p>For example this is a compilation error:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> A = <span>0</span> <span>and</span> B &lt;&gt; <span>0</span> <span>then</span> ... </code></pre>
</div>
</div>
<p>The above fails to compile, because the compiler sees the bit-wise <code>and</code> inside: <code>(0 and B)</code>.</p>
<p>This is correct:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>var</span>
  A, B: Integer;
<span>begin</span>
  <span>if</span> (A = <span>0</span>) <span>and</span> (B &lt;&gt; <span>0</span>) <span>then</span> ...</code></pre>
</div>
</div>
<p>The <em>short-circuit evaluation</em> is used. Consider this expression:</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> MyFunction(X) <span>and</span> MyOtherFunction(Y) <span>then</span>...</code></pre>
</div>
</div>
<div>
<ul>
<li>
<p>It’s guaranteed that <code>MyFunction(X)</code> will be evaluated first.</p>
</li>
<li>
<p>And if <code>MyFunction(X)</code> returns <code>false</code>, then the value of expression is known (the value of <code>false and whatever</code> is always <code>false</code>), and <code>MyOtherFunction(Y)</code> will not be executed at all.</p>
</li>
<li>
<p>Analogous rule is for <code>or</code> expression. There, if the expression is known to be <code>true</code> (because the 1st operand is <code>true</code>), the 2nd operand is not evaluated.</p>
</li>
<li>
<p>This is particularly useful when writing expressions like</p>
<div>
<div>
<pre><code data-lang="pascal"><span>if</span> (A &lt;&gt; <span>nil</span>) <span>and</span> A.IsValid <span>then</span>...</code></pre>
</div>
</div>
<p>This will work OK, even when <code>A</code> is <code>nil</code>.</p>
</li>
</ul>
</div>
</div>
<div>
<h3 id="_testing_single_expression_for_multiple_values_case">2.5. Testing single expression for multiple values (case)</h3>
<p>If a different action should be executed depending on the value of some expression, then the <code>case .. of .. end</code> statement is useful.</p>
<div>
<div>
<pre><code data-lang="pascal"><span>case</span> SomeValue <span>of</span>
  <span>0</span>: DoSomething;
  <span>1</span>: DoSomethingElse;
  <span>2</span>: <span>begin</span>
       IfItsTwoThenDoThis;
       AndAlsoDoThis;
     <span>end</span>;
  <span>3</span>..<span>10</span>: DoSomethingInCaseItsInThisRange;
  <span>11</span>, <span>21</span>, <span>31</span>: AndDoSomethingForTheseSpecialValues;
  <span>else</span> DoSomethingInCaseOfUnexpectedValue;
<span>end</span>;</code></pre>
</div>
</div>
<p>The <code>else</code> clause is optional. When no condition matches, and there’s no <code>else</code>, then nothing happens.</p>
<p>In you come from C-like languages, and compare this with <code>switch</code> statement in these languages, you will notice that there is no automatic <em>fall-through</em>. This is a deliberate blessing in Pascal. You don’t have to remember to place <code>break</code> instructions. In every execution, <em>at most one</em> branch of the <code>case</code> is executed, that’s it.</p>
</div>
<div>
<h3 id="_enumerated_and_ordinal_types_and_sets_and_constant_length_arrays">2.6. Enumerated and ordinal types and sets and constant-length arrays</h3>
<p>Enumerated type in Pascal is a very nice, opaque type. You will probably use it much more often than enums in other languages:)</p>
<div>
<div>
<pre><code data-lang="pascal"><span>type</span>
  TAnimalKind = (akDuck, akCat, akDog);</code></pre>
</div>
</div>
<p>The convention is to prefix the enum names with a two-letter shortcut of type name, hence <code>ak</code> = shortcut for <em>"Animal Kind"</em>. This is a useful convention, since the enum names are in the unit (global) namespace. So by prefixing them with <code>ak</code> prefix, you minimize the chances of collisions with other identifiers.</p>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
The collisions in names are not a show-stopper. It’s Ok for different units to define the same identifier. But it’s a good idea to try to avoid the collisions anyway, to keep code simple to understand and grep.
</td>
</tr>
</tbody></table>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
You can avoid placing enum names in the global namespace by directive <code>{$scopedenums on}</code>. This means you will have to access them qualified by a type name, like <code>TAnimalKind.akDuck</code>. The need for <code>ak</code> prefix disappears in this situation, and you will probably just call the enums <code>Duck, Cat, Dog</code>. This is …</td></tr></tbody></table></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://newpascal.org/assets/modern_pascal_introduction.html">http://newpascal.org/assets/modern_pascal_introduction.html</a></em></p>]]>
            </description>
            <link>http://newpascal.org/assets/modern_pascal_introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742999</guid>
            <pubDate>Sun, 05 Jul 2020 23:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a winning 4K intro in Rust]]>
            </title>
            <description>
<![CDATA[
Score 322 | Comments 81 (<a href="https://news.ycombinator.com/item?id=23742870">thread link</a>) | @Dowwie
<br/>
July 5, 2020 | https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html | <a href="https://web.archive.org/web/*/https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4371838969983872321" itemprop="description articleBody">
<div><p><span>I recently wrote my first 4K intro in Rust and released it at the Nova 2020 where it took first place in the new school intro competition. Writing a 4K intro is quite involved and requires you to master many different areas at the same time. Here I will focus on what I learned about making Rust code as small as possible.</span></p><p><iframe allowfullscreen="" height="322" src="https://www.youtube.com/embed/SIkkYRQ07tU" width="387" youtube-src-id="SIkkYRQ07tU"></iframe></p><p>You can view the demo on<span>&nbsp;</span><a href="https://www.youtube.com/watch?v=SIkkYRQ07tU">youtube</a>, download the executable at<span>&nbsp;</span><a href="https://www.pouet.net/prod.php?which=85924">pouet</a><span>&nbsp;</span>or get the source code from<span>&nbsp;</span><a href="https://github.com/janiorca/sphere_dance">github</a></p><p>A 4K intro is a demo where the entire program ( including any data ) has two be 4096 bytes or less so it is important that the code is as space efficient as possible. Rust has a bit of a reputation for creating bloated executables so I wanted to find out if is possible to create very space efficient code with it.</p><p>The entire intro is written in a combination of Rust and glsl. Glsl is used for rendering everything on screen but Rust does everything else; world creation, camera and object control, creating instruments and playing music etc.</p><p>Some of the features I depend on, such as xargo, are not yet part of stable Rust so I use the nightly rust toolchain. To install and use the nightly toolchain as default you need the following rustup commands.</p><pre data-info="" data-role="codeBlock"><code>rustup toolchain install nightly
rustup default nightly
</code></pre><p>I use<span>&nbsp;</span><a href="http://crinkler.net/">crinkler</a><span>&nbsp;</span>to compress the object file generated by the rust compiler.</p><p>I also used<span>&nbsp;</span><a href="https://github.com/laurentlb/Shader_Minifier">shader minifier</a><span>&nbsp;</span>for pre-processing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>shader to make it smaller and more crinkler friendly. The shader minifier doesn't support output into<span>&nbsp;</span><code>.rs</code><span>&nbsp;</span>files so I ended up using its raw output and manually copying it into my<span>&nbsp;</span><a href="http://shader.rs/">shader.rs</a><span>&nbsp;</span>file. (In hindsight, I should have written something to automate that stage. Or even created a PR for shader minifier)</p><p>The starting point was the proof of concept code I developed earlier (<a href="https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html">https://www.codeslow.com/2020/01/writing-4k-intro-in-rust.html</a>) which I thought was pretty lean at the time. That article also goes into but more detail about setting up the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file and how to use xargo for compiling tiny executable.</p><p>Many of the most effective size optimizations have nothing to do with clever hacks but are the result of rethinking the design.</p><p>My initial design had one part of the code creating the world, including placing the spheres and another part was responsible for moving the spheres. At some point I realized that the sphere placement and sphere moving code were doing very similar things and I could merge them into one sightly more complicated function that did both. Unfortunately, this type of optimization can make the code less elegant and readable.</p><p>At some point you have to look at the compiled assembly code to understand what the code gets compiled into and what size optimizations are worth it. The Rust compiler has a very useful option,<span>&nbsp;</span><code>--emit=asm</code><span>&nbsp;</span>for outputting assembler code. The following command creates a<span>&nbsp;</span><code>.s</code><span>&nbsp;</span>assembly file;</p><pre data-info="" data-role="codeBlock"><code>xargo rustc --release --target i686-pc-windows-msvc -- --emit=asm
</code></pre><p>It is not necessary to be an expert in assembler to benefit from studying the assembler output but it definitely helps to have a basic understanding assembler syntax. The release version uses<span>&nbsp;</span><code>opt-level = "z</code><span>&nbsp;</span>which causes the compiler to optimize for the smallest possible size. This can make it a bit tricky to work out which part of the assembly code corresponds to which part of the Rust code.</p><p>I discovered that the Rust compiler can be surprisingly good at minimizing code; getting rid of unused code and unnecessary parameters and folding code. It can also do some strange things which is why it is essential to occasionally study the resulting assembly code.</p><p>I worked with two versions of the code; one version does logging and allows the viewer to manipulate the camera which is used for creating interesting camera paths. Rust allows you to define<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>that you can use to optionally include bits of functionality. The<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file has a<span>&nbsp;</span><strong>[features]</strong><span>&nbsp;</span>section that lets you declare the available features and their dependencies. My 4K intro has the following section in the<span>&nbsp;</span><code>toml</code><span>&nbsp;</span>file;</p><pre data-info="toml" data-role="codeBlock"><span>[</span><span>features</span><span>]</span>
<span>logger</span> <span>=</span> <span>[</span><span>]</span>
<span>fullscreen</span> <span>=</span> <span>[</span><span>]</span>
</pre><p>Neither of the optional features has dependencies so they effectively work as being conditional compilation flags. The conditional blocks of code are preceded by<span>&nbsp;</span><code>#[cfg(feature)]</code><span>&nbsp;</span>statement. Using features in itself does not make the code smaller but it makes development process much nicer when you easily switch between different feature sets.</p><pre data-info="rust" data-role="codeBlock">        <span>#[cfg(feature = "fullscreen")]</span>
        <span>{</span>
            
        <span>}</span>

        <span>#[cfg(not(feature = "fullscreen"))]</span>
        <span>{</span>
            
        <span>}</span>
</pre><p>Having inspected the compiled code I am certain that only the selected features get included in the compiled code.</p><p>One of the main uses of<span>&nbsp;</span><strong>features</strong><span>&nbsp;</span>was to enable logging and error checking for the debug build. The code loading and compiling the glsl shader failed frequently and without useful error messages it would have been extremely painful to find the problems.</p><p>When putting code inside an<span>&nbsp;</span><code>unsafe{}</code><span>&nbsp;</span>block I sort of assumed that all safety checks would be disabled within this block but this is not true, all the usual checks are still applied and these checks can be expensive.</p><p>By default Rust range checks all array accesses. Take the following Rust code</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> sequence<span>[</span> play_pos <span>]</span><span>;</span>
</pre><p>Before doing the table look up the compiler would insert code that checks that play_pos is not indexing past the end of sequence and panic if that was the case. This adds considerable size to the code as there can be a lot of table look-ups like this.</p><p>Converting the above code into</p><pre data-info="rust" data-role="codeBlock">    delay_counter <span>=</span> <span>*</span>sequence<span>.</span><span>get_unchecked</span><span>(</span> play_pos <span>)</span><span>;</span>
</pre><p>tells the compiler to not perform any range checks and just do the table look-up. This is clearly a potentially dangerous operation and can thus only be performed within an<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code block</p><p>Initially all my loops used the idiomatic rust way of doing loops, using the<span>&nbsp;</span><code>for x in 0..10</code><span>&nbsp;</span>syntax which I just assumed would be compiled into tightest possible loop. Surprisingly, this was not the case. The simplest case;</p><pre data-info="rust" data-role="codeBlock"><span>for</span> x <span>in</span> <span>0</span><span>..</span><span>10</span> <span>{</span>
    
<span>}</span>
</pre><p>would get translated into assembly code that did the following;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    check for loop condition    
    if loop finished, jump to end
    // do code inside loop
    unconditionally jump to loop
end:
</code></pre><p>whereas if did the following rust code</p><pre data-info="rust" data-role="codeBlock"><span>let</span> x <span>=</span> <span>0</span><span>;</span>
<span>loop</span><span>{</span>
    
    x <span>+=</span> <span>1</span><span>;</span>
    <span>if</span> i <span>==</span> <span>10</span> <span>{</span>
        <span>break</span><span>;</span>
    <span>}</span>
<span>}</span>
</pre><p>would get directly compiled into;</p><pre data-info="" data-role="codeBlock"><code>    setup loop variable
loop:
    // do code inside loop
    check for loop condition    
    if loop not finished, jump to loop
end:
</code></pre><p>Note that the loop condition is checked at the end of each loop which makes the unconditional jump unnecessary. This is small space saving for one loop but they do add up when there are 30 loops in the program.</p><p>The other, much harder to understand, problem with the idiomatic Rust loop is that in some cases it the compiler would add some additional iterator setup code that really bloated the code. I never fully understood what triggered this additional iterator setup as it was always trivial to replace the<span>&nbsp;</span><code>for {}</code><span>&nbsp;</span>constructs with a<span>&nbsp;</span><code>loop{}</code><span>&nbsp;</span>construct.</p><p>I spent a lot of time optimizing the<span>&nbsp;</span><code>glsl</code><span>&nbsp;</span>code and one of the best class of optimizations ( which also usually made the code run faster) was to operate on an entire vector at a time instead of operating at a component at a time.</p><p>For example, the ray tracing code use a fast<span>&nbsp;</span><a href="http://www.cse.yorku.ca/~amana/research/grid.pdf">grid traversal algorithm</a><span>&nbsp;</span>to check which parts of the map each ray visits. The original algorithm considers each axis separately but it is possible to rewrite the algorithm so it considers all axes at the same time and does not need any branches. Rust doesn't really have a native vector type like glsl but you can use intrinsics to tell it to use SIMD instructions.</p><p>To use intrinsics I would convert the following code</p><pre data-info="rust" data-role="codeBlock">        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>0</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>0</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>1</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>1</span> <span>]</span><span>*</span>camera_speed<span>;</span>
        global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>[</span> <span>2</span> <span>]</span> <span>+=</span> camera_rot_speed<span>[</span> <span>2</span> <span>]</span><span>*</span>camera_speed<span>;</span>
</pre><p>into</p><pre data-info="rust" data-role="codeBlock">        <span>let</span> <span>mut</span> dst<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        <span>let</span> <span>mut</span> src<span>:</span>x86<span>:</span><span>:</span>__m128 <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_load_ps</span><span>(</span>camera_rot_speed<span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>)</span><span>;</span>
        dst <span>=</span> core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_add_ps</span><span>(</span> dst<span>,</span> src<span>)</span><span>;</span>
        core<span>:</span><span>:</span>arch<span>:</span><span>:</span>x86<span>:</span><span>:</span><span>_mm_store_ss</span><span>(</span> <span>(</span><span>&amp;</span><span>mut</span> global_spheres<span>[</span> CAMERA_ROT_IDX <span>]</span><span>)</span><span>.</span><span>as_mut_ptr</span><span>(</span><span>)</span><span>,</span> dst <span>)</span><span>;</span>
</pre><p>which would be quite a bit smaller ( but a lot less readable ). Sadly, for some reason this broke the debug build while working perfectly on the release build. Clearly, this is a problem with my intrinsics knowledge and not a problem with Rust. This is something I would spend more time on for my next 4K intro as the space saving were significant.</p><p>There are lot of standard Rust crates for loading OpenGL functions but by default they all load a very large set of OpenGL functions. Each loaded function takes up some space because the loader has to know its name. Crinkler does a very good job of compressing this kind of code but it is not able to completely get rid of the overhead so I had to create my own version<span>&nbsp;</span><code>gl.rs</code><span>&nbsp;</span>that only includes the OpenGL functions that are used in the code.</p><p>My first objective was to write a competitive proper 4K intro to prove that language was suitable for scenarios where every single byte counts and you really need low level control. Typically this has been the sole domain of assembler and C. The secondary objective was to write it using idiomatic Rust as much possible.</p><p>I think I was fairly successful on the first objective. At no point during the development did I feel that Rust was holding me back in any way or that I was sacrificing performance or capabilities because I was using Rust rather than C.</p><p>I was less successful on the second objective. There is far too much<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code that doesn't really need to be there.<span>&nbsp;</span><code>Unsafe</code><span>&nbsp;</span>has a corrupting effect; it is very easy to use<span>&nbsp;</span><code>unsafe</code><span>&nbsp;</span>code to quickly accomplish something (like using mutable statics) but once the unsafe code is there it begets more unsafe code and suddenly it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html">https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</a></em></p>]]>
            </description>
            <link>https://www.codeslow.com/2020/07/writing-winning-4k-intro-in-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742870</guid>
            <pubDate>Sun, 05 Jul 2020 23:00:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Poor Man's Cluster]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23742683">thread link</a>) | @FilingTrader
<br/>
July 5, 2020 | http://www.regressionist.com/2020/07/05/poor-mans-cluster/ | <a href="https://web.archive.org/web/*/http://www.regressionist.com/2020/07/05/poor-mans-cluster/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/cluster.jpg 765w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-300x229.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/cluster-624x476.jpg 624w" sizes="(max-width: 765px) 100vw, 765px"></figure>



<p>This part might just be me cargo-culting, but I feel like even a startup quant fund needs a compute cluster. I once even heard a joke that any self-respecting quant should be able expand their computational needs to fill an arbitrarily large number of servers. The cluster I’ve just built is a low-budget clunker, made of a motley bunch of leftover and refurbished servers, linked together with parts off eBay. But I’m very proud of it!</p>



<h2>Maximum compute per dollar</h2>



<div><p>New servers cost a fortune, and only a small fraction of the cost is for the actual CPU. These servers are designed for use cases that cannot tolerate downtime, where the administrators are remote, and where all the hardware and even software must be supported by some company with expensive contracts. In contrast, my cluster is designed only for research. Downtime is ok, as long as no data gets lost and I get get back up and running easily. So, my focus is only on maximizing performance given a limited budget. I’m optimizing for compute per dollar. (Incidentally, I’ve found the <a href="https://www.cpubenchmark.net/cpu_list.php">PassMark CPU mark</a> to accurately reflect how well each CPU can handle my workload.)</p><p>There is a stigma around buying refurbished enterprise grade equipment that I don’t understand. Basic compute servers that cost $25k three years ago now cost only $2.5k, refurbished at places like <a href="https://www.metservers.com/">metservers.com</a> or <a href="https://www.stalliontek.com/">stalliontek.com</a>. Both of these companies provide warranties, too. Even better, these are real servers that already exist and can be shipped to you immediately, rather than waiting months for new ones due to things like worldwide memory shortages. New <a href="https://store.mellanox.com/products/mellanox-mcx515a-ccat-connectx-5-en-network-interface-card-100gbe-single-port-qsfp28-pcie3-0-x16-tall-bracket-rohs-r6.html">Mellanox 100GbE</a> infiniband cards cost $795 each, but on <a href="https://www.ebay.com/sch/i.html?_nkw=Mellanox+ConnectX-3+56GbE&amp;_sacat=0&amp;LH_TitleDesc=0&amp;_osacat=0&amp;_odkw=Mellanox+ConnectX-3+56">eBay 56GbE cards</a> can be bought for $40 each.</p></div>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_front.jpg 598w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_front-300x87.jpg 300w" sizes="(max-width: 598px) 100vw, 598px"></figure>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/R630_back.jpg 594w, http://www.regressionist.com/wp-content/uploads/2020/07/R630_back-300x107.jpg 300w" sizes="(max-width: 594px) 100vw, 594px"></figure>



<h2>NVMe vs. memory</h2>



<p>Memory can really drive up the cost of a server, doubling or tripling the price. I don’t think loading up on RAM is cost-effective at scale. Instead, I recommend NVMe drives as an affordable alternative. Typical RAM for a refurbished Dell R630 server would be DDR4-2133, which has bandwidth of 136Gbps. The Samsung 970 EVO Plus 2TB NVMe drive has a read speed of 28Gbps. With the right software, an old infiniband card can max out its 56Gbps bandwidth by reading simultaneously from NVMe drives on only 2-3 other boxes in the cluster. For my workload, this is close enough to RAM speed that I/O ceases to be a bottleneck, and I can focus on just getting the computations done.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram.png 828w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-300x200.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-768x512.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/nvme_vs_ram-624x416.png 624w" sizes="(max-width: 828px) 100vw, 828px"></figure>



<p>I have also chosen to go with retail NVMe drives. They cost far less than enterprise NVMe drives, and they have the same speed (PCIe Gen 3.0 x4) as all but the very newest enterprise drives. The advantage of enterprise drives is the longer lifetime, measured in hundreds or thousands of Terabytes written). But I tend to read far more than I write. Another advantage is that some enterprise drives are dual-port. This is a high-availability feature that allows two hosts to access the same drive, keeping it connected in case of host failure. But as I’ve said, I don’t need expensive high-availability features.</p>



<h2>Distributed storage</h2>



<p>Having a distributed filesystem simplifies coding on a cluster. It makes it feel almost like just working on one big machine. Each job reads and writes to a shared filesystem that is mounted locally, using traditional posix system calls.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs.png 901w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-300x142.png 300w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-768x364.png 768w, http://www.regressionist.com/wp-content/uploads/2020/07/mfs_and_beegfs-624x296.png 624w" sizes="(max-width: 901px) 100vw, 901px"></figure>



<p>After searching out <a href="http://www.regressionist.com/2020/06/20/reviews-of-distributed-filesystems/">filesystem reviews</a>, I decided to use <strong>MooseFS</strong> for my robust storage. It is easy to configure. It can handle my collection of drives of all sizes, and is robust to the failure of a drive, or even an entire server. It also has a nice browser-based monitoring tool. I have set it up to store one copy of each data chunk on an SSD, and the replicated chunk on a regular spinning disk. The clients are configured to prefer SSD chunkservers, which makes reading reasonably fast. Note: chunkserver labels apply to the whole server, so don’t mix SSDs and HDDs in one server if you want to explicitly prioritize reading from SSDs.</p>



<p>I considered paying for MooseFS Pro, but decided it was too expensive. For a 20TB lifetime license for versions 3.x and 4.x, I was quoted $1,620, or $810 if it was for non-commercial use. The main two benefits of getting a Pro license are 1) getting the high-availability of multiple online master servers instead of just metaloggers, and 2) getting erasure coding for more efficient use of storage space. The erasure coding is interesting to me, but for slow storage, big disks are really cheap. So, storing multiple full copies of a file isn’t such a big deal.</p>



<p>For serious speed, I’ve chosen <strong>BeeGFS</strong> with NVMe drives. BeeGFS supports RDMA (remote direct memory access) with infiniband, so it can move data between boxes without involving the CPUs. It is very fast. It is also relatively easy to configure. I am treating this sort of like volatile storage, and I have not set up “buddy mirrors.” Since I will lose data if my hardware fails, I frequently rsync with the robust storage. I was disappointed to find out that even Pro BeeGFS doesn’t support erasure coding. It would make more sense to use with these expensive NVMe drives. However, erasure coding also slows down both reading and writing. So, I’m ok with giving up robustness in order to have one blazing fast filesystem.</p>



<h2>Conclusion</h2>



<p>Benchmarking a distributed filesystem is complicated and workload-dependent. But everything is working as I hoped. My cluster is mostly hyperconverged, with CPU and storage combined in each server. However, I do have some servers that are clients/CPU only. They are less powerful, so I keep them powered off until needed, to conserve energy. I got an APC AP7911A rack-mount PDU on eBay, so controlling power to the different ports is easy.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/07/apc-1.png 488w, http://www.regressionist.com/wp-content/uploads/2020/07/apc-1-300x225.png 300w" sizes="(max-width: 488px) 100vw, 488px"></figure>



<p>Building a cluster has been a lot of fun, and previously slow processes are now excitingly fast. But I’m anxious to begin real research now, and stop messing around with infrastructure.</p>



<h2>Appendix A, configuring infiniband on CentOS 7</h2>



<p>As a non-HPC guy, learning about infiniband, and getting the network functioning was the hardest part of building the cluster. It took me a long time, and lots of reading and trial-and-error. For that reason, I think it’s worth posting detailed instructions on what eventually worked for me. I don’t believe I’m getting all that is possible out of my infiniband network, but I’m still very pleased with it.</p>



<h3>The cards</h3>



<p>I went with 79DJ3 Mellanox ConnectX-3 CX353A FDR InfiniBand + 56GbE/ 40GbE Single QSFP+ RDMA cards. The most recent ones I ordered on eBay were $35 each. I believe the PCIe lanes cannot handle the full bandwidth of the dual-port cards, which is why I stayed with the simpler single-port card/setup. I did have to order replacement brackets for a couple of my high-profile-PCIe computers.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3.png 785w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-300x186.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-768x476.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/79DJ3-624x387.png 624w" sizes="(max-width: 785px) 100vw, 785px"></figure>



<h3>The cables</h3>



<p>I went with Mellanox MC2207130-0A1 1.5M IB FDR QSFP copper cables for about $20 each. Fiber optic cables are better for long distances, but these passive cables have worked perfectly.</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1024x768.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-300x225.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-768x576.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-1536x1152.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable-624x468.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/FDR_cable.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>The switch</h3>



<p>There are two switches that will work. The first is a small unmanaged switch, the Mellanox SX6005. It runs about $90 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005.png 807w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-300x201.png 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-768x514.png 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6005-624x418.png 624w" sizes="(max-width: 807px) 100vw, 807px"></figure>



<p>The second is the larger, managed, Mellanox SX6036. It runs about $300 used:</p>



<figure><img src="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg" alt="" srcset="http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1024x353.jpg 1024w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-300x103.jpg 300w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-768x264.jpg 768w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-1536x529.jpg 1536w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036-624x215.jpg 624w, http://www.regressionist.com/wp-content/uploads/2020/06/mellanox_SX6036.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>If you have more than one switch involved, you can daisy chain them together. You can even run multiple cables between them, which will reduce the bottleneck between the switches. No special configuration is necessary, just plug in multiple cables, and it will spread the load among them to some degree.</p>



<h3>Subnet manager</h3>



<p>There needs to be exactly one subnet manager for the infiniband network. The managed switch can provide this service, but you need to enable it in the configuration interface. The unmanaged switch cannot provide this service. In that case, you need to run a subnet manager on one server. <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-configuring_the_subnet_manager">It is trivial to install on CentOS 7:</a></p>



<pre><code>yum install opensm
systemctl enable opensm
systemctl start opensm</code></pre>



<h3>Software</h3>



<p>I’m using CentOS 7 on my cluster, because at this time neither MooseFS nor BeeGFS supports CentOS 8. When I first played around with Ubuntu, it was much more difficult to get infiniband working. And I also had to downgrade its kernel to get BeeGFS working. I don’t think it is worth all that hassle, and CentOS 7 is working great.</p>



<pre><code># install packages
yum groupinstall "Infiniband Support"
yum install net-tools mstflint infiniband-diags iperf

# disable firewall
systemctl status firewalld
systemctl stop firewalld
systemctl disable firewalld

# disable SELINUX
nano /etc/selinux/config
# set, then reboot
SELINUX=disabled

# start the RDMA service
systemctl start rdma
systemctl enable rdma</code></pre>



<h3>Updating the card firmware</h3>



<p>After installing the infiniband card, find out the PCI address:</p>



<pre><code># Check the device’s PCI address
lspci | grep Mellanox
# 04:00.0 Network controller: Mellanox Technologies MT27500 Family [ConnectX-3]
# so "04:00.0" is the address</code></pre>



<p>Next, use the PCI address to find the card’s PSID, and note the current firmware version:</p>



<pre><code># Identify the adapter card's PSID (last line of the output)
mstflint -d 04:00.0 q
#Image type:            FS2
#FW Version:            2.32.5100
#FW Release Date:       3.9.2014
#Rom Info:              type=PXE version=3.4.306 proto=IB
#Device ID:             4099
#Description:           Node             Port1            Port2            Sys image
#GUIDs:                 e41d2d0300b2bdc0 e41d2d0300b2bdc1 e41d2d0300b2bdc2 e41d2d0300b2bdc3 
#MACs:                                       e41d2db2bdc1     e41d2db2bdc2
#VSD:                   
#PSID:                  DEL1100001019</code></pre>



<p>Now use the PSID to find the latest firmware version:</p>



<pre><code># Download the firmware BIN file from the Mellanox website that matches your card's PSID:
http://www.mellanox.com/page/firmware_table_dell?mtag=oem_firmware_download
Adapters
Dell EMC ConnectX-3 Firmware Download Center
2.42.5000
079DJ3
DEL1100001019
http://www.mellanox.com/downloads/firmware/fw-ConnectX3-rel-2_42_5000-079DJ3-FlexBoot-3.4.752.bin.zip</code></pre>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.regressionist.com/2020/07/05/poor-mans-cluster/">http://www.regressionist.com/2020/07/05/poor-mans-cluster/</a></em></p>]]>
            </description>
            <link>http://www.regressionist.com/2020/07/05/poor-mans-cluster/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742683</guid>
            <pubDate>Sun, 05 Jul 2020 22:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Triplebyte data download doesn’t give you all your data]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23742473">thread link</a>) | @wolfgang42
<br/>
July 5, 2020 | https://www.linestarve.com/blog/post/triplebyte-data-download/ | <a href="https://web.archive.org/web/*/https://www.linestarve.com/blog/post/triplebyte-data-download/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="<%= page.layout %>-<%= page.slug %>" itemscope="" itemprop="blogPost">
	<div>
		<div>
			<div>
				<p>In May of last year I decided to start looking for a new job, and started by taking <a href="https://triplebyte.com/">Triplebyte</a>’s quiz. Having passed that, I spent the next three months going through the rest of their process, from a <a href="https://triplebyte.com/interview_guide">two-hour remote interview</a> all the way through to final negotiations with the company whose offer I selected. Throughout the process they were extremely competent and helpful, and at the end of it all I had only good things to say about them. They made the whole process go extremely smoothly, answered all the questions I had and gave me a ton of advice on the whole process, and their screening process was not only great from the my perspective but also gave me confidence in the quality of all their candidates.</p>

<p>Then, a little over a month ago, I got an email announcing the upcoming launch of Triplebyte’s new public profiles. I thought they were was a neat idea, and made a note that I should turn mine on next time I started a job hunt. Then someone <a href="https://news.ycombinator.com/item?id=23279837">posted the email on Hacker News</a>, pointing out that buried in the middle of the email was the fact that these new profiles were going to be opt-<em>out,</em> and unless I turned it off in the next week my profile would become public. This understandably caused an uproar, which the Triplebyte CEO Ammon <a href="https://news.ycombinator.com/item?id=23280460">completely misinterpreted</a>, posting a series of <a href="https://news.ycombinator.com/item?id=23280120">inflammatory comments</a> that <a href="https://news.ycombinator.com/item?id=23280472">misunderstood what people were upset about</a> before vanishing. A few days later he came back with a very apologetic email explaining that they weren’t going to go through with it after all, though it received <a href="https://news.ycombinator.com/item?id=23303037">mixed reactions</a>, with a lot of people being concerned that the idea had been considered at all.</p>

<p>In the midst of all this, I submitted a request through the <a href="https://triplebyte.com/privacy-center">Triplebyte privacy center</a> to download my data. (I considered deleting my account, but decided to give them the benefit of the doubt until things settled down.) After approving the request by clicking an email link, I was informed that it might take up to 30 days to complete my request, so I settled down to wait. As the weeks passed, I thought that the sudden influx of requests must have overwhelmed whoever was responsible for gathering the data from all the systems it was stored in.</p>

<p>Then, 36 days after I first submitted the request, I got an email informing me that my data was now ready to be downloaded. I clicked the link in the email, and then another link on the next page, and finally I got—</p>

<p>A 2,917 byte JSON blob.</p>

<p><em>Odd,</em> I thought, <em>that seems like an awfully long time for so little data.</em> (It’s just over 81 bytes per day, in fact, though I realize that’s a silly metric.) Still, I was relieved to know that they hadn’t been gathering reams of data about me behind my back. Scanning over the minified data, it looked like all they had was my address, some information I’d given them about my past jobs and preferred languages, and a couple of recent IP addresses. Seemingly they hadn’t even kept any information at all about my job search with them.</p>

<p>Then I opened up the file in a JSON viewer and gradually realized: <em>this was not all the information they had.</em> It wasn’t even all of the information they were <em>willing to admit</em> they had—it was missing some obvious things, like the text descriptions on the <code>education</code> and <code>work experience</code> objects, which were prominently displayed on my profile page. As far as I can tell, all I got was a sloppy attempt at making it look at a casual glance like they’d given me what I asked for.</p>

<p>This raises serious concerns for me about Triplebyte, even more so than their plan to make profiles public by default, which started this all. That may well have been born of overenthusiastic naïvité, and was quickly rescinded after being exposed to public comment. After that fiasco, though, I would have expected them to double down on making sure that they were taking privacy seriously. They had over a month before sending me this data to fix any issues with the system, and instead they sent me some slapdash attempt at maybe giving me a whiff of my data.</p>

<p>Triplebyte (as they explain in their privacy center) “care deeply about how your personal information is used and shared,” but apparently not enough to actually put effort into getting it right when you ask for it.</p>

<p>(I’ve sent them an email asking what happened to the rest of the data, and will update this post when I get a response. As it’s the weekend I may not hear back for a few days.)</p>

			</div>
		</div>
	</div>
</article></div>]]>
            </description>
            <link>https://www.linestarve.com/blog/post/triplebyte-data-download/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742473</guid>
            <pubDate>Sun, 05 Jul 2020 22:02:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contrarian view on closing files]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 110 (<a href="https://news.ycombinator.com/item?id=23742390">thread link</a>) | @coady
<br/>
July 5, 2020 | https://coady.github.io/posts/closing-files/ | <a href="https://web.archive.org/web/*/https://coady.github.io/posts/closing-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<div>

<div>
<div>
<h2 id="Contrarian-view-on-closing-files.">Contrarian view on closing files.<a href="#Contrarian-view-on-closing-files.">¶</a>
</h2>
<p>It has become conventional wisdom to always explicitly close file-like objects, via context managers.
The <a href="https://google.github.io/styleguide/pyguide.html#311-files-and-sockets">google style guide</a>
is representative:</p>
<blockquote>
<p>Explicitly close files and sockets when done with them.
Leaving files, sockets or other file-like objects open unnecessarily has many downsides, including:</p>
<p>They may consume limited system resources, such as file descriptors.</p>
<ul>
<li>Code that deals with many such objects may exhaust those resources unnecessarily if they're not returned to the system promptly after use.</li>
<li>Holding files open may prevent other actions being performed on them, such as moves or deletion.</li>
<li>Files and sockets that are shared throughout a program may inadvertantly be read from or written to after logically being closed. If they are actually closed, attempts to read or write from them will throw exceptions, making the problem known sooner.</li>
</ul>
<p>Furthermore, while files and sockets are automatically closed when the file object is destructed, tying the life-time of the file object to the state of the file is poor practice, for several reasons:</p>
<ul>
<li>There are no guarantees as to when the runtime will actually run the file's destructor. Different Python implementations use different memory management techniques, such as delayed Garbage Collection, which may increase the object's lifetime arbitrarily and indefinitely.</li>
<li>Unexpected references to the file may keep it around longer than intended (e.g. in tracebacks of exceptions, inside globals, etc).</li>
</ul>
<p>The preferred way to manage files is using the "with" statement:</p>

<pre><code>with open("hello.txt") as hello_file:
    for line in hello_file:
        print line</code></pre>
</blockquote>
<h3 id="In-theory">In theory<a href="#In-theory">¶</a>
</h3>
<p>Good points, and why limit this advice to file descriptors?  Any resource may be limited or require exclusivity;  that's why they're called resources.  Similarly one should always explicitly call <code>dict.clear</code> when finished with a <code>dict</code>.  After all, "there are no guarantees as to when the runtime will actually run the &lt;object's&gt; destructor.  And "code that deals with many such objects may exhaust those resources unnecessarily", such as memory, or whatever else is in the <code>dict</code>.</p>
<p>But in all seriousness, this advice is applying a notably higher standard of premature optimization to file descriptors than to any other kind of resource.  There are plenty of Python projects that are guaranteed to run on CPython for a variety of reasons, where destructors are immediately called.  And there are plenty of Python projects where file descriptor usage is just a non-issue.  It's now depressingly commonplace to see this in <code>setup.py</code> files:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>with</span> <span>open</span><span>(</span><span>"README.md"</span><span>)</span> <span>as</span> <span>readme</span><span>:</span>
    <span>long_description</span> <span>=</span> <span>readme</span><span>.</span><span>read</span><span>()</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<p>Let's consider a practical example: a <code>load</code> function which is supposed to read and parse data given a file path.</p>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>import</span> <span>csv</span>
<span>import</span> <span>json</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly bad way"""</span>
    <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>open</span><span>(</span><span>filepath</span><span>))</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""the supposedly good way"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>file</span><span>)</span>

<span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>"""with a different file format"""</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>return</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Which versions work correctly?  Are you sure?  If it's not immediately obvious why one of these is broken, that's the point.  In fact, it's worth trying out before reading on.</p>
<p>...</p>
<p>The <code>csv</code> version returns an iterator over a closed file.  It's a violation of procedural abstraction to know whether the result of <code>load</code> is lazily evaluated or not; it's just supposed to implement an interface.  Moreover, according to this best practice, it's <em>impossible</em> to write the <code>csv</code> version correctly.  As absurd as it sounds, it's just an abstraction that can't exist.</p>
<p>Defiantly clever readers are probably already trying to fix it.  Maybe like this:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>yield from</span> <span>csv</span><span>.</span><span>reader</span><span>(</span><span>file</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>No, it will not be fixed.  This version only appears to work by <em>not</em> closing the file until the generator is exhausted or collected.</p>
<p>This trivial example has deeper implications.  If one accepts this practice, then one must also accept that storing a file handle anywhere, such as on an instance, is also disallowed.  Unless of course that object then virally implements it owns context manager, ad infinitum.</p>
<p>Furthermore it demonstrates that often the context is not being managed locally.  If a file object is passed another function, then it's being used outside of the context.  Let's revisit the <code>json</code> version, which works because the file is fully read.  Doesn't a json parser have some expensive parsing to do after it's read the file?  It might even throw an error.  And isn't it desirable, trivial, <a href="https://github.com/python/cpython/blob/master/Lib/json/__init__.py#L274">and likely</a> that the implementation releases interest in the file as soon as possible?</p>
<p>So in reality there are scenarios where the supposedly good way could keep the file open <em>longer</em> than the supposedly bad way.  The original inline version does exactly what it's supposed to do: close the file when all interested parties are done with it.  Python uses garbage collection to manage shared resources.  Any attempt to pretend otherwise will result in code that is broken, inefficient, or reinventing reference counting.</p>
<p>A true believer now has to accept that <code>json.load</code> is a useless and dangerous wrapper, and that the only correct implementation is:</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>def</span> <span>load</span><span>(</span><span>filepath</span><span>):</span>
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
        <span>contents</span> <span>=</span> <span>file</span><span>.</span><span>read</span><span>()</span>
    <span>return</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>contents</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>This line of reasoning reduces to the absurd: a file should never be passed or stored anywhere.  Next an example where the practice has caused real-world damage.</p>
<h3 id="In-practice">In practice<a href="#In-practice">¶</a>
</h3>
<p><a href="https://requests.readthedocs.io/en/master/">Requests</a> is one of the most popular python packages, and <a href="https://docs.python.org/3/library/http.client.html#module-http.client">officially recommended</a>.  It includes a <a href="http://requests.readthedocs.org/en/latest/user/advanced/#session-objects">Session</a> object which supports closing via a context manager.  The vast majority of real-world code uses the the top-level functions or single-use sessions.</p>

</div>
</div>
</div>
<div>
<div>
<p>In&nbsp;[&nbsp;]:</p>
<div>
    <div>
<div><pre><span></span><span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>

<span>with</span> <span>requests</span><span>.</span><span>Session</span><span>()</span> <span>as</span> <span>session</span><span>:</span>
    <span>response</span> <span>=</span> <span>session</span><span>.</span><span>get</span><span>(</span><span>...</span><span>)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div>

<div>
<div>
<p>Sessions manage the connection pool, so this pattern of usage is establishing a new connection every time.  There are popular standard API clients which seriously do this, for every single request to the same endpoint.</p>
<p>Requests' documentation prominently states that "Keep-alive and HTTP connection pooling are 100% automatic".  So part of the blame may lay with that phrasing, since it's only "automatic" if sessions are reused.  But surely a large part of the blame is the dogma of closing sockets, and therefore sessions, explicitly.
The whole point of a connection pool is that it may leave connections open, so users who genuinely need this granularity are working at the wrong abstraction layer.  <code>http.client</code> is already builtin for that level of control.</p>
<p>Tellingly, requests' own top-level functions didn't always close sessions.  There's a long history to that code, including a <a href="https://github.com/kennethreitz/requests/commit/3155bc99362a8c6ab136b6a3bb999732617cd2e5">version that only closed sessions on success</a>.  An older version was <a href="https://github.com/kennethreitz/requests/issues/1882">causing warnings</a>, when run to check for such warnings, and was being blamed for the <em>appearance</em> of <a href="https://github.com/kennethreitz/requests/issues/1685">leaking memory</a>.  Those threads are essentially debating whether a resource pool is "leaking" resources.</p>

</div>
</div>
</div>
<div>

<div>
<div>
<h3 id="Truce">Truce<a href="#Truce">¶</a>
</h3>
<p>Prior to <code>with</code> being introduced in Python 2.5, it was <em>not</em> recommended that inlined reading of a file required a <code>try... finally</code> block.  Far from it, in the past idioms like <code>open(...).read()</code> and <code>for line in open(...)</code> were lauded for being succinct and expressive.  But if all this orphaned file descriptor paranoia was well-founded, it would have been a problem back then too.</p>
<p>Finally, let's address readability.  It could be argued (though it rarely is) that showing the reader when the file is closed has inherent value.  Conveniently, that tends to align with having opened the file for writing anyway, thereby needing an reference to it.  In which case, the readability is approximately equal, and potential pitfalls are more realistic.  But readability is genuinely lost when the file would have been opened in a inline expression.</p>
<p>The best practice is unjustifiably special-casing file descriptors, and not seeing its own reasoning through to its logical conclusion.  This author proposes advocating for <em>anonymous read-only</em> <code>open</code> expressions.  Your setup script is not going to run out of file descriptors because you wrote <code>open("README.md").read()</code>.</p>

</div>
</div>
</div>
</div>
    </div></div>]]>
            </description>
            <link>https://coady.github.io/posts/closing-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23742390</guid>
            <pubDate>Sun, 05 Jul 2020 21:50:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The key points of Software Design X-Rays]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23741261">thread link</a>) | @nicoespeon
<br/>
July 5, 2020 | https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/ | <a href="https://web.archive.org/web/*/https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>How do you analyze a very large Legacy codebase?</p><p>Where do you start when your system is distributed across dozens of micro-services?</p><p>How do you identify development bottlenecks and prioritize refactoring?</p><p>In his book <!-- -->[Software Design X-Rays]<!-- -->(<a href="https://www.google.com/search?q=software+design+x-rays&amp;oq=soft">https://www.google.com/search?q=software+design+x-rays&amp;oq=soft</a>, Adam Tornhill presents a very unique approach to answer these questions. It’s a mix of software architecture and human psychology that generates powerful techniques to tackle large codebases.</p><p>Yet, I realized it’s not a very known book.</p><blockquote><p>I’ve read <a href="https://www.google.com/search?q=your+code+as+a+crime+scene">Your Code as a Crime Scene</a> from the same guy. How is this different?</p></blockquote><p>Well, “Software Design X-Rays” was written after “Your Code as a Crime Scene”. While the forensics flavor of the book was fun and all, Adam stopped referring it too much to avoid getting the reader distracted. The content is much more polished!</p><p>Let me give you my summary of what’s inside the book and why I think it can help you:</p><h2 id="tackle-technical-debt-with-behavioral-code-analysis"><a href="#tackle-technical-debt-with-behavioral-code-analysis" aria-label="tackle technical debt with behavioral code analysis permalink"></a>Tackle Technical Debt with Behavioral Code Analysis</h2><p>The book focuses on giving you the answers to these 3 questions:</p><ol><li>Where’s the code with the higher interest rate?</li><li>Does your architecture support the way your system evolves?</li><li>Are there any productivity bottlenecks for inter-team coordination?</li></ol><p>To do so, Adam presents a technique called <strong>Behavioral Code Analysis</strong>. It uses the information contained in your Version Control System (VCS) to help you make smart decisions on large codebases.</p><h3 id="identify-your-system-hotspots"><a href="#identify-your-system-hotspots" aria-label="identify your system hotspots permalink"></a>Identify your system Hotspots</h3><p>Technical Debt isn’t really a problem if you don’t have to maintain it.</p><p>Static analysis tools consider all debt to be equivalent. They report countless of code smells that you have no choice but to focus on the critical ones. Still, that leaves plenty of things to clean up!</p><p>That’s why you should use the time dimension to identify <strong>Hotspots</strong>: places where you should focus the Refactor efforts in a large codebase if you want to be super effective.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="hotspots" title="" src="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png" srcset="https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/00d96/hotspots.png 148w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/0b23c/hotspots.png 295w,https://understandlegacycode.com/static/019e5f99d9ed31fd581770a1835f8ba1/4cf67/hotspots.png 572w" sizes="(max-width: 572px) 100vw, 572px">
    </span>
  </span>
  
  </a>
    </undefined></p><p><undefined>
  <a href="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="code that matters" title="" src="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png" srcset="https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/00d96/code-that-matters.png 148w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/0b23c/code-that-matters.png 295w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/799d3/code-that-matters.png 590w,https://understandlegacycode.com/static/00cdf44baa120d7c01e6f6c9536df456/11d19/code-that-matters.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>If you want to learn how to generate and use these, I presented the technique in details:</p><ul><li><a href="https://understandlegacycode.com/blog/focus-refactoring-with-hotspots-analysis">Focus refactoring on what matters with Hotspots Analysis</a></li><li><a href="https://understandlegacycode.com/blog/convince-management-to-address-tech-debt-with-enclosure-diagrams">Convince managers to address Tech Debt with Enclosure Diagrams</a></li></ul><p>Interestingly, hotspots tend to stay here because people are afraid to tackle them. So they attract even more complexity and become problematic bottlenecks.</p><h3 id="loc-a-simple-and-efficient-indicator-of-code-complexity"><a href="#loc-a-simple-and-efficient-indicator-of-code-complexity" aria-label="loc a simple and efficient indicator of code complexity permalink"></a>LOC: a simple and efficient indicator of code complexity</h3><p>When it comes to evaluating the complexity of the code, many metrics compete. The most popular is probably Cyclomatic Complexity. Yet, it’s fascinating to see that the count of Lines Of Code (LOC) is often a <em>good enough</em> indicator!</p><p>As it’s a language-neutral metric, it’s very easy to generate regardless of your language tooling. You can use <a href="http://cloc.sourceforge.net/">cloc</a> for that:</p><pre data-language="bash" data-index="0"><p><code><span><span>cloc </span><span>.</span><span> --csv --quiet --report-file=your_project.csv</span></span></code></p></pre><p>Another language-neutral metric that works well is the <strong>Indentation Level</strong>. Indentation carries the meaning of logical splits. That’s a good indicator that code is complex.</p><p>The limit of using these is when you have a change in the coding style in the history of the project. But because these metrics are simple, it makes no sense to look at specific values and thresholds. <strong>It’s the trend that matters</strong>. That’s usually enough.</p><h3 id="evaluate-hotspots-with-complexity-trends"><a href="#evaluate-hotspots-with-complexity-trends" aria-label="evaluate hotspots with complexity trends permalink"></a>Evaluate Hotspots with Complexity Trends</h3><p>If you analyze the evolution of complexity of a file over time, you get the story of that file:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="complexity trend" title="" src="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png" srcset="https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/00d96/complexity-trend.png 148w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/0b23c/complexity-trend.png 295w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/799d3/complexity-trend.png 590w,https://understandlegacycode.com/static/cb402f296f7492bb21a7edeee345b91e/48606/complexity-trend.png 701w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>That’s helpful to show the impact of refactoring to non-technical managers. That helps them visually see the effects of such work, and the results on team productivity.</p><h3 id="perform-x-rays-analysis-to-narrow-even-deeper"><a href="#perform-x-rays-analysis-to-narrow-even-deeper" aria-label="perform x rays analysis to narrow even deeper permalink"></a>Perform X-Rays analysis to narrow even deeper</h3><p>Once you identified Hotspots, you can apply the same logic at the file level to find the complex functions:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray" title="" src="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png" srcset="https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/00d96/x-ray.png 148w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/0b23c/x-ray.png 295w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/799d3/x-ray.png 590w,https://understandlegacycode.com/static/2e63aa78e40f6496f17d737b9ead73c8/11d19/x-ray.png 800w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>This is what Adam calls “X-Ray analysis”. Here’s the rough recipe:</p><ol><li>Fetch the source code of the file for each revision from Git</li><li>Run a <code>git diff</code> for every revision to list the modifications</li><li>Match the <code>diff</code> results to the functions that existed in this version (parsing the code is necessary here)</li><li>Perform a Hotspot calculation for the functions<ul><li>Change Frequency = times a function was changed</li><li>Complexity = length or indentation level of the function</li><li>Combine them to calculate the score</li></ul></li></ol><p><undefined>
  <a href="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="x ray results" title="" src="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png" srcset="https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/00d96/x-ray-results.png 148w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/0b23c/x-ray-results.png 295w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/799d3/x-ray-results.png 590w,https://understandlegacycode.com/static/2dd2ea002e1ba78bc3e7234740b86379/e7347/x-ray-results.png 849w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>With the Hotspot + X-Ray techniques, you can take a 400kLOC codebase and focus on the few hundred lines of code that will have the most impact if they are refactored.</p><p>It’s good to know you can perform a cheap X-Ray with git log, using the <code>-L</code> option:</p><pre data-language="bash" data-index="1"><p><code><span><span>git log -L:intel_crtc_page_flip:drivers/gpu/drm/i915/intel_display.c</span></span></code></p></pre><h2 id="coupling-in-time-where-surprises-happen"><a href="#coupling-in-time-where-surprises-happen" aria-label="coupling in time where surprises happen permalink"></a>Coupling in Time: where surprises happen</h2><p>You generally forget about the time dimension when you analyze the code to evaluate its design. That’s a mistake! <strong>Change Coupling</strong> is when files change together over time.</p><p><undefined>
  <a href="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling" title="" src="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png" srcset="https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/00d96/change-coupling.png 148w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/0b23c/change-coupling.png 295w,https://understandlegacycode.com/static/772eb927f6f8cbe7cc9a4f933ac7d6fd/3af27/change-coupling.png 545w" sizes="(max-width: 545px) 100vw, 545px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>2 files might change together accidentally. But if they changed together in many commits, with a high degree of coupling, then there’s a high chance these 2 files are coupled!</p><p>This allows you to identify things that empirically belong together. If these files are not co-located, then there might be a problem with the current design. Maybe there’s a bad abstraction or maybe there’s copy-pasted code that keeps evolving together.</p><p>Expected coupling:</p><ul><li>highly-cohesive files (same module)</li><li>code &amp; tests</li></ul><p>Unexpected coupling:</p><ul><li>low-cohesive files (different modules)</li><li>surprising relationships</li></ul><p>Since you’re using git metadata to determine these coupling, it’s <strong>language agnostic</strong>. Therefore, you can detect coupling across stacks, like between front-end and back-end.</p><p>A limit of this technique is the commit patterns developers use. If a developer always commits tests and code independently, you can adapt the technique and consider commits from the same author in a 24h sliding window as “coupled together”. Usually, that’s good enough.</p><h3 id="identify-actual-code-duplication"><a href="#identify-actual-code-duplication" aria-label="identify actual code duplication permalink"></a>Identify actual code duplication</h3><p>Copy-paste is not bad in itself.</p><p>It’s only bad if you need to keep changing all occurrences together. Hence, if you integrate a metric of <em>Similarity</em> in your Change Coupling analysis, you can detect problematic copy-paste:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="change coupling copy paste" title="" src="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png" srcset="https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/00d96/change-coupling-copy-paste.png 148w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/0b23c/change-coupling-copy-paste.png 295w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/799d3/change-coupling-copy-paste.png 590w,https://understandlegacycode.com/static/33313f1bcd8d42c2f66ef8fd55ac3875/388a9/change-coupling-copy-paste.png 681w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>Fixing code duplication is often a quick win. It helps getting started in refactoring a Hotspot.</p><p>As a rule of thumb: <strong>things that are coupled should be co-located</strong>.</p><h2 id="the-principles-of-code-age"><a href="#the-principles-of-code-age" aria-label="the principles of code age permalink"></a>The Principles of Code Age</h2><p>Code is only desirable in 2 states:</p><ol><li>Very recent, because it’s fresh in your mind</li><li>Very old, because it means it has stabilized</li></ol><p>When you meet a very old code, you can encapsulate that into a library and extract it from your codebase. That’s less code to deal with, which is good for developers and onboarding!</p><p><strong>Old code usually has no bugs.</strong></p><p>A code that doesn’t stabilize is problematic. It usually means you need to patch it. Because you don’t know it very well, there’s a high chance of creating bugs by ignorance. By creating more bugs, you need to update the code again: it doesn’t stabilize.</p><h3 id="calculate-the-age-of-code"><a href="#calculate-the-age-of-code" aria-label="calculate the age of code permalink"></a>Calculate the age of code</h3><p>The algorithm is simple:</p><ol><li>List modified files with <code>git ls-files</code></li><li>Get the last modification date for each file with <code>git log -l --format="%ad" --date=short -- path/to/file</code></li><li>Calculate the age of the file</li></ol><p>If the codebase was not maintained for some time, consider the youngest one to be 0.</p><h3 id="refactor-towards-code-of-similar-age"><a href="#refactor-towards-code-of-similar-age" aria-label="refactor towards code of similar age permalink"></a>Refactor towards code of similar age</h3><p>Within the same packages, you can identify the code of different ages (very old AND very recent). Try to understand why some code fails to stabilize.</p><p>Maybe you’ll be able to extract parts of it that would actually stabilize.</p><p>Maybe you’ll identify different concepts that are mixed. So you can refactor the structure of the code:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="architecture" title="" src="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png" srcset="https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/00d96/architecture.png 148w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/0b23c/architecture.png 295w,https://understandlegacycode.com/static/54ecf644a3270956bb2619a3ed374ec2/fed2b/architecture.png 564w" sizes="(max-width: 564px) 100vw, 564px">
    </span>
  </span>
  
  </a>
    </undefined></p><h2 id="beyond-conways-law"><a href="#beyond-conways-law" aria-label="beyond conways law permalink"></a>Beyond Conway’s Law</h2><h3 id="development-congestion"><a href="#development-congestion" aria-label="development congestion permalink"></a>Development Congestion</h3><p>When you put too many developers on the same code, it’s hard to keep productive. That’s because the code constantly changes: the code you wrote three days ago is now different, so you have to constantly re-discover what it does. The risk of bug is high.</p><p>This is <em>Development Congestion</em>.</p><p>That’s why if you put more people on a late project, the project will be even later.</p><p>Code reviews and automated tests can mitigate the risk of bugs.</p><h3 id="the-problem-of-having-too-many-contributors"><a href="#the-problem-of-having-too-many-contributors" aria-label="the problem of having too many contributors permalink"></a>The problem of having too many contributors</h3><p><strong>Many minor contributors you have in the last 3 months = higher chances to have bugs</strong>.</p><p>That’s because contributors don’t have the full context of what they change.</p><p>With many contributors, <em>diffusion of responsibility</em> makes the codebase rot because each developer thinks someone else will take care of refactoring.</p><p>Also, many contributors lead to <em>process loss</em> (waste) due to communication overhead.</p><p>Thus, you need to introduce <strong>areas of responsibility</strong> to give teams full ownership. Other teams may contribute through PRs, but one team should own their part, be involved in reviews, and have the final word.</p><p>Finally, <strong>teams should have a broader knowledge boundary (what they know) than their operational boundary (what they change)</strong>. You can make that happen with:</p><ul><li>Teams demoing what they’re working on</li><li>Inter-teams code reviews to spread knowledge</li><li>Make people move between teams</li></ul><h3 id="calculating-the-diffusion-score"><a href="#calculating-the-diffusion-score" aria-label="calculating the diffusion score permalink"></a>Calculating the Diffusion score</h3><p>You can count the number of developers on a specific part of the code from git:</p><pre data-language="bash" data-index="2"><p><code><span><span>git shortlog -s --after=2020-01-12 -- some/module/path | wc -l</span></span></code></p></pre><p>If you analyze the distribution of contributions on a part of the code, you get a <em>Diffusion</em> score:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion formula" title="" src="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png" srcset="https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/00d96/diffusion-formula.png 148w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/0b23c/diffusion-formula.png 295w,https://understandlegacycode.com/static/02bdece8d042cd9e25d429bfdb5b2c9e/4ba4a/diffusion-formula.png 497w" sizes="(max-width: 497px) 100vw, 497px">
    </span>
  </span>
  
  </a>
    </undefined>
<undefined>
  <a href="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion results" title="" src="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png" srcset="https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/00d96/diffusion-results.png 148w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/0b23c/diffusion-results.png 295w,https://understandlegacycode.com/static/cbb6e1f1ec465eacf6ddc572c3787682/b3297/diffusion-results.png 474w" sizes="(max-width: 474px) 100vw, 474px">
    </span>
  </span>
  
  </a>
    </undefined></p><p>You can generate an enclosure diagram to identify bottlenecks in your large codebase:</p><p><undefined>
  <a href="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="diffusion diagram" title="" src="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png" srcset="https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/00d96/diffusion-diagram.png 148w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/0b23c/diffusion-diagram.png 295w,https://understandlegacycode.com/static/9552981d4e14928c6b9520a0f25fee0c/c5652/diffusion-diagram.png 466w" sizes="(max-width: 466px) 100vw, 466px">
    </span>
  </span>
  
  </a>
    </undefined></p><h3 id="keep-a-decision-log"><a href="#keep-a-decision-log" aria-label="keep a decision log permalink"></a>Keep a decision log</h3><p><a href="https://understandlegacycode.com/blog/earn-maintainers-esteem-with-adrs">Architecture Decision Record (ADR)</a> are very useful to simply keep track of architectural decisions in the project.</p><p>They help people understand why and how decisions were taken in the past. This is useful to re-evaluate them later in the project, as well as spreading knowledge.</p><h3 id="a-few-management-pitfalls"><a href="#a-few-management-pitfalls" aria-label="a few management pitfalls permalink"></a>A few management pitfalls</h3><p>Adam gives a few pieces of advice to managers, referring to human psychology. Whether you’re a Tech Lead or a non-technical manager, these are gold.</p><p>First, you should never …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/">https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</a></em></p>]]>
            </description>
            <link>https://understandlegacycode.com/blog/key-points-of-software-design-x-rays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741261</guid>
            <pubDate>Sun, 05 Jul 2020 19:37:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Collapse of civilisation is the most likely outcome’: top climate scientists]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23741179">thread link</a>) | @1qazxsw23edc
<br/>
July 5, 2020 | https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/ | <a href="https://web.archive.org/web/*/https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
<p>Australia’s top climate scientist says “we are already deep into the trajectory towards collapse” of civilisation, which may now be inevitable because 9 of the 15 known global climate tipping points that regulate the state of the planet have been activated.</p>



<p>Australian National University emeritus professor Will Steffen (pictured) told <em>Voice of Action</em> that there was already a chance we have triggered a “global tipping cascade” that would take us to a less habitable “Hothouse Earth” climate, regardless of whether we reduced emissions.</p>



<p>Steffen says it would take 30 years at best (more likely 40-60 years) to transition to net zero emissions, but when it comes to tipping points such as Arctic sea ice we could have already run out of time. </p>



<p>Evidence shows we will also lose control of the tipping points for the <a rel="noreferrer noopener" href="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" data-type="https://www.theguardian.com/world/2019/jul/25/amazonian-rainforest-near-unrecoverable-tipping-point?CMP=share_btn_tw" target="_blank">Amazon rainforest</a>, the West Antarctic ice sheet, and the Greenland ice sheet in much less time than it’s going to take us to get to net zero emissions, Steffen says.</p>



<p>“Given the momentum in both the Earth and human systems, and the growing difference between the ‘reaction time’ needed to steer humanity towards a more sustainable future, and the ‘intervention time’ left to avert a range of catastrophes in both the physical climate system (e.g., melting of Arctic sea ice) and the biosphere (e.g., loss of the Great Barrier Reef), we are already deep into the trajectory towards collapse,” said Steffen.</p>



<p>“That is, the intervention time we have left has, in many cases, shrunk to levels that are shorter than the time it would take to transition to a more sustainable system.</p>



<p>“The fact that many of the features of the Earth System that are being damaged or lost constitute ‘tipping points’ that could well link to form a ‘tipping cascade’ raises the ultimate question: Have we already lost control of the system? Is collapse now inevitable?”</p>



<p>This is not a unique view – leading Stanford University biologists, who were first to reveal that we are already experiencing the sixth mass extinction on Earth, released <a href="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" data-type="https://www.theguardian.com/environment/2020/jun/01/sixth-mass-extinction-of-wildlife-accelerating-scientists-warn" target="_blank" rel="noreferrer noopener">new research this week</a> showing species extinctions are accelerating in an unprecedented manner, which may be a tipping point for the collapse of human civilisation.</p>



<p>Also in the past week <a rel="noreferrer noopener" href="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" data-type="https://www.smh.com.au/environment/climate-change/australia-among-global-hot-spots-as-droughts-worsen-in-warming-world-20200601-p54ydh.html?btis" target="_blank">research emerged</a> showing the world’s major food baskets will experience more extreme droughts than previously forecast, with southern Australia among the worst hit globally.</p>



<p>Steffen used the metaphor of the Titanic in one of his recent talks to describe how we may cross tipping points faster than the time it would take us to react to get our impact on the climate under control.</p>



<p>“If the Titanic realises that it’s in trouble and it has about 5km that it needs to slow and steer the ship, but it’s only 3km away from the iceberg, it’s already doomed,” he said.</p>



<h3>‘This is an existential threat to civilization’</h3>



<p>Steffen, along with some of the world’s most eminent climate scientists, laid out our predicament in the starkest possible terms in a <a href="https://www.nature.com/articles/d41586-019-03595-0" data-type="https://www.nature.com/articles/d41586-019-03595-0" target="_blank" rel="noreferrer noopener">piece for the journal Nature</a> at the end of last year.</p>



<p>They found that 9 of the 15 known Earth tipping elements that regulate the state of the planet had been activated, and there was now scientific support for declaring a state of planetary emergency. These tipping points can trigger abrupt carbon release back into the atmosphere, such as the release of carbon dioxide and methane caused by the irreversible thawing of the Arctic permafrost.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1.jpg 907w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-300x209.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-768x536.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-143x100.jpg 143w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-500x349.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/tipping-points-climate-change-nature-comment-1-690x482.jpg 690w" sizes="(max-width: 907px) 100vw, 907px"><figcaption>9 of 15 known Earth tipping points have been activated</figcaption></figure>



<p>“If damaging tipping cascades can occur and a global tipping point cannot be ruled out, then this is an existential threat to civilization,” they wrote.</p>



<p>“No amount of economic cost–benefit analysis is going to help us. We need to change our approach to the climate problem.</p>



<p>“The evidence from tipping points alone suggests that we are in a state of planetary emergency: both the risk and urgency of the situation are acute.”</p>



<p>Steffen is also the lead author of the heavily cited 2018 paper, <a rel="noreferrer noopener" href="https://www.pnas.org/content/115/33/8252" data-type="https://www.pnas.org/content/115/33/8252" target="_blank">Trajectories of the Earth System in the Anthropocene</a>, where he found that “even if the Paris Accord target of a 1.5°C to 2°C rise in temperature is met, we cannot exclude the risk that a cascade of feedbacks could push the Earth System irreversibly onto a ‘Hothouse Earth’ pathway.”</p>



<p>Steffen is a global authority on the subject of tipping points, which are prone to sudden shifts if they get pushed hard enough by a changing climate, and could take the trajectory of the system out of human control. Further warming would become self-sustaining due to system feedbacks and their mutual interaction.</p>



<p>Steffen describes it like a row of dominos and his concern is we are already at the point of no return, knocking over the first couple of dominos which could lead to a cascade knocking over the whole row.</p>



<p>“Some of these we think are vulnerable in the temperature range we’re entering into now,” said Steffen.</p>



<p>“If we get those starting to tip we could get the whole row of dominos tipping and take us to a much hotter climate even if we get our emissions down.”</p>



<p>Even the notoriously conservative United Nations Intergovernmental Panel on Climate Change (IPCC) has found that already with the 1.1°C of warming we have had to date, there was a moderate risk of tipping some of these – and the risk increased as the temperatures increased.</p>



<p>Steffen believes we are committed to at least a 1.5°C temperature rise given the momentum in the economic and climate system, but we still have a shot at staying under 2°C with urgent action.</p>



<h3>+4°C world would support &lt; 1 billion people</h3>



<p>Professor Hans Joachim Schellnhuber, director emeritus and founder of the Potsdam Institute for Climate Impact Research, believes if we go much above 2°C we will quickly get to 4°C anyway because of the tipping points and feedbacks, which would spell the end of human civilisation.</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1024x680.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-300x199.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-768x510.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-1536x1020.jpg 1536w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-151x100.jpg 151w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-500x332.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k-690x458.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/15341907941_4ecef6f665_k.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>“There is a very big risk that we will just end our civilisation”: Professor Schellnhuber</figcaption></figure>



<p>Johan Rockström, the head of one of Europe’s leading research institutes, warned in 2019 that in a 4°C-warmer world it would be “difficult to see how we could accommodate a billion people or even half of that … There will be a rich minority of people who survive with modern lifestyles, no doubt, but it will be a turbulent, conflict-ridden world”.</p>



<p>Schellnhuber, one of the world’s leading authorities on climate change, said that if we continue down the present path “there is a very big risk that we will just end our civilisation. The human species will survive somehow but we will destroy almost everything we have built up over the last two thousand years.”</p>



<p>Schellnhuber said in a <a rel="noreferrer noopener" href="https://youtu.be/4PTRTwn3wrg" data-type="https://youtu.be/4PTRTwn3wrg" target="_blank">recent interview</a> that the IPCC report stating we could stay below 1.5°C of warming was “slightly dishonest” because it relies on immense negative emissions (pulling CO2 out of the air) which was not viable at global scale. He said 1.5°C was no longer achievable but it was still possible to stay under 2°C with massive changes to society.</p>



<p>If we don’t bend the emissions curve down substantially before 2030 then keeping temperatures under 2°C becomes unavoidable. The “carbon law” <a rel="noreferrer noopener" href="https://science.sciencemag.org/content/355/6331/1269" data-type="https://science.sciencemag.org/content/355/6331/1269" target="_blank">published in the journal Science</a> in 2017 found that, to hold warming below 2°C, emissions would need to be cut in half between 2020 and 2030.</p>



<p>Steffen told <em>Voice of Action</em> that the three main challenges to humanity – climate change, the degradation of the biosphere and the growing inequalities between and among countries – were “just different facets of the same fundamental problem”.</p>



<p>This problem was the “neoliberal economic system” that spread across the world through globalisation, underpinning “high production high consumption lifestyles” and a “religion built not around eternal life but around eternal growth”.</p>



<p>“It is becoming abundantly clear that (i) this system is incompatible with a well-functioning Earth System at the planetary level; (ii) this system is eroding human- and societal-well being, even in the wealthiest countries, and (iii) collapse is the most likely outcome of the present trajectory of the current system, as prophetically modelled in 1972 in the Limits to Growth work,” Steffen told <em>Voice of Action</em>.</p>



<h3>Eternal growth is not possible</h3>



<p>The <a href="https://www.clubofrome.org/report/the-limits-to-growth/" data-type="https://www.clubofrome.org/report/the-limits-to-growth/" target="_blank" rel="noreferrer noopener">Limits to Growth model</a> released by the Club of Rome in 1972 looked at the interplay between food production, industry, population, non-renewable resources and pollution.</p>



<p>The basic findings were that you can’t grow the system indefinitely as you will cause environmental and resource issues that will ultimately cause the whole global system to collapse (ABC’s This Day Tonight program covered it <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=cCxPOqwCr1I" data-type="https://www.youtube.com/watch?v=cCxPOqwCr1I" target="_blank">here</a>). At the time of the model’s release it accurately reproduced the historical data from 1900 to 1970.</p>



<p>A <a rel="noreferrer noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" data-type="https://www.sciencedirect.com/science/article/abs/pii/S0959378008000435" target="_blank">2008 study</a> by Graham Turner, then a senior CSIRO research scientist, used three decades of real-world historical data to conclude that the Limits to Growth model’s predictions were coming to pass: “30 years of historical data compare favourably with key features of a business-as-usual [BAU] scenario called the ‘standard run’ scenario, which results in collapse of the global system midway through the 21st century.”</p>



<figure><img src="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg" alt="" srcset="https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-1024x547.jpg 1024w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-300x160.jpg 300w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-768x410.jpg 768w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-187x100.jpg 187w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-500x267.jpg 500w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner-690x369.jpg 690w, https://voiceofaction.org/wp-content/uploads/2020/06/grahamturner.jpg 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Former CSIRO scientist Graham Turner has been warning about collapse for decades</figcaption></figure>



<p>Turner ran updated figures through the model <a rel="noreferrer noopener" href="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" data-type="https://www.ingentaconnect.com/contentone/oekom/gaia/2012/00000021/00000002/art00010" target="_blank">again in 2012</a> for another peer-reviewed paper, and <a rel="noreferrer noopener" href="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" data-type="https://sustainable.unimelb.edu.au/__data/assets/pdf_file/0005/2763500/MSSI-ResearchPaper-4_Turner_2014.pdf" target="_blank">again in 2014</a> when he had joined the University of Melbourne’s Sustainable Society Institute.</p>



<p>“Data from the forty years or so since the LTG study was completed indicates that the world is closely tracking the BAU scenario,” Turner concluded in the 2014 paper.</p>



<p>“It is notable that there does not appear to be other economy-environment models that have demonstrated such comprehensive and long-term data agreement.”</p>



<p>Turner semi-retired in 2015 but runs a small organic market garden on a rural property in the NSW south coast’s Bega Valley.</p>



<p>He and his wife grow most of their own food and live off grid powered by a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/">https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</a></em></p>]]>
            </description>
            <link>https://voiceofaction.org/collapse-of-civilisation-is-the-most-likely-outcome-top-climate-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741179</guid>
            <pubDate>Sun, 05 Jul 2020 19:27:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UBC quietly changes references to Taiwan amid sensitive political climate]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23741119">thread link</a>) | @abc-xyz
<br/>
July 5, 2020 | https://www.ubyssey.ca/news/taiwan-references-changed/ | <a href="https://web.archive.org/web/*/https://www.ubyssey.ca/news/taiwan-references-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <p>UBC has quietly made a significant change in the way it refers to Taiwan in its annual enrolment report.</p><p>In <a href="https://academic.ubc.ca/sites/vpa.ubc.ca/files/documents/2018-19%20Enrolment%20Report.pdf" target="_blank"><u>past reports</u></a>, the university simply listed the island as “Taiwan,” but in the recent <a href="https://bog3.sites.olt.ubc.ca/files/2020/01/4_2020.02_Enrolment-Annual-Report.pdf" target="_blank"><u>2019/20</u></a> enrolment report, it was lengthier: “Taiwan (Province of China).”</p><p>In a written statement from Kurt Heinrich, UBC Media Relations senior communications director, he said this is because in 2018, UBC’s data governance steering committee adopted International Organization for Standardization (ISO) data standards.</p><p>The ISO, which is recognized by the United Nations, has referred to Taiwan as “Province of China” <a href="https://www.taiwannews.com.tw/en/news/3812381" target="_blank"><u>since 1974</u></a> under ISO 3166, and the UN switched its recognition of China from the Republic of China (Taiwan) to the People’s Republic of China (Mainland China) in 1971.</p><p>In a later email, the university stated that the adoption of ISO standards was “necessary for the university’s successful transition to Workday,” UBC’s partner for its software overhaul that will replace aging systems. Elsewhere on UBC websites, however, the island is still referred to as “Taiwan.”</p><p>The nature of Taiwan’s sovereignty is a deeply political debate. Taiwan, which boasts its own democratically elected government, claims to be an independent nation. Mainland China, on the other hand, claims Taiwan to be an integral province of China.</p>
<p>“To put ‘Province of China’ after the name is to politicize the name,” said Dr. Timothy Brook, a UBC professor and an expert in Chinese history.</p><p>Many countries have <a href="https://www.newsweek.com/who-recognizes-taiwan-two-change-china-1460559" target="_blank"><u>switched their allegiance</u></a> from Taipei to Beijing in recent decades. In 1970, Canada severed diplomatic ties with Taipei in favour of Beijing, but Canada and Taiwan maintain strong trade and informal ties.</p><p>UBC’s decision to make the change to label Taiwan as a “Province of China” came at a low point in Chinese–Canadian relations, following the <a href="https://www.ctvnews.ca/world/trudeau-says-china-made-obvious-link-between-meng-and-two-michaels-1.4994128" target="_blank"><u>arrests</u></a> of Huawei CFO Meng Wanzhou in Vancouver, and the <a href="https://www.theglobeandmail.com/politics/article-china-suggests-it-will-free-two-michaels-if-canada-allows-huawei/" target="_blank"><u>two Michaels</u></a> in China, which Brook described as “political hostage taking.”</p><p>For UBC, the stakes for appeasing China are high. Huawei has granted <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>$9.5 million</u></a> in funding for research projects at UBC in recent years, which continued even after Meng’s December 2018 arrest.</p><p>Chinese students make up more than one third of all international students at UBC. In 2019/20, international student tuition made up <a href="https://bog3.sites.olt.ubc.ca/files/2020/04/2.1_2020.04_Budget-Fiscal-2020-2021.pdf" target="_blank"><u>$507 million</u></a> in revenue compared to $386 million from domestic students. Rising Canadian–Chinese tensions have made UBC administrators fear potential impacts on Chinese student enrolment and funding.</p><p>In 2019, Vice-Provost International Murali Chandrashekaran sent an <a href="https://nationalpost.com/news/meng-wanzhou-arrest-caused-ubc-leaders-concern-over-enrolment-fundraising-internal-documents-show" target="_blank"><u>email</u></a> to colleagues calling for a campus-wide meeting to address this, “given our significant reliance on China for students/$.”</p><p>If diplomatic tensions reach a point where China restricts students from going to UBC, as<a href="https://www.ubyssey.ca/news/ubc-urges-saudi-arabia-students-to-contact-enrolment-services/" target="_blank"><u> Saudi Arabia did in 2018</u></a>, UBC could face a significant <a href="https://theprovince.com/pmn/news-pmn/canada-news-pmn/credit-agency-warns-big-risk-to-canadian-schools-if-china-pulls-students/wcm/268ed61c-89fd-41e0-8a2d-3aba815152e3" target="_blank"><u>credit risk</u></a>, according to prominent credit agency Moody’s.</p><p>Anxieties surrounding Chinese interference also exist at other Canadian universities. At McMaster University, a Chinese student group had its club status <a href="https://www.scmp.com/news/china/diplomacy/article/3036309/chinese-student-association-mcmaster-university-loses-appeal" target="_blank"><u>revoked</u></a> after allegations it reported a talk by a Uyghur–Canadian woman to the Chinese consulate. At the University of Toronto, Chemi Lhamo, student union president and Canadian of Tibetan origins, was met with widespread <a href="https://www.cbc.ca/news/canada/toronto/china-tibet-student-election-1.5019648" target="_blank"><u>backlash</u></a> by Chinese students after her election win.</p>
<p>Yves Tiberghien, a UBC political science professor focusing on China and the Asia-Pacific Region, said he “can’t imagine” that the change in recognition of Taiwan in the recent enrolment report was due to Chinese financial influence.</p><p>“If I had to guess,” he added, the technical committee that decided this likely “did not have the full knowledge” of the sensitive political nature of the Taiwan–China relationship.</p><p>According to Brook, however, it is “entirely possible” that there were some Chinese pressures. “I wouldn’t be surprised if every Chinese consulate in Canada was going around and looking at things like universities to see how [they] refer to Taiwan, but I have no evidence of this,” he said. “It would be entirely in keeping with the kind of broader diplomatic initiatives that the [People’s Republic of China]’s been making over the last five years.”</p><p>While the university claims the decision was made for technical purposes, it did not respond to a follow-up email asking whether the committee responsible for the change was aware of the political context around the name.</p><p>“I wish they hadn’t done it,” said Tiberghien. “I don’t think it’s a good idea because it’s stepping into something that’s raw right now … the last thing you want is to step into this now.”</p>
      
      </div></div>]]>
            </description>
            <link>https://www.ubyssey.ca/news/taiwan-references-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741119</guid>
            <pubDate>Sun, 05 Jul 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport makes up only 6% of the greenhouse gas emissions from food]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 73 (<a href="https://news.ycombinator.com/item?id=23741040">thread link</a>) | @shafyy
<br/>
July 5, 2020 | https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>There's a common misconception that eating locally produced foods is important from an environmental point of view. Even the <a href="https://twitter.com/UN/status/1188622911080415235">UN tweeted about it.</a> This is wrong.</p><p>Transport makes up only 6% of the greenhouse gas emissions from food:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/How-much-of-GHGs-come-from-food-1-.png" alt="" width="3889" height="3935" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/How-much-of-GHGs-come-from-food-1-.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/How-much-of-GHGs-come-from-food-1-.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/How-much-of-GHGs-come-from-food-1-.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/How-much-of-GHGs-come-from-food-1-.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/environmental-impacts-of-food">Our World in Data</a>.</figcaption></figure><p>The reason for this is that most foods are transported by ship and not plane. Only about 0.16% of food miles are done by plane:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/share-food-miles-by-method.png" alt="" width="3400" height="2400" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/share-food-miles-by-method.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/share-food-miles-by-method.png 1000w, https://blog.yeticheese.com/content/images/size/w1600/2020/07/share-food-miles-by-method.png 1600w, https://blog.yeticheese.com/content/images/size/w2400/2020/07/share-food-miles-by-method.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://ourworldindata.org/grapher/share-food-miles-by-method">Our World in Data</a>.</figcaption></figure><p>It makes sense to try and avoid foods that are transported by air. Typically, those are foods which are highly perishable, such as asparagus, green beans and berries.</p><p>In some cases, eating local food even has a more negative impact on the environment than buying something that has been produced half way around the world. For example, heated greenhouses are energy intensive and can produce more greenhouse gases than transporting something for thousands of kilometers by water or road.</p><p>It's clear that avoiding meat and dairy has a much bigger impact on reducing greenhouse gas emissions.</p><p>So, why do people keep saying that we should eat local?</p><p>It could just be ignorance. However, I think that it's often a straw man argument pushed by interest groups that want to keep selling meat and dairy. It is something that is easy to do and seems to make sense on the surface to many people. Let's take another look at that UN tweet from before:</p><figure><img src="https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png" alt="" width="1194" height="634" srcset="https://blog.yeticheese.com/content/images/size/w600/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 600w, https://blog.yeticheese.com/content/images/size/w1000/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1000w, https://blog.yeticheese.com/content/images/2020/07/Screenshot-2020-07-05-at-7.18.44-PM.png 1194w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://twitter.com/UN/status/1188622911080415235">Tweet from @UN</a> on Oct 28, 2019.</figcaption></figure><p>In addition to eating local food, they also recommend unplugging unused appliances and using less hot water. Like avoiding plastic bags or plastic straws, this is good advice but a long shot from making a meaningful impact on climate change.</p><p>Arguments like these try to shift away the spot light from big companies who collectively make up a large chunk of the greenhouse gas emissions to individuals. People think that they did something meaningful by buying local food, which, as we have seen, is not the case.</p><p>I'm not saying that we shouldn't do those things. We absolutely should, but it shouldn't be the main talking points of organizations like the UN or WWF.</p><p>To make real change, we must eat less meat and dairy, move to more renewable energy sources and reduce air and road travel significantly.</p><p>PS: I'm only talking about the impact on climate change in this article. Eating local and organic food has other benefits such as supporting the local economy and in most cases it's a good idea to do it.</p><p>Comments or questions? Join in on the discussion on <a href="https://twitter.com/yeticheeseparty/status/1279850824378781697?s=20">this Twitter thread</a>. </p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->


<div id="mc_embed_signup">
<p>
    Our plant-based Yeti Feta will be available to order soon. Leave your email below and we'll let you know when it's ready. (No newsletters or other shenanigans)
</p>

</div>

<!--End mc_embed_signup--><!--kg-card-end: html-->
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/eating-local-has-tiny-environmental-impact/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741040</guid>
            <pubDate>Sun, 05 Jul 2020 19:05:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Organising WS2811 LEDs]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23741036">thread link</a>) | @iamflimflam1
<br/>
July 5, 2020 | https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html | <a href="https://web.archive.org/web/*/https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Lots of LEDs? It’s not Christmas yet!</p>

<p>I had a big bundle of addressable WS2811 LED strings and an ESP-CAM board (an ESP32 dev board with a camera). There’s only one possible project that you can do with these components. Turn the disorganised chaos of lights into something a bit more organised.</p>

<p>As an added bonus I’ve ended up duplicating the image processing code in JavaScript so you don’t even need a camera on your ESP32 board - you can just use a plain dev board to drive the LEDs.</p>

<p>You can see the results of my efforts in the video below and I’ll run through a bit more detail of the code in the following text.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The full sample code can be found here: <a href="https://github.com/atomic14/self-organising-leds">https://github.com/atomic14/self-organising-leds</a></p>

<p>If you want to do this yourself then you will need an ESP32 dev board of some kind and of course you’ll need some kind of addressable LEDs. I’m using the <a href="https://github.com/FastLED/FastLED">FastLED</a> library for driving the LEDs so with some small code changes you can probably support pretty much any addressable LEDs.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/boards.jpg" alt="ESP32 and ESP-CAM Boards"></p>

<p>Our challenge comes down to a very basic problem, given access to a stream of images from a camera identity the approximate locations of each LED in 2D space. Once you’ve done that it’s a simple problem to map from each LED’s x and y location onto a frame buffer containing the pattern you want to show.</p>

<p>There’s a bunch of boiler plate code to initialise the ESP-CAM - I took inspiration from the sample code <a href="https://randomnerdtutorials.com/esp32-cam-video-streaming-face-recognition-arduino-ide/">here</a> and copied the bits I needed to get the camera up and running.</p>

<p>An important change I’ve made is only capture greyscale images at the lowest framesize:</p>

<div><div><pre><code><span>config</span><span>.</span><span>pixel_format</span> <span>=</span> <span>PIXFORMAT_GRAYSCALE</span><span>;</span>
<span>config</span><span>.</span><span>frame_size</span> <span>=</span> <span>FRAMESIZE_QQVGA</span><span>;</span>
</code></pre></div></div>

<p>And then to grab a frame from the camera we simply do:</p>

<div><div><pre><code>    <span>camera_fb_t</span> <span>*</span><span>fb</span> <span>=</span> <span>esp_camera_fb_get</span><span>();</span>
    <span>Frame</span> <span>*</span><span>frame</span> <span>=</span> <span>new</span> <span>Frame</span><span>(</span><span>fb</span><span>);</span>
    <span>esp_camera_fb_return</span><span>(</span><span>fb</span><span>);</span>
</code></pre></div></div>

<p>With our Frame class grabbing a copy of the pixels along with the width and the height of the image.</p>

<div><div><pre><code><span>pixels</span> <span>=</span> <span>(</span><span>uint8_t</span> <span>*</span><span>)</span><span>malloc</span><span>(</span><span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>memcpy</span><span>(</span><span>pixels</span><span>,</span> <span>fb</span><span>-&gt;</span><span>buf</span><span>,</span> <span>fb</span><span>-&gt;</span><span>height</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>width</span><span>);</span>
<span>width</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span><span>;</span>
<span>height</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
<span>length</span> <span>=</span> <span>fb</span><span>-&gt;</span><span>width</span> <span>*</span> <span>fb</span><span>-&gt;</span><span>height</span><span>;</span>
</code></pre></div></div>

<p>The image below shows a frame grabbed from the ESP-CAM sensor.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/grabbed-frame.png" alt="Grabbed Frame"></p>

<p>For the JavaScript version of this code it’s a bit more complicated. One of the biggest problems is that we need to be running over HTTPS to have access to the camera - more on this later….</p>

<div><div><pre><code><span>const</span> <span>stream</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>mediaDevices</span><span>.</span><span>getUserMedia</span><span>({</span>
  <span>video</span><span>:</span> <span>{</span> <span>facingMode</span><span>:</span> <span>"</span><span>environment</span><span>"</span> <span>},</span>
  <span>audio</span><span>:</span> <span>false</span><span>,</span>
<span>});</span>
<span>const</span> <span>canPlayListener</span> <span>=</span> <span>()</span> <span>=&gt;</span> <span>{</span>
  <span>// the video is loaded and we can grab frames</span>
  <span>onVideoReady</span><span>(</span><span>video</span><span>);</span>
  <span>video</span><span>.</span><span>removeEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>};</span>
<span>video</span><span>.</span><span>addEventListener</span><span>(</span><span>"</span><span>canplay</span><span>"</span><span>,</span> <span>canPlayListener</span><span>);</span>
<span>video</span><span>.</span><span>srcObject</span> <span>=</span> <span>stream</span><span>;</span>
<span>video</span><span>.</span><span>play</span><span>();</span>
</code></pre></div></div>

<p>Once we have a video stream coming from the camera we can grab a frame by drawing the video to a canvas context and then getting the imageData from it.</p>

<div><div><pre><code><span>function</span> <span>getVideoFrame</span><span>(</span><span>video</span><span>:</span> <span>HTMLVideoElement</span><span>,</span> <span>canvas</span><span>:</span> <span>HTMLCanvasElement</span><span>)</span> <span>{</span>
  <span>const</span> <span>width</span> <span>=</span> <span>video</span><span>.</span><span>videoWidth</span><span>;</span>
  <span>const</span> <span>height</span> <span>=</span> <span>video</span><span>.</span><span>videoHeight</span><span>;</span>
  <span>const</span> <span>context</span> <span>=</span> <span>canvas</span><span>.</span><span>getContext</span><span>(</span><span>"</span><span>2d</span><span>"</span><span>);</span>
  <span>// draw the video to the canvas</span>
  <span>context</span><span>!</span><span>.</span><span>drawImage</span><span>(</span><span>video</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// get the raw image bytes</span>
  <span>const</span> <span>imageData</span> <span>=</span> <span>context</span><span>!</span><span>.</span><span>getImageData</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>width</span><span>,</span> <span>height</span><span>);</span>
  <span>// convert to greyscale</span>
  <span>const</span> <span>bytes</span> <span>=</span> <span>new</span> <span>Uint8Array</span><span>(</span><span>width</span> <span>*</span> <span>height</span><span>);</span>
  <span>for</span> <span>(</span><span>let</span> <span>y</span> <span>=</span> <span>0</span><span>;</span> <span>y</span> <span>&lt;</span> <span>height</span><span>;</span> <span>y</span><span>++</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>let</span> <span>x</span> <span>=</span> <span>0</span><span>;</span> <span>x</span> <span>&lt;</span> <span>width</span><span>;</span> <span>x</span><span>++</span><span>)</span> <span>{</span>
      <span>const</span> <span>r</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span><span>];</span>
      <span>const</span> <span>g</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>1</span><span>];</span>
      <span>const</span> <span>b</span> <span>=</span> <span>imageData</span><span>.</span><span>data</span><span>[(</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>)</span> <span>*</span> <span>4</span> <span>+</span> <span>2</span><span>];</span>
      <span>// https://en.wikipedia.org/wiki/Grayscale#Converting_color_to_grayscale</span>
      <span>const</span> <span>grey</span> <span>=</span> <span>Math</span><span>.</span><span>min</span><span>(</span><span>255</span><span>,</span> <span>0.299</span> <span>*</span> <span>r</span> <span>+</span> <span>0.587</span> <span>*</span> <span>g</span> <span>+</span> <span>0.114</span> <span>*</span> <span>b</span><span>);</span>
      <span>bytes</span><span>[</span><span>y</span> <span>*</span> <span>width</span> <span>+</span> <span>x</span><span>]</span> <span>=</span> <span>grey</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> <span>bytes</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/phone-interface.png" alt="Phone Interface"></p>

<p>Now we can grab frames we just need to grab a frame with no LEDs lit, light one LED, grab another frame and then compare the two. The difference should tell us where the LED is. To avoid noise or small movements of the camera having a bit impact we apply a guassian blur to the captured frames before taking the difference.</p>

<p>This is a of course a very naive and simple algorithm and could easily be improved on.</p>

<p>In the C++ code of the ESP32 we do all this directly in code. In the JavaScript version we call API functions on the web interface of the ESP32 to turn LEDs on and off and once we’ve finished the processing send up the calculated positions of the LEDs to the board.</p>

<p>In our ESP32 code we create a framebuffer and draw patterns into it. We then use the locations of each LED to work out what color it should be.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/organised.jpg" alt="Organised"></p>

<p>To solve the issue of needing HTTPS to access the camera and also needing the API calls to be HTTPS as well (we can’t mix content nowadays!) we need a way of serving both the UI and the API from the ESP32 web server over HTTPS. There are web servers that support HTTPS and self signed certificates available for the ESP32 but this leads to other problems and would require a rewrite of the device code. An easy workaround to this problem is to use a service such as <a href="https://ngrok.com/">ngrok</a> to provide a secure URL from the cloud through our computer to the ESP32 device. Slightly convoluted, but it works!</p>

<p>This in only needed if you are not using an ESP-CAM and have to use your phone’s camera for calibrating the LEDs. Sign up for a free acount with ngrok and then find the IP address of your ESP32 board:</p>

<div><div><pre><code>ping espcam.local
PING espcam.local (10.0.1.17): 56 data bytes
64 bytes from 10.0.1.17: icmp_seq=0 ttl=255 time=14.343 ms
64 bytes from 10.0.1.17: icmp_seq=1 ttl=255 time=6.493 ms
</code></pre></div></div>

<p>Take the IP-Address and ask ngrok to start proxying requests for us:</p>

<div><div><pre><code>ngrok http 10.0.1.17 -inspect=false
</code></pre></div></div>

<p>You’ll need steady hands - there’s quite a lot of latency going on so the space between turning an LED on and off and grabbing a frame can be quite large. I slightly moved as I was taking the frame to show the locations so the positions are slightly off.</p>

<p><img src="https://blog.cmgresearch.com/assets/article_images/2020-06-05-ws2811/located.png" alt="LED locations"></p>

<p>Checkout the video to see how well it works - surprising for such a simple algorithm.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/Ueim2Ko8VWo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

          </div></div>]]>
            </description>
            <link>https://blog.cmgresearch.com/2020/06/05/self-organising-ws2811-leds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23741036</guid>
            <pubDate>Sun, 05 Jul 2020 19:04:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Persuasion]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23740669">thread link</a>) | @apsec112
<br/>
July 5, 2020 | https://www.persuasion.community/p/the-purpose-of-persuasion | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/the-purpose-of-persuasion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/76311586-b35a-4d2b-82b1-d8a8b6ca9b18_4522x3019.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:6649732,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Friends,</p><p>I'm floored by the response of the past three days.</p><p>Once I hit <em>send</em>, this article will land in the inboxes of over 15,000 people. When we launched, my main fear was that the world would not be interested in a community that pledges to defend the values of a free society; now, my main fear is that we won't be able to live up to the hype.</p><p>So, here's my promise: We will do our very best to earn your trust. Some great articles will be coming your way soon. We are getting ready to announce more events and high-level members of the community. I hope you will join us for our inaugural townhall, which will take place next Sunday, July 12th, at 4pm EST. (Watch this space for the invite.) I'm very, very excited about what lies ahead. But I also know that it is hard to build this kind of community from the ground up, and that we will undoubtedly make mistakes along the way. Please bear with us when we do.</p><p>In the meanwhile, I want to take you a little deeper into the thinking that went into creating <em>Persuasion</em>. Why this project? Why now? And how can just a bunch of us—even if we are a much larger bunch than I could possibly have dreamed a few days ago—really make a difference to the future of free societies in the United States and around the world? The key to an answer lies in a short (and necessarily schematic) history of American intellectual life over the past half century. </p><p>Fifty years ago, the most important American institutions enjoyed a degree of legitimacy that is now hard to fathom. Nearly every American watched the news on one of the three network television stations. Nearly every American had a positive opinion of Princeton and Stanford. Nearly every Member of Congress believed that the advice of the Brookings Institution or the Council on Foreign Relations was to be taken seriously.&nbsp;</p><p>These institutions had much to recommend them: They gave the public a shared set of facts and assumptions, which could form the basis of political debate. And, though they never thought of their primary goal as fighting for the ideals of a free society, their operating system was philosophically liberal: From CBS to Harvard to Brookings, senior decision makers instinctively believed in values like free speech and due process.</p><p>However, these institutions also suffered from two important shortcomings. First, the people they admitted into their gilded halls only represented a small slice of America's population: sexism, racism and homophobia were <em>far</em> more prevalent in these institutions than they are today. The views they considered serious sometimes included the morally abhorrent.&nbsp;</p><p>Second, the realm of the “reasonable" was rather narrow. And, though this narrowness of debate constituted the lesser injustice, it was—at least in the short term—the cause of greater instability: Having come to believe that they could never quite speak in their own voices in the halls of the Brookings Institution or the column inches of the <em>New York Times</em>, a few assorted bands of malcontents started to cast around for an alternative. </p><p>Of these, the group that had the biggest impact on public life in America was a band of devoted conservatives, determined to create an ideological counter-establishment that could rival the mainstream.&nbsp;What started with <em>National Review</em>, an ideological fighting magazine, quickly grew into a sprawling and immensely powerful network of conservative institutions. The Heritage Foundation was set up to rival the influence of Brookings. The Federalist Society sought to change the ideological composition of America's judiciary. Fox News did its dismal best to spread the ideas of the conservative movement beyond the Beltway. A whole network of activist groups provided conservatives with an ideological foundation, a group of friends, and a professional home. Measured by its own ambitions,&nbsp;the movement was a staggering success.</p><p>Other minoritarian ideological movements took a page out of the same playbook. In 1960, a libertarian was a person with idiosyncratic views and no obvious political home. Then, the Institute for Humane Studies started to advocate libertarian ideas on college campuses, <em>Reason </em>took up their public defense, and a reinvigorated American Enterprise Institute set out to influence legislators on Capitol Hill. By 1980, the influence and intellectual self-confidence of libertarians had increased enormously.</p><p>The further left has always had its share of counter-establishment institutions. <em>The Nation</em>, after all, is one of the oldest magazines in the country, and some academic disciplines have long been at the forefront of leftist thought. But the left, too, has of late succeeded in building a more cohesive network of fighting institutions, as universities have become much more progressive, movements like the Democratic Socialists of America have awakened from decades of peaceful slumber, and publications like <em>Jacobin </em>have infused the movement with fresh intellectual energy.</p><p>Five or ten years ago, our potted history might have concluded here. Ideological movements from conservative to libertarian to leftist had fighting institutions of their own. Though philosophical liberals did not have a comparable home, they could confidently express their views within mainstream institutions.&nbsp;</p><p>But then those institutions started to change.</p><p>The story of that change has attracted an immense amount of attention over the past months. I won't bore you with a detailed recap of its most worrying manifestations, from the firing of James Bennet to the uncritical celebration of Robin DiAngelo. Nor do I want to suggest that these changes have completely delegitimized the mainstream: These institutions have not yet become wholly illiberal, and the advocates of a free society would be foolish to stop fighting for them.</p><p>But the erosion of values like free speech and due process within mainstream institutions does put philosophical liberals at a unique disadvantage. It is difficult to convey just how many amazing writers, journalists, and think-tankers—some young and some old, some relatively obscure and others very famous—have privately told me that they can no longer write in their own voices; that they are counting the days until they get fired; and that they don't know where to turn if they do. (Astonishingly, a number of them are far enough to the left to have supported Bernie Sanders in the primaries.)</p><p>This, to me, is a huge part of the reason why the defenders of the free society have seemed to lack conviction in recent months and years. Feeling, at best, begrudgingly tolerated by the institutions that employ them, they are always on the back foot: writing and speaking with one eye on Twitter, one eye on a hostile editor, and one eye on the attacks being shared on their own company’s Slack channel. (As you may have noticed, that requires too many eyes.)</p><p>But, if this situation helps to explain the collective lack of confidence among the advocates of a free society, it also points the way to an obvious solution. <strong>Instead of lamenting our loss of control over the establishment, we should follow the lead of other movements that have successfully built their own counter-establishment institutions.</strong><em>&nbsp;</em></p><p><em>That </em>is the goal I had in mind in starting <em>Persuasion</em>.</p><p>One core element of this project is a publishing platform explicitly devoted to debating, articulating, and defending the values of a free society. Emulating what <em>Reason</em>, <em>Jacobin,</em> and the <em>National Review</em> have accomplished within their own ideological traditions, I hope to create a space in which philosophical liberals can ask hard questions and come up with compelling answers. This requires both a commitment to a set of shared aspirations and enough diversity of opinion to force us to think very hard about how we can make the world a better place. This is a space for people who are open to changing their minds, but not their fundamental values.</p><p>But creating a modern reinvention of a fighting magazine, devoted to defending the ideals of a free society, is not my only ambition. If places like the <em>National Review</em> had a tremendous influence on our society, it is also because they became the nucleus of a cohesive community, which seeded a much wider archipelago of allied institutions. This is why I take the community element of <em>Persuasion</em>—all the live events, book clubs and social gatherings we'll experiment with over the coming months—so seriously. And it is also why I hope that this particular venture will spawn many formally independent organizations that share our founding values.</p><p>Before I close, let me say two quick words about some of the establishment institutions whose recent fate I have been lamenting. The first is that we must do what we can to preserve those universities, publications, and think tanks that still operate with fundamentally (small l) liberal assumptions. For example, I deeply love <em>The Atlantic</em>, and will continue to write for it. A small fighting institution that primarily addresses a devoted crowd of philosophical liberals neither is nor should be in competition with a large general interest magazine whose readership will always span a much broader ideological range. Part of the reason why we should articulate these values as clearly, forcefully, and persuasively as possible within these pages is to maximize the likelihood that they will continue to form the implicit operating system of vitally important publications like <em>The Atlantic</em>.&nbsp;</p><p>The second thing is that our ambition needs to extend beyond nostalgia. There is much to lament about the changes that have taken place in some of the country's most important institutions over the past years. But there is also much to criticize in what these institutions looked like at their supposed best. Our goal is not to return to a golden age that has, sadly, never existed; it is to build societies that live up to the noble and ambitious values of freedom and justice better than any society of the past.</p><p>The examples I have used here&nbsp;are very …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/the-purpose-of-persuasion">https://www.persuasion.community/p/the-purpose-of-persuasion</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/the-purpose-of-persuasion</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740669</guid>
            <pubDate>Sun, 05 Jul 2020 18:16:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Deep Introduction to JIT Compilers: JITs are not very Just-in-time]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 93 (<a href="https://news.ycombinator.com/item?id=23740655">thread link</a>) | @chrisseaton
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-intro/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p><em>If you are familiar with how JITs generally work (if you get what the title is referring to), I recommend skimming this or going straight to reading <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a></em> </p>
<p>My mentor, <a href="https://chrisseaton.com/">Chris</a>, who took me from “what is a JIT” to where I am now once told me that compilers were just bytes in bytes out and not at all low-level and scary. This is actually fairly true, and it's fun to learn about compiler internals and often useful for programmers everywhere!</p>
<p>This blog post gives background on how programming languages are implemented and how JITs work. It'll introduce the implementation details of the Julia language, though it won't talk about specific implementation details or optimizations made by more traditional JITs. Check out <a href="https://carolchen.me/blog/jits-impls">How JIT Compilers are Implemented and Fast: Julia, Pypy, LuaJIT, Graal and More</a> to read about how meta-tracing is implemented, how Graal supports C extensions, the relationship of JITs with LLVM and more!</p>
<h2 id="how-programming-languages-are-implemented">How Programming Languages are Implemented<a href="#how-programming-languages-are-implemented" aria-label="Anchor link for: how-programming-languages-are-implemented"> <i></i></a>
</h2>
<p>When we run a program, it’s either interpreted or compiled in some way. The compiler/interpreter is sometimes referred to as the "implementation" of a language, and one language can have many implementations. You may have heard things like "Python is interpreted", but that really means the reference(standard/default) implementation of Python is an interpreter. Python is a language specification and <em>CPython</em> is the interpreter and implementation of Python. </p>
<p>An interpreter is a program that directly executes your code. Well-known interpreters are usually written in C. Ruby, Python and PHP are written in C. Below is a function that loosely models how an interpreter might work:</p>
<pre><code><span>func </span><span>interpret</span><span>(</span><span>code </span><span>string</span><span>) {
  </span><span>if </span><span>code </span><span>== </span><span>"print('Hello, World!')" </span><span>{
    </span><span>print</span><span>(</span><span>"Hello, World"</span><span>);
  } </span><span>else if </span><span>code </span><span>==</span><span> “</span><span>x </span><span>= </span><span>0</span><span>; </span><span>x </span><span>+= </span><span>4</span><span>; </span><span>print</span><span>(</span><span>x</span><span>)” {
    variable_x </span><span>:= </span><span>0 
    </span><span>variable_x </span><span>+= </span><span>4
    </span><span>print</span><span>(</span><span>x</span><span>)
  }
}
</span></code></pre>
<p>A compiler is a program that translates code from some language to another language, though it usually refers to a destination language that is a machine code. Examples of compiled languages are C, Go and Rust.</p>
<pre><code><span>func </span><span>compile</span><span>(</span><span>code </span><span>string</span><span>) {
  []</span><span>byte </span><span>compiled_code </span><span>= </span><span>get_machine_code</span><span>(</span><span>code</span><span>);
  </span><span>write_to_executable</span><span>(</span><span>compiled_code</span><span>);
}
</span></code></pre>
<p>The difference between a compiled and interpreted language is actually much more nuanced. C, Go and Rust are clearly compiled, as they output a machine code file - which can be understood natively by the computer. The compile and run steps are fully distinct.</p>
<p>However, compilers can translate to any target language (this is sometimes called transpiling). Java for example, has a two-step implementation. The first is compiling Java source to bytecode, which is an Intermediate Representation (IR). The bytecode is then JIT compiled - which involves interpretation.</p>
<p>Python and Ruby also execute in two steps. Despite being known as interpreted languages, their reference implementations actually compile the source down to a bytecode. You may have seen .pyc files (not anymore in Python3) which contain Python bytecode! The bytecode is then interpreted by a virtual machine. These interpreters use bytecode because programmers tend to care less about compile time, and creating a bytecode language allows the engineers to specify a bytecode that is as efficient to interpret as possible. </p>
<p>Having bytecode is how languages check syntax before execution (though they could technically just do a pass before starting the interpreter). An example below shows why you would want to check syntax before runtime.</p>
<pre><code><span>sleep</span><span>(</span><span>1000</span><span>)
bad syntax beep boop beep boop
</span></code></pre>
<p>Another important note is that interpreted languages are typically slower for various reasons, the most obvious being that they're executed in a higher level language that has overhead execution time. The main reason is that the dynamic-ness of the languages they tend to implement means that they need many extra instructions to decide what to do next and how to route data. People still choose to build interpreters over compilers because they're easier to build and are more suited to handle things like dynamic typing, scopes etc (though you could build a compiler that has the same features). </p>
<h3 id="so-what-is-a-jit">So What is a JIT?<a href="#so-what-is-a-jit" aria-label="Anchor link for: so-what-is-a-jit"> <i></i></a>
</h3>
<p>A JIT compiler doesn't compile code Ahead-Of-Time (AOT), but still compiles source code to machine code and therefore is not an interpreter. JITs compile code at runtime, while your program is executing. This gives the JITs flexibility for dynamic language features, while maintaining speed from optimized machine code output. JIT-compiling C would make it slower as we'd just be adding the compilation time to the execution time. JIT-compiling Python would be fast, as compilation + executing machine code can often be faster than interpreting, especially since the JIT has no need to write to a file (disk writing is expensive, memory/RAM/register writing is fast). JITs also improve in speed by being able to optimize on information that is only available at runtime.</p>
<h3 id="julia-a-jit-compiler-that-s-just-in-time">Julia: a JIT Compiler that's Just-in-time<a href="#julia-a-jit-compiler-that-s-just-in-time" aria-label="Anchor link for: julia-a-jit-compiler-that-s-just-in-time"> <i></i></a>
</h3>
<p>A common theme between compiled languages is that they're statically typed. That means when the programmer creates or uses a value, they’re telling the computer what type it is and that information is guaranteed at compile time.</p>
<p>Julia is dynamically typed, but internally Julia is much closer to being statically typed.</p>
<pre><code><span>function </span><span>multiply</span><span>(x, y)
  x </span><span>*</span><span> y
</span><span>end
</span></code></pre>
<p>Here is an example of a Julia function, which could be used to multiply integers, floats, vectors, strings etc (Julia allows operator overloading). Compiling out the machine code for <em>all</em> these cases is not very productive for a variety of reasons, which is what we'd have to do if we wanted Julia to be a compiled language. Idiomatic programming means that the function will probably only be used by a few combinations of types and we don't want to compile something that we don't use yet since that's not very jitty (this is not a real term).</p>
<p>If I were to code <code>multiply(1, 2)</code>, then Julia will compile a function that multiplies integers. If I then wrote <code>multiply(2, 3)</code>, then the already-compiled code will be used. If I then added <code>multiply(1.4, 4)</code>, another version of the function will be compiled. We can observe what the compilation does with <code>@code_llvm multiply(1, 1)</code>, which generates LLVM Bitcode (not quite machine code, but a lower-level Intermediate Representation).</p>
<pre><code><span>define i64 @julia_multiply_17232(i64, i64) {
top</span><span>:</span><span>
; ┌ @ int</span><span>.</span><span>jl</span><span>:</span><span>54</span><span> within `*'
   </span><span>%</span><span>2 </span><span>=</span><span> mul i64 </span><span>%</span><span>1</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret i64 </span><span>%</span><span>2</span><span>
}
</span></code></pre>
<p>And with <code>multiply(1.4, 4)</code>, you can see how complicated it can get to compile even one more function. In AOT compiled Julia, all (some optimizations can be made to reduce) of these combinations would have to live in the compiled code even if only one was used, along with the control flow to delegate. </p>
<pre><code><span>define double @julia_multiply_17042(double, i64) {
top</span><span>:</span><span>
; ┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*'
; │┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>282</span><span> within `promote'
; ││┌ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>259</span><span> within `_promote'
; │││┌ @ number</span><span>.</span><span>jl</span><span>:</span><span>7</span><span> within `convert'
; ││││┌ @ float</span><span>.</span><span>jl</span><span>:</span><span>60</span><span> within `</span><span>Float64</span><span>'
       </span><span>%</span><span>2 </span><span>=</span><span> sitofp i64 </span><span>%</span><span>1</span><span> to double
; │└└└└
; │ @ promotion</span><span>.</span><span>jl</span><span>:</span><span>312</span><span> within `*' @ float</span><span>.</span><span>jl</span><span>:</span><span>405
   </span><span>%</span><span>3 </span><span>=</span><span> fmul double </span><span>%</span><span>2</span><span>, </span><span>%</span><span>0</span><span>
; └
  ret double </span><span>%</span><span>3</span><span>
}
</span></code></pre>
<p>The general strategy of “assume a type and compile/behave based on that” is called type inferencing, which Julia mildly uses in the examples above. There are a lot of other compiler optimizations that are made, though none of them are very specific to JITs as Julia may be better described as a lazy AOT compiler.</p>
<p>The simplicity of this kind of jitting makes it easy for Julia to also supply AOT compilation. It also helps Julia to benchmark very well, definitely a tier above languages like Python and comparable to C (I'd cite numbers, but those are always nuanced and I don't want to get into that).</p>
<h3 id="so-what-is-a-jit-take-two">So What is a JIT? Take Two.<a href="#so-what-is-a-jit-take-two" aria-label="Anchor link for: so-what-is-a-jit-take-two"> <i></i></a>
</h3>
<p>Julia is actually the jittiest JIT I'll discuss, but not the most interesting as a "JIT". It actually compiles code right before the code needs to be used -- just in time. Most JITs however (Pypy, Java, JS Engines), are not actually about compiling code just-in-time, but compiling <em>optimal code</em> at an optimal time. In some cases that time is actually never. In other cases, compilation occurs more than once. In a vast majority of the cases compilation doesn't occur until after the source code has been executed numerous times, and the JIT will stay in an interpreter as the overhead to compilation is too high to be valuable.</p>
<p><img src="https://carolchen.me/blog/img/jits/jitbrr.jpg" alt=""></p>
<p>The other aspect at play is generating <em>optimal code</em>. Assembly instructions are not created equal, and compilers will put a lot of effort into generating well-optimized machine code. Usually, it is possible for a human to write better assembly than a compiler (though it would take a fairly smart and knowledgeable human), because the compiler cannot dynamically analyze your code. By that, I mean things like knowing the possible range of your integers or what keys are in your map, as these are things that a computer could only know after (partially) executing your program. A JIT compiler can actually do those things because it interprets your code first and gathers data from the execution. Thus, JITs are expensive in that they interpret, and add compilation time to execution time, but they make it up in highly optimised compiled code. With that, the timing of compilation is also dependent on whether the JIT has gathered enough valuable information.</p>
<p>The cool part about JITs is that I was sort of lying when I said a JIT implementation of C could not be faster than existing compiled implementations. It would not be feasible to try, but jit-compiling C in the way I just described is not a strict superset of compiling a language and thus it is not logically impossible to compile code fast enough to make up for the compile+profile+interpreting time. If I "JIT compiled" C similarly to how Julia does it (statically compile each function as it's called), it would be impossible to …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-intro/">https://carolchen.me/blog/jits-intro/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740655</guid>
            <pubDate>Sun, 05 Jul 2020 18:14:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multiple Dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23740622">thread link</a>) | @wikunia
<br/>
July 5, 2020 | https://opensourc.es/blog/basics-multiple-dispatch/ | <a href="https://web.archive.org/web/*/https://opensourc.es/blog/basics-multiple-dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From time to time I hear that my posts are a little bit too deep and complicated for beginners. I totally agree: especially in my newest series on <a href="https://opensourc.es/blog/constraint-solver-1">"How to build a constraint solver from scratch?"</a> which is probably a never ending series. I do like to blog about it and will continue but this series is different.</p>
<p>Julia is a relatively young language and not too many people are using it. It thrives in scientific computing but I believe that it can be used for general computing (probably where start up time is not that relevant) i.e. I do use it for creating this blog with <a href="https://franklinjl.org/">Franklin</a> which I blogged a bit about as well <a href="https://opensourc.es/blog/Franklin.jl">here</a>.</p>
<p>This series tries to explain some of the core concepts of Julia and maybe some packages to beginners. I, the explainer of this stuff here, am by no means an expert in any of these. If you know this blog then you might know that I'm trying to explain stuff directly after I've learned them to hopefully be able to communicate better than some people who do this their entire life and are experts in it. Blogs from experts are sometimes hard to follow for me, so maybe also for you. I'll let them proof read my blog post just to be sure that there is nothing wrong with what I explain ;)</p>
<p>Posts in this series can be reached over the side bar. </p>
<p>Post 2: <a href="https://opensourc.es/blog/basics-repl-revise">REPL &amp; Revise</a></p>
<p>Okay everyone ready?</p>

<h2 id="what_is_dispatch"><a href="#what_is_dispatch">What is dispatch?</a></h2>
<p>In every programming language there are <code>functions</code> which have the purpose of providing structure and reusability of code. The functions have a <code>name</code> and some <code>arguments</code>.  They are defined like</p>
<pre><code>def add(x, y):
    return x + y</code></pre>
<p>In Python this can be called with <code>add(2,3)</code> which gives the expected <code>5</code> but also <code>add("2","3")</code> gives <code>'23'</code> which might make sense or not depending on who you ask :D</p>
<p>Now how about <code>add("2", 3)</code> ?</p>
<p>This results in an error <code>TypeError: can only concatenate str (not "int") to str</code> which again can make sense. Well I would say it does but Javascript does something different:</p>
<pre><code>function add(x,y) {
    return x+y
}</code></pre>
<p>will produce <code>"23"</code> for that.</p>
<p>Then there are of course languages like <code>C++</code> where this all is not that simple because we need to introduce types:</p>
<pre><code>int add(int x, int y) {
  return x+y;
}</code></pre>
<p>There it is clear for everyone that it takes two <code>int</code> and returns one <code>int</code>. Because it is a compiled language we would get an error directly when trying to call it with <code>add("2", 3)</code>.</p>
<p>Now what is the point? We can see different concepts here with having static types as in C++ and dynamic typing in JS and Python. They both have pros and cons which is probably obvious.  The one is easier to reason about and the others are maybe easier to hack around with.</p>
<p>Let's go into dispatching on those three languages:</p>
<p>In Python it is: Ah okay the user wants to call <code>add</code>:</p>
<ul>
<li><p>We have the <code>add</code> function</p>
</li>
<li><p>Lets call it with the arguments.</p>
</li>
<li><p>Good that works as it expects two arguments and we have two.</p>
</li>
</ul>
<p>Then we might get to the point where the function doesn't work like for <code>add("2", 3)</code> and throw an error or it works out and the answer is returned. </p>
<p>It is basically the same in JS. There are possibility some "extensions" like Typescript where things might happen differently. I haven't programmed with any of those languages lately so keep that in mind.</p>
<p>In <code>C++</code> more things are going on as each variable has a static type and one can check directly whether this fits or not. This means as we can later see that there can be more functions with the same name. I'll explain the difference between function overloading and multiple dispatch in that part ;)</p>
<p>In all of these languages we can have classes such that we might have a class <code>Manufacturer</code> and we can define <code>add(self, thing)</code> or something like that and can call the function with  <code>manufacturer.add(thing)</code>. This can be kind of seen as single dispatch. Dispatch is basically the process of deciding which function to call. Here it depends on the type of <code>manufacturer</code>. Is it a <code>Manufacturer</code> or a <code>Box</code>? For a <code>Box</code> we might have defined a class <code>Box</code> and <code>add(self, box)</code> inside of it.</p>
<div><p>⚠ Note</p> <p>These examples are more from the Python world but hopefully convey the point.</p></div>
<p>For people coding in Julia for longer this might sound like a weird concept. Actually writing about it, I am thinking: How would I do some things, where I use multiple dispatch all the time (like in the ConstraintSolver) in one of those languages?</p>
<p>Before I explain multiple dispatch I want to note:</p>
<p>Yes there are ways in Python for single dispatching like <a href="https://www.blog.pythonlibrary.org/2016/02/23/python-3-function-overloading-with-singledispatch/">@singledispatch</a> but given that the main posts I found when searching are 3-4 years old I doubt that a lot are using it :D</p>
<p>And it is still single dispatch.</p>
<h2 id="how_does_dispatch_work_in_julia"><a href="#how_does_dispatch_work_in_julia">How does dispatch work in Julia?</a></h2>
<p>Now that there is that out of our way let us have a look at one example in Julia:</p>
<pre><code>add(x, y) = x+y</code></pre>
<p>just to show a neat little way of defining one-line functions... (or as they are called in Julia: Methods)</p>
<p>The interesting things is when you type this in the Julia REPL (Read-eval-print loop) you get:</p>
<pre><code>julia&gt; add(x, y) = x+y
add (generic function with 1 method)</code></pre>
<p>calling that function works basically like in Python (from the user perspective for now). It doesn't work for strings though.</p>
<div><p>⚠ Note</p> <p>Julia and <code>+</code> for strings: Julia is a mathematical language and <code>+</code> is commutative whereas concatenating strings is not. So <code>"2"+"3"</code> is not <code>"3"+"2"</code>. Therefore Julia decided to use <code>*</code> instead. Which is commutative for numbers but not matrices for example.</p></div>
<p>Okay where did I interrupt myself? ... Ah yeah so we have an <code>add</code> function with one method now in the REPL. That looks like we might be able to add a new one, right?</p>
<div><p>⚠ Note</p> <p>As correctly pointed out on <a href="https://www.reddit.com/r/Julia/comments/hfk3u3/basics_multiple_dispatch_start_of_a_new_series/fvykyl3?utm_source=share&amp;utm_medium=web2x">Reddit</a>: I use mostly the word function. In Julia there is actually a difference between functions and methods. There is one <code>+</code> function with a lot of different implementations: called methods.</p></div>
<pre><code>julia&gt; add(x,y) = 2x+y
add (generic function with 1 method)</code></pre>
<p>okay that did not work because it still allows all types of inputs (and throws an error later when it doesn't work) because the compiler had no way to decide which <strike> function</strike>method to call. </p>
<p>Should it guess? It just overwrites the old method.</p>
<p>A small side step again: Let's check what happens when we call <code>add("2", "3")</code>
</p><pre><code>julia&gt; add("a", "b")
ERROR: MethodError: no method matching *(::Int64, ::String)
Closest candidates are:
  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:529
  *(::Missing, ::AbstractString) at missing.jl:174
  *(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54
  ...
Stacktrace:
 [1] add(::String, ::String) at ./REPL[3]:1
 [2] top-level scope at REPL[4]:1</code></pre>
<p>That error occurs when calling <code>2x</code> where it figured that <code>2</code> is an integer and <code>x = "2"</code> is a string. It gives us information of what kind of types it can multiply.</p>
<p>Let's pick one: </p><pre><code>*(::T, ::T) where T&lt;:Union{Int128, Int16, Int32, Int64, Int8, UInt128, UInt16, UInt32, UInt64, UInt8} at int.jl:54</code></pre>
<p>This tells us that we can multiply two numbers of those types when they are the same. So <code>UInt8</code> with <code>UInt8</code> but I come to that syntax later.</p>
<p>You might wonder how many of those <code>*</code> <strike> functions</strike>methods there are: <code>357</code> is the answer which you get when typing</p>
<pre><code>julia&gt; methods(*)
...</code></pre>
<p>which gives you a long list with all kind of weird types where it sometimes spreads over several lines. I mean what is this? :D</p>
<pre><code>[345] *(A::LinearAlgebra.LQ{TA,S} where S&lt;:AbstractArray{TA,2}, B::Union{DenseArray{TB,1}, DenseArray{TB,2}, Base.ReinterpretArray{TB,1,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReinterpretArray{TB,2,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,1,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, Base.ReshapedArray{TB,2,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray}, SubArray{TB,1,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, Base.ReshapedArray{T,N,A,MI} where MI&lt;:Tuple{Vararg{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, SubArray{T,N,A,I,true} where I&lt;:Union{Tuple{Vararg{Real,N} where N}, Tuple{AbstractUnitRange,Vararg{Any,N} where N}} where A&lt;:DenseArray where N where T, DenseArray} where N where T, DenseArray}, SubArray{TB,2,A,I,L} where L where I&lt;:Tuple{Vararg{Union{Int64, AbstractRange{Int64}, Base.AbstractCartesianIndex},N} where N} where A&lt;:Union{Base.ReinterpretArray{T,N,S,A} where S where A&lt;:Union{SubArra…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://opensourc.es/blog/basics-multiple-dispatch/">https://opensourc.es/blog/basics-multiple-dispatch/</a></em></p>]]>
            </description>
            <link>https://opensourc.es/blog/basics-multiple-dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740622</guid>
            <pubDate>Sun, 05 Jul 2020 18:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing a Rust web framework]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 30 (<a href="https://news.ycombinator.com/item?id=23740028">thread link</a>) | @LukeMathWalker
<br/>
July 5, 2020 | https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<blockquote>
<p><em>This post was originally meant as a section of <a href="https://www.lpalmieri.com/posts/2020-05-24-zero-to-production-0-foreword/"><strong>Zero To Production</strong></a> to explain the reasoning behind our technology choice. It eventually grew so large to be its own article!</em></p>

<p><em>You can discuss the article on <a href="https://news.ycombinator.com/item?id=23740028">HackerNews</a> or <a href="https://www.reddit.com/r/rust/comments/hlpsw5/choosing_a_rust_web_framework_2020_edition/">r/rust</a></em>.</p>
</blockquote>

<p>As of July 2020, the main web frameworks in the Rust ecosystem are:</p>

<ul>
<li><a href="https://actix.rs/"><code>actix-web</code></a>;<br></li>
<li><a href="https://rocket.rs/"><code>rocket</code></a>;<br></li>
<li><a href="https://github.com/http-rs/tide"><code>tide</code></a>;<br></li>
<li><a href="https://github.com/seanmonstar/warp"><code>warp</code></a>.</li>
</ul>

<p>Which one should you pick if you are about to start building a new <strong>production-ready</strong> API in Rust?</p>

<p>I will break down where each of those web frameworks stands when it comes to:</p>

<ul>
<li><a href="#1-comprehensiveness">Comprehensiveness</a>;<br></li>
<li><a href="#2-community-and-adoption">Community and adoption</a>;<br></li>
<li><a href="#3-sync-vs-async">Sync vs Async</a>, as well as their choice of <a href="#3-1-futures-runtime">futures runtime</a>;<br></li>
<li><a href="#4-documentation-tutorials-and-examples">Documentation, tutorials and examples</a>;<br></li>
<li><a href="#5-api-and-ergonomics">API and ergonomics</a>.</li>
</ul>

<p>I will in the end make <a href="#6-our-choice">my recommendation</a>.<br>
Worth remarking that there are no absolutes: different circumstances (and taste) might lead you to a different pick.</p>

<h2 id="1-comprehensiveness">1. Comprehensiveness</h2>

<p><code>actix-web</code>, <code>tide</code> and <code>warp</code> are <em>slim</em> web frameworks: they offer you an HTTP web server, routing logic, middleware infrastructure and basic building blocks and abstractions to parse, manipulate and respond to HTTP requests.</p>

<p><code>rocket</code> takes a different approach - it aims to be batteries-included: the most common needs should be covered by functionality provided out-of-the-box by <code>rocket</code> itself, with hooks for you to extend <code>rocket</code> if your usecase needs it.<br>
It should not come as a surprise then that <code>rocket</code> ships an easy-to-use <a href="https://rocket.rs/v0.4/guide/state/#databases">integration to manage connection pools</a> for several popular database (e.g. Postgres, Redis, Memcache, etc.) as well as its own <a href="https://rocket.rs/v0.4/guide/configuration/">configuration system</a> in <a href="https://api.rocket.rs/v0.4/rocket_contrib/"><code>rocket-contrib</code></a>, an ancillary crate hosted in <code>rocket</code>’s own repository.</p>

<p>We can compare them to frameworks available in other ecosystems:</p>

<ul>
<li><code>actix-web</code>, <code>tide</code> and <code>warp</code> are closer in spirit to <a href="https://palletsprojects.com/p/flask/"><code>Flask</code></a> from Python or <a href="https://expressjs.com/"><code>Express</code></a> from Javascript - they might be opinionated, but they do not ship a configuration management system or an ORM integration out of the box. You are in charge of structuring your API as you deem appropriate, bringing all the necessary crates and patterns into the picture;<br></li>
<li><code>rocket</code> is closer to <a href="https://www.djangoproject.com/"><code>Django</code></a> from Python or <a href="https://symfony.com/"><code>Symphony</code></a> from PHP: a stable and solid core with a set of high-quality in-tree components to fulfill your every day needs when building a solid web application. <code>rocket</code> has still a long way to go to match its peers in breadth and scope, but it is definitely off to a good start.</li>
</ul>

<p>Of course this is a snapshot of the landscape as of today, but the situation is continuously shifting according to the maintainers’ intentions - e.g. <code>actix-web</code> has slowly been accumulating more and more supporting functionality (from security to session management) in <a href="https://github.com/actix/actix-extras"><code>actix-extras</code></a>, under the umbrella of the <code>actix</code> GitHub organization.<br>
Furthermore, using a slim web framework does not force you to write everything from scratch as soon as the framework is falling short of your needs: you can leverage the ecosystem built by the community around it to avoid re-inventing the wheel on every single project.</p>

<h2 id="2-community-and-adoption">2. Community and adoption</h2>

<p>Numbers can be misleading, but they are a good conversation starting point. Looking at <a href="https://crates.io/">crates.io</a>, we have:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td>~1250k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>rocket</code></td>
<td>~525k</td>
<td>~1000</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>~435k</td>
<td>~3000</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>~47k</td>
<td>~300</td>
</tr>
</tbody>
</table>

<p>The number of total downloads is obviously influenced by how long a framework has been around (e.g. <code>actix-web:0.1.0</code> came out at the end of 2017!) while daily downloads are a good gauge for the current level of interest around it.</p>

<p>You should care about adoption and community size for a couple of reasons:</p>

<ul>
<li>consistent production usage over years makes it way less likely that you are going to be the first one to spot a major defect. Others cried so that you could smile (most of the time);<br></li>
<li>it correlates with the number of supporting crates for that framework;<br></li>
<li>it correlates with the amount of tutorials, articles and helping hands you are likely to find if you are struggling.</li>
</ul>

<p>The second point is particularly important for slim frameworks.<br>
You can get a feel of the impact of community size, once again, by looking at the number of results popping up on <a href="https://crates.io/">crates.io</a> when searching a framework name:</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th># results</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>rocket</code></td>
<td>178</td>
</tr>

<tr>
<td><code>actix-web</code></td>
<td>113</td>
</tr>

<tr>
<td><code>warp</code></td>
<td>57</td>
</tr>

<tr>
<td><code>tide</code></td>
<td>20</td>
</tr>
</tbody>
</table>

<p>Will all those crates be relevant? Unlikely.<br>
Will a fair share of them be outdated or unproven? Definitely.</p>

<p>Nonetheless it is a good idea, before starting a project, to have a quick look for functionality you know for a fact you will need. Let’s make a couple of quick examples with features we will be relying on in the email newsletter implementation we are building in <em>Zero To Production</em>:</p>

<ul>
<li>if you need to add Prometheus’ metrics to your API you can get off the ground in a couple of minutes with <a href="https://crates.io/crates/actix-web-prom"><code>actix-web-prom</code></a> or <a href="https://crates.io/crates/rocket_prometheus"><code>rocket-prometheus</code></a>, both with thousands of downloads. If you are using <code>warp</code> or <code>tide</code> you will have to write the integration from scratch;<br></li>
<li>if you want to add distributed tracing, <a href="https://crates.io/crates/actix-web-opentelemetry"><code>actix-web-opentelemetry</code></a> has your back. You will have to re-implement it if you choose any other framework.</li>
</ul>

<p>Most of these features are not too much work to implement, but the effort (especially maintenance) compounds over time. You need to choose your framework with your eyes wide open on the level of commitment it is going to require.</p>

<h2 id="3-sync-vs-async">3. Sync vs Async</h2>

<p>Rust landed its <code>async</code>/<code>await</code> syntax in version <code>1.39</code> - a game changer in terms of ergonomics for asynchronous programming.<br>
It took some time for the whole Rust ecosystem to catch up and adopt it, but it’s fair to say that crates dealing with IO-bound workloads are now generally expected to be async-first (e.g. <code>reqwest</code>).</p>

<p>What about web frameworks?<br>
<code>actix-web</code> adopted <code>async</code>/<code>await</code> with its <code>0.2.x</code> release, same as <code>warp</code>, while <code>tide</code> was using <code>async</code>/<code>await</code> before its stabilisation relying on the <code>nightly</code> Rust compiler.<br>
<code>rocket</code>, instead, still exposes a synchronous interface. <code>async</code>/<code>await</code> support is expected as part of its next <code>0.5</code> release, <a href="https://github.com/SergioBenitez/Rocket/issues/1065">in the making since last summer</a>.</p>

<p>Should you rule out <code>rocket</code> as a viable option because it does not yet support asynchronous programming?<br>
It depends.<br>
If you are implementing an application to handle high volumes of traffic with strict performance requirements it might be better to opt for an async web framework.<br>
If that is not the case, the lack of async support in <code>rocket</code> should not be one of your primary concerns.</p>

<h3 id="3-1-futures-runtime">3.1. Futures runtime</h3>

<p><code>async</code>/<code>await</code> is not all sunshine and roses.<br>
Asynchronous programming in Rust is built on top of the <code>Future</code> trait: a future exposes a <code>poll</code> method which has to be called to allow the future to make progress. You can think of Rust’s futures as <em>lazy</em>: unless polled, there is no guarantee that they will execute to completion.<br>
This is often been described as a <em>pull</em> model compared to the <em>push</em> model adopted by other languages<sup id="fnref:async-announcement"><a href="#fn:async-announcement">1</a></sup>, which has some interesting implications when it comes to performance and task cancellation.</p>

<p>Wait a moment though - if futures are lazy and Rust does not ship a runtime in its standard library, who is in charge to call the <code>poll</code> method?<br>
<strong>BYOR</strong> - <strong>B</strong>ring <strong>Y</strong>our <strong>O</strong>wn <strong>R</strong>untime!<br>
The async runtime is literally a dependency of your project, brought in as a crate.<br>
This provides you with a great deal of flexibility: you could indeed implement your own runtime optimised to cater for the specific requirements of your usecase (see <a href="http://smallcultfollowing.com/babysteps/blog/2019/12/09/async-interview-2-cramertj/#async-interview-2-cramertj">the Fuchsia project</a> or <a href="https://github.com/bastion-rs/bastion"><code>bastion</code></a>’s actor framework) or simply choose the most suitable on a case-by-case basis according to the needs of your application.<br>
That sounds amazing on paper, but reality is a bit less glamorous: interoperability between runtimes is quite poor at the moment; mixing runtimes can be painful, often causing issues that are not straight-forward either to triage, detect or solve.<br>
While most libraries should not depend on runtimes directly, relying instead on the interfaces exposed by the <a href="https://docs.rs/futures/0.3.5/futures/"><code>futures</code></a> crate, this is often not the case due to historical baggage (e.g. <code>tokio</code> was for a long time the only available runtime in the ecosystem), practical needs (e.g. a framework has to be able to spawn tasks) or lack of standardisation (e.g. the ongoing discussion on the <code>AsyncRead</code>/<code>AsyncWrite</code> traits - see <a href="http://smallcultfollowing.com/babysteps/blog/2020/01/20/async-interview-5-steven-fackler/">here</a> and <a href="http://smallcultfollowing.com/babysteps/blog/2020/03/10/async-interview-7-withoutboats/#async-interview-7-withoutboats">here</a>).<br>
Therefore picking an async web framework goes beyond the framework itself: you are choosing an ecosystem of crates, suddenly making it much more cumbersome to consume libraries relying on a different async runtime.</p>

<p>The current state of affairs is far from ideal, but if you are writing async Rust today I’d recommend you to make a <em>deliberate</em> choice when it comes to your async runtime.</p>

<p>The two main general-purpose async runtimes currently available in Rust are <a href="https://tokio.rs/"><code>tokio</code></a> and <a href="https://github.com/async-rs/async-std"><code>async-std</code></a>.<br>
<code>tokio</code> has been around for quite some time and it has seen extensive production usage. It is fairly tunable, although this results in a larger and more complex API surface.<br>
<code>async-std</code> was released almost a year ago, around the time of <code>async</code>/<code>await</code> stabilization. It provides great ergonomics, while leaving less room for configuration knobs.</p>

<p><a href="https://crates.io/">crates.io</a> can once again be used as a gauge for adoption and readiness:</p>

<table>
<thead>
<tr>
<th>Runtime</th>
<th>Total Downloads</th>
<th>Daily Downloads</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>tokio</code></td>
<td>~9600k</td>
<td>~30k</td>
</tr>

<tr>
<td><code>async-std</code></td>
<td>~600k</td>
<td>~4k</td>
</tr>
</tbody>
</table>

<p>How do frameworks map to runtimes?</p>

<table>
<thead>
<tr>
<th>Framework</th>
<th>Runtime</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>actix-web</code></td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>rocket</code> (<code>0.5.x</code>)</td>
<td><code>tokio</code></td>
</tr>

<tr>
<td><code>tide</code></td>
<td><code>async-std</code></td>
</tr>

<tr>
<td><code>warp</code></td>
<td><code>tokio</code></td>
</tr>
</tbody>
</table>

<h2 id="4-documentation-tutorials-and-examples">4. Documentation, tutorials and examples</h2>

<p>Having to dive into the source code to understand how something works can be fun (and educational!), but it should be a choice, not a necessity.<br>
In most situations I’d rather rely on the framework being well-documented, including non-trivial examples of relevant usage patterns.<br>
Good documentation, tutorials and fully-featured examples are <strong>mission-critical</strong> if you are working as part of a team, especially if one or more teammates are not experienced Rust developers.</p>

<p>Rust’s tooling treats documentation as a first class concept (just run <code>cargo doc --open</code> to get auto-generated docs for your project!) and it grew to be part of the culture of the Rust community itself. Library authors generally take it seriously and web frameworks are no exception to the general tendency: what you can find on <a href="https://docs.rs/">docs.rs</a> is quite thorough, with contextual examples …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/">https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/2020-07-04-choosing-a-rust-web-framework-2020-edition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740028</guid>
            <pubDate>Sun, 05 Jul 2020 16:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Pandas: Comparing Dask, Ray, Modin, Vaex, and Rapids]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 33 (<a href="https://news.ycombinator.com/item?id=23740012">thread link</a>) | @FHMS
<br/>
July 5, 2020 | https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray | <a href="https://web.archive.org/web/*/https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Python and its most popular data wrangling library, Pandas, are soaring in popularity. Compared to competitors like Java, Python and Pandas make data exploration and transformation <strong>simple</strong>.</p><p>But both Python and Pandas are known to have issues around <strong>scalability</strong> and <strong>efficiency</strong>.</p><p>Python loses some efficiency right off the bat because it’s an interpreted, dynamically typed language. But more importantly, Python has always focused on simplicity and readability over raw power. Similarly, Pandas focuses on offering a simple, high-level API, largely ignoring performance. In fact, the creator of Pandas wrote “<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">The 10 things I hate about pandas</a>,” which summarizes these issues:</p><figure id="w-node-412b9aecdea3-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62e9007b2509635bd1ba2_image3.png" alt="Ten things Wes McKinney hates about Pandas."></p><figcaption>Performance issues and lack of flexibility are the main things Pandas’ own creator doesn’t like about the library. (<a href="https://wesmckinney.com/blog/apache-arrow-pandas-internals/">source</a>)</figcaption></figure><p>So it’s no surprise that many developers are trying to add more power to Python and Pandas in various ways. Some of the most notable projects are:</p><ul role="list"><li><a href="https://www.datarevenue.com/ml-tools/dask"><strong>Dask</strong></a><strong>:</strong> a low-level scheduler and a high-level partial Pandas replacement, geared toward running code on compute clusters.</li><li><strong>Ray:</strong> a low-level framework for parallelizing Python code across processors or clusters.</li><li><a href="https://www.datarevenue.com/ml-tools/modin"><strong>Modin</strong></a><strong>:</strong> a drop-in replacement for Pandas, powered by either <strong>Dask</strong> or <strong>Ray</strong>.</li><li><a href="https://www.datarevenue.com/ml-tools/vaex"><strong>Vaex</strong></a><strong>:</strong> a partial Pandas replacement that uses lazy evaluation and memory mapping to allow developers to work with large datasets on standard machines.</li><li><a href="https://www.datarevenue.com/ml-tools/rapids"><strong>RAPIDS</strong></a><strong>: </strong>a collection of data-science libraries that run on GPUs and include <a href="https://github.com/rapidsai/cudf">cuDF</a>, a partial replacement for Pandas.</li></ul><p>There are others, too. Below is an overview of the Python data wrangling landscape:</p><figure id="w-node-78c43e6cecae-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62eb85c7038610cea20d0_image2.png" alt="A graph showing how often popular data wrangling libraries are compared in Google searches."></p><figcaption>Dask, Modin, Vaex, Ray, and CuDF are often considered potential alternatives to each other. Source: Created with <a href="https://anvaka.github.io/vs/?query=Dask">this tool</a></figcaption></figure><p>So if you’re working with a lot of data and need faster results, which should you use?</p><h2><strong>Just tell me which one to try</strong></h2><p>Before you can make a decision about which tool to use, it’s good to have some more context about each of their approaches. We’ll compare each of them closely, but you’ll probably want to try them out in the following order:</p><ul role="list"><li><strong>Modin</strong>, with <strong>Ray</strong> as a backend. By installing these, you might see significant benefit by changing just a single line (`import pandas as pd` to `import modin.pandas as pd`). Unlike the other tools, Modin aims to reach full compatibility with Pandas.</li><li><strong>Dask</strong>,<strong> </strong>a larger and hence more complicated project. But Dask also provides <a href="https://docs.dask.org/en/latest/dataframe.html">Dask.dataframe</a>, a higher-level, Pandas-like library that can help you deal with <a href="https://en.wikipedia.org/wiki/External_memory_algorithm">out-of-core</a> datasets.</li><li><strong>Vaex, </strong>which is designed to help you work with large data on a standard laptop. Its Pandas replacement covers some of the Pandas API, but it’s more focused on exploration and visualization.</li><li><strong>RAPIDS, </strong>if you have access to NVIDIA graphics cards<strong>.</strong></li></ul><h2><strong>Quick comparison</strong></h2><p>Each of the libraries we examine has different strengths, weaknesses, and scaling strategies. The following table gives a broad overview of these. Of course, as with many things, most of the scores below are heavily dependent on your exact situation.&nbsp;</p><figure id="w-node-3fc1cb6579be-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5ef62ef85090a97b0c469fa9_image5.png" alt="A table comparing the tools across maturity, popularity, ease of adoption, and other metrics."></p><figcaption>Dask and Ray are more mature, but Modin and Vaex are easier to get started with. Rapids is useful if you have access to GPUs.</figcaption></figure><p>These are subjective grades, and they may vary widely given your specific circumstances. When assigning these grades, we considered:</p><ul role="list"><li><strong>Maturity: </strong>The time since the first commit and the number of commits.</li><li><strong>Popularity: </strong>The number of GitHub stars.</li><li><strong>Ease of Adoption: </strong>The amount of knowledge expected from users, presumed hardware resources, and ease of installation.</li><li><strong>Scaling ability: </strong>The broad dataset size limits for each tool, depending on whether it relies mainly on RAM, hard drive space on a single machine, or can scale up to clusters of machines.&nbsp;</li><li><strong>Use case: </strong>Whether the libraries are designed to speed up Python software in general (“<strong>General</strong>”), are focused on data science and machine learning (“<strong>Data science</strong>”), or are limited to simply replacing Pandas’ ‘DataFrame’ functionality (“<strong>DataFrame</strong>”).</li></ul><h2><strong>CPUs, GPUs, Clusters, or Algorithms?</strong></h2><p>If your dataset is too large to work with efficiently on a single machine, your main options are to run your code across…</p><ul role="list"><li><strong>...multiple threads or processors:</strong> Modern CPUs have several independent cores, and each core can run many threads. Ensuring that your program uses all the potential processing power by parallelizing across cores is often the easiest place to start.</li><li><strong>...GPU cores: </strong>Graphics cards were originally designed to efficiently carry out basic operations on millions of pixels in parallel. However, developers soon saw other uses for this power, and “GP-GPU” (general processing on a graphics processing unit) is now a popular way to speed up code that relies heavily on matrix manipulations.</li><li><strong>...compute clusters: </strong>Once you hit the limits of a single machine, you need a networked cluster of machines, working cooperatively.</li></ul><p>Apart from adding more hardware resources, clever algorithms can also improve efficiency. Tools like Vaex rely heavily on <a href="https://en.wikipedia.org/wiki/Lazy_evaluation"><strong>lazy evaluation</strong></a><strong> </strong>(not doing any computation until it’s certain the results are needed) and <a href="https://en.wikipedia.org/wiki/Memory-mapped_file"><strong>memory mapping</strong></a><strong> </strong>(treating files on hard drives as if they were loaded into RAM).</p><p>None of these strategies is inherently better than the others, and you should choose the one that suits your specific problem.</p><p>Parallel programming (no matter whether you’re using threads, CPU cores, GPUs, or clusters) offers many benefits, but it’s also quite complex, and it makes tasks such as debugging far more difficult.</p><p>Modern libraries can hide some – but not all – of this added complexity. No matter which tools you use, you’ll run the risk of expecting everything to work out neatly (below left), but getting chaos instead (below right).</p><figure id="w-node-7b8872b99c95-e2612716"><p><img src="https://global-uploads.webflow.com/5d3ec351b1eba4332d213004/5efef852495a4ce0972910e9_image4_s.jpg" alt="Puppies in a row eating food from different bowls – and then chaos ensues."></p><figcaption>Parallel processing doesn’t always work out as neatly as you expect. (<a href="https://www.reddit.com/r/aww/comments/2oagj8/multithreaded_programming_theory_and_practice/">Source</a>)</figcaption></figure><h2><strong>Dask vs. Ray vs. Modin vs. Vaex vs. RAPIDS</strong></h2><p>While not all of these libraries are direct alternatives to each other, it’s useful to compare them each head-to-head when deciding which one(s) to use for a project.</p><p>Before getting into the details, note that:</p><ul role="list"><li>RAPIDS is a collection of libraries. For this comparison, we consider only the <strong>cuDF</strong> component, which is the RAPIDS equivalent of Pandas.</li><li>Dask is better thought of as two projects: a low-level Python scheduler (similar in some ways to Ray) and a higher-level Dataframe module (similar in many ways to Pandas).</li></ul><h3><strong>Dask vs. Ray</strong></h3><p>Dask (as a lower-level scheduler) and Ray overlap quite a bit in their goal of making it easier to execute Python code in parallel across clusters of machines. Dask focuses more on the data science world, providing higher-level APIs that in turn provide partial replacements for Pandas, NumPy, and scikit-learn, in addition to a low-level scheduling and cluster management framework.</p><p>The creators of Dask and Ray discuss how the libraries compare in <a href="https://github.com/ray-project/ray/issues/642">this GitHub thread</a>, and they conclude that the scheduling strategy is one of the key differentiators. Dask uses a centralized scheduler to share work across multiple cores, while Ray uses distributed bottom-up scheduling.</p><h3><strong>Dask vs. Modin</strong></h3><p>Dask (the higher-level Dataframe) acknowledges the limitations of the Pandas API, and while it partially emulates this for familiarity, it doesn’t aim for full Pandas compatibility. If you have complicated existing Pandas code, it’s unlikely that you can simply switch out Pandas for Dask.Dataframe and have everything work as expected. By contrast, this is exactly the goal Modin is working toward: 100% coverage of Pandas. Modin can run on top of Dask but was originally built to work with Ray, and that integration remains more mature.</p><h3><strong>Dask vs. Vaex</strong></h3><p>Dask (Dataframe) is not fully compatible with Pandas, but it’s pretty close. These close ties mean that Dask also carries some of the baggage inherent to Pandas. Vaex deviates more from Pandas (although for basic operations, like reading data and computing summary statistics, it’s very similar) and therefore is also less constrained by it.</p><p>Ultimately, Dask is more focused on letting you scale your code to compute clusters, while Vaex makes it easier to work with large datasets on a single machine. Vaex also provides features to help you easily visualize and plot large datasets, while Dask focuses more on data processing and wrangling.</p><h3><strong>Dask vs. RAPIDS (cuDF)</strong></h3><p>Dask and RAPIDS play nicely together via an integration <a href="https://rapids.ai/dask.html">provided by</a> RAPIDS. If you have a compute cluster, you should use Dask. If you have an NVIDIA graphics card, you should use RAPIDS. If you have a compute cluster of NVIDIA GPUs, you should use both.</p><h3><strong>Ray vs. Modin or Vaex or RAPIDS</strong></h3><p>It’s not that meaningful to compare Ray to Modin, Vaex, or RAPIDS. Unlike the other libraries, Ray doesn’t offer high-level APIs or a Pandas equivalent. Instead, Ray powers Modin and <a href="https://docs.ray.io/en/latest/tune.html">integrates with RAPIDS</a> in a similar way to Dask.</p><h3><strong>Modin vs. Vaex</strong></h3><p>As with the Dask and Vaex comparison, Modin’s goal is to provide a full Pandas replacement, while Vaex deviates more from Pandas. Modin should be your first port of call if you’re looking for a quick way to speed up existing Pandas code, while Vaex is more likely to be interesting for new projects or specific use cases (especially visualizing large datasets on a single machine).</p><h3><strong>Modin vs. RAPIDS (cuDF)</strong></h3><p>Modin scales Pandas code by using many CPU cores, via Ray or Dask. RAPIDS scales Pandas code by running it on GPUs. If you have GPUs available, give RAPIDS a try. But the easiest win is likely to come from Modin, and you should probably turn to RAPIDS only after you’ve tried Modin first.</p><h3><strong>Vaex vs. RAPIDS (cuDF)</strong></h3><p>Vaex and RAPIDS are similar in that they can both provide performance boosts on a single machine: Vaex by better utilizing your computer’s hard drive and processor cores, and RAPIDS by using your computer’s GPU (if it’s available and compatible). The RAPIDS project as a whole aims to be much broader than Vaex, letting you do machine learning end-to-end without the data leaving your GPU. Vaex is better for prototyping and data exploration, letting you explore large datasets on consumer-grade machines.</p><h2><strong>Final remarks: Premature optimization is the root of all evil</strong></h2><p>It’s fun to play with new, specialized tools. That said, many …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray">https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</a></em></p>]]>
            </description>
            <link>https://datarevenue.com/en-blog/pandas-vs-dask-vs-vaex-vs-modin-vs-rapids-vs-ray</link>
            <guid isPermaLink="false">hacker-news-small-sites-23740012</guid>
            <pubDate>Sun, 05 Jul 2020 16:47:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Here Is What You Need To Know Before Learning Code. Bookmark This Guide]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23739809">thread link</a>) | @yassinerajallah
<br/>
July 5, 2020 | https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/ | <a href="https://web.archive.org/web/*/https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			
<p>Before starting out, I’d like to take a minute to thank you for reading &amp; sharing my last article<span>&nbsp;</span><em><a href="https://devhypercharged.com/the-7-traps-that-make-your-software-unusable/">“You Need To Know These 7 Traps That Make Your Software Useless”</a></em></p>
<p>Since we have numerous new members joining the club, feel free to send me your requests, topics, comments, advice, and I’ll make sure to reply to each one of your emails!</p>
<p>Without further ado, let’s dive in.</p>
<p>Learning how to code can be daunting, the progress is slow, the concepts are unique, and the positive feedback loop that will keep you motivated is hard to maintain. Countless are the articles that tell you should learn some framework X because it’s the future or master a language Y because it’s robust. Personally, I wouldn’t have learned multiple stacks (Deep learning, iOS dev, Android dev, Game dev, Cloud services) had I found the right source to guide me. And this is what I wished I had known:</p>
<p>Before choosing what programming language/framework to learn, let’s establish these first principles:</p>
<h3><strong>Programming is an investment&nbsp;</strong></h3>
<p>Learning programming and taking it to the next level are two different things, this is what you’ll be working with for years to come, the market is competitive but you definitely have a spot – if you work hard+smart enough. You don’t need to be a genius but willing to sit down and work. Had I told anyone I wanted to learn deep learning when I was still a freshman with 0 experience in coding, they’d have laughed their life off.</p>
<p>When you pick a programming language, you’ll start building “assets”. Think of assets as utilities that help you in video games. The harder the level, the more you need them to win fast. Typically, after 2 or 3 side projects, you’ll be having a folder full of code snippets that will save you hours! (I’m constantly taking code from projects I’ve finished 3 years ago)</p>
<p>No, you don’t need to stick with your programming language and you can always bounce off to something else. That might sound counter-intuitive, but at least before switching, you’ll have an important cognitive asset:</p>
<ul>
<li>The ability to make complex decisions fast.</li>
<li>Knowing how to learn the new programming language/framework faster &amp; more reliably</li>
<li>Apply the same general concepts onto the new PL</li>
</ul>
<p>However, I don’t recommend switching areas frequently unless you have a valid technical reason for doing so.</p>
<h3><strong>You can’t skip the basics</strong></h3>
<p>Not fun to hear, I’m fully aware. But learning the basics is your first step into programming. Here, you build your tools, learn facts, and polish your skills. Many people struggle with this phase, and when stuck, they think programming isn’t for them.</p>
<p>Think of this step as learning how to reason in sequence. The human brain is a supercomputer on steroids, 1 + 1 appears trivial since you are looking at an equation from a top view. However, the machine only gets to look at 1 operand at a time, so you have to declare your intentions first then tell it what to do with your intentions.</p>
<p>Finally, you elevate your reasoning by solving a real-world problem using an algorithm (a set of instructions).</p>
<p>Again, it doesn’t have to be daunting or scary, as I always say, take an hour or two a day and learn at your own pace. Don’t compare with others because chances are you’ll feel overtaken. And there is no room for intelligence or stupidity in learning code. Only actions and results.</p>
<p>To close off this first part, I invite you to experiment and try whatever works for you. This isn’t the absolute rule on how to learn how to code. If the analogies aren’t that practical for you then great! set your own. If my logic is flawed, then also great, rethink yours! It’s always great to experiment.</p>
<p>Now let’s get you started with choosing the right platform, here is what you should know:</p>
<h2><strong>Gaming<span>&nbsp;</span></strong></h2>
<ul>
<li>Unity is your friend. I still remember the day I decided to make games and become a game dev. The language is C# and unbelievably easy to learn.</li>
<li>Some people prefer using Xcode, but the software is platform restricted, and from my experience, I found it a thousand times easier to learn game dev on Unity than Xcode</li>
<li>The game engine (Unity) does the heavy lifting, you tell the objects to move by a given speed and whether they can collide or not, and there you go, the embedded physics kick in</li>
<li>You’ll have a huge boost by learning design using Blender (An open-source software for design and animation) or similar. Nevertheless, it’s not required, but there will be instances when you wish you’d known how to design</li>
<li>You can compile your game for whatever platform! (Desktop, consoles, web, mobile, etc..) Check out<span>&nbsp;</span><a href="https://unity.com/features/multiplatform">this link</a><span>&nbsp;</span>for more info</li>
<li>The industry is competitive and requires a lot of discipline since you’ll be working long hours. Some like it some don’t, it’s up to you to decide</li>
<li>You are restricted a bit in terms of employment. There are only as many game dev companies out there, and if you don’t like the domain anymore, you’ll need to learn another skill instead of reusing what you already know</li>
<li>Game physics are annoying sometimes, however, the more you learn, the easier it gets – Classic debugging scenario. Game dev is inherently time-consuming given the small details to address. Also, often you’ll get unwanted guests: Bugs. The combinations of physics are near unlimited, sometimes you’ll find yourself debugging for 5 hours a small bug that you simply can’t fix. In this scenario, you can get help from someone you know or revert back to online forums.</li>
<li>No, you won’t make “easy” money with game development. It will take a bit of time to learn how to make smooth, flawless mechanics. So if you are doing it for the money only, maybe you want to save yourself the frustration.</li>
<li>If you are doing it by passion, by no means try it out! you’ll have so much fun creating weird games. Let your imagination go wild, it only gets better from there!</li>
</ul>
<h2><strong>Competitive Programming</strong></h2>
<ul>
<li>Simply practice and resilience: Back in freshman year, I decided to dive into competitive programming. It sounded nerdy and cool. I finished the “cracking the coding interview” by Google. Which contains 150 programming interview questions. I noticed slight progress given the giant amount of work I had to endure for a full summer.</li>
<li>If you want to make money through this, you sure love making money the hard way, but it’s doable. Nevertheless, this is a great way to get into big techs if you rank top in programming contests.</li>
<li>You only remember as much as you practice. The hidden trump card about Competitive programming isn’t the difficulty of the problems but how prepared are you. You don’t have to remember how you solved a problem but where you missed. If you stop practicing, you’ll feel you lost that ‘cognitive prowess’ that helped you draw links between multiple parts of the question.</li>
<li>More often than not, the standard programming language is C++. Python is on the rise too.</li>
</ul>
<h2><strong>Mobile Development</strong></h2>
<ul>
<li>Android or iOS, it’s up to you to choose. I prefer coding for iOS (Swift) because it feels much cleaner. Back in Android (Java/Kotlin), I had to deal with preliminary problems like fixing “Gradle” after an update to just get the project going. Also, I felt that Android was a bit messy to code for in a native language. So I switched to iOS.</li>
<li>iOS is more restricted, you need to pay $100/year for the Apple Developer Program. Also, you need the membership if you want to include advanced features in your app such as Deep Links, notifications, background activity, etc…</li>
<li>Android on the other side, you pay $25 for a<span>&nbsp;</span><strong>lifetime.</strong><span>&nbsp;</span>You submit as many apps as you want, and no one is restricting you in any way. You have a wide audience of developers and potential users waiting for your app. But on the other side, you are competing with more people.</li>
<li>Why not both? Use a framework! I learned both Android &amp; iOS dev and now I’m switching completely to Flutter (more on this in the last paragraph). Using a framework helps with coding for multiple platforms using the same code base. You don’t want to do double the work, and maintaining just 1 app needs<span>&nbsp;</span><strong>many!<span>&nbsp;</span></strong>people. It’s not a matter of “competency” but resources. If I judge by my skills, I don’t need anyone technical on my team, but often than not, I need many people to help me out because there are many small details to take care of.</li>
<li>App developers have a favorable edge in the job market. Mobile users are on the rise. According to BankMyCell, 3.5B people are using their smartphone and it’s only been growing to date</li>
<li>Career-wise, you can work anywhere from the comfort of your home. Also, you ‘ll progress quite fast if you know what you’re doing. Salaries are on the rise too, and the benefits are staggering. Finally, you’re not limited to some predefined companies, you can work for startups, freelance, build your own project, and so on.</li>
<li>This area is getting more &amp; more competitive, and there is a slight switch that is happening, which is the move to software development kits (aka Flutter, React native, etc…). Instead of paying a full-stack mobile dev to write code for 1 platform only, you can have the same code base work for multiple platforms.</li>
</ul>
<h2><strong>Web Development</strong></h2>
<ul>
<li>Web dev is in some serious demand as well. Here you don’t have a predefined programming language because you can literally combine multiple ones, for example: Html + CSS + JS. I never wanted to learn web dev because of javascript. Spaghetti language (sorry!) Also the idea of learning multiple languages to do 1 thing never made sense to me. However, in your case, this isn’t a problem anymore. If you are passionate about creating websites or Web apps, you can go for frameworks such as React Js or Flutter (in Beta). And you’re sorted for life.</li>
<li>No, you don’t need to worry about the “no-code tools” and the “website builders”. These can only help as much. If you want to focus on the backend (servers, technical logic, business logic, etc…) you are in a much better position given that each use case is different. And for a no-code tool to handle that, it’s pretty unreasonable.</li>
<li>Web Development is a dimension in itself. I’m not a web developer and don’t want to snap off someone …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/">https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</a></em></p>]]>
            </description>
            <link>https://devhypercharged.com/here-is-what-you-need-to-know-before-learning-how-to-code-bookmark-this-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739809</guid>
            <pubDate>Sun, 05 Jul 2020 16:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Interface of Kai Krause's Software]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23739545">thread link</a>) | @bschne
<br/>
July 5, 2020 | https://www.mprove.de/script/99/kai/index.html | <a href="https://web.archive.org/web/*/https://www.mprove.de/script/99/kai/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
				<div>
					<h2 skip="">Contents</h2>
					<ol>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#history"><b>Meta-History</b></a></li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#software"><b>The Software</b></a>
							<ul>
								<li>Maximize the Interface</li>
								<li>Full Screen Mode</li>
								<li>Rooms</li>
								<li>Minimize the Interface</li>
								<li>The Desktop</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#interfacelanguage"><b>Kai’s Interface Language</b></a>
							<ul>
								<li>Unfolding functionality</li>
								<li>MouseOver</li>
								<li>MouseDragging instead of Value-Slider</li>
								<li>Memory Dots / Five Favorites</li>
								<li><nobr>Transparency &amp; Shadows (KPT Lens f/x, Poser</nobr><nobr>)</nobr></li>
								<li>Full Screen Mode, <a href="https://www.mprove.de/script/99/kai/index.html#rooms">Rooms Metaphor</a></li>
								<li>Workspace – Desktop</li>
								<li>MetaWindow</li>
							</ul>
						</li>
						<li><a href="https://www.mprove.de/script/99/kai/index.html#references"><b>References</b></a></li>
					</ol>
				</div>
			</div>
			<h2><a name="history" id="history"></a>Meta-History</h2>
			<h3>CV</h3>
			<p><a id="Truong97" name="Truong97"></a><strong><a href="https://en.wikipedia.org/wiki/Kai_Krause">Kai Krause</a></strong> [today: <a href="http://kai.sub.blue/">kai.sub.blue</a>]was born 1957 in Dortmund. He came to California in 1976 with two friends. He worked as a musician for <em>Disney Sound Effects</em>; <strike>the sound track for “Star Trek: The Movie” was created on his synthesizers</strike>*. <span>* In fact Kai won a Clio Award for his sound effects in a Star Wars radio spot.</span> <a href="https://en.wikipedia.org/wiki/Emerson,_Lake_&amp;_Powell">Emerson, Lake &amp; Powell</a> bought sound systems from him and he is still working with <a href="https://petergabriel.com/">Peter Gabriel</a> today in order to fulfill his vision of visualized music as 3D sculptures. [<a href="https://www.mprove.de/script/99/kai/index.html#refTruong97">Truong97</a>]</p>
			<p>He was running a forum for several years on AOL: <a href="https://www.mprove.de/script/90/KPT/index.html"><em>Kai’s Power Tips &amp; Tricks</em></a>. He gave people tips and little pieces of code on line, simply because they shared his passion for computer graphics. This became an extensive and valuable collection of practical information how to get special effects with <em>Adobe Photoshop</em>. It can still be downloaded from several web sites. [<a id="KaiTT" name="KaiTT" href="https://www.mprove.de/script/99/kai/index.html#refKaiTT">KaiTT</a>]</p>
			<h3>The Company</h3>
			<p><img src="https://www.mprove.de/script/99/kai/_media/high/history.jpg" height="441" width="803"></p>
			<p>Fig. 1 Timeline with companies and products</p>
			<p><em>Harward Systems Corporation</em> (HSC Software Corp.) [also <em>Happy Software Company</em>] was founded by John Wilczak. Ben Weiss and Kai joined him in 1991 at HSC and created the first version of <em>Kai’s Power Tools</em>. KPT is a set of plug-ins that use the Adobe Photoshop programing interface for 3rd party filters. Many ideas from <a href="https://www.mprove.de/script/90/KPT/index.html">Kai’s Power Tips &amp; Tricks</a> get implemented as simple and easy to use pieces of software. KPT evolved until version 3 in 1995. This release contains the <em>Texture Explorer</em>, the <em>Spheroid Designer</em> and <em>KPT Lens f/x</em> among others. <em>Convolver</em> came out as a separate product. HSC was renamed to <em>MetaTools, Inc.</em> the same year.</p>
			<p>Eric Wenger and Phil Clevenger came into the team to develop a landscape-simulating product called <em>Bryce</em> (named after the <a href="https://www.nps.gov/brca/index.htm">Bryce Canyon</a>). They started creating other kinds of software starting with <em>Kai’s Power GOO</em>, <em>Kai’s Photo Soap</em> and <em>Kai’s Power Show</em>. Before GOO, Kai was well known only by computer artists as a creator of creative tools. With GOO, Kai became noticed by a much broader audience. People played with GOO. The complex and difficult algorithms are well hidden by the interface. Even children can change images of their classmates or teachers to funny caricatures. Kai himself calls this sort of computer programs <em>funware</em>.</p>
			<p>In 1998 Phil Clevenger and Kai managed to transfer the main interface concepts from Bryce to <em>Poser3</em>. Poser was originally created by <em>Fractal Design</em>. The companies MetaTools and Fractal Design merged in 1997. The new company was named <a href="https://en.wikipedia.org/wiki/MetaCreations"><em>MetaCreations Corp</em>.</a> In 1998 it had about 300 employees. The main office is in Santa Barbara, CA, but several other facilities e.g. in San Francisco, are part of MetaCreations. <a id="MCRE" name="MCRE"></a>[<a href="https://www.mprove.de/script/99/kai/index.html#refMCRE">MCRE</a>]</p>
			<h4>Update π-day 2018</h4>
			<ul>
				<li><a href="https://www.scribd.com/document/373825984/MataTools-Flyer-1996">MetaTools Flyer 1996</a></li>
				<li><a href="http://vv.arts.ucla.edu/teaching/software/lifeintheuniverse/"><em>Life in the Universe (1997)</em></a> – <a href="http://victoriavesna.com/index.php?p=teaching&amp;item=2">course material by Victoria Vesna</a>, UCLA (Thanks to Christopher Cowan for sharing the link.)
					<ul>
						<li><a href="https://www.facebook.com/kaikemono/posts/10216470444058859" target="_blank"><strike>Some thoughts by the designer Kai Gradert</strike></a></li>
					</ul>
				</li>
			</ul>
			<h2><a name="software" id="software"></a>The Software</h2>
			<h3>Maximize the Interface</h3>
			<h4>Full Screen Mode</h4>
			<p><a id="Kai95-1" name="Kai95-1"></a>Kai describes how it came to the large dialogs in KPT3:</p>
			<blockquote>
				<p>»I would love to interact with the image in the way that Levels or Curves does, but the plug-in interface as of today simply will not allow it. What that leads to is simply that the plug-in gets a rectangle and is supposed to do something with the pixels in some other room and then give them back.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Many of the filters in KPT3 like <em>KPT Texture Explorer</em>, <em>KPT Spheroid Designer</em> and <em>KPT Convolver</em> use a rectangular area that fits on a 14" monitor. All other elements get blacked out – no menu bar, no Photoshop image window and no desktop. The user experience is really like coming into a room with a special suited environment for one specific task.</p>
			<p><a name="Fig2 KPT Texture"></a><img src="https://www.mprove.de/script/99/kai/_media/high/KPT3TextureExplorer.jpg" height="460" width="640"></p>
			<p>Fig. 2 KPT Texture Explorer 3.0</p>
			<p>KPT Texture Explorer is a modal dialog, that is especially prepared to create textures and nothing else.</p>
			<p><img id="spheroiddesigner" src="https://www.mprove.de/script/99/kai/_media/high/KPT3SpheroidDesigner.jpg" name="spheroiddesigner"></p>
			<p>Fig. 3 KPT Spheroid Designer 3.0</p>
			<p>KPT Spheroid Designer is meant to create collections of special looking orbs. Different controls allow the definition of light or to select a special surface structure for the orbs. The KPT users manual notes that Spheroid Designer may seem to resemble glass balls dropped into mud, but actually it’s meant to be glass balls embedded in an “old stale brownie”. [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]<br>
					<a id="kansei" name="kansei"></a></p>
			<p><a name="Fig4 KPT Convolver"></a><img id="convolver" src="https://www.mprove.de/script/99/kai/_media/high/KPTConvolver.jpg" name="convolver"></p>
			<p>Fig. 4 KPT Convolver</p>
			<p><a id="Tog96" name="Tog96"></a><a href="http://asktog.com/">Bruce “Tog” Tognazzini</a> writes about <em>Kansei Engineering</em>:</p>
			<blockquote>
				<p>»Since the year A.D. 618 the Japanese have been creating beautiful Zen gardens, environments of harmony designed to instill in their users a sense of serenity and peace. […] Every rock and tree is thoughtfully placed in patterns that are at once random and yet teeming with order. Rocks are not just strewn about; they are carefully arranged in odd-numbered groupings and sunk into the ground to give the illusion of age and stability. Waterfalls are not simply lined with interesting rocks; they are tuned to create just the right burble and plop. […]<br>
					
					Kansei speakes to a totality of experience: colors, sounds, shapes, tactile sensations, and kinesthesia, as well as the personality and consistency of interactions.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 171]</p>
			</blockquote>
			<p>Then Tog comes to software design:</p>
			<blockquote>
				<p>»Where does kansei start? Not with the hardware. Not with the software either. Kansei starts with attitude, as does quality. The original <a href="https://www.mprove.de/visionreality/text/3.1.6_xeroxstar.html">Xerox Star</a> team had it. So did the <a href="https://www.mprove.de/visionreality/text/3.1.8_lisa.html">Lisa</a> team, and the <a href="https://www.mprove.de/visionreality/text/3.1.9_macintosh.html">Mac</a> team after. All were dedicated to building a single, tightly integrated environment – a totality of experience. […]<br>
					KPT Convolver […] is a marvelous example of kansei design. It replaces the extensive lineup of filters that graphic designers traditionally grapple with when using such tools as Photoshop with a simple, integrated, harmonious environment.<br>
					In the past, designers have followed a process of picturing their desired end result in their mind, then applying a series of filters sequentially, without benefit of undo beyond the last-applied filter. Convolver lets users play, trying any combination of filters at will, either on their own or with the computer’s aid and advice. […] Both time and space lie at the user’s complete control.« [<a href="https://www.mprove.de/script/99/kai/index.html#refTog96">Tog96</a>, pp. 174]</p>
			</blockquote>
			<p>Many of the interface ideas evolved from <em>KPT</em> into <em>Bryce</em>. It is a whole environment that covers the complete screen. It overcomes the limitation of a fixed 14" rectangle, because the interface scales itself to the according screen dimensions. The same holds for <em>Poser3</em> and <em>KPT5</em> as they were shipped late in 1998.</p>
			<p><img id="bryce" src="https://www.mprove.de/script/99/kai/_media/high/bryce_full.jpg" name="bryce"></p>
			<p>Fig. 5 Bryce 2</p>
			<h4><a id="rooms" name="rooms"></a><a name="Lombreglia97"></a>Rooms</h4>
			<blockquote>
				<p>»The writer <a href="https://en.wikipedia.org/wiki/John_Updike">John Updike</a> is said to have several different writing rooms in his home, each used for a different kind of work -- a fiction room, a poetry room, a room for writing essays and book reviews. All writers want a special room for working (with door, without telephone), but why would any writer -- even such a deservedly successful and prosperous one as John Updike -- need entirely different rooms for different kinds of writing?<br>
					Actually, I know exactly why. Mr. Updike’s arrangement sounded great to me the first time I heard about it. I’m sure working in those rooms is his way of staying inspired, fighting boredom and distraction, getting creative work done by being in a space that’s not only set aside for work but that also somehow provokes that work, probably in quite subtle ways.« [<a href="https://www.mprove.de/script/99/kai/index.html#refLombreglia97">Lombreglia97</a>]</p>
			</blockquote>
			<p><a name="Fig6 GOO"></a><img id="goo" src="https://www.mprove.de/script/99/kai/_media/high/GOO.jpg" name="goo"></p>
			<p>Fig. 6 Kai’s Power GOO</p>
			<p>The <em>GOO room</em> is a specialized environment for shifting pixels around. But because Kai’s Power GOO is one of the first stand-alone applications from MetaTools some operating systems tasks like opening and closing images need to be accessible within the application. In order not to clutter the room that is special suited to edit the image, other rooms become part of the application. <span><a href="http://www.macworld.com/article/3005783/software-graphics/an-ode-to-kais-power-goo.html"><span>cf. An ode to Kai’s Power Goo, Macworld 11/2015</span></a></span> E.g. <em>Kai’s Photo Soap</em> (Fig. 7) initially presents you with a series of seven “rooms” – In, Prep, Tone, Color, Detail, Finishing and Out – which one can enter to perform particular tasks.</p>
			<p><img id="soap-rooms" src="https://www.mprove.de/script/99/kai/_media/high/SoapRooms.jpg" name="soap-rooms"></p>
			<p>Fig. 7 Plan-Room in Kai’s Photo Soap</p>
			<h3><a id="Bier93" name="Bier93"></a>Minimize the Interface</h3>
			<p>The concept of Magic Lenses was introduced by [<a href="https://www.mprove.de/script/99/kai/index.html#refBier93">Bier et al. 93</a>]. Two years later Kai designed a tool for KPT3 that can be dragged on top of an image. A circled look-through area shows a preview of the selected filter attributes.</p>
			<p><img id="lens" src="https://www.mprove.de/script/99/kai/_media/high/KPTLens.jpg" name="lens"></p>
			<p>Fig. 8 KPT Lens f/x 3.0 on top of a Photoshop image window</p>
			<p><a name="Kai95-2"></a>Kai himself describes the design concept that lead to the lens tool in KPT3:</p>
			<blockquote>
				<p>»What is called the “lenses” was in alpha known as the Dragon, as in “drag-on-the-image” and its design concept was so simple: make a precision instrument, like a little Swiss Army knife or a watch or microscope (it was also known as the fx Scope…) which has just a few very tiny controls around a center window. In this window a number of effects could be shown exactly as they would appear, over the real image, and updated in realtime.<br>
					It’s a lovely idea to keep all kinds of options hidden inside little wheels and dials that pop out to set and hide themselves during use… I think we have barely begun to use all the possibilities of that. And the actual interaction with the screen image is still a little clunky, hampered by the very illegality of bypassing the plug-in interface altogether.« [<a href="https://www.mprove.de/script/99/kai/index.html#refKai95">Kai95</a>]</p>
			</blockquote>
			<p>Soap is the consequent next step into this direction. The tools no longer need to be modal like the KPT lens; they can be used in a very natural modeless manner. Pens, brushes and erasers are distributed all over the workspace. They are large, they cast <strike>real</strike> virtual shadows, and the tips of the tools get pressed down while they are in use.</p>
			<p><img id="soap" src="https://www.mprove.de/script/99/kai/_media/high/Soap.jpg" name="soap" height="500" width="776"></p>
			<p>Fig. 9 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mprove.de/script/99/kai/index.html">https://www.mprove.de/script/99/kai/index.html</a></em></p>]]>
            </description>
            <link>https://www.mprove.de/script/99/kai/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739545</guid>
            <pubDate>Sun, 05 Jul 2020 15:47:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JIT Compilers Are Implemented and Fast: Julia, PyPy, LuaJIT, Graal and More]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23739416">thread link</a>) | @kipply
<br/>
July 5, 2020 | https://carolchen.me/blog/jits-impls/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/jits-impls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>This post goes into details of 5+ JITs and various optimization strategies and discuss how they work with different JITs. Information in this blog post is more <em>depth-first</em>, thus there are many important concepts that may be skipped.</p>
<p>For background on JIT compilers see <a href="https://carolchen.me/blog/jits-intro">A Deep Introduction to JIT Compilers: JITs are not very Just-in-time</a>. If the title does not make sense to you then it may be worth a skim. </p>
<blockquote>
<p><em>Mild Disclaimers, can be skipped</em>.</p>
</blockquote>
<blockquote>
<p>I will often describe an optimization behaviour and claim that it probably exists in some other compiler. Though I don't always check if an optimization exists in another JIT (it's sometimes ambiguous), I'll always state explicitly if I know it’s there. 
I will also provide code examples to show where an optimization might occur, however the optimization may not necessarily occur for that code because another optimization will take precedence. There may also be some general oversimplifications, but not more than I think exists in most posts like these. </p>
</blockquote>
<h2 id="table-of-contents-highlights">Table of Contents / Highlights<a href="#table-of-contents-highlights" aria-label="Anchor link for: table-of-contents-highlights"> <i></i></a>
</h2>
<ul>
<li><a href="https://carolchen.me/blog/jits-impls/#wait-but-you-said-meta-tracing">Meta-tracing in Pypy works</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#interpreting-c">How GraalVM languages support C extensions</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#go-back-to-the-interpreted-code-it-ll-be-faster">Deoptimisation</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#wet-code-is-fast-code-inlining-and-osr">Inlining and OSR</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#what-if-instead-of-instruction-based-ir-like-everyone-else-we-had-a-big-graph-and-also-it-modifies-itself">Seas of Nodes</a></li>
<li><a href="https://carolchen.me/blog/jits-impls/#yay-jit-compiled-code-let-s-compile-it-again-and-again">Tiering JITs</a></li>
</ul>

<p>LuaJIT employs a method called tracing. Pypy does meta-tracing, which involves using a system to generate tracing interpreters and JITs. Pypy and LuaJIT are not the reference implementations of Python or Lua, but a projects on their own. I would describe LuaJIT as shockingly fast, and it describes itself as one of the fastest dynamic language implementations -- which I buy fully.</p>
<p>To determine when to start tracing, the interpreting loop will look for "hot" loops to trace (the concept of "hot" code is universal to JITS!). Then, the compiler will "trace" the loop, recording executed operations to compile well optimized machine code. In LuaJIT, the compilation is performed on the traces with an instruction-like IR that is unique to LuaJIT. </p>
<h3 id="how-pypy-implements-tracing"><strong>How Pypy Implements Tracing</strong><a href="#how-pypy-implements-tracing" aria-label="Anchor link for: how-pypy-implements-tracing"> <i></i></a>
</h3>
<p>Pypy will start tracing a function after 1619 executions, and will compile it after another 1039 executions, meaning a function has to execute around 3000 times for it to start gaining speed. These constants were carefully tuned by the Pypy team (lots of constants are tuned for compilers in general!).</p>
<p>Dynamic languages make it hard to optimize things away. The following code could be statically eliminated by a stricter language, as <code>False</code> will always be falsy. However, in Python 2, that could not have been guaranteed before runtime.</p>
<pre><code><span>if </span><span>False</span><span>:
  </span><span>print</span><span>(</span><span>"FALSE"</span><span>)
</span></code></pre>
<p>For any sane program, the conditional will always be false. Unfortunately, the value of <code>False</code> could be reassigned and thus if the statement were in a loop, it could be redefined somewhere else. For this case, Pypy would build a "guard". When a guard fails, the JIT will fall back to the interpreting loop. Pypy then uses another constant (200), called <em>trace eagerness</em> to decide whether to compile the rest of the new path till the end of the loop. That sub-path is called a <em>bridge</em>.</p>
<p>Pypy also exposes all those constants as arguments that can be tweaked at execution, along with configuration for unrolling (expanding loops) and inlining! It also exposes some hooks so we can see when things are compiled. </p>
<pre><code><span>def </span><span>print_compiler_info</span><span>(</span><span>i</span><span>):
  </span><span>print</span><span>(i</span><span>.</span><span>type)
pypyjit</span><span>.</span><span>set_compile_hook</span><span>(print_compiler_info)

</span><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>if </span><span>False</span><span>:
    </span><span>pass

</span><span>print</span><span>(pypyjit</span><span>.</span><span>get_stats_snapshot</span><span>()</span><span>.</span><span>counters)
</span></code></pre>
<p>Above, I set up a plain python program with a compile hook to print the type of compilation made. It also prints some data at the end, where I can see the number of guards. For the above I get one compilation of a loop and 66 guards. When I replaced the if statement with just a pass under the for-loop, I was left with 59 guards.</p>
<pre><code><span>for </span><span>i </span><span>in </span><span>range</span><span>(</span><span>10000</span><span>):
  </span><span>pass </span><span># removing the `if False` saved 7 guards!
</span></code></pre>
<p>With these two lines added to the for loop, I will get two compilations, with the new one being of type 'bridge'!</p>
<pre><code><span>if </span><span>random</span><span>.</span><span>randint</span><span>(</span><span>1</span><span>, </span><span>100</span><span>) </span><span>&lt; </span><span>20</span><span>:
  </span><span>False </span><span>= </span><span>True
</span></code></pre><h3 id="wait-but-you-said-meta-tracing">Wait, but you said Meta-tracing!<a href="#wait-but-you-said-meta-tracing" aria-label="Anchor link for: wait-but-you-said-meta-tracing"> <i></i></a>
</h3>
<p>The concept behind meta-tracing is “write an interpreter, get a compiler for free!” or more magically, “turn your interpreter into a JIT-compiler!”. This is just obviously a great thing, since writing compilers is hard so if we can get a great compiler for free that’s just a good deal. Pypy "has" an interpreter and a compiler, but there’s no explicit implementation of a traditional compiler.</p>
<p>Pypy has a toolchain called RPython (which was built for Pypy). It is a framework program for implementing interpreters. It is a language in that it specifies a subset of the Python language, namely to force things like static typing. It is a language to write an interpreter in. It is not a language to code in typed-Python, since it doesn’t care or have things like standard libraries or packages. Any RPython program is a valid Python program. RPython programs are transpiled to C and then compiled. Thus, the RPython meta-compiler exists as a compiled C program.</p>
<p>The “meta” in meta-tracing comes from the fact that the trace is on the execution of the interpreter rather than the execution of the program. The interpreter more or less behaves as any interpreter, with the added capability of tracing its own operations, and being engineered to optimize those traces by updating the path of the interpreter (itself). With further tracing, the path that the interpreter takes becomes more optimized. With a very optimized interpreter taking a specific, optimized path, the compiled machine code being used in that path from the compiled RPython can be used as the compilation. </p>
<p>In short, the “compiler” in Pypy is compiling your interpreter, which is why Pypy is sometimes referred to as a meta-compiler. The compiler is less for the program you're trying to execute, but rather for compiling the trace of the optimizing interpreter!</p>
<p>Metatracing might be confusing, so I wrote a very bad metatracing program that can only understand <code>a = 0</code> and <code>a++</code>to illustrate.</p>
<pre><code><span># interpreter written with RPython
</span><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>line </span><span>== </span><span>"a = 0"</span><span>:
    </span><span>alloc</span><span>(a, </span><span>0</span><span>)
  </span><span>elif </span><span>line </span><span>== </span><span>"a++"</span><span>:
    </span><span>guard</span><span>(a, </span><span>"is_int"</span><span>) </span><span># notice how in Python, the type is unknown, but after being interpreted by RPython, the type is known
    </span><span>guard</span><span>(a, </span><span>"&gt; 0"</span><span>)
    </span><span>int_add</span><span>(a, </span><span>1</span><span>)
</span></code></pre>
<p>If I ran the following in a hot loop;</p>
<pre><code><span>a </span><span>= </span><span>0
</span><span>a</span><span>++
</span><span>a</span><span>++
</span></code></pre>
<p>Then the traces may look something like:</p>
<pre><code><span># Trace from numerous logs of the hot loop
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>0</span><span>) </span><span># guards can go away
</span><span>a </span><span>= </span><span>int_add</span><span>(a, </span><span>1</span><span>)
a </span><span>= </span><span>int_add</span><span>(a, </span><span>2</span><span>)

</span><span># optimize trace to be compiled
</span><span>a </span><span>= </span><span>alloc</span><span>(</span><span>2</span><span>) </span><span># the section of code that executes this trace _is_ the compiled code
</span></code></pre>
<p>But the compiler isn't some special standalone unit, it's built into the interpreter! So the interpreter loop would actually look something like this</p>
<pre><code><span>for </span><span>line </span><span>in </span><span>code:
  </span><span>if </span><span>traces</span><span>.</span><span>is_compiled</span><span>(line):
    </span><span>run_compiled</span><span>(traces</span><span>.</span><span>compiled</span><span>(line))
    </span><span>continue
  elif </span><span>traces</span><span>.</span><span>is_optimized</span><span>(line):
    </span><span>compile</span><span>(traces</span><span>.</span><span>optimized</span><span>(line))
      </span><span>continue
  elif </span><span>line </span><span>== </span><span>"a = 0"
  </span><span># ....
</span></code></pre><h2 id="an-introduction-to-jvms">An Introduction to JVMs<a href="#an-introduction-to-jvms" aria-label="Anchor link for: an-introduction-to-jvms"> <i></i></a>
</h2>
<p>Disclaimer: I worked on/with a Graal-based language, <a href="https://github.com/oracle/truffleruby">TruffleRuby</a> for four months and loved it.</p>
<p>Hotspot (named after looking for <em>hot</em> spots) is the VM that ships with standard installations of Java, and there are actually multiple compilers in it for a tiered strategy. Hotspot is open source, with 250,000 lines of code which contains the compilers, and three garbage collectors. It does an <em>awesome</em> job at being a good JIT, there are some benchmarks that have Hotspot on par with C++ impls (oh my gosh so many asterisks on this, you can Google to find all the debate). Though Hotspot is not a tracing JIT, it employs a similar approach of having an interpreter, profiling and then compiling. There is not a specific name for what Hotspot does, though the closest categorization would probably be a Tiering JIT. </p>
<p>Strategies used in Hotspot inspired many of the subsequent JITs, the structure of language VMs and especially the development of Javascript engines. It also created a wave of JVM languages such as Scala, Kotlin, JRuby or Jython. JRuby and Jython are fun implementations of Ruby and Python that compile the source code down to the JVM bytecode and then have Hotspot execute it. These projects have been relatively successful at speeding up languages like Python and Ruby (Ruby more so than Python) without having to implement an entire toolchain like Pypy did. Hotspot is also unique in that it's a JIT for a less dynamic language (though it's technically it's a JIT for JVM bytecode and not Java). </p>
<p><img src="https://carolchen.me/blog/img/jits/vms.png" alt=""></p>
<p>GraalVM is a JavaVM and then some, written in Java. It can run any JVM language (Java, Scala, Kotlin, etc). It also supports a Native Image, to allow AOT compiled code through something called Substrate VM. Twitter runs a significant portion of their Scala services with Graal, so it must be pretty good, and better than the JVM in some ways despite being written in Java. </p>
<p>But wait, there's more! GraalVM also provides Truffle, a framework for implementing languages through building Abstract Syntax Tree (AST) interpreters. With Truffle, there’s no explicit step where JVM bytecode is created as with a conventional JVM language, rather Truffle will just use the interpreter and communicate with Graal to create machine code directly with profiling and a technique called partial evaluation. Partial evaluation is out of scope for this blog post, tl;dr it follows metatracing’s “write an interpreter, get a compiler for free” philosophy but is approached differently.</p>
<blockquote>
<p>TruffleJS, the Truffle implementation of Javascript outperforms the JavaScript V8 engine on select benchmarks which is really impressive since V8 has had numerous more years of development, Google money+resources poured in and some crazy skilled people working on it. TruffleJS is still by no means “better” than V8 (or other JS engines) on most measures but it is a sign of promise for Graal. </p>
</blockquote>

<h3 id="interpreting-c">Interpreting C<a href="#interpreting-c" aria-label="Anchor link for: interpreting-c"> <i></i></a>
</h3>
<p>A common problem with JIT implementations is support for C Extensions. Standard interpreters such …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/jits-impls/">https://carolchen.me/blog/jits-impls/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/jits-impls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739416</guid>
            <pubDate>Sun, 05 Jul 2020 15:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Andrew Wilkinson and Tiny Capital]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23739381">thread link</a>) | @colinkeeley
<br/>
July 5, 2020 | https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual | <a href="https://web.archive.org/web/*/https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-db1d94e86a488296a48d"><div><blockquote><p><em>“Let someone else run the marathon and incentivize them.”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p><strong>What is Tiny?</strong></p><p><a href="http://tinycapital.com/">Tiny</a>&nbsp;is a long term holding company for internet businesses started by&nbsp;<a href="https://twitter.com/awilkinson">Andrew Wilkinson</a>&nbsp;and&nbsp;<a href="https://twitter.com/_sparling_?lang=en">Chris Sparling</a>. They take majority, generally whole, stakes in "profitable, simple, and often boring” internet businesses.&nbsp;</p><p><strong>Why are holding companies and micro private equity interesting?&nbsp;</strong></p><p>I suspect this is the most dependable way to become very wealthy. It isn’t as glamorous or as quick (potentially) as founding or investing in the next multi-billion dollar startup. This is a longer-term grind it out approach.&nbsp;</p><p>Starting companies is fun, but anyone who has done it knows it is a lot of work. Buying established businesses with existing cash flow isn’t as sexy so I suspect it is wildly underrated as a way of building wealth.&nbsp;</p><p>The reality is that it is easier to buy and improve businesses than to start them. It is easier to go from 3 to 10 than from 0 to 1. Even for the folks that have done it before.&nbsp;</p><p>There isn’t much info on how holding companies or micro-PEs like Tiny actually operate. I’ve listened to every podcast Andrew has been on and compiled these notes from them.&nbsp;</p><p>Here is what they are doing behind the scenes.</p><p><strong>How Andrew got started? Where the capital comes from?</strong></p><p>In 2006, Andrew founded&nbsp;<a href="http://metalab.co/">MetaLab</a>, a Victoria, Canada-based design agency shortly after high school. After rapid growth, he used the profits to diversify into a variety of businesses, which today form Tiny, a holding company he owns fully with his business partner Chris Sparling.&nbsp;</p><p>Agencies traditionally aren’t very profitable, but MetaLab is able to charge San Francisco agency rates and only pay Victoria, Canada wages.&nbsp;</p><p>Tiny shifted its focus from starting businesses to buying them in 2013 when MetaLab and all their other businesses combined were doing $7M/year in profit. Tiny is fully self-funded today.</p><p><strong>What’s the scale of Tiny now?</strong></p><p>Comfortably not tiny. It sounds like somewhere around $80-95M revenue per year (double-digit millions is what Andrew says) with highly profitable businesses. They have around 350-400 employees across 20ish companies.&nbsp;</p><p><strong>What Tiny looks for in businesses to buy?</strong></p><p>From their site:</p><blockquote><p><em>3-5+ years of operating history</em></p><p><em>Profits. A minimum $500k/year in annual profit, as high as $15MM.</em></p><p><em>A high-quality team in place. This is negotiable if the business is simple to operate and the team wants to leave.</em></p><p><em>We are open to owners sticking around, leaving cold turkey, or transitioning out over time. We'll work with you to transition.</em></p><p><em>Simple internet businesses that have high margins, don't require tons of people or complex technology, and have a competitive advantage that protects them from competitors. For example: A dominant brand, a large and loyal community, a niche vertical, or something similar.</em></p></blockquote><p>Andrew describes these businesses as "New Zealand companies.”</p><p>What is a New Zealand company?</p><ul data-rte-list="default"><li><p>It is in the middle of nowhere, nobody is paying attention to it, but it is quietly growing. It is not at risk of nuclear war.&nbsp;</p></li><li><p>It is self-sufficient and thriving. It’s food &amp; energy independent. A "safe" business isn't beholden to benevolent gatekeepers like Google or Facebook to reach their customer.&nbsp;</p></li></ul><p>Andrew is always worried about staying power.&nbsp;</p><p>An example of one of his New Zealand business is Dribbble:</p><ul data-rte-list="default"><li><p>Top 1,000 site on the internet&nbsp;</p></li><li><p>A huge community of designers</p></li><li><p>Profitable</p></li><li><p>Few competitors. Big companies are not trying to kill it or compete.&nbsp;</p></li><li><p>Not dependent on Facebook or Google for traffic. People type Dribbble.com into the address bar to visit.&nbsp;</p></li></ul><p><strong>Types of businesses Tiny has bought/started?</strong></p><p>I don’t know if this is by design, but it seems like Andrew has progressed from services to tools/products to platforms/communities to digital marketplaces.&nbsp;</p><ul data-rte-list="default"><li><p>Agencies: MetaLab (design agency), Double Up (podcast growth agency), 8020 (no-code agency)</p></li><li><p>SaaS tools:&nbsp;Flow&nbsp;(product management), Castro (podcast player), Supercast (podcast subscriptions)</p></li><li><p>Products: Caramba (furniture)</p></li><li><p>Communities: Dribbble&nbsp;(designer community)</p></li><li><p>Media: Designer News, RideHome (podcast network)</p></li><li><p>Job Boards:&nbsp;We Work Remotely (remote job board)</p></li><li><p>Digital goods marketplaces: Creative Market, Pixel Union</p></li></ul><p><strong>How Tiny companies operate?</strong></p><p>Tiny companies have fewer information responsibilities than typical PE-owned companies. There are no formal board meetings for example.&nbsp;</p><p>Once a month companies send Tiny a finance-only update with the P&amp;L, balance sheet, and KPIs. No operational info is included.&nbsp;</p><p>Once a quarter companies send Tiny a SWOT (strengths, weaknesses, opportunities, and threats) analysis.&nbsp;</p><p>Companies contact Tiny ASAP for emergencies, major news, or decisions.&nbsp;</p><p>Some CEOs will go 6 months or more without speaking with Andrew.&nbsp;</p><p><strong>How Tiny launches new businesses?</strong></p><p>Tiny’s primary business is buying majority stakes in businesses, not starting them. For a while Andrew would start a new business in any niche he was interested in. He tries to avoid that now and thinks it’s a lot better to buy something that is already good.</p><p>When Andrew does start a new business now, he delegates almost all aspects of it. He recently said he only spent something like 4 hours on each of the new businesses he has launched.&nbsp;</p><p>Andrew will pay for all the work to be done and the investment will form his stake in the business. He will find a CEO to run the business and pay the new CEOs a month or two of salaries to get things going. Then he’ll help with intros, but otherwise, he’ll be hands-off. All in he said it takes $10-50k to get off the ground with a great operator.</p><p><strong>Why do Founders sell to Tiny?</strong></p><p>Tiny is positioned as the good guys of private equity. The Berkshire Hathway of internet businesses.</p><p>They have become known for doing simple acquisitions. Andrew didn’t like the traditional acquisition process: long due diligence, and renegotiation of terms. Warren Buffet does deals in seven days and those are larger, more complex businesses. Smaller deals should be even quicker.</p><p>A challenge with this model is that it is difficult to acquire tech companies at reasonable prices. Acquiring boring traditional businesses is easier because the valuations are so much lower than tech companies. To successfully use this approach you need discipline around what you’re willing to pay for a business and a reputation for being easy to work with. Andrew gets deals by being a nice guy and offering a good home for businesses to live on. Contrast this with the typical PE approach of dramatically cutting costs (ie firing everyone) and squeezing as much profit out as possible. Some founders are looking more for freedom and an easy process than maximizing their financial outcome. </p><p>These smaller PE opportunities are underserved relative to the typical VC businesses. The lifestyle businesses that VC shuns are Andrew’s ideal companies. He is fishing in a less crowded pond. </p><p>Andrew will occasionally pay 10x for an amazing business, but that is rare.&nbsp;</p><p><strong>What happens to businesses after the sale?&nbsp;</strong></p><p>For the employees, it is business as usual for the most part. The goal is for the employees to not even notice.&nbsp; </p><p>The biggest difference is that Tiny becomes the bank. Cash is kept in the company based on historical working capital needs and any extra goes to the head office for new acquisitions.&nbsp; </p><p>Often Tiny buys product or designer-led startups that have grown organically. They will put standard best-practice marketing and sales processes in place and sometimes raise prices. Each company has its own CEO with a few exceptions like all job boards (5+) are under one CEO.&nbsp; </p><p>Tiny has a preference for remote companies where they can hire more affordably. Andrew estimates the cost of running a business in Canada can be 60-65% the cost of in California. Struggling American companies with inflated cost structures can reduce costs by moving to Canada. Canadian arbitrage includes lower salaries, not needing to pay medical benefits, SRED, and cheaper currency.</p><p><strong>Who runs the business after a sale?&nbsp;</strong></p><p>Often Andrew is buying from bootstrapped founders that have been at it for 5-10 years and want to move on.</p><p>Finding great people to run these companies is one of the hardest aspects of this model.&nbsp;</p><p>Andrew deals with this by paying up and hiring CEOs that have managed similar businesses at larger scales already before instead of trying to find underpriced less-experienced talent.&nbsp;</p><p>Months before closing on a deal Andrew works to identify opportunities for the business and a new leader to come in.&nbsp;</p><p>He finds these new CEOs through his existing CEOs by asking “we’re about to buy a business who’s the smartest person you know in the space."</p><p><strong>What does the operating company and Andrew do day-to-day?</strong></p><blockquote><p><em>“Entrepreneurship is just delegation”&nbsp;</em></p><p><em>-Andrew Wilkinson</em></p></blockquote><p>Andrew spends time looking for new deals and looking at their existing portfolio and thinking "how they could get fucked”.&nbsp;</p><p>Andrew says his strengths are:</p><ul data-rte-list="default"><li><p>Laser focused on problems for a short period of time. Moves fast.&nbsp;</p></li><li><p>Very good at 0 to 1. Burns bright for 15 days.&nbsp;</p></li><li><p>Inch deep and a mile wide</p></li><li><p>Not good at execution or day to day details</p></li></ul><p>Being comfortable with delegation is key to this model. Andrew is the owner, not the CEO. The owner can’t constantly be delegating what can or can’t be done or the CEO grows resentful. Some comfort with decisions being made that you don’t agree with comes with the territory. Large decisions that require more capital than usual are a discussion.&nbsp;</p><p><strong>How connected are businesses in the holding company?</strong></p><p>Tiny companies are not at all connected. They each operate independently.&nbsp;</p><p>CEOs will take calls and give advice on best practices, but nothing beyond small favors. Real work gets paid for. Tiny pays all companies for the work they do for the holding company and all work between companies is paid at the full rate.&nbsp;</p><p>Synergies are appealing, but they generally just make the CEOs resentful so they are avoided entirely.&nbsp;</p><p><strong>How much debt do they use?</strong></p><p>Tiny uses little debt for acquisitions (less than Berkshire Hathaway) and they like to pay off debt within 6 months. Debt comes from&nbsp;<a href="https://en.wikipedia.org/wiki/Business_Development_Bank_of_Canada"><strong>BDB of Canada</strong></a>, or traditional banks.</p><p><em>If you …</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual">https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</a></em></p>]]>
            </description>
            <link>https://colinkeeley.com/blog/andrew-wilkinson-tiny-capital-operating-manual</link>
            <guid isPermaLink="false">hacker-news-small-sites-23739381</guid>
            <pubDate>Sun, 05 Jul 2020 15:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Productivity Templates – by experienced project delivery manager]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23738963">thread link</a>) | @sssmith12
<br/>
July 5, 2020 | https://slidegame.io/templates/productivity | <a href="https://web.archive.org/web/*/https://slidegame.io/templates/productivity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://slidegame.io/templates/productivity</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738963</guid>
            <pubDate>Sun, 05 Jul 2020 14:34:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most logical explanation is that it comes from a laboratory]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23738545">thread link</a>) | @markdog12
<br/>
July 5, 2020 | https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860 | <a href="https://web.archive.org/web/*/https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

            <section>

                
                <div>

    

            <h2>NYHET</h2>



        

        

            <h3 itemprop="description">
            The well-known Norwegian virologist Birger Sørensen and his colleagues have examined the corona virus. They believe it has certain properties which would not evolve naturally. These conclusions are politically controversial, but in this interview he shares the findings behind the headlines.
            </h3>

    

</div>


                <div><p>“I understand that this is controversial, but the public has a legitimate need to know, and it is important that it is possible to freely discuss alternate hypotheses on how the virus originated” Birger Sørensen starts to explain when Minerva visits him in his office one morning in Oslo.</p><p>Despite the explosiveness of his statements and research, Sørensen remains calm and collected.</p><p>Sørensen has been a point of controversy ever since former MI6 director Richard Dearlove cited a yet to be published article by Sørensen and his colleagues in an interview with The Daily Telegraph. The article claims that the virus that causes Covid-19 most likely has not emerged naturally.</p><p>“It’s a shame that there has already been so much talk about this, because I have yet to publish the article where I put forward my analysis”, Sørensen says in the form of an exasperated sigh.</p><p>Together with his colleagues, Angus Dalgleish and Andres Susrud have authored an article that looks into the most plausible explanations regarding the origins of the novel coronavirus. The article builds upon an already published article in the Quarterly Review of Biophysics that describes newly discovered properties in the virus spike protein. The authors are still in dialogue with scientific journals regarding an upcoming publication of the article.</p><p>News outlets are thus confronted with a difficult question: Are the findings and arguments Sørensen and his colleagues put forward of a sufficiently high quality to be presented and discussed in the public sphere? Sørensen explains that they in their dialogue with scientific journals are encountering a certain reluctance to publishing the article – without, however, proper scientific objections. Minerva has read a draft of the article, and has after an overall assessment decided that the findings and arguments do deserve public debate, and that this discussion cannot depend entirely on the publication process of scientific journals.</p><p>In this interview with Minerva, Sørensen therefore puts forward his hypothesis on why it is highly unlikely that the coronavirus emerged naturally.</p><p>On May 18th, WHO decided to conduct an inquiry into the coronavirus epidemic in China. Sørensen believes that it is important that this inquiry looks into new and alternate explanations for how the virus originated, beyond the already well-known suggestion that the virus originated in the Wuhan Seafood Market.</p><p>“There are very few who still believe that the epidemic started there, so as of today we have no good answers on how the epidemic started. Then we must also dare to look at more controversial, alternative explanations for the origin,” Sørensen says.</p><p>Birger Sørensen and one of his co-authors, Angus Dalgleish, are already known as HIV researchers par excellence.</p><p>In 2008, Sørensen’s work came to international <a href="https://www.dagensperspektiv.no/2008/norsk-firma-med-hiv-gjennombrudd">attention</a> when he launched a new immunotherapy for HIV. <a href="https://www.nature.com/search?author=%22Angus%20G.+Dalgleish%22">Angus Dalgleish</a> is the professor at St. George’s Medical School in London who became world famous in 1984 after having <a href="https://www.nature.com/articles/312763a0">discovered</a> a novel receptor that the HIV virus uses to enter human cells.</p><p>The purpose of the work Sørensen and his colleagues have done on the novel coronavirus, has been to produce a vaccine. And they have taken their experience in trialling HIV vaccines with them to analyse the coronavirus more thoroughly, in order to make a vaccine that can protect against Covid-19 without major side effects.</p><h2>Exceptionally well adjusted</h2><p>“The difference between our approach and other vaccine manufacturers is that we have a chemistry background, and we analyse the virus in detail as if we were making a drug,” Sørensen starts to explain.</p><p>“Biology is also chemistry, so by considering the virus from a chemistry perspective, we carry out more detailed analysis, zooming in on certain components.”</p><p>Sørensen takes us through the basic elements of their approach:</p><p>“The first thing you need to establish is which parts of the virus are changing, and which parts are stable. If you want to make a vaccine that lasts, you must stimulate the immune system to react against those parts of the virus that are constant, otherwise the effect will disappear and, in the worst-case scenario, lead to increased illness.</p><p>“Once we know this, we can try to make a vaccine. Where we differ is that we are trying to make a vaccine that uses elements that have as little in common with the body’s natural components as possible, so that the immune system is taught to recognise exactly what the vaccine should protect against”, Sørensen elaborates.</p><p>Sørensen believes this is an important insight which will prevent the immune system from being falsely stimulated in a way that could lead the vaccine to create too many dangerous side effects in the vaccinated person.</p><p>“When we have not succeeded in creating an HIV vaccine, despite the enormous efforts put into that endeavour for the past 30 years, it is because we haven’t understood this,” Sørensen continues.</p><p>He believes that there has not been enough interaction between the part of the pharmaceutical industry that makes HIV medicines and the part that runs the vaccine research. As a consequence, the knowledge you need to make a successful vaccine against HIV in the big pharmaceutical companies has not been adequately exploited by the big, international HIV preventing vaccine studies that have been carried out.”</p><p>Asked about what significance his approached has had when he has analyzed the coronavirus, Sørensen explains:</p><p>“We have examined which components of the virus are especially well suited to attach themselves to cells in humans. And we have done this by comparing the properties of the virus with human genetics. What we found was that this virus was exceptionally well adjusted to infect humans.”</p><p>He pauses for a second.</p><p>“So well that it was suspicious,” he adds.</p><h2>Perfected to infect humans</h2><p>It is already known that the novel coronavirus, like the virus that caused the SARS epidemic in Southeast Asia in 2002-2003, could attach itself to the ACE-2 receptors in the lower respiratory tract.</p><p>“But what we have discovered is that there are properties in this new virus which enables it to use an additional receptor, and create a binding to human cells in the upper respiratory tract and the intestines which is strong enough to produce an infection,” Sørensen elaborates.</p><p>Sørensen says that it is the use of this additional receptor that most likely results in a different illness in Covid-19 patients than the one resulting from SARS.</p><p>“This is what enables the virus to transmit to a greater degree between humans, without the virus having attached itself to the ACE-2 receptors in the lower respiratory tract, where it causes deep pneumonia.</p><p>“That is also why so many of the Covid-19 patients have mild symptoms at the start of the illness, and are contagious before they develop severe symptoms,” he adds.</p><p>It might also explain why some people are ‘super spreaders’ without being ill themselves, Sørensen says.</p><p>In the already published article Sørensen and his colleagues Angus Dalgleish and Andres Susrud describe what they claim is curious about the spike protein of the coronavirus, which makes it especially well suited to infect humans. These findings are the foundation for the hypothesis Sørensen and his colleagues develop in the new article, where they claim that the virus is not natural in origin.</p><div id="factbox-361864">
    <div>
        
        <h2>FACT BOX – Spike Protein</h2>
        <p>A spike protein is a part of the virus attached to the surface of the virus. The spike protein is used by the virus when it enters cells, enabling it to stick in humans. The properties of the spike determines which receptors a virus can utilise and thus which cells the virus can enter to create illness.</p>
        
    </div>
    
</div><p>“There are several factors that point towards this,” says Sørensen. “Firstly, this part of the virus is very stable; it mutates very little. That points to this virus as a fully developed, almost perfected virus for infecting humans.</p><p>“Secondly, this indicates that the structure of the virus cannot have evolved naturally. When we compare the novel coronavirus with the one that caused SARS, we see that there are altogether six inserts in this virus that stand out compared to other known SARS viruses,” he goes on explaining.</p><p>Sørensen says that several of these changes in the virus are unique, and that they do not exist in other known SARS coronaviruses.</p><p>“Four of these six changes have the property that they are suited to infect humans. This kind of aggregation of a type of property can be done simply in a laboratory, and helps to substantiate such an origin,” Sørensen points out.</p><h2>An artificially created virus</h2><p>Asked about whether this implies that the virus is not natural, Sørensen goes on to explain the laboratory process that leads to the creation of new viruses.</p><p>“In a sense it is natural. But the natural processes have most likely been accelerated in a laboratory,” he explains. “It’s also possible for a virus to attain these properties in nature, but it’s not likely. If the mutations had happened in nature, we would have most likely seen that the virus had attracted other properties through mutations, not just properties that help the virus to attach itself to human cells.”</p><p>Sørensen vividly explains this argument:</p><p>“Imagine that you have cultivated a billion coronaviruses you have gathered from nature, then you take this mass of viruses and inject them into a human cell culture from for example the upper respiratory tract. As a result, a few of these viruses will change in order to better attach themselves to …</p></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860">https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</a></em></p>]]>
            </description>
            <link>https://www.minervanett.no/corona/the-most-logical-explanation-is-that-it-comes-from-a-laboratory/361860</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738545</guid>
            <pubDate>Sun, 05 Jul 2020 13:38:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New revamped version of the AnyMeal recipe management software]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23738543">thread link</a>) | @wedesoft
<br/>
July 5, 2020 | https://www.wedesoft.de/software/2020/06/30/anymeal/ | <a href="https://web.archive.org/web/*/https://www.wedesoft.de/software/2020/06/30/anymeal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.wedesoft.de/software/2020/06/30/anymeal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23738543</guid>
            <pubDate>Sun, 05 Jul 2020 13:37:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Conflict-Free Replicated Data Types]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23737639">thread link</a>) | @signa11
<br/>
July 5, 2020 | https://lars.hupel.info/topics/crdt/01-intro.html | <a href="https://web.archive.org/web/*/https://lars.hupel.info/topics/crdt/01-intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This is a series about Conflict-Free Replicated Data Types, or CRDTs for short.
Their purpose is to allow seamless replication of data on different nodes in a distributed system.
Merging is by construction always possible, without any conflicts.
This series assumes no knowledge about CRDTs, but be prepared to learn a thing or two about algebras.
All code samples on this page are interactive and executed in your browser.
Understanding the code is necessary for understanding the concepts, so you should be familiar with JavaScript.
If you notice any bugs on this page, <a href="https://github.com/larsrh/website/issues">please let me know</a>!</p><article>
    <p>Dear reader!
If you’re reading this, that’s most likely because you’ve pointed your browser to my website and/or followed a link to this page.
Maybe you’re even reading this from a mobile device!<sup id="fnref:footnote-mobile" role="doc-noteref"><a href="#fn:footnote-mobile">1</a></sup>
Perfect conditions for motivating what all this is about.</p>

<h2 id="contents">Contents</h2>

<ol>
  <li>Preliminaries (this page)</li>
  <li><a href="https://lars.hupel.info/topics/02-contracts">Algebras &amp; contracts</a></li>
  <li><a href="https://lars.hupel.info/topics/03-lattices">Lattices</a></li>
  <li><a href="https://lars.hupel.info/topics/04-combinators">Combinators</a></li>
  <li><a href="https://lars.hupel.info/topics/05-tombstones">Tombstones</a>
    <ul>
      <li>Side note on <a href="https://lars.hupel.info/topics/05a-adt">Abstract Data Types</a></li>
    </ul>
  </li>
  <li><a href="https://lars.hupel.info/topics/06-time">Time</a></li>
  <li><a href="https://lars.hupel.info/topics/07-deletion">Registers and Deletion</a></li>
  <li>Outlook (to be written)</li>
</ol>

<h2 id="the-web-is-a-truly-distributed-application-platform">The web is a truly distributed application platform</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/world.jpg" data-toggle="lightbox" data-footer="A network of nodes">
  <img src="https://lars.hupel.info/img/topics/crdt/world.jpg" alt="A network of nodes" data-toggle="tooltip" data-placement="bottom" title="A network of nodes">
</a></p>

<p>That’s right.
When you’re building a web application, you absolutely, positively have to care about the distributed aspect of the web.
(Unless your application is stateless, like my website.)</p>

<p>What does this mean?
You may have a bunch of users.
These users may be manipulating their data from a variety of devices.
Some devices may have a slow Internet connection.
Devices may go offline at any point in time.</p>

<p>Sometimes, application developers punt on this issue:
the mobile app displays “You’re offline” and won’t let you see your data (best case), or silently discard information (worst case).</p>

<p>One particular piece in the puzzle of building distributed applications is to figure out the <em>storage</em>.
Ideally, this storage should be resilient towards users that may become unavailable, concurrent edits, and so on.</p>

<p>Enter <em>Conflict-free Replicated Data Types</em>.
A glorious example of Computer Science naming that actually Makes Sense™, they attempt to provide a flexible solution to the storage problem.
The fundamental idea is this:
You have data.
This data is stored on multiple <em>replicas</em>.
CRDTs describe how to coordinate these replicas to always arrive at a consistent state.</p>

<p>Note that there are two different categories of CRDTs: <em>state-based</em> and <em>op-based</em>.
Both serve the same purpose, but work in different ways and come with their own design trade-offs.
In this series, I’m mostly going to focus on state-based CRDTs.</p>

<h2 id="about-crdts">About CRDTs</h2>

<p><a href="https://lars.hupel.info/img/topics/crdt/cool.webp" data-toggle="lightbox" data-footer="Abed Nadir thinks CRDTs are cool">
  <img src="https://lars.hupel.info/img/topics/crdt/cool.webp" alt="Abed Nadir thinks CRDTs are cool" data-toggle="tooltip" data-placement="bottom" title="Abed Nadir thinks CRDTs are cool">
</a></p>

<p>That’s it!
You now understand the idea behind CRDTs.</p>

<p>Of course, that’s only half the story.
There are at least two sides to understanding CRDTs deeply.</p>

<ol>
  <li>Knowing all the varieties (counters, maps, sets, …) and how they can be embedded in application software.</li>
  <li>Diving into the mathematical background (lattices! partial orderings! wooooooo) powering their implementations.</li>
</ol>

<p>In this series, I want to focus on the second aspect and explain everything that’s needed in a bottom-up fashion using interactive notebooks, diagrams and code notation that’s familiar with a large amount of programmers: JavaScript.
I’ll be employing a few libraries for testing code and visualizing data, but otherwise, there are no further dependencies.
The research papers that describe them often assume a great deal of background knowledge in abstract algebra.
I’ll try to introduce just the necessary knowledge gently.</p>

<p>If however, you want to learn more about their use, this series is not for you.
But fear not: there are tons of resources to check out, e.g. <a href="https://crdt.tech/">crdt.tech</a>.
There’s no tracking on this page so I won’t even notice if you’re gone 🤷</p>

<p>Still here?
Cool. <em>Cool, cool, cool.</em></p>

<p>But before we can strap in and talk about CRDTs, we first need to get some paperwork out of the way.</p>

<h2 id="how-to-work-with-this-document">How to work with this document</h2>

<p>All code snippets here are live: this page functions similarly to Jupyter Notebook.
The main difference is that all code is executed in your browser; there’s no roundtrip to a backend service.
Snippets are evaluated when a page is loaded and can be re-evaluated by clicking the <em>Run</em> button.
Feel free to change any snippet to your liking, but note that subsequent snippets are not automatically re-run.
If you want to reset the session, e.g. because you deleted some code, just reload the page.
Your code is not saved between reloads!</p>

<h2 id="tests">Tests</h2>

<p>This page has a built-in test runner.
It takes named <em>properties</em> that should be checked.
The term <em>property</em> is overloaded in programming, so let me be clear: I’m not talking about properties in an object; instead I’m talking about functions that may take arguments and return a truth value.
In other words, a property is a predicate that should be evaluated on ideally all inputs to see if it always holds.</p>

<p>In the following example, we have two properties, one is valid, the other one isn’t.
They are defined using the <a href="https://github.com/dubzzz/fast-check/">fast-check</a> library, which is available under the <code>fc</code> object.</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; x == x),
  "fail": fc.property(fc.string(), x =&gt; x != x)
});
</code></pre></div></div>

<p>Under the hood, fast-check automatically generates 100 different inputs.
Granted, 100 different inputs is not exactly <em>all inputs</em>, but since there are infinitely many strings, we can’t exactly do that, can we?
fast-check will call the function (e.g. <code>x =&gt; x == x</code>) with the inputs as specified (<code>fc.string()</code> generates ASCII strings with only printable characters).
If the function ever returns <code>false</code> or throws an exception, the property is marked as failed.
Otherwise, it’s marked as successful.</p>

<p>Fortunately, we can also use <a href="https://www.chaijs.com/">Chai</a> assertions inside our properties to get rich error messages:</p>

<div><div><pre><code>checkAll({
  "succeed": fc.property(fc.string(), x =&gt; assert.equal(x, x)),
  "fail": fc.property(fc.string(), x =&gt; assert.notEqual(x, x))
});
</code></pre></div></div>

<p>The great thing about fast-check is that it will automatically show you the <em>smallest</em> (and hopefully simplest) input it could find where the property failed.
This is called the <em>counterexample</em>.
There could be many counterexamples, but here, we only show one.</p>

<div><div><pre><code>checkAll({
  "strlen": fc.property(fc.string(), x =&gt; assert.isAtMost(x.trim().length, 5))
});
</code></pre></div></div>

<p>You’ll see in the results a failure where the counterexample has length 6 and does not just consist of spaces.</p>

<p>Note that a property could be invalid and we’d still not notice it because fast-check didn’t generate that input for us.
That’s a risk we have to live with.</p>

<h2 id="playground">Playground</h2>

<p>Intrigued?
Why not play around with the test runner a little.
Of course, you could modify the code boxes above, but maybe you were afraid to.
So, I prepared a special playground just for you.
Go wild!</p>

<div><div><pre><code>checkAll({
  "be-creative": null
});
</code></pre></div></div>

<p>Feel free to consult the <a href="https://github.com/dubzzz/fast-check/blob/v1.24.1/documentation/1-Guides/Arbitraries.md">fast-check documentation</a> about which data generators there are.</p>

<h2 id="printing">Printing</h2>

<p>The runner can also print different kinds of outputs, e.g. arrays.
Note that only the last expression in a snippet is printed.</p>

<div><div><pre><code>1 + 1;

[
  "this",
  "is",
  "an",
  "array"
]
</code></pre></div></div>

<p>If you define variables without <code>var</code> (or <code>const</code> or <code>let</code>), they can be accessed in subsequent snippets.
I will use that throughout the series.</p>

<p>We can define different printing for a particular object using the <code>interactiveRender</code> symbol.
It can be declared as a method and will be invoked by the runner automatically:</p>

<div><div><pre><code>class Test {
  constructor(value) {
    this.value = value;
  }

  [interactiveRender]() {
    return `Hi ${this.value}!`;
  }
}

new Test("reader")
</code></pre></div></div>

<h2 id="onwards">Onwards</h2>

<p>You are now ready to proceed with the actual introduction.
<a href="https://lars.hupel.info/topics/02-contracts">Go here</a> to learn all about contracts.</p>

<h2 id="testimonials">Testimonials</h2>

<p>People on The Internet™ seem to enjoy these posts:</p>

<div><blockquote><p lang="en" dir="ltr">Great read. This is as entertaining as educational.</p>— Julius Adorf (@jeadorf) <a href="https://twitter.com/jeadorf/status/1276235893586702336?ref_src=twsrc%5Etfw">June 25, 2020</a></blockquote>

</div>
<div><blockquote><div lang="en" dir="ltr"><p>GREAT STUFF</p><p>I found this incredibly accessible, as I have at best a shallow grasp of this kind of mathematics.</p><p>I'd only learned about Lattice theory in the last couple of weeks (while searching for partial ordering), and found your article on lattices easy to follow.</p><p>1/(2 V 3)</p></div>— david Kaye (--The "K" stands for Quality) (@dfkaye) <a href="https://twitter.com/dfkaye/status/1279152170869207040?ref_src=twsrc%5Etfw">July 3, 2020</a></blockquote>

</div>

<h2 id="references">References</h2>

<ul>
  <li>Map by TheAndrasBarta on <a href="https://pixabay.com/photos/world-europe-map-connections-1264062/">Pixabay</a></li>
  <li>Abed Nadir on <a href="https://giphy.com/gifs/community-abed-cool-2HONNTJbRhzKE">Giphy</a></li>
</ul>




<hr>

Thanks to the people who've read drafts of this series and provided valuable feedback:
Andrea, Clement Delafargue, Heiko Seeberger, Hillel Wayne, Johannes Link, Matthew Weidner, Princess.

  </article></div>]]>
            </description>
            <link>https://lars.hupel.info/topics/crdt/01-intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737639</guid>
            <pubDate>Sun, 05 Jul 2020 09:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust on the ESP32 (2019)]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23737451">thread link</a>) | @lnyan
<br/>
July 5, 2020 | https://mabez.dev/blog/posts/esp32-rust/ | <a href="https://web.archive.org/web/*/https://mabez.dev/blog/posts/esp32-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p>About six months ago, I made a <a href="https://www.reddit.com/r/rust/comments/ar2d3r/espressif_have_finally_released_an_llvm_fork_this/">post on reddit</a> highlighting the launch of Espressif's llvm xtensa fork, not too long after, I had a working <code>rustc</code> toolchain capable of generating xtensa assembly. At this point I had to put this project to the side to finish my final year of university. Funnily enough I didn't stray too far, my final year project used Rust to create a <a href="https://github.com/MWatch">'smartwatch'</a> (I may write about this in the future, if anyone is interested). </p>
<p>Since then I have seen a few posts utilising my fork to run Rust on the <a href="https://www.espressif.com/en/products/hardware/esp32/overview">ESP32</a> (<a href="https://dentrassi.de/2019/06/16/rust-on-the-esp-and-how-to-get-started/">see this great write up</a> by ctron, if you haven't already), most of which are building on top of <a href="https://github.com/espressif/esp-idf">esp-idf</a> which is written in C. In this post I'll be discussing the steps I took to generate valid binaries for the xtensa architecture with <code>rustc</code> and then write some <code>no_std</code> code to build a blinky program for the ESP32 only using Rust!</p>
<h2 id="hacking-the-compiler">Hacking the compiler</h2>
<p>In March of 2019, Espressif released their first run at an <a href="https://github.com/espressif/llvm-xtensa">llvm fork</a> to support the xtensa architecure. Shortly after I got to work bootstrapping Rust to use this newly created fork. Prior to this project, I'd had no experience with the compiler, fortunately I came across the <a href="https://github.com/rust-lang/rust/pull/52787">RISCV PR</a> which gave me a rough idea of what was required. After <em>many</em> build attempts I finally got it working; I was now able to generate xtensa assembly from Rust source code!</p>
<p>The next step was to assemble and link the generated assembly. The llvm fork in it's current state cannot perform object generation, so we must use an external assembler. Luckily Rust allows us to do so by specifying the <code>linker_flavor</code> as <code>gcc</code> and providing a path to the linker with the <code>linker</code> target option, in this case <code>xtensa-esp32-elf-gcc</code>. After that I created a few built-in targets (which you can see <a href="https://github.com/MabezDev/rust-xtensa/blob/ad570c5cb999f62a03156286fdb5d3d1bbd0fb8b/src/librustc_target/spec/xtensa_esp32_none_elf.rs">here</a>); <code>xtensa-esp32-none-elf</code> for the ESP32; <code>xtensa-esp8266-none-elf</code> for the ESP8266; finally the <code>xtensa-unknown-none-elf</code> target for a generic xtensa target.</p>
<h2 id="blinky-code">Blinky code</h2>
<p>Now lets try and get a ESP32 board to blink the onboard LED using just Rust. First off, we need our basic program structure. The <code>xtensa_lx6_rt</code> crate does most of the heavy lifting in this respect, we simply need to define an entry point and the panic handler. Some of this may look vaguely familiar if you have any experience with <code>cortex-m</code> development on Rust, I've tried to mirror the API as best as I can.</p>
<pre><span>#![</span><span>no_std</span><span>]
#![</span><span>no_main</span><span>]


</span><span>use</span><span> xtensa_lx6_rt as _;

</span><span>use </span><span>core::panic::PanicInfo;

</span><span>/// Entry point - called by xtensa_lx6_rt after initialisation
</span><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>loop </span><span>{}
}

</span><span>/// Simple panic handler
</span><span>#[</span><span>panic_handler</span><span>]
</span><span>fn </span><span>panic</span><span>(</span><span>_info</span><span>: &amp;PanicInfo) -&gt; ! {
    </span><span>loop </span><span>{}
}
</span></pre>
<p>Now lets add some register definitions for the peripherals we want to use. For our blinky program, we will need to control the GPIO peripheral. In the ESP32 (and most modern processors) peripherals are mapped to memory adresses, commonly refered to as memory mapped peripherals. To control a peripheral we simply need to write values to the right addresses in memory, with respect to the reference manual supplied by the chip manufacturer.</p>
<pre><span>/// GPIO output enable reg
</span><span>const </span><span>GPIO_ENABLE_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44024</span><span>;

</span><span>/// GPIO output set register
</span><span>const </span><span>GPIO_OUT_W1TS_REG</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44008</span><span>;
</span><span>/// GPIO output clear register
</span><span>const </span><span>GPIO_OUT_W1TC_REG </span><span>: </span><span>u32 </span><span>= </span><span>0x3FF4400C</span><span>;

</span><span>/// The GPIO hooked up to the onboard LED
</span><span>const </span><span>BLINKY_GPIO</span><span>: </span><span>u32 </span><span>= </span><span>2</span><span>;

</span><span>/// GPIO function mode
</span><span>const </span><span>GPIO_FUNCX_OUT_BASE</span><span>: </span><span>u32 </span><span>= </span><span>0x3FF44530</span><span>;
</span><span>const </span><span>GPIO_FUNCX_OUT_SEL_CFG</span><span>: </span><span>u32 </span><span>= </span><span>GPIO_FUNCX_OUT_BASE </span><span>+ (</span><span>BLINKY_GPIO </span><span>* </span><span>4</span><span>);
</span></pre>
<p>Using these definitions it should be possible to change the gpio for your board<sup><a href="#gpio_pin">1</a></sup> by changing the <code>BLINKY_GPIO</code>; for my board (NODEMCU ESP-32S) it was GPIO2.</p>
<h3 id="initialisation">Initialisation</h3>
<p>Next lets setup the pin as a GPIO output. For the ESP32, this is a two step process<sup><a href="#gpio_pin">1</a></sup>. Firstly, its simply a case of setting a bit in the GPIO ouput enable register. Secondly the pin has to be configured in GPIO mode. There are not enough pins for all the possible peripherals in the chip, to combat this each pin can have multiple function modes. In the case of the ESP32, each pin has up to 256 different functions, although not all are mapped. To put the pin in GPIO mode, we need to put in mode 256 (0x100), we do this by writing to the function select register. After issuing those two register writes, we should be able to turn on the GPIO by setting the relevant bit inside the GPIO set register<sup><a href="#2">2</a></sup>.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {

    </span><span>// configure the pin as an output
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_ENABLE_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; </span><span>BLINKY_GPIO</span><span>);
        </span><span>// 0x100 makes this pin a simple gpio pin - see the technical reference for more info
        </span><span>core::ptr::write_volatile(</span><span>GPIO_FUNCX_OUT_SEL_CFG </span><span>as </span><span>*mut </span><span>_, </span><span>0x100</span><span>); 
    }
    </span><span>// turn on the LED
    </span><span>unsafe </span><span>{
        core::ptr::write_volatile(</span><span>GPIO_OUT_W1TS_REG </span><span>as </span><span>*mut </span><span>_, </span><span>0x1 </span><span>&lt;&lt; idx);           
    }
    </span><span>loop </span><span>{}
}
</span></pre><h3 id="delaying">Delaying</h3>
<p>For the next stage of our blinky program, we need a way to delay; a simple approach could use <code>for</code> loop like so.</p>
<pre><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>let</span><span> dummy_var: </span><span>u32 </span><span>= </span><span>0</span><span>;
    </span><span>for </span><span>_ in </span><span>0</span><span>..clocks {
        </span><span>unsafe </span><span>{ core::ptr::read_volatile(&amp;dummy_var) };
    }
}
</span></pre>
<p>We add the volatile read so that the compiler doesn't optimise our delay away. The problem with this approach is that depending of the optimisation level, the number of clock cycles each iteration of the loop changes. We need a cycle accurate way of delaying, fortunately the ESP32 has an internal clock counting register which can be accessed with the read special register <code>rsr</code> instruction. Now are delay function looks like this.</p>
<pre><span>/// cycle accurate delay using the cycle counter register
</span><span>pub fn </span><span>delay</span><span>(</span><span>clocks</span><span>: </span><span>u32</span><span>) {
    </span><span>// NOTE: does not account for rollover
    // ommitted: the asm to read the ccount
    </span><span>let</span><span> target = </span><span>get_ccount</span><span>() + clocks;
    </span><span>loop </span><span>{
        </span><span>if </span><span>get_ccount</span><span>() &gt; target {
            </span><span>break</span><span>;
        }
    }
}
</span></pre>
<p>Now we have cycle accurate counting we can delay for one second by waiting for the number of cycles the processor will do in one second. The default clock speed on most ESP boards is 40mhz, hence waiting for 40 million cycles equates to a one second delay.</p>
<p>Bringing the snippets together and cleaning up the code into functions, we now have <code>main</code> that looks like this.</p>
<pre><span>#[</span><span>no_mangle</span><span>]
</span><span>fn </span><span>main</span><span>() -&gt; ! {
    </span><span>// configure the pin as an output
    </span><span>configure_pin_as_output</span><span>(</span><span>BLINKY_GPIO</span><span>);

    </span><span>loop </span><span>{
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>true</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
        </span><span>set_led</span><span>(</span><span>BLINKY_GPIO</span><span>, </span><span>false</span><span>);
        </span><span>delay</span><span>(</span><span>CORE_HZ</span><span>);
    }
}
</span></pre>
<p>After flashing to the board, and firing up our JTAG debugger<sup><a href="#1">3</a></sup>, we are greeted with a blinking LED!</p>

<p>The full source can be found in the <a href="https://github.com/MabezDev/xtensa-rust-quickstart">the xtensa quickstart repo</a> if you wish to try it for yourself.</p>
<p>Now I know what most of you are thinking at this point, it's not very Rusty; it contains bundles of unsafe and there are no real abstractions here, and you are right; but it's something to get the ball rolling.</p>
<h2 id="limitations">Limitations</h2>
<p>There are a few small teething issues, but by far the biggest being issue is that the fork struggles with generating debug info; the external assembler does not support <a href="https://sourceware.org/binutils/docs-2.24/as/CFI-directives.html#CFI-directives">CFI directives</a> something that all llvm targets need to support. CFI directives can easily be removed with some preprocessing, but does of course add an extra step. After pushing past that issue, I was still getting relocation linker errors. I opened <a href="https://github.com/espressif/llvm-xtensa/issues/10">an issue</a> to document my findings in the hopes it can be sorted in the next iteration of the llvm fork.</p>
<h2 id="future-work">Future work</h2>
<p>Once the debuginfo issue is sorted, I hope to start developing an ecosystem of HAL's and drivers similar to the <a href="https://github.com/stm32-rs">stm32-rs</a> and <a href="https://github.com/nrf-rs">nrf-rs</a>; I've already started the <a href="https://github.com/esp-rs">esp-rs</a> organization which is where <code>xtensa-lx6-rt</code> currently resides. Espressif has started the upstream process, the first ten patches are now in review, there should be an update coming to their fork moving from the older llvm6 to llvm8 (and hopefully some other additions and fixes too!).</p>
<h2 id="links">Links</h2>
<ul>
<li><a href="https://github.com/MabezDev/xtensa-rust-quickstart">xtensa-quickstart</a> - A quickstart project for using Rust on xtensa</li>
<li><a href="https://github.com/MabezDev/rust-xtensa">rust-xtensa</a> - The xtensa fork of Rust</li>
<li><a href="https://github.com/MabezDev">github</a> - My github</li>
</ul>
<br>
<hr>
<br>




	</div></div>]]>
            </description>
            <link>https://mabez.dev/blog/posts/esp32-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23737451</guid>
            <pubDate>Sun, 05 Jul 2020 09:00:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Abstraction]]>
            </title>
            <description>
<![CDATA[
Score 243 | Comments 79 (<a href="https://news.ycombinator.com/item?id=23735991">thread link</a>) | @jesseduffield
<br/>
July 4, 2020 | https://jesseduffield.com/beginners-guide-to-abstraction/ | <a href="https://web.archive.org/web/*/https://jesseduffield.com/beginners-guide-to-abstraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-75">
	<!-- .entry-header -->

	
	
	<div>
		<p>In <em>The Pragmatic Programmer</em>, Andrew Hunt and David Thomas introduced the DRY (Don't Repeat Yourself) principle. The rationale being that if you see the same code copy+pasted 10 times you should probably factor that code into its own method/class.</p>
<p>But then Sandi Metz came along and <a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction">said</a>:</p>
<blockquote>
<p>Duplication is far cheaper than the wrong abstraction.</p>
</blockquote>
<p>And so the eternal war began.</p>
<h3>What is abstraction?</h3>
<p>For the purposes of this post I'm referring to the kind of abstraction as described in the <a href="https://en.wikipedia.org/wiki/Abstraction_(computer_science)#Abstraction_in_object_oriented_programming">Abstraction Principle</a>, which Wikipedia describes like so:</p>
<blockquote>
<p>In software engineering and programming language theory, the abstraction principle (or the principle of abstraction) is a basic dictum that aims to reduce duplication of information in a program (usually with emphasis on code duplication) whenever practical by making use of abstractions provided by the programming language or software libraries</p>
</blockquote>
<p>This post has nothing to say about the conceptual kind of abstraction where from the concrete examples of 'Parrot' and 'Sparrow' you create an abstraction of 'Bird'. This post is about duplicated code, how to respond to it, and how to respond to other people's responses to it.</p>
<p>I define the verb 'abstraction' to be an <em>attempt</em> to reduce complexity by combining repeated commonality into some generalisation. And so, the noun 'abstraction' is the result of that attempt. If you're somebody who believes abstraction is by definition a <em>successful</em> attempt, feel free to substitute the term 'wrong abstraction' with 'failure to abstract' throughout this post.</p>
<p>The process of abstraction typically goes like this:<br>
1) you identify different chunks of code that you think are all essentially doing the same thing<br>
2) you create a method or a class with a narrow interface which can be substituted in for all the chunks of code you found<br>
3) you go and swap out the chunks of code with a call to your method/class</p>
<h3>Abstraction is always a gamble</h3>
<p>In the world of software engineering, when requirements are always changing, every abstraction is a gamble. When you make an abstraction over some concrete things, you're making a bet that the concrete things are more similar than they are different, and that their similarities are not mere coincidences: that there is a common purpose shared by the concrete things which would lead them to evolve in lockstep as requirements evolve. If you win the bet, your codebase will be easier to work in and adding new use cases via your abstraction will be trivially easy. If you lose, you'll see a flash of fear in your colleague's eyes whenever they're assigned a ticket to make yet another extension to the misfigured monster that the once-innocent abstraction has now become</p>
<p>But risk abounds everywhere, and leaving duplicated code unabstracted is its own gamble. You're betting that the chunks of code will evolve in separate directions as requirements change and that their current similarities are more coincidence than a reflection of their common purpose. Win the bet and your colleague gets to sleep soundly at night knowing they won't be facing the abstraction monster at work the next day. Lose, and code that should have evolved in lockstep is now implemented in completely different ways across different files, where a developer fixes a bug identified in one place, only for the same bug to be reported days later in a completely different file.</p>
<p>Your job is to get good at making the right bets.</p>
<h3>The right/wrong abstraction</h3>
<p>You'll know that you've made the <em>right</em> abstraction when a long time passes and you haven't needed to expand the interface (an example of expanding the interface is adding an optional flag argument). You'll also know you've made the right abstraction when another developer doesn't find it that much harder to understand how the code behaves for a given use case than if somebody had written the code to satisfy the use case without the abstraction.</p>
<p>You'll know you've made the <em>wrong</em> abstraction when after a while the interface has been expanded to support various optional flags, each for a different use case, and you need to be a genius to reason about what the code will actually do for a given use case. By the way, if you have a string arg that merely gets fed into a switch statement inside a method and for each new use case you come up with a new accepted value for it, you <em>are</em> expanding the implicit interface, even if that fact isn't captured in your type system.</p>
<p>There is plenty of daylight between the perfect abstraction and the completely wrong abstraction (perhaps the interface needs to be fundamentally changed but afterwards you're back to having a good abstraction), and so the point of this section isn't to prescribe how much you should be abstracting, but to encourage you to think about both perspectives and be able to make a case in a PR review for why you think an abstraction should/should-not exist.</p>
<h3>Do you over or under-abstract?</h3>
<p>Given it is impossible to make the right decision with regards to abstraction every time, you are probably either somebody who over-abstracts or somebody who under-abstracts.</p>
<p>If common feedback on your PR reviews is that you should DRY up your code, you could probably benefit from doing a scan for duplicated code before submitting a PR and considering whether it belongs in its own method/class.</p>
<p>If you commonly get feedback that your methods are hard to understand because they support too many disparate use cases at once, you are probaby over-abstracting and should consider whether you should increase your tolerance for duplication.</p>
<p>Note that it's not always as simple as under-abstracting vs over-abstracting. Sometimes abstraction is appropriate, but you might take the wrong approach. If an abstraction is deemed wrong by the team, that doesn't mean no abstraction is necessarily the best alternative.</p>
<h3>Under-abstraction examples</h3>
<p>The main sign that you could be under-abstracting is that you have a heap of code doing the exact same thing called in a heap of places with no obvious reason why anybody would want the code to diverge.</p>
<h4>Example: Hard-coded formulas</h4>
<h5>Bad:</h5>
<pre><code># sphere has radius of 11
sphere_volume = 4*Math::PI/3*11**3
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = 4*Math::PI/3*radius**3
sphere.volume = volume</code></pre>
<h5>Good:</h5>
<pre><code>def sphere_volume(radius)
  4*Math::PI/3*radius**3
end

# sphere has radius of 11
sphere_volume = sphere_volume(11)
puts "the volume of the sphere is #{sphere_volume} cm^3"
...

radius = calculate_radius
volume = sphere_volume(radius)
sphere.volume = volume</code></pre>
<p>Why is it a good idea to abstract the formula for a sphere's volume into its own method? Because if mathematicians ever found out they got the formula wrong, you would want to go through all the places in your code that you used the formula and update it to be correct. That is, we know ahead of time that we want the code to be in lockstep. This is as safe a gamble as you can get.</p>
<h3>Over-abstraction examples</h3>
<p>The main sign that you're over-abstracting is that your method accepts a bunch of optional args:</p>
<h4>Example: Bloated method</h4>
<h5>Bad:</h5>
<pre><code>def average(arr, type = Integer, ignore_nulls = false)
  if arr.any?(&amp;:nil?)
    if ignore_nulls
      arr = arr.compact
    else
      return nil
    end
  end

  if type == String
    arr = arr.map(&amp;:to_i)
  end

  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

puts average(['1','2','3'], String)
=&gt; 2

puts average(['1','2','3', nil], String, true)
=&gt; 2

puts average([1, 2, 3, nil], Integer, false)
=&gt; nil</code></pre>
<p>If you want to know how the <code>average</code> method behaves when you're dealing with an array of strings with no <code>nil</code> values, you have to read through the first if condition which has nothing to do with your use case before reaching the code that does. Likewise if you want to know how the <code>average</code> method behaves when the array contains either nils or integers, the second if condition is irrelevant, but you'll still need to read through that to understand how the whole thing works.</p>
<p>If each of the use cases came up dozens or hundreds of times, maybe then it would make sense to retain the abstraction, but when the number of optional arguments is roughly equal to the number of different use cases, chances are you've got the wrong abstraction.</p>
<h5>Good:</h5>
<pre><code>def average(arr)
  arr.sum / arr.size
end

puts average([1,2,3])
=&gt; 2

arr = ['1','2','3'].map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = ['1','2','3', nil].compact.map(&amp;:to_i)
puts average(arr)
=&gt; 2

arr = [1, 2, 3, nil]
if arr.any?(&amp;:nil?)
  puts nil
else
  puts average(arr)
end
=&gt; nil</code></pre>
<p>In this case we're not removing the abstraction altogether: we're just keeping the part that actually applies to all cases. Now understanding the logic of any one invocation of our <code>average</code> method is trivial.</p>
<p>We now have <code>.map(&amp;:to_i)</code> being duplicated whereas it only appeared once in the <code>Bad</code> alternative, but it's a small cost for a vast improvement.</p>
<p>Note that looking at the <code>Good</code> variant, it's clear that the behaviour is quite different from one use case to the next, but that is not at all clear in the <code>Bad</code> variant because the method calls all look so simple and it was anybody's guess how much code inside <code>average</code> applied to each use case.</p>
<p>This is why abstractions go bad over time: because as you expand the interface more and more, it becomes harder and harder to judge how appropriate the abstraction is to any given use case, and developers end up assuming that all that convoluted code is vaguely relevant to the majority of use cases when in fact it's not.</p>
<h4>Example: Awkward class</h4>
<h5>Bad:</h5>
<pre><code>class Shape
  def initialize(radius: nil, width: nil, type:)
    @radius = radius
    @width = width
    @type = type
  end

  def area
    case @type
    when :square
      @width ** 2
    when :circle
      (@radius ** 2) * Math::PI
    end
  end

  def perimeter
    case @type
    when :square
      @width * 4
    when :circle
      @radius * 2 * Math::PI
    end
  end

  def diameter
    case @type
    when :square
      nil
    when :circle
 …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesseduffield.com/beginners-guide-to-abstraction/">https://jesseduffield.com/beginners-guide-to-abstraction/</a></em></p>]]>
            </description>
            <link>https://jesseduffield.com/beginners-guide-to-abstraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23735991</guid>
            <pubDate>Sun, 05 Jul 2020 01:12:40 GMT</pubDate>
        </item>
    </channel>
</rss>
