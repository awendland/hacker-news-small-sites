<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 21 Nov 2020 16:35:14 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 21 Nov 2020 16:35:14 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Go standard library benchmarks – Intel vs. M1]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25158243">thread link</a>) | @jeremylevy
<br/>
November 19, 2020 | https://roland.zone/m1-go-benchmarks/ | <a href="https://web.archive.org/web/*/https://roland.zone/m1-go-benchmarks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr><th></th><th colspan="2">time/op</th><th>delta
</th></tr><tr><th colspan="4">pkg:archive/tar goos:darwin goarch:arm64</th></tr><tr><td>/Writer/USTAR</td><td>20.2Âµs Â±26%</td><td>2.4Âµs Â± 1%</td><td>âˆ’87.95%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>/Writer/GNU</td><td>4.56Âµs Â± 2%</td><td>2.84Âµs Â± 0%</td><td>âˆ’37.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Writer/PAX</td><td>7.95Âµs Â± 2%</td><td>4.96Âµs Â± 0%</td><td>âˆ’37.59%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/USTAR</td><td>3.60Âµs Â± 2%</td><td>2.20Âµs Â± 2%</td><td>âˆ’38.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/GNU</td><td>2.29Âµs Â± 2%</td><td>1.40Âµs Â± 0%</td><td>âˆ’38.74%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/PAX</td><td>7.58Âµs Â± 3%</td><td>4.65Âµs Â± 1%</td><td>âˆ’38.57%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:archive/zip goos:darwin goarch:arm64</th></tr><tr><td>CompressedZipGarbage</td><td>4.84ms Â± 8%</td><td>1.57ms Â± 0%</td><td>âˆ’67.51%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Zip64Test</td><td>12.1ms Â± 3%</td><td>11.8ms Â± 1%</td><td>~</td><td>(p=0.095 n=5+5)
</td></tr><tr><td>Zip64TestSizes/4096</td><td>7.44Âµs Â±12%</td><td>3.79Âµs Â± 3%</td><td>âˆ’49.01%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Zip64TestSizes/1048576</td><td>102Âµs Â± 5%</td><td>40Âµs Â± 2%</td><td>âˆ’60.29%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Zip64TestSizes/67108864</td><td>6.02ms Â± 3%</td><td>2.26ms Â± 1%</td><td>âˆ’62.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:bufio goos:darwin goarch:arm64</th></tr><tr><td>ReaderCopyOptimal</td><td>84.5ns Â± 4%</td><td>54.9ns Â± 1%</td><td>âˆ’35.01%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderCopyUnoptimal</td><td>140ns Â± 4%</td><td>91ns Â± 0%</td><td>âˆ’34.72%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderCopyNoWriteTo</td><td>3.98Âµs Â± 4%</td><td>1.55Âµs Â± 1%</td><td>âˆ’60.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderWriteToOptimal</td><td>313ns Â± 5%</td><td>321ns Â± 1%</td><td>~</td><td>(p=0.310 n=5+5)
</td></tr><tr><td>ReaderReadString</td><td>107ns Â± 3%</td><td>74ns Â± 0%</td><td>âˆ’30.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyOptimal</td><td>91.3ns Â± 2%</td><td>58.1ns Â± 1%</td><td>âˆ’36.39%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyUnoptimal</td><td>116ns Â± 2%</td><td>70ns Â± 1%</td><td>âˆ’39.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyNoReadFrom</td><td>3.85Âµs Â± 2%</td><td>1.53Âµs Â± 0%</td><td>âˆ’60.21%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderEmpty</td><td>792ns Â± 4%</td><td>354ns Â± 1%</td><td>âˆ’55.27%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterEmpty</td><td>694ns Â± 5%</td><td>342ns Â± 1%</td><td>âˆ’50.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterFlush</td><td>13.7ns Â± 2%</td><td>8.9ns Â± 4%</td><td>âˆ’34.87%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:bytes goos:darwin goarch:arm64</th></tr><tr><td>ReadString</td><td>5.76Âµs Â± 5%</td><td>2.16Âµs Â± 2%</td><td>âˆ’62.56%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriteByte</td><td>13.2Âµs Â±12%</td><td>9.0Âµs Â± 1%</td><td>âˆ’31.51%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriteRune</td><td>32.4Âµs Â± 2%</td><td>18.2Âµs Â± 1%</td><td>âˆ’43.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BufferNotEmptyWriteRead</td><td>222Âµs Â± 1%</td><td>184Âµs Â± 1%</td><td>âˆ’17.11%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BufferFullSmallReads</td><td>50.8Âµs Â± 1%</td><td>36.1Âµs Â± 0%</td><td>âˆ’28.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/10</td><td>5.17ns Â± 2%</td><td>4.16ns Â± 1%</td><td>âˆ’19.48%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/32</td><td>6.46ns Â± 2%</td><td>3.94ns Â± 0%</td><td>âˆ’38.91%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>IndexByte/4K</td><td>84.3ns Â± 2%</td><td>72.9ns Â± 1%</td><td>âˆ’13.52%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/4M</td><td>176Âµs Â±15%</td><td>64Âµs Â± 0%</td><td>âˆ’63.48%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/64M</td><td>4.42ms Â± 2%</td><td>1.08ms Â± 2%</td><td>âˆ’75.47%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/10</td><td>6.38ns Â± 1%</td><td>5.66ns Â± 1%</td><td>âˆ’11.29%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/32</td><td>27.7ns Â± 1%</td><td>12.5ns Â± 0%</td><td>âˆ’54.77%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>IndexBytePortable/4K</td><td>1.55Âµs Â± 2%</td><td>1.29Âµs Â± 0%</td><td>âˆ’16.30%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/4M</td><td>1.60ms Â± 1%</td><td>1.31ms Â± 0%</td><td>âˆ’17.84%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/64M</td><td>26.3ms Â± 1%</td><td>21.1ms Â± 0%</td><td>âˆ’19.79%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/10</td><td>17.1ns Â± 2%</td><td>9.7ns Â± 1%</td><td>âˆ’43.04%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/32</td><td>17.2ns Â± 0%</td><td>13.6ns Â± 2%</td><td>âˆ’21.37%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>IndexRune/4K</td><td>116ns Â± 2%</td><td>85ns Â± 1%</td><td>âˆ’26.81%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/4M</td><td>170Âµs Â± 3%</td><td>64Âµs Â± 1%</td><td>âˆ’62.34%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/64M</td><td>4.74ms Â± 2%</td><td>1.08ms Â± 0%</td><td>âˆ’77.31%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/10</td><td>5.39ns Â± 3%</td><td>4.05ns Â± 0%</td><td>âˆ’24.86%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/32</td><td>6.88ns Â± 2%</td><td>3.92ns Â± 0%</td><td>âˆ’43.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/4K</td><td>84.2ns Â± 2%</td><td>73.0ns Â± 1%</td><td>âˆ’13.35%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/4M</td><td>157Âµs Â± 4%</td><td>64Âµs Â± 1%</td><td>âˆ’59.18%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/64M</td><td>4.37ms Â± 1%</td><td>1.08ms Â± 1%</td><td>âˆ’75.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/0</td><td>3.01ns Â± 0%</td><td>2.05ns Â± 1%</td><td>âˆ’32.05%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>Equal/1</td><td>6.56ns Â± 0%</td><td>3.43ns Â± 0%</td><td>âˆ’47.73%</td><td>(p=0.000 n=4+5)
</td></tr><tr><td>Equal/6</td><td>6.57ns Â± 0%</td><td>3.81ns Â± 1%</td><td>âˆ’42.01%</td><td>(p=0.000 n=4+5)
</td></tr><tr><td>Equal/9</td><td>6.38ns Â± 1%</td><td>3.75ns Â± 1%</td><td>âˆ’41.24%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/15</td><td>6.36ns Â± 1%</td><td>3.73ns Â± 1%</td><td>âˆ’41.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/16</td><td>6.38ns Â± 2%</td><td>3.82ns Â± 0%</td><td>âˆ’40.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/20</td><td>7.38ns Â± 3%</td><td>4.28ns Â± 0%</td><td>âˆ’42.02%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/32</td><td>8.25ns Â± 4%</td><td>4.12ns Â± 1%</td><td>âˆ’50.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/4K</td><td>106ns Â± 1%</td><td>84ns Â± 1%</td><td>âˆ’20.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/4M</td><td>267Âµs Â± 1%</td><td>111Âµs Â± 1%</td><td>âˆ’58.45%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/64M</td><td>6.98ms Â± 2%</td><td>2.20ms Â± 1%</td><td>âˆ’68.54%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/10</td><td>12.4ns Â± 2%</td><td>5.3ns Â± 1%</td><td>âˆ’57.46%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/32</td><td>12.6ns Â± 2%</td><td>29.2ns Â± 1%</td><td>+131.13%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/4K</td><td>4.91Âµs Â± 1%</td><td>1.95Âµs Â± 0%</td><td>âˆ’60.40%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/4M</td><td>5.04ms Â± 2%</td><td>1.99ms Â± 0%</td><td>âˆ’60.58%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/64M</td><td>82.9ms Â± 6%</td><td>31.9ms Â± 0%</td><td>âˆ’61.53%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/10</td><td>10.8ns Â± 4%</td><td>5.1ns Â± 1%</td><td>âˆ’53.05%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/32</td><td>12.3ns Â± 7%</td><td>9.2ns Â± 0%</td><td>âˆ’25.69%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/4K</td><td>107ns Â± 2%</td><td>77ns Â± 1%</td><td>âˆ’27.90%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/4M</td><td>176Âµs Â± 5%</td><td>64Âµs Â± 1%</td><td>âˆ’63.77%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/64M</td><td>4.62ms Â± 7%</td><td>1.07ms Â± 0%</td><td>âˆ’76.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Count/10</td><td>18.4ns Â± 1%</td><td>9.9ns Â± 0%</td><td>âˆ’45.98%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Count/32</td><td>19.5ns Â± 2%</td><td>33.4ns Â± 0%</td><td>+71.29%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Count/4K</td><td>4.92Âµs Â± 1%</td><td>1.96Âµs Â± 1%</td><td>âˆ’60.24%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>Count/4M</td><td>5.09ms Â± 5%</td><td>1.99ms Â± 0%</td><td>âˆ’60.94%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Count/64M</td><td>81.5ms Â± 2%</td><td>31.9ms Â± 0%</td><td>âˆ’60.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/10</td><td>17.0ns Â± 2%</td><td>9.5ns Â± 1%</td><td>âˆ’43.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/32</td><td>19.1ns Â± 1%</td><td>15.2ns Â± 0%</td><td>âˆ’20.43%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>CountEasy/4K</td><td>113ns Â± 2%</td><td>83ns Â± 2%</td><td>âˆ’26.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/4M</td><td>175Âµs Â± 4%</td><td>64Âµs Â± 1%</td><td>âˆ’63.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/64M</td><td>4.72ms Â± 2%</td><td>1.07ms Â± 0%</td><td>âˆ’77.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/10</td><td>6.67ns Â± 3%</td><td>6.96ns Â± 1%</td><td>+4.41%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/32</td><td>7.36ns Â± 1%</td><td>4.46ns Â± 0%</td><td>âˆ’39.43%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>CountSingle/4K</td><td>100ns Â±15%</td><td>82ns Â± 1%</td><td>âˆ’17.62%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/4M</td><td>171Âµs Â±21%</td><td>83Âµs Â± 1%</td><td>âˆ’51.70%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/64M</td><td>4.50ms Â± 0%</td><td>1.38ms Â± 1%</td><td>âˆ’69.26%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/#00</td><td>8.87ns Â± 2%</td><td>4.66ns Â± 0%</td><td>âˆ’47.40%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/ONLYUPPER</td><td>43.7ns Â± 3%</td><td>30.4ns Â± 1%</td><td>âˆ’30.55%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/abc</td><td>25.9ns Â± 2%</td><td>16.6ns Â± 0%</td><td>âˆ’36.19%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/AbC123</td><td>32.1ns Â± 3%</td><td>19.9ns Â± 1%</td><td>âˆ’38.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/azAZ09_</td><td>31.8ns Â± 1%</td><td>18.6ns Â± 1%</td><td>âˆ’41.54%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/longStrinGwitHmixofsmaLLandcAps</td><td>72.5ns Â± 3%</td><td>45.7ns Â± 0%</td><td>âˆ’36.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/longÉ�stringÉ�withÉ�nonasciiâ±¯chars</td><td>425ns Â± 2%</td><td>249ns Â± 0%</td><td>âˆ’41.31%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/É�É�É�É�É�</td><td>229ns Â± 2%</td><td>158ns Â± 1%</td><td>âˆ’31.24%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/a\u0080\U0010ffff</td><td>108ns Â± 3%</td><td>73ns Â± 1%</td><td>âˆ’32.04%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/#00</td><td>9.17ns Â± 1%</td><td>4.66ns Â± 1%</td><td>âˆ’49.16%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/abc</td><td>34.3ns Â± 1%</td><td>20.4ns Â± 0%</td><td>âˆ’40.56%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/AbC123</td><td>32.8ns Â± 2%</td><td>17.9ns Â± 0%</td><td>âˆ’45.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/azAZ09_</td><td>35.7ns Â± 3%</td><td>20.5ns Â± 0%</td><td>âˆ’42.66%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/longStrinGwitHmixofsmaLLandcAps</td><td>75.6ns Â± 1%</td><td>47.5ns Â± 1%</td><td>âˆ’37.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/LONGâ±¯STRINGâ±¯WITHâ±¯NONASCIIâ±¯CHARS</td><td>356ns Â± 2%</td><td>220ns Â± 1%</td><td>âˆ’38.08%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/â±­â±­â±­â±­â±­</td><td>191ns Â± 2%</td><td>134ns Â± 1%</td><td>âˆ’29.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/A\u0080\U0010ffff</td><td>108ns Â± 2%</td><td>72ns Â± 1%</td><td>âˆ’32.99%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/16</td><td>95.9ns Â± 3%</td><td>44.3ns Â± 0%</td><td>âˆ’53.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/256</td><td>660ns Â± 3%</td><td>357ns Â± 0%</td><td>âˆ’45.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/4096</td><td>9.66Âµs Â± 3%</td><td>4.94Âµs Â± 0%</td><td>âˆ’48.82%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/65536</td><td>200Âµs Â± 1%</td><td>111Âµs Â± 1%</td><td>âˆ’44.32%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/1048576</td><td>3.16ms Â± 1%</td><td>1.88ms Â± 0%</td><td>âˆ’40.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/16</td><td>185ns Â± 3%</td><td>109ns Â± 0%</td><td>âˆ’40.97%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/256</td><td>1.81Âµs Â± 2%</td><td>1.06Âµs Â± 0%</td><td>âˆ’41.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/4096</td><td>33.6Âµs Â± 5%</td><td>19.3Âµs Â± 1%</td><td>âˆ’42.50%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/65536</td><td>569Âµs Â± 2%</td><td>343Âµs Â± 0%</td><td>âˆ’39.63%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/1048576</td><td>9.32ms Â± 5%</td><td>5.54ms Â± 0%</td><td>âˆ’40.57%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/16</td><td>154ns Â± 5%</td><td>87ns Â± 0%</td><td>âˆ’43.61%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/256</td><td>1.58Âµs Â± 9%</td><td>0.91Âµs Â± 1%</td><td>âˆ’42.47%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/4096</td><td>26.0Âµs Â± 2%</td><td>15.6Âµs Â± 0%</td><td>âˆ’39.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/65536</td><td>411Âµs Â± 0%</td><td>249Âµs Â± 0%</td><td>âˆ’39.36%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>FieldsFunc/ASCII/1048576</td><td>6.64ms Â± 1%</td><td>4.00ms Â± 0%</td><td>âˆ’39.73%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/16</td><td>168ns Â± 0%</td><td>101ns Â± 1%</td><td>âˆ’39.72%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>FieldsFunc/Mixed/256</td><td>1.59Âµs Â± 1%</td><td>0.93Âµs Â± 0%</td><td>âˆ’41.16%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/4096</td><td>29.9Âµs Â± 3%</td><td>17.5Âµs Â± 2%</td><td>âˆ’41.65%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/65536</td><td>509Âµs Â± 2%</td><td>311Âµs Â± 0%</td><td>âˆ’38.81%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/1048576</td><td>8.22ms Â± 1%</td><td>5.05ms Â± 0%</td><td>âˆ’38.53%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/NoTrim</td><td>4.66ns Â± 1%</td><td>2.75ns Â± 1%</td><td>âˆ’40.85%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/ASCII</td><td>7.18ns Â± 1%</td><td>4.89ns Â± 1%</td><td>âˆ’31.93%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/SomeNonASCII</td><td>85.5ns Â± 2%</td><td>59.6ns Â± 0%</td><td>âˆ’30.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/JustNonASCII</td><td>158ns Â± 3%</td><td>107ns Â± 1%</td><td>âˆ’32.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/Valid</td><td>29.9ns Â± 2%</td><td>18.0ns Â± 1%</td><td>âˆ’39.99%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/InvalidASCII</td><td>36.3ns Â± 1%</td><td>24.5ns Â± 0%</td><td>âˆ’32.62%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/InvalidNonASCII</td><td>87.8ns Â± 2%</td><td>53.9ns Â± 0%</td><td>âˆ’38.64%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard1</td><td>114Âµs Â± 2%</td><td>330Âµs Â± 0%</td><td>+190.43%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard2</td><td>159Âµs Â± 2%</td><td>330Âµs Â± 0%</td><td>+107.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard3</td><td>631Âµs Â± 1%</td><td>356Âµs Â± 0%</td><td>âˆ’43.61%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard4</td><td>633Âµs Â± 1%</td><td>1313Âµs Â± 0%</td><td>+107.26%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard1</td><td>1.56ms Â± 1%</td><td>1.31ms Â± 0%</td><td>âˆ’15.66%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard2</td><td>1.57ms Â± 1%</td><td>1.31ms Â± 0%</td><td>âˆ’16.03%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard3</td><td>1.56ms Â± 1%</td><td>1.32ms Â± 0%</td><td>âˆ’15.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard1</td><td>113Âµs Â± 2%</td><td>329Âµs Â± 0%</td><td>+192.21%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard2</td><td>161Âµs Â± 9%</td><td>330Âµs Â± 1%</td><td>+105.44%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard3</td><td>644Âµs Â± 8%</td><td>356Âµs Â± 0%</td><td>âˆ’44.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitEmptySeparator</td><td>12.2ms Â± 5%</td><td>4.9ms Â± 0%</td><td>âˆ’59.71%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitSingleByteSeparator</td><td>1.46ms Â± 3%</td><td>1.75ms Â± 0%</td><td>+19.63%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitMultiByteSeparator</td><td>1.42ms Â± 1%</td><td>1.20ms Â± 2%</td><td>âˆ’15.75%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitNSingleByteSeparator</td><td>207ns Â± 9%</td><td>173ns Â± 1%</td><td>âˆ’16.49%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitNMultiByteSeparator</td><td>276ns Â± 3%</td><td>212ns Â± 1%</td><td>âˆ’23.22%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Repeat</td><td>52.8ns Â± 3%</td><td>33.4ns Â± 0%</td><td>âˆ’36.75%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/1</td><td>4.78ns Â± 2%</td><td>2.55ns Â± 0%</td><td>âˆ’46.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/2</td><td>4.74ns Â± 2%</td><td>2.51ns Â± 1%</td><td>âˆ’46.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/4</td><td>4.80ns Â± 3%</td><td>2.20ns Â± 1%</td><td>âˆ’54.08%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/8</td><td>3.89ns Â± 2%</td><td>2.06ns Â± 1%</td><td>âˆ’46.95%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/16</td><td>3.86ns Â± 2%</td><td>2.08ns Â± 0%</td><td>âˆ’46.21%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/32</td><td>5.09ns Â± 6%</td><td>2.55ns Â± 0%</td><td>âˆ’49.96%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/64</td><td>5.99ns Â± 1%</td><td>3.45ns Â± 0%</td><td>âˆ’42.43%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/128</td><td>7.95ns Â± 3%</td><td>5.32ns Â± 0%</td><td>âˆ’33.06%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/256</td><td>11.6ns Â± 9%</td><td>9.1ns Â± 1%</td><td>âˆ’21.88%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/512</td><td>18.9ns Â± 9%</td><td>16.7ns Â± 1%</td><td>âˆ’11.36%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/1024</td><td>32.7ns Â± …</td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://roland.zone/m1-go-benchmarks/">https://roland.zone/m1-go-benchmarks/</a></em></p>]]>
            </description>
            <link>https://roland.zone/m1-go-benchmarks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25158243</guid>
            <pubDate>Fri, 20 Nov 2020 07:59:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Increase in Bitcoin Addresses as More People Join the BTC Price Surge]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25157946">thread link</a>) | @coincolony
<br/>
November 19, 2020 | https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/ | <a href="https://web.archive.org/web/*/https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157946</guid>
            <pubDate>Fri, 20 Nov 2020 07:01:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assassin’s Creed: Valhalla and the Unfortunate Implications]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25157722">thread link</a>) | @parsecs
<br/>
November 19, 2020 | https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157722</guid>
            <pubDate>Fri, 20 Nov 2020 06:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to ZFS]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25157491">thread link</a>) | @arm
<br/>
November 19, 2020 | https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage.png" data-caption="Truenas Homepage"><img width="696" height="496" src="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-696x496.png" srcset="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-696x496.png 696w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-400x285.png 400w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-800x570.png 800w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-1068x761.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-589x420.png 589w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-100x70.png 100w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage.png 1291w" sizes="(max-width: 696px) 100vw, 696px" alt="Truenas Homepage" title="Truenas Homepage"></a><figcaption>Truenas Homepage</figcaption></figure></div>
            <!-- content --><p>ZFS has become increasingly popular in recent years. ZFS on Linux (ZoL) has pushed the envelope and exposed many newcomers to the ZFS fold. iXsystems has adopted the newer codebase, now called <strong>OpenZFS, </strong>into its codebase for TrueNAS CORE. The purpose of this article is to help those of you who have heard about ZFS but have not yet had the opportunity to research it.</p>
<p>Our hope is that we leave you with a better understanding of how and why it works the way it does. Knowledge is key to the decision-making process, and we feel that ZFS is something worth considering for most organizations.<br>
<span id="more-44288"></span></p>
<h2>What is ZFS?</h2>
<p>ZFS is a <strong>filesystem</strong>, but unlike most other file systems it is also the <strong>logical volume manager</strong> or LVM. What that means is ZFS directly controls not only how the bits and blocks of your files are stored on your hard drives, but it also controls how your hard drives are logically arranged for the purposes of RAID and redundancy. ZFS is also classified as a <strong>copy-on-write</strong> or <a href="https://www.ixsystems.com/documentation/freenas/11.2/zfsprimer.html">COW filesystem</a>. This means that ZFS can do some cool things like <strong>snapshots</strong> that a normal filesystem like NTFS could not. A snapshot can be thought of like it sounds, a photograph of how something was at a point in time. How a COW filesystem works, however, has some important implications that we need to discuss.</p>
<figure id="attachment_44997" aria-describedby="caption-attachment-44997"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-322x300.png" alt="The Open ZFS Logo" width="322" height="300" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-322x300.png 322w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-800x746.png 800w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-696x649.png 696w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-450x420.png 450w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_.png 1024w" sizes="(max-width: 322px) 100vw, 322px"><figcaption id="caption-attachment-44997">The Open ZFS Logo</figcaption></figure>
<p>Hard Drives work such that the pieces of your data are stored in <strong>Logical Block Addresses</strong>, or LBAs. ZFS is aware of what LBAs a specific file is stored in. Let us say we need to write a file that is big enough to fit into 3 blocks. We are going to store that file in LBA 1000, 1001, and 1002. This is considered a sequential write, as all of these blocks are stored directly next to each other. For spinning hard drives, this is ideal, as the write head does not have to move off of the track it is on.</p>
<figure id="attachment_23424" aria-describedby="caption-attachment-23424"><a href="https://www.servethehome.com/western-digital-red-pro-10tb-nas-hdd-review/wd-red-10tb-pro-nas-top/" rel="attachment wp-att-23424"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top.jpg" alt="WD Red 10TB Pro NAS Top" width="800" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top.jpg 800w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-305x300.jpg 305w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-696x684.jpg 696w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-427x420.jpg 427w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-23424">WD Red 10TB Pro NAS Top <a href="https://www.servethehome.com/wd-red-smr-vs-cmr-tested-avoid-red-smr/">Use CMR with ZFS, not SMR</a></figcaption></figure>
<p>Now, let us say we make a change to the file and the part that was stored at LBA 1001 needs to be modified. When we write that change, ZFS does not over-write the part of the file that was stored in 1001. Instead, it will write that block to LBA 2001. LBA 1001 will be kept as-is until the snapshot keeping it there expires. This allows us to have both the current version of the file, and the previous one, while <em>only storing the difference.</em> However, the next time we go to read the file back, the read head of our spinning hard drive needs to read LBA 1000, go to the track where LBA 2001 is stored, read that, and then go back to the track where LBA 1002 is stored. This phenomenon is called <strong>fragmentation.</strong></p>
<h2>A Primer on ZFS Pool Design</h2>
<p>To make ZFS pools easier to understand, we are going to focus on using small storage containers as you may have around the house or shop. Before we continue, it is worth defining some terms. A <strong>VDEV, </strong>or virtual device, is a logical grouping of one or more storage devices. A <strong>pool</strong> is then a logically defined group built from 1 or more VDEVs. ZFS is very customizable, and therefore, there are many different types of configurations for VDEVs. You can think of the construction of a ZFS pool by visualizing the following graphic:</p>
<figure id="attachment_45011" aria-describedby="caption-attachment-45011"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-800x521.jpg" alt="Nested Storage Containers" width="696" height="453" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-800x521.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-400x261.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-1536x1001.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-2048x1334.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-696x453.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-1068x696.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-645x420.jpg 645w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45011">Nested Storage Containers</figcaption></figure>
<p>Starting from the smallest container size, we have our drives. We can see that in this visualization we have two drives in each larger container. These two larger containers are our VDEVs. The single largest container, then, is our pool. In this configuration, we would have each pair of drives in a <strong>mirror. </strong>This means that one drive can fail in either (or both!) VDEV and the pool would continue to function in a <strong>degraded</strong> state.</p>
<figure id="attachment_45012" aria-describedby="caption-attachment-45012"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-800x538.jpg" alt="Two Mirrors, Each VDEV with One Bad Drive" width="696" height="468" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-800x538.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-400x269.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-1536x1034.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-2048x1378.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-696x468.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-1068x719.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-624x420.jpg 624w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45012">Two Mirrors, Each VDEV with One Bad Drive</figcaption></figure>
<p>However, if 2 drives in a <strong>single</strong> VDEV, all of the data in our entire pool is lost. There is no redundancy of the pool itself, all redundancy in ZFS is in the VDEV layer. If one <em>VDEV</em> fails, there is not enough information to rebuild the missing data.</p>
<figure id="attachment_45013" aria-describedby="caption-attachment-45013"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-800x559.jpg" alt="Two Mirrors, One VDEV where Both Drives Failed" width="696" height="486" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-800x559.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-400x280.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-1536x1074.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-696x487.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-1068x747.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-601x420.jpg 601w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-100x70.jpg 100w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed.jpg 1991w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45013">Two Mirrors, One VDEV where Both Drives Failed</figcaption></figure>
<p>Next, we need to define what&nbsp;<strong>RAID-Z</strong> is and what the various levels of RAID-Z are. RAID-Z is a way of putting multiple drives together into a VDEV and storing <strong>parity,&nbsp;</strong>or fault tolerance. In ZFS, there is no dedicated “parity drive” like in&nbsp;<strong>Unraid</strong>, but it instead stores parity across all of the drives in the VDEV.&nbsp; The amount of parity that is spread across the drives determines the level of RAID-Z. It is in this way more similar to traditional hardware RAID.</p>
<p>What can make RAID-Z a better approach than a mirrored configuration is that it does not matter <em>what&nbsp;</em>drive fails in a RAID-Z. Each drive is an equal partner, whereas, in a mirrored configuration, each mirrored VDEV is a separate entity. This benefit of RAID-Z comes at the cost of performance, however, and a mirrored pool will almost always be <em>faster</em>&nbsp;than RAID Z.</p>
<p><strong>RAID-Z</strong>&nbsp;is similar to a traditional&nbsp;<strong>RAID 5. </strong>In RAID-Z you have one drive worth of parity. In other words, if you lose one drive, your pool will continue to function. For RAID-Z you need a minimum of 3 drives per VDEV. You can have 3, 7, or even 12 drives in a RAID-Z VDEV. The more drives which you add, however, the longer it will take to <strong>resilver,&nbsp;</strong>or rebuild.</p>
<p>This increased time increases the risk of your data, as a second drive failure during this process would destroy your pool. ZFS will resilver while the data is still in use, it is a live recovery. The implication of this is that our disks are working harder than usual during this process, and this can increase the chances of a second drive failure. Your data is still accessible and in production, while it is reading all of the parity data from the existing members of your VDEV and then writing it to the new disk.</p>
<figure id="attachment_45014" aria-describedby="caption-attachment-45014"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--800x569.jpg" alt="A Pool with a Single 3-Disk Raid Z1 VDEV" width="696" height="495" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--800x569.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--400x285.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--1536x1093.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--2048x1458.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--696x495.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--1068x760.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--590x420.jpg 590w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--100x70.jpg 100w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45014">A Pool with a Single 3-Disk Raid-Z VDEV</figcaption></figure>
<p>A RAID-Z2 VDEV is more akin to a RAID 6. In this configuration, 2 drives worth of parity is stored across all of your devices. You can lose up to two drives per VDEV and your pool will still function. Adding more parity drives increases calculations required which means you need more processing performance to operate the array.</p>
<figure id="attachment_45015" aria-describedby="caption-attachment-45015"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-800x551.jpg" alt="A Pool with a Single 4-Disk Raid Z2 VDEV" width="696" height="479" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-800x551.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-400x276.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-1536x1059.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-2048x1412.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-218x150.jpg 218w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-696x480.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-1068x736.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-609x420.jpg 609w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-100x70.jpg 100w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45015">A Pool with a Single 4-Disk Raid Z2 VDEV</figcaption></figure>
<p>Finally, a RAID-Z3 VDEV provides three drives worth of parity, so you can lose up to three drives per VDEV and your pool will still function. <strong>The more drives of parity you add, however, the slower your performance ends up being</strong>. You need a minimum of four but should use at least five drives to build a RAID-Z3 VDEV.</p>
<h2>The Need for Speed</h2>
<p>There are two ways in which we measure speed or <em>fastness</em>,&nbsp;<strong>IOPS,</strong>&nbsp;and&nbsp;<strong>Throughput</strong>. In RAIDZ, more drives will give you more throughput, or the actual read and write speed you see when transferring files. However, if you have ever tried to run multiple file copies in Windows simultaneously, you may have noticed the more you do, the slower it gets. It does not always get slower at a constant rate, the more you try to do disks will get exponentially slower. This is because your disk can only do so many Input/Output Operations per Second, or IOPS.</p>
<p>RAIDZ will scale in&nbsp;<em>throughput</em>&nbsp;with the more disks you add, but it does not scale with&nbsp;<em>IOPS.</em> What that generally means is, RAIDZ is not traditionally the best choice for I/O intensive workloads, as the amount of IOPS is roughly limited to the slowest member of our VDEV if we exclude all of the caching ZFS has. Virtualization, as we are discussing here, is highly dependent on I/O.</p>
<p>Earlier, we discussed that ZFS is a COW filesystem, and because of that it suffers from data fragmentation. There are direct performance implications that stem from that fact.&nbsp;<strong>The more “full” your pool is, the slower it will ultimately get.&nbsp;</strong>Write speeds in ZFS are directly tied to the amount of&nbsp;<em>adjacent</em> free blocks there are to write to. As your pool fills up, and as data fragments, there are fewer and fewer blocks that are directly adjacent to one another. A single large file may span blocks scattered all over the surface of your hard drive. Even though you would expect that file to be a sequential write, it no longer can be if your drive is full.</p>
<figure id="attachment_45006" aria-describedby="caption-attachment-45006"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark.png" alt="Seagate Mobile HDD Crystal Disk Mark Performance" width="482" height="351" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark.png 482w, https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark-400x291.png 400w, https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark-324x235.png 324w" sizes="(max-width: 482px) 100vw, 482px"><figcaption id="caption-attachment-45006">Seagate Mobile HDD Crystal Disk Mark Performance</figcaption></figure>
<p>In the above graphic, we can see a Seagate 1TB mobile drive that I tested in CrystalDiskMark. It can do about 130 MB/s of sequential read and writes. We can also see that when we start doing random 4k I/O, the speed falls about <strong>100x</strong>. This is meant to illustrate the performance impact of data fragmentation. Additionally, we can see that the latency for these lookups can take about&nbsp;<strong>half of a second, </strong>and we are limited to about 350 IOPS. In order to be fast, virtualization workloads on traditional hard drives need to have many disks in order to compensate for this slowness. It would not be uncommon to see a pool constructed of 10 or more VDEVs of mirrored drives.</p>
<p>Additionally, there is some wisdom we can <a href="https://www.ixsystems.com/community/threads/the-path-to-success-for-block-storage.81165">borrow from the ZFS community</a>. As your pool fills up, and sequential writes become increasingly difficult to accomplish due to fragmentation, it will slow down in a non-linear way. As a general rule of thumb, at about 50% capacity your pool will be noticeably slower than it was when it was 10% capacity. At about 80%-96% capacity, your pool starts to become very slow, and ZFS will actually change its write algorithm to ensure data integrity, further slowing you down.</p>
<p>This is where SSDs come in. They radically change the game because they work very differently at the physical layer. They do not have read and write heads that are flying around a spinning disk back and forth trying to find your data. With the physical limitations of disk-based drives out of the way, SSDs can read and write non-sequential data <em>much&nbsp;</em>faster. They do not suffer the penalties of these rules nearly as severely, fragmentation does not hurt their performance to the same degree.</p>
<figure><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/05/970-EVO-Plus-250GB-Front.jpg" alt="A Samsung 970 EVO Plus SSD" width="1500" height="997"></figure>
<p>A Samsung 970 EVO Plus SSD</p>
<p>Hard drives have increased in capacity by leaps-and-bounds over the past couple of decades. We have seen hard drives grow from a single gigabyte in capacity and just last year <a href="https://www.servethehome.com/western-digital-volume-production-of-18tb-and-20tb-drives-in-2020/">Western Digital announced</a> that 18 and 20 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/">https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/</a></em></p>]]>
            </description>
            <link>https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157491</guid>
            <pubDate>Fri, 20 Nov 2020 05:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's Wrong with the Media]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25156088">thread link</a>) | @jger15
<br/>
November 19, 2020 | https://www.slowboring.com/p/whats-wrong-with-the-media | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/whats-wrong-with-the-media">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to Thursday! </p><p>I’ve been reading some interesting policy reports about everything from <a href="https://t.co/CxLqshzCAg">maternal mortality</a> to <a href="https://www.urban.org/urban-wire/can-we-design-student-loan-forgiveness-target-low-income-families">how to target student loan forgiveness</a> but at the moment there is a lot of demand for me to address the situation at Vox in detail or to assimilate my personal story into a larger narrative about “wokeness” or the culture wars. Personally I’m not a huge fan of navel-gazing. So I’ll just say that my personal interest in reclaiming my status as an independent, blog-like voice transcends any particular issues with any particular publication. I wanted to do <em>this,</em> not go find a different job, and I thank those of you who’ve joined me on this journey.</p><p>But Vox is typical of a few trends that exist broadly in the media industry and that I do think are of interest. </p><ul><li><p>The staff skews very young. </p></li><li><p>The staff is concentrated in big coastal cities, and especially New York.</p></li><li><p>The staff is overwhelmingly composed of graduates of selective colleges (state university flagship campuses and private schools with names you know).</p></li></ul><p>The media industry has long skewed young, educated, and New Yorky. But digital disruption trends have made it more so than ever before. Daily newspapers published in mid-sized cities and small towns are weaker and less significant. A lot of reporters born in the 1960s and 1970s have left the industry as it has shrunk and few of them work at digital native startups. </p><p>Separately from that change, national politics has been polarizing around age, educational attainment and population density in an unprecedented way. A group of young, recent college graduates living in Brooklyn would’ve skewed left in 1990 but this was an era when Al D’Amato could win statewide in New York and Democratic presidential campaigns would win in West Virginia. Today a demographically identical group skews much further left than it used to. None of this is really an outcome that anyone particularly wanted or intended. But it’s put a big thumb on the scales ideologically at the exact same time that economic trends have turned against the startups.</p><p>The result is that I think you should expect the instability we’ve seen this fall to be just the leading edge of the wedge.  </p><h4>Most media isn’t political journalism </h4><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png&quot;,&quot;height&quot;:1052,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2381922,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>Culture criticism today: Calling out various problematic things</figcaption></figure></div><p>Reeves Wiedeman’s recent <a href="https://nymag.com/intelligencer/2020/11/inside-the-new-york-times-heated-reckoning-with-itself.html">article about internal tensions at The New York Times</a> includes this passage, which gets at a dynamic that I think you see across the media landscape. The vast majority of the people who work at any given publication are not professional political journalists, and generally the further you get from the ~~political journalism~~ section of a media organization the more left-wing things get: </p><blockquote><p>Of all the fronts on which the Times was being pushed to change, the strongest insurrectionary energy was coming from legions of newsroom-adjacent employees in digital jobs that didn’t exist a decade ago. The employees responsible for distributing the Times in the past — typesetters, pressmen, delivery drivers — had never been encouraged to speak up about the ethical questions at the heart of the paper’s journalism. But the app developers and software engineers who deliver the Times’ journalism to the world have held their hands up in just as many Ivy League seminars as their editorial peers. They might be too shy to march over to a masthead editor and complain about a clumsy headline, but #newsroom-feedback had opened a digital door to criticism. Reporters found that suddenly it was the Times’ programmers and developers, rather than their editors, who were critiquing their work. During the town hall about the Cotton op-ed, one data engineer said on Slack, “How many such process failures would be tolerated in tech?”</p><p>Many of the techsurrectionists had come from Facebook or Uber or Amazon to join the Times out of a sense of mission, leaving the ethical quandaries of the tech industry for what they thought were more virtuous pastures. “I joined the company for one reason, and it’s because I feel a responsibility to be a part of a mission that I believe in,” a product manager who previously worked at Apple wrote in #newsroom-feedback after the Cotton op-ed. “This feels like the rug’s been pulled out from under us — not just because it feels like that mission [has] been severely compromised by the decision to publish this piece, but even more so because the products we’re building were used to do it.”</p><p>“It’s like making telephone poles,” one software engineer added, “and finding out they’re being used as battering rams.”</p></blockquote><p>People who cover politics professionally, for better or worse, end up spending a fair amount of time talking to Republicans and trying to understand what conservatives think about public policy issues. If we’re doing our jobs at all correctly we can do stories that bring a mostly-progressive audience a greater understanding of what is happening on the other side. And when a professional political reporter does a bad job it’s often because he or she is taking a dive to maintain relationships with sources on the right, or bending over <em>too far</em> backwards to be fair. </p><p>At the same time, we political journalists have our fair share of totally ignorant hot takes about music or cooking or sports or whatever else that we can fire off. </p><p>The flip side is that our colleagues who cover sports or music or cooking also have hot takes about politics. Hot takes that come from the very narrow demographic and ideological niche that dominates the media and is untempered by the need to actually cover politics.</p><h4>Coverage has gotten really weird </h4><p>Ian Walker <a href="https://kotaku.com/playstation-5-the-kotaku-review-1845588904">recently ended his PS5 review for Kotaku with this thought</a>: </p><blockquote><p>The world is still reeling under the weight of the covid-19 pandemic. There are more Americans out of work right now than at any point in the country’s history, with no relief in sight. Our health care system is an inherently evil institution that forces people to ration life-saving medications like insulin and choose suicide over suffering with untreated mental illness.</p><p>As I’m writing this, it looks very likely that Joe Biden will be our next president. But it’s clear that the worst people aren’t going away just because a new old white man is sitting behind the Resolute desk—well, at least not&nbsp;<em>this</em>&nbsp;old white man. Our government is fundamentally broken in a way that necessitates radical change rather than incremental electorialism.</p><p>The harsh truth is that, for the reasons listed above and more, a lot of people simply won’t be able to buy a PlayStation 5, regardless of supply. Or if they can, concerns over increasing austerity in the United States and the growing threat of widespread political violence supersede any enthusiasm about the console’s SSD or how ray tracing makes reflections more realistic. That’s not to say you&nbsp;<em>can’t</em>&nbsp;be excited for those things—I certainly am, on some level—but there’s an irrefutable level of privilege attached to the ability to simply tune out the world as it burns around you.</p></blockquote><p>The problem here, to me, is not that Walker ought to “stick to sports.” It’s that the analysis is bad. But because it’s in a video game console review rather than a policy analysis section and conforms to the predominant ideological fads, it just sails through to our screens. </p><p>What actually happened is that starting in March the household savings rate soared (people are taking fewer vacations and eating out less) and while it’s been declining from its peak as of September it was still unusually high.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png&quot;,&quot;height&quot;:700,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:94064,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>One result of this is a lot of people have been able to pay off old debts. At the same time, interest rates have plunged without sparking an increase in borrowing, so household debt service costs have plummeted. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png&quot;,&quot;height&quot;:684,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109636,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>The upshot of this is that no matter what you think about Biden or the American health care system, the fact is that the sales outlook for a new video game console system is very good. There is economic hardship in America, but the larger trend is that middle class people are seeing their homeowners’ equity rise and their debt payments fall, while cash piles up on their balance sheets, because it’s not safe to throw a big birthday party or take a vacation this weekend.</p><p>Not to just pick on this one article, but it was striking to me because it was both emblematic of the way far-left politics has suffused non-political media and also because the topic had nothing to do with race or gender identity issues.  </p><h4>It’s not really about “wokeness”</h4><p>There’s a lot of talk lately about excessive “wokeness” in the media driving people away from their jobs. But I don’t really think the underlying dynamics are specific to any particular issue area. </p><p>I remember a time in December 2018 when there was a <a href="https://www.vox.com/the-goods/2018/11/26/18112769/amazon-prime-cancel">flurry of articles about an Amazon Prime backlash</a> and I felt inspired to write a corrective noting that <a href="https://www.vox.com/policy-and-politics/2018/12/11/18129809/amazon-polling-popular-confidence">Amazon is actually incredibly popular</a> both as a shopping destination and in polls. In response to a similar barrage of articles about how <a href="https://www.vanityfair.com/style/2020/04/how-should-a-climate-change-reporter-think-about-having-children">maybe you shouldn’t have children because of climate change</a>, I felt inspired to write, at somewhat greater length, my book One Billion Americans. </p><p>The basic dynamic is that if you take a normal distribution (say of political views) and then shift the average a bit to one side, you end up with explosive growth in the number of outliers. In this chart, the average of the red line isn’t so different from the average of the black line. But the right-hand tail of the red line is much higher than the black.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg&quot;,&quot;height&quot;:461,&quot;width&quot;:999,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:85183,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>If everyone in digital media is an under-fifty college graduate living in a big city, then it’s not that everyone in digital media is a far-left weirdo, but you do get <em>drastically more</em> far-left weirdness. </p><p>This tendency could obviously be tempered by business considerations. Hollywood is famously full of left-wing people and they do produce some content that reflects those ideas. But they mostly produce content that lacks overt political themes, and they also feed the network television audience a steady diet of police procedurals that embed very …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/whats-wrong-with-the-media">https://www.slowboring.com/p/whats-wrong-with-the-media</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/whats-wrong-with-the-media</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156088</guid>
            <pubDate>Fri, 20 Nov 2020 00:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg Is Finally Granted a US Visa]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25154334">thread link</a>) | @andrewnicolalde
<br/>
November 19, 2020 | https://daniel.haxx.se/us-visa.html#got-it | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/us-visa.html#got-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p> Time it took for Daniel to get a US visa </p>
<p><span>
 937 days
</span></p><p> Background </p>
<p>
 On June 26th 2017, Daniel was denied to travel to the US - while still having
 a valid ESTA and passport. He was then denied ESTA on April 3, 2018. When
 subsequently applying for a visa instead, there has been no response for over
 two years. (To <i>visit</i>, not to apply for permanent residency.)
</p><p> This page was edited with <a href="#got-it">new content</a> on:
 <b>November 9, 2020</b>
</p><p> Blog posts </p>
<p> First blog post: <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/">Administrative

 purgatory</a>
</p><p> The one year anniversary: <a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/">One

year in still no visa</a>.
</p><p> <a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/">Two years in</a>

</p><p> Q&amp;A </p>
<p>
<a href="#got-it">Visa approved</a>
</p><div>
<p>
 937 days since my application, I have a visa in my passport. Valid for 10 years.
</p><p> As an unexpected bonus, there's also a 30 days "NIE" (National Interest
 Exception) that allows me a single entry to the US during "PP" (Presidential
 Proclamations) - which is restricting travels to the US from the European
 Schengen zone.
</p></div>
<p>
<a href="#parcel">"There's a package being delivered to you"</a>
</p><div>
<p>
 934 days into the process (10:30 November 6, 2020) I received this
 text on my phone, saying there's a parcel sent to me from "the
 Embassy of the United State".
</p><p>
<img src="https://daniel.haxx.se/media/embassy-text.png" width="600">
</p></div>
<p>
<a href="#send-in">Please send in your passport</a>
</p><div>
<p> On October 13, 2020 (910 days in), the embassy emailed me again,
asking me to "Please send in your passport for further processing."
</p><p> On October 16, I mailed it to the embassy.
</p></div>
<p>
<a href="#plans">Updated travel plans please!</a>
</p><div>
<p> On September 22, 2020 (889 days in), the US Embassy emailed me, and I will
quote verbatim from the email below.
</p><pre>Dear Sir,
&nbsp;
Your visa application is still in administrative processing. However, we regret to
inform you that because you have missed your travel plans, we will require updated
travel plans from you. If you intend to proceed with your visa application, we
therefore ask you to kindly send your updated travel plans, including any relevant
supporting documents (such as  an official invitation letter and financial support
letter/other financial supporting documents). Thank you.
</pre>
<p> So I need to provide updated plans and "invitation letters"...
</p><p> It seems reasonable to suspect that the embassy woke up and realized this
 after having being prodded by the <a href="#officials">congressman's
 email</a> a few days ago. The travel plans have been outdated for the last
 800 days or so and they only email to ask this now?
</p><p> On October 2, 220 (898 days in) I responded to the email with an
 invitation letter with an offer to visit my colleagues at wolfSSL in the US
 at two different future dates (one in December 2020, one in March 2021) and
 "All expenses, hotel, airfare, transportation and food will be paid for him".
 Signed by Larry Stefonic, CEO of wolfSSL.
</p></div>
<p>
<a href="#long">Do you know why this takes so long?</a>
</p><div>
<p> No. They've just informed me "someone is working on it" and that it "may
take a long time" but without qualifying what that means. They call it
"administrative processing."
</p><p> I have talked to several persons who've experienced similar situations, and
  I have learned about waiting times up to 20 months until a definite "no". I used
  to think of that as a sort of "worst case" waiting time. Now we know it can
  take longer...
</p></div>
<p>
<a href="#esta">Why don't you just apply for an ESTA?</a>
</p><p>
  I already did and they denied me that. See one of the <a href="#images">images below</a>.
</p>
<p>
Why did they deny you ESTA?
</p><p>
  I don't know as they won't tell. And I also don't know why they can't respond to my visa application.
</p>
<p>
<a href="#working">So, someone is working on it?</a>
</p><p>
  Allegedly, yes. I'm sure that person must be working very hard...
</p>
<p>
<a href="#eventually">Do you think they will grant you a visa eventually?</a>
</p><div>
<p>
  No. I have been in contact with many people who have been in similar
  situations such as this, as well as many people who have applied for visas
  for very complicated matters, and it is basically unheard of that it would
  take this long time and still end up with a positive response in the end.
</p><p>
  Someone emailed me and explained how they got their visa approved after 10
  months waiting - so it obviously <i>can</i> happen after a fairly
  long time!
</p></div>
<p>
<a name="#arab">Did you travel to any arab countries, middle-east, North Korea, Sudan, Iran or Iraq?</a>
</p><p>
 No.
</p>
<p>
<a name="#ever">Did you ever visit the US?</a>
</p><div>
<p> Yes, I have visted the US around a dozen times over a time period of almost
 twenty years. I have applied and gotten ESTA permissions several times. I have
 many friends living and working in the US.
</p><p> My latest visit to the US was in December 2016 - using the same ESTA and
 passport I subsequently wanted to use in the summer of 2017 when I was first
 denied travelling to the US.
</p></div>
<p>
<a href="#blocked">How many trips have this blocked you from taking so far?</a>
</p><div>
<p> I have been invited personally to several meetings in the US that I couldn't
 attend. (excluding IETF, HTTPbis or QUIC meetings)
</p><ol>
<li> San Francisco June 2017. Mozilla All Hands.
</li><li> San Francisco June 2018. Mozilla All hands.
</li><li> San Francisco October 2018. Conference speaking engagement.
</li><li> Orlando, Florida December 2018. Mozilla All hands.
</li><li> Portland, Oregon January 2019. Conference speaking engagement.
</li><li> California, March 2019. Conference speaking engagement.
</li><li> Summer of 2019. Wedding.
</li></ol>
</div>
<p>
<a href="#employer">Can't your employer help you?</a>
</p><p> We've already tried all available ways to get information or otherwise
bring this effort forward. To no avail.
</p>
<p>
<a href="#Mozilla">Will Mozilla move more meetings outside of the US?</a>
</p><p> Yes. Several of the coming All hands are now planned and scheduled to
happen outside of the US, for example in Canada and Germany. But I will not be
there to experience them since I quit Mozilla in December 2018.
</p>
<p>
Will your visa situation change when you've quit Mozilla?
</p><p> Unfortunately, there is no reason to suspect or hope so.
</p>
<p>
<a href="#lost">Maybe they lost your application?</a>
</p><div>
<p> I emailed them in July 2019 just to make sure they just hadn't
 forgot about my case or similar over the past year, and I received their
 reply on August 1st 2019. The response said "I have forwarded your email to
 my supervisor to highlight the problem."  - but then nothing more came.
</p><p> I emailed them again on January 28, 2020.<br>
<img src="https://daniel.haxx.se/media/651-days-email.png">
</p><p>
 They responded very politely:
 </p><pre>Dear Sir,
&nbsp;
All applications are processed in the most expeditious manner
possible. While we understand your frustration, we are required to follow
immigration law regarding visa issuances. This process cannot be expedited or
circumvented. Rest assured that we will contact you as soon as the
administrative processing is concluded.
</pre>
</div>
<p>
<a href="#likely">What do you think is the most likely explanation for this treatment?</a>
</p><div>
<p> I think one of the likelier explantions is that someone somewhere has
 found my name and my code used in some evil or malicious manner and drawn the
 wrong conclusions about how my code ended up there or how I could've been
 involved. Like for example in some malware, virus or other attack software. I
 make tools and code available for free and openly and sometimes those are
 unfortunately used in ways I don't condone.
</p><p> Since they won't tell me why, basically all theories are equally likely.
 We just won't know.
</p></div>
<p>
Any other plausible explanations?
</p><div>
<p> People have mentioned my domain name <b>haxx.se</b> or suggested it is
because I have referred to myself as "a hacker" at times. I find that unlikely
since I used the domain and used the term for decades before this.
</p><p> Others have offered the explanation that the immigration authorities
might've decided that I violated the ESTA rules in a previous visit. I can of
course not know what they think, but I have not violated those rules.
</p></div>
<p>
<a href="#crime">Convicted of a crime?</a>
</p><p>
No, I have never been convicted of a crime in Sweden and not anywhere
else. Not even charged. Nor have I ever been involved in a lawsuit of any
kind.
</p>
<p>
<a href="#license">Can you change the curl license?</a>
</p><div><p>
Lots of people suggest this, most probably in jest, but let me be perfectly
clear: no I won't change the curl license.
</p><ol>
 <li> excluding a specific user would make a license to not be open source anymore
 </li><li> curl has many more copyrights than mine, it would be hard
 </li><li> curl is bigger than me personally, I wouldn't do it anyway
</li></ol>
</div>
<p>
<a href="#covid">But Covid-19?</a>
</p><p>
During the Corona pandemic (starting in spring 2020), the US has closed its
borders for a lot of more people who otherwise would have been allowed
entry. I suspect the visa processing has slowed down during this period since
people can't go there anyway. But I have not been notified about anything and
I still expect to get a rejection at some point. Pandemic or not.
</p>
<p>
<a href="#officials">Have you contacted any US officials?</a>
</p><div><p>
A US citizen friend of mine sent the following text in an email to the
U.S. Congressman Gerry Connolly on September 3, 2020.
</p><pre>Dear Representative Gerry Connolly:
&nbsp;
Could you please help my friend Daniel Stenberg *finally* gain permission to
travel to the US? He has been denied permission to travel to the US for years,
yet there is no cause for it.
&nbsp;
On June 26, 2017, Mr. Stenberg was denied to travel to the US, even though he
had a valid ESTA and passport. He was then denied ESTA on April 3, 2018. He
then applied for a visa in April 2018, and has *still* not heard anything.
&nbsp;
This is especially galling because is a widely-known leader in the computer
community. He developed and maintains the "curl" program, a program used
worldwide by many software developers and computer system administrators. In
October 2017 he won the "Polhem prize" for his work on curl; in that ceremony
the Swedish king personally handed Daniel a gold medal. In February 2019 he
joined wolfSSL, an American company (he's their only Swedish hire), and yet
he's still not allowed to travel to the US.
&nbsp;
Perhaps there is a confusion about the word "hacker". In the computer
community, a "hacker" is NOT someone who breaks into computers, a hacker
is "a person who delights in having an intimate understanding of the
internal workings of a system, computers and computer networks in
particular."  ( IETF RFC 1983, https://tools.ietf.org/html/rfc1983).

Mr. Stenberg does *not* break into computers without authorization.
&nbsp;
At the least, the State Department should have asked questions instead of
reflexively denying entry to a world leader in the computer industry.
&nbsp;
More information is available on his personal website:
https://daniel.haxx.se/us-visa.html
</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/us-visa.html#got-it">https://daniel.haxx.se/us-visa.html#got-it</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/us-visa.html#got-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154334</guid>
            <pubDate>Thu, 19 Nov 2020 21:04:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows Subsystem for Linux: The lost potential]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25154300">thread link</a>) | @r0sk
<br/>
November 19, 2020 | https://jmmv.dev/2020/11/wsl-lost-potential.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/11/wsl-lost-potential.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>If you have followed Windows 10 at all during the last few years, you know that the <strong>Windows Subsystem for Linux</strong>, or <strong>WSL</strong> for short, is <em>the</em> hot topic among developers. You can finally run your Linux tooling on Windows as a first class citizen, which means you no longer have to learn PowerShell or, god forbid, suffer through the ancient <code>CMD.EXE</code> console.</p>
<p>Unfortunately, not everything is as rosy as it sounds. I now have to do development <em>on</em> Windows <em>for</em> Windows as part of my new role within Azure… and the fact that WSL continues to be separate from the native Windows environment shows. Even though I was quite hopeful, I cannot use WSL as my daily driver because I need to interact with “native” Windows tooling.</p>
<p>I believe things needn’t be this way, but with the recent push for WSL 2, I think that the potential of an alternate world is now gone. But what do I mean with this? For that, we must first understand the differences between WSL 1 and WSL 2 and how the push for WSL 2 may shut some interesting paths.</p>
<p><strong>DISCLAIMER:</strong> I have zero insight on what’s going on within the WSL team or what their future plans are. This is purely my personal opinion based on what I have experienced as a user.</p>

<p>Let’s first take a look at WSL 1, and for that, we must look at what’s in the awkward name. Why was this feature named Windows subsystem… <em>for</em> Linux? Isn’t that backwards? This is not a subsystem in Linux to do anything Windows-related; it’s the other way around!</p>
<p>Well… you see, the name is technically correct when considering the design of the Windows NT kernel. From the <a href="https://en.wikipedia.org/wiki/Architecture_of_Windows_NT">Architecture of Windows NT</a> page in the Wikipedia, we find (emphasis mine):</p>
<blockquote>
<p>User mode in Windows NT is made of subsystems capable of passing I/O requests to the appropriate kernel mode device drivers by using the I/O manager. <strong>The user mode layer of Windows NT is made up of the “Environment subsystems”, which run applications written for many different types of operating systems</strong>, and the “Integral subsystem”, which operates system-specific functions on behalf of environment subsystems. The kernel mode stops user mode services and applications from accessing critical areas of the operating system that they should not have access to.</p>
</blockquote>
<p>Windows NT was designed from the ground up to support running processes from a multitude of operating systems, and Win32 was “just” one of those environment subsystems. With these solid foundations, WSL 1 supplies a new environment subsystem, the Linux subsystem, to run Linux binaries atop the Windows NT kernel. Both the Win32 and Linux environment subsystems share the common integral subsystem.</p>
<p>Mumble jumbo. What does any of that actually mean?</p>
<p>Different system call “front-ends”—that’s what it means. A user-space process is a collection of binary instructions that the processor executes uninterruptedly (leaving interrupts aside). The operating system’s kernel is unaware of what the process is doing until the process issues a system call: at that point, the kernel regains control to perform an operation on behalf of the user, which can be something like reading a file or pausing for a few seconds.</p>
<p>The way a process issues system calls, and the semantics of those system calls, are specific to the operating system. For example, on old x86: opening a file on Win32 is system call number <code>17h</code> invoked via <code>INT 2Eh</code> whereas opening a file on Linux is system call number <code>5h</code> invoked via <code>INT 80h</code>.</p>
<p>But… conceptually, opening a file is opening a file, right? The fact that the system call numbers or the software interrupt numbers are different among them is not particularly interesting. And hereby lies the key design aspect of WSL 1: the Linux subsystem in the NT kernel is, simply put, an implementation of Linux’s system call layer in front of the NT kernel. These system calls later delegate to NT primitives, <em>not</em> Win32 calls. Which is important to repeat: there is no translation from Linux to Win32 system calls.</p>
<p>This is a feat of engineering considering how generally good support for Linux apps got to be under WSL 1 and the many ways in which NT internally differs from Unix, <code>fork+exec</code> being the eternal archenemy.</p>
<p>The true beauty of this design is that there is a single kernel running on the machine, and this kernel has a holistic view of all the processes beneath it. The kernel knows everything about the Win32 <em>and</em> Linux processes. And these processes all interact with unified resources, such a single networking stack, a single memory manager, and a single process scheduler.</p>

<p>If WSL 1 is so cool, then why does WSL 2 exist? Two reasons:</p>
<ul>
<li>WSL 1 has to, essentially, implement all of Linux’s kernel ABI, “bit by bit”. If there is a bug in that interface, the WSL 1 has to replicate it. And if there is a feature that is difficult to represent within the NT kernel, either the feature cannot be implemented or it needs extra kernel logic (and thus becomes slower).</li>
<li>Linux subsystem in WSL 1 has to abide by any “limitations” and inherent differences that exist between the NT kernel and the traditional Unix design. The most obvious one is the NTFS file system and its semantics, and how these differences harm performance of Linux binaries. Poor file system performance seems to be a common complaint in WSL 1.</li>
</ul>
<p>WSL 2 “throws away” all of the Linux subsystem parts of the name and replaces everything with a full-blown (but very well-hidden and fast) virtual machine. The virtual machine then runs a proper Linux kernel, a proper Linux file system, and a proper Linux networking stack within it.</p>
<p>What this means is that the beauty of the WSL 1 design is gone: the Windows NT kernel doesn’t get to see anything that happens within the Linux world any more. All it knows is that there is a big black box that does “stuff” inside, and all it gets to see are the <code>VMENTER</code> and <code>VMEXIT</code> hook points for virtual machines and block-level read/write requests on a virtual disk. The NT kernel is now unaware of Linux processes and file accesses. Similarly, the Linux kernel is unaware of anything in NT land.</p>
<p>You can read about some more differences in the <a href="https://docs.microsoft.com/en-us/windows/wsl/compare-versions">official documentation</a>.</p>

<p>From the user’s point of view, WSL 2 feels strictly better: Linux apps now run much, much faster because they are not subject to awkward Linux system call “emulation” within the NT kernel. If using NTFS with Linux semantics is difficult, that’s no problem because the Linux environment now uses ext4 on a virtual disk. And support for Linux apps can be much more complete, because, well, WSL 2 <em>is</em> Linux: if you want FUSE, to name something, you got it.</p>
<p>But this comes at the cost <em>of what WSL could have been</em>:</p>
<ul>
<li>Can you imagine how cool it would be if you could type <code>ps</code> or <code>top</code> within a WSL session and see Linux <em>and</em> Windows processes side-by-side, able to mutate their state with <code>kill</code>?</li>
<li>Can you imagine how cool it would be to manipulate Windows services from the WSL session?</li>
<li>Can you imagine how cool it would be if you could use <code>ifconfig</code> (wait, is that <code>ip</code>? 🙄) within a WSL session to inspect and modify the machine’s network interfaces?</li>
<li>Essentially, can you imagine doing all of your Windows system administration tasks from within WSL?</li>
</ul>
<p>Although this never existed, I can well imagine such a world… and it’s one that <em>only the WSL 1 design can provide</em>. And the reason I can imagine this is because macOS gives you this model (albeit cheating because macOS is essentially Unix).</p>
<p>Which is what brings me to my frustration: even though I could install WSL on my development machine for Azure, there is nothing I can use it for. I still have to interact with the system via <code>CMD.EXE</code> because I have to deal with Windows-native processes and resources, and because the tooling I have to deal with is Windows-only.</p>
<p>The FAQ for WSL 2 claims that <a href="https://docs.microsoft.com/en-us/windows/wsl/wsl2-faq#what-will-happen-to-wsl-1-will-it-be-abandoned">WSL 1 will not be abandoned</a>, and if we abide by Microsoft’s backwards-compatibility guarantee, that may be true. But keeping WSL 1 running is a monumental effort due to the need to keep up with Linux changes. Regardless, I hope that this is the case and that WSL 1 continues to exist. Who knows, maybe the reason WSL 1 stays behind is to pursue this magical world I’m describing? 🤔</p>

<p>I can’t finish this post without talking about the various BSDs. The BSDs, always trailing behind Linux and other commercial operating systems, have had binary-level compatibility for ages. The earliest I can find is Linux compatibility in the NetBSD kernel back in 1995. That’s 25 years ago, and 21 before WSL 1’s first debut.</p>
<p>And, heck, this isn’t limited to Linux. NetBSD has had support to emulate <em>various</em> different operating systems throughout the years. SVR4 support appeared in 1994 and, for a brief stint, <a href="https://man.netbsd.org/NetBSD-5.0/compat_pecoff.8">NetBSD even had support for… 🥁… PE/COFF binaries</a>—that’s right, Win32 binaries. So, in a way, NetBSD implemented the WSL 1 model in reverse: it let you run Win32 binaries atop the NetBSD kernel back in 2002.</p>
</article>
            </div>
          </div><div>
            <div>
              <p><b>Want more posts like this one? Take a moment to subscribe!</b></p>
            </div>
            <div>
              
              <p>
                  <a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;screen_name=jmmv">
                    <img src="https://jmmv.dev/images/badges/Twitter_logo_blue_32.png" alt="Follow @jmmv on Twitter">
                  </a>
                </p>
              <p><a href="https://jmmv.dev/feed.xml"><img src="https://jmmv.dev/images/badges/feed-icon-28x28.png" alt="RSS feed"></a></p>
            </div>
          </div><div>
            <div>
              <p><b>Enjoyed this article? Spread the word or join the ongoing discussion!</b></p>
            </div>
            
          </div></div>]]>
            </description>
            <link>https://jmmv.dev/2020/11/wsl-lost-potential.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154300</guid>
            <pubDate>Thu, 19 Nov 2020 21:00:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawsuit: Tyson managers bet money on how many workers would contract Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25154104">thread link</a>) | @DanBC
<br/>
November 19, 2020 | https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/ | <a href="https://web.archive.org/web/*/https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div><figure><img width="2016" height="1512" src="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg" srcset="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg 2016w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-300x225.jpg 300w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1024x768.jpg 1024w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-768x576.jpg 768w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1536x1152.jpg 1536w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-80x60.jpg 80w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-265x198.jpg 265w" sizes="(max-width: 2016px) 100vw, 2016px" alt="" title="Workstation Dividers at Tyson Facility"><figcaption>Tyson workers have had plastic dividers separating them on the production line. (Photo provided by Tyson Fresh Meats)</figcaption></figure></div>
        <p>A wrongful death lawsuit tied to COVID-19 infections in a Waterloo pork processing plant alleges that during the initial stages of the pandemic, Tyson Foods ordered employees to report for work while supervisors privately wagered money on the number of workers who would be sickened by the deadly virus.</p>
<p>Earlier this year, the family of the late Isidro Fernandez sued the meatpacking company, alleging Fernandez was exposed to the coronavirus at the Waterloo plant where he worked. The lawsuit alleges Tyson Foods is guilty of a “willful and wanton disregard for workplace safety.”</p>
<p>In a written statement issued Thursday afternoon, Tyson Foods’ president and chief executive officer, Dean Banks, said: “We are extremely upset about the accusations involving some of the leadership at our Waterloo plant. Tyson Foods is a family company with 139,000 team members and these allegations do not represent who we are, or our core values and team behaviors. We expect every team member at Tyson Foods to operate with the utmost integrity and care in everything we do.</p>
<p>“We have suspended, without pay, the individuals allegedly involved and have retained the law firm Covington &amp; Burling LLP to conduct an independent investigation led by former Attorney General Eric Holder. If these claims are confirmed, we’ll take all measures necessary to root out and remove this disturbing behavior from our company.</p>
<p>“Our top priority is and remains the health and safety of our team members.”</p>
<p>Fernandez, who died on April 20, was one of at least five Waterloo plant employees who died of the virus. According to the Black Hawk County Health Department, more than 1,000 workers at the plant — over a third of the facility’s workforce — contracted the virus.</p>
<p>The lawsuit alleges that despite the uncontrolled spread of the virus at the plant, Tyson required its employees to work long hours in cramped conditions without providing the appropriate personal protective equipment and without ensuring workplace-safety measures were followed.</p>
<p>The lawsuit was recently amended and includes a number of new allegations against the company and plant officials. Among them:</p>
<ul>
<li>In mid-April, around the time Black Hawk County Sherriff Tony Thompson visited the plant and reported the working conditions there “shook [him] to the core,” plant manager Tom Hart organized a cash-buy-in, winner-take-all, betting pool for supervisors and managers to wager how many plant employees would test positive for COVID-19.</li>
<li>John Casey, an upper-level manager at the plant, is alleged to have explicitly directed supervisors to ignore symptoms of COVID-19, telling them to show up to work even if they were exhibiting symptoms of the virus. Casey reportedly referred to COVID-19 as the “glorified flu” and told workers not to worry about it because “it’s not a big deal” and “everyone is going to get it.” On one occasion, Casey intercepted a sick supervisor who was on his way to be tested and ordered him to get back to work, saying, “We all have symptoms — you have a job to do.” After one employee vomited on the production line, managers reportedly allowed the man to continue working and then return to work the next day.</li>
<li>In late March or early April, as the pandemic spread across Iowa, managers at the Waterloo plant reportedly began avoiding the plant floor for fear of contracting the virus. As a result, they increasingly delegated managerial authority and responsibilities to low-level supervisors who had no management training or experience. The supervisors did not require truck drivers and subcontractors to have their temperatures checked before entering the plant.</li>
<li>In March and April, plant supervisors falsely denied the existence of any confirmed cases or positive tests for COVID-19 within the plant, and allegedly told workers they had a responsibility to keep working to ensure Americans didn’t go hungry as the result of a shutdown.</li>
<li>Tyson paid out $500 “thank you bonuses” to employees who turned up for every scheduled shift for three months — a policy decision that allegedly incentivized sick workers to continue reporting for work.</li>
<li>Tyson executives allegedly lobbied Iowa Gov. Kim Reynolds for COVID-19 liability protections that would shield the company from lawsuits, and successfully lobbied the governor to declare that only the state government, not local governments, had the authority to close businesses in response to the pandemic.</li>
</ul>
<p>While Tyson has yet to file a formal response to the new allegations, it has said in previous court filings that it “vigorously disputes” the plaintiffs’ claims and has “invested millions of dollars to provide employees with safety and risk-mitigation equipment.”</p>
<p>The lawsuit claims that while Tyson has repeatedly claimed that its operations needed to remain open to feed America, the company increased its exports to China by 600% during the first quarter of 2020.</p>
<p>The lawsuit is seeking unspecified damages for fraudulent misrepresentation and gross negligence.</p>
<p>The case was initially filed in state court, claiming violations of Iowa law. At Tyson’s request, the case was moved to federal court, with the company claiming it had remained open during the pandemic “at the direction of a federal officer” — President Donald Trump, who, on April 28, invoked his authority under the <a href="https://iowacapitaldispatch.com/2020/05/04/trumps-critics-warn-his-order-to-keep-meat-plants-open-imperils-workers/">Defense Production Act</a> and ordered meat and poultry processing companies to continue operating.</p>
<p>The nonprofit organization Public Citizen has filed an amicus brief in the case, supporting the Fernandez family’s efforts to remand the action back to state court. In its brief, Public Citizen has said that neither the Defense Production Act nor the executive order signed by President Trump had “directed” Tyson to do anything.</p>
<p>The Waterloo facility is Tyson’s largest pork plant in the United States. The facility employs approximately 2,800 workers who process approximately 19,500 hogs per day.</p>

        </div></div>]]>
            </description>
            <link>https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154104</guid>
            <pubDate>Thu, 19 Nov 2020 20:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Postgres Foreign Data Wrapper for Clickhouse in Go]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25153782">thread link</a>) | @arunk-s
<br/>
November 19, 2020 | https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/ | <a href="https://web.archive.org/web/*/https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p><a href="https://www.postgresql.org/">Postgres</a>(hereinafter mentioned as PG) is a pretty cool database with lots of nice features, one of them little known ones is the ability of having Foreign data wrappers <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers">(hereinafter mentioned as FDWs)</a>.</p>

<p><a href="https://clickhouse.tech/">Clickhouse</a>(hereinafter mentioned as CH) is another amazing database with an altogether different set of features targeted for OLAP use cases.</p>

<h2 id="what-are-foreign-data-wrappers-fdws-then">What are Foreign Data Wrappers (FDWs) then?</h2>

<p>Well unlike so many names in tech, we can actually infer some idea from the name itself in this case.
So FDWs in essence, allows to access <em>foreign</em> <em>data</em> sources inside Postgres(PG) via a set of <a href="https://www.postgresql.org/docs/current/fdwhandler.html">wrapper APIs</a>.</p>

<p>That is, you can access data sitting in a Mysql/SQlite/Clickhouse(<em>any other data source</em>) table inside PG as you would do for a normal PG table. Isn’t that amazing!</p>

<p>There are already numerous such FDWs. A list is available <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers">here</a>.</p>

<p>One caveat is that the extent of features you can expect from a FDW is dependent on the particular implementation.
We can expect normal read support but other niceties like push-down filters, aggregations or joins, or write support can be missing.</p>

<h2 id="accessing-clickhouse-ch-via-postgres-pg">Accessing Clickhouse(CH) via Postgres(PG)</h2>

<p>Given the existence of so many possibilities of accessing other datastores, wouldn’t it be fun if we could access Clickhouse from inside Postgres.</p>

<p>Why would you want to do it! you may ask.</p>

<p>Well one reason could be of course, for <em>fun</em>.</p>

<p>But more realistically, one of the ambitious use cases at <a href="https://messagebird.com/">MessageBird</a>(my employer) was the ability to connect Clickhouse to <a href="https://looker.com/">Looker</a> as no direct integration existed at that time.
It was a bit of a moonshot but we decided to give it a try to see if it would work :)</p>

<p>MessageBird has generously made the full source for our experiment open source! The repository is available <a href="https://github.com/messagebird/clickhouse-postgres-fdw">here</a>.
So you can reference the ideas mentioned in the blog post directly in the code as well :)</p>

<h3 id="now-on-to-writing-one-fdw">Now on to writing one FDW!</h3>

<p>There are already <a href="https://www.postgresql.org/docs/current/fdwhandler.html">documentations</a> on how we should approach this and some simple examples are also available on Github. Most of the full fledged FDWs have their code in open so we can consult them as well.
Note that most of them are written in C becauses the FDW API of PG is in C, which makes sense.
I should highlight one particular <a href="https://github.com/pgspider/sqlite_fdw">FDW</a> that is made for SQLite and has a solid feature set, which helped me a lot while writing the one for Clickhouse.</p>

<p>But what if we want to be adventurous and write one in Go? Well, it should be possible given the existence of <a href="https://golang.org/cmd/cgo/">CGo</a>.</p>

<p>We can expect that it will not be at all trivial. ;)
There are already attempts on making Postgres Extensions in <a href="https://github.com/liztio/k8s-fdw">Go</a>, which gives a very valuable insight.</p>

<h4 id="setting-up-the-build-process-and-interaction-between-go-and-postgres-c-api">Setting up the build process and interaction between Go and Postgres C API</h4>

<p>First we should familiarize ourselves with the <a href="https://www.postgresql.org/docs/13/extend-pgxs.html">PG Extension Build Infrastructure/PGXS</a> and how to write <a href="https://www.postgresql.org/docs/current/xfunc-c.html#DFUNC">C code</a> for PG.
These are crucial as we would want to integrate the C code with Go, and knowing how the build process works should help us in understanding where our code will fit.</p>

<p>For writing a FDW we have to provide an entry point in form of a <code>struct</code> containing function pointers to the implemented callback functions.
Since we want to write those callback in Go, we can consult documentation for <a href="https://golang.org/cmd/cgo/#hdr-C_references_to_Go">accessing Go functions in C</a>, which says there are specific annotations that should allow us to export go functions outside to the C code.
All the important work is done in these callbacks only.<br>
Now it should be possible to add functions that PG FDW API expects via Go.</p>

<p>But, how will the C code find the callback functions written in Go land ? <a href="https://golang.org/cmd/go/#hdr-Build_modes">Go build modes</a> is the answer.
Directly referencing from the documentation, the <code>-buildmode=c-archive</code> allows us to:</p>

<pre><code>Build the listed main package, plus all packages it imports,
into a C archive file. The only callable symbols will be those
functions exported using a cgo //export comment. Requires
exactly one main package to be listed.
</code></pre>

<p>Perfect! Now, the exported Go functions are available in the <a href="https://linux.die.net/man/1/ar">archive file</a>.
The only remaining thing is to link the archive with C code during build.
Thankfully, <a href="https://www.postgresql.org/docs/13/extend-pgxs.html">PGXS</a> provides a <code>Make</code> variable <code>SHLIB_LINK</code> that can be used to set the shared library used. So we’ll use that flag to provide the archive build from Go source files.</p>

<p>You can see it in action <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/main/Makefile">here</a>.</p>

<!-- * how linking go code to c via statically linked libraries works ? .a files linking with Go. -->

<!-- And we want a library of sorts which should be callable inside C code. For this we can use go build mode (c-archive), this will create a statically linked archive(see difference btwn shared objects and statically linked libraries and how to build them) -->

<h4 id="understanding-inner-working-of-the-fdw-api-and-their-relation-with-different-query-stages">Understanding inner working of the FDW API and their relation with different Query Stages</h4>

<!-- * Figuring out which stages do what, what do you want and where to look for them -->

<p>To actually write a working FDW, we need to familiarize with the different stages a query goes through in PG and how the API functions play them out.
Postgres has an excellent documentation and moreover since all the <a href="https://github.com/messagebird/clickhouse-postgres-fdw/">source code</a> is open, we can just navigate through the code as well!</p>

<p>It would take more space than a blog post to explain the full internals of Query planner in Postgres and I probably can’t describe it well enough.
So, I suggest to go through <a href="https://www.postgresql.org/docs/current/fdw-callbacks.html">the official documentation</a> which is quite excellent and there are many other excellent references on the web.</p>

<p>I’ll try to briefly explain the flow of the API functions for the context of this post.
A very basic plan looks like this:</p>

<pre><code>+-------------------------+
|                         |
|                         |
|    GetForeignRelSize    |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     GetForeignPaths     |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     GetForeignPlan      |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     BeginForeignScan    |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|    IterateForeignScan   |
|                         |
|                         |
+-------------------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     EndForeignScan      |
|                         |
|                         |
+-------------------------+

</code></pre>

<p>There are other functions in the FDW API that I’ve omitted here (like <code>ReScanForeignScan</code>, <code>AnalyzeForeignTable</code>, <code>GetForeignUpperPaths</code>) but a basic FDW can be done with these.
Also note that this path is only concerned with the read queries. To enable writing on the foreign database, there are separate functions that need to be implemented.
You can see how the read path is implemented for our clickhouse FDW <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/main/ch_fdw.c">here</a>.</p>

<p>Important ones to take note of to properly implement the read path of a query are:</p>

<ul>
<li><p>GetForeignRelSize: It should be used to determine the estimated number of rows to be scanned on the foreign server. However, it is also used to extract the restriction clauses present in the query presented by PG and to pass them to the foreign server if it can support them.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L180">example</a>.</p></li>

<li><p>GetForeignPlan: It should return the planner node(a data structure that contains the query plan). However, it is also used to extract the target columns that can be fetched from remote/foreign servers and pass that info along with restriction clauses, table names to the next stage.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L275">example</a>.</p></li>

<li><p>BeginForeignScan: It should perform the initalization that is needed to perform the scan on the foreign server, for example: initialize the foreign DB connection, formalize the query running on foreign server and init the state with row iterator to be used in the next stage.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L508">example</a>.</p></li>

<li><p>IterateForeignScan: It should return a row from the foreign server converted to the PG specific structure. This function should convert the foreign server specific data types to PG column data types.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L620">example</a>.</p></li>

<li><p>EndForeignScan: It should clean the state being stored for the query, like row iterators, db connections should be closed.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L760">example</a>.</p></li>
</ul>

<p>This is a very dense overview of the functionality of a <em>basic</em> FDW. It usually helps to look around the other FDWs that are open source to look for ideas of a sample implementation. But it can differ since the foreign server can be of various types.
Usually, if we take databases that support some dialect of SQL then the hardest things are usually figuring out if the restriction clauses are remote safe, which can involve parsing the full expression clauses and then converting them to remote variants.
Converting the foreign server datatypes to PG types is comparatively easy but is very toiling.</p>

<p>You can look into how <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go">clickhouse FDW</a> does this to get an idea, but beware that it could be bug prone, since it hasn’t been tested thoroughly.</p>

<p>I’ll also suggest getting an idea of commonly used PG datatypes and conventions like <code>OID</code>, <code>Tuple</code>, <code>RelOptInfo</code> or just going over <a href="https://doxygen.postgresql.org/relation_8h.html"><code>relation.h</code></a> reference from PG source code.</p>

<h3 id="few-tips-and-tricks">Few Tips and Tricks</h3>

<p>These are some ideas that I’ve seen are fairly used while developing a FDW. Some can help in easy interop between Go and C, whether it is a good idea or not, is up for debate ;)</p>

<h4 id="interfacing-c-macros-within-go">Interfacing C macros within Go</h4>

<p>There are a lot of internal macros in PG source which makes it easier to access system cache, lists, heap tuples etc. which aren’t directly callable from Go’s userland.<br>
This is because CGo doesn’t quite allow directly calling C <code>#define</code> macros.<br>
You can try to simulate the same behaviour using underlying constructs but that can get hairy and cumbersome. Instead one <em>easy</em> idea is to define simple C wrapper functions like</p>

<pre><code>void *wrapper_access_list(void *list, int index){
	return access_list(list, index);
}
</code></pre>

<p>This can now be used directly on Go side. But make sure you cast the results to proper types.</p>

<h4 id="moving-out-c-code">Moving out C code</h4>

<p>There can be a point where writing C code directly in Go source files is not feasible …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/">https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/</a></em></p>]]>
            </description>
            <link>https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153782</guid>
            <pubDate>Thu, 19 Nov 2020 20:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First Kernel Module: A Debugging Nightmare]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25153388">thread link</a>) | @ksml
<br/>
November 19, 2020 | https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html | <a href="https://web.archive.org/web/*/https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is the story of the time I wrote some code, deployed it to production, and
ended up bricking the server it was running on by frying the kernel.</p>

<figure>
    <a href="https://reberhardt.com/blog//images/my-first-kernel-module/frying-pan.jpg">
        <img src="https://reberhardt.com/blog//images/my-first-kernel-module/frying-pan.jpg" alt="Beautiful rendition of me frying the kernel">
    </a>
    
    <figcaption>Beautiful rendition of me frying the kernel</figcaption>
    
</figure>

<p>This post is about perils of concurrency and race conditions.  My code was
nearly correct, but ultimately, there were two major synchronization bugs that
killed it.</p>

<!--more-->

<p>This is a really long post that gets into the weeds at times, but I have tried
to write it so that you can jump into any section and hopefully learn something
from it:</p>

<ul>
  <li><a href="#a-nightmare-begins">A nightmare begins</a>: How I discovered this issue and
initially triaged it</li>
  <li><a href="#context-c-playground-visual-debugger">Context: C Playground visual
debugger</a>: How Linux <code>/proc</code> files
work, and how Linux stores process and open file information. I drew some
spiffy diagrams so you can visualize how this works!</li>
  <li><a href="#the-debugging-process">The debugging process</a>: How I attempted to track
down the bug(s)
    <ul>
      <li><a href="#finding-a-footing">Finding a footing</a></li>
      <li><a href="#red-herrings">Red herrings</a></li>
      <li><a href="#the-processes-smell-fishy">The processes smell fishy</a></li>
      <li><a href="#desperation-and-the-start-of-progress">Desperation, and the start of progress</a></li>
      <li><strong><a href="#rcu-read-copy-update">RCU: Read, Copy, Update</a>: The cause of (and fix for) my first bug</strong></li>
      <li><a href="#fix-1-dont-block-in-critical-sections">Fix #1: Don’t block in critical sections</a></li>
      <li><a href="#the-emotional-rollercoaster-continues">The emotional rollercoaster continues</a></li>
      <li><a href="#fix-2-rebuilding-the-kernel">Fix #2: Rebuilding the kernel</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a>: Takeaways and lessons learned</li>
</ul>

<p><strong>Looking for a quick read?</strong> Skip to the <a href="#rcu-read-copy-update">RCU: Read, Copy,
Update</a> section for spoilers.</p>

<p>In this post, I assume you have some understanding of how files and concurrency
work on Unix systems. I will try to explain everything else!</p>

<h2 id="a-nightmare-begins">A nightmare begins</h2>

<p>I have been working on building a <a href="https://reberhardt.com/blog/2019/12/12/generating-diagrams-for-teaching-multiprocessing.html">graphical debugger for C Playground</a> for
some time, allowing users to run code in the browser and visualize how their
program is being executed. As part of this work, I had to implement a kernel
module. (I’ll explain more about this project in the next section.) After
testing the code locally for a few months, I pushed it to production.</p>

<p>The next morning, I woke up to a text from my roommate: <em>“I think the server
crashed.”</em> Uh oh, that’s not supposed to happen. I quickly pulled out my laptop
and tried to SSH into the server to pull the logs, but to my surprise, I
couldn’t reach the server:</p>

<div><div><pre><code>ssh: connect to ... port 22: Operation timed out
</code></pre></div></div>

<p>Something wasn’t right. I logged into DigitalOcean to restart the machine, but
while I was doing that, I noticed a spike in the server’s CPU usage graph
around the time my roommate texted me. The CPU was cleanly pegged at 100%.
Normally, if a process running on the machine is hogging the CPU, we should
expect to see slight fluctuations around 100%, but that was not the case here
– it was a clean, horizontal line.</p>

<figure>
    <a href="https://reberhardt.com/blog//images/my-first-kernel-module/digitalocean-cpu-usage.png">
        <img src="https://reberhardt.com/blog//images/my-first-kernel-module/digitalocean-cpu-usage.png" alt="">
    </a>
    
</figure>

<p>After force-restarting the server via DigitalOcean and rolling back the
debugging feature, I started going through logs to get a sense for what
happened. My kernel module has print statements, and these get saved to the
kernel’s log in <code>/var/log/kern.log</code>. I scanned through this file, hoping to
find some clues, but this only confused me even more; there was <em>nothing</em> in
the kernel logs from any time near when the server locked up. It seemed to
suggest my kernel module wasn’t even running at that time. But I felt it <em>had</em>
to be a problem with my kernel module: nothing in user space could cause a
computer to lock up the way it did, completely unresponsive and pegged at 100%
CPU.</p>

<p>I kept digging. If the kernel logs didn’t give me anything helpful, maybe there
might be some application-side records that would indicate what happened.
However, when I checked the C Playground log file, I felt things only getting
worse:</p>

<div><div><pre><code>[2020-03-25T14:47:00-0400] [INFO]   [p5wDiTxoeX4hdYwDAAEm] Websocket connection received from &lt;redacted&gt;
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Program is at alias lion-eland-echidna
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Run logged with ID 55229
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Saving code to /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Successfully created gdb socket at /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-gdb.sock
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Starting container: docker run -it --name dfb5e628-595f-464d-a4dd-1559db7b78d8 --read-only --tmpfs /cplayground:mode=0777,size=32m,exec -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8:/cplayground/code.cpp:ro -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-include.zip:/cplayground/include.zip:ro -e COMPILER=g++ -e CFLAGS=-g -std=c++17 -O0 -Wall -no-pie -lm -pthread -e SRCPATH=/cplayground/code.cpp --cap-drop=all --memory 96mb --memory-swap 128mb --memory-reservation 32mb --cpu-shares 512 --pids-limit 16 --ulimit cpu=10:11 --ulimit nofile=64 --network none -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-gdb.sock:/gdb.sock --cap-add=SYS_PTRACE -e CPLAYGROUND_DEBUG=1 cplayground /run.py
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Initial terminal size 80x24
[2020-03-25T14:47:01-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Resize info received: 17x74
[2020-03-25T14:47:01-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Resize info received: 17x75
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
&lt;truncated for brevity&gt;
</code></pre></div></div>

<p>What on earth is <em>that</em>???</p>

<p>After some Googling, I figured out that <code>^@</code> is how <code>less</code> displays null bytes.
So, my log file is filled with null bytes. Why would that be?</p>

<p>Then it occurred to me: Filesystem writes aren’t synchronous. When a program
writes to a file, the data is usually not immediately written to disk. Instead,
to improve performance, the data is written to a buffer in memory. Normally,
the kernel flushes this buffer to disk periodically, so that the data is
persisted. But if the kernel is incapacitated, there is no way the data can
reach the disk, and when the machine force-restarts, it is lost forever. From
the above output, I could see that parts of the logs made it to disk, but later
parts of the logs were not so lucky, appearing as scrambled null bytes instead.</p>

<p>I started to feel a sense of dread creeping in. This was reminding me of the
extremely late nights and brain-frying debugging sessions from that time I took
an operating systems class. Except this might be even worse: This problem is
<em>only</em> happening in production, and I can’t reproduce it, and I can’t get any
logs to explain what’s wrong.</p>

<p>In the next section, I’ll explain what my kernel module was doing, so that you
can follow along with my debugging process. Then, in the last section, I’ll
talk you through the long, long process I went through to identify the <em>two</em>
bugs that caused this problem. (Spoiler alert: there were two race conditions
that caused two use-after-frees, in which I attempted to use memory after it
had already been freed.)</p>

<h2 id="context-c-playground-visual-debugger">Context: C Playground Visual Debugger</h2>

<p>I have been working on <a href="https://cplayground.com/">C Playground</a> for some time,
which is an online sandbox for quickly testing out C and C++ code. It is
specifically designed for learning systems programming, and I have been working
on features that generate diagrams to illustrate what is happening under the
hood when you run code on a computer.</p>

<p>Most recently, I was working on generating diagrams of the data structures that
the kernel uses to keep track of a program’s open files. The context and
motivation for this are described in much more detail in <a href="https://reberhardt.com/blog/2019/12/12/generating-diagrams-for-teaching-multiprocessing.html">this blog
post</a>.
As a very brief summary, this feature aims to help students understand system
calls such as <code>open</code>, <code>close</code>, <code>dup2</code>, <code>fork</code>, <code>pipe</code>, and others. Using these
system calls requires an understanding of what they are doing on your behalf.
Usually, we explain these system calls in terms of the <em>vnode table</em>, which
caches information about files on the system, the <em>open file table</em>, which
stores <em>session</em> information (e.g. program X has file Y open for reading, and
has read 100 bytes so far), and the <em>file descriptor table</em>, which stores
pointers into the open file table indicating which sessions a process has open.</p>

<p>When teaching these concepts, we typically draw a lot of diagrams by hand. C
Playground aims to generate diagrams automatically, helping students to build
up and confirm their intuitions without needing access to a TA. The platform
allows students to set breakpoints and step through …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html">https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html</a></em></p>]]>
            </description>
            <link>https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153388</guid>
            <pubDate>Thu, 19 Nov 2020 19:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jackie Chan's Best Advice]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25151667">thread link</a>) | @oDot
<br/>
November 19, 2020 | https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/ | <a href="https://web.archive.org/web/*/https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
      
    
<p>
  <iframe src="https://www.youtube.com/embed/TqM1oX7Ckfc" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<blockquote>
<p>Whatever you do, do the best you can, because the film live forever. “No, because, you know, that day raining and the actor don’t have time”. I said “Would you go to every theater to tell the audience?” No! The audience sit in the theater – “good movie”, “bad movie”. That’s all.</p>
</blockquote>
<p>I try to follow it with everything I do. With professional work – the software I create, the screenplays I write and the films I produce. With my personal life – how I talk to people, the things I buy and the cleanliness of my house.</p>
<p>To function, it must be implemented at every level. To do the best we can in software work, we must do the best we can with every line of code, email to a client and commit message. We will not clean our house the best we can unless we take care to pull out a toothbrush when needed, and even research the right toothbrush to have in our cleaning kit (don’t worry, any will do).</p>
<p>I can hear you already, “it’s too mentally tasking to do”. That line of thought is exactly what Jackie Chan advises us against. Even when the reservation is true, even when it’s raining and the actor doesn’t have time, we should ask ourselves “how can this be done despite the trouble”. Same thing goes for the advice itself. Instead of dismissing it on the account of mental load, one should ask “How can I apply this in my life anyway?”</p>
<p>Do no conflate “the best you can” with “perfect”. They are different things. “The best you can” refers to achieving goals. Goals usually combine all considerations, rather than the focus on an isolated metric of quality. The goal to have good breakfast will not be achieved the best you can if you eternally postpone it trying to perfect a french omelette.</p>
<p>Not any goal will do. Goals must adhere to high standards. That is why it can take Jackie Chan a year to film a movie. He takes the time needed to do the best he can, and still, he says, can see the imperfections when watching his own work. We should balance.</p>
<p>Yet it is true. Even though it’s somewhat of an “obvious” insight, it is very hard to put into practice. Around every corner hides a legitimate reason to do less.</p>
<p>We must remember that having reasons does not turn a failure to success. End results are completely unaffected by rationalization as to why they should or shouldn’t be the way they are.</p>
<p>An end result is just is.</p>



      
    </article>
    
    
      
      
</div></div>]]>
            </description>
            <link>https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151667</guid>
            <pubDate>Thu, 19 Nov 2020 17:13:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The New Era of Developer Experience: Delivering World-Class Support]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25151420">thread link</a>) | @apitracker
<br/>
November 19, 2020 | https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape | <a href="https://web.archive.org/web/*/https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Download Now</strong><span>Enter your email address to download this Hoss resource.</span></p></div></div></div>]]>
            </description>
            <link>https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151420</guid>
            <pubDate>Thu, 19 Nov 2020 16:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney Stiffs SF Writer Alan Dean Foster]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25151408">thread link</a>) | @samizdis
<br/>
November 19, 2020 | https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1606">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
tyson, labor, covid, late-stage capitalism, guillotine watch, dearmickey, disneymustpay,alan dean foster, copyright, copyfight, chickenization, monopolies, contracts, sfwa, publishing, writing, disney, attack surface lectures, attack surface, science fiction, cyberpunk

Summary:
Cyberpunk and Post-Cyberpunk; Disney stiffs writer; Tyson execs bet on covid spread in unsafe plant

URL:
https://pluralistic.net/2020/11/19/disneymustpay/

Title:
Pluralistic: 19 Nov 2020 disneymustpay

Bullet:
🧛🏼‍♀️

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: JWZ (https://www.jwz.org/blog/).

--><br>
<a href="https://pluralistic.net/2020/11/19/disneymustpay/"><img src="https://i0.wp.com/craphound.com/images/19Nov2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/19Nov2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#asl">Cyberpunk and Post-Cyberpunk</a>: Bruce Sterling and Christopher Brown on the Attack Surface Lectures.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">Disney stiffs writer</a>: Sure, what's new, but this is next-level fuckery #DisneyMustPay.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#you-bet-your-life">Tyson execs bet on covid spread in unsafe plant</a>: Upton Sinclair was an optimist.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#retro">This day in history</a>: 2010, 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="asl"></a><br>
<img src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today on the Attack Surface Lectures (a series of 8 panels exploring themes from the third Little Brother book, hosted by Tor Books and 8 indie bookstores): Cyberpunk &amp; Post-Cyberpunk with Christopher Brown and Bruce Sterling, which Anderson's hosted on Oct 19.</p>
<p><a href="https://www.youtube.com/watch?v=xLlfrayuKAw">https://www.youtube.com/watch?v=xLlfrayuKAw</a></p>
<p>You can watch it without Youtube's surveillance courtesy of the Internet Archive:</p>
<p><a href="https://archive.org/details/asl-cyberpunk">https://archive.org/details/asl-cyberpunk</a></p>
<p>Or get the audio as an MP3:</p>
<p><a href="https://archive.org/download/asl-cyberpunk/Cyberpunk%20with%20Bruce%20Sterling%20and%20Christopher%20Brown.mp3">https://archive.org/download/asl-cyberpunk/Cyberpunk%20with%20Bruce%20Sterling%20and%20Christopher%20Brown.mp3</a></p>
<p>Earlier instalments in the series:</p>
<p>I. Politics and Protest (with Eva Galperin and Ron Deibert, hosted by The Strand):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/">https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/</a></p>
<p>II. Cross-Media Sci-Fi (with Amber Benson and John Rogers, hosted by the Brookline Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/">https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/</a></p>
<p>III. Race, surveillance and tech (Meredith Whittaker and Malkia Devich-Cyril, hosted by The Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/">https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/</a></p>
<p>Here's a master post with all the media as it is goes live:</p>
<p><a href="https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/">https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/</a></p>
<p>And you can also get this as it's posted on my podcast feed – search for "Cory Doctorow podcast" in your podcatcher or use the RSS:</p>
<p><a href="https://feeds.feedburner.com/doctorow_podcast">https://feeds.feedburner.com/doctorow_podcast</a></p>
<hr>
<p><a name="disneymustpay"></a><br>
<img src="https://i0.wp.com/craphound.com/images/Disney-Must-Pay-Basic-Text-768x432.jpg?resize=768%2C432&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/Disney-Must-Pay-Basic-Text-768x432.jpg?resize=768%2C432&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Alan Dean Foster is an sf legend – a writer who produced a shelf of original novels but also made a reputation novelizing movies and TV from Star Wars to Aliens, turning out books that transcended quickie adaptations, becoming beloved bestsellers in their own right.</p>
<p>Disney now owns a bunch of these books, thanks to their acquisitions of Lucas and Fox, and these books continue to sell briskly. Disney not only isn't paying Foster any royalties for these books – they're refusing to even issue him royalty statements.</p>
<p><a href="https://www.sfwa.org/2020/11/18/disney-must-pay/">https://www.sfwa.org/2020/11/18/disney-must-pay/</a></p>
<p>Disney has blackholed Foster's agents and lawyers, and also the Science Fiction Writers of America (SFWA); to the extent that they have communicated with him, they have espoused a radical (jaw dropping) copyright theory.</p>
<p>This is Disney's theory: When they bought Lucas and Fox, they acquired the copyright licenses that enabled them to sell the Foster's books – but not the liability, the legal obligation to pay him for his books.</p>
<p>As SFWA president Mary Robinette Kowal says, this theory could absolutely upend the nature of copyright itself. Any publisher that wanted to go on making money from an author without paying them could simply sell the rights to a sister company, which then denies any obligations.</p>
<p>Foster brought his case to SFWA's grievance committee – a group that has worked on my behalf in the past, extracting a fee from a multinational publisher that commissioned and accepted a story from me but then offered an odious and unacceptable contract they refused to amend.</p>
<p>Usually griefcom work happens in the background: a SFWA member goes to griefcom, griefcom goes to the publisher, the publisher settles. This is the first time in more than a decade that SFWA has gone public with a complaint.</p>
<p>To be fair, Disney <em>did</em> offer to meet with Foster, but demanded that he sign an NDA <em>prior</em> to any negotiation. This is Not Normal. Sometimes the OUTCOME of a negotiation is confidential, but you don't go into a negotiation under NDA.</p>
<p>Disney appears to be taking a page from the cartoonish villain Scooter Braun, who refused to meet with Taylor Swift about buying back the rights to her masters without an NDA.</p>
<p><a href="https://twitter.com/taylorswift13/status/1328471874318311425">https://twitter.com/taylorswift13/status/1328471874318311425</a></p>
<p>Foster's case is a gross injustice. He has cancer and his wife is ill. He wrote these books, Disney bought them. They're making money from them. They owe him money. Period.</p>
<p>But beyond the individual injustice being visited upon Foster, Kowal and SFWA worry that this represents a suite of new, corporate anti-writer tactics: flipping assets without liabilities, refusing to talk about it without an NDA.</p>
<p>You can follow Foster's case with the #DisneyMustPay hashtag. If you're a writer facing similar tactics (even if you're not a SFWA member), they're seeking your story, via this form:</p>
<p><a href="https://airtable.com/shrr2S8rs4pcokske">https://airtable.com/shrr2S8rs4pcokske</a></p>
<hr>
<p><a name="you-bet-your-life"></a><br>
<img src="https://i0.wp.com/craphound.com/images/x1080.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/x1080.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Remember last April, when US meatpacking giants like Tyson were the epicenter of runaway superspreader events that slaughtered the poor, precarious, racialized workers who toiled under brutal and unsafe conditions?</p>
<p>One of the hardest-hit was Tyson's Waterloo, IA plant (the largest meat packing plant in America), where workers were denied PPE, forced to work without social distancing, and where more than 1,000 of them contracted covid. Many died.</p>
<p>One of the dead is Isidro Fernandez. In a wrongful death suit, his lawyers revealed details of Tyson's abuse of its workers that shock the conscience, like the fact that manager Tom Hart ran a betting pool on how many workers would contract covid.</p>
<p><a href="https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</a></p>
<p>The suit also claims senior manager John Casey told supervisors that they were required to report for work even if they had symptoms, calling covid a "glorified flu." He forced a supervisor to cancel a testing appointment, saying "We all have symptoms – you have a job to do."</p>
<p>A worker who was so sick he vomited on the line was ordered back to work the next day.</p>
<p>As conditions in the plant deteriorated, Tyson managers stopped visiting the floor altogether in a bid to protect themselves. Instead, they delegated to inexperienced supervisors.</p>
<p>They also told workers they would only be eligible for a $500 "thank you bonus" if they reported for every shift they were scheduled to work, regardless of whether they were sick and contagious.</p>
<p>All of this was justified – by Tyson and its enablers in the GOP – as a necessary, regrettable part of keeping America fed during the lockdown. But Tyson's breakneck meat-packing wasn't primarily domestic: they were serving the Chinese market.</p>
<p>Chinese meat-packers had largely been mothballed to spare workers from the virus; as a result, the company was able to increase its exports to China by 600% during Q1-2020.</p>
<p>But this isn't the story that Tyson's execs told Governor Kim Reynolds when they lobbied for exemptions from liability for the employees they maimed and murdered during the same period – they claimed it was all patriotic zeal to feed America.</p>
<p>The case has moved to federal court, thanks to Trump's invocation of the Defense Production Act, which ordered Tyson to stay open during the lockdown.</p>
<hr>
<p><a name="retro"></a><br>
<img src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>#10yrsago TSA confiscates heavily-armed soldiers’ nail-clippers <a href="https://redstate.com/erick/2010/11/18/another-tsa-outrage-n37064">https://redstate.com/erick/2010/11/18/another-tsa-outrage-n37064</a></p>
<p>#5yrsago Manhattan DA calls for backdoors in all mobile operating systems <a href="https://web.archive.org/web/20151120003032/https://www.manhattanda.org/sites/default/files/11.18.15%20Report%20on%20Smartphone%20Encryption%20and%20Public%20Safety.pdf">https://web.archive.org/web/20151120003032/https://www.manhattanda.org/sites/default/files/11.18.15%20Report%20on%20Smartphone%20Encryption%20and%20Public%20Safety.pdf</a></p>
<p>#1yrago Coop’s tribute to Randotti Skulls, from the golden age of Haunted Mansion merchandise <a href="https://memex.craphound.com/2019/11/18/coops-tribute-to-randotti-skulls-from-the-golden-age-of-haunted-mansion-merchandise/">https://memex.craphound.com/2019/11/18/coops-tribute-to-randotti-skulls-from-the-golden-age-of-haunted-mansion-merchandise/</a></p>
<hr>
<p><a name="bragsheet"></a><br>
<img src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today's top sources: JWZ (<a href="https://www.jwz.org/blog/">https://www.jwz.org/blog/</a>).</p>
<p>Currently writing: My next novel, "The Lost Cause," a post-GND novel about truth and reconciliation. Yesterday's progress: 513 words (85767 total).</p>
<p>Currently reading: The Ministry for the Future, Kim Stanley Robinson</p>
<p>Latest podcast: Someone Comes to Town, Someone Leaves Town (part 23) <a href="https://craphound.com/podcast/2020/11/16/someone-comes-to-town-someone-leaves-town-part-23/">https://craphound.com/podcast/2020/11/16/someone-comes-to-town-someone-leaves-town-part-23/</a></p>
<p>Upcoming appearances:</p>
<ul>
<li>Keynote, Cybersummit 2020, Nov 26 <a href="https://www.cybera.ca/cyber-summit-2020/">https://www.cybera.ca/cyber-summit-2020/</a>
</li>
<li>
<p>Keynote, Cologne Futures, Nov 27, details TBD</p>
</li>
<li>
<p>Beaverbrook Lecture: How to Destroy Surveillance Capitalism, Nov 30, <a href="https://www.mcgill.ca/maxbellschool/channels/event/2020-beaverbrook-annual-lecture-part-ii-cory-doctorow-325538">https://www.mcgill.ca/maxbellschool/channels/event/2020-beaverbrook-annual-lecture-part-ii-cory-doctorow-325538</a></p>
</li>
<li>
<p>Teach-In Against Surveillance, Dec 1, <a href="https://www.eventbrite.ca/e/teach-in-against-surveillance-tickets-128926228821">https://www.eventbrite.ca/e/teach-in-against-surveillance-tickets-128926228821</a></p>
</li>
<li>
<p>Keynote, NISO Plus, Feb 22-25, <a href="https://niso.plus/cory-doctorow-to-keynote-at-niso-plus-2021/">https://niso.plus/cory-doctorow-to-keynote-at-niso-plus-2021/</a></p>
</li>
</ul>
<p>Recent appearances:</p>
<ul>
<li>Fully Charged: The future of energy over the next 300 years<br>
<a href="https://fullycharged.show/podcasts/podcast-84-the-future-of-energy-over-the-next-300-years-cory-doctorow/">https://fullycharged.show/podcasts/podcast-84-the-future-of-energy-over-the-next-300-years-cory-doctorow/</a>
</li>
<li>
<p>Allen School Distinguished Lecture "Early Onset Oppenheimers"<br>
<a href="https://www.youtube.com/watch?v=Ep78A-jtcrE">https://www.youtube.com/watch?v=Ep78A-jtcrE</a></p>
</li>
<li>
<p>Author Stories Podcast<br>
<a href="https://www.youtube.com/watch?v=yxSPZn8EGTE">https://www.youtube.com/watch?v=yxSPZn8EGTE</a></p>
</li>
</ul>
<p>Latest book:</p>
<ul>
<li>"Attack Surface": The third Little Brother novel, a standalone technothriller for adults. The <em>Washington Post</em> called it "a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance." Order signed, personalized copies from Dark Delicacies <a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a></li><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a><li><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a><p><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">"How to Destroy Surveillance Capitalism": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. </a><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
</li>
<li>
<p>"Little Brother/Homeland": A reissue omnibus edition with a new introduction by Edward Snowden: <a href="https://us.macmillan.com/books/9781250774583">https://us.macmillan.com/books/9781250774583</a>; personalized/signed copies here: <a href="https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html">https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html</a></p>
</li>
<li>
<p>"Poesy the Monster Slayer" a picture book about monsters, bedtime, gender, …</p></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151408</guid>
            <pubDate>Thu, 19 Nov 2020 16:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Years of Scaling TimescaleDB Without Clustering]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150265">thread link</a>) | @serenadns
<br/>
November 19, 2020 | https://www.dnsfilter.com/blog/timescaledb-performance/ | <a href="https://web.archive.org/web/*/https://www.dnsfilter.com/blog/timescaledb-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-elementor-type="wp-post" data-elementor-id="4345" data-elementor-settings="[]"><div><div><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="a1c80e6" data-element_type="section"><div><div><div data-id="5ff4de5" data-element_type="column"><div><div><div data-id="9e21dcc" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>It’s been over 2 years since we made the switch from </span><a href="https://fltr.ai/2OOM" target="_blank" rel="noopener"><span>InfluxDB to TimescaleDB</span></a><span> at DNSFilter. You can read the </span><a href="https://fltr.ai/2OOO" target="_blank" rel="noopener"><span>original blog</span></a><span> for all the details on why we transitioned to TimescaleDB in the first place, but the main thing we were after was reliability. We’re still using TimescaleDB, and unsurprisingly we’ve made a lot of changes to our infrastructure since that original post as our total users have continued to grow. Over the last 2 years we’ve worked to optimize TimescaleDB performance, and we’ve done it all </span><i><span>without</span></i><span> clustering.</span></p><h2><span>Expectation Vs. Reality</span></h2><p><span>In 2018, I made the prediction that we could get to 3B queries per day without major structural changes to our setup. I wasn’t quite wrong, but I wasn’t totally right either.&nbsp;</span></p><p><span>After going roughly 18 months without issues (with daily queries steadily growing), we hit over 1.2B for the first time in October of 2019. It was the first sign that the actual hardware supporting TimescaleDB would have trouble getting to 3B daily queries. The server had trouble keeping up with </span><a href="https://kafka.apache.org/" target="_blank" rel="noopener"><span>Kafka</span></a><span>, and the lag was </span><i><span>hours</span></i><span> long. We weren’t losing queries like we had previously with InfluxDB, but the disk I/O of our TimescaleDB server had trouble keeping up.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="9b23b4b" data-element_type="section"><div><div><div data-id="e8c98dd" data-element_type="column"><div><div><div data-id="208228a" data-element_type="widget" data-widget_type="image.default"><div><div><figure> <img width="1024" height="329" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png" alt="TimescaleDB Performance on our old server" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-300x96.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-768x246.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-500x160.png 500w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio.png 1331w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-300x96.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-768x246.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-500x160.png 500w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio.png 1331w"><figcaption>You can see the server struggle in October 2019 and then hit a temporary wall in March 2020.</figcaption></figure></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="7d801f6" data-element_type="section"><div><div><div data-id="7902b84" data-element_type="column"><div><div><div data-id="3ec0127" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>We tweaked the ram usage in PostgreSQL and started to plan for a new approach.</span></p><p><span>At the time, this was just a spike in daily queries, but we knew we were approaching the moment where we would have to sustain over 1B queries daily. To help us out, we looked at setting up a virtual machine with </span><a href="https://www.digitalocean.com/" target="_blank" rel="noopener"><span>Digital Ocean</span></a><span>.</span></p><p><span>The original intention wasn’t to replace that server, it was just to take the load off of it. We wound up setting up 2 additional servers with Digital Ocean.&nbsp;</span></p><p><span>In February, our original server hit another wall and by March the Digital Ocean servers were officially online. For a few months, we had 3 TimescaleDB servers running (all receiving the same information) until it became clear the original server was no longer necessary. It wasn’t carrying much of the load anymore, and it was not as performant as the Digital Ocean servers. At that point, it was just deadweight and extra costs, so we deprecated it in June 2020.</span></p><h2><span>The spike that didn’t stop</span></h2><p><span>As of fall 2020, our daily requests have skyrocketed compared to where we were this time last year (even with that October spike in requests). To handle this sustained surge in requests, we’ve done something a little different: We now have one bare metal TimescaleDB server set up to handle </span><i><span>just</span></i><span> DNS requests. Our 2 Digital Ocean servers are currently still going strong, handling unique queries from our app and a portion of daily requests.</span></p><p><span>This change was prompted to accommodate an integration partner, but the cool thing is that we’ve actually doubled my original projection with this move. That bare metal server now processes about 6B requests per day. Granted, it does not handle the full load the Digital Ocean servers do. It handles DevOps monitoring of our infrastructure, handling far fewer read queries than our primary Digital Ocean server. Though it still processes a large number of requests daily with only 5% CPU utilization.</span></p><p><span>Meanwhile, the main Digital Ocean server rarely goes over 30% CPU utilization. Though as I’ll get into later, CPU isn’t the best metric for monitoring the health of these servers.</span></p><h2><span>The beginning of a major move to bare metal</span></h2></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="308de7c" data-element_type="section"><div><div><div data-id="746c630" data-element_type="column"><div><div><div data-id="ae9e5a0" data-element_type="widget" data-widget_type="image.default"><div><div><figure> <img width="1024" height="576" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png" alt="TimescaleDB performance on bare metal" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-300x169.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-768x432.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1536x864.png 1536w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-2048x1152.png 2048w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-500x281.png 500w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-300x169.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-768x432.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1536x864.png 1536w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-2048x1152.png 2048w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-500x281.png 500w"><figcaption>This is our bare metal server. Our hosting provider is always nice enough to send a picture my way when I ask. They even gave me one as a magnet.</figcaption></figure></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="43cd417" data-element_type="section"><div><div><div data-id="17169e9" data-element_type="column"><div><div><div data-id="c2094d2" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>In the past, we were renting servers. But we didn’t see that being sustainable for our business long-term.</span></p><p><span>We saw 3 possible options, and we ran costs on all of them:</span></p><ul><li><span>Colocation</span></li><li><span>Continued server rental</span></li><li><span>A major move to AWS</span></li></ul><p>Colocation was the clear winner.</p><p><span>While you need to put money down upfront, the costs begin to go down month over month. After 3 years, our server costs will be half of what they would be if we continued renting—and nearly 1/17 of what a switch to AWS would be.&nbsp;</span></p><p><span>While the monetary benefits are pretty obvious, the actual drive performance of the colocated server would be 10 times better than the AWS servers. On top of that, our setup included 648TB/month, which would have cost us $37,000 </span><i><span>alone</span></i><span> with AWS.</span></p><p><span>That bare metal server handling 6B requests daily is a </span><a href="https://netactuate.com/colocation/" target="_blank" rel="noopener"><span>colocated server</span></a><span> we built with the help of our hosting provider, </span><a href="https://netactuate.com/" target="_blank" rel="noopener"><span>NetActuate</span></a><span>.</span></p><p><span>With the performance we’re currently seeing on our bare metal server (and the cost savings), we plan on migrating </span><i><span>everything</span></i><span> from Digital Ocean to bare metal. I just don’t see anything but colocation being able to meet our needs into the future.</span></p><p><span>Using colocated servers allows us to have the fastest, newest machines at a lower cost. I told NetActuate the specs I was looking for in a server, and then their team built everything, shipped it to the data center, and racked it for us.</span></p><p><span>It’s a happy medium. I don’t want DNSFilter to be in the business of running its own datacenter. Going this route still allows me to be hands-on while not having to worry about the actual hardware day-to-day.</span></p><p><span>The main challenge for me now is hiring DevOps staff to handle ongoing infrastructure and performance management that I’ve been doing the majority of.</span></p><h2><span>Monitoring&nbsp;</span></h2><p><span>Before putting any hardware into production, first I use </span><a href="https://serverscope.io/" target="_blank" rel="noopener"><span>ServerScope</span></a><span> to understand how performant that hardware can possibly be. It also lets me know if there is anything that might indicate a defect in the hardware. That’s something that might cause limitations to the hardware’s life expectancy.</span></p><p><span>To monitor all of our servers, across both our Timescale database and our anycast network, we use </span><a href="https://www.site24x7.com/" target="_blank" rel="noopener"><span>Site24x7</span></a><span>. Here, I’m able to check on KPIs, with the most important one in my day-to-day being Disk I/O.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="1198909" data-element_type="section"><div><div><div data-id="f411b25" data-element_type="column"><div><div><div data-id="972d48e" data-element_type="widget" data-widget_type="image.default"><div><p><img width="842" height="429" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png" alt="Last 3 months TimescaleDB performance" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png 842w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-300x153.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-768x391.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-840x429.png 840w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-500x255.png 500w" data-sizes="(max-width: 842px) 100vw, 842px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png 842w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-300x153.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-768x391.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-840x429.png 840w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-500x255.png 500w"></p></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="4bca6c0" data-element_type="section"><div><div><div data-id="52574cc" data-element_type="column"><div><div><div data-id="2d4a946" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>The image above represents the Disk I/O of our main production server over Q3 2020. You can see it held steadily around 60 MB/sec for disk writes until the end of September. That’s around the time we had a huge uptick in daily queries, causing additional strain on the server. After seeing this, we decided to add our bare metal server to start handling a large portion of DNS queries. This took some of the load off of our primary server that is still handling user interface queries (in addition to a portion of DNS requests).</span></p><p><span>However, IOPS (Input/Output Operations Per Second) is arguably the best metric to look at since databases do short bursts of access. This is in contrast to a sustained (and uninterrupted) transfer, similar to the way a file server might write information. When using ServerScope, IOPS is the most significant metric I check prior to putting a server in production. It’s valuable to know what IOPS that server is capable of handling. To get an idea of the capacity we’re looking for, </span><a href="https://www.wiredzone.com/shop/product/10028190-intel-ssdpe2ke064t8-hard-drive-nvme-6-4tb-u-2-2-5in-pcie-3-1-3d-tlc-3dwpd-dc-p4610-series-2294" target="_blank" rel="noopener"><span>one recent storage drive</span></a><span> we put into production has a random read of 654k IOPS and random write of 210k IOPS.</span></p><p><span>CPU utilization is useful to know, but really you just want to make sure that your server isn’t hitting over 80% for days or weeks at a time. That’s a sign it’s working too hard and it needs some help.&nbsp;</span></p><p><span>Another aspect we monitor is Kafka lag. What we saw in October 2019 (and later in March 2020) was TimescaleDB suddenly falling behind. In fact, it was </span><i><span>hours</span></i><span> behind. Once we saw the lag, we could investigate Disk I/O to see what the root cause of the problem was. The issue here was (again) that huge amount of new queries. TimescaleDB was suddenly writing an amount of data from Kafka it was not accustomed to writing and could not keep up. Without the ability to discover what caused the lag and subsequently working to fix it, we would have continued to get further and further behind.</span></p><h2><span>No clusters, no problem…yet</span></h2><p><span>We are still running on open source TimescaleDB after 2 years. It’s been able to handle all of the additional queries we’re now getting with our increase in users after the hardware changes I’ve talked about above. And on top of that, we haven’t used clustering </span><i><span>at all</span></i><span>.</span></p><p><span>With the announcement of </span><a href="https://blog.timescale.com/blog/timescaledb-2-0-a-multi-node-petabyte-scale-completely-free-relational-database-for-time-series/" target="_blank" rel="noopener"><span>TimescaleDB 2.0</span></a><span> and the option to use clustering for multi-node deployments in the open source version, we can continue to use open source TimescaleDB without an issue.</span></p><p><span>We’re still running a single node instance, but we do plan on implementing clusters at some point. We’ve tested clustering in the past, but there were bugs, so we never committed fully. We also haven’t used partitioning. If we try clustering again and we still run into issues or if it doesn’t allow us to scale the way we want to, partitioning is the next thing on the list for us to test.</span></p><p><span>One recent optimization we’ve made is to have chunks fit in RAM. This is a recommendation I discovered recently in </span><a href="https://docs.timescale.com/latest/api#create_hypertable-best-practices" target="_blank" rel="noopener"><span>TimescaleDB’s documentation around best practices</span></a><span>.&nbsp;</span></p><p><span>For a long time, we had our chunk interval set as a single day (24 hours). When we weren’t even breaking 200M queries a few years ago, that was fine. But we’ve grown so much, so each of our TimescaleDB servers has a separate chunk interval time. Our primary server is now set at 4 hours, and our dedicated query server (the one handling 6B queries daily) is set to </span><b>20 minutes</b><span>. This is a recent change, so it will take some time to get a clear idea of how much this change has benefited our infrastructure.</span></p><p><span>After 2 years of scaling TimescaleDB, I can make more accurate estimates and plan better. Now I know what type of stress 1B queries will put on our current servers and what changes need to be made to accommodate those new queries. We’ve also carefully mapped out our costs for the next 3 years, which will only benefit us when we run into the inevitable hiccup.&nbsp;</span></p><p><span>There is a lot more we plan on testing with TimescaleDB going forward, but we have a good idea of what the future of our server infrastructure will look like.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="fa18430" data-element_type="section"></section></div></div></div></div></div>]]>
            </description>
            <link>https://www.dnsfilter.com/blog/timescaledb-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150265</guid>
            <pubDate>Thu, 19 Nov 2020 15:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Curious Moon]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25149803">thread link</a>) | @Tomte
<br/>
November 19, 2020 | https://bigmachine.io/products/a-curious-moon/ | <a href="https://web.archive.org/web/*/https://bigmachine.io/products/a-curious-moon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tcb_landing_page">
<div>
<div id="tve_flt"><div id="tve_editor" data-post-id="161773"><div data-inherit-lp-settings="1" data-css="tve-u-16cdc668863">

<div data-css="tve-u-16cdc61feee"><div data-aspect-ratio="16:9" data-float-visibility="mobile" data-overlay="0" data-type="vimeo" data-float="false" data-aspect-ratio-default="0" data-url="https://vimeo.com/247734637" data-float-width-m="300px" data-float-padding1-m="25px" data-float-padding2-m="25px" data-float-position="top-left" data-float-width-d="300px" data-float-padding1-d="25px" data-float-padding2-d="25px" data-css="tve-u-171ae0f3dad">
<div>
<div><iframe data-code="247734637" data-provider="vimeo" src="https://player.vimeo.com/video/247734637?portrait=1&amp;title=1&amp;color=fff&amp;byline=1&amp;autopause=0" data-src="https://player.vimeo.com/video/247734637?portrait=1&amp;title=1&amp;color=fff&amp;byline=1&amp;autopause=0" frameborder="0" allowfullscreen=""></iframe></div>
</div>
</div><div data-css="tve-u-1685be6002c">

<div><div data-css="tve-u-1685bea876e"><div data-css="tve-u-1685bea84b7"><div data-css="tve-u-1685beca9a6"><div data-css="tve-u-16cdd2b7da4"><p data-css="tve-u-1719fb93a47">Dive into &nbsp;<strong>raw data from the Cassini mission</strong> - straight from JPL, in the search for possible alien life. Oh yeah - <strong>and learn about PostgreSQL.</strong></p></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-16cd8a48aaa">

<div data-css="tve-u-16cd8a48ab5"><div data-css="tve-u-170e2ff2527">

<div><p data-tag="h2" data-css="tve-u-168603256ce"><h2 data-css="tve-u-16cdc6d1c80">You've found yourself in charge of a PostgreSQL database... <em>what now</em>?</h2></p><p data-css="tve-u-171a4c58cd8"><strong>Data is a powerful drug</strong> - it's the life blood of your business. How do you ensure that it's <strong>correct and tells the right story</strong>? PostgreSQL can help, but there's a lot more to this game.</p><div data-css="tve-u-1685c0e6c3b"><div data-css="tve-u-1685c0e6834"><div data-css="tve-u-16cdd398a82"><div data-css="tve-u-1685c14ddde"><div data-css="tve-u-16cdd2d3630"><p>Starting an application is simple enough, whether you use migrations, a model-synchronizer or good old-fashioned hand-rolled SQL. A year from now, however, when your app has grown and you're trying to measure what's happened... the story can quickly change when <strong>data is overwhelming you </strong>and you need to <strong>make sense</strong> of what's been accumulating.&nbsp;</p><p>Learning how PostgreSQL works is&nbsp;<em>just one aspect</em> of working with data. PostgreSQL is there to enable, enhance and extend what you do as a developer/DBA. And just like any tool in your toolbox, <strong>it can help you create crap, slice off some fingers, or help you be the superstar that you are</strong>.</p><p>That's the perspective of&nbsp;<em>A Curious Moon</em> - data is the truth, data is your friend, data is your business. The tools you use (namely PostgreSQL) are simply there to safeguard your treasure and help you understand what it's telling you.</p></div></div></div><div data-css="tve-u-16cdd398b63"><div data-css="tve-u-1685c1512d6"><div data-css="tve-u-1685c127b2d"><p>But <strong>what does it mean to be "data-minded"? </strong>How do you even get started? These are good questions and ones I struggled with when outlining this book. I quickly realized that the only way you could truly understand the power and necessity of solid databsae design was to <strong>live the life of a new DBA... thrown into the fire</strong> like we all were at some point...</p><p>Meet Dee Yan, our fictional intern at Red:4 Aerospace. She's just been handed the keys to <strong>a massive set of data, straight from Saturn</strong>, and she has to load it up, evaluate it and then analyze it for a critical project. She knows that PostgreSQL exists... but that's about it.</p><p>Much more than a tutorial, this book has a narrative element to it a bit like&nbsp;<em>The Martian</em>, where you get to know Dee and the problems she faces as a new developer/DBA... and how she solves them.</p><p>The truth is in the data...</p></div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-168604cedc5" data-inherit-lp-settings="1">

<div data-css="tve-u-1685c8a1093"><p data-tag="h2" data-css="tve-u-1685c0e8154"><h2 data-css="tve-u-1685c8db5fd"><em>A Curious Moon</em>: Exploring Cassini's Data with PostgreSQL</h2></p><div data-css="tve-u-1685c40e6db">

<div data-css="tve-u-1685c3f3ad3"><div><div><div><div><p><span><img alt="" data-id="357" width="330" data-init-width="550" height="530" data-init-height="883" title="cover_v3" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg" data-css="tve-u-171a8e23a1a" data-width="330" data-height="530" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg?w=550&amp;ssl=1 550w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg?resize=187%2C300&amp;ssl=1 187w" sizes="(max-width: 330px) 100vw, 330px"></span></p></div></div><div><div><div data-css="tve-u-171a9ed79f5"><p data-css="tve-u-171a8e37403">Follow along with Dee Yan, our fictional data science intern, as she assumes the job of interim database administrator at the fictional aerospace startup, Red:4. She’ll&nbsp;<strong>learn PostgreSQL</strong>&nbsp;like we all do:&nbsp;<em>on the job and under pressure</em>.</p><p>You’ll start out with the basics: creating tables and importing data. Soon, however, you’ll be awash in glorious SQL and data from space (<strong>the NASA/JPL archives of the Cassini mission</strong>), creating functions, common table expressions and calculating aggregates using window functions all in the name of science while trying to&nbsp;<strong>figure out if there’s life under the ice of a very curious little moon.</strong></p></div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-16cd8a366f5" data-inherit-lp-settings="1">

<div data-css="tve-u-16cd8a36703"><div data-css="tve-u-171a8e493b9" tcb-template-name="Quote 15" tcb-template-id="41894" tcb-template-pack="137" data-keep-css_id="1"><div data-css="tve-u-171a8e493ba">

<div data-css="tve-u-171a8e493bc"><div data-css="tve-u-171a8e493bd"><div data-css="tve-u-171a8e493be"><div data-css="tve-u-171a8e493bf"><div data-css="tve-u-171a8e493c0"><p><span><img alt="" width="208" height="202" title="loren_stewart_200x" data-id="362" src="https://bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png" data-init-width="200" data-init-height="194" loading="lazy" data-css="tve-u-171a8e587bf" data-width="208" data-height="202" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png?w=200&amp;ssl=1 200w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png?resize=180%2C175&amp;ssl=1 180w" sizes="(max-width: 208px) 100vw, 208px"></span></p><p>&nbsp;<strong>Loren Steward</strong></p></div></div><div data-css="tve-u-171a8e493c3"><div data-css="tve-u-171a8e493c4"><p><span><img loading="lazy" alt="" width="217" height="170" title="Quotation_marks_image_03" data-id="41605" src="https://bigmachine.io/wp-content/uploads/tcb_content_templates/contentblock/images/Quotation_marks_image_03.png" data-css="tve-u-171a8e62de6" data-width="217" data-height="170" data-init-width="175" data-init-height="137"></span></p><p data-css="tve-u-171a8e67921"><em><strong>A Treasure Trove</strong></em></p><p data-css="tve-u-171a8e55e4f">"I’ve found the book to be a treasure trove of Postgres features. CTEs are blowing my mind right now. I’m a backend engineer, and I’ve been sharing what I’ve learned with my coworker who is a DBA. She is picking &nbsp;up some tips through me now! I haven’t found a good, engaging tutorial for these intermediate/advanced Postgres tricks, and "A Curious Moon" fills this gap. As a bonus, I’m also picking up some bash tips from the book."</p></div></div></div></div></div>
</div></div></div>
</div><div data-css="tve-u-168602fef0f" data-inherit-lp-settings="1">

<div data-css="tve-u-1686030115d"><p data-tag="h3" data-css="tve-u-168603280cf"><h3 data-css="tve-u-1686030ea3f">You'll dig in to some of the most amazing data of our lifetime...</h3></p><p data-css="tve-u-16860558abc">I won't waste your time with sleep-inducing demos and examples - we're going to <strong>hit the ground running</strong> by <strong>importing millions of records</strong> into PostgreSQL right from the command line and then we're going to interrogate it for correctness. From there we <strong>put our detective hats on</strong> and get to work.</p><div data-css="tve-u-171a8f8117e" tcb-template-name="Resource List 06" tcb-template-id="41686" tcb-template-pack="137" data-keep-css_id="1"><div data-css="tve-u-171a8f8117f">

<div data-css="tve-u-171a8f81180"><div data-css="tve-u-171a8fba418" tcb-template-name="Team 10" tcb-template-id="41907" data-keep-css_id="1"><div data-css="tve-u-171a8fba419">

<div data-css="tve-u-171a8fba41a"><div data-css="tve-u-171a8fba41c">

<div data-css="tve-u-171a8fba41d"><div data-css="tve-u-171a8fba41e"><div data-css="tve-u-171a8fba41f"><div><div data-css="tve-u-171a8fba420"><div data-css="tve-u-171a8fba421">

<div data-css="tve-u-171a8fba423"><div data-css="tve-u-171a9010f1a">

<div><p><span><img alt="" data-id="161826" width="800" data-init-width="800" height="575" data-init-height="575" title="14 copy" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/14-copy.png" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?w=800&amp;ssl=1 800w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=300%2C216&amp;ssl=1 300w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=768%2C552&amp;ssl=1 768w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=247%2C178&amp;ssl=1 247w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=510%2C367&amp;ssl=1 510w" sizes="(max-width: 800px) 100vw, 800px"></span></p><p data-css="tve-u-171a900da73"><h3 data-css="tve-u-171a8fd31ac">Working with the PostgreSQL CLI</h3></p><p data-css="tve-u-16d9dc501ff"><strong>We don't have time for fluffy tooling!</strong> Yes there are GUIs and visual tools out there, but SQL with PostgreSQL is simple and easy to use when describing the precise table and index set that you want.</p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-171a8fba432"><div data-css="tve-u-171a9ee5b8c">

<div><p><span><img alt="" data-id="161840" width="309" data-init-width="800" height="222" data-init-height="575" title="00-csvs" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/00-csvs.png" mt-d="-1" data-css="tve-u-171a905f8cb" data-width="309" data-height="222" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?w=800&amp;ssl=1 800w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=768%2C552&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=247%2C178&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=510%2C367&amp;ssl=1 510w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9018c8d"><h3 data-css="tve-u-171a9018c8e">importing data from massive csv files</h3></p><p data-css="tve-u-171a906570f"><strong>You'll import data like a pro, using the command line and a Makefile.</strong> There are GUIs you could use, but here at Red:4 we believe in keeping things simple and powerful..</p></div>
</div></div></div><div><div><div data-css="tve-u-171a9ee473f">

<div><p><span><img alt="" data-id="161842" width="309" data-init-width="889" height="222" data-init-height="575" title="leapyear" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/leapyear.png" mt-d="-1" data-css="tve-u-171a9078bd8" data-width="309" data-height="222" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/leapyear.png?zoom=2&amp;resize=309%2C222&amp;ssl=1 618w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/leapyear.png?zoom=3&amp;resize=309%2C222&amp;ssl=1 927w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9078bd9"><h3 data-css="tve-u-171a9078bda">WEEDING OUT THE INEVITABLE CRAP DATA</h3></p><p data-css="tve-u-171a9081ff7"><strong>You will become "data minded".</strong>You'll go through a basic audit process from real, raw data from JPL. It doesn't matter where the data is from, it will&nbsp;<em>always have errors</em>.</p></div>
</div></div></div></div></div></div>
</div></div>
</div></div></div>
</div><div data-css="tve-u-171a8f8117f">

<div data-css="tve-u-171a8f81180"><div data-css="tve-u-171a90bbfa7" tcb-template-name="Team 10" tcb-template-id="41907" data-keep-css_id="1"><div data-css="tve-u-171a8fba419">

<div data-css="tve-u-171a8fba41a"><div data-css="tve-u-171a8fba41c">

<div data-css="tve-u-171a8fba41d"><div data-css="tve-u-171a8fba41e"><div data-css="tve-u-171a8fba41f"><div><div data-css="tve-u-171a8fba420"><div data-css="tve-u-171a8fba421">

<div data-css="tve-u-171a8fba423"><div data-css="tve-u-171a9010f1a">

<div><p><span><img alt="" data-id="161844" width="1368" data-init-width="1368" height="916" data-init-height="916" title="shot_186" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?w=1368&amp;ssl=1 1368w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=300%2C201&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=1024%2C686&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=768%2C514&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=247%2C165&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=510%2C341&amp;ssl=1 510w" sizes="(max-width: 1368px) 100vw, 1368px"></span></p><p data-css="tve-u-171a900da73"><h3 data-css="tve-u-171a8fd31ac">TRIAGING AND SIZING UP WHAT THE DATA MEANS</h3></p><p data-css="tve-u-171a90c3a39"><span data-css="tve-u-1634af88282"><strong>You'll sleuth through raw Cassini data using basic queries</strong>. Pulling data in is only part of the process – looking for clues and understanding what you're seeing is the next step. To do this you'll use <strong>Common Table Expressions</strong>, <strong>Full Text Search</strong> indexing and <strong>Windowing Functions</strong>.</span></p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-171a8fba432"><div data-css="tve-u-171a9018c8b">

<div><p><span><img alt="" data-id="161845" width="370" data-init-width="544" height="212" data-init-height="312" title="shot_187" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg" mt-d="0" data-css="tve-u-171a915ce14" data-width="370" data-height="212" ml-d="-4" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?w=544&amp;ssl=1 544w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=300%2C172&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=247%2C142&amp;ssl=1 247w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=510%2C293&amp;ssl=1 510w" sizes="(max-width: 370px) 100vw, 370px"></span></p><p data-css="tve-u-171a911509f"><h3 data-css="tve-u-171a9018c8e">OPTIMIZING QUERIES</h3></p><p data-css="tve-u-171a906570f"><strong>You'll speed up slow queries with built-in analysis tools</strong> and objects. The Cassini data dump is gigantic, and sifting through the analysis records can be time consuming! You'll use EXPLAIN and ANALYZE to figure out where to put your indexes and when it makes sense to build a materialized view, which is data cached on disk.</p></div>
</div></div></div><div><div><div data-css="tve-u-171a9078bd5">

<div><p><span><img alt="" data-id="161858" width="309" data-init-width="1058" height="233" data-init-height="798" title="shot_188" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg" mt-d="-4" data-css="tve-u-171a9154582" data-width="309" data-height="233" ml-d="0" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?w=1058&amp;ssl=1 1058w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=1024%2C772&amp;ssl=1 1024w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=768%2C579&amp;ssl=1 768w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=247%2C186&amp;ssl=1 247w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=510%2C385&amp;ssl=1 510w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9078bd9"><h3 data-css="tve-u-171a9078bda">verifying what we have using sql</h3></p><p data-css="tve-u-171a9081ff7">NASA is a very thorough organization, but it's staffed by humans and humans like spreadsheets and <strong>spreadsheets destroy data</strong>. You'll use mathematical analysis to verify <strong>flyby altitudes and speeds</strong> using data from the INMS during the 22 close encounters with Enceladus.</p></div>
</div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-171a91d3d1c" tcb-template-name="Call to Action 06" tcb-template-id="41514" data-keep-css_id="1"><div data-css="tve-u-171a91d3d1d">

<div><div data-css="tve-u-171a91d3d1e">

<div data-css="tve-u-171a91d3d20"><div data-css="tve-u-171a91d3d21"><div data-css="tve-u-171a91d3d22"><div data-css="tve-u-171a91d3d23"><div><p><span><img alt="" width="232" height="180" title="Image10017" data-id="161853" src="https://bigmachine.io/wp-content/uploads/2020/04/Image10017.png" data-init-width="946" data-init-height="733" loading="lazy" data-css="tve-u-171a91e5bbd" data-width="232" data-height="180" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?w=946&amp;ssl=1 946w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=300%2C232&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=768%2C595&amp;ssl=1 768w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=247%2C191&amp;ssl=1 247w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=510%2C395&amp;ssl=1 510w" sizes="(max-width: 232px) 100vw, 232px"></span></p></div></div><div data-css="tve-u-171a91d3d25"><div data-css="tve-u-171a91d3d26"><p data-css="tve-u-171a91d3d27"><h3 data-css="tve-u-171a9206468">You'll run queries looking for the presence of life under this amazing moon.</h3></p><div data-css="tve-u-171a91d3d29"><p data-css="tve-u-171a91e4ce5"><span data-css="tve-u-1634af8827d"><strong>You'll finally perform the ultimate analysis on very real scientific data:&nbsp;<em>Is There Life Under the Ice of Enceladus?</em>&nbsp;&nbsp;</strong></span></p><p data-css="tve-u-171a91e4ce5"><span data-css="tve-u-1634af8827d"><strong></strong>You will have all the data you need to support this claim: thermal, chemical and mineralogical results from two of the most sensitive instruments humans have ever created. You'll run the query and see the results for yourself!</span></p></div></div></div></div></div></div>
</div></div>
</div></div></div></div>
</div></div></div>
</div><div data-css="tve-u-168604d64ed">

<div data-css="tve-u-168604e56fa"><p data-tag="h3" data-css="tve-u-1687a2f0c50"><h3>Working with data can be the most fun you've ever had at work.</h3></p><p>It's a discovery that most DBAs don't want "app devs" to know:&nbsp;<strong><em>working with data is intoxicating</em></strong>. Learning the skills you need to effectively work with data can be one of the <span data-css="tve-u-171a925f9eb">best investements in your career</span>... just ask these people...</p><div data-css="tve-u-1602b1ebd26" data-ct-name="Resume Clients" data-ct="testimonial-7342" data-element-name="Testimonial">

<div data-css="tve-u-16cdcc0fe5a"><div data-css="tve-u-16860547721"><div data-css="tve-u-16870ae36ee"><div><div data-css="tve-u-168605c3908"><div data-css="tve-u-1688010799d">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="400" height="400" title="tompkins" data-id="389" src="https://bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg" data-init-width="400" data-init-height="400" loading="lazy" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?w=400&amp;ssl=1 400w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=280%2C280&amp;ssl=1 280w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=300%2C300&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=100%2C100&amp;ssl=1 100w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 400px) 100vw, 400px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-168800e7098">

<div data-css="tve-u-16afd6a6c48"><p data-css="tve-u-168605f9847"><strong><strong><strong>Compulsively readable. Recommended.</strong></strong></strong></p><p data-css="tve-u-1686119f5bd">"Reading through&nbsp;<em>A Curious Moon</em>... It's like reading&nbsp;<em>The Martian</em>, only instead of trying to survive in the hostile environment of another planet, it's about trying to survive in the hostile environment of snarky DBAs. Compulsively readable. Recommended."</p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-1687b353150"><div data-css="tve-u-1687091a411">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="400" height="400" title="meggan" data-id="386" src="https://bigmachine.io/wp-content/uploads/2018/05/meggan.jpg" data-init-width="400" data-init-height="400" loading="lazy" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?w=400&amp;ssl=1 400w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=280%2C280&amp;ssl=1 280w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 400px) 100vw, 400px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-168800e8e1f">

<div data-css="tve-u-16afd6a80ba"><p data-css="tve-u-168605f9847"><strong><strong>I am&nbsp;<em>loving</em>&nbsp;the book!</strong></strong></p><p data-css="tve-u-17493010a6a">I am loving the book! The narrative format is like no other programming book I've ever read, and it's really keeping me engaged and interested. I've struggled in the past to keep pushing through programming books that are dry &amp; stock standard, but the characters in A Curious Moon make the book relatable and it makes me want to learn.</p></div>
</div></div>
</div></div></div><div data-css="tve-u-1749300e95c"><div data-css="tve-u-168605c5931"><div data-css="tve-u-1687b4daac8">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="210" height="210" title="george" data-id="402" src="https://bigmachine.io/wp-content/uploads/2018/05/george.jpg" data-init-width="210" data-init-height="210" loading="lazy" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?w=210&amp;ssl=1 210w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=180%2C180&amp;ssl=1 180w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=100%2C100&amp;ssl=1 100w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 210px) 100vw, 210px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-1688037c1e9">

<div data-css="tve-u-16afd6a933b"><p data-css="tve-u-168605f9847"><strong>One of the best technical books I've ever read.</strong></p><p data-css="tve-u-1686119f5bd">"I really am enjoying this book! It is one of the best technical books I've ever read, and I read more than 40 books per year (technical and non-technical). What I like most about this book is that you mixed a sci-fi story with technical writing. It is like a novel for geeks!"<em></em></p></div>
</div></div>
</div></div></div></div></div></div>
</div></div>
</div><div>

<div data-css="tve-u-171a9df25e6"><div data-css="tve-u-171a9f9c219">

<div><p data-tag="h3" data-css="tve-u-16860dbc5e4"><h3 data-css="tve-u-171a9be5c3f">Wait are you serious? Enceladus? Possible life under its icy shell?</h3></p><p data-css="tve-u-168709e7e48">Yes, absolutely. Back in 2005 Cassini did a routine flyby of Enceladus, a moon that's about the size of Great Britain (313 mi in diameter). It's the most reflective body in the solar system, covered with smooth ice... except for its south pole...</p><div><div data-css="tve-u-171aa0692ac"><div><div><p><span><img alt="" data-id="161850" width="677" data-init-width="1000" height="694" data-init-height="1025" title="Image8807" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg" data-css="tve-u-171a9c34e97" data-width="677" data-height="694" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?w=1000&amp;ssl=1 1000w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=293%2C300&amp;ssl=1 293w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=768%2C787&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=247%2C253&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=510%2C523&amp;ssl=1 510w" sizes="(max-width: 677px) 100vw, 677px"></span></p></div></div><div><div><p data-css="tve-u-171a9ca6462">A Great Cosmic Mystery</p><div data-css="tve-u-171a9ca8f87"><p data-css="tve-u-171a9c7c9dd">Turns out this little moon gets squeezed between Jupiter and Titan and the <strong>gravitational pull grinds out some heat</strong> within its core. Heat that produces <strong>temperatures up <em>90 C</em></strong> in some spots, which look suspiciously like the deep water plumes we see here on Earth.</p><p data-css="tve-u-171a9c3f5d6">Oh, but it gets weirder...</p></div></div></div></div></div><p data-css="tve-u-171a9cb2eb5">The Bioreactor</p><div><div><div><div><div data-css="tve-u-171a9c3dd3f"><p data-css="tve-u-171a9c3f5d6">That heated water produces plumes at the moon's south pole which jet material into space. We didn't know what was in that material until 2007, when <strong>Cassini flew right through them</strong> at ridiculously high speeds and low elevation.</p><p data-css="tve-u-171a9c3f5d6">The onboard mass spectrometers scooped it up and... wouldn't ya know... it's <strong>sea water</strong>. <strong>There's a salty ocean under the ice</strong>&nbsp; and it containes <strong>methane</strong> and <strong>hydrocarbons</strong> that mirror the deep sea "chimneys" that we have here on Earth. This has led scientists to speculate that Enceladus is a <em>bioreactor</em>, capable of producing life in extraordinary circumstances.&nbsp;</p></div></div></div><div><div><p><span><img alt="" data-id="161849" width="677" data-init-width="627" height="694" data-init-height="531" title="Image8791" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg" data-css="tve-u-171a9c34e97" data-width="677" data-height="694" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg?zoom=2&amp;resize=677%2C694&amp;ssl=1 1354w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg?zoom=3&amp;resize=677%2C694&amp;ssl=1 2031w" sizes="(max-width: 677px) 100vw, 677px"></span></p></div></div></div></div><p><span><img alt="" data-id="161852" width="1317" data-init-width="1317" height="548" data-init-height="548" title="09" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/09.jpg" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?w=1317&amp;ssl=1 1317w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=300%2C125&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=1024%2C426&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=768%2C320&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=247%2C103&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=510%2C212&amp;ssl=1 510w" sizes="(max-width: 1317px) 100vw, 1317px"></span></p><div data-css="tve-u-171a9e37e81"><p>This little moon is quite small, about <strong>the size of Texas</strong>, yet it jets water out continuously into space. Some of it rains back down as fine ice particles, covering the surface and making it the most reflective body in the solar system. Some of it gets sucked back into Saturn itself, making Enceladus the only moon we know of that contributes matter back to its host planet.</p><p>And <strong>some of it goes into orbit, creating the "E ring" </strong>of Saturn which you see above. That ghostly blue glow, the second largest planetary ring in the solar system, was created entirely from the icy jets of Enceladus... which is <strong>way too small to contribute that much material</strong>.</p></div></div>
</div></div>
</div><div data-css="tve-u-171a9fdfad8">

<div data-css="tve-u-171a9d26e2f"><p data-css="tve-u-171a9d37687">What the hell is going on up there?</p><div data-css="tve-u-171a9f0fd95"><p>I don't know...&nbsp;<strong><em>you tell me</em>.</strong> We can speculate all day about aliens, sunken UFOs and Thor's hidden palace but you know what would be even better? Letting the data tell us what's going on.</p><p>That's what we do as data people: <strong>let the data tell us the story</strong>. It's all in there, and with Cassini's mission data we have <strong>a gigantic amount that we get to sift through for answers</strong>.</p><p>That&nbsp;<em>you get to sift through</em>. <strong>Buckle up</strong>! PostgreSQL is fun and all, but it's the data behind this story that's the fun part. When you're done with this story, you'll be able to run (and understand) one hell of an amazing database query. These results were dubbed a "<strong>smoking gun for life</strong> in the waters of Enceladus" by <em>NASA itself</em>.</p></div><p><span><img alt="" data-id="161876" width="1200" data-init-width="1200" height="718" data-init-height="718" title="Image12632 copy" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?w=1200&amp;ssl=1 1200w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=300%2C180&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=1024%2C613&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=768%2C460&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=247%2C148&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=510%2C305&amp;ssl=1 510w" sizes="(max-width: 1200px) 100vw, 1200px"></span></p><div data-css="tve-u-171a9e9683d" tcb-template-name="Call to Action 12" tcb-template-id="41889" data-keep-css_id="1"><div data-css="tve-u-171a9e9683e">

<div><div data-css="tve-u-171a9e96840"><div data-css="tve-u-171a9e96841"><div data-css="tve-u-171a9e96842"><div data-css="tve-u-171a9e96843"><p><span><img alt="" data-id="368" width="316" data-init-width="750" height="189" data-init-height="448" title="curious_slide" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg" data-width="316" data-height="189" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?w=750&amp;ssl=1 750w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=280%2C167&amp;ssl=1 280w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=550%2C329&amp;ssl=1 550w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=300%2C179&amp;ssl=1 300w" sizes="(max-width: 316px) 100vw, 316px"></span></p></div></div><div data-css="tve-u-171a9e96845"><div data-css="tve-u-171a9e96846"><p data-css="tve-u-171a9e96847"><h3 data-css="tve-u-171a9f14274">The most fun you'll have learning something new.</h3></p><p>Spend the weekend with Dee and the gang at Red:4, digging in to the planetary mystery of Enceladus.</p></div></div></div></div></div>
</div></div></div>
</div><div data-inherit-lp-settings="1" data-css="tve-u-16cdd4acc71">

<div data-css="tve-u-16cdd4acc80"><p data-tag="h2" data-css="tve-u-16899a6ae75"><h2>Frequently Asked Questions
</h2></p><div data-css="tve-u-16898db49ac"><div data-css="tve-u-16898db468a"><div><div data-css="tve-u-16899be2e7e"><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899be7319" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd402a"><strong>Is this a print or digital book?</strong>
</h4>
</div>

</div>
</div>
</div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899be4c12" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd673c"><strong>Do I get any and all updates?&nbsp;</strong>
</h4>
</div>

</div>
</div>
</div></div></div><div><div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899bf19eb" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd4f6a"><strong>Is this for real? You must have made some of this up?</strong></h4>
</div>

</div>
</div>
</div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899bef9ab" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd7ef4">How can I get …</h4></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bigmachine.io/products/a-curious-moon/">https://bigmachine.io/products/a-curious-moon/</a></em></p>]]>
            </description>
            <link>https://bigmachine.io/products/a-curious-moon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149803</guid>
            <pubDate>Thu, 19 Nov 2020 14:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Koans]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149640">thread link</a>) | @manjana
<br/>
November 19, 2020 | https://sanctum.geek.nz/arabesque/vim-koans/ | <a href="https://web.archive.org/web/*/https://sanctum.geek.nz/arabesque/vim-koans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>These koans have been independently translated into <a href="https://web-beta.archive.org/web/20160313124308/http://ranmocy.me/translation/vim-koans/">Chinese</a>,
thanks to Wanzhang Sheng, and into <a href="http://silly-bytes.blogspot.com/2016/05/vim-koans-espanol.html">Spanish</a>, thanks to Daniel Campoverde Carrión.</em></p>

<p><em>See also: <a href="https://blog.samwhited.com/2015/04/the-dharma-of-vi/">The Dharma of Vi</a>, <a href="https://sanctum.geek.nz/etc/emperor-sh-and-the-traveller.txt">Emperor Sh and the Traveller</a></em></p>

<h2>Master Wq and the Windows developer</h2>

<p>Master Wq was addressing some Vim novices. After his lecture on the many
virtues of Vim, he asked if there were any questions. A young man raised his
hand.</p>

<p>“Master, by what means might one filter for the second column of a plaintext
table for all rows that contain the string ‘tcp’?”</p>

<p>Master Wq said nothing, turned to the whiteboard behind him, and wrote:</p>

<pre><code>:%!awk '/tcp/{print $2}'
</code></pre>

<p>There was a murmur of approval from the other students.</p>

<p>“But I develop on Windows … ” the student stammered.</p>

<p>Master Wq turned again, erased the command, and wrote:</p>

<pre><code>:v/tcp/d
:v/^\s*\S\+\s\+\(\S\+\).*/d
:%s//\1/
</code></pre>

<p>“What! That is far too complex for such a simple task!” cried the student.</p>

<p>Master Wq turned again, erased the command, and wrote:</p>

<pre><code>Microsoft Excel
</code></pre>

<p>At once, the student was enlightened.</p>

<hr>

<h2>No ultimate difference</h2>

<p>One day a monk visited Master Wq, and inquired, “Master, how will my code be
different when I have mastered Vim?”</p>

<p>Master Wq answered, “Before Vim: declare, define, process, print. After Vim:
declare, define, process, print.”</p>

<hr>

<h2>Master Wq and the Markdown acolyte</h2>

<p>A Markdown acolyte came to Master Wq to demonstrate his Vim plugin.</p>

<p>“See, master,” he said, “I have nearly finished the Vim macros that translate
Markdown into HTML. My functions interweave, my parser is a paragon of
efficiency, and the results nearly flawless. I daresay I have mastered
Vimscript, and my work will validate Vim as a modern editor for the enlightened
developer! Have I done rightly?”</p>

<p>Master Wq read the acolyte’s code for several minutes without saying anything.
Then he opened a Markdown document, and typed:</p>

<pre><code>:%!markdown
</code></pre>

<p>HTML filled the buffer instantly. The acolyte began to cry.</p>

<hr>

<h2>Master Wq and the Unix master</h2>

<p>An old Unix master came to Master Wq. “I am troubled, Wq. You teach the way of
Vim. vi is holy but Vim is not; its code sprawls, its features crowd memory;
its binaries are vast, its behavior inconsistent. This is not the way of Unix.
I fear you mislead your students. What can be done?”</p>

<p>Master Wq nodded. “You are right,” he said. “Vim is broken. Let us fix it.
Shall we begin?”</p>

<p>The old Unix master agreed, and opened a shell. He typed:</p>

<pre><code>$ vi vim.c
</code></pre>

<p>He began to code. Master Wq watched for a while and then asked him, “Which
implementation of vi are you using? Nvi? Vim? Elvis?”</p>

<p>“I don’t know,” said the Unix master. “It doesn’t matter.”</p>

<p>Master Wq nodded. The Unix master sat stunned for a moment and closed his
document unsaved.</p>

<hr>

<h2>No greatest tool</h2>

<p>One night there was a storm, and Master Wq’s house collapsed. The next morning
he began to build it again using his old tools. His novice came to help him,
and they built for a while and were making good progress. As they worked, the
novice began to tell Master Wq of his latest accomplishments.</p>

<p>“Master, I have developed a wonderful Vim script to give all sorts of useful
information about a document. It counts the words, the sentences, the
paragraphs, and even tells you what kind of document it is using the syntax
highlighting rules. I use it in my pipelines all the time. It is a thing of
beauty, and I am very proud. Truly, Vim is the greatest tool!”</p>

<p>Master Wq did not reply. Thinking he had unwittingly angered his master, the
novice fell silent and continued his work.</p>

<p>The novice finished aligning two beams and had positioned a nail ready for
beating into the wood, but found the hammer was out of reach.</p>

<p>“Would you pass me the hammer, master?”</p>

<p>Master Wq handed the novice a saw.</p>

<p>At once, the novice was enlightened.</p>

<hr>

<h2>Master Pope’s dream</h2>

<p><a href="https://github.com/tpope">Master Pope</a> once dreamt he was an Emacs user. When he awoke, he exclaimed:</p>

<p>“I do not know if I am Tim Pope dreaming I am an Emacs user, or an Emacs
user dreaming I am Tim Pope!”</p>

<hr>

<h2>The superior editor</h2>

<p><a href="http://vimcasts.org/">Master Neil</a> and <a href="http://derekwyatt.org/">Master Wyatt</a> were famous for their instruction in the
ways of Vim, and travelled around the country teaching.</p>

<p>One day a student asked them, “Master Neil speaks calmly and evenly, his accent
carefully lilting over his words, as though planned down to the syllable. But
Master Wyatt is full of enthusiasm, he starts and stops, his speech is rapid
and energetic, and his soul flows into his lectures. Which is the superior way
of teaching Vim?”</p>

<p>Masters Neil and Wyatt answered in unison, “Which is the superior editor: vi or
ex?”</p>

<p>At once, several students were enlightened.</p>

<hr>

<h2>The slow student’s despair</h2>

<p>Master Wq was eating his luncheon when a student burst into his room and knelt
at his feet. Tears were in his eyes and he seemed profoundly frustrated. Master
Wq put down his bowl and asked, “What upsets you so, young man?”</p>

<p>“Master,” he said. “I give up. I will never attain mastery of Vim! I will never
learn the ways of the great patriarchs! I will never attain the brutal
simplicity, the divine emptiness of perfectly efficient Vim usage!”</p>

<p>“Why do you say this?”</p>

<p>“I am your worst student, by far. When I am struggling with writing a simple
macro, my fellow students are writing recursive macros with ease. When I am
trying to remember the regular expression for white space characters, my fellow
students are writing cyclomatic complexity tests in Vimscript. I am too slow,
and I am ashamed, and I am afraid I have failed.”</p>

<p>Master Wq stood up. “Come with me to the window,” he said.</p>

<p>The student got up and followed Master Wq to the window, and looked across the
street to Master Wq’s neighbour’s house. Through the window, the two could see
a young man in suit and tie, working on a document.</p>

<p>“What do you see?” asked Master Wq. The student watched for a while.</p>

<p>“That young man is using Microsoft Excel to generate a spreadsheet. He is
updating every single cell by hand. He doesn’t even know how to use formulas.
He makes capital letters by pressing Caps Lock, and then pressing it again when
he is done. He is so slow! I do not understand. How can he be so content?”</p>

<p>“Seeing this young man, how can you not be?” returned Master Wq.</p>

<p>The student was immediately enlightened. His name was Qa, and he later became
one of the great masters.</p>

<hr>

<h2>Mastery of Vimscript</h2>

<p>A student enquired of Master Wq, “When will I know I have mastered Vimscript?”</p>

<p>Master Wq answered, “When you never use it.”</p>

<hr>

<h2>The Vim poet</h2>

<p>A young man begged an audience with Master Wq to read him his latest work, an
ode to the glories of Vim. With tearful eyes he read out his heartfelt words,
pouring his soul into his veneration for his text editor.</p>

<p>The master sat and listened to the poet for a while. After the tenth verse, he
held up his hand. “Please, no more. Your poem is awful.”</p>

<p>The young man was very angry.</p>

<p>“Master Wq, surely you of all people can best appreciate the poem, you who know
the great beauty of the editor. How can you be so terse, so dismissive? I even
wrote this poem in Vim!”</p>

<p>“You wrote it in Vim,” said the Master. “But your meter is uneven, your rhyming
pattern inconsistent, your metaphors mixed. You have written a very bad poem
using a very good tool. You are not a poet, and Vim will not make you one; many
of my students are not programmers, and Vim will not help them either.”</p>

<p>“Vim is eternally beautiful,” protested the poet. “It is a worthy subject for
an ode.”</p>

<p>“Vim is not permanent. nvi is not permanent. vi itself is not permanent, only
vi-nature. Emacs has vi-nature, nano has vi-nature, even Notepad has vi-nature.
You narrow your sights, you grow attached, and hence you do not grasp the true
value of your poem’s subject. You must leave. Come back when you have mastered
Emacs.”</p>

<p>The poet left, deeply ashamed. He never returned.</p>

<hr>

<h2>Master Wq’s missing name</h2>

<p><em>Contributed by Rafael Beraldo.</em></p>

<p>One afternoon, Master Wq was meditating under a pine tree. He contemplated how
easily the wind moves through leaves and trunks, both moving them and having
its course altered by their presence. A student approached and nervously stood
by. Having finally mustered all the courage she could, the student said:</p>

<p>“Master Wq, I am troubled by what I have seen.”</p>

<p>The Master looked at her face, and she continued:</p>

<p>“I have mastered movement, I have understood macros, I am familiar with the
source and have not touched vimscript. I have followed your every advice,
ruminated on every teaching. Yet, there is something I cannot understand.
Nowhere in Vim have I found your name. Never has anybody thanked you in the
help pages. How can that be? The greatest of all Vim masters, unknown to all?
In a desperate last try, I ran :Wq and the terminal screamed at me:</p>

<pre><code>E492: Not an editor command: Wq.
</code></pre>

<p>My heart is drowned in doubt, and I am ashamed to admit that.”</p>

<p>Master Wq looked away. After a few moments, he said:</p>

<p>“You think you have committed a great sin. However, the breeze still follows
its path, the leaves make their usual sound and the sky is no greyer.”</p>

<p>As the great master spoke this, with a sharp pebble he wrote in the dirt:</p>

<pre><code>command! Wq wq
</code></pre>
			</div></div>]]>
            </description>
            <link>https://sanctum.geek.nz/arabesque/vim-koans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149640</guid>
            <pubDate>Thu, 19 Nov 2020 14:15:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HopsFS: 100x Times Faster Than AWS S3]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25149154">thread link</a>) | @nathaliaariza
<br/>
November 19, 2020 | https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3 | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p>TLDR; Many developers believe S3 is the "end of file system history". It is impossible to build a file/object storage system on AWS that can compete with S3 on cost. But what if you could build on top of S3 a distributed file system with a HDFS API that gives you POSIX goodness and improved performance? That’s what we have done with a cloud-native release of HopsFS that is highly available across availability zones, has the same cost as S3, but has 100X the performance of S3 for file move/rename operations, and 3.4X the read throughput of S3 (EMRFS) for the DFSIO Benchmark (peer reviewed at ACM Middleware 2020).</p></div><figure id="w-node-31b3b43a5a37-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65d314c5b6d0d5e4ae699_p4lO2294TIlBpyTyn36TMK3IC2UgJYIsOShNfA_v4ubinKblLQKOXG8rKcWnKuxoNJVGfRHWH69bEpG-twMaswNrBnv22mhMlGDVnW2SU3s1mRtQ-7BWL9kii4GleyV774hoZCE4.png" alt=""></p><figcaption><strong>HopsFS has lower latency and higher throughput than EMRFS (S3) for metadata operations (</strong><a href="https://www.logicalclocks.com/research/hopsfs-s3-extending-object-stores-with-posix-like-semantics-and-more-industry-track"><strong>Middleware ‘20</strong></a><strong>).<br></strong></figcaption></figure><h2>The Dumb Bucket</h2><p>S3 has become the de-facto platform for storage in AWS due to its scalability, high availability, and low cost. However, S3 provides weaker guarantees and lower performance compared to distributed hierarchical file systems. Despite this, many developers erroneously believe that S3 is the end of file system history - there is no alternative to S3, so just re-write your applications to account for its limitations (such as slow and inconsistent file listings, non atomic file/dir rename, closed metadata, and limited change data capture (CDC) support). Azure has built an improved file system, <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction">Azure Data Lake Storage</a> (ADLS) V2, on top of Azure Blob Storage (ABS) service. ADLS provides a HDFS API to access data stored in a ABS container, giving improved performance and POSIX-like goodness. But, until today, there has been no equivalent to ADLS for S3. Today, we are launching HopsFS as part of <a href="https://www.hopsworks.ai/">Hopsworks</a>.</p><h2>Hierarchical File Systems strike back in the Cloud</h2><p>Hierarchical distributed file systems (like HDFS, CephFS, GlusterFS) were not scalable enough or highly available across availability zones in the cloud, motivating the move to S3 as the scalable storage service of choice. In addition to the technical challenges, AWS have priced virtual machine storage and inter-availability zone network traffic so high that no third party vendor could build a storage system that offers a per-byte storage cost close in price to S3.&nbsp;</p><p>However, the move to S3 has not been without costs. Many applications need to be rewritten as the stronger POSIX-like behaviour of hierarchical file systems (atomic move/rename, consistent file listings, consistent read-after-writes) has been replaced by weakened guarantees in S3. Even simple tasks, such as finding out what files you have, cannot be easily done on S3 when you have enough files, so a <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-inventory.html">new service was introduced</a> to enable you to pay extra to get a stale listing of your files. Most analytical applications (e.g., on EMR) use <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-fs.html">EMRFS</a>, instead of S3, which is a new metadata layer for S3 that provides slightly stronger guarantees than S3 - such as consistent file listings.</p><h2>File systems are making the same Journey as Databases</h2><p>The journey from a stronger POSIX-like file system to a weaker object storage paradigm and back again has parallels in the journey that databases have made in recent years. Databases made the transition from strongly consistent single-host systems (relational databases) to highly available (HA), eventually consistent distributed systems (NoSQL systems) to handle the massive increases in data managed by databases. However, <a href="https://www.singlestore.com/blog/why-nosql-databases-wrong-tool-for-modern-application/">NoSQL is just too hard for developers</a>, and databases are returning to strongly consistent (but now scalable) NewSQL systems, with databases such as Spanner, CockroachDB, SingleSQL, and MySQL Cluster.&nbsp;</p><p>In this blog, we show that distributed hierarchical file systems are completing a similar journey, going from strongly consistent POSIX-compliant file systems to object stores (with their weaker consistency models, but high availability across data centers), and back to distributed hierarchical file systems that are HA across data centers, without any loss in performance and, crucially, without any increase in cost, as we will use S3 as block storage for our file system.</p><h2>HopsFS</h2><p>HopsFS is a distributed hierarchical file system that provides a HDFS API (POSIX-like API), but stores its data in a bucket in S3. We redesigned HopsFS to (1) be <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">highly available across availability zones in the cloud</a> and (2) to <a href="https://www.logicalclocks.com/research/hopsfs-s3-extending-object-stores-with-posix-like-semantics-and-more-industry-track">transparently use S3 to store the file’s blocks without sacrificing the file system’s semantics</a>. The original data nodes in HopsFS have now become stateless workers (part of a standard Hopsworks cluster) that include a new block caching service to leverage faster local VM storage for hot blocks. It is important to note that the cache is a global cache - not a local worker cache found in other vendor’s Spark workers - that includes secure access control to the cache. In our experiments, we show that HopsFS outperforms <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-fs.html">EMRFS</a> (S3 with metadata in DynamoDB for improved performance) for IO-bound workloads, with up to 20% higher performance and delivers up to 3.4X the aggregated read throughput of EMRFS. Moreover, we demonstrate that metadata operations on HopsFS (such as directory rename or file move) are up to two orders of magnitude faster than EMRFS. Finally, HopsFS opens up the currently closed metadata in S3, enabling correctly-ordered change notifications with HopsFS’ change data capture (CDC) API and customized extensions to metadata.&nbsp;</p><p>At Logical Clocks, we have leveraged HopsFS’ capabilities to build the industry’s first feature store for machine learning (<a href="https://docs.hopsworks.ai/">Hopsworks Feature Store</a>). The Hopsworks Feature Store is built on <a href="https://github.com/logicalclocks/hive">Hops Hive</a> and customized metadata extensions to HopsFS, ensuring strong consistency between the offline Feature Store, the online Feature Store (<a href="http://mikaelronstrom.blogspot.com/">NDB Cluster</a>), and data files in HopsFS.</p><figure id="w-node-f9d069e8e82e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65dda6508bd64742b2b40_Screenshot%202020-11-19%20at%2012.58.07.png" loading="lazy" alt=""></p></figure><h3>Some of the key advantages of HopsFS/S3 are:</h3><h4><strong>POSIX-Like Semantics with a HDFS API</strong></h4><ul role="list"><li>Consistent file listings, consistent read-after-write, atomic rename (files/directories).</li></ul><h4><strong>Open, Extensible Metadata</strong></h4><ul role="list"><li><a href="https://hopsworks.readthedocs.io/en/stable/user_guide/hopsfs/xattrs.html">XAttr API</a> to attach arbitrary metadata to files/directories.</li></ul><h4><strong>Change Data Capture API</strong></h4><ul role="list"><li>Correctly ordered stream of file system mutation events delivered with low latency to downstream clients by <a href="https://ieeexplore.ieee.org/document/8752956">ePipe</a>.</li></ul><h4><strong>Free-Text search API for File System Namespace</strong></h4><ul role="list"><li>File system namespace metadata changes can be transparently replicated to Elasticsearch for low-latency free-text search of the namespace and its extended metadata. This service is provided by Hopsworks.</li></ul><h4><strong>X.509 Certificates for Authentication, TLS for Encryption-in-Transit</strong></h4><ul role="list"><li>HopsFS uses X.509 Certificates to identify and authenticate clients, with TLS providing end-to-end encryption-in-transit.&nbsp;</li></ul><h4><strong>Faster Metadata Operations</strong></h4><ul role="list"><li>File/directory rename/move, file listings - no limit on retrieving 1000 files-at-a-time (as in S3).&nbsp;</li></ul><h4><strong>Faster Read Operations</strong></h4><ul role="list"><li>Workers in HopsFS securely cache file blocks on behalf of clients using local VM storage. NameNodes are cache-aware and redirect clients to securely read the cached block from the correct worker.</li></ul><h4><strong>Highly Available across Availability Zones (AZs)</strong></h4><ul role="list"><li>Support for high availability (HA) across AZs through AZ-aware replication protocols.<br></li></ul><h2>HopsFS/S3 Performance</h2><p>We compared the performance of EMRFS instead of S3 with HopsFS, as EMRFS provides stronger guarantees than S3 for consisting listing of files and <a href="https://www.hatch.team/blog/post/achieving-s3-read-after-update-consistency">consistent read-after-updates</a> for objects. EMRFS uses DynamoDB to store a partial replica of S3’s metadata (such as what files/directories are found in a given directory), enabling faster listing of files/dirs compared to S3 and <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-consistent-view.html">stronger consistency</a> (consistent file listings and consistent read-after-update, although no atomic rename) .</p><p>Here are some selected results from our peer-reviewed research paper accepted for publication at ACM/IFIP Middleware 2020. The paper includes more results than shown below, and for writes, HopsFS is on-average about 90% of the performance of EMRFS - as HopsFS has the overhead of first writing to workers who then write to S3.&nbsp; HopsFS has a global worker cache (if the block is cached at any worker, clients will retrieve the data directly from the worker)&nbsp; for faster reads and the HopsFS’ metadata layer is built on NDB cluster for faster metadata operations.</p><figure id="w-node-b5601ef697cf-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65eaca9a96e19315a05e8_Screenshot%202020-11-19%20at%2013.01.36.png" loading="lazy" alt=""></p></figure><p>*Enhanced DFSIO Benchmark Results with 16 concurrent tasks reading 1GB files. For higher concurrency levels (64 tasks), the performance improvement drops from 3.4X to 1.7X.</p><p>**<a href="https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/#:~:text=Amazon%20S3%20now%20provides%20increased,time%20for%20no%20additional%20charge.">As of November 2020</a>, 3500 ops/sec is the maximum number of PUT/COPY/POST/DELETE per second per S3 prefix, while the maximum number of GET/HEAD requests per prefix is 5500 reads/sec. You can increase throughput in S3 by reading/writing in parallel to different prefixes, but this will probably require rewriting your application code and increasing the risk of bugs. For HopsFS (without S3), <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">we showed</a> that it can reach 1.6m metadata ops/sec across 3 availability zones.&nbsp;</p><p>In our <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">paper published at ICDCS</a>, we measured the throughput of HopsFS when deployed in HA mode over 3 availability zones. Using a workload from Spotify, we compared the performance with CephFS. HopsFS (1.6M ops/sec) reaches 2X the throughput of CephFS (800K ops/sec) when both are deployed in full HA mode. CephFS, however, does not currently support storing its data in S3 buckets.<br></p><h2>How do I get started with HopsFS?</h2><p>HopsFS is available as <a href="https://github.com/hopshadoop/hops">open-source</a> (Apache V2). However, cloud-native HopsFS is currently only available as part of the <a href="https://www.hopsworks.ai/">hopsworks.ai</a> platform. Hopsworks.ai is a platform for the design and operation of AI applications at scale with support for scalable compute in the form of Spark, Flink, TensorFlow, etc (comparable to Databricks or AWS EMR). You can also connect Hopsworks.ai to a Kubernetes cluster and launch jobs on Kubernetes that can read/write from HopsFS. You connect your cluster to a S3 bucket in your AWS account or on Azure to a Azure Blob Storage bucket. You can dynamically add/remove workers to/from your cluster, and the workers act as part of the HopsFS cluster - using minimal resources, but reading/writing to/from S3 or ABS on behalf of clients, providing access control, and caching blocks for faster retrieval.</p><h3>References</h3><ul role="list"><li>Ismail Mahmoud, Salman Niazi, Gautier Berthou, …</li></ul></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3">https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149154</guid>
            <pubDate>Thu, 19 Nov 2020 13:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Millennials, the Dying Children]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25149073">thread link</a>) | @krebs_liebhaber
<br/>
November 19, 2020 | https://lexic.co/barfblog/millennials-dying-children | <a href="https://web.archive.org/web/*/https://lexic.co/barfblog/millennials-dying-children">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lexic.co/barfblog/millennials-dying-children</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149073</guid>
            <pubDate>Thu, 19 Nov 2020 13:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Light and Glory over Crete]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25148776">thread link</a>) | @jayass
<br/>
November 19, 2020 | https://misspellede.com/us/light-and-glory-over-crete/ | <a href="https://web.archive.org/web/*/https://misspellede.com/us/light-and-glory-over-crete/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div> 
                            <p><img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/CreteSky_Slovinsky_1080.jpg" alt="Light and Glory over Crete cover image"></p>
            <p><a href="https://misspellede.com/us/cosmos/">cosmos</a></p><p>Tomáš Slovinský • 2020-11-16</p><h2>Greek island of Crete</h2>



<p>The month was July, the place was the Greek island of Crete, and the sky was spectacular. Of course there were the usual stars like Polaris, Vega, and Antares -- and that common asterism everyone knows: the Big Dipper. </p>



<p>But this sky was just getting started. The band of the Milky Way Galaxy stunned as it arched across the night like a bridge made of stars and dust but dotted with red nebula like candy. The planets Saturn and Jupiter were so bright you wanted to stop people on the beach and point them out. </p>



<p>The air glowed like a rainbow -- but what really grabbed the glory was a comet. Just above the northern horizon, Comet NEOWISE spread its tails like nothing you had ever seen before or might ever see again. Staring in amazement, there was only one thing to do: take a picture. </p>



<p><span>Coverage: NASA's SpaceX Crew-1 Mission</span></p>

        </div>
    </article></div>]]>
            </description>
            <link>https://misspellede.com/us/light-and-glory-over-crete/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148776</guid>
            <pubDate>Thu, 19 Nov 2020 12:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need no service mesh]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25148642">thread link</a>) | @SerCe
<br/>
November 19, 2020 | https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/ | <a href="https://web.archive.org/web/*/https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Hi!</p>
<p>Service meshes have attracted an enormous amount of hype around them. With at least a few talks about service meshes during each tech conference, one can easily be convinced that having a service mesh in their infrastructure is a must. However, hype isn’t a good indicator of whether the new shiny tech is the right solution for your problems. So below, I’ll try to express an anti-hype opinion on service meshes to hopefully make it less confusing when you want to decide whether you may or may not need one.</p>
<p><span><img src="https://serce.me/img/servicemesh/rick.png" alt="rick"></span></p>
<div>
<blockquote>
<p>There’s a lesson here, and I’m not going to be the one to figure it out.</p>
</blockquote>
<p>
— Rick Sanchez
</p>
</div>
<div>
<h3 id="_the_invention">The invention</h3>
<p>Let’s take a step back in history and take a look at one of the <a href="https://eng.lyft.com/envoy-7-months-later-41986c2fd443">early articles</a> about introducing Envoy at Lyft.</p>
<div>
<blockquote>
<p>As it turns out, almost every company with a moderately-sized service oriented architecture is having the same problems that Lyft did prior to the development and deployment of Envoy:</p>
<div>
<ul>
<li>
<p>An architecture composed of a variety of languages, each containing a half-baked RPC library, including partial (or zero) implementations of rate limiting, circuit breaking, timeouts, retries, etc.</p>
</li>
<li>
<p>Differing or partial implementations of stats, logging, and ….</p>
</li>
</ul>
</div>
</blockquote>
</div>
<p>While Envoy is not a service mesh by itself, the outlined problems describe the exact reason why service meshes were invented. They add “rate limiting, circuit breaking, …” and other reliability, observability, and security features to the services by enforcing the communication to go through the service mesh proxies, a data plane. Additionally, they require a separate component, a control plane, to control the configuration.</p>
<p>However, at this point, a lot of people miss the context in which service meshes were introduced. Service meshes are able to solve the problem not because it’s impossible to solve them in any other way. There are many battle-proof RPC libraries that take on the challenges of a separate data plane layer, <a href="https://github.com/twitter/finagle">Finagle</a>, <a href="https://github.com/grpc">gRPC</a>, <a href="https://github.com/line/armeria">Armeria</a>, <a href="https://github.com/apple/servicetalk">Servicetalk</a>, to name a few. After all, the very first service mesh - Linkerd 1.0 <a href="https://github.com/linkerd/linkerd">is powered by Finagle</a>. The RPC libraries will need a component which provides service discovery and configuration management to make it a true mesh. For instance, Zookeeper, or Consul, a component that service meshes call a control plane.</p>
<p>Why introduce a new concept to solve the problems that have been solved before? The service mesh concept wasn’t introduced to address problems that hadn’t been addressed before but rather address them in a way that doesn’t require any modifications to the application code, which is incredibly convenient when it’s hard to introduce an RPC layer into an existing heterogeneous microservice environment.</p>
<p>When you hear service mesh, Istio with Envoy might be the first thing that comes to mind, but it wasn’t the first service mesh to enter the market. Linkerd authors who pioneered the space, described exactly this situation in the <a href="https://linkerd.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/#why-is-the-service-mesh-necessary">"why is the service mesh necessary"</a>. Interestingly, in many hype-y articles on the Internet this context is often forgotten, or omitted.</p>
<p>Solving a problem well, even if it’s a problem that a lot of people have, doesn’t magically provide the tech with a lot of hype. There is always a sponsor behind it. I don’t know who the sponsor was here, and I’m going to speculate, but it’s hard to sell an RPC library in the world where open source is a fundamental requirement. There is no clear business model there, that’s why most of the mature RPC libraries were open-sourced by large tech companies for which it’s not a part of the core business model. A library is just code, not a piece of infrastructure. Service meshes are a different story. It’s an isolated non-trivial piece of infrastructure. As a vendor, not only can you provide consultancy around the configuration and deployment, but you can also sell complete hosted solutions around it.</p>
</div>
<div>
<h3 id="_disillusionments">Disillusionments</h3>
<p>Now that we’ve established the problems, the solution, and most importantly, the context in which the solution was made, let’s take a look at the alternatives. The most obvious one, in the spirit of KISS, is to use an RPC library for your preferred language. Here is where the context is crucial: if you have a large fleet of services, each written in its own language/ecosystem, and the only language that they share is HTTP then having a single shared RPC library is going to be hard. Perhaps, you’ve got a fabric of deployed and running services, but everyone is afraid of touching them, no one knows how they work, and each redeploy is an adventure. A service mesh is here to help you, because at least you’ll be able to roll out new infrastructure features to the mesh regularly.</p>
<p>On the other hand, if you have a fleet of healthy services written in a single application stack, then it’s a good idea to think twice before introducing a service mesh. By simply introducing or evolving a shared RPC library, you’ll get the exact same benefits and avoid dealing with the downsides of maintaining service meshes. By studying the service mesh limitations thoroughly, you can avoid finding yourself in the trough of disillusionment.</p>
<p><span><img src="https://serce.me/img/servicemesh/curve.png" alt="Hype Cycle"></span></p>
<div>
<h4 id="_different_ecosystem">Different ecosystem</h4>
<p>The ecosystem of the service mesh of your choice will likely be different from the ecosystem of your services. Beautiful websites always make you believe that the solution is plug’n’play, always works and never goes down. In reality, sooner or later problems, bugs, quirks in behaviour will reveal themselves, as they always do. At that point, you’ll need to have engineers who work on the service-mesh’s ecosystem which when it’s different from the main app, effectively limits the set of people who can introduce changes or fix problems. This is likely to reintroduce silos, which is against the whole DevOps spirit. Yes, having a DevOps team of engineers who are doing DevOps-y things <a href="https://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/">is against DevOps</a>.</p>
</div>
<div>
<h4 id="_unnecessary_overhead">Unnecessary overhead</h4>
<p>Not only having a proxy in front of each service adds overhead (often significant, talking about <a href="https://istio.io/latest/docs/ops/deployment/performance-and-scalability/">90pt</a> rather than 99pt in the performance summary <a href="https://www.infoq.com/presentations/latency-response-time/">doesn’t make software run faster</a>) and consumes resources, but you also requires time (or rather a team of people) to manage them. Yes, it can help to make some of the tasks potentially easier - yay, you can now add canary deployments with a few lines of YAML to simple applications now. However, you still need to manage canary deployments of the proxies themselves which don’t have a proxy in front of them. The problems just get pushed up the stack.</p>
</div>
<div>
<h4 id="_limiting_your_architecture_to_what_the_proxy_supports">Limiting your architecture to what The Proxy supports.</h4>
<p>As you’re reading this paragraph, HTTP/3 is slowly being rolled out to the Internet. It uses UDP as transport. Why use UDP rather than create a completely new protocol you ask? That’s because anything but TCP and UDP is simply “blocked” by the boxes, various proxies on the internet - routers, gateways, etc. This phenomenon got named <a href="https://http3-explained.haxx.se/en/why-quic/why-ossification">ossification</a>. So, only TCP or UDP are left is the practical chose, and even UDP is partially blocked by various corporate proxies which slows down the adoption.</p>
<p>Even though your microservice environment is probably much smaller compared to the Internet, you can draw parallels with service meshes. Proxies can ossify your application architecture by limiting how your services talk to each other, and there is not much benefit in having proxies if you can bypass them. Suppose you want to build a reactive application which is using RSocket over pure tcp? Or perhaps a message-driven application using an actor model? Or maybe push the performance boundaries with Aeron? Not going to happen until the box in the middle becomes aware of the protocol.</p>
</div>
</div>
<div>
<h3 id="_do_i_need_one">Do I need one?</h3>
<p>What does it all mean for you as an engineer? The answer to whether you need to adopt the service mesh approach comes down to the state of the microservice environment you’re trying to improve. As we have established, compared to an RPC framework, service meshes allow you to:</p>
<div>
<ol>
<li>
<p>Deploy the infra changes more often than deploying your services.</p>
</li>
<li>
<p>Introduce infra changes without touching the service code.</p>
</li>
</ol>
</div>
<p>The point 1. is important when for whatever reason you can’t redeploy your services very often, e.g. maybe no one remembers how it’s done anymore, or maybe there are other restrictions. The point 2. is important when your stack is heterogeneous, e.g. some services are built in Go, some in Java, some in Haskell, etc. Where are you on the interval from a huge set of heterogeneous services with unknown deployment schedules to a set of homogenous regularly deployed services defines whether a service mesh is the best solution for you.</p>
</div>
<div>
<h3 id="_conclusion">Conclusion</h3>
<p>Service meshes have a lot of hype around them, and way too much in my opinion. However, before committing to a piece of technology, it’s crucial to understand the problems it solves, and the context in which the solution was made. A service mesh is not an ultimate “good practice” but simply one of the patterns to solve a set of issues, and it’s quite a heavy one.</p>
<p>Rather than jumping on board, look carefully - the last thing you want is to find out that you have invested in a solution for a problem that you don’t have. Service meshes are an amazing piece of tech solving a whole lot of problems. Not in every case, it is the best solution.</p>
</div>
<div>
<h3 id="_thank_you_to">Thank you to</h3>
<div>
<ul>
<li>
<p>You for reading this article.</p>
</li>
<li>
<p><a href="https://twitter.com/ptuls">Paul Tune</a> for reviewing the article.</p>
</li>
</ul>
</div>
</div>
<div>

<hr>
<blockquote><p lang="en" dir="ltr">"You don't need no Service Mesh". Just published a new blog post with an anti-hype opinion on the over-hyped topic. <a href="https://t.co/SVXS3nWKzj">https://t.co/SVXS3nWKzj</a></p>— Sergey Tselovalnikov (@SerCeMan) <a href="https://twitter.com/SerCeMan/status/1286242507664191488?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote> 
</div>

</div></div>]]>
            </description>
            <link>https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148642</guid>
            <pubDate>Thu, 19 Nov 2020 12:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Beef with RuboCop]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25147990">thread link</a>) | @todsacerdoti
<br/>
November 19, 2020 | https://www.rubypigeon.com/posts/my-beef-with-rubocop/ | <a href="https://web.archive.org/web/*/https://www.rubypigeon.com/posts/my-beef-with-rubocop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Consider a hypothetical class that filters out unsafe HTML elements:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
      <span>super</span>
    <span>else</span>
      <span>nil</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The default RuboCop settings would have us change it to this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>super</span> <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Let us feast on a three-course meal of opinion about why this is
worse.</p>

<h2 id="that-nil-was-written-for-a-purpose">That <code>nil</code> Was Written For A Purpose</h2>

<p>My first beef — the hors d’oeuvre, if you will — is that
<code>Style/EmptyElse</code> wants us to change from an <em>explicit</em> <code>nil</code> return
value to an <em>implicit</em> one. It says there is a “redundant
else-clause”. I’ll tell you what’s redundant: the <code>Style/EmptyElse</code>
cop.</p>

<p>This cop would prefer that the <code>else</code> clause did not exist, like this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
      <span>super</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>In terms of behaviour at runtime, this is exactly the same. In terms
of readability, it is not.</p>

<p>The explicit <code>nil</code> in the original implementation implies that the
method is being called for its return value — that it’s probably
functional, with inconsequential side effects.</p>

<p>Making the <code>nil</code> implicit says that <em>the return value is not
important</em>. This method now reads like it’s implemented by avoiding
side effects within <code>super</code>.</p>

<p>So which one is it? Is the filter supposed to work by returning <code>nil</code>,
or does it work by avoiding the side effects in the <code>super</code> call?
These are very different behaviours, and RuboCop just changed the
human interpretation from the correct one to the wrong one.</p>

<p>Bad cop. No doughnut.</p>

<h2 id="its-not-a-guard-clause">It’s Not A Guard Clause</h2>

<p>My other beef (the main course) is with <code>Style/GuardClause</code>. This cop
takes conditionals and turns one of the branches into a guard clause
— something like this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>return</span> <span>nil</span> <span>unless</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>

    <span>super</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Again, the runtime behaviour is identical, but the cop makes it less
readable.</p>

<p>Guard clauses are for bailing out early when you know that it’s not
necessary to run the rest of the method. They are usually trivial in
comparison to the <em>real</em> work done by the rest of the method. For
example, if we were implementing a sorting algorithm, then we could
have a guard clause for inputs with one element or less — there is
no need to run a sorting algorithm when there is nothing to sort.</p>

<p>Except in this case, we’re not “guarding” the rest of the method from
being run. That conditional is the <em>entire raison d’être of the
class</em>. It’s the most important part. The whole purpose of a filter is
to decide what elements stay in, and what elements get filtered out.</p>

<p>RuboCop has taken the most important part of the class and turned it
into a trivial-looking guard clause.</p>

<p>Bad cop. No doughnut.</p>

<h2 id="branching-should-look-like-branching">Branching Should Look Like Branching</h2>

<p>My final qualm (is there such a thing as dessert beef?) is with
<code>Style/GuardClause</code> removing the obvious indenting of the two
branches, making it look like straight-line procedural code.</p>

<p>Most of the time, developers don’t so much <em>read</em> code as they do
<em>scan</em> code. We don’t read from left to right, top to bottom, as if
the codebase were the world’s most boring novel. We skim over code,
navigating by the colours of syntax highlighting and the shapes
made by indentation.</p>

<p>So when we’re skimming over the original code, trying to find the
conditional — which we’ve already established as being the most
important part of the class — we will find two landmarks: a line
that starts with a brightly coloured <code>if</code> keyword, and indentation
that suggests a conditional.</p>

<p>But skimming over the guard-clause-enhanced code we see neither of
these landmarks. Instead, we find indentation that suggests
<em>procedural</em> code: a series of statements that run from top to bottom.
RuboCop has taken an obvious conditional and reshaped it to look like
there is no conditional.</p>

<p>The <code>Style/GuardClause</code> cop is double bad, and misses out on two
doughnuts.</p>

<h2 id="disclaimerconclusion">Disclaimer/Conclusion</h2>

<p>I don’t dislike RuboCop. It’s well made, and a useful tool.</p>

<p>The problem starts when it is viewed not as a tool, but as a set of
divine commandments. Thou shalt not make implicit <code>nil</code>s explicit.
Thou shalt not write long-form conditionals. Thus saith the RuboCop.</p>

<p>This is not necessarily a problem with RuboCop itself — it’s a
problem with how people sometimes use RuboCop. One could argue that
the defaults aren’t great, but they are not a problem until someone
hooks them up to CI.</p>

<p>My only aim here is to disabuse readers of the notion that RuboCop can
only make code better. It’s a tool, and whether it helps or hurts
depends on how it’s used. Don’t be afraid to disable cops if you can’t
see how they benefit the team.</p>



        

      </div></div>]]>
            </description>
            <link>https://www.rubypigeon.com/posts/my-beef-with-rubocop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147990</guid>
            <pubDate>Thu, 19 Nov 2020 10:19:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advent of Code in Haskell: T Minus 16]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25147851">thread link</a>) | @todsacerdoti
<br/>
November 19, 2020 | https://www.bulters.dev/posts/t-minus-16/ | <a href="https://web.archive.org/web/*/https://www.bulters.dev/posts/t-minus-16/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			
<p>For the past few years I’ve been trying to learn haskell in various ways but
have never been able to stick to the method, let alone actually “become
productive” in Haskell.</p>
<p>Since I’ve decided to spent more time on tinkering during the evenings, I
thought it would be a nice idea to document my learning process.</p>
<p>The general idea is that I will do the challenges from the Advent of Code (2020
edition) and implement them in Haskell. And since there are 16 days left before
“it begins”, I’ll kick off with doing some of the challenges from last year to
prepare.</p>
<p>The documentation part will not really involve the learning of the language
itself, but more on “everything ephemeral” (the plumbing?). I’ll try to
elaborate on some of the “typical difficult Haskell stuff” as I encounter them
(and when I deem them appropriate).</p>
<p>I’m convinced that Haskell in itself is quite an easy language to grasp (once
you manage to get “some functional programming practices to click”), but that
there are a number of barriers that prevent people from becoming productive in
it.</p>

<p>During this attempt to grasp Haskell I will be working on my Windows 10 laptop
under WSL2 running an Ubuntu 20.04 installation. My notes will assume that a
sort of sane setup for an editor is available.</p>
<p>I use vim myself, with a fairly minimal vimrc (no haskell specific
configuration) and the following packages:</p>
<div><pre><code data-lang="shell">ale/ coc.nvim/ fzf/ ultisnips/ vim-go/ vim-repeat/ vim-surround/ vim-vinegar/
</code></pre></div><p>To get started I installed the GHC compiler through the default Ubuntu package
manager:</p>
<p>And then verified that installation has succeeded by running</p>
<div><pre><code data-lang="shell">&gt; ghci --version
The Glorious Glasgow Haskell Compilation System, version 8.6.5
&gt; ghc --version
The Glorious Glasgow Haskell Compilation System, version 8.6.5
&gt; cabal --version
cabal-install version 2.4.0.0
compiled using version 2.4.0.1 of the Cabal library
</code></pre></div><p>This ensured that all binaries are properly available (in path) to get going.</p>

<p>For those who do not know, The Advent of Code (TAOC) is a yearly event in which
50 programming assignments are made available during the first 25 days of
december, outlining a glorious story usually involving santa, elves, presents
and the (not so) daily challenges they face.</p>
<p>Every day two programming challenges are presented that take a certain input
(your daily input file) and require you to do StuffTM with that input to
accomplish a certain task. Don’t worry, it will all become clear when you
actually try this.</p>
<p>You can register on <a href="https://adventofcode.com/">https://adventofcode.com</a>.</p>

<p>With the environment setup I create a fresh directory for the first day:</p>
<p>and paste my input for the first challenge into taoc19/day1/input.txt</p>
<p>Since I’m not trying to do anything fancy right now, I create a new cabal
package with the <code>cabal init</code> command.  During the interrogation cabal gives
me, I stick with the defaults, except when asked whether I’m building a package
or executable, in which I choose ‘executable’.</p>
<p>This gives me a few files that I can use to start building.</p>
<p>To start the process I need to get my data from the input.txt file into a
function. Since I’ve read something about Haskell before (and some quick
googling) I try using the readFile function (from the stdlib/Prelude) in GHCi
and voila:</p>
<div><pre><code data-lang="haskell"><span>let</span> raw <span>=</span> readFile <span>"input.txt"</span>
</code></pre></div><p>The problem arises when I put the <code>let raw = readFile 'input.txt'</code> line in my
main do-block. Haskell has this notorious Monad thing going on, which I do not
yet fully grasp. But you don’t need to understand it to use it, so a small
Google session quickly led to the insight that I need to “reverse arrow put”
the result of the <code>readFile</code> call into a variable instead of using <code>let</code>. This
leads to a really minimal Main.hs file</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>
        print raw
</code></pre></div><p>when loadng it into GHCi and running main, it nicely outputs my input data.
First win achieved!</p>
<div><pre><code data-lang="shell">Prelude&gt; :l Main.hs
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
&lt;your data here&gt;
</code></pre></div><p>Step two involves splitting up the input into lines and converting these lines
into an array of integers.</p>
<p>To accomplish the first step, Haskell has a handy function <code>lines</code> (in the
Prelude) available. The second part involves the <code>read</code> function (also a
Prelude thing) and specifying the type of the statement. Initially I created a
separate function <code>stoi</code> for this</p>
<div><pre><code data-lang="haskell"><span>stoi</span> <span>::</span> <span>String</span> <span>-&gt;</span> <span>Int</span>
<span>stoi</span> <span>=</span> rread
</code></pre></div><p>but decided that “casting” the data inline would still be perfectly readable
(and perhaps even clearer), resulting in:</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>

        <span>-- since lines does not take an IO &lt;something&gt; but a regular String</span>
        <span>-- we do not use the do ... &lt;- syntax here, but put it in a variable</span>
        <span>-- directly.</span>
        <span>let</span> ls <span>=</span> lines raw

        <span>-- we want to have an [Int], so map the read function over the lines.</span>
        <span>let</span> nums <span>=</span> map read ls <span>::</span> [<span>Int</span>]

        print nums
</code></pre></div><p>Achievement 2 unlucked, I’m finally ready to do something with my data.</p>
<p>Part 1 of the challenge involves calculating how much fuel we need according to
a certain formula, so for every input we apply a function to it, and sum the
results.o</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>fuelRequired</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>fuelRequired</span> <span>=</span> id <span>-- todo</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>

        <span>-- since lines does not take an IO &lt;something&gt; but a regular String</span>
        <span>-- we do not use the do ... &lt;- syntax here, but put it in a variable</span>
        <span>-- directly.</span>
        <span>let</span> ls <span>=</span> lines raw

        <span>-- we want to have an [Int], so map the read function over the lines.</span>
        <span>let</span> nums <span>=</span> map read ls <span>::</span> [<span>Int</span>]

        <span>-- apply the fuelRequired function to all the inputs and sum the result</span>
        <span>let</span> totalFuel <span>=</span> sum <span>$</span> map fuelRequired nums
        print totalFuel
</code></pre></div><p>which if we load it into GHCi gives us the sum of all the weights.</p>
<div><pre><code data-lang="shell">*Main&gt; :edit
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
<span>9961383</span>
*Main&gt;
</code></pre></div><p>The actual calculation of required fuel involves dividing the weight by 3,
rounding it down and subtracting 2, giving me a really simple to implement
fuelRequired function.</p>
<div><pre><code data-lang="haskell"><span>-- fuelRequired should be the mass x, divided by 3, minus 2</span>
<span>-- with a minimum of 0.</span>
<span>fuelRequired</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>fuelRequired</span> x <span>=</span> max <span>0</span> <span>$</span> (div x <span>3</span>) <span>-</span> <span>2</span>
</code></pre></div><p>Running the main file in GHCi again (after reloading the Main.hs file) gives me
a number that, when entered in the answer field on AOC tells me I’m on the
right track! Yay!</p>

<p>Oh, surprise, physics kicks in. Turns out, fuel weighs something as well, so
we’ll have to calculate the amount of fuel required to carry the fuel, which
also requires fuel to carry, etc.</p>
<p>This looks like a typically recursive situation where fuel that requires no
fuel (i.e. weighing 9 or less) serves as a perfect termination case. Let’s try
to write this as a recursive function with a guard in it.</p>
<div><pre><code data-lang="haskell"><span>-- recursiveFuelRequired is implemented as a recursive function</span>
<span>-- where we terminate recursion as soon as there is no more</span>
<span>-- fuel required for a certain component.</span>
<span>recursiveFuelRequired</span> x
        <span>|</span> x <span>==</span> <span>0</span>    <span>=</span> <span>0</span>
        <span>|</span> otherwise <span>=</span> <span>let</span> thisFuel <span>=</span> fuelRequired x <span>in</span>
                        thisFuel <span>+</span> recursiveFuelRequired thisFuel
</code></pre></div><p>and then calculating the actual total fuel required in the same way as before,
but now with this new recursive function:</p>
<div><pre><code data-lang="haskell"><span>let</span> totalFuel <span>=</span> sum <span>$</span> map recursiveFuelRequired nums
<span>print</span> totalFuel
</code></pre></div><p>output copy-paste into solution field, press submit, and… GREAT SUCCESS!</p>
<p>I’ll cover my solving of the Day 2 challenges somewhere in the upcoming days.</p>

		</section></div>]]>
            </description>
            <link>https://www.bulters.dev/posts/t-minus-16/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147851</guid>
            <pubDate>Thu, 19 Nov 2020 09:50:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Sunshine]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25147134">thread link</a>) | @rxever
<br/>
November 18, 2020 | https://sunshine.com/introducing-sunshine/ | <a href="https://web.archive.org/web/*/https://sunshine.com/introducing-sunshine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="838105f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>How do you make the mundane magical?&nbsp; Imagine if your contacts magically stayed up-to-date with no effort on your part.&nbsp; Or if the great photos you have of your friends got sent to them automatically. What if you never forgot another birthday?</p>

<p>The impossible is now possible. Smartphones have connected the world and put the entire internet into our pockets. We can get whatever we want delivered to our home whenever we want, sometimes by flying drone. With the rise of artificial intelligence, dreams of virtual assistants, self-driving cars and global facial recognition are no longer that far-fetched. However, despite transformational advances in technology, there are still tons of mundane, time-consuming tasks that we all do (or just don’t do) daily.<br><span><br><b>Sunshine’s technology will make the mundane effortless, free up your time, and make it easier to be thoughtful.</b></span></p>
<p><span>Every day, we muddle through tasks with technology that is “good enough” – contacting friends with stale information that may or may not reach them; searching through email for phone numbers and addresses that we know we have somewhere; manually and painstakingly creating group distribution lists for every occasion; scheduling time to get together with friends using a hodge-podge of calendar, email, and text; pinching and zooming through photos to find one with everyone’s eyes open. We’re used to the mess, and we’ve come to accept the friction.&nbsp;</span></p>

<p>No more.&nbsp; Everyday things should <b>just work</b>, and that’s Sunshine’s mission. We’re creating technology to address practical, everyday pain points in the basic, foundational tools that connect us with the people we care about. Ultimately, Sunshine will remove complexity in things like contact management, scheduling, event organization, and group communication so you can spend time more meaningfully.</p>

<p>We want to put the focus back on people, and let technology advance in its sophistication and fade into the background.</p>

<p>Today, we’re launching Sunshine Contacts (see our announcement here). Leveraging the power of artificial intelligence, Sunshine Contacts finds, deduplicates, and organizes your contacts. Using a variety of sources, we ensure your contact list is in one place, organized, always complete, and up-to-date.&nbsp; Sunshine Contacts makes your contacts <b>just work</b>.</p>

<p>Sunshine Contacts is our foundation. When your contacts are organized and truly work, they create a flywheel where scheduling, planning, organizing, and being thoughtful about your relationships becomes infinitely easier. When your contacts are complete, comprehensive, and accurately reflect relationships, you can spend your time building meaningful connections and shared experiences. Our future suite of products will make it effortless to keep in touch with the people in your life on a personal and professional level in a thoughtful way.</p>

<p>This is just the beginning.&nbsp; Sunshine is building a suite of services to solve the common pain points that modern technology hasn’t addressed.</p>

<p>At Sunshine, we strive to make the mundane magical. Our vision is to support your day-to-day life – to eliminate time spent on “technology” and simply make things better.&nbsp; Easier.&nbsp; If this means you save some “screen time” and give more thought to the most important people in your life, then we’ll know we’ve done it right.</p>

<p>We can’t wait to show you what’s next.</p>

<p><i>– Marissa and Enrique</i></p>
</div>
				</div>
				</div></div>]]>
            </description>
            <link>https://sunshine.com/introducing-sunshine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147134</guid>
            <pubDate>Thu, 19 Nov 2020 07:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mac is losing me]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25146808">thread link</a>) | @lawik
<br/>
November 18, 2020 | https://underjord.io/the-mac-is-losing-me.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-mac-is-losing-me.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-18</small>
        <p>I’ve been mostly happy using a Mac since I got myself my first computer earned with programmer money. I believe it was a mid 2009 15" MacBook Pro. That was a computer I used at least until 2016 which I consider very decent usable life. At that point I had replaced the hard-drive with an SSD, upgraded the RAM and switched a battery that was worn out. I stopped using it when it just straight died some time in 2016.</p>
<h2 id="my-history-with-the-mac">My history with the Mac</h2>
<p>So what was that computer to me? It was an extremely well-built and solid-feeling piece of aluminium. A cool keyboard backlight. The magsafe charger and a bunch of USB ports. The keyboard and touchpad were best in class. The build quality was better than any laptop I had owned before. Partly because I had only bought the cheap ones before but also because they really were a step above at the time.</p>
<p>I got it primarily on recommendation from a friendly hacker who’s recommendations had never lead me wrong before. He spoke well of the underlying UNIX and the experience of using it. Fast, clean and visually pleasing. I think he mostly really liked the backlit keyboard, very hackerly. His recommendation held true, this computer was very good to me.</p>
<p>I’ve also been the admin on an Xserve server. That was wild. Neat UIs but buggy and finicky as all hell.</p>
<p>Since then I’ve used the second generation Macbook Air (I believe 2nd, first wedge version) at 11". That was a cool little machine and did what it did very nicely.</p>
<p>Hardware aside, MacOS in it’s earlier incarnations on these computers was always a snappy and competent experience. A polished surface which did a bunch of stuff under the hood that generally made it work better than the different Ubuntu desktop environments and various Windows versions I’ve had before. Things like Wifi and even Bluetooth felt good in a way they never had before.</p>
<p>A lot of it was the visual polish and the extremely snappy UI. But in total the experience was just great. Spotlight was glorious. I think my first upgrade was Snow Leopard which was generally a very good update as it focused on performance and stability.</p>
<p>As a developer’s machine it was fast enough, competent enough, got out of the way and the UNIX underpinnings meant I didn’t miss Linux at all. I’ve never been able to really connect with the equivalent powershell stuff in Windows. I guess I just like UNIX.</p>
<p>The only bad thing I can say about my early years of MacBook Pro usage was that the trackpad and the Magic Trackpad I got eventually are probably some of the biggest culprits in some of the RSI-style hand pain I’ve been dealing with. Trackpads are just murder on my hands and I worked loads off of that setup for a number of years. Took a while before I realized that it was trackpad-related.</p>
<p>Beyond that I’ve had some refurb Macs for my wife and assorted family, some 13" MBP for work at one point and then a 15" butterfly touchbar MBP for work. I think that was when I started to feel that Apple was diverging from my preferences in the MBP line.</p>
<h2 id="my-current-experience">My current experience</h2>
<p>That’s the same computer I have and work on now and it is.. fine? Maybe just OK. Not great. I’ve had some keys getting stuck but fixable with canned air. I don’t like the touchbar, it has been between useless and an actual hindrance. The TouchID power button is good though. I don’t like living in dongle-town though I mostly like USB C in the long run.</p>
<p>The reason it has been mostly fine for me is that I keep it on tray mounted on a VESA arm, dangling dongles like a technical octopus and I use external peripherals for input.</p>
<p>It gets really hot and loud and then it performs incredibly poorly. So I guess this is one of the throttliest generations. I think I had the “don’t charge it on the wrong side” problem as well. Some of the CPU shenanigans have calmed down as I installed the Turbo Boost Switcher tool to just disable the Turbo Boost, removing performance for peace and quiet.</p>
<p>As I’ve been using these devices it has become increasingly annoying to figure out how to install “unknown” apps. I need some non-discoverable terminal incantation to get the option to accept installing things that are unsigned. There’s always a new piece getting locked down. And while I think that’s often to the benefit of the average consumer, I’m not that. And I just get more annoyed.</p>
<p>I’ve been frustrated about the uninspiring performance delivered for the incredible brand markup that Apple charges. I don’t mind the computer being expensive if the experience is good and the hardware reasonable. The experience feels like it is slipping, especially for my needs and the hardware has just been getting less impressive to me.</p>
<h2 id="the-hardware">The hardware</h2>
<p>My gaming computer has a Ryzen. For a while I did my dev on that as we had just moved to our house and the office wasn’t finalized. Woof, aside from running Windows as a dev environment which I didn’t enjoy there was some serious upside on that machine.</p>
<p>On the Mac my options are very limited. I can’t get a Ryzen, I can’t get anything modern with Intel or meaningfully upgradable at all. The Mac Pro doesn’t count. It comes underspeced at hilarious prices. I like some of the design decisions but the price-point doesn’t make any kind of sense for me and what I do. I can’t buy an interesting Mac from a performance standpoint.</p>
<p>Or can I? Well, they just announced the M1 chip and ARM Macs are now a fact. I think I might get one at some point. For a travel laptop I don’t think the rest of the industry is ready to fight Apple. Battery life and good bang for buck power might actually keep a Mac in my life for that. But I feel like the general trend is away from what I want. Or I might just use my iPad Pro for that use-case.</p>
<p>I think the M1 will be quite impressive when the benchmarks roll in. I’m sure it will suit many people for real-world use-cases as well. However, from the first presentation on it and the first batch of Macs I don’t feel like the direction is for me. IO was heavily sacrificed. Upgradability is pretty much out the window. These things can be fine for a travel device for me where battery and weight are primary concerns. In that regard the new Air looks pretty good.</p>
<h2 id="the-software">The software</h2>
<p>Beyond that the coming OS, Big Sur, is taking MacOS in a direction I dislike. Catalina was quite messy and felt like it took steps toward walling off the Mac. Big Sur seems even more heavy-handed in that area and finally the M1 can push that even further if Apple feels like it. My trust is eroding on letting Apple set the tone for my computing life.</p>
<p>Don’t get me wrong, I think their approach to this transition is incredibly neat with Rosetta2 and how they are using the bytecode stuff with the App Store and whatnot. And the possibility to run iOS and iPad apps natively could be very useful. But none of this really moves the needle for me.</p>
<h2 id="so-whats-next">So what’s next?</h2>
<p>With my office in the garage as my primary work location I’m looking to transition to a desktop computer with lots of power. It will run Linux. Marking my first major return to desktop linux as a daily driver in a bundle of years. And it will run as light a desktop environment as I can stomach. I just wanted a stupid amount of performance to offset som of the UX niceties I know I will miss or have to customize  on my own.</p>
<p>I’m excited about exercising my development tools on a strong modern CPU rather than the throttled mess my current laptop offers. But I’m not thrilled about this move beyond the hardware aspect. I liked MacOS but I just don’t feel like Apple gives much of a care for the things I care about. And I feel like the software side on the Mac is slipping, consistently.</p>
<p>If they released an expandable Mac that wasn’t ridiculously expensive they would really make me think twice. But that feels unlikely.</p>
<p>So I’ll build myself a monstrous machine that can compensate in raw power for the potential lack of elegance and which offers unbounded flexibility rather than a poorly tended garden that someone keeps trying to wall in.</p>
<p>I’m not happy about it. I’ve generally enjoyed using my Macs. But when someone says “we’ll give you the full experience”, settling into that requires trust. And my trust that Apple and me are in alignment keeps fading.</p>
<p>Also, I’m developing a lot with heavily concurrent workloads. So I really look forward to exercising more cores. 2021, year of the Linux desktop (for me).</p>
<p>If you have thoughts, comments or a hell yeah you want to share about this topic or maybe you want me to cover some specific part of my transition here, let me know either via <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. My first thoughts and my build might just show up first on my newsletter, so consider signing up for that below. It don’t track. Thanks for reading.</p>

    </article></div>]]>
            </description>
            <link>https://underjord.io/the-mac-is-losing-me.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146808</guid>
            <pubDate>Thu, 19 Nov 2020 06:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Community Voices: Lars Wikman]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25146798">thread link</a>) | @lawik
<br/>
November 18, 2020 | https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>To say that Lars (a.k.a <a href="https://twitter.com/lawik">@lawik</a>) is only, as he describes himself, an “Elixir consultant with too much enthusiasm” will be an understatement. The guy is all over the place, writing software, helping businesses move forward, writing <a href="https://underjord.io/the-beam-marches-forward.html">inspiring stories</a> about the future of the BEAM, and co-hosting <a href="https://devchat.tv/podcasts/elixir-mix/">an Elixir podcast.</a> That is how I first got to know Lars. </p><p>Based in Sweden, Lars started his programming journey by building websites with Notepad, then learning PHP and eventually taking his hobby pro through contract work, a failed startup, a couple of product teams and onward into independent consulting. He lives along the west coast of Sweden - a little way out of the city, where he attempts to grow vegetables with his wife and baby. The baby is terrible at growing vegetables.</p><p>In 2016 Lars discovered Erlang/Elixir, and this changed his view on developing software.</p><h2 id="what-brought-you-to-elixir">What brought you to Elixir?</h2><p><strong>Lars:</strong> At first, it was a bit of hype. I had a colleague who was quite a good talker and he went on at length about the legendary resilience of Erlang and hot updates for buried telephone switches. He spoke very well of Ecto changesets and was generally, very positive about Elixir. I ended up looking at talks about Phoenix. This was when <a href="https://hexdocs.pm/phoenix/channels.html">Channels</a> was the new hotness and just before <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> took the keynote stage. Looking at what the community was putting out made me give Elixir a try. When I went into business for myself, I was expecting to do a lot of Python, but I intended to try and get into Elixir.</p><p>I enjoy toying around with Raspberry Pi, so it was just a matter of time before I started playing with <a href="https://www.nerves-project.org/">Nerves</a>. I wanted to use the <a href="https://shop.pimoroni.com/products/inky-what?variant=21214020436051">Inky eInk</a> display with Nerves but the library was only available for Python. So, I decided to make a pure Elixir reimplementation. It proved to be a rabbit hole, but the Nerves community was very welcoming and helpful, and I was sold on Elixir for good. Love that crew!</p><p>I feel like I’ve written <a href="https://underjord.io/why-am-i-interested-in-elixir.html">at</a> <a href="https://underjord.io/why-am-i-still-excited-about-elixir.html">least</a> <a href="https://underjord.io/more-than-one-thing-at-a-time.html">four</a> <a href="https://underjord.io/the-beam-marches-forward.html">blog posts</a> about why I remain interested in and excited by Elixir and the BEAM. I like Python. I understand why people like Node.js but I can’t quite get excited about it. Either you go higher level on top of good abstractions, as the BEAM has, or you go lower level for unconstrained performance and flexibility.</p><h2 id="elixir-and-erlang-differ-significantly-from-other-mainstream-programming-languages-what-did-you-find-most-challenging-when-starting-with-the-stack">Elixir and Erlang differ significantly from other mainstream programming languages. What did you find most challenging when starting with the stack?</h2><p><strong>Lars:</strong> Immutability and the functional programming paradigm. Much of my early code did nothing or only did things by accident because I expected that the Map functions would mutate the map, not return a new one. Grasping map, reduce and all of their derivatives in the Enum module took me a bit. It was an adaptation process.</p><p>I guess it has also taken a while to disentangle <em>use</em>, <em>require</em>, <em>import</em> and <em>alias</em>. I still wouldn’t take bets on my understanding of <em>require</em> ;)</p><p>I’ve found the community incredibly welcoming at every step. I’ll call out <a href="https://twitter.com/nyaray">Emilio Nyaray</a> for helping me with some major refactoring and absorbing idiomatic Elixir. I hope everyone has such a good reception and it feels like the general feel of the community is very positive.</p><h2 id="tell-us-a-bit-about-your-most-recent-project-why-did-you-choose-elixir-for-it">Tell us a bit about your most recent project. Why did you choose Elixir for it?</h2><p><strong>Lars:</strong> A little while ago I made <a href="https://underjord.io/live-server-push-without-js.html">a very silly thing</a>. It is a way to show live information on a web page without using Javascript. Instead, it uses the <a href="https://en.wikipedia.org/wiki/Motion_JPEG">MJPEG</a> video protocol to deliver a new frame whenever the state changes. I used it to implement a live counter.</p><p>I used Plug and some code I found that the Nerves people had put together. The state is managed by a GenServer which keeps track of the connections as they come in, asking for the ”image”. It would add them to the list, render a new frame with some text on it, and send it to everyone connected. &nbsp;That would have been incredibly finicky in most runtimes. In my case, the biggest challenge was hitting the front page of Hacker News, where my Nginx config became a bottleneck for concurrent connections. I might have also needed to tweak my Plug a bit. It all maxed out at 450 or so concurrent connections, and I think it should be able to do way more.</p><p>I am about to add some upgrades to the <a href="https://beambloggers.com/">Beambloggers Webring</a> soon that follow the same vein. I don’t like running a database if I don’t need one. So the MJPEG thing is just in-memory data and a temporary state. I restart it, the connections are gone, and start building up again. Similarly, I want Beambloggers to bring in some fresh information about the different blogs. So I’ll have it run a GenServer that pulls in RSS feeds and parses out some recent items that I can link to. In-memory, background work.</p><p>Such use cases are something I’d hesitate to do in Python, for example. If I build something stateful in Python, I feel like it is bound to leak somewhere. Elixir and Erlang have abstractions that allow me to do such things with confidence.</p><h2 id="you-also-do-elixir-consulting-what-kinds-of-applications-do-your-clients-choose-the-beam-for-as-opposed-to-other-tech-stacks"><br>You also do Elixir consulting. What kinds of applications do your clients choose the BEAM for, as opposed to other tech stacks?</h2><p><strong>Lars: </strong>Distributed applications that run indefinitely. Those line up with the absolute majority of work I’ve ever done. Servers, services, and web applications. If I were building large amounts of CLI tooling, I wouldn’t pick it. If I needed native desktop bindings, I wouldn’t pick it. But generally, I’m in the web application world.</p><p>As the cultural successor to Ruby on Rails, I am seeing Phoenix being used all over the place and quite popular with startups. I have seen a lot of companies picking up Elixir without necessarily knowing much about OTP. I think this is fine, and mostly speaks to the maturity of Phoenix and Ecto that people don’t need to.</p><h2 id="in-the-era-of-kubernetes-and-microservices-where-do-you-see-monolithic-beam-applications-fit-into-the-picture">In the era of Kubernetes and Microservices, where do you see monolithic BEAM applications fit into the picture?</h2><p><strong>Lars:</strong> It is interesting. The way Erlang structures things in multiple <em>applications</em> on a <em>node</em> as part of a <em>cluster</em> brings in some infrastructure concerns. I think some people worry that this unconventional approach is a problem when working in a polyglot environment, for example. I don’t think so. Lots of people put the BEAM in their containers and ship it out to the Kubernetes cluster in the same way as every other stack. Microservices tend to be about the contracts you expose, not the internals of how the application runs. Therefore, the fact you run a BEAM application or even a cluster of BEAM applications as one service is perfectly fine.</p><p>Where I believe much of the power of BEAM is though, is if you don’t rely on microservices and a polyglot-heavy environment. You might then be able to cut off a lot of dead weight. Or at least, manage the complexity using tools you know, rather than write YAML until it goes away. Some of the tools are there by design; others are perhaps, what we should be building in the future. I’ve gotten into it to some extent in my blog post <a href="https://underjord.io/the-beam-marches-forward.html"><em>The BEAM marches forward.</em></a></p><p><br>For an in-between path, I would take a look at <a href="https://www.nomadproject.io/">Nomad</a> which seems to be a slightly lighter Kubernetes competitor that can run things without containers. I think it suits the BEAM very well, as Elixir releases handle many of the perks of containerization. I haven’t tried it but if you do, let me know. I am curious about how Nomad differs from Kubernetes.</p><h2 id="as-someone-listening-to-podcasts-for-over-15-years-i-can-t-help-but-ask-how-does-one-get-the-courage-to-host-a-podcast">As someone listening to podcasts for over 15 years, I can’t help but ask. How does one get the courage to host a podcast?</h2><p><strong>Lars:</strong> I don’t think I’m particularly brave. You should see how uncomfortable I am on ladders.</p><p>I think I picked up a habit of pressing through discomfort partly in my teens and partly running a startup with a mentor of mine. When I was around 14, my dad passed away, essentially a heart attack out of the blue. That experience totally shifted my threshold for pain or discomfort and deeply changed how I approached life. That change in attitude was probably part of why I was keen to do the startup. And the startup led to everything else. Turns out that running a business when I barely knew what I was doing as a technical lead was a constant exercise in being okay with discomfort.</p><p>I don’t recommend overworking. I don’t recommend burning yourself out on a startup. Yet, the discomfort is part of the learning sometimes. If you spend a lot of time outside your comfort zone, you are likely to learn more. Being aware that you are choosing discomfort and staying with it is powerful.</p><p>Oh, a podcast? Well, you get asked on as a guest and enjoy it. And then, when the OG host goes off to start a new one, you get contacted as one of the potential new hosts. And since you try not to worry too much and are willing to tackle discomfort, you fret about it for a bit, ask too many questions, and then give it a shot.</p><p><strong>Lars:</strong> It might feel daunting at first. Don’t feel pressure to understand the BEAM, Erlang, OTP, and all of that good stuff right away. If you are an inexperienced developer, any language can seem imposing. We all end up being beginners when we move over to a new ecosystem. I think we will all be happier if we concede that we will not master everything and will only learn a portion of it. What one should focus on instead is building software well.</p></div>
    </div></div>]]>
            </description>
            <link>https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146798</guid>
            <pubDate>Thu, 19 Nov 2020 06:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RPC DRAM support in open source DRAM controller]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25145897">thread link</a>) | @pabs3
<br/>
November 18, 2020 | https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/ | <a href="https://web.archive.org/web/*/https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>
          <span>Published:</span>
          <time>Oct 28 2020</time>
        </p>
          <p>
            <span>Topics:</span>
            open hardware, open ASICs, open FPGA</p>
      </div><div>
        <p>The Internet of Things is one of the areas that is hugely benefiting from miniaturization of semiconductor technologies, as more computing power can be encapsulated into increasingly smaller devices. Shrinking in size and requiring less power, various devices - including AI-capable ones - are applied in ways that were not possible a few years ago. One of the new and exciting developments in this space is the emergence of <a href="https://etronamerica.com/products/rpc-dram/">RPC (reduced pin-count) DRAM</a> - a small form factor memory, for which Antmicro has developed support in the open source memory controller, LiteDRAM. Our contribution, already made available on <a href="https://github.com/antmicro/litedram/tree/rpc-dram-support">GitHub</a> is being polished and undergoing final tests, and will be mainlined shortly.</p>

<h3 id="what-is-rpc-dram">What is RPC DRAM</h3>

<p>Standard modern DRAM chips, with their small but not miniscule footprints and rather high I/O requirements, are impossible to use in space-constrained applications. By using a large number of pins in the device they connect to, they can also push the envelope of the device itself even more, requiring larger and more expensive packages of the FPGA or SoC used. <br>
And while many edge devices could easily do with a smaller amount (e.g. sub-1Gb) of RAM than what modern memory parts offer, it is impossible to cut a RAM chip in half and get less memory capacity. Well, at least until now - kind of.</p>

<p>The so-called RPC (Reduced Pin Count) DRAM - a new technology from Etron - has the potential to profoundly impact the AI, IoT and VR/AR markets. It is a tiny memory chip family which can get as small as 1.96mm x 4.63mm, offering 256Mbits and high bandwidth (the same as DDR3) using only 10% of the DDR3 PCB area and only half of the SoC or FPGA pins that the DDR3 memory takes up. Its clock speed can go up to 1200MHz, with bandwidth of up to 4800 Mb/s.</p>

<p><img src="https://antmicro.com/blog/images/LiteDRAM_with_RPC_RAM_blog-note.png" alt="DDR RAM and RPC DRAM comparison"></p>

<p>RPC DRAM is ideal for space-constrained edge AI applications that locally process data such as video, audio or image, where, apart from space saving, low power consumption is critical. The small number of pins used by RPC DRAM leaves more available resources for other system functionalities, while the possibility of stacking multiple RPC DRAM chips on top of one another for further layout optimization makes the technology even more appealing. It also enables interesting scenarios like <a href="https://antmicro.com/blog/2020/10/open-chiplet-initiative/#future-developments">embedding in a chiplet-based SiP</a>, or even bare-die integration with small FPGAs for a powerful, Linux-capable device. But to use the memory with FPGAs, you need to interface with it using a DRAM controller - and that is where our latest work with LiteDRAM comes in.</p>

<h3 id="litedram-and-open-source-ip-ecosystem">LiteDRAM and open source IP ecosystem</h3>

<p>LiteDRAM is a configurable memory controller that is part of LiteX, an open source SoC builder that we are developing and using to design FPGA-based systems. By creating support for RPC DRAM in LiteDRAM we have enabled the miniscule memory to be added to products that we build and to the whole LiteX ecosystem. This enables our customer’s devices to run more compute-hungry applications or full-fledged operating systems such as Linux in dedicated SoCs created by Antmicro on demand.</p>

<p>We use and contribute to LiteDRAM, LiteX and other open source IP to develop unique designs interfaced with DDR memories for high-bandwidth video and other data processing systems; and RPC DRAM support is just one example of the enablement work we are performing in the ecosystem. Combined with the exciting work related to open source we are performing as part of <a href="https://antmicro.com/blog/2020/07/swerv-cores-tools-ecosystem/">CHIPS Alliance</a>, <a href="https://antmicro.com/blog/2020/06/skywater-open-source-pdk/">SkyWater PDK</a> and the fantastic enregy catalyzed by the open <a href="https://antmicro.com/technologies/risc-v/">RISC-V</a> CPU architecture (which is an obvious candidate for combining with RPC RAM both in soft- and hard CPU contexts), future is looking bright for tiny, open, ML-capable systems.</p>

<h3 id="antmicros-open-source-fpga-ip">Antmicro’s open source FPGA IP</h3>

<p>We often use FPGAs to build a wide array of configurable systems for our customers, leveraging the flexibility and customizability that this technology offers. We create open source FPGA IPs that are reusable across various designs and platforms without any licensing restrictions imposed on our customers. Antmicro’s open source IP cores portfolio includes MIPI CSI, MIDI, PCIe, USB, Ethernet etc.</p>

<p>The FPGA systems that we build consist of modern, vendor-neutral components that ensure future-proofness and give our clients full control over the product. Reach out to us at <a href="mailto:contact@antmicro.com">contact@antmicro.com</a> if you’d like to get a specialized FPGA-based system performing complex tasks.</p>

      </div></div>]]>
            </description>
            <link>https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145897</guid>
            <pubDate>Thu, 19 Nov 2020 03:29:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AMD Announces New “Instinct MI100” GPU, Breaks the 10 Tflops Barrier in FP64]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25145600">thread link</a>) | @luord
<br/>
November 18, 2020 | https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/ | <a href="https://web.archive.org/web/*/https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content-area">
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/48301387cddb344c254ee94cde7f04d7/p/uploads/2020/11/db6591d4-1.png" alt="" width="700" height="313"></p>
<p>With the rising demand for HPC and AI-powered cloud applications comes a need for very powerful datacenter GPUs. Usually NVIDIA is the king of this field, but AMD’s latest MI100 GPU presents some serious competition.</p>
<h2 role="heading" aria-level="2">A Card For The HPC Market</h2>
<p>The card is fast, seriously fast. NVIDIA’s high end A100 GPU peaks at&nbsp;9.7 TFLOPS in FP64 workloads. The new “AMD Instinct MI100” leaps past that at 11.5 TFLOPS.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/2f6292f97a12046b544017f07246a4f8/p/uploads/2020/11/8d6e8097.png" alt="" width="700" height="312"></p>
<p>Of course, NVIDIA’s cards support other speedup techniques for AI-specific workloads in different number formats, such as the TensorFloat-32 precision format and<a href="https://www.cloudsavvyit.com/4796/nvidias-new-ampere-gpu-is-a-game-changer-for-artificial-intelligence/"> fine-grained structured sparsity</a>. For AI and Machine Learning workloads, NVIDIA is still king, as their cards are built specifically for tensor-based operations.</p>
<p>But, for general purpose High Performance Computing, the MI100 takes the crown for raw compute power. Plus, it’s nearly half the price, and is much more efficient per watt.</p>
<p>On top of the other improvements, the new architecture also brings mixed-precision improvements, with their “Matrix Core” technology delivering 7x greater FP16 performance compared to their prior generation of cards.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/6588bb99d6c97c60163b08630e9b8d86/p/uploads/2020/11/292c692b.png" alt="" width="700" height="216"></p>
<p>AMD CPUs and Instinct GPUS are <a href="https://www.olcf.ornl.gov/frontier/">both powering two of the US Department of Energy’s exascale supercomputers</a>. The “Frontier” supercomputer is planned to be built next year with current Epyc CPUs and MI100s, and will deliver more than 1.5 exaflops of peak computing power. The “El Capitan” supercomputer is planned to be built in 2023 on next gen hardware, and will deliver more than 2 exaflops of double precision power.</p>
<h2 role="heading" aria-level="2">Can ROCm Live Up to CUDA?</h2>
<p>Of course, all of this power is useless if the software doesn’t support it. It’s no secret that NVIDIA has managed to make machine learning a bit of a walled garden.</p>
<p>NVIDIA’s compute framework is called <a href="https://en.wikipedia.org/wiki/CUDA">CUDA</a>, or&nbsp;Compute Unified Device Architecture. It’s proprietary, and only works with their cards. But since their cards have historically been the fastest, many applications are only built with CUDA support first and foremost.</p>
<p>There are cross-platform programming models, most notably OpenCL, which AMD supports very well <a href="https://rocmdocs.amd.com/en/latest/">with their ROCm platform</a>. Both NVIDIA cards and AMD cards support OpenCL, but because NVIDIA only supports it by transpiling to CUDA, it’s actually slower to use OpenCL with an NVIDIA card. Because of this, not all applications will support it.</p>
<p>Ultimately, you’ll need to do your own research and see if the application you intend to run can be run on AMD cards, and maybe be prepared for some tinkering and bug fixing. NVIDIA GPUs on the otherhand are mostly plug and play, so even if AMD is faster, NVIDIA can continue to hinder them with closed-source software.</p>
<p>However, this situation is getting better—AMD is committed to open sourcing everything and creating an open environment. Tensorflow and PyTorch, two very popular ML frameworks, both support the ROCm ecosystem.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/03aae3c52689bd7fd58e8278df8fefac/p/uploads/2020/11/301c98b9.png" alt="" width="697" height="479"></p>
<p>Hopefully the raw specs of AMD’s latest offerings can push the industry to a more competitive environment. After all, they’re being put to use in supercomputers</p>
</div></div>]]>
            </description>
            <link>https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145600</guid>
            <pubDate>Thu, 19 Nov 2020 02:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Changes to the pip dependency resolver in 20.3]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25145396">thread link</a>) | @di
<br/>
November 18, 2020 | https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="user-guide">

<div id="running-pip">
<h2>Running pip<a href="#running-pip" title="Permalink to this headline">¶</a></h2>
<p>pip is a command line program. When you install pip, a <code><span>pip</span></code> command is added
to your system, which can be run from the command prompt as follows:</p>
<div>
<p><label for="tab-set--0-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>python</span> <span>-m</span> <span>pip</span></code> executes pip using the Python interpreter you
specified as python. So <code><span>/usr/bin/python3.7</span> <span>-m</span> <span>pip</span></code> means
you are executing pip for your interpreter located at /usr/bin/python3.7.</p>
</div>
<p><label for="tab-set--0-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>py</span> <span>-m</span> <span>pip</span></code> executes pip using the latest Python interpreter you
have installed. For more details, read the <a href="https://docs.python.org/3/using/windows.html#launcher">Python Windows launcher</a> docs.</p>
</div>
</div>
</div>
<div id="installing-packages">
<h2>Installing Packages<a href="#installing-packages" title="Permalink to this headline">¶</a></h2>
<p>pip supports installing from <a href="https://pypi.org/">PyPI</a>, version control, local projects, and
directly from distribution files.</p>
<p>The most common scenario is to install from <a href="https://pypi.org/">PyPI</a> using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirement-specifiers"><span>Requirement Specifiers</span></a></p>
<div>
<p><label for="tab-set--1-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage            <span># latest version</span>
python -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
python -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
<p><label for="tab-set--1-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage            <span># latest version</span>
py -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
py -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
</div>
<p>For more information and examples, see the <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> reference.</p>
</div>
<div id="basic-authentication-credentials">
<h2>Basic Authentication Credentials<a href="#basic-authentication-credentials" title="Permalink to this headline">¶</a></h2>
<p>pip supports basic authentication credentials. Basically, in the URL there is
a username and password separated by <code><span>:</span></code>.</p>
<p><code><span>https://[username[:password]@]pypi.company.com/simple</span></code></p>
<p>Certain special characters are not valid in the authentication part of URLs.
If the user or password part of your login credentials contain any of the
special characters
<a href="https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters">here</a>
then they must be percent-encoded. For example, for a
user with username “user” and password “he//o” accessing a repository at
pypi.company.com, the index URL with credentials would look like:</p>
<p><code><span>https://user:he%2F%2Fo@pypi.company.com</span></code></p>
<p>Support for percent-encoded authentication in index URLs was added in pip 10.0.0
(in <a href="https://github.com/pypa/pip/issues/3236">#3236</a>). Users that must use authentication
for their Python repository on systems with older pip versions should make the latest
get-pip.py available in their environment to bootstrap pip to a recent-enough version.</p>
<p>For indexes that only require single-part authentication tokens, provide the token
as the “username” and do not provide a password, for example -</p>
<p><code><span>https://0123456789abcdef@pypi.company.com</span></code></p>
<div id="netrc-support">
<h3>netrc Support<a href="#netrc-support" title="Permalink to this headline">¶</a></h3>
<p>If no credentials are part of the URL, pip will attempt to get authentication credentials
for the URL’s hostname from the user’s .netrc file. This behaviour comes from the underlying
use of <a href="https://requests.readthedocs.io/en/master/user/authentication/#netrc-authentication">requests</a> which in turn delegates it to the <a href="https://docs.python.org/3/library/netrc.html">Python standard library</a>.</p>
<p>The .netrc file contains login and initialization information used by the auto-login process.
It resides in the user’s home directory. The .netrc file format is simple. You specify lines
with a machine name and follow that with lines for the login and password that are
associated with that machine. Machine name is the hostname in your URL.</p>
<p>An example .netrc for the host example.com with a user named ‘daniel’, using the password
‘qwerty’ would look like:</p>
<div><div><pre><span></span>machine example.com
login daniel
password qwerty
</pre></div>
</div>
<p>As mentioned in the <a href="https://docs.python.org/3/library/netrc.html">standard library docs</a>,
only ASCII characters are allowed. Whitespace and non-printable characters are not allowed in passwords.</p>
</div>
<div id="keyring-support">
<h3>Keyring Support<a href="#keyring-support" title="Permalink to this headline">¶</a></h3>
<p>pip also supports credentials stored in your keyring using the <a href="https://pypi.org/project/keyring/">keyring</a>
library. Note that <code><span>keyring</span></code> will need to be installed separately, as pip
does not come with it included.</p>
<div><div><pre><span></span>pip install keyring
<span>echo</span> your-password <span>|</span> keyring <span>set</span> pypi.company.com your-username
pip install your-package --extra-index-url https://pypi.company.com/
</pre></div>
</div>
</div>
</div>
<div id="using-a-proxy-server">
<h2>Using a Proxy Server<a href="#using-a-proxy-server" title="Permalink to this headline">¶</a></h2>
<p>When installing packages from <a href="https://pypi.org/">PyPI</a>, pip requires internet access, which
in many corporate environments requires an outbound HTTP proxy server.</p>
<p>pip can be configured to connect through a proxy server in various ways:</p>
<ul>
<li><p>using the <code><span>--proxy</span></code> command-line option to specify a proxy in the form
<code><span>[user:passwd@]proxy.server:port</span></code></p></li>
<li><p>using <code><span>proxy</span></code> in a <a href="#config-file"><span>Config file</span></a></p></li>
<li><p>by setting the standard environment-variables <code><span>http_proxy</span></code>, <code><span>https_proxy</span></code>
and <code><span>no_proxy</span></code>.</p></li>
<li><p>using the environment variable <code><span>PIP_USER_AGENT_USER_DATA</span></code> to include
a JSON-encoded string in the user-agent variable used in pip’s requests.</p></li>
</ul>
</div>
<div id="requirements-files">
<h2>Requirements Files<a href="#requirements-files" title="Permalink to this headline">¶</a></h2>
<p>“Requirements files” are files containing a list of items to be
installed using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> like so:</p>
<div>
<p><label for="tab-set--2-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--2-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>Details on the format of the files are here: <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a>.</p>
<p>Logically, a Requirements file is just a list of <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> arguments
placed in a file. Note that you should not rely on the items in the file being
installed by pip in any particular order.</p>
<p>In practice, there are 4 common uses of Requirements files:</p>
<ol>
<li><p>Requirements files are used to hold the result from <a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a> for the
purpose of achieving <a href="#repeatability"><span>repeatable installations</span></a>.  In
this case, your requirement file contains a pinned version of everything that
was installed when <code><span>pip</span> <span>freeze</span></code> was run.</p>
<div>
<p><label for="tab-set--3-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip freeze &gt; requirements.txt
python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--3-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip freeze &gt; requirements.txt
py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
</li>
<li><p>Requirements files are used to force pip to properly resolve dependencies.
pip 20.2 and earlier <a href="https://github.com/pypa/pip/issues/988">doesn’t have true dependency resolution</a>, but instead simply uses the first
specification it finds for a project. E.g. if <code><span>pkg1</span></code> requires
<code><span>pkg3&gt;=1.0</span></code> and <code><span>pkg2</span></code> requires <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code>, and if <code><span>pkg1</span></code> is
resolved first, pip will only use <code><span>pkg3&gt;=1.0</span></code>, and could easily end up
installing a version of <code><span>pkg3</span></code> that conflicts with the needs of <code><span>pkg2</span></code>.
To solve this problem, you can place <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code> (i.e. the correct
specification) into your requirements file directly along with the other top
level requirements. Like so:</p>
<div><div><pre><span></span><span>pkg1</span>
<span>pkg2</span>
<span>pkg3</span><span>&gt;=</span><span>1.0</span><span>,</span><span>&lt;=</span><span>2.0</span>
</pre></div>
</div>
</li>
<li><p>Requirements files are used to force pip to install an alternate version of a
sub-dependency.  For example, suppose <code><span>ProjectA</span></code> in your requirements file
requires <code><span>ProjectB</span></code>, but the latest version (v1.3) has a bug, you can force
pip to accept earlier versions like so:</p>

</li>
<li><p>Requirements files are used to override a dependency with a local patch that
lives in version control.  For example, suppose a dependency
<code><span>SomeDependency</span></code> from PyPI has a bug, and you can’t wait for an upstream
fix.
You could clone/copy the src, make the fix, and place it in VCS with the tag
<code><span>sometag</span></code>.  You’d reference it in your requirements file with a line like
so:</p>
<div><div><pre><span></span><span>git</span><span>+</span><span>https</span><span>:</span><span>//</span><span>myvcs</span><span>.</span><span>com</span><span>/</span><span>some_dependency</span><span>@sometag</span><span>#egg=SomeDependency</span>
</pre></div>
</div>
<p>If <code><span>SomeDependency</span></code> was previously a top-level requirement in your
requirements file, then <strong>replace</strong> that line with the new line. If
<code><span>SomeDependency</span></code> is a sub-dependency, then <strong>add</strong> the new line.</p>
</li>
</ol>
<p>It’s important to be clear that pip determines package dependencies using
<a href="https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-dependencies">install_requires metadata</a>,
not by discovering <code><span>requirements.txt</span></code> files embedded in projects.</p>
<p>See also:</p>
<ul>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a></p></li>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a></p></li>
<li><p><a href="https://caremad.io/2013/07/setup-vs-requirement/">“setup.py vs requirements.txt” (an article by Donald Stufft)</a></p></li>
</ul>
</div>
<div id="constraints-files">
<h2>Constraints Files<a href="#constraints-files" title="Permalink to this headline">¶</a></h2>
<p>Constraints files are requirements files that only control which version of a
requirement is installed, not whether it is installed or not. Their syntax and
contents is nearly identical to <a href="#requirements-files"><span>Requirements Files</span></a>. There is one key
difference: Including a package in a constraints file does not trigger
installation of the package.</p>
<p>Use a constraints file like so:</p>
<div>
<p><label for="tab-set--4-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -c constraints.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--4-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -c constraints.txt
</pre></div>
</div>
</div>
</div>
<p>Constraints files are used for exactly the same reason as requirements files
when you don’t know exactly what things you want to install. For instance, say
that the “helloworld” package doesn’t work in your environment, so you have a
local patched version. Some things you install depend on “helloworld”, and some
don’t.</p>
<p>One way to ensure that the patched version is used consistently is to
manually audit the dependencies of everything you install, and if “helloworld”
is present, write a requirements file to use when installing that thing.</p>
<p>Constraints files offer a better way: write a single constraints file for your
organisation and use that everywhere. If the thing being installed requires
“helloworld” to be installed, your fixed version specified in your constraints
file will be used.</p>
<p>Constraints file support was added in pip 7.1. In <a href="#resolver-changes-2020"><span>Changes to the pip dependency resolver in 20.3 (2020)</span></a> we did a fairly comprehensive overhaul, removing several
undocumented and unsupported quirks from the previous implementation,
and stripped constraints files down to being purely a way to specify
global (version) limits for packages.</p>
</div>
<div id="installing-from-wheels">
<h2>Installing from Wheels<a href="#installing-from-wheels" title="Permalink to this headline">¶</a></h2>
<p>“Wheel” is a built, archive format that can greatly speed installation compared
to building and installing from source archives. For more information, see the
<a href="https://wheel.readthedocs.io/">Wheel docs</a> , <span id="index-0"></span><a href="https://www.python.org/dev/peps/pep-0427"><strong>PEP 427</strong></a>, and <span id="index-1"></span><a href="https://www.python.org/dev/peps/pep-0425"><strong>PEP 425</strong></a>.</p>
<p>pip prefers Wheels where they are available. To disable this, use the
<a href="https://pip.pypa.io/en/latest/reference/pip_install/#install-no-binary"><span>--no-binary</span></a> flag for <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a>.</p>
<p>If no satisfactory wheels are found, pip will default to finding source
archives.</p>
<p>To install directly from a wheel archive:</p>
<div>
<p><label for="tab-set--5-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
<p><label for="tab-set--5-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
</div>
<p>For the cases where wheels are not available, pip offers <a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> as a
convenience, to build wheels for all your requirements and dependencies.</p>
<p><a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> requires the <a href="https://pypi.org/project/wheel/">wheel package</a> to be installed, which provides the
“bdist_wheel” setuptools extension that it uses.</p>
<p>To build wheels for your requirements and all their dependencies to a local
directory:</p>
<div>
<p><label for="tab-set--6-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install wheel
python -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--6-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install wheel
py -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>And <em>then</em> to install those requirements just using your local directory of
wheels (and not from PyPI):</p>
<div>
<p><label for="tab-set--7-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install --no-index --find-links<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--7-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install --no-index --find-links<span>=</span>…</pre></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</a></em></p>]]>
            </description>
            <link>https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145396</guid>
            <pubDate>Thu, 19 Nov 2020 02:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome ‘Bug’ Exempts Google Cookies from Data Privacy Settings]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25143814">thread link</a>) | @betaman0
<br/>
November 18, 2020 | https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/ | <a href="https://web.archive.org/web/*/https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-342">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/pexels-deepanker-verma-1482061-1080x540.jpg" alt="" loading="lazy">		</figure>

		
	
<div>

	<h4>A programmer named <a href="https://lapcatsoftware.com/articles/chrome-google.html" target="_blank" rel="noopener noreferrer">Jeff Johnson</a> recently discovered that enabling the “Clear cookies and site data when you quit Chrome” meant Google Search and YouTube cookies were not deleted, and exempt from this rule.</h4>
<p>He found that the only way to include Google and YouTube cookies for clearing is to specifically add <code>google.com</code> and <code>youtube.com</code> to <em>sites that can never use cookies</em> – it is not made obvious to the user that Google’s own services are exempt from the cookie clearing rule by default. <em>(<a href="https://lapcatsoftware.com/articles/chrome-google.html" target="_blank" rel="noopener noreferrer">source</a>)</em></p>
<p>Furthermore, <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/google-privacy-chrome-youtube-search-bug-b1180705.html" target="_blank" rel="noopener noreferrer"><em>The Independent</em></a> investigated this issue and found similar results.</p>
<p>Google was made aware of this issue, and a Google spokesperson issued the following statement:</p>
<blockquote><p>“We are aware of a bug in Chrome that is impacting how cookies are cleared on some first-party Google websites. We are investigating the issue, and plan to roll out a fix in the coming days.” (<a href="https://www.theregister.com/2020/10/19/google_cookie_wipe/" target="_blank" rel="noopener noreferrer">source</a>)<em><br>
</em></p></blockquote>
<hr>
<p><em><strong>Author’s Note:</strong> Google has a <a href="https://en.wikipedia.org/wiki/Privacy_concerns_regarding_Google" target="_blank" rel="noopener noreferrer">long history of privacy violations</a>, which is one of the primary reasons I recommend finding ways to become less reliant on their services. A good first step would be to replace Chrome with <a href="https://www.mozilla.org/en-US/firefox/new/?redirect_source=firefox-com" target="_blank" rel="noopener noreferrer">Firefox</a>, and from there, looking to replace Google Search with <a href="https://duckduckgo.com/" target="_blank" rel="noopener noreferrer">DuckDuckGo</a> or <a href="https://startpage.com/" target="_blank" rel="noopener noreferrer">Startpage</a>.</em></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I’m an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I’m also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25143814</guid>
            <pubDate>Wed, 18 Nov 2020 23:02:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple's 15% Deflection Tactic]]>
            </title>
            <description>
<![CDATA[
Score 584 | Comments 454 (<a href="https://news.ycombinator.com/item?id=25143303">thread link</a>) | @lux
<br/>
November 18, 2020 | https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/ | <a href="https://web.archive.org/web/*/https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="app" data-v-8769139c=""><div data-v-8769139c=""><div data-v-8769139c=""><div data-v-8769139c=""><blockquote>
<p>This post is in response to <a href="https://www.apple.com/newsroom/2020/11/apple-announces-app-store-small-business-program/" target="_blank" rel="nofollow noopener noreferrer">Apple’s App Store Small Business Program announcement</a>.</p>
</blockquote>
<p>For decades, developers were able to create and distribute their software, whether free or for a fee, to anyone with a PC or laptop. There was no gatekeeper deciding who was in or out, and there was no requirement that they hand over a significant percentage of their revenue to the device maker.</p>
<p>Video game consoles were the obvious exception to this, with the claim that they were specialized devices and, therefore, closed ecosystems. But personal computing was open, and that was an important catalyst for innovation for a long time.</p>
<p>That changed with the introduction of Apple's app store on iOS. Developers had to be approved by Apple, and had to agree to use Apple as their sole payment processor, to the tune of $99/year and 30% of their revenue. For contrast, payment processors at the time were charging around 2.9% and $0.30/transaction. That's a massive difference in and of itself.</p>
<blockquote>
<p>The 30% number was based on what video game consoles were charging developers.</p>
</blockquote>
<h2 id="apples-original-rationale">Apple's original rationale</h2>
<p>Apple's argument for the iPhone being a closed ecosystem was that a phone is a specialized device because its primary function is to make phone calls, and that primary function must be protected against rogue software that may disrupt its ability to make those calls.</p>
<p>Apple's argument that the 30% fee was fair was that it takes manpower to review and approve apps to be listed on their store.</p>
<h2 id="ripples-into-other-app-stores">Ripples into other app stores</h2>
<p>The issue grew bigger as Google implemented similar requirements and fee structures on the Android app store, and pretty much every app store from Steam to Samsung Galaxy followed suit.</p>
<p>Now that Microsoft and Apple have introduced app stores on Windows and macOS, they plan to slowly erode our freedom on PCs too so that they can reap the same financial benefits on our labour on all computing platforms (save for open source operating systems like Linux). Apple has since added warning messages discouraging users not to install third party software that hasn't paid for Apple's signature of approval. These warnings are getting more and more alarming with each OS upgrade, causing users to fear installing third party software through other, traditional means.</p>
<p>This needs to be stopped now because device makers are making the case that future devices like VR and AR headsets are also specialized devices and so they too should be subject to the same closed ecosystem and payment processing restrictions, which is simply untrue.</p>
<p>If an AR device replaces your PC, it's a generalized computing device, plain and simple.</p>
<h2 id="phones-are-not-specialized-computing-devices">Phones are not specialized computing devices</h2>
<p>Making phone calls was the sole function of a telephone, but a mobile phone is a powerful computer that can perform a wide range of functions. The new iPhone 12 Pro has built-in Lidar, a total of 4 cameras, GPS, and many other features that extend far being making phone calls.</p>
<p>What was once a primary feature is now just one of thousands, and potentially one of its least important features as we have dozens or more options for voice, video, and text-based messaging available to us. Many young people would probably be just fine on an iPod Touch that doesn't make calls at all, and many probably wouldn't know the difference.</p>
<p>Phones are general computing devices, and as such, should not be maintained as closed ecosystems. This doesn't benefit users, many of whom are also developers themselves, because it limits our freedom on both sides of the equation. General computing platforms should be protected from such predatory practices by manufacturers through strong government regulations.</p>
<h2 id="the-fee-isnt-the-issue-the-requirement-to-pay-is">The fee isn't the issue, the requirement to pay is</h2>
<p>Tying your right distribute an app that you developed independently of the hardware maker to the requirement to use their payment processor is anti-competitive because it means that every developer benefits the hardware maker while the hardware maker provides little more than a gatekeeper function and a small amount of file storage for their release builds.</p>
<p>How can any indie developer hope to compete with the likes of Apple or Google or Microsoft when every sale they make gives 15% of their profits over to their competition? And if they make more than $1m, it goes back up to 30%. That's a huge disparity that serves to protect the interests of the hardware maker at the expense of businesses everywhere.</p>
<p>If there was a hard cost for Apple and others to review and approve apps, then that should be charged up-front and not as a percentage of profit. Developers should be free to choose the payment processing service that best serves their needs, whether that's Stripe or Paypal or Apple's built-in offering. Apple's payment processor should be chosen because it's better, not because you have no other choice.</p>
<h2 id="disproportionate-profits">Disproportionate profits</h2>
<p>Since the cost of the review process and hosting are the justification for the payment processing fees, a good way to tell if they're in line with each other is to look at Apple's profits on the app store. In 2019, Apple generated about <a href="https://www.cnbc.com/2020/01/07/apple-app-store-had-estimated-gross-sales-of-50-billion-in-2019.html" target="_blank" rel="nofollow noopener noreferrer">$50bn in sales on the iOS app store</a>, with their take being about <strong>$15bn in profit</strong>.</p>
<p>Does it really cost Apple anywhere close to $15bn/year to maintain the app store's review process and hosting infrastructure?</p>
<h2 id="this-makes-some-business-models-unfeasible">This makes some business models unfeasible</h2>
<p>Some business models, like establishing a marketplace for content creators to share their work with each other, become unfeasible when 15-30% off the top goes straight to the device maker. Many businesses operate with profit margins well under 30% or even 15%. Amazon is widely known for maintaining a 1% profit margin across their entire business as a strategic advantage to be able to undercut everyone else.</p>
<p>Other payment processors are essentially locked out of these ecosystems entirely, which is unfair and anti-competitive against them. I bet Stripe would love to be able to provide a better mobile payment option – their core business – without Apple being such a significant portion of the sale, thereby negating any benefit that Stripe on its own can differentiate itself with.</p>
<h2 id="this-is-not-just-a-problem-for-developers">This is not just a "problem for developers"</h2>
<p>I've seen many comments on sites like Hacker News and MacRumours that this isn't a problem users should care about and that developers should essentially stop whining or take their software elsewhere. But this also limits the choices users have, and it limits the types of apps they get to benefit from. This limitation won't be felt directly, because you don't feel the absence of something you never knew you could have. <em>You don't know what you don't know.</em></p>
<p>Stifling innovation isn't good for anyone, and as more and more people become software developers, this really just hurts the small guys. The indies who are more similar in size and need to average consumers than the likes of tech giants like Apple or Google. Indie developers need protection from monopolistic and anti-competitive practices from larger players in the market through strong government regulation, not a discount on their first $1m in sales.</p>
<h2 id="this-model-is-being-replicated-in-vr-and-ar">This model is being replicated in VR and AR</h2>
<p>It's no secret that I work in Virtual Reality. In fact, writing this gives me some anxiety because my company could be targeted and harmed for me saying things that don't benefit the VR headset makers. <em>But this needs to be said.</em> In fact, I'd say this is one of the most important fights in the software industry today because it will determine whether future platforms are open or closed.</p>
<p>VR headsets have already been set up to be <a href="https://searchsecurity.techtarget.com/definition/walled-garden" target="_blank" rel="nofollow noopener noreferrer">walled gardens</a>, and although Oculus has turned a blind eye for the time being to third party app stores like <a href="https://sidequestvr.com/" target="_blank" rel="nofollow noopener noreferrer">SideQuest</a>, they could still decide to cut it off at any point in the future with little or no recourse.</p>
<p>Whether third party app stores are the solution also remains to be seen, but gauging by how difficult device makers make it for average users to install them, and what little percentage market share they have on each respective platform, I'd say they don't go far enough to solve this problem.</p>
<p>The ability to easily <a href="https://en.wikipedia.org/wiki/Sideloading" target="_blank" rel="nofollow noopener noreferrer">sideload</a>, aka install software directly onto a device that you own and not through any given app store, is paramount to maintaining free access to today's as well as tomorrow's computing platforms. And we should have the ability to do so without navigating a maze of warnings discouraging the average user from doing so.</p>
<h2 id="pcs-will-become-headsets-which-are-general-computing-devices">PCs will become headsets, which are general computing devices</h2>
<p>Augmented Reality is still in its infancy and isn't a general computing platform yet, not because it's specialized but because the technology isn't of sufficient quality yet. But it's improving rapidly, and one day it will be good enough to overtake both PCs and phones as the dominant computing platform of the future.</p>
<p>When it does, it will be critical to indie developers everywhere that we maintain the same level of freedom on these future platforms that we enjoy today on PCs, and stop the current erosion of those freedoms by big tech companies. Failure to do so will close off all software that isn't blessed by device makers, which will further increase the financial divide between indie developers and the companies who will control the platforms of the future, whether that's Apple, Google, Microsoft, or Facebook. <em>We can't let that happen.</em></p>
<h2 id="whats-the-solution">What's the solution?</h2>
<p>The solution is simple and threefold:</p>
<ol>
<li>Mobile phones and headset-based computing devices should be classified as general computing platforms in the eyes of the law.</li>
<li>General computing platforms should have the legal requirement that developers can distribute their software however they see fit, so long as it doesn't harm users (malware, spyware, etc.).</li>
<li>Choice of payment processors should not be forced on developers in exchange for the ability to distribute software on any general computing platform.</li>
</ol>
<p>Only when the above rights have been won in the eyes of the law will our fight be over on this front, but there will always be other …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/">https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/</a></em></p>]]>
            </description>
            <link>https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25143303</guid>
            <pubDate>Wed, 18 Nov 2020 22:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Letter from Facebook Content Moderators]]>
            </title>
            <description>
<![CDATA[
Score 358 | Comments 202 (<a href="https://news.ycombinator.com/item?id=25142657">thread link</a>) | @ynac
<br/>
November 18, 2020 | https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic | <a href="https://web.archive.org/web/*/https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-layout-label="Post Body" data-type="item" data-updated-on="1605716470576" id="item-5fb548adc77fc917bd132369"><div><div><div data-block-type="2" id="block-5e3e902ee21503131a93"><div><p><em>Foxglove is supporting social media content moderators in their fights for fair treatment from the platforms they work for, and for safe working conditions during the pandemic. Here is the full text of an open letter which over 200 Facebook content moderators from across the world have just addressed to Facebook’s leaders:</em></p><p><strong>November 2020</strong></p><p><strong>Mark Zuckerberg <br>Sheryl Sandberg <br>Anne Heraty (CEO, CPL/Covalen) <br>Julie Sweet (CEO, Accenture) <p>Via email and posting on Facebook’s Workplace channels </p></strong></p><div><p><strong>Open letter from content moderators re: pandemic <br></strong><br>Dear Mr. Zuckerberg, Ms. Sandberg, Ms. Heraty, Ms. Sweet </p><p>We, the undersigned Facebook content moderators and Facebook employees, write to express our dismay at your decision to risk our lives—and the lives of our colleagues and loved ones—to maintain Facebook’s profits during the pandemic. </p></div><p>After months of allowing content moderators to work from home, faced with intense pressure to keep Facebook free of hate and disinformation, you have forced us back to the office. Moderators who secure a doctors’ note about a personal COVID risk have been excused from attending in person.[1] Moderators with vulnerable relatives, who might die were they to contract COVID from us, have not. </p><p>The pandemic has been good for Facebook. More than 3 billion people have now joined Facebook services, creating more demand for our work than ever.[2] Mr. Zuckerberg nearly doubled his fortune during the crisis.[3] He is now worth well over $100 billion. It has been good for Facebook’s contractors, too: CPL, one of the main European contractors, is due to be sold for €318m.[4] </p><p>Despite vast sums flowing to each of you as corporate executives, you have refused moderators hazard pay. A content moderator at Accenture’s office in Austin, Texas generally earns $18/hour[5]. </p><p>Before the pandemic, content moderation was easily Facebook’s most brutal job. We waded through violence and child abuse for hours on end. Moderators working on child abuse content had targets increased during the pandemic, with no additional support. </p><p>Now, on top of work that is psychologically toxic, holding onto the job means walking into a hot zone. In several offices, multiple COVID cases have occurred on the floor.[6] Workers have asked Facebook leadership, and the leadership of your outsourcing firms like Accenture and CPL, to take urgent steps to protect us and value our work. You refused. We are publishing this letter because we are left with no choice. </p><p>Stop Needlessly Risking Moderators’ Lives </p><p>It is important to explain that the reason you have chosen to risk our lives is that this year Facebook tried using ‘AI’ to moderate content—and failed.[7] </p><p>At the start of the pandemic, both full-time Facebook staff and content moderators worked from home. To cover the pressing need to moderate the masses of violence, hate, terrorism, child abuse, and other horrors that we fight for you every day, you sought to substitute our work with the work of a machine. </p><p>Without informing the public, Facebook undertook a massive live experiment in heavily automated content moderation. Management told moderators that we should no longer see certain varieties of toxic content coming up in the review tool from which we work— such as graphic violence or child abuse, for example. </p><p>The AI wasn’t up to the job. Important speech got swept into the maw of the Facebook filter—and risky content, like self-harm, stayed up. </p><p>The lesson is clear. Facebook’s algorithms are years away from achieving the necessary level of sophistication to moderate content automatically. They may never get there. </p><p>This raises a stark question. If our work is so core to Facebook’s business that you will ask us to risk our lives in the name of Facebook’s community—and profit—are we not, in fact, the heart of your company? </p><p>Without our work, Facebook is unusable. Its empire collapses. Your algorithms cannot spot satire. They cannot sift journalism from disinformation. They cannot respond quickly enough to self-harm or child abuse. We can. </p><p>Facebook needs us. It is time that you acknowledged this and valued our work. To sacrifice our health and safety for profit is immoral. </p><p>These are our demands. </p><p>1. Keep moderators and their families safe. At the moment, only individual content moderators with a doctors’ note indicating that they are high risk are excused from working in the office. Even this is not offered in some workplaces. Those who live with an at-risk person – who have, for example, a child with epilepsy – have been forced to come in. All content moderators who are high risk or who live with someone who is high risk for Covid should be permitted to work from home indefinitely. </p><p>2. Maximize at-home working. Work that can be done from home should continue to be done from home. You have previously said content moderation cannot be performed remotely for security reasons. If that is so, it is time to fundamentally change the way that the work is organized. There is a pervasive and needlessly secretive culture at Facebook. Some content, such as content that is criminal, may need to be moderated in Facebook offices. The rest should be done at home. </p><p>3. Offer hazard pay. If you want moderators to risk their lives to maintain ‘community’ and profit, you should pay. Moderators who are working in the office on high-risk material (eg, child abuse) should be paid hazard pay of 1.5x their usual wage. </p><p>4. End outsourcing. There is, if anything, more clamor than ever for aggressive content moderation at Facebook. This requires our work. Facebook should bring the content moderation workforce in house, giving us the same rights and benefits as full Facebook staff. </p><p>5. Offer real healthcare and psychiatric care. Facebook employees enjoy various benefits, including private health insurance and visits to psychiatrists. Content moderators, who bear the brunt of the mental health trauma associated with Facebook’s toxic content, are offered 45 minutes a week with a ‘wellness coach’. These ‘coaches’ are generally not psychologists or psychiatrists and are contractually forbidden from diagnosis or treatment. And they generally cannot build a relationship of trust with moderators, since workers know that Facebook management (and Accenture/CPL management) ask ‘coaches’ to reveal confidential details of counselling sessions. Moderators deserve at least as much mental and physical health support as full Facebook staff. </p><p>The current crisis highlights that at the core of Facebook’s business lies a deep hypocrisy. By outsourcing our jobs, Facebook implies that the 35,000 of us who work in moderation are somehow peripheral to social media. Yet we are so integral to Facebook’s viability that we must risk our lives to come into work. </p><p>It is time to reorganize Facebook’s moderation work on the basis of equality and justice. We are the core of Facebook’s business. We deserve the rights and benefits of full Facebook staff. We look forward to your public response. </p><p>Very sincerely yours, </p><ul data-rte-list="default"><li><p>Andrea</p></li><li><p>Angela De Hoyos Hart</p></li><li><p>Ani Niow</p></li><li><p>Audrey Martin</p></li><li><p>Aune Mitchell</p></li><li><p>Azer Gueco</p></li><li><p>Baris Aytan</p></li><li><p>Brady Bennett</p></li><li><p>Cam Herringshaw</p></li><li><p>Carlin Scrudato</p></li><li><p>Carlos Ancira</p></li><li><p>Charles Maxwell</p></li><li><p>Chris Chan</p></li><li><p>Christopher Glenn</p></li><li><p>Claire Sexton</p></li><li><p>Crystal Chan</p></li><li><p>Danica Michaels</p></li><li><p>Daniel Baxley</p></li><li><p>Daniel Finlayson</p></li><li><p>Daniel Rezende Fuser</p></li><li><p>Danille Sindac</p></li><li><p>Diego Ramirez</p></li><li><p>Dominick Martinez</p></li><li><p>Douglas Hart</p></li><li><p>Erin Donohue</p></li><li><p>Fletcher West</p></li><li><p>Hua Hoai Nam</p></li><li><p>James J. Morrow</p></li><li><p>Jeremy Calvert</p></li><li><p>Jess L</p></li><li><p>Jessica den Boer</p></li><li><p>John Reese</p></li><li><p>John Royales McTurk</p></li><li><p>Jonathan Daniel</p></li><li><p>Jonathan de la Rosa</p></li><li><p>Joseph Pouttu</p></li><li><p>Joseph Sarhan</p></li><li><p>Joshua Sklar</p></li><li><p>Katie Adamsky</p></li><li><p>Kelly Lambert</p></li><li><p>Kevin Fei</p></li><li><p>Kevin Liao</p></li><li><p>Kiara Gaytan</p></li><li><p>Lucy Yang</p></li><li><p>Marcus Rodriguez</p></li><li><p>Maria Sam</p></li><li><p>Mark Reitblatt</p></li><li><p>Mayra Ota Coffey</p></li><li><p>Michael Thot</p></li><li><p>Mike Vitousek</p></li><li><p>Naomi Shiffman</p></li><li><p>Nathan Tokala</p></li><li><p>Niccolo Coluccio</p></li><li><p>Nicholas O'Brien</p></li><li><p>Nick Azcarate</p></li><li><p>Nick Martens</p></li><li><p>Noah Korotzer</p></li><li><p>Nuno Picareta</p></li><li><p>Palina Andrayuk </p></li><li><p>Phil Wills</p></li><li><p>Phillip Shih</p></li><li><p>Phong Vu</p></li><li><p>Purnam Jantrania</p></li><li><p>Raimonds Gabalis</p></li><li><p>Ramazan Sahin</p></li><li><p>Rena</p></li><li><p>Robert Boyce</p></li><li><p>Ryan Hoyt</p></li><li><p>Sam Ringel</p></li><li><p>Sara Valderrama</p></li><li><p>Sarah Dunn</p></li><li><p>Shom Mazumder</p></li><li><p>Steffan Voges</p></li><li><p>Stephanie Marina</p></li><li><p>Stuart Millican</p></li><li><p>Tariq Yusuf</p></li><li><p>Thi Cat Tuong Trinh</p></li><li><p>Tina Wall</p></li><li><p>Tom G</p></li><li><p>Tristam MacDonald</p></li><li><p>Vahid Liaghat</p></li><li><p>Vitor Cordeiro Pileggi</p></li><li><p>Zoya Waliany</p></li><li><p><em>(and a further  248 content moderators who’ve signed anonymously)</em></p></li></ul><p><br>[1] <a href="https://www.vice.com/en/article/z3vvv9/leaked-audio-facebook-moderators-terrifiedto-return-to-office-during-covid-outbreak">https://www.vice.com/en/article/z3vvv9/leaked-audio-facebook-moderators-terrifiedto-return-to-office-during-covid-outbreak </a><br>[2] <a href="https://www.vox.com/2020/4/29/21241601/facebook-coronavirus-pandemic-usersadvertising-growth-making-losing-money-users-q1-2020-earnings">https://www.vox.com/2020/4/29/21241601/facebook-coronavirus-pandemic-usersadvertising-growth-making-losing-money-users-q1-2020-earnings </a><br>[3] <a href="https://www.theguardian.com/business/2020/sep/17/wealth-of-us-billionaires-rises-bynearly-a-third-during-pandemic">https://www.theguardian.com/business/2020/sep/17/wealth-of-us-billionaires-rises-bynearly-a-third-during-pandemic </a><br>[4] <a href="https://www.irishtimes.com/business/retail-and-services/cpl-agrees-318m-takeover-byjapan-s-outsourcing-inc-1.4399832">https://www.irishtimes.com/business/retail-and-services/cpl-agrees-318m-takeover-byjapan-s-outsourcing-inc-1.4399832</a> <br>[5] <a href="https://www.glassdoor.co.uk/Salaries/austin-content-moderator-salarySRCH_IL.0,6_IM60_KO7,24.htm">https://www.glassdoor.co.uk/Salaries/austin-content-moderator-salarySRCH_IL.0,6_IM60_KO7,24.htm </a><br>[6]<a href="https://theintercept.com/2020/10/20/facebook-coronavuris-content-moderatoraccenture/"> https://theintercept.com/2020/10/20/facebook-coronavuris-content-moderatoraccenture/ </a><br>[7] <a href="https://www.politico.eu/article/facebook-content-moderation-automation">https://www.politico.eu/article/facebook-content-moderation-automation</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25142657</guid>
            <pubDate>Wed, 18 Nov 2020 21:27:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue vs React: Best Choice for Startups]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25141661">thread link</a>) | @morchen
<br/>
November 18, 2020 | https://swimm.io/blog/vue-vs-react-best-choice-for-startups/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/vue-vs-react-best-choice-for-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>A former front-end student of mine (Zoe*) recently emailed me, and honestly wanted to understand why is it that I chose to code <a href="http://swimm.io/">Swimm</a>, with Vue.Js and not React:</p>
<blockquote>
<p>“I just have one question for you: Why Vue?[...] I hope you're not rolling your eyes thinking - “ah no, another question about Vue”. Although knowing you and your passion, I'm sure you have a pretty strong opinion that could swallow me into becoming a Vue fan without even knowing it.”</p>
</blockquote>
<p>Vue.js gained a reputation in recent years as an edgy must-know framework, but developers often question what the hype is about, how it relates to them and what web framework they should choose for their product.</p>
<p>While there might be some over-hype around the expected <a href="https://madewithvuejs.com/blog/vue-3-roundup#:~:text=Vue%203%20release%20date,2020%2C%20according%20to%20the%20roadmap.">Vue 3 release due in Q3 2020</a>, Vue has been gaining traction for a few years now, and it was just a matter of time for <a href="https://www.netguru.com/blog/13-top-companies-that-have-trusted-vue.js-examples-of-applications">bigger companies</a> like Netflix, Behance, Grammarly, Alibibaba, GitLab and others, to pick it up. Yet according to <a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-web-frameworks-wanted2">Stackoverflow’s 2020 developer</a> React.js is still the most wanted web framework (Vue.js coming in second).</p>
<h3>Vue.js vs React In a Nutshell</h3>
<p>I first used Vue at <a href="https://www.imcreator.com/">IM Creator</a>, a product I co-built originally with JQuery, and Vue was a breath of crisp air in my face. It was user friendly and progressive as it enabled me to use the framework for specific parts each time, without huge migrations. I could then for example create a menu in Vue, while the rest remained in legacy JQuery. What’s there not to like?</p>
<p>With Swimm (a new dev tool product) it wasn't even a question. I started our PoC with Vue.js and continued since then to our Beta self-served version. Several benefits should speak volumes to Startups these days especially compared to React:</p>
<ul>
<li><strong>Vue is Lightweight and Flexible</strong>. It means it's a framework that feels more like a library than a framework at all. You can try it out first in small use cases in your app before going all-in.</li>
<li><strong>Vue is less intrusive than React</strong> and much easier to onboard. Project components and structure in Vue are similar whie projects in React each vary in architecture and implementation. I find that you can recognize Vue structures easily which is what speeds up onboarding time for any developer learning a new codebase. Vue becomes easier to maintain. This is especially true for smaller products.</li>
<li><strong>Readability is key</strong> - Vue is based on the most basic principles of the Web and is more readable than React. The html/css and JS are separate while in React everything is in JS.</li>
<li><strong>Indie at its core</strong>. While it’s my personal opinion, many developers appreciate tools that are not backed by tech giants (for example React backed by Facebook, and Angular by Google), but rather grows from a community and that is why it is highly oriented to developer needs.</li>
</ul>
<h3>When does React Trump Vue.js:</h3>
<ul>
<li><strong>React is still most wanted by the industry</strong>. That can be a problem for new coders. From my recent experience recruiting for Swimm’s growing dev team, Vue is still harder to recruit for because of React’s persistent popularity. <strong>By the same token</strong>, even if many of the larger companies are picking it up, it’s still part of side projects and not the main product. This is why for the <a href="https://www.itc.tech/">ITC.tech</a> web-dev Bootcamp, I created a React-based curriculum.</li>
<li><strong>Flexibility in some aspects</strong>. React still has the ability to split between the visibility of a component and maintenance of the component - and still provides more flexibility.</li>
<li><strong>Docs are light years ahead</strong>. The features Release in React is fast paced and as React docs are extensive and elaborate. [Try skimming through all of the 500 pages of questions on React on Stackoverflow].</li>
</ul>
<h3><strong>To Sum it Up: A Note to Zoe</strong></h3>
<blockquote>
<p>“ Hi Zoë,</p>
<p>I chose Vue for many reasons.</p>
<p>It is easy to integrate into existing projects (That was my need the first time I used Vue)</p>
<p>It is has a more readable syntax</p>
<p>It's really reactive (no need to explicitly call the set function)</p>
<p>It is not maintained by a big company (Facebook / Google)[...]</p>
<p>Give it a try :)”</p>
</blockquote>
<p>Of course there is always a trade-off. These lessons learned reflect my personal views, insight gained from working in various startups and alongside numerous tech clients. As always, <a href="https://www.mindk.com/blog/react-vs-vue/">in depth research</a> is required to make sure which framework best suits your business case. But if you’re looking for a flexible  non-enterprise solution, Vue has proved easy to learn, scalable, user-friendly backed by a solid community that caters to other developers.</p>
<p>...</p>
<p>* Thanks for the inquisitive question, <a href="https://www.linkedin.com/in/zo%C3%ABcohen/">Zoe Cohen</a>.</p>
<p><strong>About Author:</strong></p>
<p><a href="https://www.linkedin.com/in/gilad-navot/">Gilad Navot</a> is Co-Founder and CPO at Swimm. Previously VP R&amp;D at <a href="https://www.imcreator.com/">IM Creator</a>, and was part of the founding <a href="https://www.itc.tech/">ITC.tech</a> team teaching front-end development to hundreds of students around the world.</p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/vue-vs-react-best-choice-for-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141661</guid>
            <pubDate>Wed, 18 Nov 2020 19:57:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I compiled all blog posts I read in past six months to learn product management]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25141437">thread link</a>) | @soorajchandran
<br/>
November 18, 2020 | https://sooraj.io/product-management-for-engineers/ | <a href="https://web.archive.org/web/*/https://sooraj.io/product-management-for-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-206" class="page">
	<div>
		<!-- .entry-header -->

		<div>
			
<p>A few months ago, the company I co-founded&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://money.yahoo.com/oyster-acquires-carrom-accelerate-global-100000172.html">Carrom, was acquired by Oyster</a>. I joined Oyster to build the employment platform. It was officially my first time in a product role. Although I have been creating products for a good part of my life, I felt I lacked a lot of basic product management wisdom.</p>



<p>Over the past few months, I’ve been learning about the missing pieces with guidance from a few great mentors. I have curated a list of blog posts, books, and videos I’ve consumed along the way.</p>



<div><figure><img data-attachment-id="311" data-permalink="https://sooraj.io/screenshot-2020-11-18-at-20-36-01-1/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png" data-orig-size="1562,868" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-11-18-at-20.36.01-1" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=300" data-large-file="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=640" src="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=1024" alt="" srcset="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=1024 1024w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=150 150w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=300 300w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=768 768w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png 1562w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>







<p>The above is not an exhaustive list of things you have to learn. But this can help you get started.</p>



<p><strong>These are very superficial.</strong> It might also work for non-engineers. But I might have taken some things for granted that I already know. Hence the title Product Management for Engineers.</p>



<p>I will keep updating the list as I discover more quality content. You can follow me on&nbsp;<a target="_blank" href="https://twitter.com/soorajchandran_" rel="noreferrer noopener">Twitter</a>&nbsp;if you are interested.</p>








					</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article><!-- #post-## -->


				
			
		</main><!-- #main -->
	</div><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://sooraj.io/product-management-for-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141437</guid>
            <pubDate>Wed, 18 Nov 2020 19:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Native Buildpacks Enter Incubation in CNCF]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25141102">thread link</a>) | @sclevine
<br/>
November 18, 2020 | https://www.cncf.io/blog/2020/11/18/toc-approves-cloud-native-buildpacks-from-sandbox-to-incubation/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/blog/2020/11/18/toc-approves-cloud-native-buildpacks-from-sandbox-to-incubation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Today, the CNCF Technical Oversight Committee (TOC) voted to promote <a href="https://buildpacks.io/">Cloud Native Buildpacks</a> to incubation from the CNCF sandbox. Since joining CNCF in 2018, the Cloud Native Buildpacks project has added more than 15 new <a href="https://github.com/buildpacks/community/blob/master/ADOPTERS.md">production users</a>, new committers from more organizations, and defined an <a href="https://github.com/buildpacks/community/blob/main/GOVERNANCE.md">open governance process</a> and a clear <a href="https://github.com/buildpacks/community/blob/main/ROADMAP.md">project roadmap</a>.</p>



<p>The goal of the Cloud Native Buildpacks (CNB) project is to translate source code into container images with a focus on developer productivity, container security, and operations involving containerized applications at scale. The project also aims to unify the buildpack ecosystems of the past with a well-defined contract ideal for modern cloud native platforms.</p>



<p>“Cloud Native Buildpacks enable developers to work at whichever layer of abstraction is most productive for them while solving big problems like vulnerable dependencies and slow builds,” said Emily Casey, Buildpacks maintainer and staff engineer at VMware. “The project’s robust specification and tools have helped facilitate an ecosystem of composable buildpacks that interoperate with diverse platforms. We are excited to continue to grow the community as Buildpacks moves to incubation.”&nbsp;</p>



<p>“Heroku (Salesforce) open sourced the original Buildpacks project in 2012 with the hope that they would spread beyond the Heroku platform,” said Terence Lee, Buildpacks co-creator and principal engineer at Salesforce. “In 2018, Heroku and Pivotal (VMware) came together to start Cloud Native Buildpacks as a CNCF Sandbox project. With the move from the CNCF Sandbox to Incubation, Buildpacks are now fulfilling that vision while using OCI Image standards, increasing transparency, and building our community. We look forward to working with the community on new features and even more adoption.”&nbsp;</p>



<p>Cloud Native Buildpacks were accepted into the CNCF Sandbox in October 2018. Buildpacks are used in production by end user organizations, including Greenhouse, Salesforce, and VMware; in cloud native open source software <a href="https://github.com/cloudfoundry/cf-for-k8s/blob/master/README.md#purpose">Cloud Foundry on K8s</a>, <a href="https://github.com/GoogleContainerTools/skaffold/tree/master/examples/buildpacks">Google Skaffold</a>, <a href="https://www.hashicorp.com/blog/announcing-waypoint">Hashicorp Waypoint</a>, and <a href="https://github.com/pivotal/kpack">kpack</a>; and in commercial offerings including <a href="https://www.digitalocean.com/docs/app-platform/concepts/buildpack/">DigitalOcean App Platform,</a> <a href="https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks">Google Cloud</a>, <a href="https://developer.salesforce.com/blogs/2019/11/introducing-salesforce-evergreen.html">Salesforce Evergreen</a>, and <a href="https://tanzu.vmware.com/build-service">VMware Tanzu Build Service</a>.</p>



<p>“HashiCorp Waypoint was built from day one with buildpacks in mind. We wanted a way for developers to go from code to deploy as quickly and easily as possible and Cloud Native Buildpacks provided the standard, technology, and community to achieve that goal,” says Mitchell Hashimoto, founder of HashiCorp “We look forward to continue investing in and improving our buildpack usage.”</p>



<p>“Developers shouldn’t have to think about how to package their applications for deployment, so I’m excited to see Cloud Native Buildpacks promoted to a CNCF incubation project,” said James Ward, developer advocate, Google Cloud. “At Google Cloud, we’ve open sourced our Buildpacks and added support for them into numerous products, including Cloud Build, Cloud Run, App Engine, Cloud Functions, Cloud Code, Cloud Shell, and Skaffold. Now going from source to running on the cloud is even easier.”&nbsp;</p>



<p><strong>Main Buildpacks Features:</strong></p>



<ul><li><strong>Specification</strong> – a formal-language <a href="https://github.com/buildpacks/spec">specification</a> that describes the platform-to-buildpack contract.</li><li><strong>Implementation</strong> –&nbsp; robust lifecycle tooling necessary for platforms to add support for building images using buildpacks.</li><li><strong>Platform</strong> – components that provide a developer experience directly to end users, including integrations with popular build tools and cloud platforms.&nbsp;</li></ul>



<p><strong>Notable Milestones:</strong></p>



<ul><li>6 maintainers from Salesforce and VMware</li><li>20 committers&nbsp;</li><li>More than 2k contributions</li><li>Almost&nbsp; 5k commits</li><li>Over 1,200k GitHub Stars</li><li>15 contributors</li></ul>



<p>The Cloud Native Buildpacks project is complementary to other CNCF projects, including Helm, Harbor, and Kubernetes. Cloud Native Buildpacks produce Open Container Initiative (OCI) images managed by Helm, stored in Harbor, and deployed to Kubernetes. The project’s overarching goal is to provide a reliable, safe, modular, and fast way to build OCI images from source or input artifacts.&nbsp;</p>



<p>“Cloud Native Buildpacks provide a reliable and seamless way to turn code into containers,” said Chris Aniszczyk, CTO of Cloud Native Computing Foundation and executive director of OCI. “This lowers the barrier for developers to take advantage of cloud native technology and improves the developer experience for a segment of developers and cloud native platforms.”</p>



<p>“Users need a simple way to package, provision, and manage cloud native applications. Buildpacks – originally used by Heroku or Cloud Foundry – have now gone fully cloud-native, embracing key patterns popularized by Kubernetes.” said Alexis Richardson, CEO Weaveworks and former CNCF TOC member, “Those are the same key patterns that are at the core of GitOps, and used in combination they provide Weaveworks customers the ability to upgrade and patch their application deployments.”</p>



<p>As a CNCF-hosted project, joining incubating technologies Argo, CloudEvents, CNI, Contour, Cortex, CRI-O, Dragonfly, etcd, Falco, gRPC, Linkerd, NATS, Notary, OPA, OpenTracing, Operator Framework, Rook, SPIFFE, SPIRE, Thanos, and KubeEdge, Cloud Native Buildpacks is part of a neutral foundation aligned with its technical interests, as well as the larger Linux Foundation, which provides governance, marketing support, and community outreach. For more information on maturity requirements for each level, please visit the <a href="https://github.com/cncf/toc/blob/master/process/graduation_criteria.adoc">CNCF Graduation Criteria</a>.</p>



<p>To learn more about Cloud Native Buildpacks, visit <a href="https://buildpacks.io/">buildpacks.io</a>. The maintainers will be hosting <a href="https://kccncna20.sched.com/event/focW?iframe=no">office hours</a> during <a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/">KubeCon + CloudNativeCon North America Virtual 2020</a> to answer any questions about the project. Be sure to <a href="https://zoom.us/webinar/register/WN_4PhgzL2SRtaMacu6ZYdSYg">register and join</a> on Friday, November 20 at 4:00 pm EST.</p>


			<hr>
			
		</div></div>]]>
            </description>
            <link>https://www.cncf.io/blog/2020/11/18/toc-approves-cloud-native-buildpacks-from-sandbox-to-incubation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141102</guid>
            <pubDate>Wed, 18 Nov 2020 19:17:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Scratch.js – Interactive JavaScript Scratchpad]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25138872">thread link</a>) | @kahole
<br/>
November 18, 2020 | https://hole.dev/scratch/ | <a href="https://web.archive.org/web/*/https://hole.dev/scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hole.dev/scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138872</guid>
            <pubDate>Wed, 18 Nov 2020 16:39:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a technical book: from idea to print]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25138216">thread link</a>) | @sararob
<br/>
November 18, 2020 | https://sararobinson.dev/2020/11/17/writing-a-technical-book.html | <a href="https://web.archive.org/web/*/https://sararobinson.dev/2020/11/17/writing-a-technical-book.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p><strong>tl;dr</strong> - I co-authored an O’Reilly book with my colleagues <a href="https://twitter.com/lak_gcp" target="_blank">Lak</a> and <a href="https://www.linkedin.com/in/munnm/" target="_blank">Mike</a>! You can <a href="https://www.oreilly.com/library/view/machine-learning-design/9781098115777/" target="_blank">order it here</a> and 100% of the royalties go to <a href="https://girlswhocode.com/" target="_blank">Girls Who Code</a>. This post is about the writing process.</p>

<h3 id="deciding-to-write">Deciding to write</h3>

<p>Back in January of this year, Lak graciously reached out to me asking if I was interested in co-writing an O’Reilly book on machine learning. As I read the email, my reaction was almost an immediate no because:</p>

<ul>
  <li>It sounded like something that would take a lot of time.</li>
  <li>With a quickly evolving field like ML, wouldn’t a book be obsolete before it hit the shelves?</li>
</ul>

<p>I let Lak’s request sit in my inbox for a few days even though I was sure I had made up my mind, because saying no to projects is much harder than saying yes. A few days later on a long car ride with my fiancé, I mentioned the book offer in passing.</p>

<blockquote>
  <p>“You have an opportunity to write a book and you’re saying <em>no</em>?” he said, nearly pulling off the road.</p>
</blockquote>

<p>I suppose I had considered this offer as more of a <strong>burden</strong>, but from his perspective it was an <strong>opportunity</strong>. Ok, he wouldn’t be the one writing it, but he has <a href="https://www.amazon.com/Building-Embedded-Linux-Systems-Techniques-dp-0596529686/dp/0596529686" target="_blank">written</a> an O’Reilly book before!</p>

<p>It would no doubt be hard, but it also provided a chance to learn a lot along the way and have a book at the end of it. With his advice in mind, I decided to learn more about the book before saying no. The plan for the book was to catalog a series of patterns, each of which would outline a common challenge in ML and provide some approaches for solving it. I was intrigued, but some doubts started to creep in as I read through the pattern ideas:</p>

<ul>
  <li>
    <p>I was very familiar with some, but much less so with others. Didn’t I need to have all this knowledge in my head before writing for this to work?</p>
  </li>
  <li>
    <p>Why me? Why was I qualified to do this? Objectively, I have created a lot of ML content over the years to educate app developers, data scientists, and customers. I’d like to think I’m a decent writer, but a book? That seemed like a different beast, and I wasn’t sure I was the best person for the job.</p>
  </li>
</ul>

<p>There can always be a million reasons not to do something, but I ultimately decided to ignore them all and give it a try.</p>

<h3 id="starting-with-an-idea">Starting with an idea</h3>

<p>This happened before I joined the project, so I asked Lak what he did before reaching out to O’Reilly with the idea for the book. Publishers get cold proposals all the time, so it helps if you can clearly communicate what the book will be about and show that you know what you will be writing about.</p>

<p>In our case, Lak wrote a couple of blog posts on machine learning design patterns (<a href="https://medium.com/swlh/ml-design-pattern-1-transform-9e82ccbc3209">Transform</a> and <a href="https://towardsdatascience.com/ml-design-pattern-2-checkpoints-e6ca25a4c5fe">Checkpoints</a>) to gauge whether readers were interested in this idea. They were, but he realized that readers’ interest was very much in how to implement, adapt, and extend these patterns. He also did a talk on the topic at a couple of conferences and discovered that conference attendees were a bit different – they needed a clear explanation of the reason to use the pattern and a prescriptive approach to addressing the problem. In other words, readers who knew the pattern beforehand wanted a technical manual, while conference attendees (who were being introduced to the pattern for the first time) wanted to know why the pattern matters. This helped him write the next set of blog posts, where he started with a crisp problem statement, a canonical solution, and a couple of variations.</p>

<p>Once he had a good idea of how to communicate ML design patterns, Lak reached out to an O’Reilly editor with a short message:</p>

<blockquote>
  <p>I have a <a href="https://link.medium.com/7BSgxXdts1">list</a> of about 20 machine learning design patterns that I want to write about. Do you think they would do well as a book? If so, I can see about finding a co-author who would be interested in expanding on these…</p>
</blockquote>

<p>The editor replied that since O’Reilly has a solid franchise in design patterns, he was very interested. He was assigned an acquisitions editor who would work with us to craft the actual proposal. And that’s when Lak reached out to me to see if I was interested in co-authoring.</p>

<h3 id="building-an-outline">Building an outline</h3>

<p>I knew nothing about writing a book going into this, and my first question was: how will we split up the work? Will we alternate paragraphs, sections, chapters, words? I’m sure this varies for every book with multiple authors. We decided to split work by sections. In our case, each section was a design pattern and each chapter had 3-6 patterns. We started by making an outline, with an initial list of 20 patterns.</p>

<p>Chapters in our book are organized by different phases in a typical machine learning workflow. We first determined the topic for each chapter, and then came up with the patterns we wanted to be included in it. In the outline, each pattern had a 1-2 sentence description. It took a few iterations of adding and removing patterns and moving some between chapters before we had something we were happy with. We finished this process with a total of 30 patterns split across 6 chapters, with 2 additional chapters for an intro and conclusion. This brought us to the end of February.</p>

<h3 id="submitting-a-book-proposal">Submitting a book proposal</h3>

<p>The first step in the publishing process for many books is writing a proposal and submitting it to an acquisitions editor. Acquisitions editors are in charge of reviewing proposals, providing feedback, and deciding whether a proposal will move to the next stage in the approval process. They also work on overall content strategy, deciding which topics they want to cover. Sometimes people reach out to them cold, and other times these editors may proactively reach out to prospective authors.</p>

<p>The proposal (which includes the outline, but also comparisons with existing titles, and who the intended audience is) went through a few rounds of feedback (which is where I joined the process), including detailed technical feedback, before getting approved. The acquisitions editor focuses on acquiring new content, so once ours got approved we moved to the next step in the process which was working with a development editor. This person was our main point of contact throughout the writing process – more on that in the next section.</p>

<p>I recently had a great conversation with our acquisitions editor, where I learned a lot more about the publishing industry and how this all works. One thing from this conversation especially stood out: she mentioned she <em>rarely</em> receives a cold book proposal from a woman, and she gets many cold proposals each day. I’m sharing this data (with her permission) in hopes that it encourages more women with book ideas to just go for it. Reach out! You’ve got nothing to lose. If your proposal gets rejected, you’ll likely still get some feedback in the process.</p>

<h3 id="writing-time">Writing time</h3>

<p>I assumed we’d begin at the beginning, but we started by writing Chapter 2. Chapter 1 didn’t have any patterns – it was meant to be an overview of the entire book, explain our goals, and set the stage for the intended audience. Without anything written yet this would be hard to write, so we got right into patterns by starting with Chapter 2. Before sitting down to write this chapter, we took our short Chapter 2 outline and worked together to expand it. This is something we did before every chapter, with the goals of:</p>

<ul>
  <li>Ensuring the three of us had the same understanding of each pattern</li>
  <li>Agreeing on what should and shouldn’t be covered</li>
  <li>Splitting up the writing by pattern</li>
</ul>

<p>Early on in the outline process, we had decided each pattern should follow the same structure. If you’re reading the book, you’ll notice that every pattern is split into the following:</p>

<ul>
  <li><strong>Problem</strong>: describes the ML challenge a pattern addresses</li>
  <li><strong>Solution</strong>: describes one approach to solving the problem, including code snippets and recommended tooling for solving the problem</li>
  <li><strong>Tradeoffs and Alternatives</strong>: extended discussion on the pattern, including tools not covered in the Solution section, potential gotchas, and related solutions</li>
</ul>

<p>Having a structure for each section was extremely useful in ensuring consistency throughout the book.</p>

<p>After outlining Chapter 2 in detail, I had two patterns assigned to me and it was finally time to write. I wish I could tell you this is the part where I sat down at my desk, closed the door, and let the insights flow onto the page. This is how I’d always imagined book writing went. For better or worse (and maybe because the outside world went into chaos while this was happening), my process went more like this:</p>

<blockquote><div lang="en" dir="ltr"><p>My writing process:</p><p>* Write 2 sentences<br>* My glasses are splotchy, where are the lens wipes?<br>* Edit the last sentence I wrote<br>* Research the latest keyboards<br>* Write another 2 sentences<br>* Refill water, clean the counter<br>* Stare at my now perfect paragraph<br>* Open Twitter</p></div>— Sara Robinson (@SRobTweets) <a href="https://twitter.com/SRobTweets/status/1244312122613473281?ref_src=twsrc%5Etfw">March 29, 2020</a></blockquote>


<p>It wasn’t a very efficient way to start, but it got the job done and over time my process improved. I also quickly debunked my initial question:</p>

<p><em>Didn’t I need to have all this knowledge in my head before writing for this to work?</em></p>

<p>Even if I did have experience implementing a particular pattern, I couldn’t write only what I already knew. I had to do a considerable amount of research before I started writing the bulk of each pattern to find out:</p>

<ul>
  <li>What writing on this topic already existed?</li>
  <li>Are there any important research papers that cover this?</li>
  <li>What tools are available for solving this pattern?</li>
</ul>

<p>With all this research I started to have some doubts. If I was just collating information from various sources, was I providing anything useful? Then I thought about some of my favorite non-fiction books and realized most of them work by:</p>

<p><em>Presenting existing, relevant information + adding a unique angle</em></p>

<p>I’ve met with a lot of customers and seen production use of ML, and I’ve also built demos to help developers understand how to use different ML tools. Turns out I did have a unique angle! Before writing I did a lot of reading to make sure I fully understood the ins and outs of the pattern. Then I had enough information to write. I still wouldn’t say the words flowed at this point, but I did slowly get …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sararobinson.dev/2020/11/17/writing-a-technical-book.html">https://sararobinson.dev/2020/11/17/writing-a-technical-book.html</a></em></p>]]>
            </description>
            <link>https://sararobinson.dev/2020/11/17/writing-a-technical-book.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138216</guid>
            <pubDate>Wed, 18 Nov 2020 15:56:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming Language Fragility]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25138125">thread link</a>) | @da_big_ghey
<br/>
November 18, 2020 | https://cancel.fm/blog/2019-11/language-fragility/ | <a href="https://web.archive.org/web/*/https://cancel.fm/blog/2019-11/language-fragility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><dl><dt>Published</dt><dd><time datetime="2019-11-02T00:00:00Z">2019-11-02</time></dd><dt>Last updated</dt><dd>2019-11-02 16:28 UTC</dd></dl><section><p>Suggestions and corrections: <a href="mailto:cancel@cancel.fm">cancel@cancel.fm</a></p><hr><p>How fragile are the products of programming languages? If you write some software in a particular language, can you copy the compiled program to another computer and expect it to work? If the internet stopped functioning, would you be left helpless?</p><table><thead><tr><th>Language</th><th>Portable by Default</th><th>Portable with Effort</th><th>Notes</th></tr></thead><tbody><tr><td>C</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>C++</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>Rust</td><td>No (libc)</td><td>OK</td><td>Requires no_std. Most of the Rust ecosystem will be unusable.</td></tr><tr><td>Go</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Pascal (fpc &amp; Delphi)</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Zig</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Nim</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Odin</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>D</td><td>No (libc)</td><td>No (libc)</td><td>Must use glibc on on Linux, and glibc cannot be statically linked.</td></tr><tr><td>Haskell</td><td>No (libc)</td><td>Partial (static libc)</td><td>Complex build process to statically link runtime libc. Must avoid using libgmp features.</td></tr><tr><td>OCaml</td><td>No (libc)</td><td>Partial (static libc)</td><td>Complex build process to statically link runtime libc. Win32 requires cygwin.</td></tr><tr><td>Swift</td><td>No (no Win32)</td><td>No (no Win32)</td><td></td></tr><tr><td>Java</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>C#/F#/.NET</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>Python</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Ruby</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Perl</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>JavaScript (Node.js)</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Scheme (Racket)</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>Lua</td><td>No (custom binary)</td><td>Partial (custom binary)</td><td>Must build custom binary of the runtime plus your program code bundled together.</td></tr><tr><td>Tcl</td><td>No (complex runtime)</td><td>Partial (custom binary)</td><td>Must build custom binary of the runtime plus your program code bundled together.</td></tr></tbody></table><hr><p>What about the compilers themselves? How likely is something to go wrong when acquiring or setting up a compiler?</p><table><thead><tr><th>Compiler/Interpreter</th><th>Portable</th><th>Notes</th></tr></thead><tbody><tr><td>gcc</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>clang</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>msvc</td><td>No</td><td>Requires installer. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>tcc</td><td>OK</td><td></td></tr><tr><td>Rust</td><td>No</td><td>Requires installer or package manager. Recommended installation method is to pipe curl into bash.</td></tr><tr><td>Go</td><td>OK</td><td></td></tr><tr><td>Free Pascal</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Delphi</td><td>No</td><td>Requires installer.</td></tr><tr><td>Zig</td><td>OK</td><td></td></tr><tr><td>Nim</td><td>No</td><td>Requires a C compiler.</td></tr><tr><td>Odin</td><td>OK</td><td></td></tr><tr><td>D</td><td>Partial</td><td>Multiple executables. Some environment entanglement. No installer required.</td></tr><tr><td>Haskell</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>OCaml</td><td>No</td><td>Requires installer or package manager. Requires cygwin on Win32.</td></tr><tr><td>Swift</td><td>No</td><td>Requires installer. Heavy environment entanglement. Mac only.</td></tr><tr><td>Java</td><td>No</td><td>Requires installer or package manager. Multiple executables. Licensing issues.</td></tr><tr><td>C#/F#/.NET</td><td>No</td><td>Requires installer or package manager. Multiple executables. (Mono, .NET, and .NET Core)</td></tr><tr><td>Python</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>Ruby</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Perl</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement.</td></tr><tr><td>JavaScript (Node.js)</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Scheme (Racket)</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Lua</td><td>OK</td><td>Rolling your own host executable is required.</td></tr><tr><td>Tcl</td><td>OK</td><td>Fully portable via tclkits/all-in-one binaries.</td></tr></tbody></table><hr><p>Bonus round: portable compilers that can build themselves, portably.</p><table><thead><tr><th>Compiler/Interpreter</th><th>Builds Itself Portably</th><th>Notes</th></tr></thead><tbody><tr><td>tcc</td><td>OK</td><td>When using musl-libc. No Win32.</td></tr><tr><td>Go</td><td>OK</td><td></td></tr><tr><td>Everything else</td><td>No</td><td></td></tr></tbody></table><hr><p><span>P.S.</span> I’ve been working on some indie shareware: if you use Slack but don’t like the default browser-based client, give Ripcord a try.</p><a href="https://cancel.fm/ripcord/"><div><dl><dt>Ripcord</dt><dd>Cross-platform, not-a-web-browser desktop chat client for Slack (and Discord.)</dd></dl><p><img src="https://cancel.fm/ripcord/static/ripcord_screenshot_win_7_small.jpg" height="75px" alt="Screenshot of the main Ripcord window with light theme"></p></div></a></section></main></div></div>]]>
            </description>
            <link>https://cancel.fm/blog/2019-11/language-fragility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138125</guid>
            <pubDate>Wed, 18 Nov 2020 15:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weekly Digs NEWSLETTER -- Is an “Eviction Tsunami” looming in 2021?]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25137873">thread link</a>) | @cpow85
<br/>
November 18, 2020 | https://theweeklydigs.com/2020/11/18/is-an-eviction-tsunami-looming-in-2021/ | <a href="https://web.archive.org/web/*/https://theweeklydigs.com/2020/11/18/is-an-eviction-tsunami-looming-in-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-240">
		
	
	<div>
		
<p>This week on The Weekly Digs: Is an “Eviction Tsumami” looming in 2021? The U.S. economy has only recovered half the 22 million jobs lost during 2020; meanwhile, stimulus checks and support for unemployed is drying up fast. On another note, the housing market in the U.S. continues to be red hot. This and more, below the fold.</p>



<h2>For free real estate news every week, sign up for The Weekly Digs</h2>



	<div data-blog-id="165588401">
		<div>
			<form aria-describedby="wp-block-jetpack-mailchimp_consent-text">
				
				

				<p id="wp-block-jetpack-mailchimp_consent-text">
					By clicking submit, you agree to share your email address with the site owner and Mailchimp to receive marketing, updates, and other emails from the site owner. Use the unsubscribe link in those emails to opt out at any time.				</p>

				
			</form>
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	



<ul>
    <li>
        <a href="https://sparkrental.com/eviction-crisis/">
            Is an “Eviction Tsunami” Looming in 2021?
        </a>
        <ul>
            <li>
                Millions of Americans remain out of work in the coronavirus pandemic, after the economy has recovered only half of the 22 million jobs lost in the spring of 2020. Meanwhile, the stimulus checks and extended unemployment benefits are ancient history by November. This…
            </li>
        </ul>
    </li>
</ul>



    <ul>
      <li>
        <h2>
          <a href="https://www.biggerpockets.com/show417">
            BiggerPockets Podcast 417: 9 Ways to Tweak Your Mindset So You Can Lock Down Deals with Brandon and David
          </a>
        </h2>
        <ul>
          <li>
            <p>
              Are you a new or aspiring real estate investor who hasn’t locked down your first deal? Or maybe you haven’t hit your personal goal or unit count yet. If so, you may need to tweak your mindset to reach new heights.
Brandon and David are back flying solo on this weekend’s episode to talk about the 9 m
            </p>
          </li>
        </ul>
      </li>
    </ul>
  


    <h2>From <a href="https://www.calculatedriskblog.com/">Calculated Risk’s</a> Most recent posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/comments-on-october-housing-starts.html">
              
Comments on October Housing Starts

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/18/2020 09:32:00 AM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/housing-starts-increased-to-1530.html">
              
Housing Starts increased to 1.530 Million Annual Rate in October

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/18/2020 08:38:00 AM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/mba-mortgage-applications-decrease-in_18.html">
              
MBA: Mortgage Applications Decrease in Latest Weekly Survey

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/18/2020 07:00:00 AM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/wednesday-housing-starts.html">
              
Wednesday: Housing Starts

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/17/2020 09:15:00 PM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/november-17-covid-19-test-results.html">
              
November 17 COVID-19 Test Results; Record Hospitalizations

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/17/2020 07:57:00 PM

              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://www.realtor.com/news/real-estate-news/">Realtor.com’s</a> Latest News</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.realtor.com/news/real-estate-news/home-builder-confidence-surges-to-new-record-high-as-sales-volume-grows/">
              Home Builder Confidence Surges to New Record High as Sales Volume Grows
            </a>
            <ul>
              <li>
                The construction industry’s outlook improved again in November, according to research from a trade group released Monday.
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.realtor.com/videos/economic-update-this-week-signs-of-improvement-/54dc0d4b-a15b-46c1-a476-c1208dd5d02d">
              Economic Update This Week: Signs of Improvement?
            </a>
            <ul>
              <li>
                
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.realtor.com/news/real-estate-news/u-s-housing-market-takes-a-breather-but-stays-hot/">
              U.S. Housing Market Takes a Breather But Stays Hot
            </a>
            <ul>
              <li>
                Between the presidential election and a new wave of coronavirus cases, buyers and sellers had reasons to pause, report finds.
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.realtor.com/news/real-estate-news/home-prices-rise-by-double-digits-in-much-of-country/">
              Despite Uncertainty, Home Prices Are Rising by Double Digits in Much of Nation
            </a>
            <ul>
              <li>
                Home prices sharply headed up—even as the turmoil over a hotly contested presidential election, the coronavirus pandemic, and high unemployment persisted.
              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://sparkrental.com/rental-income-blog/">Spark Rental’s</a> Latest Blog Posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://sparkrental.com/property-taxes-by-state/">
              Property Taxes by State &amp; County: Lowest Property Taxes in the US Mapped
            </a>
            <ul>
              <li>
                Where are the lowest property taxes in the US? The highest property taxes? Some states offer no surprises. New Jersey, for example, charges the highest property taxes in the nation as a statewide average. But Texas also ranks among the top five highest property taxes…
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://sparkrental.com/eviction-crisis/">
              Is an “Eviction Tsunami” Looming in 2021?
            </a>
            <ul>
              <li>
                Millions of Americans remain out of work in the coronavirus pandemic, after the economy has recovered only half of the 22 million jobs lost in the spring of 2020. Meanwhile, the stimulus checks and extended unemployment benefits are ancient history by November. This…
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://sparkrental.com/due-diliegence-real-estate/">
              What Is Due Diligence in Real Estate, and How Do You Do It?
            </a>
            <ul>
              <li>
                In short, due diligence in real estate means “do your homework.” This goes beyond looking for the “perfect” property, whether for your personal residence or an investment. Due diligence means conducting thorough research to ensure the home is a good investment before…
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://sparkrental.com/capital-gains-tax-real-estate/">
              Capital Gains Tax on Real Estate – And How to Avoid It
            </a>
            <ul>
              <li>
                Real estate investments come with a slew of tax advantages. While you own the property as a rental, you can take nearly two dozen landlord tax deductions.&nbsp; Then, when it comes time to sell, you can reduce or avoid capital gains taxes on real estate through another…
              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://biggerpockets.com/blog">Bigger Pockets’</a> Top Popular Posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://biggerpockets.com/blog/i-will-never-trust-real-estate-wholesalers">
              Opinion: I Don’t Trust Anyone Who Wholesales—Here’s Why
            </a>
            <ul>
              <li>
                By Darren Sager
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://biggerpockets.com/blog/should-real-estate-investors-leave-california">
              If ‘Everyone’ Is Leaving California, Should Real Estate Investors Leave, Too?
            </a>
            <ul>
              <li>
                By Andrew Syrios
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://biggerpockets.com/blog/foreclosures-u-s-increase-covid-continues-rise">
              Foreclosures in the US Increase as COVID Continues To Rise
            </a>
            <ul>
              <li>
                By BiggerPockets
              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://realpage.com/blog">PM Insider’s</a> Latest Posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.realpage.com/blog/data-makes-the-difference-in-gaining-control-of-multifamily-utilities/">
              Data Makes the Difference in Gaining Control of Multifamily Utilities
            </a>
          </li>
        
          <li>
            <a href="https://www.realpage.com/blog/automated-multifamily-vendor-payment-processing-is-saving-time-money-and-headaches/">
              Automated Multifamily Vendor Payment Processing  is Saving Time, Money and Headaches
            </a>
          </li>
        
          <li>
            <a href="https://www.realpage.com/blog/multifamily-pmcs-using-benchmarking-to-optimize-marketing-spend/">
              Multifamily PMCs Using Benchmarking to Optimize Marketing Spend
            </a>
          </li>
        
          <li>
            <a href="https://www.realpage.com/blog/affordable-compliance-speed-vs-accuracy-in-certifications/">
              Affordable Compliance: Speed vs. Accuracy in Certifications
            </a>
          </li>
        
    </ul>
  


    <h2>From Reddits <a href="https://reddit.com/r/realestate">/r/RealEstate</a> Subreddit</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.reddit.com/r/RealEstate/comments/jtxgvt/i_just_signed_my_title_on_a_three_story_town/">
              I just signed my title on a three story town house using the VA loan on veterans day and closed on Friday the 13th.. first time home buyer. I’ll remember this day to infinity.
            </a>
            <ul>
            <li>
              current score on reddit: 511
            </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.reddit.com/r/RealEstate/comments/jv4ksz/i_just_put_in_an_offer_40_thousand_over_asking/">
              I just put in an offer 40 THOUSAND over asking and still did not get the home in Grand Rapids,MI. Tell me there is still hope for me.
            </a>
            <ul>
            <li>
              current score on reddit: 283
            </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.reddit.com/r/RealEstate/comments/jvky5z/real_estate_brokers_keep_cold_calling_my_parents/">
              Real Estate Brokers keep cold calling my parents asking if they want to sell their home. These calls are increasing in frequency and they even managed to get my cell phone number even though I do not live there.
            </a>
            <ul>
            <li>
              current score on reddit: 256
            </li>
            </ul>
          </li>
        
    </ul>
  

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://theweeklydigs.com/2020/11/18/is-an-eviction-tsunami-looming-in-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25137873</guid>
            <pubDate>Wed, 18 Nov 2020 15:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boilerplates for a Head Start When Building a SaaS App]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25136653">thread link</a>) | @jakeprins
<br/>
November 18, 2020 | https://jakeprins.com/blog/7-boilerplates-for-a-head-start-when-building-a-saas-app | <a href="https://web.archive.org/web/*/https://jakeprins.com/blog/7-boilerplates-for-a-head-start-when-building-a-saas-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>Building a SaaS platform is hard, especially if you’re a solo founder who needs to build everything by yourself. But there are options to help you build and launch your project faster.</p><hr><p>When you have a great idea and start working on it from scratch, you feel a rush of excitement. It’s great to work on an interesting idea, but instead of focusing on what makes your product unique, you first need to put in the hours to work on things that are less exciting: configuring a project, building authentication flows, integrating payments, building forms, etc.</p><p>If you want to launch faster, there are some things you might want to consider. You probably want to use a web framework to increase development speed. Nobody builds their SaaS with plain Ruby code. You’d much rather use a framework like Rails. And the same goes for styling your application. Instead of writing all the CSS yourself, you could use a framework like Bootstrap, Material, or Tailwind. But if you really want to save a lot of time, you should start with a SaaS boilerplate.</p><p>A SaaS boilerplate includes a lot of functionalities that cost a lot of time to build out yourself. Think about authentication or billing. These are things that every SaaS needs to have, so why build it all yourself?</p><p>You should launch your SaaS fast so you can get feedback as soon as possible. To do that, starting out with a boilerplate/starter kit can save you tons of time. Here is a list of seven boilerplates that could help you build your SaaS faster.</p><hr><h3>Serverless SaaS</h3><p>The <a href="https://serverless.page/">Serverless SaaS</a> boilerplate is the perfect starting point for your next React app. It’s built with TypeScript, Next.js, Tailwind, and Firebase. You can tap into user authentication, payments with Stripe, teams, and more with zero effort.</p><p>Going serverless is a great way of cutting costs because the pay-as-you-go pricing model means you can start free and only pay when your startup gets real traction. You also don’t have to worry about scaling issues. With Serverless platforms you are outsourcing a lot of responsibilities which allows you to move quicker.</p><p>That makes this starter kit great for solo developers and small teams who want to launch something quickly without spending money.</p><img alt="Serverless SaaS logo and slogan" src="https://miro.medium.com/max/700/1*7yHuIcpwIcUBkecK2LORMg.jpeg"><p>Source: <a href="https://serverless.page/">https://serverless.page/</a></p><hr><h3>Jumpstart</h3><p><a href="https://jumpstartrails.com/">Jumpstart</a> is a great starter kit for your next Ruby on Rails app. You can skip the boilerplate set up and build your Rails app faster. It handles all the stuff you need like a user authentication system and even background processing. It also has very good <a href="https://jumpstartrails.com/docs">documentation</a>. You can even try out a <em>lite</em> version that is available for free on <a href="https://github.com/excid3/jumpstart">Github</a>.</p><img alt="Jumpstart home page" src="https://miro.medium.com/max/700/1*8vcaD5txgZRmwqHrxMPvUQ.png"><p>Source: <a href="https://jumpstartrails.com/docs">https://jumpstartrails.com</a></p><hr><h3>Laravel Spark</h3><p><a href="https://spark.laravel.com/">Laravel Spark</a> is a Laravel package that is built by Taylor Otwell, the creator of Laravel. An amazing project to help you build your next great product with PHP. It provides a lot of scaffolding features so you don’t have to code everything yourself. It also has the features that every SaaS business needs, like (two-factor) authentication, subscription billing, and invoices.</p><img alt="Spark logo" src="https://miro.medium.com/max/700/1*OIiJ6wMYQE3XFx48b7NWvw.png"><p>Source: <a href="https://spark.laravel.com/">https://spark.laravel.com/</a></p><hr><h3>Gravity</h3><p>With Gravity, you can build a Node.js and React SaaS app at warp speed. It comes with a lot of features and pre-built components to get you up and running quickly. It even has a built-in user-onboarding flow feedback widget.</p><img alt="Gravity home page" src="https://miro.medium.com/max/700/1*2R71R0rWY_9N8I2wnrAfVA.png"><p>Source: <a href="https://usegravity.app/">https://usegravity.app</a></p><hr><h3>Sjabloon</h3><p><a href="https://www.getsjabloon.com/">Sjabloon</a> is a modern Ruby on Rails SaaS starter kit that also includes all the SaaS features like authentication and payments with Stripe, but also comes with a huge UI components library that is built with Tailwind, the rising CSS framework. This allows you to focus on your core product right from the start. Just like Jumpstart, it also has a lite version that is available for free on <a href="https://github.com/GetSjabloon/sjabloon-lite">Github</a>.</p><img alt="Sjabloon home page" src="https://miro.medium.com/max/700/1*cDQ56JMFLiPsqdiDPmjlkg.png"><p>Source: <a href="https://www.getsjabloon.com/">https://www.getsjabloon.com/</a></p><hr><p>React Milkshake</p><p><a href="https://www.reactmilkshake.com/">React Milkshake</a> is a basic React boilerplate to build high-performance apps faster. It does not come with as many features as the other boilerplates mentioned, but it does come with a code generator that generates components and <a href="https://redux.js.org/">Redux</a> code. If you are using Redux as a state management tool, using this boilerplate will save you a lot of time.</p><img alt="React Milkshake home page" src="https://miro.medium.com/max/700/1*GfuUSjr7h6tkB6YQZqWGEQ.png"><p>Source: <a href="https://www.reactmilkshake.com/">https://www.reactmilkshake.com</a></p><hr><h3>Wave</h3><p>Voyager is a popular Laravel Admin Package and <a href="https://wave.devdojo.com/">Wave</a> is a starter kit built on top of both Laravel and <a href="https://voyager.devdojo.com/">Voyager</a>. You can install this starter-kit on your own server and customize it to fit your needs. Wave integrates with both Stripe or Braintree and is well documented. It also has theme support for three different starter themes. You can choose from Bootstrap, UIKit, or Tailwind. Wave also checks all the boxes for all the other SaaS features so it will much likely speed up your development time when crafting a SaaS from scratch.</p><img alt="Wave home page" src="https://miro.medium.com/max/700/1*1dYotspAZBJ9xXBFGIaLSQ.png"><p>Source: <a href="https://wave.devdojo.com/">https://wave.devdojo.com</a></p><hr><p>Thanks for reading! I hope you find these helpful.</p></article></div></div>]]>
            </description>
            <link>https://jakeprins.com/blog/7-boilerplates-for-a-head-start-when-building-a-saas-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136653</guid>
            <pubDate>Wed, 18 Nov 2020 13:49:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Have a Difficult Conversation]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25136200">thread link</a>) | @MurizS
<br/>
November 18, 2020 | https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger | <a href="https://web.archive.org/web/*/https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Iâ€™m in a Zoom meeting, speaking to a screen full of black squares, trying to coax voices out of the void. The other callers are all members of an executive board, and theyâ€™re in turmoil over the strategic direction of their company. Several of them are no longer on speaking terms, and employees and shareholders have not been shielded from the drama. On a good day, these calls are tense, but more often than not theyâ€™re explosive. Only my camera is turned on, and I watch myself try to look optimistic.</p>
<p>Iâ€™m a mediator. I have helped people have difficult conversations for more than 20 years: in conflict zones and in living rooms, with leaders of corporations and foundations, and people in my own community. If youâ€™ve ever avoided or postponed a difficult conversation, youâ€™re not alone. Conflict avoidance is everywhere. At home and at work, we steer around conflict as prodigiously as we create it.</p>
<p>And yet conflict isnâ€™t inherently bad. It offers us information about how we could work with others more effectively, improve our relationships, and grow as individuals. Itâ€™s far worse to try to avoid it, because you just end up creating new conflict â€“ which ends up being more insidious and costly than the original issue.</p>
<p>When I help people have difficult conversations, weâ€™re always aiming for one of three outcomes: a solution, a plan or an understanding. A solution is a grand bargain, a resounding win, a comprehensive resolution expected to withstand the pressures of all unknown future challenges. With a mediator this can happen, but itâ€™s ambitious. We all have a tendency to hope for a dramatic and permanent solution, but this usually causes new problems by overburdening an already stressed relationship. A plan is more realistic, and is like a map for finding a solution. It leaves the precise terms of the resolution open-ended but provides a path forward. A plan reorganises the relationship with new boundaries, revised norms, and sets up shared expectations for how the trickiest parts will be navigated.</p>
<p>But the <em>most</em> realistic outcome, especially at the beginning, is to focus on reaching an understanding. An understanding is a new awareness of what the other person has experienced in the conflict; itâ€™s a mutual appreciation for one anotherâ€™s needs, fears and hopes. Reaching an understanding is feasible, provides great relief, and can lay a foundation for a plan, a solution and a new relationship.</p>
<p>For example, I recently helped a family to reach an understanding when the COVID-19 pandemic forced a college student to move back in with his parents. They were having difficulties renegotiating their relationships once they were suddenly living together again. Their renewed understanding led to a plan for new expectations and boundaries, which theyâ€™re currently using to navigate the uncertainties and discomfort of this period. I expect theyâ€™ll find their solution soon.</p>
<p>In my work as a mediator, Iâ€™ve learnt that successful conversations always involve what I call a â€˜gem statementâ€™. When two parties have listened long and hard to each other â€“ have made the heroic effort to listen curiously and empathically even when they disagree strenuously â€“ someone eventually unearths a glowing, priceless gem. It usually takes the form of a short, powerful statement, such as these two Iâ€™ve heard recently:</p>
<blockquote>Weâ€™ve kept on fighting in part because neither of us is willing to walk away from this friendship. Thatâ€™s something.</blockquote>
<blockquote>Even when we canâ€™t agree on Dadâ€™s medical care, Iâ€™ve never doubted your good intentions. I know you want the best for him.</blockquote>
<p>It happens almost every time. From the muck of blame and anger, someone lifts out a beacon. I then seize the opportunity and hold up the gleaming gem for all parties to see. It lights the way toward a new conversation revolving around compromise, solutions and goodwill.</p>
<p>In addition to gratitude for the person who dug out the gem, I have also felt impatience. Iâ€™ve wondered, <em>Why canâ€™t they say something like this earlier in the process? Or better yet, at the beginning?</em> Does the conversation need to naturally find its way to such a moment, or could we engineer it to happen much sooner? It seemed worthwhile to find out, so I developed a process to reduce the amount of time people spend digging in the muck. And Iâ€™ve found it works: when people find a gem earlier on, they experience less pain and more benefit from having their difficult conversation.</p>
<p>This Guide is to help you do this â€“ without a mediator. Mediators can be helpful during challenging times, but we donâ€™t actually resolve peoplesâ€™ conflicts. We create the conditions in which people feel heard and acknowledged, increasing the quality of their communication and problem-solving. When youâ€™re facing a tough conversation, itâ€™s not really the mediator you need â€“ itâ€™s the conditions weâ€™re good at creating and maintaining.</p>
<p>If you donâ€™t feel safe or if your situation involves illegal activity or any type of abuse, this Guide isnâ€™t right for you. In those instances, get help from a professional right away. There are also some situations that donâ€™t call for further conversation â€“ some relationships or difficulties are better left in the past, and you should trust your instinct about whether a conversation is the right step for you. But if you think talking could do some good, then this resource can help get you started.</p>
<p>Maybe you feel misunderstood or unappreciated at work. Or maybe youâ€™re caught in a recurring family pattern that causes pain and drives you <a href="https://psyche.co/guides/a-family-rift-is-locked-on-the-past-heres-how-to-move-forward" rel="noopener">away</a> from the people you love. If you feel hurt or angry when thinking of a difficult conversation you need to have, there is a good chance that the relationship is important to you. Whether itâ€™s a relationship within your family, at work or in your community, itâ€™s become this challenging because you have a vested interest, you care deeply or your future is somehow intertwined with the person you need to talk with.</p>
<p>If you feel the situation could improve if someone <em>really heard</em> what you have to say, thereâ€™s hope. If you feel ready to make an earnest effort to <em>really hear</em> someone in return, thereâ€™s even more than hope. Remember that your goal here is not to find a quick solution or plan straight away â€“ thatâ€™s tempting but unrealistic, and might backfire. Your goal is to understand each other.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>1. Prepare for the conversation</strong></p>
<p>The first step is a thought experiment: think about the person with whom you need to talk, and allow yourself to imagine that you just finished having the best possible conversation with them. You were heard fully. Each of your concerns was addressed to your satisfaction. If an apology was appropriate, you received an excellent one. <em>Stay with this â€“ just imagine it!</em> Youâ€™ve reached an understanding that gives you confidence in the future of the relationship. <em>This is a challenging thought experiment, but youâ€™re almost thereâ€¦</em> You are relieved, you feel lighter, and even grateful to the person youâ€™ve been in conflict with.</p>
<p><strong>2. Dig out a gem</strong></p>
<p>What would you say to them in this moment? (Remember, in this exercise youâ€™ve been heard, youâ€™ve received an apology, and it went exceedingly well.) What would you say to your counterpart if all of that happened? Whatâ€™s â€˜underneathâ€™ the conflict? Whatâ€™s true when youâ€™re not consumed with negative feelings? Write down the first gem statement you think of. You can write others too, but usually the first one is the real deal.</p>
<p>Your statement should be an authentic expression of how youâ€™re feeling, but should also have significant meaning and positive impact for the other person. For example, two more gem statements I heard recently were: â€˜I can tell you care a lot about reaching our teamâ€™s goals, and I have a lot of respect for you<em>.</em>â€™ You can tell itâ€™s a gem when youâ€™re terribly tempted to tack on a grievance to the end of it. Like this: <em>I can tell you care a lot about reaching our teamâ€™s goals, </em><em><strong>but the way you go about it is causing great difficulty to everyone around you.</strong></em> If you find yourself doing this, leave out the second part. Youâ€™ll get to say it, just not here.</p>
<p><strong>3. Ask yourself if youâ€™re ready</strong></p>
<p>Are you willing to say the statement to them? We recoil from being generous and kind when we feel our counterpart doesnâ€™t deserve it. Moreover, making such statements can put us in an even more vulnerable position. If thatâ€™s the case, it might help to think of this another way. Uttering your gem statement is a temporary discomfort; the benefits youâ€™ll experience will be lasting and profound.</p>
<p>At this point, you should share this Guide with the other person. Even if you donâ€™t follow these steps closely or have the conversation right away, it will be helpful simply to both read the Guide and give thought to it. If you do proceed with a conversation, having this Guide in advance means that they will have undertaken this same process and unearthed a gem statement for you, which will likely mitigate your vulnerability and discomfort.</p>
<p><strong>4. Phone a friend</strong></p>
<p>Tell a friend who isnâ€™t involved in the conversation what youâ€™re going to do. The purpose is not to craft the gem statement together, and it isnâ€™t even to get their advice. Instead, say the four sentences below to your friend:</p><ul>
<li>The biggest emotion that Iâ€™m feeling toward the person I need to have a difficult conversation with isâ€¦</li>
<li>The biggest emotion that I expect the person is feeling toward me isâ€¦</li>
<li>The gem statement I will make to them isâ€¦</li>
<li>My hope for the conversation isâ€¦</li>
</ul><p>The fourth sentence â€“ identifying your hope for the conversation â€“ is a critical piece of your planning. Remember that the best initial outcome is achieving a new, shared understanding, rather than a comprehensive solution or a detailed plan. New understanding can bring you relief and allow space for forward movement, without expecting a miraculous resolution of all tension and …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger">https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136200</guid>
            <pubDate>Wed, 18 Nov 2020 12:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer and BioNTech Conclude Phase 3 Study of Covid-19 Vaccine Candidate]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25135984">thread link</a>) | @doener
<br/>
November 18, 2020 | https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine | <a href="https://web.archive.org/web/*/https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-nir-pid3469-content">
  
    
      <h2>

</h2>





<article role="article">

  <div>
                <ul><li><em>Primary efficacy analysis demonstrates BNT162b2 to be 95% effective against COVID-19 beginning 28 days after the first dose; 170 confirmed cases of COVID-19 were evaluated, with 162 observed in the placebo group versus 8 in the vaccine group</em></li><li><em>Efficacy was consistent across age, gender, race and ethnicity demographics; observed efficacy in adults over 65 years of age was over 94%</em></li><li><em>Safety data milestone required by U.S. Food and Drug Administration (FDA) for Emergency Use Authorization (EUA) has been achieved</em></li><li><em>Data demonstrates vaccine was well tolerated across all populations with over 43,000 participants enrolled; no serious safety concerns observed; the only Grade 3 adverse event greater than 2% in frequency was fatigue at 3.8% and headache at 2.0%</em></li><li><em>Companies plan to submit within days to the FDA for EUA and share data with other regulatory agencies around the globe</em></li><li><em>The companies expect to produce globally up to 50 million vaccine doses in 2020 and up to 1.3 billion doses by the end of 2021</em></li></ul><p><strong>NEW YORK and MAINZ, GERMANY, November 18, 2020</strong> — <a href="https://www.globenewswire.com/Tracker?data=Yli2d5nvthuV5tgeZIpzfNa66X9aMWyRcb2c3eYCC7LVUbfEPTAS5qEjoWW9lex6gtFcZvarKhgdJF9WTS1yog==" rel="nofollow" target="_blank"><u>Pfizer Inc.</u></a> (NYSE: PFE) and <a href="https://www.globenewswire.com/Tracker?data=hDf010SOKY9ImJTMfLoYkeqr7USo3RbkSJXZNMRX8mlCKyHr1c2F9DT9mjo9LMT6ewFhRCEzViCxu4yA2e7l7g==" rel="nofollow" target="_blank"><u>BioNTech SE</u></a> (Nasdaq: BNTX) today announced that, after conducting the final efficacy analysis in their ongoing Phase 3 study, their mRNA-based COVID-19 vaccine candidate, BNT162b2, met all of the study’s primary efficacy endpoints. Analysis of the data indicates a vaccine efficacy rate of 95% (p&lt;0.0001) in participants without prior SARS-CoV-2 infection (first primary objective) and also in participants with and without prior SARS-CoV-2 infection (second primary objective), in each case measured from 28 days after the first dose, 7 days after the second dose. The first primary objective analysis is based on 170 cases of COVID-19, as specified in the study protocol, of which 162 cases of COVID-19 were observed in the placebo group versus 8 cases in the BNT162b2 group. Efficacy was consistent across age, gender, race and ethnicity demographics. The observed efficacy in adults over 65 years of age was over 94%.</p>  <p>There were 10 severe cases of COVID-19 observed in the trial, with nine of the cases occurring in the placebo group and one in the BNT162b2 vaccinated group. To date, the Data Monitoring Committee for the study has not reported any serious safety concerns related to the vaccine. A review of unblinded reactogenicity data from the final analysis which consisted of a randomized subset of at least 8,000 participants 18 years and older in the Phase 2/3 study demonstrates that the vaccine was well tolerated, with most solicited adverse events resolving shortly after vaccination. The only Grade 3 (severe) solicited adverse events greater than or equal to 2% in frequency after the first or second dose were fatigue at 3.8% and headache at 2.0% following dose 2. Consistent with earlier shared results, older adults tended to report fewer and milder solicited adverse events following vaccination. </p>  <p>In addition, the companies announced that the safety milestone required by the U.S. Food and Drug Administration (FDA) for Emergency Use Authorization (EUA) has been achieved. Pfizer and BioNTech plan to submit a request within days to the FDA for an EUA based on the totality of safety and efficacy data collected to date, as well as manufacturing data relating to the quality and consistency of the vaccine. These data also will be submitted to other regulatory agencies around the world.</p>  <p>“The study results mark an important step in this historic eight-month journey to bring forward a vaccine capable of helping to end this devastating pandemic. We continue to move at the speed of science to compile all the data collected thus far and share with regulators around the world,” said <strong>Dr. Albert Bourla, Pfizer Chairman and CEO</strong>. “With hundreds of thousands of people around the globe infected every day, we urgently need to get a safe and effective vaccine to the world.” </p>  <p>“We are grateful that the first global trial to reach the final efficacy analysis mark indicates that a high rate of protection against COVID-19 can be achieved very fast after the first 30 µg dose, underscoring the potential of BNT162 to provide early protection,” said <strong>Ugur Sahin, M.D., CEO and Co-founder of BioNTech</strong>. “These achievements highlight the potential of mRNA as a new drug class. Our goal from the very beginning was to design and develop a vaccine that would generate rapid and potent protection against COVID-19 with a benign tolerability profile across all ages. We believe we have&nbsp;successfully accomplished this with our vaccine candidate BNT162b2 in all age groups studied so far and look forward to sharing further details with the regulatory authorities. I want to thank all the devoted women and men who contributed to this historically unprecedented achievement. We will continue to work with our partners and governments around the world to prepare for global distribution in 2020 and beyond.”</p>  <p>The Phase 3 clinical trial of BNT162b2 began on July 27 and has enrolled 43,661 participants to date, 41,135 of whom have received a second dose of the vaccine candidate as of November 13, 2020. Approximately 42% of global participants and 30% of U.S. participants have racially and ethnically diverse backgrounds, and 41% of global and 45% of U.S. participants are 56-85 years of age. A breakdown of the diversity of clinical trial participants can be found <a href="https://www.globenewswire.com/Tracker?data=ad78-V3TIZpaI0hRxmiSbgkEJUyAXaiiyEL-ARI3BmSe5nBb577HWGg9iwQLkpFDr5Zut3MDUXtDp4gcUuk1TJMOdJQMV0I0rP8L9ghyxUs=" rel="nofollow" target="_blank"><u>here</u></a><u>&nbsp;</u>from approximately 150 clinical trials sites in United States, Germany, Turkey, South Africa, Brazil and Argentina. The trial will continue to collect efficacy and safety data in participants for an additional two years. </p>  <p>Based on current projections, the companies expect to produce globally up to 50 million vaccine doses in 2020 and up to 1.3 billion doses&nbsp;by the end of 2021. Four of Pfizer’s facilities are part of the manufacturing and supply chain; St. Louis, MO; Andover, MA; and Kalamazoo, MI in the U.S.; and Puurs in Belgium. BioNTech’s German sites will also be leveraged for global supply.</p>  <p>Pfizer is confident in its vast experience, expertise and existing cold-chain infrastructure to distribute the vaccine around the world. The companies have developed specially designed, temperature-controlled thermal shippers utilizing dry ice to maintain temperature conditions of -70°C±10°C. They can be used be as temporary storage units for 15 days by refilling with dry ice. Each shipper contains a GPS-enabled thermal sensor to track the location and temperature of each vaccine shipment across their pre-set routes leveraging Pfizer’s broad distribution network.</p>  <p>Pfizer and BioNTech plan to submit the efficacy and safety data from the study for peer-review in a scientific journal once analysis of the data is completed.</p>  <p><strong>About Pfizer: Breakthroughs That Change Patients’ Lives</strong><br>At Pfizer, we apply science and our global resources to bring therapies to people that extend and significantly improve their lives. We strive to set the standard for quality, safety and value in the discovery, development and manufacture of health care products, including innovative medicines and vaccines. Every day, Pfizer colleagues work across developed and emerging markets to advance wellness, prevention, treatments and cures that challenge the most feared diseases of our time. Consistent with our responsibility as one of the world's premier innovative biopharmaceutical companies, we collaborate with health care providers, governments and local communities to support and expand access to reliable, affordable health care around the world. For more than 150 years, we have worked to make a difference for all who rely on us. We routinely post information that may be important to investors on our website at <a href="https://www.globenewswire.com/Tracker?data=efkBESitL-YYL3Z0laTvow2llGFscFffkJd5BwOiTNGOtjFDXsnDOMTTrrWjwIHkGrKr7l170Vr-Cf0IOcmK5A==" rel="nofollow" target="_blank"><u>www.Pfizer.com</u></a>. In addition, to learn more, please visit us on <a href="https://www.globenewswire.com/Tracker?data=efkBESitL-YYL3Z0laTvo2zbdJuTNF9-WfK2D7Q6C5GUvy5ow-iKwQsyx4ZETtqc0zENUzOZqpNT5axWduuvIg==" rel="nofollow" target="_blank"><u>www.Pfizer.com</u></a> and follow us on Twitter at <a href="https://www.globenewswire.com/Tracker?data=_G7bMvP0UnHgRNdBi7C58Y5yD_vt1MwKM6uavr4WH8J9GONODA3QgMnza1EVMOxj60PNXXgeMmkscyRk7kz9qg==" rel="nofollow" target="_blank"><u>@Pfizer</u></a> and <a href="https://www.globenewswire.com/Tracker?data=_G7bMvP0UnHgRNdBi7C58aDSWJrj99jYJyKkvw72mTcupprjbYWTE_o_8oUmeQOe0zPfz4E2RmC-oF4TaVBRlXH8iP_6Bix5Xu9JnlN_J7M=" rel="nofollow" target="_blank"><u>@Pfizer News</u></a>, <a href="https://www.globenewswire.com/Tracker?data=33yxYtC2I0K4tZPfGski5s3o4ZHP3agvfitL54fVKSjNuaz9dJMbcS2fs_yowRkoI0H6GkHJ-V8eJS481Br7O_HudP6nCQCn8GgLiQR8_ao=" rel="nofollow" target="_blank"><u>LinkedIn</u></a>, <a href="https://www.globenewswire.com/Tracker?data=wDqRtJtHVFLrdnoY4rjV_QUVojDDDSL9NIZNQLhPL9rquT_S_TQq6AO4do7dxb91mS86msyzNiDLUOTenvwXSw==" rel="nofollow" target="_blank"><u>YouTube</u></a> and like us on Facebook at <a href="https://www.globenewswire.com/Tracker?data=dksh0JnhdKBurO_iVOmXvoO4yOIddjXTCsCPmWuYLjSsFuZnBZqF1BL6C2m7YnFEj37K3VlD2qyWE_dSx5HscHETzEHDKFBMIAuvMoaa-uE=" rel="nofollow" target="_blank"><u>Facebook.com/Pfizer</u></a>.</p>  <p><strong>Pfizer Disclosure Notice</strong><br>The information contained in this release is as of November 18, 2020. Pfizer assumes no obligation to update forward-looking statements contained in this release as the result of new information or future events or developments.</p>  <p>This release contains forward-looking information about Pfizer’s efforts to combat COVID-19, the collaboration between BioNTech and Pfizer to develop a potential COVID-19 vaccine, the BNT162 mRNA vaccine program, and modRNA candidate BNT162b2 (including qualitative assessments of available data, potential benefits, expectations for clinical trials, anticipated timing of regulatory submissions and anticipated manufacturing, distribution and supply), that involves substantial risks and uncertainties that could cause actual results to differ materially from those expressed or implied by such statements. Risks and uncertainties include, among other things, the uncertainties inherent in research and development, including the ability to meet anticipated clinical endpoints, commencement and/or completion dates for clinical trials, regulatory submission dates, regulatory approval dates and/or launch dates, as well as risks associated with clinical data (including the Phase 3 data that is the subject of this release), including the possibility of unfavorable new preclinical or clinical trial data and further analyses of existing preclinical or clinical trial data; the ability to produce comparable clinical or other results, including the rate of vaccine effectiveness and safety and tolerability profile observed to date, in additional analyses of the Phase 3 trial or in larger, more diverse populations upon commercialization; the risk that clinical trial data are subject to differing interpretations and assessments, including during the peer review/publication process, in the scientific community generally, and by regulatory authorities; whether and when data from the BNT162 mRNA vaccine program will be published in scientific journal publications and, if so, when and with what modifications; whether …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine">https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine</a></em></p>]]>
            </description>
            <link>https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135984</guid>
            <pubDate>Wed, 18 Nov 2020 12:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding bad flamingo drawings with recurrent neural networks]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25135848">thread link</a>) | @swyx
<br/>
November 18, 2020 | https://colinmorris.github.io/blog/bad_flamingos | <a href="https://web.archive.org/web/*/https://colinmorris.github.io/blog/bad_flamingos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <article itemscope="" itemtype="http://schema.org/BlogPosting">

    
  
  

  <div itemprop="articleBody">
    <p>Have you played <a href="https://quickdraw.withgoogle.com/">Quick, Draw!</a> yet? It’s basically Pictionary, played against a neural network, and it’s a lot of fun. Not long ago, Google released a <a href="https://github.com/googlecreativelab/quickdraw-dataset">dataset</a> of some of the millions of sketches people have drawn so far over 345 categories.</p>

<p>In this post, I’ll just be looking at sketches in the ‘flamingo’ category. You can browse a random sample <a href="https://quickdraw.withgoogle.com/data/flamingo">here</a>. Some of them are lovely.</p>

<figure>
<img src="https://colinmorris.github.io/assets/quickdraw/svgs/nice_flamingos.svg">
</figure>

<p>Others, well…</p>

<figure>
<img src="https://colinmorris.github.io/assets/quickdraw/svgs/nonnice_flamingo.svg">
<figcaption>
It's, um, a viking ship with a chicken carved into the prow?
</figcaption>
</figure>

<p>What if we want to automatically identify the jankiest flamingos in the dataset?</p>

<h2 id="sketch-rnn-as-probability-estimator">Sketch-RNN as probability estimator</h2>

<p>Along with the datasets, Google has released some <a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/sketch_rnn#pre-trained-models">pre-trained models</a> that use the Sketch-RNN architecture described in <a href="https://arxiv.org/abs/1704.03477">this paper</a>.</p>

<p>These models were trained to generate new sketches. For example:</p>

<figure>
<img src="https://colinmorris.github.io/assets/quickdraw/svgs/generated_flamingos.svg">
</figure>

<p>But we can also repurpose them to get some insight into existing human-generated sketches. As I talked about in an earlier post on <a href="http://colinmorris.github.io/blog/dreaming-rbms">character-level RBMs</a>, learning to generate new examples of X is basically the same as learning the probability distribution of X.</p>

<p>So in addition to sampling from the learned distribution to generate new sketches, we can take existing sketches, and ask the model how probable it thinks they are. It seems reasonable that the sketches the model assigns the lowest probabilities should be among the ‘worst’.</p>

<h2 id="good-flamingos">Good flamingos</h2>

<p>Before we roast Quickdraw’s least gifted flamingo-drawers, let’s look at some of the ‘best’ flamingo sketches - i.e. those assigned the highest probabilities:</p>

<figure>
    <img src="https://colinmorris.github.io/assets/quickdraw/svgs/flamingo_best.svg">
</figure>

<p>Audubon they ain’t, but these are at least mostly recognizable as flamingos. Because we’re ranking by probability, we should in some sense expect the most ‘typical’ sketches here, rather than the most beautiful.</p>

<h2 id="bad-flamingos">Bad flamingos</h2>

<p>To quote Tolstoy, <i>happy flamingos are all alike, but every garbage flamingo is garbage in its own way</i>.</p>

<p>We can broadly classify our worst birds into a few groups.</p>

<h3 id="well-intentioned-but-frankly-awful">Well-intentioned but frankly awful</h3>

<p>God bless these artists, they really tried.</p>



<p>You can check out some more examples <a href="https://colinmorris.github.io/assets/quickdraw/svgs/botflamingos_awful.svg">here</a>.</p>

<h3 id="scribbles">Scribbles</h3>



<p>In most cases, the artist started out with something flamingo-like, then scratched it out in frustration. The Quickdraw dataset encodes sketches as a sequence of pen strokes, rather than just a grid of pixels, so we can actually reconstruct the history of sketches like this:</p>



<h3 id="cheating-attempts">Cheating attempts</h3>



<h3 id="wrong-category">Wrong category</h3>



<p>There are some cases where the artist was pretty clearly drawing a different Quickdraw category like ‘pineapple’, or ‘compass’. It’s not clear whether it was a glitch that landed these images in the flamingo dataset, or user error (maybe the players didn’t realize they ran out of time and were given a new category?).</p>

<h3 id="have-you-ever-even-seen-a-flamingo">Have you ever even seen a flamingo?</h3>



<p>More head-scratching examples <a href="https://colinmorris.github.io/assets/quickdraw/svgs/botflamingos_wtf.svg">here</a>. The ‘wrong category’ explanation doesn’t work for most of these, because they don’t look like any of Quickdraw’s other categories (for example, there are no categories for ‘beaver’, ‘sitar’, or ‘female skeleton doing aerobics’).</p>

<h3 id="graffiti">Graffiti</h3>

<figure>
    <img src="https://colinmorris.github.io/assets/quickdraw/svgs/graffiti_censored.svg">
</figure>

<p>Some scoundrels just treated Quickdraw like a bathroom wall. The uncensored version is <a href="https://colinmorris.github.io/assets/quickdraw/svgs/graffiti_uncensored.svg">here</a> (NSFW).</p>

<h3 id="the-unjustly-maligned">The unjustly maligned</h3>



<p>Most of what I found was garbage, but the three above are actually kind of gorgeous. Add some colour to #3 and it could be a New Yorker cover! What gives?</p>

<p>These are great drawings, and pretty recognizable as flamingos, but that doesn’t count for much. We’re not ranking by how clearly these images represent their subject (i.e. <code>P(category=flamingo | drawing)</code>), but rather how likely someone is to come up with this when asked to draw a flamingo (<code>P(drawing | category=flamingo)</code>).</p>

<p>Very few people would think to draw the legs and head, with the body out of frame, as #3 does. #1 uses unusually many short, disconnected lines, and #2 uses a unique stylized head shape.</p>

<figure>
<div>
    <p><img src="https://colinmorris.github.io/assets/quickdraw/svgs/bottom/notbad/5.svg">
    </p>
    <p><img src="https://colinmorris.github.io/assets/quickdraw/Audubon-Flamingo.jpg">
    </p>
</div>
<figcaption>Left: Anonymous Quickdraw artist. Right: The American flamingo, illustrated by by <a href="https://en.wikipedia.org/wiki/John_James_Audubon">John Audubon</a>.</figcaption>
</figure>

<p>The drawing above is another good example. Flamingos do bend their heads down low like that, but when asked to draw a flamingo, almost no-one thinks to pose it with its head below the horizon.</p>

<p>
You can browse a gallery of all the bottom 400 flamingos <span><a href="https://colinmorris.github.io/badflamingos">here</a></span> (warning: contains a few NSFW sketches).
</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p>It totally could be!</p>

<p>Google described their dataset as being ‘individually moderated’, and you can scroll through the examples <a href="https://quickdraw.withgoogle.com/data/flamingo">here</a> for a long time before hitting any graffiti (and if you do find any, you can even click it to ‘flag as inappropriate’). It seems they’ve already done a pretty good job of filtering out most of the irrelevant/malicious sketches that were surely rampant in the raw data.</p>

<p>But this approach was able to easily identify a subset of sketches containing a high density of overlooked graffiti, scribbles, and irrelevant sketches. And it’s quite ‘cheap’, since it uses an existing model trained for a different purpose. If we wanted to go further, this would be a good place to start to get some labelled examples to bootstrap a graffiti classifier.</p>

<h2 id="appendix-measuring-probability">Appendix: Measuring probability</h2>

<p>(Warning: There are no more funny flamingo sketches ahead, just boring technical details.)</p>

<p>I’ve been talking about measuring the ‘probability’ a Sketch-RNN model assigns to each sketch, and ranking by those probabilities, but the truth is a little messier. There are a few complications we need to consider here.</p>

<h3 id="probability-vs-probability-density">Probability vs. probability density</h3>

<p>Sketch-RNN models the location of the pen as a continuous random variable. In this view, the probability of any stroke’s (x, y) position, and therefore of any sketch as a whole, is 0. So it makes more sense to talk about measuring the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density</a> of sketches. If A’s density is twice B’s, then A is in some sense ‘twice as likely’. (Both sketches still have probability zero, but we can measure a non-zero probability for the set of similar sketches in some tiny neighbourhood of equal size around A and B, and the probability near A will be twice as high).</p>

<h3 id="varying-lengths">Varying lengths</h3>

<p>Sketch-RNN outputs probabilities (/densities) per stroke. The natural way to get the probability (density) for a sketch as a whole would be to multiply the values for each stroke. (Densities can be multiplied together much like probabilities.)</p>

<p>However, the number of strokes per drawing in the dataset varies:</p>

<figure>
    <img src="https://colinmorris.github.io/assets/quickdraw/nstrokes.png">
    <figcaption>
        I couldn't find much information on how the dataset was preprocessed, but it seems pretty clear that this poor distribution has been violently amputated.
    </figcaption>
</figure>

<p><em>A priori</em>, we’d expect longer sketches to be less probable - every time we multiply probabilities, we get a smaller number. In language modeling, we’d control for this by measuring the <a href="https://en.wikipedia.org/wiki/Perplexity#Perplexity_per_word">perplexity per word</a> of a sentence or longer text. We can do something similar here, and measure the density per stroke.</p>

<p>(An interesting twist is that sorting by non-normalized densities, the sketches with the lowest <em>and</em> the highest values were biased toward having more strokes, which completely broke my intuition. The reason for this is that, unlike probabilities, densities can be greater than 1. If the strokes in a sketch mostly have densities greater than 1, then adding more strokes leads to a higher overall density. This doesn’t mean that strokes <code>S_1, S_2, S_3</code> are more likely than their prefix <code>S_1, S_2</code> (that’d be weird). It means that comparing the values of density functions with different dimensions is generally a bad idea.)</p>

<h3 id="what-i-actually-did">What I actually did</h3>

<p>I sorted on formula (9) in <a href="https://arxiv.org/pdf/1704.03477.pdf">this paper</a> - the reconstruction loss. This is basically the log density of the sketch (times the constant, <code>-1/N_max</code>). A minor deviation from (9): <code>L_p</code>, the loss with respect to pen state, is summed up to the number of strokes in the sketch,<code>N_s</code>, not the maximum strokes per sketch,<code>N_max</code>. (This is actually <a href="https://github.com/tensorflow/magenta/blob/v0.1.13/magenta/models/sketch_rnn/model.py#L298">a hidden feature of the code</a> when running in evaluation mode. I’m not sure whether the loss figures they reported e.g. in Table 1 include this tweak, but I’d be surprised if it makes much difference.)</p>

<p>The <a href="https://colinmorris.github.io/badflamingos">Bad Flamingos</a> page sorts by the loss function normalized by number of strokes. The examples on this page were mostly selected from the sketches with the worst unnormalized values. Qualitatively, both metrics gave pretty reasonable results with a high degree of overlap, but I ended up preferring the normalized version because its bottom N had a more representative distribution of lengths. The fact that unnormalized loss worked at all is basically a fluke and not something to rely on - if you rescaled the (x,y) values of pen positions to different units, it could drastically change the sort for unnormalized loss, but it wouldn’t affect <code>loss/nstrokes</code>.</p>

<p>All the code for this experiment is available <a href="https://github.com/colinmorris/sketch-rnn-experiments">here</a>.</p>

  
    
        
        
      <p>
        <small>Tagged: <a href="https://colinmorris.github.io/blog/tagged/machine-learning/">Machine Learning</a></small>
      </p>
    


  </div>



      

</article>

  </div>
</div></div>]]>
            </description>
            <link>https://colinmorris.github.io/blog/bad_flamingos</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135848</guid>
            <pubDate>Wed, 18 Nov 2020 12:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Months of Tiny Projects]]>
            </title>
            <description>
<![CDATA[
Score 854 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25135752">thread link</a>) | @tinyprojects
<br/>
November 18, 2020 | https://tinyprojects.dev/posts/six_months_of_tiny_projects | <a href="https://web.archive.org/web/*/https://tinyprojects.dev/posts/six_months_of_tiny_projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	
	<nav>
		<a href="https://tinyprojects.dev/">Home</a>
		<a href="https://tinyprojects.dev/projects">Projects</a>
		<a href="https://tinyprojects.dev/guides">Guides</a>
		<a href="https://tinyprojects.dev/blog">Blog</a>
	</nav>
	
	<p><i>November 18th 2020</i></p>

	<p>Six months ago, I set myself the goal of creating one tiny project each week.</p> 

	<p>My main aim was to get better at testing out all the ideas I had written down in my phone, but not actually done anything with.</p>

	<p>26 weeks later, and a quick glance of this website, you'll notice I've launched 6 things.</p>

	<p>Although I'm 20 projects short, it's not all bad. My projects are generating some passive income, I've gone from no online following, to a few hundred twitter followers, and I've had a great time building weird and wonderful internet things.</p>

	<p>In this post I'll give an update on how these projects are performing, and the pros and cons of launching micro-businesses.</p>

	<p>Let's rewind.</p>

	<h3>💡 <a href="https://tinyprojects.dev/projects/tiny_website" target="_blank">Tiny Website</a></h3>
	<ul>
		<li><i>Page views: <b>129,000</b></i></li>
		<li><i>Unique users: <b>58,000</b></i></li>
		<li><i>HN Upvotes: <b>348</b></i></li>
		<li><i>Cost: <b>£10.00</b></i></li>
	</ul>

	<p>Tiny Projects was born the day after my 25th birthday. Project #1 is this bare-bones tiny website that you're reading right now.</p>

	<p>When it launched, the only content on this website was a blog post, a guide on making tiny websites, and an update about my goals.</p>

	<p>Randomly, I decided to submit my blog post "Tiny websites are great" onto Hacker News. Over the next 24 hours it hit the top of the front page, bringing 25k users to this site in its first day. It was absolutely thrilling.</p>

	<p>As a double whammy, the guide I'd produced also hit the top of the learn programming sub-reddit with 1.3k upvotes.</p>

	<p>Somehow, I'd managed to hit a homerun with no idea what I was doing. Pageviews, followers and emails were flying in fast. Anyone who has produced a bit of viral content on the internet will know, the dopamine rush is insane.</p> 

	<h3>🌐 <a href="https://tinyprojects.dev/projects/silicon_valley_domain_names" target="_blank">Silicon Valley Domain names</a></h3>
	<ul>
		<li><i>Page views: <b>28,500</b></i></li>
		<li><i>Unique users: <b>25,500</b></i></li>
		<li><i>HN Upvotes: <b>410</b></i></li>
		<li><i>Cost: <b>£76.25</b></i></li>
	</ul>

	<p>Funnily enough, my second Tiny Project was the only one I actually completed in a week. Spurred on by the previous project, I was keen to replicate my success.</p>

	<p>I wanted to investigate domain names. Specifically, was it possible to buy a google.x domain name? It was an investigative piece with a bit of coding sprinkled in.</p>

	<p>Completing this project in a week was gruelling. My day-job was neglected, and I pulled some very long hours. However, 7 days later, I hit publish on my second blog post: "I bought netflix.soy".</p>

	<p>Again, I posted it on Hacker News. It became the most viral thing I've written.</p>

	<p>The Tiny Projects website received 28k page views, and the post got 410 upvotes. Hundreds of followers and emails again poured in.</p>

	<p>Writing two viral pieces back-to-back made me question what I was really doing. Somehow I'd  stumbled into writing click-baity blog posts for Hacker News instead of building tiny projects.</p>

	<p>6 months on, I still own all the domains I purchased for this project except the Facebook one. Damn you Zuck.</p>

	<h3>⚔️ <a href="https://tinyprojects.dev/projects/battle_royale" target="_blank">8-bit Battle Royale</a></h3>
	<ul>
		<li><i>Downloads: <b>25</b></i></li>
		<li><i>HN Upvotes: <b>3</b></i></li>
		<li><i>Revenue: <b>£0.00</b></i></li>
		<li><i>Cost: <b>£36.71</b></i></li>
	</ul>

	<p>For my third tiny project, I decided I wanted to make an online game.</p>

	<p>With minimal knowledge of Unity, I cobbled together a tiny battle royale game called "Wee Royale" in 2 weeks and launched it on Android.</p>

	<p>Posting this project write up on Hacker News got zero attention. I expected this, as it didn't really fit the usual HN content, but I was still disappointed. My brain had been jaded by the massive numbers of the first two posts.</p>

	<p>Wee Royale currently has 25 downloads on the Google Play Store. I'm actually not sure if the game still works though.</p>

	<p>Overall, Wee Royale was a flop, but it was hilarious to play it with my friends.</p>

	<h3>🛍️ <a href="https://tinyprojects.dev/projects/one_item_store" target="_blank">One Item Store</a></h3>
	<ul>
		<li><i>Page views: <b>1,500</b></i></li>
		<li><i>Stores: <b>1,400</b></i></li>
		<li><i>PH Upvotes: <b>83</b></i></li>
		<li><i>Revenue: <b>£1.63</b></i></li>
		<li><i>Cost: <b>£41.00</b></i></li>
	</ul>

	<p>With a minimalist design, and the tag line "just sell your stuff", One Item Store lets anyone create an online shop in minutes to sell their goods.</p>

	<p>After two weeks of building my micro e-commerce platform, I launched it on Product Hunt. At the end of the day I finished on the homepage with 83 upvotes.</p>

	<p>Today, people have created over 1400 stores, selling everything from t-shirts, to human beings. I've seen some very strange things.</p>

	<p>In total, £163.09 has flowed through One Item Store checkouts, mainly from a car dealership in Australia offering deals throughout the pandemic. I take a small 1% fee on every transaction, netting me a small fortune of £1.63.</p>

	<p>Although its not a significant amount, this was my first Tiny Projects internet money! The best thing is, One Item Store makes money without me having to do anything.</p>

	<p>One Item Store is a Tiny Project I'd like to continue building. My next step would be to add some better checkout designs, and make the website look a bit more legit.</p>

	<h3>📗 <a href="https://tinyprojects.dev/projects/snormal" target="_blank">Snormal</a></h3>
	<ul>
		<li><i>Page views: <b>2,000</b></i></li>
		<li><i>Users: <b>200</b></i></li>
		<li><i>PH Upvotes: <b>59</b></i></li>
		<li><i>Revenue: <b>£0.00</b></i></li>
		<li><i>Cost: <b>£10.00</b></i></li>
	</ul>

	<p>Snormal is a social network for everything that doesn't make it onto your Instagram highlight reel. A typical post on Snormal is something like: "Dude, I just ate a whole baguette in bed".</p>

	<p>I launched Snormal with zero intentions of making any money. It was a bit of a social experiment to see if people were becoming as jaded with social media as me.</p>

	<p>After 1 month of building, and an accidental Product Hunt launch, Snormal has gone on to gain 200 registered users, who have scrolled 4432 times on the discover feed.</p>

	<p>Its incredibly fun running a micro-social network.</p>

	<p>Two weeks after Snormal launched, I hadn't implemented comments on posts. When I finally added them, it felt godlike letting people finally talk to each other.</p>

	<p>Growth on Snormal slowly increasing. For some strange reason it has become popular in Portugal. Have a scroll now, and you'll see loads of statuses in Portugese.</p>

	<h3>💸 <a href="https://tinyprojects.dev/projects/earlyname" target="_blank">Earlyname</a></h3>
	<ul>
		<li><i>Page views: <b>10,000</b></i></li>
		<li><i>Subscribers: <b>1,500</b></i></li>
		<li><i>PH Upvotes: <b>274</b></i></li>
		<li><i>MRR: <b>$200.00</b></i></li>
		<li><i>Cost: <b>$108.20</b></i></li>
	</ul>

	<p>Earlyname helps you claim rare usernames (like @ben or @alice) on new, emerging social platforms. Currently it is generating $200/month.</p>

	<p>Running Earlyname is so much fun. I get to talk with founders, try out new products, do a bit of web scraping/automation, and find rare usernames for people.</p>

	<p>The only downside is that it requires my input every month to produce a new email. I'm anxious for the month I can't find any new social platforms.</p>

	<p>At present, Earlyname has 1500 subscribers on its email list, a number which thankfully seems to be growing naturally.</p>

	<p>Although its currently only at $200/mo, its cool to think Earlyname is generating $2k/year. My plan is to keep plugging away launching monthly newsletters and see how high that monthly revenue number can get.</p>

	<h3>👍 Positives of Tiny Projects</h3>

	<p>I believe there's a big advantage to this "micro-bet" approach of launching many tiny businesses, and then sticking with the ones that become successful.</p>

	<p>Firstly, it drastically reduces the risk of putting too much time into an idea that doesn't quite work. Even if you stumbled across a decent idea that did work, what if there's an amazing one just around the corner? It keeps you on your toes.</p>

	<p>Creating lots of tiny businesses also keeps things fun and interesting. This is probably the most important factor for me.</p>

	<p>Feeling obligued to keep building something that you've sunk hundreds of hours into but no longer enjoy sounds like my personal hell.</p>

	<p>With tiny projects, the stakes are so low, I can kill a project with no guilt and build something else, or just bounce between the projects I want to work on.</p>

	<h3>👎 Negatives of Tiny Projects</h3>

	<p>My original plan was to launch one tiny project each week, however I've realised this is an insane schedule. You can't build or document anything meaningful in this time.</p>

	<p>This schedule might be possible if I treated Tiny Projects full-time like a YouTuber. But, I don't think going all in on Micro-SaaS businesses would be very fun with the revenue they're currently generating.</p>

	<p>1-2 months is a more reasonable tiny project timeframe. It gives you enough time to build something with substance, and test the idea thoroughly.</p>

	<p>One major downside of launching lots of things is that you become way too happy to give up on a project when it doesn't show instant success.</p>

	<p>Perhaps if I spent more time on marketing, or slightly pivoted a project, I could see more success. Currently, I'm more inclined to just start something new.</p>

	<p>Maintaining lots of software can also become a bit of a burden. Once the domain name renewal date comes around, I'll have to make some decisions as to whether a project lives on for another year or not.</p>

	<h3>🔮 Conclusions &amp; The Future</h3>

	<p>I feel like I'm trying to learn the skill of generating better ideas, and rapidly building and launching them into a business.</p>

	<p>I try to think about this process like going for a run. The more runs I do, the faster and fitter I'll be. The more projects I launch, the better and more profitable they'll be.</p>

	<p>How often does someone build &amp; launch a business in their lifetime? I'm hoping that by doing this process over and over again, I'll discover some really interesting things.</p>
	
	<p>My main goal for the next six months of Tiny Projects is to learn how to get better at making money on the internet from my projects.</p>

	<p>A Product Hunt launch can easily get you a spike in traffic, but afterwards I really don't know what I'm doing. There's this whole other level afterwards called "sales &amp; marketing" that I want to master.</p>

	<p>Another goal is to also be more consistent with my writing. Hopefully, this ultimately means you'll be hearing a lot more things from me!</p>

	<p>It was nice to catch up.</p>

	
	
	
	
	
	

</div>]]>
            </description>
            <link>https://tinyprojects.dev/posts/six_months_of_tiny_projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135752</guid>
            <pubDate>Wed, 18 Nov 2020 11:48:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI design for software developers. Part 1, Colors]]>
            </title>
            <description>
<![CDATA[
Score 226 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25135215">thread link</a>) | @Igor_Wiwi
<br/>
November 18, 2020 | http://amortizedcost.net/ui-desing-for-software-developer-part-1/ | <a href="https://web.archive.org/web/*/http://amortizedcost.net/ui-desing-for-software-developer-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: markdown--><p>In this series of articles, I will show full process of creating a UI design for <a href="https://play.google.com/store/apps/details?id=net.amortizedcost.batchimageshrinker">Batch Image Shrinker</a> (<a href="market://details?id=net.amortizedcost.batchimageshrinker">Google play link</a>) mobile application which I did by myself. As a software developer always I've been thinking that UI design is not for me, that it's complex and requires some art skill or something.</p>
<p>It's a myth and I will try to debunk it.</p>
<p>I will show you that UI design is for everyone, you just need to know some basic technics and a couple of tricks.</p>
<p>It's not going to be easy, but I promise you it will be very interesting.</p>
<h2 id="dominatingcolor">Dominating color</h2>
<p>With the dominating presence of dark-mode, I noticed that for me it was easier to work with darker colors as baseline colors than with brighter ones, and since  I almost always use dark-mode of the applications, so I wanted to have something similar in my application. I was certain that I didn't want to use <a href="https://colornames.org/color/3b5998">Facebook blue</a> color and it's successors, so I had to find something more futuristic and brave than that. My choice fell on <code>#464d77</code> which is a very intense dark blue, almost purple color.</p>
<p><img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-17-at-20.10.09.png" alt="Screenshot-2020-11-17-at-20.10.09"></p>
<p>Common advice here will be not to use pure black or white colors, which, as perfectly described in <a href="https://ianstormtaylor.com/design-tip-never-use-black/">the article</a>, hardly present in the real-world color pallet. <em>What a coincidence, I found <a href="https://lawsofux.com/aesthetic-usability-effect.html">a website</a> with a perfect example of dark background color and great content to read.</em></p>
<h2 id="colorpalette">Color palette</h2>
<p>Of cause, just one baseline color will not be enough to build a feature-rich application. You will need a couple of colors for different types of components like buttons, checkboxes, radio buttons, etc. Another one or two colors will be needed for the text itself. Also,  some gradients for several states of a component, such as "active", "disabled", "pressed". So before creating an actual UI, we will need to have a rich pallet of colors to work with. In my case, I ended up with 6 colors in total which was more than enough to create a simple yet interesting UI.</p>
<p>This step is much easier than the previous one, because here we will be either reusing or generating new color pallets using the baseline color from the previous part.</p>
<p>The generator which I was using is <a href="https://coolors.co/palettes/popular/f9db6d">this</a>. Here you could either put the color hex into a search bar or simply choose the pallet from the <a href="https://coolors.co/a1e8af-94c595-747c92-372772-3a2449">hundreds</a> of pre-generated ones. If the color range is not enough for you, try to extend it with <a href="https://learnui.design/tools/data-color-picker.html#palette">another</a> good palette generator. Put on the left side the baseline color and select how many colors you will need.</p>
<p>Pro-tip, you can combine those tools to get even more combinations. As you can see here, I was using a baseline color on the right side and colors from <a href="https://coolors.co/464d77-36827f-f9db6d-f4eded-877666">the palette</a> as values for the right side of the generator:</p>
<p><img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-16-at-23.50.31.png" alt="Screenshot-2020-11-16-at-23.50.31"><br>
<img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-16-at-23.51.04.png" alt="Screenshot-2020-11-16-at-23.51.04"></p>
<p>If you are not satisfied with the results try to get back to choosing the baseline color and repeat the whole process again. Since we are learning it's ok to do multiple roundtrips until your gut feelings tell you that that is it.</p>
<p>Once we are done with the color schema we are good to go to we move to the next step - choosing fonts, which will be covered next time.</p>
<!--kg-card-end: markdown-->
			</section><section>
				<p>Get the latest posts delivered right to your inbox.</p>
        


      </section></div>]]>
            </description>
            <link>http://amortizedcost.net/ui-desing-for-software-developer-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135215</guid>
            <pubDate>Wed, 18 Nov 2020 10:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frontpage: The Good, Bad and Ugly]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25135058">thread link</a>) | @jandeboevrie
<br/>
November 18, 2020 | https://invisibleup.com//articles/33/ | <a href="https://web.archive.org/web/*/https://invisibleup.com//articles/33/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/33/thumb.png" alt="FrontPage: The Good, The Bad, and The Ugly thumbnail">
	
	

	<p>PLEASE don't use FrontPage for modern web development! It's filled with security vulnerabilities and obsolete standards. The goal of this is not to convince you otherwise. The newest version came out almost two decades ago!</p>

<p>Microsoft FrontPage. The mere mention of that name is making most (if not all) of you seasoned web devs groan. "FrontPage was utter rubbish from dark ages of GeoCities" you say. "Everything it touched was ruined with horrific output and proprietary nonsense!" And yes, it was.</p>
<p>But... FrontPage as a concept. As a dream of what could have been, and a window into what <em>was</em>. Letting the typical home user at the time create websites, express creativity, and conquer the world by storm, all without being forced to learn HTML or CSS or JavaScript... In that regard, FrontPage couldn't be beat.</p>
<p>Let's talk about why Microsoft FrontPage was for a brief period of time the ultimate content creation tool of the Internet, and why it later fell from grace.</p>
<h2>History</h2>
<p>Before we can talk about goodness and ugliness, we need to talk about carphones and business meetings. Because this was 1994, when the Internet was still really new. At that point in time most internet chatter occured on Usenet groups (think something like Reddit) or BBS systems (think something like <a href="https://invisibleup.com//articles/5/">old AOL</a>; example pictured below). If you needed buisness stuff, like stocks or the such, you had to log onto the BBS of whoever had what you needed. This was kind of a pain.</p>
<p><img alt="A picture of a BBS (tilde.town) as of today" src="https://invisibleup.com//articles/33/BBS.png"></p>
<p>Enter Randy Forgaard and Charles H. Ferguson. Ferguson, renowned computer industry consultant, contacted MIT graduate Forgaard (over carphone, in case you were wondering) to discuss starting a new, internet-based company.</p>
<p>His idea was that many corporations such as the Dow Jones, Bloomberg, Apple, etc. were sinking millions into building their own, completely incompatible dial-in Internet services. Therefore, they should create a standardized, completely open server/client combo to replace all the independent efforts. This hopefully would reduce the cost of development for those corporations, and provide a market for growth by making buisnesses <em>want</em> to have an Interent presence.</p>
<p>The two decided to found their own company, Vermeer Technologies, Inc. A month later, still in the planning stages, they caught wind of the brand new World Wide Web out of CERN. It was decentralized, open, and even more robust than they were planning. It was just about perfect. The only issue was that it was rather a pain to make websites if you were just some lowly advertising manager or whoever. The web needed an authoring tool for websites.</p>
<p><img alt="FrontPage 1.0a, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-1.0.png"></p>
<p>So, somehow, they managed to hire many professional coders for no salary whatsoever to work on FrontPage. (Early start-up culture, perhaps?) Evidently it worked, as FrontPage was released (only!) a week behind schedule on October of 1995. By then the World Wide Web was exploding, with a 20% increase in sites <em>per month</em>. FrontPage also managed to explode, receiving many awards and positive reviews. In fact, it was so good that Microsoft ended up buying them out. According to them, not only did it feel like a native Office application, it was perfect for their ongoing plan to become more internet centric.</p>
<p><img alt="FrontPage 97, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-97.png"></p>
<p>FrontPage over the years got integrated into the Office suite and made a flagship product for Microsoft productivity products. By Office 2000, FrontPage had more Office integration than you should shake a stick at; nailing down the Office user interface and allowing imports and exports across the whole suite. There's... other stuff as well, but let's stay positive for now.</p>
<p>I'll be covering FrontPage 2002, as that's the version I own, and the one I have the most experience with.</p>
<h2>The Good</h2>
<p>The interface... is (in my opinion) one of the best interfaces for any program ever. No hyperbole. I think only the other Microsoft applications of the era like PowerPoint and Visio can top it. I can <em>see</em> why it won awards.</p>
<p><img alt="FrontPage's start screen with no webs open" src="https://invisibleup.com//articles/33/FP-Start.png"></p>
<p>Like any other Microsoft Office XP program, there's the sidebar on the right with common tasks. What you'll probably want to do is, of course, make a new site.</p>
<p>FrontPage's equivalent to "projects" are called "Webs". These Webs contain the files (all your HTML, CSS, images, etc.) and preferences (such as which web server to sync up with or what compatibility settings to use) for that website.</p>
<p><img alt="FrontPage's template selector" src="https://invisibleup.com//articles/33/FP-NewWeb.png"></p>
<p>Start by selecting a new "Empty Web". Up pops a bunch of templates, including the "Empty Web" template. A bit odd, but sure.</p>
<p><img alt="The &quot;Personal Homepage&quot; template in action" src="https://invisibleup.com//articles/33/FP-Template.png"></p>
<p>If you <em>were</em> to choose a template, it would give you a pre-populated fill-in-the-blanks site ready for your words and pictures. It takes some of the layout work and design originality out of it, but that <em>is</em> the purpose of a template after all. (Although, as a word of advice, <em>don't use these.</em> They're rather awfully designed from a web standards point of view. You can see it barely fitting in my window there. Imagine that on a smartphone.)</p>
<p><img src="https://invisibleup.com//articles/33/FP-BlankWeb.png" alt="FrontPage open to a new blank web. Folder list and Views bar are visible."></p>
<p>Anyways, once you open your blank web, you get... nothing! (That's what you asked for, isn't it?) No worries. Really, if you think about it, it would be rather silly to start making a page off the bat. You see, FrontPage takes a <em>project oriented</em> approach to things. While you easily <em>could</em> just sit down and start banging stuff out, that's really not the way FrontPage wants you to go.</p>
<p><img alt="FrontPage Navigation editor with some pages created and linked up." src="https://invisibleup.com//articles/33/FP-NavView.png"></p>
<p>Here's probably my favorite FrontPage feature: the Navigation editor. Here you create blank pages and link them together in a logical hierarchy. This closely resembles the process you'd usually take on paper when designing a website.</p>
<p><img alt="Navigation bar settings dialog" src="https://invisibleup.com//articles/33/FP-Navbar.png"></p>
<p>With this hierarchy, you can automatically create a navigation bar in all your pages that are properly linked. If you decide to make a new top-level page, for instance, every page on your site will be updated to feature that page. (To replicate that feature on this site, I had to use some pretty tricky template scripting with my custom Flask server. I'd vastly prefer something like this.)</p>
<p>This feature is also nice because it forces you to <em>think about your site</em>. You can't just sit down like it's Microsoft Word and bang out some pages. You need a coherent plan. Before you can even start, you need to sit down with your client/team/self and ask "What do you want on your website?" To most people it's obvious that you need a website. Everybody has a website. What's significantly less obvious is <em>what</em> needs to be on the website. And FrontPage's web editor allows you to play around with hierarchies and layouts before commiting to anything.</p>
<p><img alt="PowerPoint Slide Sorter mode&quot;" src="https://invisibleup.com//articles/33/PPT-SlideSorter.png"></p>
<p>One thing that's intersting is that Word, PowerPoint and Access all (vaguely) follow a similar model. Word has the Outline editor, PowerPoint has the Slide Sorter mode (pictured above, showing an interactive game I made when I was 11), and Access, being a typical database program, requires you to declare your tables before you can work on them.</p>
<p>What's even more interesting is that, with the exception of Access (which not many people used, mostly due to its cost and relative rarity), you were never <em>required</em> to have a plan before starting. Most people I've seen use Word just do straight typing, or perhaps work off another document with an outline. But the option was there! One could do their outline <em>in their document</em> and flesh out around that. Likewise with PowerPoint, as well.</p>
<p><img alt="Highlighted template include code" src="https://invisibleup.com//articles/33/FP-TemplateInclude.png"></p>
<p>Another common task in web design is defining a "template" page where you fill all your content into. For example, every page on this site you're reading on now has the same header and footer, and every article has the same sort of thumbnail image at the top. That was all scripted using template features.</p>
<p>FrontPage, being an Office product, supports templates. The implementation admittedly is <em>super</em> janky, but it's there. You can include pages within other pages just fine, it's just a little tricky to set up. (FYI, Word, Excel, and PowerPoint do templates too. It's one of their lesser-known features, IMHO.)</p>
<p><img alt="Report view window" src="https://invisibleup.com//articles/33/FP-Reports.png"></p>
<p>Another really neat feature: reports. Like a compiler in an IDE, FrontPage produces warnings, errors, and statistics for your site. At a glance I can view all broken links, orphaned pages, oversized images, etc. This is a <em>fantastic</em> feature, something that modern web dev software just <em>doesn't</em> have.</p>
<p><img alt="Hyperlinks view window" src="https://invisibleup.com//articles/33/FP-Links.png"></p>
<p>In the same vein as the Reports, you can see at a glance what links to what. It's a lot like the call chart in a software development IDE. I can see quickly every site linked from any page (shown here is <a href="https://invisibleup.com//articles/24/">the Sonic R color fix article</a>) and any subpages.</p>
<p><img alt="Tasks view, showing a task labeled &quot;Write FrontPage article&quot;" src="https://invisibleup.com//articles/33/FP-Tasks.png"></p>
<p>Last feature, although this isn't nearly as useful in the year 2020. In the tasks view, you can put up a list of tasks that needs to be accomplished. Already that seems rather nice for keeping track of what you need to do. It's a lot like GitHub or GitLab's issue tracker, in a sense.</p>
<p>However, if you connect to a server with FrontPage Web Extensions (I'll get to that...), you can share this task list with other people. You can (again, like an issue tracker) put up a task to be done by someone else and work on a task that somebody else put up. It's a <em>very</em> nice feature for web development, but nowadays this is normally handled by source control providers like GitHub or GitLab.</p>
<p><img alt="FrontPage editing the Sonic R color mod article" src="https://invisibleup.com//articles/33/FP-Editor.png"></p>
<p>And, of course, there's the webpage editor. This works almost exactly like Microsoft Word, with some web-flavored spice. You type words and they appear in the page. You make those words blue, they're blue. <em>That said</em>, when you edit elements like that, it inserts an HTML 3.2 style <code>&lt;FONT&gt;</code> tag instead of trying to match it to a CSS rule. There's ways around this, but you have to be very diligent in doing so. This is mostly just due to FrontPage being a product of its time, though.</p>
<p>FrontPage is a program about planning, executing, and reviewing. Take the Navigation editor. You plan out the content of your site. You sketch up the layout. Then you reflect on if your layout matches your requirements. Or the Reports. Create content, check reports. Or the Tasks. Plan out what you need to do, do that, and then check if the task is complete. That, right …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com//articles/33/">https://invisibleup.com//articles/33/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com//articles/33/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135058</guid>
            <pubDate>Wed, 18 Nov 2020 10:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cobalt – Lightweight Electron Alternative]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25134848">thread link</a>) | @ash
<br/>
November 18, 2020 | https://cobalt.foo/overview.html | <a href="https://web.archive.org/web/*/https://cobalt.foo/overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="centerCol">
      <div id="content">
        <p>Cobalt is a lightweight HTML5/CSS/JS application container that is designed
to provide a rich application development environment with minimal resource
consumption (deployment size, RAM, CPU, GPU). At the same time, Cobalt enables
a rich, low-latency user experience across a wide variety of platforms and
devices.</p>

<h4 id="target-audiences">Target audiences</h4>

<p>Cobalt's documentation is written with two audiences in mind:</p>

<ul>
<li><p><strong>Porters</strong> enable Cobalt to work on other platforms by using Starboard,
Cobalt's porting layer and OS abstraction, to implement the
platform-specific functionality that Cobalt uses. Each Starboard module
(memory, socket, thread, etc.) defines functions that must be implemented
for the porter's platform.</p></li>
<li><p><strong>Developers</strong> want to build applications in familiar environments with
advanced debugging tools without having to worry about compatibility with
a highly fragmented set of browsers. At the same time, they want to have
full control over their codebase so that they can ship features for
constrained platforms, like TVs, on time and without technical risk.</p></li>
</ul>

<h2 id="benefits-of-cobalt">Benefits of Cobalt</h2>

<p>Cobalt significantly reduces the cost of supporting a browser on non-standard
and resource-constrained platforms. In addition, since Cobalt operates at a
consolidated, versioned platform abstraction layer, its porting effort is
man-weeks, and subsequent rebases are near-free.</p>

<p>These are some other benefits that Cobalt provides:</p>

<ul>
<li><p><strong>More platforms</strong></p>

<ul>
<li>  Cobalt does not require platforms to support JIT compilation and can
run on platforms that disallow execution of dynamically generated code.</li>
<li>  Cobalt is a single-process application and does not rely on the ability
to spawn multiple processes.</li>
<li>  Cobalt precompiles a set of shaders that are sufficient to express all
graphical effects, thereby accommodating platforms that cannot compile
shaders at runtime.</li>
<li>  Cobalt requires a compliant C++11 compiler, allowing it to reach
platforms with toolchains that don't support the newest C++17 features.</li>
</ul></li>
<li><p><strong>Small footprint</strong></p>

<ul>
<li>  Cobalt is optimized for memory. Its surface cache never exceeds a
predefined budget, and it never creates duplicate layers, reducing
the likelihood of out-of-memory crashes.</li>
<li>  Cobalt's small binary is designed to take up as little space as
possible. By supporting a subset of HTML5/CSS/JS, Cobalt's reduced
package size even allows bundling of CJK fonts on low-end devices.</li>
</ul></li>
<li><p><strong>Reduced input latency</strong></p>

<ul>
<li>  Cobalt produces consistent 60FPS animations by only supporting
animation of properties that don't affect layout, like <code>transform</code>,
and always running animations on a separate thread.</li>
<li>  Cobalt is optimized to run on single-core CPUs, resulting in better
input latency since the renderer and resource loader do not compete
with layout operations.</li>
<li>  On platforms that support GLES2, Cobalt avoids CPU painting by
performing almost all rendering operations on the GPU.</li>
</ul></li>
</ul>

<h2 id="getting-started">Getting started</h2>

<h3 id="porters">Porters</h3>

<p>Porters should begin with the <a href="https://cobalt.foo/starboard/porting.html">porting guide</a>,
which explains how to use Starboard, Cobalt's porting layer, to customize the
platform-specific functionality that Cobalt uses. There are several reference
documents to help porters customize configuration files and to implement
module-specific functionality. The <a href="https://cobalt.foo/starboard/testing.html">Testing with
NPLB</a> document provides an overview of
Starboard's compliance test suite.</p>

<h3 id="developers">Developers</h3>

<p>Developers can follow the setup instructions for
<a href="https://cobalt.foo/development/setup-linux.html">Linux</a> or
<a href="https://cobalt.foo/development/setup-raspi.html">RasPi</a> to set up their Cobalt development
environment, fetch a copy of the Cobalt code repository, and build a Cobalt
binary. The <a href="https://cobalt.foo/development/reference/supported-features.html">Cobalt support</a>
guide lists the HTML elements, CSS properties, CSS selectors, and JavaScript Web
APIs that developers can use in their Cobalt applications.</p>

        
          
            
          
        
      </div>
    </div></div>]]>
            </description>
            <link>https://cobalt.foo/overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134848</guid>
            <pubDate>Wed, 18 Nov 2020 09:34:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I/Q Data for Dummies]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25134698">thread link</a>) | @pabo
<br/>
November 18, 2020 | http://whiteboard.ping.se/SDR/IQ | <a href="https://web.archive.org/web/*/http://whiteboard.ping.se/SDR/IQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">
<p>This is a description of using I/Q Data (aka "analytic signal") representing a signal. Since the topic may be quite confusing, I've described the same thing here from different point of views. If you find the information somewhat redundant, it is because it is. Different views may appeal to different readers, and if something seems unclear, keep on reading and it may be more comprehensible later - hopefully.
</p>
<h2>Why I/Q Data?</h2>
<p>I/Q Data is a signal representation much more precise than just using a series of samples of the momentary amplitude of the signal. Have a look at the following signal below.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/cosample.png" alt="Plain signal" title="Plain signal"></p>
<p>This is what you may be used to work with. So why I/Q Data - isn't this good enough?
</p>
<p>Not really. We have a few problems here.
</p>
<ul><li>First, it is impossible to determine the frequency of this signal. Sure, it looks simple enough, just look at the period length? True, but you have no clue if it's a positive or negative frequency since they both generate the same curve. I.e. cos(x) = cos(-x). This becomes a problem working with the signal. Mixing (multiplying) two signals and it'll cause multiple solutions due to the uncertainty of the sign: f1 âŠ— f2 equals f1 + f2 as well as f1 - f2.
</li><li>Second, it's hard to determine the power (peak amplitude, envelope) of the signal. Basically you can only see the peak amplitude here at 0Â°, 180Â°, 360Â° etc, and how do you know the power is the same everywhere else as well? And did you sample the signal exactly at its peak? You really don't know.
</li></ul><p>I/Q Data solves this. Instead of looking at the signal as a flat curve as above, look at it as a corkscrew (helix, spiral, coil spring) in three dimensions.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkscrew.png" alt="Complex signal" title="Complex signal"></p>
<hr>
<p>Now if you look at this curve from the side, you'll actually get the same graph as the first one above. Your "real" signal actually is this 2D projection of this corkscrew signal. This is your "I" in I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkI.png" alt="Side view" title="Side view"></p>
<hr>
<p>Now have a look at the corkscrew from above. This looks quite similar, but as you see, it is out of phase 90Â°  starting at zero, not at one as the other. This this the Q part of your I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkQ.png" alt="Top view" title="Top view"></p>
<hr>
<p>Now looking at the corkscrew down the time axis you'll see it winds counter-clockwise. This means we know the frequency is positive. It could have wound clockwise as well, still generating the same I-signal (projection) but different Q-signal, representing a negative frequency.
</p>
<p>You also see that the radius of the corkscrew is constant at every sample, if small in I large in Q and vice versa. The radius is the peak amplitude of your signal. 
</p>
<p>The axes are of course 90Â°, so the radius must be equal to (IÂ²+QÂ²)<sup>1/2</sup>. This is the peak amplitude of your signal, and as you can see you know this for each and every sample.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkT.png" alt="Viewed down time axis" title="Viewed down time axis"></p>
<h2>What is I/Q Data?</h2>
<p>AS you now understand, the I/Q Data Sample is the coordinates of your signal as seen down the time axis of the corkscrew.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/onesample.png" alt="" title=""></p>
<p>You might object that your signal isn't a pure cosine function as the one we have shown here, and it might be very true. Still, every single sample of your signal can be described as such, i.e. with a peak amplitude times cosine of some phase angle.
</p>
<p>Every single point of your signal can be described as the function Aâ‹…cos(Ï•)
</p>
<p>Since you may freely chose any amplitude A and angle Ï• this must of course be true (as long as the signal is continuous). The value of Aâ‹…cos(Ï•) is the <strong>I</strong> component of the I/Q signal, i.e. your real signal. Note that this only describes your signal in one single point, i.e. one sample. Next sample gives you a new I and Q very likely resulting in another amplitude and/or phase angle, reflecting the modulation of the signal.
</p>
<h2>One sample I/Q Data</h2>
<p>Ok, lets take one sample of I/Q Data and see what it represents. This is also called a phase vector, or phasor.
</p>
<pre>I = 0.69
Q = 0.40
</pre>
<p>Lets draw this in the complex plane.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/iqdraw1.png" alt="" title=""></p>
<p>Lets see what this tells us about our data point.
</p>
<ul><li>The momentary amplitude of our real signal is by definition <strong>I</strong>, i.e. 0.69
</li><li>Pythagoras tells us the amplitude A of the cosine wave is <code>(0.69Â²+0.40Â²)<sup>1/2</sup> = 0.8</code>
</li><li>Trigonometry tells us our angle is +30Â° into our cosine wave.
</li></ul><p>- <em>Hold it</em>, you say, <em>what cosine wave?</em>
</p>
<p>Well, I/Q actually assumes your real signal (<strong>I</strong>, that is) can be described as the
function <strong>I</strong> = Aâ‹…cos(Ï•)
</p>
<p>Since you are free to chose A and Ï• this must of course be true, as long the function is continuous. Remember we are looking at one single sample now, i.e. one point in time.
</p>
<p>So by using IQ Data we not only get the momentary values of our signal, but the function generating it as well. If we put above together we get:
</p>
<p>The real signal I = 0.8â‹…cos(30Â°)
</p>
<hr>
<ul><li>I/Q Data is the representation (data type) of this cosine function.
</li></ul><p>I/Q Data is the rectangular representation of the polar notation we used above. There is a unique transformation between the two, and the different notations have different properties calculating with them. The rectangular form of I/Q Data is chosen due to the ease of hardware implementations of the most common operations.
</p>
<p>I/Q Data consists of I and Q represented as two separate variables, a vector of length two, or more often, the complex number  I + Q<em>i</em>  (yes, I is the real part).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/polrep.png" alt="" title=""></p>
<p>Note that the Amplitude above is the waves peak amplitude, not the momentary amplitude.
</p>
<ul><li>I is the current momentary amplitude of the signal (i.e. the Real signal)
</li><li>Q is the momentary amplitude of the signal phase shifted -90Â°.
</li></ul><p>For a simple function such as sine, the phase shift is what the signal was earlier in time, but for a signal with more than one sine component, Q reflects a -90Â° shift of the individual components, and not the composite signal as such. To convert a Real Signal to a I/Q Data Signal, discrete Fourier transformation is required (Hilberts transform).
</p>
<h2>Different ways of representing the same I/Q Data Sample</h2>
<p>There are at least three common ways to represent the I/Q Data Sample. Different representations gives you different pros and cons. Some are more easy to add, other are more easy to multiply etc. This may be important in the implementation, resulting in less complex hardware/software using the best representation.
</p>
<h3>The rectangular form</h3>
<p>The I/Q Data on the form Q and I is called "rectangular" (or "Cartesian") form as it can be viewed as positions in a coordinate system. I and Q are the x and y axis respectively. This is the most common representation you are used to. This form is most common due the ease of modulating/demodulating it in hardware. More about that later.
</p>
<ul><li>As a complex number: I + Q<em>i</em>
</li><li>As a vector [I,Q]
</li><li>Or just the two plain variables I and Q
</li></ul><h3>The polar form</h3>
<ul><li>Amplitude and angle
</li></ul><p>I = Amplitudeâ‹…cos(angle) <br>Q = Amplitudeâ‹…sin(angle)
</p>
<p>The Amplitude is the peak amplitude of the cos (and sin) function, and the angle is how far into the period from zero to 360Â° you are (or 0 to 2Ï€ if you prefers radians).
</p>
<h3>Eulers form</h3>
<p>Since cos(Ï•) + iâ‹…sin(Ï•) = e<sup>iÏ•</sup> we can write our IQ sample as
</p>
<p><span> Ae<sup>iÏ•</sup> </span>
</p>
<p>This might (not?) be the most intuitive representation of the sample. Ï• rotates the angle as seen in the polar representation, and A is of course the amplitude. Realizing this, Eulers identity becomes obvious. Because Ï• is the rotation of the vector in the complex plane, rotating it half a turn, 180Â° or Ï€ radians, results in a real part of -1 and no imaginary part, hence:
</p>
<p><span> e<sup>Ï€i</sup>+1 = 0 </span>
</p>
<p><em>"The student should find this to be immediately obvious,</em> <br><em>otherwise he'll never be a first rate mathematician"</em>
</p>
<p><em>-- Carl Friedrich Gauss </em>
</p>
<h2>Positive versus negative frequency</h2>
<p>It is now easy to see that using I/Q we can represent the signal frequency either as positive or negative. Have a look at the two I/Q signals red and blue below to the left and compare them with their corresponding real projections. It is as obvious they differ in signs in I/Q, as it's impossible to determine the signs using only the real signal component (neither the I nor the Q projection separately).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/freqsign.gif" alt="Positive versus negative frequencies" title="Positive versus negative frequencies"></p>
<p><span>(sidenote: I've put them slightly out of phase compared to each other since else they wouldn't be possible to distinguish at all in the real representation to the right. Also, please note I'm here, quiet unconventional, using the x axis in the phasor for the imaginary <strong>Q</strong>)</span>
</p>
<p>The same signal (well, more or less) in a 3D representation.
</p>
<p>The <strong>I</strong> components (side view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-i.png" alt="" title=""></p>
<p>The <strong>Q</strong> components (top view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-q.png" alt="" title=""></p>
<p>The I/Q signals in 3D:
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-3d.png" alt="" title=""></p>
<p><a name="twopriceone" id="twopriceone"></a>
As the Nyquistâ€“Shannon sampling theorem states you can only represent
frequencies up to <code>f/2</code> using a samplings rate of <code>f</code>. This is still true
using IQ Data, but since you now can represent negative frequencies
the signal spans <code>[-f/2..+f/2]</code> compared to <code>[0..+f/2]</code> using a â„�eal signal,
hence the range is in effect doubled. Using a
sampling rate of <code>f</code> and you now can represent a signal range of <code>f</code> as well.
Two to the price of one!
</p>
<h2>Mixing and multiplying signals</h2>
<p>Using real signals or IQ Signals gives different results when you multiply them. This is because using only the real component it's not possible to uniquely determine the phase angle of the signal, hence impossible to distinguish a positive frequency from a negative.
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-real.png" alt="Mixing 10 kHz with 3 kHz using real" title="Mixing 10 kHz with 3 kHz using real"></span></p>
<p>Multiplying two signals f1 and f2 in the real domain:
</p>
<p><span> Â±f1 âŠ— Â±f2 = (Â±)f1 Â± f2 </span>
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-iq.png" alt="Mixing 10 kHz with 3 kHz using I/Q" title="Mixing 10 kHz with 3 kHz using I/Q"></span></p>
<p>Using IQ Data the signs are now given, and the result is unambiguous:
</p>
<p><span> f1 âŠ— f2 = f1 + f2 </span>
</p>
<p><br>
A frequency spectrum in the real domain usually never show the negative side, since it always must be symmetric around zero due to the uncertainty of the sign of the frequency of the real signal -- hence the parentheses around the sign of <code>f1</code> in the first formula mixing the real signals. I've included the negative side here for illustrative purposes, despite of its redundancy.
</p>
<p>Multiplying two complex number is easiest understood in the polar representation. The amplitude is multiplied and the angle added.
</p>
<p><span> A<sub>1</sub>â‹…e<sup>iÏ•<sub>1</sub></sup>â‹…A<sub>2</sub> e<sup>iÏ•<sub>2</sub></sup> = A<sub>1</sub>A<sub>2</sub> e<sup>i(Ï•<sub>1</sub>+Ï•<sub>2</sub>)</sup> </span>
</p>
<p>Realizing the angle is added under multiplication makes it obvious that the frequencies are added as well.
</p>
<h3>And in time domain ...</h3>
<p>Now let us have a look at this in time domain. To make it easier (doable!) to calculate the DFT in our …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://whiteboard.ping.se/SDR/IQ">http://whiteboard.ping.se/SDR/IQ</a></em></p>]]>
            </description>
            <link>http://whiteboard.ping.se/SDR/IQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134698</guid>
            <pubDate>Wed, 18 Nov 2020 09:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games released before PS4 are no longer appearing in search on PlayStation.com]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25134263">thread link</a>) | @petepete
<br/>
November 18, 2020 | https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/ | <a href="https://web.archive.org/web/*/https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- .entry-header -->


            <div>
                
<p>The heartbreak continues for those of us that relied on Sony’s websites to find and buy games or to research what was available. After <a href="https://delistedgames.com/sony-makes-it-official-playstation-3-psp-vita-removed-from-psn-website-between-october-21-and-26/">cutting out</a> older PlayStation content from the PlayStation Store over the past month, Sony’s eye has seemingly fallen on PlayStation.com and I find myself feeling gutted this morning. For those who didn’t use it regularly, PlayStation.com housed a gargantuan history of pages for North American PlayStation releases going all the way back to the original console from 1995. Up until this week you could easily find titles using the search box on the site but now anything before the PlayStation 4 returns a disappointing “<em>0 results found</em>“.</p>



<p>The older pages weren’t overflowing with info but they did offer some product details that I couldn’t easily find elsewhere. For newer games these pages also frequently retained links to the PlayStation Store which helped in my research. Even when they <em>were</em> on sale some games were just hard to find on the PlayStation Store while their PlayStation.com pages linked directly to them. Sometimes these pages were among the scant bits of evidence that I could find to confirm these games even existed digitally. Now, like with the changes to the PlayStation Store, all that’s gone too. Well, mostly gone.</p>



<p>Thankfully, like our “<a href="https://delistedgames.com/get-the-old-playstation-store-back-for-now/">old PS Store</a>” workaround, there’s still a way to search PlayStation.com but it might also eventually go away. Google’s “search within a site” function has been around for nearly a decade at this point but I’m sure lots of people don’t even know it exists. For our purposes just head to <em>the Google</em>, type ‘site:playstation.com’ and then whatever game you’re looking for. You can use Google’s other search operators to refine the results as well. Put it all together and it looks something like this: <strong>site:playstation.com “age of booty”</strong></p>



<p>You’ll get search results across the playstation.com domain including PlayStation Blog posts and PlayStation Store pages but look for the ones that specifically state ‘www.playstation.com’. In the case of Age of Booty the page gives us a description and even some screenshots as well as a ‘Buy Download’ link. Of course, the download page has been hidden by Sony’s recent changes to their sites but the URL remains accessible so you can check other territories or check it out using the “<a href="https://delistedgames.com/get-the-old-playstation-store-back-for-now/">old</a>” method. Yes, <a href="https://delistedgames.com/age-of-booty/">Age of Booty</a> is still delisted on PlayStation 3.</p>



<p>Maybe it was just a feature that only <strong><em>I</em></strong> benefited from but it’s really sad to see Sony ostensibly kill 25 years of PlayStation content on the web. It makes the nostalgia trip of Astro’s Playroom feel a little more hollow.</p>

                            </div>
            <!-- .entry-content -->



                    </div></div>]]>
            </description>
            <link>https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134263</guid>
            <pubDate>Wed, 18 Nov 2020 08:10:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA["Equal pay for equal work" in remote jobs]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 587 (<a href="https://news.ycombinator.com/item?id=25134220">thread link</a>) | @nityeshaga
<br/>
November 18, 2020 | https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/ | <a href="https://web.archive.org/web/*/https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
        <main id="main">
            <div>

                

                
<section>

    <header>
        <span>June 24, 2020</span>
        
            <p>Tough questions to ask your remote employer who gives you Cost Of Living based compensation and some thoughts on how remote compensation will work in the future</p>
    </header>

    <!--<div class="image main"><img src="/content/images/2020/06/micheile-henderson-03NMNUqHPdE-unsplash.jpg" alt="You should expect &quot;equal pay for equal work&quot; at your new remote job" /></div>-->

    <div>
        <figure><img src="https://www.nityesh.com/content/images/2020/06/micheile-henderson-03NMNUqHPdE-unsplash--1-.jpg" alt=""></figure><blockquote>Your star designer out in the sticks is just as valuable (maybe more so) to the team as those working from the big-city home office. Make sure she feels that way. <p>By the same token, as a remote worker, you shouldn’t let employers get away with paying you less just because you live in a cheaper city. “Equal pay for equal work” might be a dusty slogan, but it works for a reason. If with regard to compensation you accept being treated as a second-class worker based on location, you’re opening the door to being treated poorly on other matters as well.</p><p>- <a href="https://www.nityesh.com/books-read/#remote-office-not-required-by-david-heinemeier-hanson">Remote</a> by David Heinemeir Hanson and Jason Fried</p></blockquote><p>Almost all the knowledge jobs have become work-from-home in this sudden pandemic. Societies, companies, employees and job-seekers - all have been caught in this sudden shift in the way of working.</p><p>I am writing this for the new job-seekers. It's a tough market out there but you should still expect "equal pay for equal work" at whatever remote company you work for in the future. Most of us will probably not get it anytime soon but I believe that there's value in setting expectations.</p><h2 id="tough-questions-against-cost-of-living-col-based-adjustments">Tough questions against Cost Of Living (COL) based adjustments</h2><p>Big companies like Twitter, Shopify and Facebook have announced that they are adopting remote work for good. It's inevitable that this will pave the path for other companies to follow suit. </p><p>But along with this they might also make location based compensation the norm.</p><figure><blockquote><p lang="en" dir="ltr">Wait what? Facebook is seriously going to dunk someone's salary if they move? That's barbaric. <a href="https://t.co/xoV5XpstH3">https://t.co/xoV5XpstH3</a></p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1263544194359947264?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>Below I present some tough questions that you can ask your employer who has adopted this practice.</p><h3 id="-1-opening-the-doors-to-discrimination-at-work">#1. Opening the doors to discrimination at work</h3><p>If you don't live in the highest wage city of the world, you might have a peer at the company who lives in a more expensive city than you. Are you ready to be treated as a second-class employee just because of the geography that you live in?</p><p><em>How will you know that all the lousy work doesn't get passed on to you because it is justified in terms of 'returns on investment'?</em></p><p>When your manager has the final say, isn't it possible that they distribute work so that a low-risk, low-impact project is assigned to you while your "more expensive" peers get assigned the high-risk, high impact one?</p><p><strong>HR at your COL company</strong><em>: "We have a policy that says we won't discriminate based on the employee's location."</em></p><p>That's all well and good but what about the silent bias.</p><p><em>How can you be sure that your extremely well-meaning manager wasn't thinking about it when they assign you a project that you don't like? Wouldn't they be making a wise decision that is justified in terms of returns of investment? Can you be sure that they won't?</em></p><h3 id="-2-differences-in-government-spending-across-countries">#2. Differences in Government spending across countries</h3><p>Public spending enables governments to produce and purchase goods and services, in order to fulfil their objectives – such as the provision of public goods or the redistribution of resources - like social protection, education and healthcare.</p><p>Recent data on public spending reveals substantial cross-country heterogeneity. Relative to low-income countries, government expenditure in high-income countries tends to be much larger (both in per capita terms, and as share of GDP), and it also tends to be more focused on social protection.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Yes! In Spain families with more than 2 children also get benefits from the government, but they have nothing to do with your employer.</p>— Rosa (@rosapolis) <a href="https://twitter.com/rosapolis/status/1264238728123465728?ref_src=twsrc%5Etfw">May 23, 2020</a></blockquote>

</figure><p>In India, the government spent about 1,700 US dollars per head (adjusted based on Purchasing Power Parity) in the year 2015; while in countries such as Norway, that figure was over 30,000 US dollars (adjusted based on PPP) and in USA it was over 21,000 USD.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Source: <a href="https://ourworldindata.org/government-spending">https://ourworldindata.org/government-spending</a></p><p>This lack of government spending is ultimately passed on to the citizens who need to pay for these benefits with their own money, thus reflecting it in their costs of living.</p><p>An impotent public schooling system means that employees need to send their children to expensive private schools. A broken public hospital infracture means that people need to avail the expensive private hospitals for their healthcare. And a lot of these private enterprises are not above profiteering in times of crises.</p><p><em>How does cost of living based compensation take into account the differences in government spending accross countries? Shouldn't the employees be compensated for this difference?</em></p><h3 id="-3-relocations-get-complicated-at-best-and-outright-unfair-at-worst">#3. Relocations get complicated, at best and outright unfair, at worst</h3><p><em>What happens if I relocate to a lower paid region? Will I be compensated differently?</em></p><p>Companies like GitLab are pretty transparent about this. <a href="https://about.gitlab.com/handbook/total-rewards/compensation/#relocating">"Yes, you take a pay cut."</a></p><p><em>But what happens if I was living in a cheap city and decide to move to a more expensive one?</em></p><p>I asked the CEO of Gitlab. Here's what he replied -</p><figure><blockquote><p lang="en" dir="ltr">I don’t remember ever declining such a request.</p>— Sid Sijbrandij (@sytses) <a href="https://twitter.com/sytses/status/1264219857609912320?ref_src=twsrc%5Etfw">May 23, 2020</a></blockquote>

</figure><p>Coming from India, I know for a fact that a lot of people in lower-income countries will jump at this opportunity.</p><p><em>What happens if I choose to be a digital nomad changing cities every couple of months?</em></p><p><em>What if I choose to get an official address in some expensive city while I actually live in the suburbs?</em></p><h3 id="-4-loose-definition-of-cost-of-living">#4: Loose definition of "Cost of Living"</h3><p>The most common arguement against "equal pay for equal work" for remote employees is the difference in housing prices across cities/countries.</p><figure><blockquote><p lang="en" dir="ltr">But those COL adjustments are meant to reflect the local reality no (the house I live in here in SF will a lot cheaper in the middle of nowhere )? Assuming you have the same pool of money to pay people, how do you make sure people have the same experience regardless of place?</p>— Sriram Krishnan (@sriramk) <a href="https://twitter.com/sriramk/status/1263541004289753088?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>So, how do you define the "Cost of Living"?</p><p>Is it just the housing prices? And groceries? Restaurant bills, maybe?</p><p>That seems incomplete. It is only a small percentage of a lot of people's actual costs of living.</p><p>What about living with an elderly parent?</p><p>What about living a single life vs. being married? For that matter, how about having a stay-at-home spouse vs. having a spouse in a high-paying job?</p><p>What about the number of kids one has?</p><p>Number of dogs? Cats?</p><p><em>What's included in "Cost of Living"? </em></p><p><em>More importantly, who defines it? Should it be the employee who is actually incurring these costs? Or should it be the employer who is paying the employee?</em></p><figure><blockquote><div lang="en" dir="ltr"><p>If you’re going to pay people differentially based on where they choose to live, why not pay them differentially based on whether they have kids, too?</p><p>These little monsters are expensive, after all. I’ve got costs!</p></div>— Blair Reeves (@BlairReeves) <a href="https://twitter.com/BlairReeves/status/1263527961371738112?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><h3 id="other-tough-questions">Other tough questions</h3><ul><li><em>Who dictates the proportion in which I should be spending my money?</em></li></ul><p>Electronic devices from big brands are priced the same regardless of whether they are sold in the USA or Brazil. A Macbook would cost you the same every city of the world (except for the import duties that people outside the USA probably need to bear).</p><p>So, what if I choose to spend just 10% of my income on housing expenses and 30% surrounding myself with the latest tech gadgets from the world? And maybe another 40% investing in NASDAQ stocks?</p><p>It sure doesn't make sense to have a 100% of my salary reduced based on just 10% of my expenses.</p><ul><li><em>Where does the leadership in the company live? </em></li></ul><p>Leadership in companies that offer COL based compensation, often live and work in high-wage markets but they might feel differently if they were subject to lower pay for the same work.</p><ul><li><em>How do you account for the costs of reduced opportunities that employees, who don't live in primary talent markets, incur?</em></li></ul><p>People who don't live in the tech hubs of the world might have to bear costs in terms of reduced networking advantages and lesser alternate job opportunities.</p><hr><p>Unless a company is ready to give satisfactory answers to all such questions, it should default to equal pay for equal work.</p><figure><blockquote><div lang="en" dir="ltr"><p>Where you live is a consumption choice. We all make different choices based on what we like, and those are okay!</p><p>Just don’t penalize my compensation for your choices. Give me that bread! I’ve got a mortgage and a dog</p></div>— Blair Reeves (@BlairReeves) <a href="https://twitter.com/BlairReeves/status/1263285240098951168?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p><em>People doing the same jobs and providing the same value should be paid the same.</em></p><p>It is simple. It is fair.</p><p><strong>A COL employer</strong>: <em>"But it's unreal!"</em></p><p>Actually, no. A lot of remote companies are doing this already:</p><figure><blockquote><p lang="en" dir="ltr">Adding <a href="https://twitter.com/podia?ref_src=twsrc%5Etfw">@podia</a>, <a href="https://twitter.com/ConvertKit?ref_src=twsrc%5Etfw">@ConvertKit</a>, <a href="https://twitter.com/MeetEdgar?ref_src=twsrc%5Etfw">@MeetEdgar</a>, <a href="https://twitter.com/WhimsicalPowers?ref_src=twsrc%5Etfw">@WhimsicalPowers</a>, <a href="https://twitter.com/boundless_HQ?ref_src=twsrc%5Etfw">@boundless_HQ</a>, <a href="https://twitter.com/honeycombio?ref_src=twsrc%5Etfw">@honeycombio</a>, <a href="https://twitter.com/upstream_tech?ref_src=twsrc%5Etfw">@upstream_tech</a>, <a href="https://twitter.com/timeular?ref_src=twsrc%5Etfw">@timeular</a> to this list. Pumped to see that <a href="https://twitter.com/automattic?ref_src=twsrc%5Etfw">@automattic</a> and <a href="https://twitter.com/photomatt?ref_src=twsrc%5Etfw">@photomatt</a> are doing equal pay for equal work as well, which I wasn't aware of! 🙌 <a href="https://t.co/YKW3SekIZU">https://t.co/YKW3SekIZU</a></p>— Nick Francis (@nickfrancis) <a href="https://twitter.com/nickfrancis/status/1262837601762869248?ref_src=twsrc%5Etfw">May 19, 2020</a></blockquote>

</figure><h2 id="tough-questions-against-equal-pay-for-equal-work-and-my-answers-to-them">Tough questions against "equal pay for equal work" and my answers to them</h2><p>There are some really tough questions on the other side as well. I have been thinking about them for a while now. I'll take a stab at composing a reply to them.</p><h3 id="isn-t-it-against-market-economics-to-pay-people-living-in-different-cities-of-the-world-the-same-money">"Isn't it against market economics to pay people, living in different cities of the world, the same money?"</h3><p>No, it is not. </p><p>On the contrary, I believe that equal pay for equal work is the default market state. </p><p>I say this because we already see it in a lot of places -</p><ul><li>Freelancers have been living this way for a long time now. Create a name for yourself and work for clients in the US from a beach in Bali.</li><li>When you start a company, your customers pay you money regardless of where you live (unless your product's value is market-specific).</li><li>Writing a book, teaching an online course, paid newsletters and other forms of passive income don't earn the creator a subsidised income based on the city that she lives in. </li></ul><p>This is because we, as consumers, pay for the value that we get …</p></div></section></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/</a></em></p>]]>
            </description>
            <link>https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134220</guid>
            <pubDate>Wed, 18 Nov 2020 08:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust from a Gopher – Lessons 7, 8 and 9]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25133921">thread link</a>) | @BookPage
<br/>
November 17, 2020 | https://levpaul.com/posts/rust-lesson-7-8-9/ | <a href="https://web.archive.org/web/*/https://levpaul.com/posts/rust-lesson-7-8-9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Hello and welcome to the fifth post in my series about learning Rust. In case you want to hit it from the start, <a href="https://levpaul.com/posts/rust-lesson-1/">here’s</a> a link to the first one! This entire series covers my journey from being a completely land-locked Gopher to becoming (hopefully) a hardened Rustacean, able to skitter the hazardous seabed of any application safely.</p><hr><p>I can’t believe we’re at post number five! It’s been a wonderful ride, and I’ve been blown away by the helpful feedback from the Rust community at large. Thank you to everyone for all of the warm help.</p><p>Whilst I’m still in my infancy with Rust, it’s getting harder and harder to hold the itch to learn more. Often I want nothing more than to open the Rust Book and truck on with learning, blog posts be darned! However, I’ve made my commitment to myself, you and the Book, so every night; write, I do.</p><p>I’ve decided to make this post a <em>triple</em>, so let’s begin where we left off!</p><h3 id="7-packages-and-crates-and-stuffhttpsdocrust-langorgbookch07-00-managing-growing-projects-with-packages-crates-and-moduleshtmlmanaging-growing-projects-with-packages-crates-and-modules">7. <a href="https://doc.rust-lang.org/book/ch07-00-managing-growing-projects-with-packages-crates-and-modules.html#managing-growing-projects-with-packages-crates-and-modules">Packages and Crates and Stuff</a></h3><p>Right off the bat, I think this chapter is very well-placed. Even though it took me the entire chapter <em>grok</em> crates, modules and packages; I don’t think it came a line too early or late. Bravo! The chapter introduced many new keywords, such as <code>use</code>, <code>pub</code>, <code>mod</code>, <code>super</code>, but you walk away feeling like you can actually use them properly.</p><h4 id="modules">Modules</h4><p>Modules are introduced leaning heavily on the analogy of a file system… Now given that modules, at the most granular level, can be defined as single files <em>with the module name</em>, I’m actually wondering how much of this <em>is an analogy</em> and how much of it is really what’s happening at the compiler level. I would grin so hard if the bit about <strong><code>use</code></strong> being <em>like</em> a symlink <em>was</em> actually just a thing that was happening somewhere in the build chain. I’m sure it’s not though… Right.</p><h4 id="privacy">Privacy</h4><p>I enjoyed how the authors talked about privacy through scope. It helped me link project structure ideas with programming rules. For some reason I always thought of privacy as logical rules applied to code after the fact, rather than just having or not having something within a certain scope. It’s a lot easier to think about the later way. All this being said, there was also an overarching “Restaurant” example which they tried to tie in with privacy - check this gem:</p><blockquote><p>The way privacy works in Rust is that all items (functions, methods, structs, enums, modules, and constants) are private by default. […] To continue with the restaurant metaphor, think of the privacy rules as being like the back office of a restaurant: what goes on in there is private to restaurant customers, but office managers can see and do everything in the restaurant in which they operate.</p></blockquote><p>… I think that metaphor died somewhere in the rafters above the restaurant, and the smell could be starting to affect the food. Sorry.</p><p>For those who don’t know, privacy in Go is defined by whether you capitalize the first letter of your func/struct/interface name. Whilst lean and consistent - I much prefer the Rust approach. Rust is private by default unless you plop a <code>pub</code> in front of it. The main irk I have with the Go way is that Go’s naming convention also tells you acronyms should be entirely uppercase. So what happens when you want a private struct called <code>jsonData</code>? Well you have to think of something else because calling it <code>JSONData</code> will make it publicly exported and <code>jsonData</code> is not idiomatic. It’s definitely but only a nit, however I’ve become (unreasonably?) irked by it on more than one occasion.</p><h5 id="clean-your-room">Clean your room!</h5><p>The lesson proved once again that the Rust compiler is helpful. Gentle warnings about my variables being unused really makes me feel cared for. Go isn’t like this. Go grabs you by your collar and pierces your eardrums with a shrewd screech. It won’t let you go either. Like a harpy, the tiny chipmunk won’t let up. Thank Crabby for small mercies is all I can say.</p><p>On a more serious note though, I like this choice by Rust - my preference for most things I’d code would be to enforce compiler errors for unused variables; but it should be a compiler option; which as far as I know - it is <strong>not</strong>, in Go. I’m going to guess you should be able to upgrade the Rust warnings to errors through compiler flags somehow.</p><h5 id="re-exporting-imports">Re-exporting Imports</h5><p>This <a href="https://doc.rust-lang.org/book/ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#re-exporting-names-with-pub-use">feature</a> of Rust gives me mixed feelings. As I understand it, when you <code>use</code> a package, that package can then bring more packages into your scope? I mean it does make sense from a library user-experience perspective, but I can’t help but feel like there’s a bit of trust going on here, if not only taste-trust. It’s definitely nice to just <code>use</code> a crate once and have everything you need to interact with it.</p><p>There’s only one Rust project I’m really interested in right now - a Game engine and editor called <a href="https://github.com/mrDIMAS/rg3d">rg3d</a>. I checked that project’s source for re-exports and found some in the top level <a href="https://github.com/mrDIMAS/rg3d/blob/master/src/lib.rs"><code>lib.rs</code></a>. Basically it just imports its own submodules publicly. I have no idea if this is idiomatic but to my lay-eyes this use-case looks correct and just.</p><p>Rust has been giving me a strong Java vibe from its imports. The nested paths feature seems good - ugly but succinct. Maybe my editor or <code>rustfmt</code> will automatically manage this for me? I enjoy not needing to worry about imports 99% of the time in Go, thanks to <code>goimports</code>, so hopefully that trend will continue in Rust.</p><h5 id="prelude-to-nothing">Prelude to Nothing</h5><p>In previous posts I mentioned being wooed by wistful mentions of a <code>prelude</code> by the Book. Well this chapter mentioned it again, and more than wistfully. It drowned my unquenchable satiety with <a href="https://doc.rust-lang.org/std/prelude/index.html">this link</a>, which to my utmost sorrow, was not a chapter in the Book. Alas, I read it in spite the fact. Oh, but my heart was flattened like my toddler’s playdough on a Sunday morning, for I was to find <strong>the prelude</strong> means nothing more than the default set of imports for a program. Through the sobriety of hindsight, I do question what else I was expecting. Given Rust doesn’t have a runtime, it doesn’t need anything fancy. Oh well, at least the great prelude mystery is solved.</p><h3 id="8-common-collectionshttpsdocrust-langorgbookch08-00-common-collectionshtml"><a href="https://doc.rust-lang.org/book/ch08-00-common-collections.html">8. Common Collections</a></h3><p>I just want to take a moment to swoon over Rust’s type inference again.</p><p>*<em><strong>swoons</strong></em>*</p><p>It’s fantastic. This is all…</p><hr><p>Now for actual chapter 8; it’s fairly dense. Covered is a brief introduction of standard library’s collections, Vectors, HashMaps and finally a deep dive into Rust Strings. Let’s begin the blow-by-blow starting with this gem:</p><div><pre><code data-lang="rust"><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>v</span><span> </span><span>=</span><span> </span><span>vec</span><span>!</span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>4</span><span>,</span><span> </span><span>5</span><span>];</span><span>
</span><span>    </span><span>let</span><span> </span><span>first</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>v</span><span>[</span><span>0</span><span>];</span><span>
</span><span>    </span><span>v</span><span>.</span><span>push</span><span>(</span><span>6</span><span>);</span><span>
</span><span>    </span><span>println</span><span>!</span><span>(</span><span>"The first element is: {}"</span><span>,</span><span> </span><span>first</span><span>);</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>Guess what won’t compile? Correct - the code above! What’s happening here is that <code>v</code> is mutable and <code>first</code> is immutable. If <code>v</code> needs to grow from something like a push; then this may end up moving the entire heap-allocated vector into another part of the heap. Had this to happen, then <code>first</code> would be a “dangling” ref to what <em>used</em> to be the first element of <code>v</code>.</p><p>Now what really tickles me is wondering about how that enforcement is encoded - what is <code>first</code> a reference to exactly? The Vec? No, my IDE tells me it’s an <code>&amp;i32</code> ref… But, somehow the compiler knows that <em>THAT</em> i32 ref is a child, or related to the Vec in the same scope. I
’d love to know more about how this works.</p><p>Perhaps not by major coincidence the Book offers up possibly the most perfect lead for such questions only paragraphs later… The Book introduces the <a href="https://doc.rust-lang.org/nomicon/vec.html">Rustinomicon</a>, telling us that we can peer into it to see details about how <code>vec</code> is made… At first, I was a little tense. Why does this reference-style-looking book have the Lovecraftian name? Only when I glimpsed the first line of its opening, did the ink droplets align:</p><h3 id="the-dark-arts-of-unsafe-rust"><code>The Dark Arts of Unsafe Rust</code></h3><p>…<em>followed by</em></p><p>THE KNOWLEDGE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF UNLEASHING INDESCRIBABLE HORRORS THAT SHATTER YOUR PSYCHE AND SET YOUR MIND ADRIFT IN THE UNKNOWABLY INFINITE COSMOS.</p><h4 id="okay-this-looks-awesome"><strong>OKAY THIS LOOKS AWESOME</strong>.</h4><p>Flipping back to the <code>vec</code> chapter of the Rustinomicon, I realised it’s not at all a boring appendix style libdoc for vectors - the god damn tomb is teaching you to write your <em>OWN</em> std::Vec from scratch!</p><p>Good God, this is made me bite my lip in awkward nuclear attraction. I had some plans in mind for what I wanted to write about after this series. Right now the thought of doing a mini-series through the nomcon is sounding mighty fine though.. <em>More to come on this later</em>, as I managed to pry myself away and back to the lesson at hand.</p><hr><p>Looking through the method list (by god the <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html">doc pages</a> are ugly; hint - only use the sidebar to navigate, do not bother free-scrolling), <code>vec</code> REALLY has some cool funcs. <code>dedup</code>, <code>drain</code>, <code>retain</code> all look to do what you’d expect. I jaunted quickly through <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html"><code>std::iter:Iterator</code></a> too and found SO many nice to haves, such as <code>gt</code>, <code>is_sorted</code>, <code>map</code>, <code>fold</code>, <code>filter</code>…</p><p>Seriously, I know there’s a lot you wouldn’t need here - but I really do wish we had simple collections/traits outside of slices and maps in Go. And yes, before I get screamed at - <em>I know</em> you can write your own in <a href="https://gobyexample.com/collection-functions">a few lines</a>, but it’s not the same - especially when you start involving complex data types. Being able to just conform to standard interfaces for elegance is something I adore and miss.</p><h4 id="string-theory">String Theory</h4><p>The chapter devotes a large swath to Strings and UTF-8. At first, I thought “how boring”, but then I realised I am the boring one! This is a much more interesting problem than I gave credit for and it made me go back to Go to better understand the “rune” system it uses for strings.</p><p>First, strings; there’s actually shit-loads of them in Rust… <code>OsString</code>, <code>CString</code>, <code>CStr</code>, <code>OsStr</code>… How wrong I was to assume a single String type in Rust indeed.</p><p>The stdlib provides many helpful functions over regular <code>String</code>. In Go, string is a part of <code>builtin</code>, but you use the stdlib’s <code>strings</code> package for more helpers.</p><hr><p><strong>Random question</strong>: Is there a difference between <code>String::from("")</code> and <code>String::new()</code>? According to this test; no:</p><div><pre><code data-lang="rust"><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>true</span><span>,</span><span> </span><span>String</span>::<span>from</span><span>(</span><span>""</span><span>)</span><span> </span><span>==</span><span> </span><span>String</span>::<span>new</span><span>());</span><span>
</span></code></pre></div><p>I’ve seen both methods being used so far and am not sure which one is “better”/idiomatic.</p><h4 id="indexing-into-strings">Indexing into Strings</h4><blockquote><p>A final reason …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://levpaul.com/posts/rust-lesson-7-8-9/">https://levpaul.com/posts/rust-lesson-7-8-9/</a></em></p>]]>
            </description>
            <link>https://levpaul.com/posts/rust-lesson-7-8-9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133921</guid>
            <pubDate>Wed, 18 Nov 2020 06:58:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snow on The Atlantic: How Cocaine Came to Europe]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25133549">thread link</a>) | @AndrewBissell
<br/>
November 17, 2020 | https://www.ebb-magazine.com/essays/snow-on-the-atlantic | <a href="https://web.archive.org/web/*/https://www.ebb-magazine.com/essays/snow-on-the-atlantic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-00c327a0e80805b65a15"><div><p>At the beginning of Alfred W. McCoy’s seminal work on the global heroin trade and the CIA, <em>The Politics of Heroin</em>, he gives us a simple formulation that’s useful for any study of illicit drugs and their trade: ‘Narcotics are not simply illegal and immoral,’ he writes. ‘They are the source of extraordinary profits and power.’ Part of the power of McCoy’s book is that he writes about his subject so thoughtfully, and eschews the sensationalism that characterizes too much writing about drugs and their traffic. ‘Simply put, narcotics are major global commodities that resist any attempt at localized suppression… As long as demand for drugs in the cities of the First World continues to grow, Third World producers will find a way to supply their markets.’</p><p>Nacho Carretero’s <em>Snow on The Atlantic, How Cocaine Came to Europe</em>, published in a translation by Thomas Bunstead in 2018 by Zed Books, is a contribution to telling the story of one of these global commodities: cocaine. It tells a tale of Galicia and its Costa Del Morte, that region in Spain sitting on top of Portugal with 930 deadly miles of coastline and an adventurous history of shipwrecks and pirates and smuggling. This book focuses on the colorful tale of how Galicia became the port for cocaine smuggling in Europe, largely through an alliance between the Medellín Cartel in Colombia and a homegrown smuggling culture and network of clans. It’s packed with characters and schemes and police operations, but one flaw is that it falls into their sensationalism too often (a <a href="https://www.antena3.com/series/farina/">popular television series</a> in Spain was based on the book), and its major failing is in not making much of an attempt to analyze the phenomenon more deeply. The details in the book, however, make great raw material for a more developed analysis down the line.</p><p>Here is a sketch of the story that Carretero tells: it begins in earnest after the Spanish Civil War, in that inter-border region between Spain and Portugal called the <em>Couto Mixto</em>. Carretero goes as far as to say the area is characterized by a ‘statelessness.’ Not so long ago, as recently as the nineteenth century, if you asked villagers in the area what country they were citizens of they couldn’t tell you. The Spanish Civil War defined these borders. And those borders made nations become as classes; the living standard in Portugal was high, while in Spanish Galicia much of the rural inhabitants lived in relative and real poverty. It was the difference, Carretero writes, ‘between one group of people who were starving, and another enjoying the spoils of African colonies.’ This was something I wish Carretero had expanded on: what was the licit economy in Galicia and why did its people live worse? On that he gives no real answer, though he does describe how some local fortunes were made from tungsten sold to the Third Reich during the Second World War.</p><p>Whatever the reasons for this poverty, the relative affluence of Portugal right across the border made Galicia a prime location for smuggling of all sorts of things. It was cigarettes which became the big money maker. Smugglers cut deals with the big guys like Reynolds &amp; Philip Morris in America to move excess production and faulty batches, dodging gargantuan amounts of taxes, and altering the flow of goods from up from Portugal to across the Atlantic. That route would define the traffic later when cocaine started coming from Colombia.&nbsp;</p><p>The law helped too. Until 1982 all you could get for smuggling was a caution. Before 1978 smuggling was only an economic offence. With the Customs Surveillance Service (SVA) enforcing the weak laws, smugglers rarely went to jail – at most they’d get a fine, and that would often be lost in the Minoan bureaucratic system of the new democratic state post-Franco.</p><p>Carretero describes a society where the lumpen ruled each class strata, not just a lumpen-proletariat but a lumpen-petty bourgeois and a lumpen bourgeoisie. ‘There was nothing abnormal about the sight of smugglers and <em>guardias</em> sharing a tumbler of wine over a game of dominos in the local tavern.’ He explains further that smugglers and police would often have agreements that let the smuggling pass unmolested, provided the police got their cut: ‘From the beginning, the relationship with the <em>Guardia Civil </em>was good. Those in the pay of the government were as hard up as everyone else, and it was almost always them who proposed the pacts.’</p><p>Police in on the take isn’t unprecedented or uncommon. More interesting are the connections Carretero details between the smugglers and the political class. When I mention smugglers, I’m referring not just to the later drug traffickers but also the ‘smoke lords’ who developed their expertise and reputation moving cigarettes. They provided the perfect resource for the cartels to exploit later when they saw the talent and culture that existed in Galicia. These mafia-like clans were generous contributors to all political parties in the region, particularly the institutional right-wing parties like the <em>People’s Alliance</em> (AP), which later became the <em>Partido Popular</em> (PP). That party had numerous links to the smugglers, from campaign contributions to friendships, to particularly salient connections through the Galician Chamber of Commerce, of which many smugglers and their associates were members at one time or another. That extended to the auxiliaries of the narcotics trade – lawyers like Pablo Vioque who defended the smugglers in their inevitable run-ins with the law.</p><div><p>How the shift to drug smuggling was made is murky. Someone bought hashish once from Africa and knew one of the <em>Capos</em>. Hashish smuggling quickly became cocaine.</p><p> However it happened, smugglers made the transition quickly. When the Medellín cartel spent some time in Galicia in exile they realized that there was an ideal infrastructure for them to use. They built this trade from the ready-made scaffolding of the tobacco trade. Clan bosses like Sito Miñanco took the speedboats they had running crates of smoke up and down the Arousa river and loaded them with blow.&nbsp;</p></div><p>The Medellín cartel had come to Galica because they were feeling some heat from the DEA in bringing drugs into the U.S. (never if it went at cross measures with the goals of the CIA, of course, as McCoy shows in his book), and they needed new markets. McCoy’s law of narcotics as commodities seeking to be sold held true. Europe in the 80s was the perfect logical next step. Not only did they have the skilled talent they needed, but the Galicians spoke their language. And the government tied its own hands to stop it thanks to their numerous corrupt connections.</p><p>This is the more interesting story that I wish the book had told, as well as delving deeper into the politics of the trade. Why did Galician politicians allow the smuggling culture to take hold? Carretero mentions that a factor in the government finally taking action was the support for interdiction of the trade by Socialist Party (PSOE) politicians, like Felipe González, who was Prime Minister of the country from 1982-1996. It was within this time period that the first blow against the smugglers came, with the ‘macro-indictment’ of 1984. This was the first coordinated strike against the whole of the smugglers and their network, rather than limited and ineffective isolated enforcement. Carretero credits the limited success of this action (nobody went down hard, though it did create a new state of affairs where the smugglers had to tread more cautiously and not so out in the open as they had before) to it having the support of a Virginio Fuentes. Fuentes was the socialist governor of Pontevedra, ‘one of the few in Galician politics to raise his voice against the smugglers.’ Carretero attributes this to Fuentes following the cue of González; he ‘sensed a potential vote-winner in taking a stand against smuggling.’</p><p>But Carretero also mentions a murkier story that would have merited closer scrutiny (or more realistically its own book). He relates an anecdote from Fernando Rodríguez Mondragón’s book <em>El hijo del ‘Ajedrecista’ </em>(The ‘Chess Player's’ Son). That chess player was Gilberto Rodríguez Orejuela, who was the boss of the Cali cartel – the cartel that shipped the cocaine over the Atlantic to Galicia. Orejuela was in Spain following a crackdown in Colombia by the President Belisario Betancur on the narcos, but he had been scooped up in November of ‘84 in Spain along with an account book of his detailing millions of dollars in transactions for the cartel. The DEA wanted Orejuela extradited to America, but after two years of jockeying and negotiation, Orejuela and the Colombians were sent back to Colombia. They spent just months in prison before getting out, while in America they could have expected 10-15-year prison sentences.</p><p>Mondragón says in his book that the reason for these reduced sentences came to Spain on Pablo Escobar’s private jet. And there were twenty million of these reasons. $5 million went to Felipe González, ‘his negotiators said there was an election coming up and they needed the money.’ $10 million went to the <em>Audiencia Nacional</em>, ‘the High Court in Spain with jurisdiction over international crimes.’ Carretero doesn’t dig any deeper into these explosive allegations, wrapping up tersely that ‘these claims remain unsubstantiated.’ But having questions like these answered would go a long way in understanding how exactly the drug trade was tolerated by the Spanish government.&nbsp;</p><p>McCoy notes that ‘the CIA’s Cold War alliances with drug lords ... created enforcement-free zones closed to outside investigation.’ How this worked was simple, ‘the DEA deferred to the CIA during the Cold War whenever covert operations became intertwined in the drug trade…’ Its links to the Medellín cartel, which Pablo Escobar founded, are documented as well. ‘All major U.S. agencies,’ writes McCoy, ‘have gone on the record stating, with varying degrees of frankness, that the Medellín cartel used contra forces to smuggle cocaine into the …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ebb-magazine.com/essays/snow-on-the-atlantic">https://www.ebb-magazine.com/essays/snow-on-the-atlantic</a></em></p>]]>
            </description>
            <link>https://www.ebb-magazine.com/essays/snow-on-the-atlantic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133549</guid>
            <pubDate>Wed, 18 Nov 2020 05:32:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India’s WhiteHat Jr is startup hell]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25133421">thread link</a>) | @_pythonlover_
<br/>
November 17, 2020 | https://themorningcontext.com/indias-whitehatjr-is-startup-hell/ | <a href="https://web.archive.org/web/*/https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<div id="primary">
		<main id="main">

		
<article id="post-83914">
	<!-- .entry-header -->

			
			<p><img width="640" height="480" src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg" alt="WhiteHat Jr" srcset="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg 1440w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1024x768.jpg 1024w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-400x300.jpg 400w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-768x576.jpg 768w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1536x1152.jpg 1536w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-2048x1536.jpg 2048w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-600x450.jpg 600w" sizes="(max-width: 640px) 100vw, 640px">			</p><!-- .post-thumbnail -->

							<!-- <div class="blog-feaured-img" style="background-image: url('');"></div> -->
		
		<div>
								<div>
						
<p>Shaarif Ansari got the call on 11 November at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p>


<p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p>

						<div>
							<div>
								<p>
									You can read this story by signing up for a <span><a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">free account</a></span>.  or <a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">log in</a> if you are already a member.
								</p>
							</div>
						</div>
					</div>
				
		
					</div><!-- .entry-content -->

					
				
				<div>
				<p><img src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/themes/tmc/images/auth-abt-close.svg" alt=""></p><div>
				<p>
				<h3>sign up to read the whole article</h3>
				<h5>PLUS OTHER FREE STORIES ON THE MORNING CONTEXT</h5>
		<!-- / 		<div class="tmc-form-container">
		// 			<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/auth-abt-close.svg" alt="" class="close-sign-up">
		// 			<div class="width-setter">
		// 				<div class="left-side-content">
		// 					<h3 class="form-title main-title"></h3>
		// 					<h5 class="form-subtitle"></h3>
		// 					
		// 							// 				</div>
		// 				<div class="right-side-img">
		// 					<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/half-ellipse.svg" alt="">
		// 				</div>
		// 			</div>
		// 		</div>
	-->
	</p></div></div></article><!-- #post-83914 -->

		</main><!-- #main -->
	</div><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://themorningcontext.com/indias-whitehatjr-is-startup-hell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133421</guid>
            <pubDate>Wed, 18 Nov 2020 05:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 millisecond bug]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25133127">thread link</a>) | @sshroot
<br/>
November 17, 2020 | https://vorner.github.io/2020/11/06/40-ms-bug.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/11/06/40-ms-bug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>This is a small story about tracking down a production bug in a Rust
application. I don’t know if there’s any take away from this one for the reader,
but it felt interesting so I’m sharing it.</p>

<h2 id="a-bit-of-backstory">A bit of backstory</h2>

<p>In Avast, we have a Rust application called <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It serves as a backend to
some other applications, provides them a HTTP API. It’s in Rust because it is
latency critical. Latencies of most requests are under a millisecond.</p>

<p>It was written with <a href="https://docs.rs/tokio/0.1.*"><code>tokio-0.1</code></a> and <a href="https://docs.rs/hyper/0.12.*"><code>hyper-0.12</code></a> to deal with the HTTP. We
were quite late to update to newer versions, in part because it worked fine and
the amount of <code>async</code> code was single quite short function, so we didn’t have
much motivation. And in part because we use the <a href="https://crates.io/crates/spirit"><code>spirit</code></a> libraries for
configuration. It’s a library to take configuration and set up the internal
state of the program for it ‒ configuration contains the ports to listen to,
etc, and it manages spawning the HTTP server objects inside the program and can
even migrate from one set of ports to other at runtime.</p>

<p>But migrating <a href="https://crates.io/crates/spirit"><code>spirit</code></a> to newer <code>tokio</code> and <code>hyper</code> was a big task (because
the API surface is quite large, the library does a bit unusual things compared
to all the usual applications and the change between old and new <code>tokio</code> was
quite large).</p>

<p>Anyway, eventually I got permission to work on the migration of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> as
part of my job. It took about a week to migrate both <a href="https://crates.io/crates/spirit"><code>spirit</code></a> and <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It
went through review, went through the automatic tests and we put it to the
staging environment for a while, watching the logs and graphs. Everything seemed
fine, so after few days of everything looking fine, we pushed the button and put
it to production.</p>

<h2 id="the-increased-latencies">The increased latencies</h2>

<p>As it goes in these kinds of stories, by now you’re expecting to see what went
wrong.</p>

<p>The thing is, our own metrics and graphs were fine. But the latency on the
downstream service querying us increased by 40ms. The deployment got reverted,
and we started to dig into where these latencies come from.</p>

<h2 id="it-was-acting-really-weird">It was acting really weird</h2>

<p>There were several very suspicious things about that.</p>

<ul>
  <li>Our own „internal“ latencies stayed the same. Our CPU usage also stayed the
same.</li>
  <li>The latency graph on the downstream side was flat 40ms <em>constant</em>.</li>
</ul>

<p>Now, if we introduced some performance regression in the query handling, we
would expect our CPU consumption to rise. We would also expect the latency graph
to be a bit spiky, not completely flat 40ms constant. It almost looked like
there was a 40ms <code>sleep</code> somewhere. But why would anyone put a 40ms sleep
anywhere?</p>

<p>I’ve looked through documentation and didn’t see anything obvious. I’ve tried
searching both our code and code of the dependencies for <code>40</code>, asked on Slack if
that <code>40ms</code> value was familiar to anyone. Nothing.</p>

<p>The working theory we started with was that there could be some kind of back-off
sleep on some kind of failure. Maybe <code>hyper</code> would be closing inactive
connections in the new version, forcing the application to reconnect (the graph
was for 99th percentile, so if we happened to close each 100th connection and
reconnection took this long…) and maybe try IPv6 first and we would be listening
on IPv4 only or… (in other words, we didn’t have a clear clue).</p>

<h2 id="the-benchmarks">The benchmarks</h2>

<p>My colleague started to investigate in a more thorough way than just throwing
ideas around on Slack. He run a <code>wrk</code> benchmark against the service. On his
machine, the latencies were fine. So he commandeered one of the stage nodes to
play with it and run the benchmark there. And every request had 40ms latency on
that machine. The previous version of <code>urlite</code> was fine, with under one
millisecond.</p>

<p><em>Something</em> was probably sleeping somewhere on the production servers, but not
on the development machine. There probably was some difference in the OS
settings, but definitely difference in the kernel version. The servers are
running some well-tried Linux distribution, so they have a lot older version,
while a developer is likely to run something much more on the edge.</p>

<h2 id="configuration-options">Configuration options</h2>

<p>The selling point of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> is that most of the thing one can set in the
builders of various libraries and types now can be just put into a config file
without any recompilation. If we did configuration by hand, we would expose only
the things we thought would be useful, but with spirit, there’s everything. So,
naturally, tweaking some of the config knobs was the next step (because it was
easy to do).</p>

<p>It was discovered that turning the <code>http1-writev</code> option <em>off</em>, which
corresponds to
<a href="https://docs.rs/hyper/0.13.8/hyper/server/struct.Builder.html#method.http1_writev">this method</a>
in <code>hyper</code>, made the latencies go away.</p>

<p>We now had a solution, but I wasn’t happy about not understanding <em>why</em> that
helped, so I went to dig the rabbit hole and find the root cause. Turns out
there were several little things in just the constellation to make the problem
manifest.</p>

<h2 id="overriding-the-defaults-of-http1_writev">Overriding the defaults of <code>http1_writev</code></h2>

<p>The method controls the strategy in which way data are pushed into the socket.
With vectored writes enabled, it sends two separate buffers (one with headers,
the other with the body if it’s small enough) through a single <a href="https://linux.die.net/man/2/writev"><code>writev</code></a>
syscall.  If they are disabled, <code>hyper</code> copies all the bytes into a single
buffer and sends that as a whole.</p>

<p>It turns out that the method takes a <code>bool</code>, but there are actually 3 states.
The third (auto) is signalled by <em>not</em> calling the method and <code>spirit-hyper</code> was
calling it always, with the default to turn the <a href="https://linux.die.net/man/2/writev"><code>writev</code></a> on. I don’t know if
leaving it on auto would make the bug go away, but I’ve fixed the problem in the
library anyway.</p>

<h2 id="splitting-vectored-writes">Splitting vectored writes</h2>

<p>Spirit wants to support a bit of configuration on top of what the underlying
libraries provide on their own. One of such things is limiting the number of
concurrently accepted connections on a single listening socket. Users don’t have
to take advantage of that (the types for the configuration can be composed
together to either contain that bit or not and the administrator may leave the
values for the limits unset in the configuration and then they won’t be
enforced).</p>

<p>Anyway, in case the support for the limits is opted in through using the type
with the configuration fields, the connections themselves are wrapped in a
<a href="https://docs.rs/spirit-tokio/0.7.*/spirit_tokio/net/limits/struct.Tracked.html"><code>Tracked</code></a>
type. The type tries to be mostly transparent for use and can be used inside
<code>hyper</code> (which is what the default configuration type alias in <code>spirit-hyper</code>
does), but tracks how many connections there are, to not accept more if it runs
out of the limit.</p>

<p>When implementing the bunch of traits for the wrapper, I’ve overlooked the
<a href="https://docs.rs/tokio/0.2.*/tokio/io/trait.AsyncWrite.html#method.poll_write_buf"><code>AsyncWrite::poll_write_buff</code></a>.
It is a provided method, which means it has a default implementation. It is the
one that abstracts the OS-level <code>writev</code>, it can write multiple buffers (the
<a href="https://docs.rs/bytes/0.5.*/bytes/buf/trait.Buf.html"><code>Buf</code></a> represents a
segmented buffer).</p>

<p>The default implementation simply delegates to multiple calls to the ordinary
write. Therefore, this omission combined with the default of enabling vectored
writes results in calling into the kernel twice, each time with a small buffer,
instead of once with two small buffers or once with a big buffer.</p>

<p>That was definitely something to get fixed, because if nothing else, syscalls
are expensive and calling more of them is not great. But I’ve finally felt like
I’m on the right path, because:</p>

<h2 id="nagles-algorithm">Nagle’s algorithm</h2>

<p>You probably know that TCP stream is built from packets going there and back.
Optimizing how to split the stream into the packets and when to send them is a
hard problem and the research in that area is still ongoing, because there are
many conflicting requirements. One wants to deliver the data with low latency,
utilize the whole bandwidth, but not overflow the capacity of the link (in which
case the latencies would go up or packets would get lost and would have to be
retransmitted), leave some bandwidth to other connections, etc.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a> is
one of the older tricks up in TCP’s sleeve. The network doesn’t like small
packets.  It is better to send as large packets as the link allows, because each
packet has certain overhead ‒ the headers that take some space, but also routers
spend computation power mostly based on number of packets and less on their
size. If you start sending a lot of tiny packets, the performance will suffer.
While the links are limited by the number of bytes that can pass through them,
routers are more limited by the number of packets. If a router declares to be
able to handle a gigabit connection, it actually means a gigabit <em>if you use
full-sized packets</em>, but will get to few megabits if you split the data into
tiny packets.</p>

<p>So it would be better to wait until the send buffer contains a packetfull of
data before sending anything. But we can’t do that, because we don’t <em>know</em>
there’ll ever be a full packet of data, or generating more data might wait for
the other side to answer. We would never send anything and wait forever and the
Internet would not work.</p>

<p>Instead, the algorithm is willing to send <em>one</em> undersized packet and then it
waits for an <code>ACK</code> from the other side until sending another undersized one. If
it gets a packetfull of data to send in the meantime, that’s great and it sends
it (it won’t get better by waiting longer), but it won’t ever have two
undersized ones somewhere in flight, therefore won’t kill the network’s
performance by them.</p>

<p>This works, it’ll make progress eventually because once the <code>ACK</code> comes and
all the data that accumulated until then is sent.</p>

<p>But it also slows things down. Like in our case. What happens if we do it using
single syscall, the whole HTTP response forms a single undersized packet (we
have really small answers) and gets sent, no matter if it’s submitted to the
kernel by one big or two small buffers.</p>

<p>On the other hand, if we split the submission into two syscalls, this is what
happens:</p>

<ul>
  <li>We write the first part (headers). The kernel sends them out as an undersized
packet.</li>
  <li>We write the second part (the body). But the kernel shelves them into the send
buffer and waits for sending them until it sees the <code>ACK</code>, because there’s one
undersized packet …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/11/06/40-ms-bug.html">https://vorner.github.io/2020/11/06/40-ms-bug.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/11/06/40-ms-bug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133127</guid>
            <pubDate>Wed, 18 Nov 2020 04:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Math of Password Hashing Algorithms and Entropy (2019)]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25133061">thread link</a>) | @mooreds
<br/>
November 17, 2020 | https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Here’s the reality, billions of credentials have been leaked or stolen and are now easily downloaded online by anyone. Many of these databases of identities include passwords in plain text, while others are one-way hashed. One-way hashing is better (we’ll get to why in a second), but it is only as secure as is mathematically feasible. Let’s take a look at one-way hashing algorithms and how computers handle them.</p>

<h2 id="hashing">Hashing</h2>

<p>A hash by definition is a function that can map data of an arbitrary size to data of a fixed size. SHA2 is a hashing algorithm that uses various bit-wise operations on any number of bytes to produce a fixed sized hash. For example, the SHA-256 algorithm produces a 256 bit result. The algorithm was designed specifically so that going from a hash back to the original bytes is infeasible. Developers use an SHA2 hash so that instead of storing a plain text password, they instead only store the hash. When a user is authenticated, the plain text password they type into the login form is hashed, and because the algorithm will always produce the same hash result given the same input, comparing this hash to the hash in the database tells us the password is correct.</p>

<h2 id="cracking-passwords">Cracking Passwords</h2>

<p>While one-way hashing means we aren’t storing plain text passwords, it is still possible to determine the original plain text password from a hash. Next, we’ll outline the two most common approaches of reversing a hash.</p>

<h3 id="lookup-tables">Lookup Tables</h3>

<p>The first is called a lookup table, or sometimes referred to as a rainbow table. This method builds a massive lookup table that maps hashes to plain text passwords. The table is built by simply hashing every possible password combination and storing it in some type of database or data-structure that allows for quick lookups.</p>

<p>Here’s an example of a lookup table for SHA2 hashed passwords:</p>

<div><div><pre><code><span>sha2_hash                                                          password</span>
<span>-----------------------------------------------------------------------------------------</span>
<span>e150a1ec81e8e93e1eae2c3a77e66ec6dbd6a3b460f89c1d08aecf422ee401a0   </span><span>123456</span>
<span>e5d316bfd85b606e728017e9b6532e400f5f03e49a61bc9ef59ec2233e41015a   broncosfan123</span>
<span>561acac680e997e22634a224df2c0931cf80b9f7c60102a4e12e059f87558232   Letmein</span>
<span>bdc511ea9b88c90b75c3ebeeb990e4e7c813ee0d5716ab0431aa94e9d2b018d6   newenglandclamchowder</span>
<span>9515e65f46cb737cd8c191db2fd80bbd05686e5992b241e8ad7727510b7142e6   opensesame</span>
<span>6b3a55e0261b0304143f805a24924d0c1c44524821305f31d9277843b8a10f4e   password</span>
<span>c194ead20ad91d30c927a34e8c800cb9a13a7e445a3ffc77fed14176edc3c08f   xboxjunkie42</span>
</code></pre></div></div>

<p>Using a lookup table, all the attacker needs to know is the SHA2 hash of the password and they can see if it exists in the table. For example, let’s assume for a moment that Netflix stores your password using an SHA2 hash. If Netflix is breached, their user database is likely now available to anyone with a good internet connection and a torrent client. Even a mediocre hacker now only needs to lookup the SHA2 hash associated with your Netflix account to see if it exists in their lookup table. This will reveal nearly instantly what your plain text password is for Netflix. Now, this hacker can log in to your Netflix account and binge watch all four seasons of Fuller House (“how rude!”). And he can also try this password on Hulu and HBO Go to see if you used the same email address and password for those accounts as well.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/salt.png" alt="Salt"></p>

<p>The best way to protect against this type of attack is to use what is called a <strong>salt</strong>. A salt is simply a bunch of random characters that you prepend to the password before it is hashed. Each password should have a different salt, which means that a lookup table is unlikely to have an entry for the combination of the salt and the password. This makes salts an ideal defense against lookup tables.</p>

<p>Here’s an example of a salt and the resulting combination of the password and the salt which is then hashed:</p>

<div><div><pre><code><span>// Bad, no salt. Very bland.</span>
<span>sha2</span><span>(</span><span>"password"</span><span>)</span> <span>// 6b3a55e0261b0304143f805a24924d0c1c44524821305f31d9277843b8a10f4e</span>

<span>// Better, add a salt.</span>
<span>salt</span> <span>=</span> <span>";L'-2!;+=#/5B)40/o-okOw8//3a"</span>
<span>toHash</span> <span>=</span> <span>";L'-2!;+=#/5B)40/o-okOw8//3apassword"</span>
<span>sha2</span><span>(</span><span>toHash</span><span>)</span> <span>// f534e6bf84a638112e07e69861927ab624c0217c0655e4d3be07659bcf6c1c07</span>
</code></pre></div></div>

<p>Now that we have added the salt, the “password” that we actually generated the hash from was the String <code>;L'-2!;+=#/5B)40/o-okOw8//3apassword</code>. This String is long, complex and contains a lot of random characters. Therefore, it is nearly impossible that the hacker that created the lookup table would have generated the hash for the String <code>;L'-2!;+=#/5B)40/o-okOw8//3apassword</code>.</p>

<h3 id="brute-force">Brute Force</h3>

<p><img src="https://fusionauth.io/assets/img/blogs/hulk.png" alt="Brute Force"></p>

<p>The second method that attackers use to crack passwords is called brute force cracking. This means that the attacker writes a computer program that can generate all possible combinations of characters that can be used for a password and then computes the hash for each combination. This program can also take a salt if the password was hashed with a salt. The attacker then runs the program until it generates a hash that is the same as the hash from the database. Here’s a simple Java program for cracking passwords. We left out some detail to keep the code short (such as all the possible password characters), but you get the idea.</p>



<div><div><pre><code><span>import</span> <span>org.apache.commons.codec.digest.DigestUtils</span><span>;</span>

<span>public</span> <span>class</span> <span>PasswordCrack</span> <span>{</span>
  <span>public</span> <span>static</span> <span>final</span> <span>char</span><span>[]</span> <span>PASSWORD_CHARACTERS</span> <span>=</span> <span>new</span> <span>char</span><span>[]</span> <span>{</span><span>'a'</span><span>,</span> <span>'b'</span><span>,</span> <span>'c'</span><span>,</span> <span>'d'</span><span>};</span>

  <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>...</span> <span>args</span><span>)</span> <span>{</span>
    <span>String</span> <span>salt</span> <span>=</span> <span>args</span><span>[</span><span>0</span><span>];</span>
    <span>String</span> <span>hashFromDatabase</span> <span>=</span> <span>args</span><span>[</span><span>1</span><span>].</span><span>toUpperCase</span><span>();</span>

    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>6</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>8</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>char</span><span>[]</span> <span>ca</span> <span>=</span> <span>new</span> <span>char</span><span>[</span><span>i</span><span>];</span>

      <span>fillArrayHashAndCheck</span><span>(</span><span>ca</span><span>,</span> <span>0</span><span>,</span> <span>salt</span><span>,</span> <span>hashFromDatabase</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>private</span> <span>static</span> <span>void</span> <span>fillArrayHashAndCheck</span><span>(</span><span>char</span><span>[]</span> <span>ca</span><span>,</span> <span>int</span> <span>index</span><span>,</span> <span>String</span> <span>salt</span><span>,</span> <span>String</span> <span>hashFromDatabase</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>PASSWORD_CHARACTERS</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>ca</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>PASSWORD_CHARACTERS</span><span>[</span><span>i</span><span>];</span>

      <span>if</span> <span>(</span><span>index</span> <span>&lt;</span> <span>ca</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>)</span> <span>{</span>
        <span>fillArrayHashAndCheck</span><span>(</span><span>ca</span><span>,</span> <span>index</span> <span>+</span> <span>1</span><span>,</span> <span>salt</span><span>,</span> <span>hashFromDatabase</span><span>);</span>
      <span>}</span> <span>else</span> <span>{</span>
        <span>String</span> <span>password</span> <span>=</span> <span>salt</span> <span>+</span> <span>new</span> <span>String</span><span>(</span><span>ca</span><span>);</span>
        <span>String</span> <span>sha2Hex</span> <span>=</span> <span>DigestUtils</span><span>.</span><span>sha2Hex</span><span>(</span><span>password</span><span>).</span><span>toUpperCase</span><span>();</span>
        <span>if</span> <span>(</span><span>sha2Hex</span><span>.</span><span>equals</span><span>(</span><span>hashFromDatabase</span><span>))</span> <span>{</span>
          <span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>"plain text password is ["</span> <span>+</span> <span>password</span> <span>+</span> <span>"]"</span><span>);</span>
          <span>System</span><span>.</span><span>exit</span><span>(</span><span>0</span><span>);</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This program will generate all the possible passwords with lengths between 6 and 8 characters and then hash each one until it finds a match. This type of brute-force hacking takes time because of the number of possible combinations.</p>

<h2 id="password-complexity-vs-computational-power">Password complexity vs. computational power</h2>

<p>Let’s bust out our TI-85 calculators and see if we can figure out how long this program will take to run. For this example we will assume the passwords can only contain ASCII characters (uppercase, lowercase, digits, punctuation). This set is roughly 100 characters (this is rounded up to make the math easier to read). If we know that there are at least 6 characters and at most 8 characters in a password, then all the possible combinations can be represented by this expression:</p>

<div><div><pre><code>possiblePasswords = 100^8 + 100^7 + 100^6
</code></pre></div></div>

<p>The result of this expression is equal to <code>10,101,000,000,000,000</code>. This is quite a large number, North of 10 quadrillion to be a little more precise, but what does it actually mean when it comes to our cracking program? This depends on the speed of the computer the cracking program is running on and how long it takes the computer to execute the SHA2 algorithm. The algorithm is the key component here because the rest of the program is extremely fast at creating the passwords.</p>

<p>Here’s where things get dicey. If you run a quick Google search for <a href="http://lmgtfy.com/?q=fastest+bitcoin+rig">“fastest bitcoin rig”</a> you’ll see that these machines are rated in terms of the number of hashes they can perform per second. The bigger ones can be rated as high as <code>44 TH/s</code>. That means it can generate 44 tera-hashes per second or <code>44,000,000,000,000</code>.</p>

<p>Now, if we divide the total number of passwords by the number of hashes we can generate per second, we are left with the total time it takes a Bitcoin rig to generate the hashes for all possible passwords. In our example above, this equates to:</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^8 + 100^7 + 100^6 = 1.0101e16

numberOfSeconds = possiblePasswords / bitcoinRig = ~230
numberOfMinutes = numberOfSeconds / 60 = ~4
</code></pre></div></div>

<p>This means that using this example Bitcoin rig, we could generate all the hashes for a password between 6 and 8 characters in length in roughly 4 minutes. Feeling nervous yet? Let’s add one additional character and see long it takes to hash all possible passwords between 6 and 9 characters.</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^9 + 100^8 + 100^7 + 100^6 = 1.010101E18

numberOfSeconds = possiblePasswords / bitcoinRig = 22,956
numberOfMinutes = numberOfSeconds / 60 = ~383
numberOfHours = numberOfMinutes / 60 = ~6
</code></pre></div></div>

<p>By adding one additional character to the potential length of the password we increased the total compute time from 4 minutes to 6 hours. This is nearing a 100x increase in computational time to use the brute force strategy. You probably can see where this is going. To defeat the brute force strategy, you simply need to make it improbable to calculate all possible password combinations.</p>

<p>Let’s get crazy and make a jump to 16 characters:</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^16 + 100^15 ... 100^7 + 100^6 = 1e32

numberOfSeconds = possiblePasswords / bitcoinRig = 2.27e18
numberOfMinutes = numberOfSeconds / 60 = 3.78e16
numberOfHours = numberOfMinutes / 60 = 630,000,000,000,000 or 630 trillion
numberOfDays = numberOfHours / 24 = 26,250,000,000,000 or 26.25 trillion days
numberOfYears = numberOfDays / 365 = 71,917,808,219 or 71.9 billion years
</code></pre></div></div>

<p>To boil down our results, if we take these expressions and simplify them, we can build an equation that solves for any length password.</p>

<div><div><pre><code>numberOfSeconds = 100^lengthOfPassword / computeSpeed
</code></pre></div></div>

<p>This equation shows that as the password length increases, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/">https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133061</guid>
            <pubDate>Wed, 18 Nov 2020 04:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Code Like You Write a Recipe]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 84 (<a href="https://news.ycombinator.com/item?id=25133041">thread link</a>) | @ahungry
<br/>
November 17, 2020 | https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html | <a href="https://web.archive.org/web/*/https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-orgdb8398b">
<p>
As it tends to do, time continues to move on.  The project and code in
it eventually becomes legacy code (aka, someone else's problem to
maintain).
</p>

<p>
One day, the business drudges up that old automated cookie creation
idea and requests that it handles a new task - "instead of just cooking
peanut butter cookies, it'd be great if the cookie system could handle
oatmeal raisin as well!".
</p>

<p>
Hah!  You remember that old system, but you're onto newer and better
things.  This is a perfect task for the intern to sink their teeth
into - afterall, it's legacy and not high profile, it's been stable,
and it was so simple to implement the first time around.
</p>

<p>
The new set of requirements/recipe the intern works off of looks very
similar to the initial ones:
</p>

<ul>
<li>Step 1: Preheat oven to 325F, grease cookie sheet</li>
<li>Step 2: In bowl, stir oats, pumpkin puree and sugar until smooth.</li>
<li>Step 3: Beat in one egg white, then stir in baking soda, salt, and cinnamon.</li>
<li>Step 4: Roll dough into 1 inch balls and place 2 inches apart on the sheet.</li>
<li>Step 5: Bake for 8 minutes, cool for 5, enjoy!</li>
</ul>

<p>
He eagerly begins to expand the original code to handle the new case:
</p>

<div>
<pre><span>function</span> <span>makeCookies</span> <span>(</span><span>type</span> = <span>'peanut-butter'</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    oven.setTemperature<span>(</span>350<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    oven.setTemperature<span>(</span>325<span>)</span>
  <span>}</span>

  sheet.grease<span>()</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    bowl.add<span>(</span>peanutButter<span>)</span>
    bowl.add<span>(</span>sugar<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    bowl.add<span>(</span>oats<span>)</span>
    bowl.add<span>(</span>pumpkinPuree<span>)</span>
    bowl.add<span>(</span>sugar<span>)</span>
  <span>}</span>

  bowl.stir<span>()</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    bowl.beat<span>(</span>egg<span>)</span>
    bowl.beat<span>(</span>egg<span>)</span>
    bowl.stirIn<span>(</span><span>[</span>bakingSoda, salt, vanilla<span>]</span><span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    bowl.beat<span>(</span>eggWhite<span>)</span>
    bowl.stirIn<span>(</span><span>[</span>bakingSoda, salt, cinnamon<span>]</span><span>)</span>
  <span>}</span>

  <span>const</span> <span>dough</span> = bowl.makeDough<span>()</span>
  sheet.add<span>(</span>dough.balls<span>()</span><span>)</span>
  oven.add<span>(</span>sheet<span>)</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    oven.setTimer<span>(</span>10<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    oven.setTimer<span>(</span>8<span>)</span>
  <span>}</span>

  <span>const</span> <span>cookies</span> = oven.remove<span>(</span>sheet<span>)</span>
  sheet.cool<span>(</span>5<span>)</span>

  <span>return</span> cookies
<span>}</span>
</pre>
</div>

<p>
The code comes in, the peer reviews pass it as it meets the
requirements and nothing is obviously wrong.  Still, it has become a
bit harder to understand and you're left with a nagging feeling.
</p>
</div></div>]]>
            </description>
            <link>https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133041</guid>
            <pubDate>Wed, 18 Nov 2020 03:56:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[K8s Workflows with Armory and Spinnaker, from Day 0 to Deployment]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25132748">thread link</a>) | @drodio
<br/>
November 17, 2020 | https://www.armory.io/blog/k8s-workflows-with-armory-spinnaker-from-day-0-to-deployment/ | <a href="https://web.archive.org/web/*/https://www.armory.io/blog/k8s-workflows-with-armory-spinnaker-from-day-0-to-deployment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                

        <main id="global-main">

                        
                        



<section>
    <div>
        <div id="post-7793">
          
            
            <div><figure><img width="800" height="303" src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.00.15-PM-e1605597986841.png" alt="" loading="lazy"></figure></div>            <div>
                
                <h2><b>Armory, Spinnaker, and Kubernetes</b></h2>
<p><span>We are excited to announce that Armory now provides a K8s-native continuous delivery experience from end-to-end, unlocking Kubernetes deployments in the enterprise at massive scale. As a cloud-native, multi-cloud CD platform, Spinnaker has always been a powerful tool for deploying to Kubernetes. In fact, AWS and Google engineering teams helped to build the </span><a href="https://www.armory.io/blog/deep-dive-into-clouddriver/"><span>Spinnaker Clouddrivers</span></a><span> for deploying to EKS and GKE, and Spinnaker powers more than </span><b>8 million monthly K8s deployments</b><span>.&nbsp;</span></p>
<p><img loading="lazy" data-src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.09.28-PM-768x410.png" alt="" width="631" height="337" src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.09.28-PM-768x410.png"></p>
<p><em>Monthly OSS Spinnaker deployments to K8s are up 5x since April.</em></p>
<p><span>Armory is enhancing Spinnaker by introducing a familiar Kubernetes workflow, eliminating context-switching and domain-specific languages, and helping Spinnaker scale deployments to thousands of Kubernetes clusters.</span></p>
<h2><b>Day 0: The Armory Operator</b></h2>
<p><span>The </span><a href="https://www.armory.io/blog/announcing-the-spinnaker-kubernetes-operator/"><span>Armory Operator</span></a><span> is a Kubernetes operator for implementing and managing Spinnaker, bringing a Kubernetes-native GitOps workflow to managing Spinnaker’s full lifecycle. With the Operator, you treat Spinnaker as simply another Kubernetes deployment, installing, managing, and upgrading it with familiar tools such as <code>kubectl</code> and <code>kustomize</code>. Install Spinnaker with just a few keystrokes, and upgrade your Spinnaker version simply by changing the version number in a config file and applying. Access to other Kubernetes features, such as Kubernetes Secrets, also comes enabled out of the box.</span></p>
<p><span>The Operator also unlocks the scalability and security of a GitOps workflow by defining all of your Spinnaker configs as code and centralizing them in a single Git repo. This enables collaborative code reviews on all config changes to ensure that Spinnaker is stable and secure. Pre-flight validation of all changes adds a further layer of safety. In the event of a bad update, built-in config version control allows for rapid rollbacks and auditability.</span></p>
<p><span>The Operator is available for both Armory and open source Spinnaker.</span></p>
<h2><b>Building your Deployment Pipelines: PaCRD</b></h2>
<p><a href="https://docs.armory.io/docs/spinnaker-user-guides/pacrd/"><span>PaCRD</span></a><span> (a combination of “</span><a href="https://www.armory.io/armory-enterprise-spinnaker/pipelines-as-code-gitops/"><span>Pipelines as Code</span></a><span>” and “</span><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"><span>Custom Resource Definition</span></a><span>”) is a Kubernetes controller that manages the lifecycle of Spinnaker applications and pipelines as objects within your K8s cluster. PaCRD extends Kubernetes functionality to support Spinnaker Application and Pipeline objects that can be observed for changes through a mature lifecycle management API.</span></p>
<p><span>With PaCRD you can:</span></p>
<ul>
<li><span>Maintain your Spinnaker pipelines as code with the rest of your Kubernetes manifests.</span></li>
<li><span>Persist Pipeline and Application changes with confidence to your Spinnaker cluster.</span></li>
<li><span>Leverage existing tools <code>helm</code> and <code>kustomize</code> to template your pipelines across teams and projects.</span></li>
</ul>
<p><span>Pipelines as Code is one of Armory’s most powerful features. It brings security and repeatability to your application deployments by enabling you to templatize and share pre-blessed pipelines that are up-to-date with your organizational best practices and security &amp; compliance policies. With PaCRD, we are providing another method for accessing those benefits, but with a K8s-native workflow and some additional Kubernetes functionality.</span></p>
<p><span>PaCRD is available as an early release feature with select </span><a href="https://www.armory.io/armory-design-partners/"><span>Armory Design Partners</span></a><span>.&nbsp;</span></p>
<h2><b>Deployment to Production: The Armory Agent for Kubernetes&nbsp;</b></h2>
<p><span>Spinnaker is the tool of choice for hundreds of the world’s leading enterprises to deploy to Kubernetes. The </span><a href="https://www.armory.io/armory-enterprise-spinnaker/armory-agent-for-kubernetes/"><span>Armory Agent for Kubernetes</span></a><span> adds further scalability and security to Kubernetes deployments on Spinnaker, unlocking enterprise use cases at the highest scale as you expand your Kubernetes footprint. With the Agent, you can deploy to thousands of Kubernetes clusters as easily as you deploy to two.&nbsp;</span></p>
<p><span>The Agent acts as a highly performant and efficient Kubernetes controller on behalf of Spinnaker’s Clouddriver service. Its distributed, optimized caching model eliminates latency and accelerates pipeline execution times, while its decentralized account management design enhances security and enables individual teams to manage permissions for their specific clusters. These security and account management features are also enabling </span><a href="https://www.armory.io/armory-cloud/"><span>Armory Cloud</span></a><span>, a SaaS version of the Armory Platform that is currently in early release (request early access </span><a href="https://www.armory.io/armory-cloud-signup/"><span>here</span></a><span>).&nbsp;&nbsp;</span><img loading="lazy" data-src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-768x478.png" alt="" width="591" height="368" srcset="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-768x478.png 768w, https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-1024x637.png 1024w, https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-360x224.png 360w, https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM.png 1164w" sizes="(max-width: 591px) 100vw, 591px" src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-768x478.png"></p>
<p><em>The Armory Agent in Agent mode (other modes available).</em></p>
<h2><b>The Proof Is in the Pudding</b></h2>
<p><span>Spinnaker today handles millions of Kubernetes deployments from thousands of users, and that number will only continue to accelerate with the new features Armory has been rolling out to our customers and the broader community. Here are what some of those customers have to say:</span></p>
<blockquote><p><i><span>“The Armory platform has been a huge upgrade over our existing tooling in helping us quickly roll out innovative solutions with confidence. As a cloud-native continuous delivery platform designed for scale in a microservices world, Armory has helped OpenGov scale up from twenty to more than a hundred Kubernetes services.”</span></i></p>
<p><span>– Ashwani Wason, VP of Engineering &amp; Operations at OpenGov</span></p></blockquote>

<blockquote><p><i><span>“With Armory’s help, we’ve scaled up Spinnaker to support daily deployments to 30+ Kubernetes clusters and multiple environments.”</span></i></p>
<p><span>– Paul Selden, Principal Engineer at OpenX</span></p></blockquote>
<p><span>Read about how other companies are leveraging Armory and Spinnaker </span><a href="https://www.armory.io/learn/customer-success-stories/"><span>here</span></a><span>.</span></p>
<h2><b>Wrap-Up</b></h2>
<p><span>From implementing and managing Spinnaker to building and sharing your deployment pipelines to deploying your applications into production environments at largest scale, Armory and Spinnaker provide a deep Kubernetes-native workflow and set of functionality. Join dozens of the world’s leading enterprises, from hyper-growth startups to Fortune 20 banks, in deploying to K8s with Armory. Reach out to us </span><a href="https://www.armory.io/contact-us/"><span>here</span></a><span> to learn more about accelerating your Kubernetes deployments.</span></p>
            </div>
        </div>
    </div>
</section>



<section>
  
</section>
<section>
  <div>
    <div>
      <div>
        <div>

      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/11/grab-logo-png-transparent-768x296.png" alt=""></p>
  
    
  
    <p>Our Journey to Continuous Delivery at Grab (Part 1)</p>
  
    <p>Note: We are delighted to host this guest post by Sylvain Bougerel from Grab. The post can also be found on the&nbsp;Grab Tech Blog. Grab is a Singapore-based technology company offering ride-hailing transport services, food delivery, and payment solutions in addition to being the most well-funded private fintech startup in the market in Southeast Asia.</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/11/MicrosoftTeams.png" alt=""></p>
  
    
  
    <p>Spinnaker Adds Microsoft Teams Notification Support</p>
  
    <p>Microsoft Teams is now supported Microsoft Teams notification support is now available in Spinnaker 1.23.0.</p>
  
  
</div>
      
<div>
    
  
    
  
    <p>LitmusChaos in your Spinnaker Pipeline</p>
  
    <p>Chaos engineering is an essential ingredient in delivering reliable services. As underlying infrastructure becomes more and more ephemeral for efficiency’s sake, it becomes ever more important to ensure your workloads are resilient in a constantly changing environment. LitmusChaos is an emerging tool in this space and garnering traction in the Kubernetes community. So if you’re […]</p>
  
  
</div>
  
        </div>
      </div>
    </div>
  </div>
</section>


        </main>

        

        </div></div>]]>
            </description>
            <link>https://www.armory.io/blog/k8s-workflows-with-armory-spinnaker-from-day-0-to-deployment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132748</guid>
            <pubDate>Wed, 18 Nov 2020 03:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forcing Small Investors Out of Big Opportunities: SEC’s 99 Investor Limit]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25132612">thread link</a>) | @rmason
<br/>
November 17, 2020 | https://tinyseed.com/latest/99-investor-problem | <a href="https://web.archive.org/web/*/https://tinyseed.com/latest/99-investor-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e7b2ccadd106c01a49f9"><div><h3>The current limit of 99 accredited investors <strong>hurts capital formation</strong>, <strong>reduces investment opportunities</strong>, <strong>increases the risk to individual investors</strong> and <strong>decreases access to private capital markets for underrepresented groups</strong>.</h3><p>At TinySeed, we are in the process of <a href="https://tinyseed.com/latest/invest">raising the second fund</a> for our SaaS accelerator, and we’re often asked why we have such a high minimum investment. If an <a href="https://www.investopedia.com/terms/a/accreditedinvestor.asp">accredited investor</a> wants to put in $50,000, why would we turn them down?&nbsp;</p><p>It all comes down to SEC regulations, which limit funds like ours to a maximum of 99 accredited investors. In order to raise the amount of capital required to execute on <a href="https://tinyseed.com/thesis">our investment thesis</a>, we must enforce a (relatively) high minimum investment.&nbsp;</p><p>We didn’t write this article to complain about our situation, as <a href="https://tinyseed.com/invest">fundraising (even with this minimum in place) is going quite well</a>. But for us, this process has brought to light an unintended consequence of this 99 investor limit.</p><p>Over time, successful venture firms raise larger and larger funds, quickly running into the 99 investor limit, and forcing their investment minimum higher. <strong>These high minimums concentrate this wealth creation opportunity to super high net worth individuals and institutional investors, excluding accredited investors who cannot afford to write such a large check.</strong></p><p>The SEC enforces certain kinds of regulations to provide investor protections against fraud and abuse, which we salute. However, current regulations (and this 99 investor limit) prohibit the average accredited investor from accessing these markets in a meaningful way. This matters because the private markets are a significant driver of wealth creation.</p><p>We fully understand that the SEC needs to have some limit on the number of investors that can invest in a private fund. <strong>However, we believe that the current limit of 99 is the wrong approach.&nbsp;</strong></p><p>We started TinySeed because we wanted to give founders more options for capital to grow their companies, and we feel that as a fund, we can and should also call for change in how sophisticated investors are able to invest their money.<strong><em> </em></strong>Specifically, we believe that successful tech founders and operators should be able to invest into the field they understand best — early stage technology — instead of being limited to real estate or the public markets.</p><p>We believe funds like ours should be able admit up to 1999 accredited investors, assuming they are required to make reasonable efforts to verify that investors are accredited.</p><h3>As the current rules are enshrined in law, we’re exploring ways to bring this issue in front of Congress. <strong>If you are an emerging manager or stakeholder who would like to see the 99 investor limit raised, send us an email at </strong><a href="mailto:hello@tinyseed.com"><strong>hello@tinyseed.com</strong></a><strong>.</strong></h3><p><strong>Please help raise awareness of this issue:</strong></p><ul data-rte-list="default"><li><p><a href="https://twitter.com/intent/tweet?text=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem%20">Share on Twitter</a></p></li><li><p><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem" target="_blank">Share on Facebook</a></p></li><li><p><a href="https://www.linkedin.com/shareArticle?mini=true&amp;source=TinySeed&amp;summary=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20&amp;title=&amp;url=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem">Share on LinkedIn</a></p></li></ul><p>Fund regulations and SEC rules are fairly complicated; read on for our breakdown of what everything means below:<br></p><h2>Current SEC regulatory regime for private funds</h2><h3>3(c)(1) vs. 3(c)(7)</h3><p>The SEC’s regulatory regime currently provides 2 exemptions to the (burdensome and expensive) requirement for a venture fund like ours to be registered with the SEC: 3(c)(1) and 3(c)(7).</p><p>A 3(c)(1) fund may have no more than 99 Accredited Investors, while a 3(c)(7) fund can have up to 1999 investors, but these must all be “Qualified Purchasers”. The qualified purchaser, or QP, definition is a significant increase in the required net worth compared to accredited investors.</p><h3>Why can’t investors pool their money and create a single entity to invest?</h3><p>The SEC stipulates that accredited investors cannot pool their money and create a single entity (for example through an SPV) to invest in the fund – the SEC will “look through” this entity and count the number of investors there as long as the entity was created for the purpose of making a specific investment.&nbsp;</p><h3>Why can’t we create parallel funds?</h3><p>Another often suggested option, to run several parallel funds that co-invest, is also forbidden, as the SEC will count as a single fund, any set of funds that a reasonable investor would deem to be identical.</p><h3>One burdensome option: The “QP sleeve”</h3><p>The only exception to the above is what’s sometimes referred to as a “QP sleeve”. A 3(c)(1) fund may operate in parallel with a separate 3(c)(7) fund. This does add significant overheads, but frees up some slots for accredited investors by moving the qualified purchasers into the 3(c)(7) (of which there can be 1999).</p><h3>The recent JOBS act</h3><p>A more recent change was introduced with the JOBS act, which expanded the ability of fund managers to promote their offerings publicly, with the trade-off that doing so would tighten the requirement to verify that all investors were in fact accredited investors (a 506c offering). We think these changes are laudable, as they increase awareness of specific offerings among accredited investors while also adding further, appropriate, protections.</p><h2>Recent regulatory efforts to expand investment opportunities, harmonize regulations with other jurisdictions and further capital formation</h2><p>&nbsp;The SEC very recently issued updated accredited investor definitions: </p><blockquote><p>For the first time, individuals will be permitted to participate in our private capital markets not only based on their income or net worth, but also based on established, <strong><em>clear measures of financial sophistication</em></strong>.</p></blockquote><p>(Emphasis ours.)</p><p>We salute this change, and even though we think the SEC has further to go in terms of widening the definition of accredited investors, it’s a great first step. This change is well inline with the SECs ongoing efforts to “simplify, harmonize, and improve the exempt offering framework, thereby expanding investment opportunities while maintaining appropriate investor protections and promoting capital formation.”</p><p><strong>&nbsp;However, we believe that the current limit of 99 accredited investors per 3(c)(1) fund runs counter to these efforts.</strong></p><h2>The many downsides of the 99 accredited investor limit</h2><p>The current limit of 99 accredited investors <strong>hurts capital formation</strong>, <strong>reduces investment opportunities</strong>,&nbsp; <strong>increases the risk to individual investors</strong> and <strong>decreases access to private capital markets for underrepresented groups</strong>.</p><ul data-rte-list="default"><li><p>A fund manager can accept smaller checks from wealthier individuals, as the higher QP limit in the sleeve means that there is effectively no minimum amount required of those individuals. </p></li><li><p>Conversely, and perversely, a fund manager looking to raise a more substantial fund is forced to ask for larger checks from the less wealthy investor, or keep that investor out of the fund entirely.</p></li></ul><p><strong>This is far from ideal and, in our experience, excludes sophisticated investors from being allowed to invest in funds like ours. </strong>In some cases these excluded investors have a deep understanding of the industry being invested into, and perhaps with atypical backgrounds as far as fund investors go. <strong>We do not believe those kinds of investors should be effectively excluded from making these kinds of investments.</strong></p><p>Instead what happens is that as funds grow from very small (sub $10m) they are forced to seek capital from larger, institutional investors like Fund of Funds, Endowments and various Family Offices.</p><p><strong>While these more institutional LPs are a fine source of capital, it’s undoubtedly true that they are more risk averse and in general prone to relying on a proven track record for the managers they back.&nbsp;</strong></p><p>A great example of this is the University of Texas’ (laudable) Emerging Managers Program. This is a program setup explicitly to support new (aka emerging) managers, though the criteria for selection includes:</p><ul data-rte-list="default"><li><p>Attributable track record within target strategy</p></li><li><p>Investment teams with history of working together</p></li><li><p>Principals known in the investment community and are positively referenceable</p></li></ul><p><strong>Clearly, such terms favor managers that “emerge” from existing funds.</strong> This means that the type of general partners that more easily get backing from these kinds of investors are of the same mold as GPs that already exist.<strong> New and diverse GPs with novel ways to invest are effectively locked into staying small or violating SEC rules.</strong></p><h2>Proposed solution: <br><strong>Allow as many Accredited Investors as Qualified Purchasers.</strong></h2><p>The oversight of private funds is light by definition, so we fully understand why the SEC imposes a limit on the number of investors. Without a limit, a fraudulent fund could become a significant issue if tens or hundreds of thousands of investors could invest.&nbsp;</p><p><strong>However, we feel the unintended consequences of concentrating wealth creation to only super high net worth individuals or institutional investors with the 99 Accredited Investors limit is not the right trade-off in this regard.</strong> We propose that private funds relying on the 3(c)(1) exemption should be allowed to admit up to 1999 accredited investors, assuming they are required to make reasonable efforts to verify that investors are in fact accredited (something that is already a requirement for a 506c offering.)</p><h3><strong>If you are an emerging manager or stakeholder who would like to see the 99 investor limit raised, send us an email at </strong><a href="mailto:hello@tinyseed.com"><strong>hello@tinyseed.com</strong></a><strong>.</strong></h3><p><strong>Please help raise awareness of this issue:</strong></p><ul data-rte-list="default"><li><p><a href="https://twitter.com/intent/tweet?text=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem%20" target="_blank">Share on Twitter</a></p></li><li><p><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem" target="_blank">Share on Facebook</a></p></li><li><p><a href="https://www.linkedin.com/shareArticle?mini=true&amp;source=TinySeed&amp;summary=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20&amp;title=&amp;url=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem" target="_blank">Share on LinkedIn</a></p></li></ul></div></div></div>]]>
            </description>
            <link>https://tinyseed.com/latest/99-investor-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132612</guid>
            <pubDate>Wed, 18 Nov 2020 02:43:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run x86 Apps (including homebrew) in the Terminal on Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 134 (<a href="https://news.ycombinator.com/item?id=25132217">thread link</a>) | @JoshuaMulliken
<br/>
November 17, 2020 | https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602 | <a href="https://web.archive.org/web/*/https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132217</guid>
            <pubDate>Wed, 18 Nov 2020 01:41:41 GMT</pubDate>
        </item>
    </channel>
</rss>
