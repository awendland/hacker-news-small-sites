<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 27 Aug 2020 08:22:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 27 Aug 2020 08:22:26 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust-Style Futures in C]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24264841">thread link</a>) | @axelf4
<br/>
August 24, 2020 | https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html | <a href="https://web.archive.org/web/*/https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>All networking applications essentially boil down to stringing together
multiple asynchronous calls in the <em>right</em> way.
Traditionally for programs written in C this would be done through
registering callbacks where the callee either handles the event itself
or dispatches through a state machine.
In such implementations however reasoning about memory safety
can be treacherous, with it sometimes requiring full-program knowledge.
Futures, or promises, as they are also referred to,
ease in that regard by allowing asynchronous programs
to be written in direct style, keeping the control flow linear.</p>

<p>All things considered, I do think that futures can be a good fit
for C programming under the right circumstances.
I also hope this article can serve to help one understand Rust futures,
by being a separate reference that only touches the fundamentals.</p>

<p>The Rust futures story is especially interesting because it is
fundamentally different from the usual workings of futures
in functional languages or, say, JavaScript.
Whereas other implementations are <em>push</em>-based -
meaning you give a function to be pushed to with
the resolved result of the future -
Rust futures are <em>poll</em>-based.
Let us see how this looks in C with the simplification
that we limit ourselves to a single task,
i.e. one top-level future running on one thread.
This is common in embedded programming, and still <em>fairly</em> manageable
without the security guarantees given by Rust.
<a href="https://libuv.org/">libuv</a> is used for the event loop.
No heap allocations will be required - it is all downhill from here
(Get it? Because the stack grows down.) -
other than those imposed by the libuv interface.</p>

<p>The main <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>std::future::Future</code></a> trait
translated into C as a virtual method table becomes</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>{</span> <span>POLL_PENDING</span><span>,</span> <span>POLL_READY</span> <span>};</span>

<span>struct</span> <span>Future</span> <span>{</span>
	<span>enum</span> <span>Poll</span> <span>(</span><span>*</span><span>poll</span><span>)(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>);</span>

	<span>// For now let's skip this method</span>
	<span>// void (*drop)(struct Future *self, struct Context *ctx);</span>
<span>};</span>
</code></pre></div></div>
<p>As an example, let us consider the simplest case:
A future that immediately resolves with the number <code>4</code>,</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>simpleFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>SimpleFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>SimpleFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>self</span><span>-&gt;</span><span>result</span> <span>=</span> <span>4</span><span>;</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>SimpleFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>int</span> <span>result</span><span>;</span>
<span>}</span> <span>simpleFuture</span> <span>=</span> <span>{</span> <span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>simpleFuturePoll</span><span>,</span> <span>}</span> <span>};</span>

<span>// ... and in the event loop</span>
<span>simpleFuture</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>simpleFuture</span><span>,</span> <span>ctx</span><span>);</span> <span>// =&gt; POLL_READY</span>
<span>// Here we can now use the result</span>
<span>simpleFuture</span><span>.</span><span>result</span> <span>// =&gt; 4</span>
</code></pre></div></div>
<p>To <em>attempt</em> to resolve the future, we poll it;
it returns <code>POLL_READY</code> and as such we are done.
And for futures that instead return <code>POLL_PENDING</code> when polled,
we just make sure to poll them again later -
futures are lazy and do not make progress unless actively told to do so.
No one knows better than the future itself when it should
be polled again - <em>awoken</em> -
so the context given to all futures allows them to awake their own task.
With many parallel tasks the additional complexity would make itself apparent here,
but in our case something like</p>
<div><div><pre><code><span>struct</span> <span>Context</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>*</span><span>mainFuture</span><span>;</span>
	<span>uv_loop_t</span> <span>loop</span><span>;</span>
<span>};</span>

<span>void</span> <span>wakeTask</span><span>(</span><span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>if</span> <span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>-&gt;</span><span>poll</span><span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_READY</span><span>)</span> <span>{</span>
		<span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span> <span>// Finished!</span>
	<span>}</span>
<span>}</span>
</code></pre></div></div>
<p>will suffice.
Polling the future once at startup will then kick off the machinery.</p>

<p>For a libuv timer future, we would want to write something like</p>
<div><div><pre><code><span>enum</span> <span>TimerStatus</span> <span>{</span> <span>TIMER_NOT_STARTED</span><span>,</span> <span>TIMER_WAITING</span><span>,</span> <span>TIMER_FINISHED</span> <span>};</span>

<span>struct</span> <span>TimerFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>enum</span> <span>TimerStatus</span> <span>status</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>uint64_t</span> <span>timeout</span><span>;</span>
		<span>uv_timer_t</span> <span>*</span><span>handle</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>static</span> <span>void</span> <span>uvCloseFree</span><span>(</span><span>uv_handle_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>free</span><span>(</span><span>handle</span><span>);</span>
<span>}</span>

<span>static</span> <span>void</span> <span>timerCb</span><span>(</span><span>uv_timer_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>data</span><span>;</span>
	<span>struct</span> <span>Context</span> <span>*</span><span>ctx</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>loop</span><span>.</span><span>data</span><span>;</span>
	<span>uv_close</span><span>((</span><span>uv_handle_t</span> <span>*</span><span>)</span> <span>handle</span><span>,</span> <span>uvCloseFree</span><span>);</span>
	<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_FINISHED</span><span>;</span>
	<span>wakeTask</span><span>(</span><span>ctx</span><span>);</span>
<span>}</span>

<span>static</span> <span>enum</span> <span>Poll</span> <span>timerFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TimerFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>status</span><span>)</span> <span>{</span>
		<span>case</span> <span>TIMER_NOT_STARTED</span><span>:</span>
			<span>uint64_t</span> <span>timeout</span> <span>=</span> <span>state</span><span>-&gt;</span><span>timeout</span><span>;</span>
			<span>state</span><span>-&gt;</span><span>handle</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span> <span>*</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>uv_timer_init</span><span>(</span><span>ctx</span><span>.</span><span>loop</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>handle</span><span>-&gt;</span><span>data</span> <span>=</span> <span>state</span><span>;</span>
			<span>uv_timer_start</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>,</span> <span>timerCb</span><span>,</span> <span>timeout</span><span>,</span> <span>/* no repeat */</span> <span>0</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_WAITING</span><span>;</span>
			<span>/* fallthrough */</span>
		<span>case</span> <span>TIMER_WAITING</span><span>:</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
		<span>case</span> <span>TIMER_FINISHED</span><span>:</span>
			<span>return</span> <span>POLL_READY</span><span>;</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>TimerFuture</span> <span>timerFutureNew</span><span>(</span><span>uint64_t</span> <span>timeout</span><span>)</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TimerFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>timerFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>status</span> <span>=</span> <span>TIMER_NOT_STARTED</span><span>,</span>
		<span>.</span><span>timeout</span> <span>=</span> <span>timeout</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>
<p>The timer handle is made to hold a reference to the future in
its user data field,
so that the callback knows which future to toggle the status on.
However this requires the future object to be pinned in memory,
moving it would make the reference dangling.
Rust deals with this unsafety using the <a href="https://doc.rust-lang.org/std/pin/index.html">Pin construct</a>,
that wraps a pointer type, <code>P</code>,
and only permits operations that cannot move the pointee
(for cases where it may not always be safe to do so, i.e. <code>P: !Unpin</code>)
and ensures its memory remains valid until it gets dropped,
or helps make manually vetted code <em>nonleaky</em>.
In C there is no such thing;
the closest you will get is with a red paragraph buried in the documentation.
This means treading with care,
allocating storage for the main future once and never copying it, and
only referring to futures with pointers to their static place in memory.</p>

<p>Note that it is possible to get by with just one global <code>uv_timer_t</code>
by recognizing that whenever the main future is awoken either:
(I) A timer, necessarily the one with smallest timeout, fired;
or (II) All timers need be dropped and reset, since the futures form a tree,
as we will see.</p>

<h2 id="after-you">After you</h2>

<p>Running multiple futures sequentially is just a matter of
constructing a new future that polls each future to completion,
one after the other.
The poll method of the outer future will have to return <code>POLL_PENDING</code>
after each intermediate step,
before continuing where it left off - like a coroutine.
Rust turns each future into a state machine,
and doing the same in C means playing the part of the Rust compiler.
An adaptation of <a href="https://en.wikipedia.org/wiki/Duff%27s_device">Duff’s device</a>,
as <a href="https://www.chiark.greenend.org.uk/~sgtatham/coroutines.html">described by Simon Tatham</a>,
can help cut down on the boilerplate.
The idea is that with a <code>switch</code> statement enveloping the whole function-body,
you can yield by creating a unique label using the <code>__LINE__</code> macro
where execution will begin upon reentry,
setting the switch-expression as such, and returning.
The following macros do just that</p>
<div><div><pre><code><span>typedef</span> <span>unsigned</span> <span>Coroutine</span><span>;</span>

<span>#define COR_START(s) switch (*(s)) { case 0:;
#define COR_YIELD(s, r) do {*(s) = __LINE__; return (r); case __LINE__:;} while(0)
#define COR_END }
</span></code></pre></div></div>
<p>where <code>s</code> is a pointer to the coroutine state.
Great care has to be taken because when returning all locals are invalidated -
if only there was a language that could statically check for such mistakes.
Awaiting then becomes</p>
<div><div><pre><code><span>#define AWAIT(s, ctx, fut) while ((fut)-&gt;poll((fut), (ctx)) == POLL_PENDING) \
	COR_YIELD((s), POLL_PENDING)
</span></code></pre></div></div>
<p>that is, yielding until the given future is resolved.</p>

<p>To illustrate, here is a future that prints four times to standard output,
first thrice at one second intervals, and then again after two more seconds:</p>
<div><div><pre><code><span>struct</span> <span>TestFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>Coroutine</span> <span>c</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>struct</span> <span>{</span>
			<span>int</span> <span>i</span><span>;</span>
			<span>struct</span> <span>TimerFuture</span> <span>timerA</span><span>;</span>
		<span>};</span>
		<span>struct</span> <span>TimerFuture</span> <span>timerB</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>struct</span> <span>TestFuture</span> <span>testFutureNew</span><span>()</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TestFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>testFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>c</span> <span>=</span> <span>0</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>

<div><table>
<thead><tr><th>With macros</th><th>Desugared</th></tr></thead>
<tbody><tr>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>COR_START</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span>

	<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
		<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
		<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>);</span>
		<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
	<span>}</span>

	<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
	<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>);</span>
	<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>

	<span>COR_END</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span> <span>{</span>
		<span>case</span> <span>0</span><span>:</span> <span>;</span>
		<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
			<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
				<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>1</span><span>;</span>
				<span>return</span> <span>POLL_PENDING</span><span>;</span>
				<span>case</span> <span>1</span><span>:</span> <span>;</span>
			<span>}</span>
			<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
		<span>}</span>

		<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
		<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>2</span><span>;</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
			<span>case</span> <span>2</span><span>:</span> <span>;</span>
		<span>}</span>
		<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
</tr>
</tbody></table></div>
<p>Note that the local <code>i</code> had to be spilled to the future struct
in order to persist across yield points,
and that unions are used to show what variables are active at each step,
and squeeze out that last driblet of performance even in the face of
uncompromising undefined behaviour threats from all directions.</p>

<h2 id="off-to-the-races">Off to the races</h2>

<p>In a similar vein, multiple futures can be made to run in parallel
using a future combinator whose poll method polls all of its children
and either waits for all to complete - <em>joins</em> them,
or selects the first to become ready.
The latter is a tad more difficult, so let us focus on that.
The reason is that after the first future has resolved,
the rest may still be running, their memory possibly referenced elsewhere.
This is where the <code>drop()</code> method that we have skimmed over comes in.
Dropping a pinned object should relax the constraint
that its memory remains valid.
The drop implementation of <code>TimerFuture</code> above could for example
call <code>uv_timer_stop()</code> so the callback never fires
or overwrite the dangling reference to the future with <code>NULL</code>.
For other types, since their drop implementations are …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</a></em></p>]]>
            </description>
            <link>https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264841</guid>
            <pubDate>Mon, 24 Aug 2020 20:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jensen Huang’s vision for data center dominance may destroy the Arm ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24264288">thread link</a>) | @kasabali
<br/>
August 24, 2020 | https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="552" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="680b3ce0" data-element_type="section">
						<div>
							<div>
					<div data-id="c620d2" data-element_type="column">
			<div>
							<div>
						<div data-id="6eb11d27" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>As the weeks pass by, the rumors keep spinning, the likelihood of an Nvidia Arm acquisition increases. On first glance, the two businesses look completely incompatible. A highly vertically integrated graphics and AI company with very high margins buying a low margin IP licensor doesn’t make sense. Nvidia can already build any product they wish as an Arm licensee. Purchasing the whole cow doesn’t yield additional milk or synergies from the current business model. Furthermore, given Nvidia’s reputation as a partner, it would likely even cause customers to start looking for contingencies and accelerate RISC-V adoption. Jensen Huang, in his quest for data center dominance, may destroy the Arm ecosystem for everyone else.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/1.jpg?resize=1140%2C606&amp;ssl=1" alt="1" width="1140" height="606" data-recalc-dims="1"></p><p>The rational for purchasing Arm seems ridiculous to many, but Jensen’s vision is for the datacenter being a computer and Nvidia being the one to build it. They need to be to be completely vertically integrated and control every aspect of this computer. Currently they have the accelerator market on lock-down with their impressive hardware and vast software moat of CUDA/various SDKs which was built by thousands of Nvidia engineers over the last decade. With the acquisition of Mellanox, they bring the “Data Processing Unit (DPU)” of the data center in house as well. They have also continued to expand their vertically integrated software stack to networking with acquisitions of SwiftStack and Cumulus Networks.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/2.jpg?resize=1140%2C575&amp;ssl=1" alt="2" width="1140" height="575" data-recalc-dims="1"></p><p>The datacenter is a 3 legged stool, and the remaining missing piece is a CPU. AMD, Intel, and various hyperscalers are also working to build out their own 3-legged stool. The largest threat to Nvidia is Intel/AMD finally having competent GPUs and software stacks to accompany them. With the US Department of Energy dumping money into SYCL and many in the industry congregating around it, the software front is accelerating rapidly. Furthermore, various hyperscalers are rapidly building out their own CPUs with Arm Neoverse IP to hook in with their accelerators such as the Google TPU and Amazon Inferentia for AI workloads. Lastly, these hyperscalers also already have their own custom network stacks. Nvidia is currently in very strong position, but it is very precarious as their moats may all be eroded simultaneously.</p><p>In any business, in order to maintain a high margin over a long period of time, one must create barriers of entry so high, that no one can break in and disrupt. Even though Intel has stopped executing for essentially 5 years, they are still raking in the dough with &gt;55% gross margins. Jensen Huang’s vision, if fully realized, would see Nvidia building a nearly impenetrable moat that commands high margins and locks customers in. This may sound nefarious, but Nvidia’s solution will be plug and play. The vast majority of companies do not have the resources required to build out the entire software stack to match specialized hardware. Nvidia would offer the best solution, which would eventually become an expensive deal imprisoning you in the Devil’s ecosystem.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/3.png?resize=1140%2C587&amp;ssl=1" alt="3" width="1140" height="587" data-recalc-dims="1"></p><p>This is where acquiring Arm rather than licensing her technology comes into play. Nvidia needs to build the moat, and the only way to do this is to effectively hijack the entire open Arm ecosystem. Developing your own CPU ISA is far too large of an investment and there would be no adoption. Even the opening up of Power and MIPS have failed to stop their slow declines to irrelevancy. RISC-V is also still in its infancy and will take many years to move into any verticals besides embedded.</p><p>Jensen can only realize the of the vision of data center dominance by becoming the only company with the trifecta of CPU, GPU, and DPU. Nvidia can only achieve this by acquiring Arm at an unreasonable price. An independent Arm is simply not worth the $35B-$50B which SoftBank wants. Even a $20B valuation would be high valuation for Arm.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/4.jpg?resize=1140%2C641&amp;ssl=1" alt="4" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia can justify this price if they are willing to flip the semiconductor IP world on its head. The ultimate path to ROI means upending the current Arm business model. Given Nvidia’s over $300B valuation, the deal wouldn’t have to be very dilutive to current shareholders. They would start by purchasing the business in a cash/stock deal and obtaining regulatory approval. Regulatory approval initially seems like a large hurdle, but we believe it will not be. The UK will gladly approve if Nvidia makes commitments for large investments. China would be willing to look the other way if the current Arm China JV drama is swept under the rug. The EU would likely need concessions, but because Nvidia does not compete in most of Arm’s verticals, it shouldn’t be too difficult to obtain approval here either. The US regulators would be foaming at the thought of US control of Arm.</p><p>The next step would involve assuring the clients that the businesses would operate separately. Jensen has already begun telegraphing this according to the <a href="https://www.ft.com/content/b4649576-9541-4857-b3a4-5b4ccb847642">Financial Times</a>.</p><blockquote><p>As the company extends its reach to supply a complete data centre computing platform, it would sell parts of the technology as separate “layers”, Mr Huang said. Other companies would also be able to license its intellectual property for use in their own chips, rather than needing to buy silicon from Nvidia, he added.</p></blockquote><p>As part of the integration of the two companies, Nvidia would cut or sell the Arm Mali GPU and Ethos NPU business. These would be redundant and can be supplemented with Nvidia’s own expertise. This would be quite the shock as Nvidia’s previous attempts to license their GPU architecture have completely failed. If Nvidia is successful in the renewed licensing efforts, we could live in a world where their CUDA architecture with accompanying software stack (read lock-in) is proliferated across phones, embedded, and the upcoming augmented reality segment. There would be some attrition as companies like Samsung have turned to licensing AMD’s RDNA graphics. In general, it would also accelerate the move out of the Arm ecosystem to RISC-V, but this will be a painful and slow move for most.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/5.png?resize=1024%2C395&amp;ssl=1" alt="5" width="1024" height="395" data-recalc-dims="1"></p><p>The key for Nvidia here is creating captive, dependant customers by rocking the boat, but not too violently. If the NvidiArm solution is convenient and cheap, most of the ecosystem will not attempt to rush out. Nvidia likely does not increase prices for a while in order to give their licensees an illusion of a happy status quo. Eventually, these price increases will come. The attrition will be the worst in the embedded market where RISC-V is mostly already here and players like <a href="https://twitter.com/dylan522p/status/1295500585123188737?s=20">Alibaba</a> and Si-Five have the IP nearly ready to go.</p><p>The mobile SOC market is captive to Arm roadmaps for years to come, and this is one of the sectors Nvidia can start aggressively extracting ROI. Apple has a perpetual license and so they won’t be affected, but Qualcomm, Samsung, and Mediatek would start to sweat bullets as their licensing costs soar and they have no alternatives without their own custom core teams which have been disbanded. Mediatek specifically is highly dependent on not only ARM CPUs, but also GPUs and interconnects for many of their SOCs.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/6.png?resize=1140%2C641&amp;ssl=1" alt="6" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia’s largest avenue for ROI comes the data center. x86 is long overdue for some disruption. Even with AMD innovating rapidly, the world wants more options. Arm server development is being done by multiple hyperscalers and independent fabless vendors. Arm is going to break the x86 monopoly with a combination of licensed Neoverse designs and in-house designs from the likes of Nuvia or Marvell. Once the x86 duopoly is broken, Nvidia can also raise prices rapidly here. &nbsp;The hyperscalers in-house Arm Neoverse designs will still have better TCO than any merchant silicon, but the savings will begin to wane.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/7.png?resize=1140%2C641&amp;ssl=1" alt="7" width="1140" height="641" data-recalc-dims="1"></p><p>Another adjacent market where Nvidia can begin to pressure their competition is automotive. While Intel’s Mobileye currently uses MIPS and is transitioning to x86, Tesla and Qualcomm use Arm Cores. If licensing fees ratchet up here significantly, Nvidia can begin to extract margin out of their competitors’ sales. Ultimately, the CPU isn’t a competitive advantage in automotive, but just the cheapest and most convenient option.</p><p>As the Arm ecosystem matures, it will stop being the cheapest option, but only remain the convenient one. Embedded markets have already seen the light of RISC-V and the adoption can only accelerate from here. Other markets have been hooked to the drug of cheap, licensed, Arm IP. With aggressive Nvidia ownership, the junkies will have no choice but to pay up and give in to demands for the short run. They will search for alternative supplies, but this move will take a long time.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/8.jpg?resize=1140%2C642&amp;ssl=1" alt="8" width="1140" height="642" data-recalc-dims="1"></p><p>Nvidia’s endgame isn’t more revenue from licensing costs. Their endgame is a fully vertically integrated data center provider. They will want to make and control every part of the three legged stool. This means they slowly destroy the idea of Neoverse. Whether through making that IP extremely costly, or having their own in house designs be a generation ahead, Nvidia will build a moat around Arm server CPUs. Over time, Jensen Huang will muscle out other Arm vendors supplementing them with Nvidia’s in-house designs. The open Arm ecosystem will be hijacked, and be replaced with a closed off ecosystem rivaling or exceeding that of Intel and AMD.</p><p><span>If Nvidia can quickly seize the worlds most important IP, the most commonly used CPU ISA and designs, they will control the destiny of mobile and data center. This is Jensen Huang’s “Trojan Horse” for a Machiavellian takeover of the future of computing.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264288</guid>
            <pubDate>Mon, 24 Aug 2020 19:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Test Case Generator for a Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24263117">thread link</a>) | @azhenley
<br/>
August 24, 2020 | http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html | <a href="https://web.archive.org/web/*/http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Maxime Chevalier-Boisvert requested resources for learning about fuzzing
programming language implementations on Twitter:</p>

<blockquote>
  <p>I’d like to learn about fuzzing, specifically fuzzing programming language
implementations. Do you have reading materials you would recommend, blog
posts, papers, books or even recorded talks?</p>
</blockquote>

<p><cite><a href="https://twitter.com/Love2Code">@Love2Code</a> · <a href="https://twitter.com/Love2Code/status/1290363848885776385">August 3,
2020</a></cite></p>

<p>Maxime received many replies linking to informative papers, blog posts, and
lectures. <a href="https://twitter.com/johnregehr/status/1290368969199636480">John Regehr suggested writing a simple generative fuzzer for the
programming
language.</a></p>

<p>A generative fuzzer combines a test case generator with the system under test
(e.g. your compiler), generating new test cases and feeding them into the
system:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>generative_fuzzer</span><span>()</span> <span>{</span>
    <span>loop</span> <span>{</span>
        <span>// Use the test case generator to create a new</span>
        <span>// input.</span>
        <span>let</span> <span>input</span> <span>=</span> <span>generate_test_case</span><span>();</span>

        <span>// Feed that input into the system under test.</span>
        <span>let</span> <span>result</span> <span>=</span> <span>run_system_under_test</span><span>(</span><span>input</span><span>);</span>

        <span>// Finally, if the system under test crashed,</span>
        <span>// failed an assertion, etc... then report</span>
        <span>// that!</span>
        <span>if</span> <span>result</span><span>.is_interesting</span><span>()</span> <span>{</span>
            <span>report</span><span>(</span><span>input</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>I realized that many people might not know what it takes to write their own
generative fuzzer, so this blog post shows one aspect of it: implementing a test
case generator.</p>

<p>Our test case generator will generate <a href="https://webassembly.org/">WebAssembly</a> programs. While
WebAssembly has its own quirks — it’s a binary format and is generally a
compilation target rather than a source language — it is a small and
simple language. The techniques we use when generating WebAssembly should
transfer to generating the programming language of your choice.</p>

<p>If you want to skip the exposition and jump head first into the code, <a href="https://github.com/fitzgen/wasm-smith">here is
the repository for our final test case generator</a>.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#what-is-a-test-case-generator">What is a Test Case Generator?</a></li>
  <li><a href="#getting-set-up">Getting Set Up</a></li>
  <li><a href="#translating-grammars-into-generators">Translating Grammars into Generators</a></li>
  <li><a href="#generating-the-type-section">Generating the Type Section</a></li>
  <li><a href="#generating-the-import-section">Generating the Import Section</a></li>
  <li><a href="#generating-the-code-section">Generating the Code Section</a></li>
  <li><a href="#using-the-test-case-generator">Using the Test Case Generator</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="what-is-a-test-case-generator">What is a Test Case Generator?</h2>

<p>Test case generators generate test cases. These test cases are always within the
test domain: no cycles are wasted on invalid inputs, such as source text that
fails to parse. Compare this to <a href="https://www.fuzzingbook.org/beta/html/MutationFuzzer.html">mutation-based fuzzing</a>, where existing seed
inputs are mutated to produce new inputs. In general, nothing guarantees that
the new, mutated input is still within the test domain: the mutation may have
introduced a syntax error. This property, that generated inputs are always
within the test domain, is generative fuzzing’s main advantage and the test case
generator’s main responsibility.</p>

<p>A test case generator should, additionally, support every feature of its target
programming language. You won’t discover a bug in your compiler’s handling of
<code>switch</code> statements if the test case generator doesn’t support generating
<code>switch</code> statements. Pushing this idea even further, the test case generator
should <em>uniformly sample</em> from the test domain. If the test case generator can
technically generate <code>switch</code> statements but the probability of doing so is
nearly zero, then you likely still won’t find that bug. However, uniformly
sampling from the infinite set of all programs that can be written in a
particular programming language is
<a href="https://blog.regehr.org/archives/1700">nontrivial</a> and an area of
<a href="https://arxiv.org/pdf/0807.0992v1.pdf">active</a>
<a href="https://havrikov.github.io/publications/ase19-preprint.pdf">research</a>.</p>

<p>A test case generator should, finally, be fast. The faster we can generate test
cases, the faster we will discover bugs. If the generator is too slow, we can
blow our time budget, failing to find those bugs at all.</p>

<h2 id="getting-set-up">Getting Set Up</h2>

<p>First, we create a new crate with <code>cargo</code>. We’ll name this crate <code>wasm-smith</code>,
giving a little nod to <a href="https://embed.cs.utah.edu/csmith/">Csmith</a>, the popular C program generator.</p>

<figure><pre><code data-lang="shell"><span>$ </span>cargo new <span>--lib</span> wasm-smith</code></pre></figure>

<p>Second, we add <a href="https://github.com/rust-fuzz/arbitrary">the <code>arbitrary</code> crate</a> as a dependency:</p>

<figure><pre><code data-lang="toml"><span># wasm-smith/Cargo.toml</span>

<span>[dependencies]</span>
<span>arbitrary</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.4.6"</span><span>,</span> <span>features</span> <span>=</span> <span>["derive"]</span> <span>}</span></code></pre></figure>

<p>The <code>arbitrary</code> crate helps us generate structured data from arbitrary bytes. It
is typically used in combination with <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> to translate the raw bytes
given to use by libFuzzer into something that the system you’re testing can
process. For example, a color conversion library might use <code>arbitrary</code> to turn
the raw fuzzer-provided bytes into <code>Rgb</code> or <code>Hsl</code> color types. We will use it in
a similar way for this project, translating raw bytes given to us by libFuzzer
into semantically valid WebAssembly modules.</p>

<p>The <code>arbitrary</code> crate’s main export is <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/trait.Arbitrary.html">the <code>Arbitrary</code> trait</a>:</p>

<figure><pre><code data-lang="rust"><span>pub</span> <span>trait</span> <span>Arbitrary</span><span>:</span> <span>Sized</span> <span>+</span> <span>'static</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>;</span>

    <span>// Provided methods hidden...</span>
<span>}</span></code></pre></figure>

<p>It takes an <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/struct.Unstructured.html"><code>Unstructured</code></a>, which is a helpful wrapper around a byte slice, and
returns an instance of the type for which it is implemented.</p>

<p>For our <code>wasm-smith</code> crate, we define a <code>Module</code> type that represents our
pseudo-random WebAssembly modules, and then we implement the <code>Arbitrary</code> trait
for it:</p>

<figure><pre><code data-lang="rust"><span>use</span> <span>arbitrary</span><span>::{</span><span>Arbitrary</span><span>,</span> <span>Result</span><span>,</span> <span>Unstructured</span><span>};</span>

<span>/// A pseudo-random WebAssembly module.</span>
<span>pub</span> <span>struct</span> <span>Module</span> <span>{</span>
    <span>// ...</span>
<span>}</span>

<span>impl</span> <span>Arbitrary</span> <span>for</span> <span>Module</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>todo!</span><span>()</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Before we fill in that <code>todo!()</code> lets take a moment to settle on a design for
what the implementation will look like.</p>

<h2 id="translating-grammars-into-generators">Translating Grammars into Generators</h2>

<p>Writing a generator is remarkably similar to hand-writing a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent
parser</a>, so if you’ve done that before, then you should feel right at home. For
example, given this grammar production (borrowed and lightly edited from <a href="https://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangling">the
C++ name mangling</a> grammar):</p>

<pre><code>&lt;class-enum-type&gt; ::= Ts &lt;name&gt;
                    | Tu &lt;name&gt;
                    | Te &lt;name&gt;
</code></pre>

<p>A recursive descent parser will, almost mechanically, translate the production
into something like this:</p>

<figure><pre><code data-lang="rust"><span>impl</span> <span>Parse</span> <span>for</span> <span>ClassEnumType</span> <span>{</span>
    <span>fn</span> <span>parse</span><span>(</span><span>p</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Parser</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Ts"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Ts"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Ts</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Tu &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Tu"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Tu"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Tu</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Te &lt;name&gt;</span>
        <span>p</span><span>.consume</span><span>(</span><span>"Te"</span><span>)</span><span>?</span><span>;</span>
        <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
        <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Te</span><span>(</span><span>name</span><span>))</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Our generator will do something similar, except instead of peeking at the input
string to decide which right-hand side of the production to parse, we will make
a pseudo-random choice to generate one of those potential right hand sides.</p>

<p>We could use a random number generator directly to make these choices, but this
has two problems:</p>

<ol>
  <li>
    <p>We give up determinism unless we are careful to control the RNG’s seed and
reuse the same RNG everywhere, threading it through all of our functions as a
parameter. Determinism is extremely important for reproducing test failures!
It’s definitely possible to do these things, but can occasionally be a little
annoying.</p>
  </li>
  <li>
    <p>More importantly, using an RNG precludes a mature fuzzing engine, like
libFuzzer, from guiding our test case generation based on code coverage and
other insights.</p>
  </li>
</ol>

<p>Instead, we use a raw input byte slice given to us by libFuzzer or AFL as a
sequence of predetermined choices.<sup id="back-dont-require-libfuzzer"><a href="#foot-dont-require-libfuzzer">0</a></sup> This <a href="https://arxiv.org/pdf/1812.00078v1.pdf">lets the fuzzer guide our
test case generation</a>, and <a href="https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf">gives us test case reduction “for
free”</a> since we can ask the fuzzer to reduce the raw input
sequence, rather than write a domain-specific test case reducer. This comes as a
relief because writing a reducer that understands WebAssembly is easily as much
effort as writing the generator itself.</p>

<p>Here is the same C++ mangling example from above, but translated from a parser
into a generator, using <code>Unstructured</code>:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_class_enum_type</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>output</span><span>:</span> <span>&amp;</span><span>mut</span> <span>String</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
    <span>match</span> <span>u</span><span>.int_in_range</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>(</span><span>0</span><span>..=</span><span>2</span><span>)</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>0</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Ts"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Tu &lt;name&gt;</span>
        <span>1</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Tu"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Te &lt;name&gt;</span>
        <span>2</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Te"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>_</span> <span>=&gt;</span> <span>unreachable!</span><span>(),</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Once again, this is mostly mechanical.</p>

<p>This pattern will generate <em>syntactically</em> correct test cases that can be parsed
successfully but which likely contain a plethora of type errors, calls to
undefined functions, etc. We’ve set out to generate <em>semantically</em> correct test
cases that pass type checking and will exercise more than just the language
implementation’s frontend.</p>

<p>Our final pattern maintains some extra information about the program we’ve
generated thus far, so that we can consult that information when generating new
forms. This extra information might include which names are in scope, the types
of each variable, etc. We consult that information while dynamically building up
thunks for every valid option we could generate. Once we have enumerated every
option, we ask the <code>Unstructured</code> to choose one of them, and finally we call the
chosen thunk to generate the form.</p>

<p>Here is an example of using this pattern for generating integer expressions,
where an integer expression is either a constant integer, an arithmetic
operation, a use of an integer variable, or a call of a function that returns an
integer:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_int_expr</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>scope</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
    <span>// We will dynamically build up all of the valid</span>
    <span>// options of what we can generate.</span>
    <span>let</span> <span>mut</span> <span>options</span><span>:</span> <span>Vec</span><span>&lt;</span><span>fn</span> <span>(</span>
        <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
        <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
    <span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;&gt;</span> <span>=</span> <span>vec!</span><span>[];</span>

    <span>// It is always valid to generate a constant.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>_</span><span>|</span> <span>{</span>
        <span>Ok</span><span>(</span><span>Expr</span><span>::</span><span>Constant</span><span>(</span><span>u</span><span>.arbitrary</span><span>::</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>()</span><span>?</span><span>))</span>
    <span>});</span>

    <span>// It is always valid to generate an addition.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>scope</span><span>|</span> <span>{</span>
        <span>let</span> <span>lhs</span> <span>=</span> <span>arbitrary_int_expr</span><span>(</span><span>u</span><span>,</span> …</code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</a></em></p>]]>
            </description>
            <link>http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263117</guid>
            <pubDate>Mon, 24 Aug 2020 17:36:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24262336">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262336</guid>
            <pubDate>Mon, 24 Aug 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I helped fix Canadaʼs Covid Alert app]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24262236">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app | <a href="https://web.archive.org/web/*/https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="https://pm.gc.ca/en/news/news-releases/2020/07/31/new-mobile-app-help-notify-canadians-potential-covid-19-exposure-now">On July 31st</a>, Canada's <a href="https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covid-alert.html">COVID Alert</a> app was made available for general use, though it does not have support for actually <em>reporting</em> a diagnosis in most provinces, yet.</p>
<p>In Quebec, we can run the tracing part of the app, and if diagnosis codes become available here, the app can retroactively report contact. It uses the tracing mechanism that <a href="https://covid19.apple.com/contacttracing">Google and Apple created together</a>, and in my opinion—at least for now—Canadians should be running this thing to help us all deal with COVID-19. I won't run it forever, but for now, it seems to me that the benefits outweigh the "government can track me" fear (it's not actually tracking you; it doesn't even know who you are), and it's enabled on my phone.</p>
<p>But, before I decided to take this position and offer up my own movement data, I wanted to be sure the app is doing what it says it's doing—at least to the extent of my abilities to be duly diligent. (Note: it's not purely <em>movement</em> data that's shared—at least without more context—but it's actual physical interactions with other people whose phones are available within the radio range of Bluetooth LE.)</p>
<p>Before installing the app on my real daily-carry phone, I decided to put it on an old phone I still have, and to do some analysis on the most basic level of communication: who is it contacting?</p>
<p>In 2015, I gave a <a href="https://prezi.com/iqwzy66rn3uo/inspect-https-with-your-own-man-in-the-middle-non-attacks/">talk</a> at <a href="https://confoo.ca/en">ConFoo</a> entitled "<em>Inspect HTTP(S) with Your Own Man-in-the-Middle Non-Attacks</em>", and this is exactly what I wanted to do here. The tooling has improved in the past 5 years, and firing up <em>mitmproxy</em>, even without ever having used it on this relatively new laptop, was a one-liner, thanks to <a href="https://nixos.org/learn.html">Nix</a>:</p>
<pre><span>nix-shell -p mitmproxy --run mitmproxy</span>
</pre>

<p>This gave me a terminal-based UI and proxy server that I pointed my old phone at (via the Wifi Network settings, under HTTP proxy, pointed to my laptop's local IP address). I needed to have mitmproxy create a Certificate Authority that it could use to generate and sign "trusted" certificates, and then have my phone trust that authority, by visiting <code>http://mitm.it/</code> in mobile Safari, and doing the certificate acceptance dance (this is even more complicated on the latest versions of iOS). Worth noting also, is that certain endpoints such as the Apple App Store appear to use <a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">Certificate Pinning</a>, so you'll want to do things like install the COVID Alert app from the App Store before turning on the proxy.</p>
<p>Once I was all set up to intercept my own traffic, I visited some <code>https://</code> URLs and saw the request flows in mitmproxy.</p>
<p>I fired up the COVID Alert app again, and noticed something strange… something disturbing:</p>
<p><img src="https://files.scoat.es/covid-tracker-traffic.png" title="COVID Alert app traffic in mitmproxy" alt="shows that the app is accessing clients.google.com"></p>
<p>In addition to the expected traffic to <code>canada.ca</code> (I noticed it's using <code>.alpha.canada.ca</code>, but I suspect that's due to the often-reported unbearably-long bureaucratic hassle in getting a <code>.canada.ca</code> TLS certificate, but that's another story), my phone, when running COVID Alert, was contacting Google.</p>
<pre><span>HEAD https://clients4.google.com/generate_204</span>
</pre>

<p>A little web searching helped me discover that this is a commonly-used endpoint that helps developers determine if the device is behind a "captive portal" (an interaction that requires log-in or payment, or at least acceptance of terms before granting wider access to the Web). I decided that this was <em>probably</em> unintended by the developers of COVID Alert, but it still bothered me that an app, designed for <em>tracking interactions between people['s devices]</em>, that the <em>government</em> wants us to run is telling Google that I'm running it, and disclosing my IP address in doing so:</p>
<p><img src="https://files.scoat.es/covid-alert-google.png" title="A request to clients.google.com, from the COVID Alert app" alt="shows that the User Agent header identifies the app as " covid="" alert="" version=""></p>
<p>(Note that the app clearly identifies itself in the <code>User-Agent</code> header.) </p>
<p>A bit more quick research turned up a <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/pipeda-compliance-help/pipeda-interpretation-bulletins/interpretations_02/#fn50-rf">statement by Canada's Privacy Commissioner</a>:</p>
<blockquote><p>An Internet Protocol (IP) address can be considered personal information if it can be associated with an identifiable individual. For example, in one complaint finding, we determined that some of the IP addresses that an internet service provider (ISP) was collecting were personal information because the ISP had the ability to link the IP addresses to its customers through their subscriber IDs.</p></blockquote>

<p>It's not too difficult to imagine that Google <em>probably</em> has enough data on Canadians for this to be a real problem.</p>
<p>I discovered that this app is maintained by the <a href="https://digital.canada.ca/">Canadian Digital Service</a>, and that the <a href="https://github.com/cds-snc/covid-alert-app">source code is on GitHub</a>, but that the <a href="https://github.com/cds-snc/covid-alert-app/search?q=clients3.google.com&amp;unscoped_q=clients3.google.com&amp;type=Code">code itself didn't directly contain any references to <code>clients3.google.com</code></a>.</p>
<p>It's a <a href="https://reactnative.dev/">React Native</a> app, and I figured that the call out to Google must be in one of the <a href="https://github.com/cds-snc/covid-alert-app/blob/master/package.json">dependencies</a>, which—considering the norm with JavaScript apps—are pleasantly restrained mostly to React itself. I had no idea which of these libraries was calling out to Google.</p>
<p>Now, I could have run this app on the iOS Simulator (which did I end up doing to test my patches, below), but I thought "let's see what my <em>actual</em> phone is doing." I threw caution to the wind, and I ran <a href="https://checkra.in/">checkra1n</a> on my <em>old</em> phone, which gave me ssh access, which in turn allowed me to copy the app's application bundle to my laptop, where I could do a little more analysis (note the app is bundled as <em>CovidShield</em> because it was previously <a href="https://www.covidshield.app/">developed by volunteers at Shopify</a> and was then renamed by CDS (or so I gather, anyway)).</p>
<pre><span>~/De/C/iphone/CovidShield.app ▶ grep -r 'clients3.google.com' *</span>
<span>main.jsbundle:__d(function(g,r,i,a,m,e,d){Object.defineProperty(e,"__esModule",{value:!0}),</span>
<span>e.default=void 0;var t={reachabilityUrl:'https://clients3.google.com/generate_204',</span>
<span>reachabilityTest:function(t){return Promise.resolve(204===t.status)},reachabilityShortTimeout:5e3,</span>
<span>reachabilityLongTimeout:6e4,reachabilityRequestTimeout:15e3};e.default=t},708,[]);</span>
</pre>

<p>(Line breaks added for legibility.) Note <code>reachabilityUrl:'https://clients3.google.com/generate_204</code>. Found it! A bit more searching led me to a package called <code>react-native-netinfo</code> (which was directly in the above-linked <code>package.json</code>), and its <a href="https://github.com/react-native-community/react-native-netinfo/blob/4e3e9813fbae89013bbeee6470b005b6d923e022/src/internal/defaultConfiguration.ts#L2">default configuration</a> that sets the <code>reachabilityUrl</code> to Google.</p>
<p>Now that I knew where it was happening, I could fix it.</p>
<p>To make this work the same way, we needed a reliable <code>204</code> endpoint that the app could hit, and to keep with the expectation that this app should not "leak" data outside of <code>canada.ca</code>, I ended up <a href="https://github.com/cds-snc/covid-alert-server/pull/241">submitting a patch</a> for the <a href="https://github.com/cds-snc/covid-alert-server">server side code</a> that the app calls. (It turns out that this was not necessary after all, but I'm still glad I added this to my report.)</p>
<p>I also <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">patched</a>, and tested the app code itself via the iOS Simulator.</p>
<p>I then submitted a write-up of what was going wrong and why it's bad, to the main app repository, as <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">cds-snc/covid-alert-app issue 1003</a>, and felt pretty good about my COVID Civic Duty of the day.</p>
<p>The fine folks at the Canadian Digital Service seemed to recognize the problem and agree that it was something that needed to be addressed. A few very professional back-and-forths later (I'll be honest: I barely knew anything about the CDS and I expected some runaround from a government agency like this, and I was pleasantly surprised), we landed on a solution that simply didn't call the reachability URL at all, and they <a href="https://github.com/cds-snc/covid-alert-app/releases">released a version of the app</a> that fixed my issue!</p>
<p><img src="https://files.scoat.es/covid-alert-release.jpg" title="COVID Alert release notes showing my fix" alt=""></p>
<p>With the new version loaded, I once again checked the traffic and can confirm that the new version of the app does not reach out to anywhere but <code>.canada.ca</code>.</p>
<p><img src="https://files.scoat.es/covid-alert-no-google.png" alt="A mitmproxy flow showing traffic to canada.ca and not google.com"></p>
</div>
    </div></div>]]>
            </description>
            <link>https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262236</guid>
            <pubDate>Mon, 24 Aug 2020 16:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 2: Shannon's story]]>
            </title>
            <description>
<![CDATA[
Score 384 | Comments 271 (<a href="https://news.ycombinator.com/item?id=24261948">thread link</a>) | @usefulcat
<br/>
August 24, 2020 | https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-clbfl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_900,h_450,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-7adfi">How much Vitamin D should I take? This is still the looming question, and it’s time to address it. </h3><p id="viewer-9k73p">First, though, imagine that someone in a public forum online asked me, “How much metoprolol (a common blood pressure medication) should I take?” It would be clear that I could not give a real answer. I could give a heavily qualified blanket statement that covered indications and common starting doses, and then recommended speaking with a doctor regarding a personalized dosage. I wouldn’t give a specific dose. But no one would expect me to.  Metoprolol is a medication, and medications are usually prescribed by a physician.</p><p id="viewer-7tpp4">We think of vitamins and supplements differently. A few readers have made comments like this: “I understand that the evidence for Vitamin D in healthy adults doesn’t really show a benefit, but I take Vitamin D because it probably won’t hurt me, and it might help.” This is a common sentiment regarding supplements, but not a statement that most people would make about metoprolol, or any prescribed medication.  Medications are generally understood to be substances taken in response to a specific disease or condition, and we hope that research has shown that they work. Supplements are given a pass; we take them if they might help, even though they may not be needed. </p><p id="viewer-2fbtq"><strong>But Vitamin D should be thought of as a medication</strong>, despite being sold over-the-counter in the supplements aisle. </p><p id="viewer-5549c">To illustrate this, let me introduce Shannon. </p><p id="viewer-518ch">In the fall of 2018, Shannon R. was the special education director for a large Arizona school district. Normally energetic and expressive, the otherwise healthy 38-year-old began having an odd and disturbing symptom: difficulty speaking. Her husband and two boys would ask her questions, and though understanding the question, she was unable to formulate the words to respond. </p><p id="viewer-e7f4v">Milder problems had started over the summer, when she felt more tired than usual. As the months passed, new symptoms appeared: palpitations, insomnia, anxiety, along with cognitive deficits – “like my brain wouldn’t function,” she recalled. Her heart rate, normally in the 60s, now often stayed in the 90s, even while in bed. She barely slept at night and lost nearly 50 pounds. By mid-semester, she was often unable to work. At around 1 AM one October morning, she was taken to the emergency room for a racing heart. When there, she had difficulty responding to the doctors’ and nurses’ questions. After a full workup, the doctors had no explanation, so they resorted to what doctors often reach for when confronted with mystery ailments: psychiatric illness. </p><p id="viewer-fu7id">Shannon would be hospitalized several times for “catatonia,” a general symptom describing difficulty with speaking or moving that is caused by certain psychiatric conditions like depression and schizophrenia. Though she had never exhibited mental illness before, doctors assumed that Shannon had developed a severe psychiatric disorder. </p><p id="viewer-4pb27">Shannon’s husband, as well as her new psychiatrist, doubted this diagnosis, and sought second and third opinions. By the time she contacted me four months later, they had consulted multiple specialists at three different hospitals around the state, but still did not have an explanation for her physical and mental decline. There was something that all of the doctors had noticed, though. Her blood calcium levels were often mildly to moderately elevated above normal, up to 11.1 mg/dl (normal for her age would be up to 10.2 mg/dl). The cause of this was unclear, but her doctors did not believe that this incidental finding was relevant to her current issues, and did not pursue it. <strong>Shannon was not taking calcium supplements at all throughout this time, but her levels were still high.</strong> When she emailed me in February 2019, she was desperate for answers and thought the calcium levels might be a clue. </p><p id="viewer-1miap">My specialty is parathyroid disease, which is the most common cause of high calcium. Based on her parathyroid hormone tests, it did not appear that Shannon had parathyroid disease. But she had high calcium levels, and the rise in those levels correlated with the onset of her symptoms. High calcium levels might initially appear to be a good thing, since we need calcium for our bones. But they are not. High blood calcium levels usually indicate a serious illness.</p><div id="viewer-ep36c"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_900,h_434,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-5d4om"><em>Calcium is known for its role in bone health, but its role in the brain and nervous system is just as important. Calcium levels need to be within a small range; anything too high or too low can cause problems.  Image by </em><a href="https://www.bigstockphoto.com/search/?contributor=madrock24" target="_blank" rel="noopener">madrock24</a> on <a href="http://bigstockphoto.com/" target="_blank" rel="noopener"><u>bigstockphoto.com</u></a></p><p id="viewer-115r5">Most patients with high calcium develop fatigue and body aches, and just generally feel bad. They may develop insomnia and palpitations, a feeling like the heart is racing. Some have more severe neurologic symptoms like muscle weakness and problems with balance, and some have psychiatric symptoms like depression and anxiety. Untreated high calcium can also lead to kidney stones, kidney failure, cardiac arrhythmias, headaches, and gastrointestinal problems. Shannon had some of the classic symptoms, as well as what appeared to be more severe “psychiatric” symptoms. I suspected they were all related to her calcium levels. </p><p id="viewer-bac7q">But why was her calcium high? The parathyroid glands exist to regulate calcium, and they do a very good job at it, keeping blood calcium within a tight range. Usually, a problem with calcium indicates a problem with the parathyroids. But over the last few years I have had more patients coming to me with high calcium related to something else: Vitamin D. </p><p id="viewer-6d1js"><strong>Vitamin D is a steroid hormone</strong>, in the same category as sex hormones like estrogen and testosterone, and glucocorticoids like the stress hormone cortisol. Steroid hormones are all made from cholesterol, and looking at their molecular structures, you can see the similarities. </p><div id="viewer-6s0p9"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_1586,h_972,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-3upia">Like the other steroid hormones, Vitamin D acts on multiple organs and only tiny amounts of the molecule are required to have substantial effects. Anyone who has gone through puberty understands the impressive physiologic changes brought about by relatively small shifts in hormone levels. Not surprisingly, most steroid hormones are considered medications that require a physician's order. Vitamin D is an exception. In the U.S., high dose Vitamin D can be purchased by anyone, without a prescription, in most drugstores and grocery stores. It is called a dietary supplement, which sounds safer than a medication, but this is misleading. Due to its role in calcium absorption, high dose Vitamin D can cause serious problems. </p><p id="viewer-21t00">Eventually we worked out what happened with Shannon: In 2013 she was diagnosed with mild osteopenia, a thinning of the bones that can be a precursor to osteoporosis. Her Vitamin D was low at the time, so her physician started her on over-the-counter Vitamin D supplementation at 5000 international units (IUs) daily. Five years later, she was still on this dose, and her blood Vitamin D level had risen to 79 ng/ml. This level is within what many labs call the normal range, between 30 and 100 ng/ml, but levels above 70 are almost always a result of high dose supplementation, and I have seen toxicity with levels between 70 and 100 ng/ml. (A better “normal range” based on what I have seen would probably be between 30 and 60.) Vitamin D builds up over time, so the longer someone is on a high dose, the more likely she is to develop toxicity. Shannon’s calcium levels began rising in the fall of 2018, when her severe symptoms developed. </p><p id="viewer-c0tav">Ironically, Shannon started to recover because she became too sick to worry about taking her vitamins, and stopped taking Vitamin D in October. It often takes many months for high Vitamin D levels to drop, and it took six months for Shannon’s level to fall into the 50s. As it fell, her calcium level gradually started to normalize, and her symptoms slowly resolved. By May, she was starting to feel like herself again. </p><p id="viewer-208hf">I spoke with Shannon recently. All of the symptoms that characterized her frightening and rapid decline in health had resolved completely. Listening to this animated woman, it was difficult to imagine her unable to talk. The only lingering effects appeared to be a wariness of physicians and distrust of vitamins, both understandable. Shannon agrees that Vitamin D should be treated like a medication. “It’s a hormone!” she exclaimed. “If I had to take ‘Hormone D’, I would have questioned my doctor about why I needed it.” Shannon is now committed to educating others about Vitamin D. </p><p id="viewer-16oc8">Of course, there is a selection bias in who comes to me. There are people out there doing just fine on 5000 units of Vitamin D daily. I only see the ones who develop high calcium levels. But I see enough of them to know that this is not an exceptionally rare occurrence. I have been to lectures in which physicians have claimed that Vitamin D toxicity almost never occurs. In my experience, this is false. I have seen many cases of Vitamin D toxicity in people who were taking the recommended dose from an over-the-counter bottle.</p><p id="viewer-8pgar">Unfortunately, none of those patients were warned about the potential for Vitamin D to cause high calcium. They all believed that they were taking a supplement to improve health and that there was very little risk. Supplements don’t require prescriptions, and most do not have the warning labels that accompany medications. For Vitamin D, a steroid hormone, that may need to change. </p><p id="viewer-4ie1g"><strong>So, how much Vitamin D should you take? </strong></p><p id="viewer-9iecb">Vitamin D should be approached like a medication that is used to treat low calcium levels and low levels of the hormone called Vitamin D. The dose depends on your calcium and current Vitamin D levels, and needs to be adjusted appropriately in response to those levels. For my patients, I can and do give very specific recommendations on Vitamin D doses. In future posts, I can go through how I decide that. I will not give any recommendation without first knowing Vitamin D and calcium levels. </p><p id="viewer-ecd8g"><strong>Edited to add: This post should not be taken as a …</strong></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261948</guid>
            <pubDate>Mon, 24 Aug 2020 16:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Mechanist's Guide to the Coronavirus Genome]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261853">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome | <a href="https://web.archive.org/web/*/https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to my Coronavirus Genome Walkthrough.</p>

<p>(Hoping someone comes out with that Vaccine Speedrun soon. This boss battle is really shaping up to be an intense one and we’ll need all the artifacts we can get.)</p>

<p>Here, I aim to provide a <em>mechanistic explanation</em> of the SARS-CoV-2 genome’s syntax and semantics. Let’s investigate what the SARS-CoV-2 viral genome actually does as if reading through code like a compiler, from nucleotides to amino acids all the way to proteins. From the four base pairs all the way up to the completed protein-coated virus, what is a virus like this is actually made of on the concrete, physical level?</p>

<h3 id="understanding-a-full-system">Understanding a Full System</h3>

<p>The underlying purpose of this essay is less about the coronavirus <em>per se</em> and more about how having a small—but functionally complete—piece of viral RNA to analyze gives me a unique opportunity to try to understand a complete self-replicating machine from scratch. This is not a feat that I would have the fortitude to manually replicate with the full human genome, for example—but the coronavirus genome, like the <a href="http://openworm.org/">nematode genome</a>, is small enough that we stand a chance at building a complete understanding. The task is perhaps akin to <a href="https://distill.pub/2018/building-blocks/">interpretability</a>, but for biological systems instead of artificial neural networks.</p>

<p>As a consequence, this essay is not intended to produce epidemiological conclusions; there are plenty of other sources for that! This essay is about fully understanding a biological system at the chemical and physical level.</p>

<h3 id="play-curiosity-and-mechanical-understanding">Play, Curiosity, and Mechanical Understanding</h3>

<p>Throughout this essay, I follow my curiosity in the style of <a href="https://en.wikipedia.org/wiki/Serious_play">serious play</a>: if I <a href="https://www.readthesequences.com/Noticing-Confusion-Sequence">notice I’m confused</a> about something, I look into it and explore it until I’m satisfied that I now understand, and that my understanding is <em>a <a href="https://plato.stanford.edu/entries/science-mechanisms/#ConMec">mechanical</a> understanding</em>. Things are made of stuff! It turns out that we can understand that stuff!</p>

<p>I may skip over some details that were not confusing to me during my own research, but your journey need not be the same as mine. If you’re confused about something while reading this essay, I encourage you to go and look it up! <a href="http://agentyduck.blogspot.com/2015/06/the-art-of-noticing.html">Notice</a> when your curiosity arises; that’s the meditation. It’s always possible to discover the <a href="http://samoburja.com/how-to-find-the-frontier-of-knowledge/">frontier of your own knowledge</a> and to expand it.</p>

<p>This all, at least, has been my intention as I set out to create this piece! As Ken Liu said of his philosophy while translating The Three-Body Problem, “I may not have succeeded, but these were the standards I had in mind as I set about my task.”</p>

<p>Part 1, here, covers just the genome and its translation to proteins. I hope to also write a Part 2 which would cover the structure and function of those proteins, their protein-protein interactions, and the full viral life cycle.</p>

<!--Finally, as you may already be able to tell, this essay also serves as a philosophical manifesto-by-example of how to think concretely about problems in biology. Along the way, I give some of my thoughts about the role of thermodynamics in molecular biology, legibility in complex systems, pedagogy, and the future of computational modeling.-->

<p>Let’s get started.</p>



<p>As a reminder, SARS-CoV-2 is a <em>positive-sense single-stranded RNA virus</em>.</p>



<p>What does this mean we can expect?</p>

<ol>
  <li><em>Single-stranded</em>: Its genome is a single strand of <a href="https://en.wikipedia.org/wiki/RNA">RNA</a> (ssRNA).</li>
  <li><em>Positive-sense</em>: That single strand of RNA can be immediately translated into protein by the ribosomes of the cell it infects.</li>
</ol>

<p>From this we can also infer that one of the proteins the virus encodes for must be <em>RNA-dependent RNA polymerase</em> (RdRP), a protein which synthesizes new RNA given an RNA template. That’s right: RNA → RNA. However, according to the <a href="https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology">central dogma of molecular biology</a>, isn’t RNA → RNA an unconscionable heresy? Correspondingly, RdRP is not naturally found in cells! All known positive-sense ssRNA viruses therefore <em>must encode</em> RdRP in order to successfully commit this heresy.</p>



<p>…Wait a minute, the phrase “positive-sense ssRNA virus” implies the existence of <em>negative-sense</em> viruses. If those don’t encode their proteins directly, how can they possibly work?</p>

<h2 id="positive-sense-and-negative-sense">Positive sense and negative sense</h2>

<p>Negative-sense ssRNA viruses also exist! Influenza, Ebola, and measles are examples.</p>



<p>The inner contents of <em>negative-sense</em> ssRNA viruses consist not of an RNA genome but of a <em>ribonucleoprotein</em>, which incorporates both an RNA genome as well as a cohort of viral proteins capable of replicating RNA. Unlike positive-sense ssRNA viruses, negative-sense ssRNA viruses must travel with a working copy of their RNA-replicating proteins. This ribonucleoprotein has enzymatic activity!</p>

<h2 id="rdrp-as-drug-target">RdRP as drug target</h2>

<p>Since RdRP has (as far as I know) no legitimate purpose in human cells and is not naturally coded by them, might it offer a potential target for novel antiviral drugs?</p>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">Velkov et al. 2014</a> explores RdRP as a drug target for antivirals against the <a href="https://en.wikipedia.org/wiki/Henipavirus">Hendra virus</a>, a negative-sense ssRNA virus, though I am unable to find the full text.</p>

<!-- <div class="unfurl-embed-info-media-default gallery-item-selectable"><img class="unfurl-embed-card-feature-image" src="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image.png"><div class="unfurl-embed-card-title unfurl-embed-card-title-default notranslate"><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">The RNA-dependent-RNA Polymerase, an Emerging Antiviral Drug Target for the Hendra Virus - PubMed</a></div><div class="unfurl-embed-card-description unfurl-embed-card-description-default notranslate"><div style="overflow: hidden; text-overflow: ellipsis; -webkit-box-orient: vertical; display: -webkit-box; -webkit-line-clamp: 2;">Australia is facing a major national medical challenge with the emergence of the Hendra virus (HeV) as a medically and economically important pathogen of humans and animals. Clinical symptoms of human HeV infection can include fever, hypotension, dizziness, encephalitis, respiratory haemorrhage and …</div></div><div class="unfurl-embed-card-url notranslate">pubmed.ncbi.nlm.nih.gov</div></div> -->

<blockquote>
  <p>This review examines the current knowledge based on the multi-domain architecture of the Hendra RdRP and highlights which essential domain functions represent tangible targets for drug development against this deadly disease.</p>
</blockquote>

<p>There must be some reason that developing antivirals against this protein is technically (or socially) complicated, or I’d have expected us to do it by now – there are a lot of RNA viruses that this drug target could theoretically hit. Flagging this discrepancy for further research.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">1</a></sup></p>



<p>Back to SARS-CoV-2! First, let’s get us a genome. Obviously this virus has seen some mutations as it’s spread around, as you can explore at <a href="https://nextstrain.org/ncov/global">NextStrain</a>, so we’ve technically got choices as to which one to analyze. For this thread I’ll just stick to analyzing <em>one</em> version of the genome: Wuhan-Hu-1.</p>

<p>As a reminder, each <code>A</code>, <code>G</code>, <code>C</code>, and <code>T</code> in a genome is one of the four <a href="https://en.wikipedia.org/wiki/Nucleotide">nucleotides</a>: <a href="https://en.wikipedia.org/wiki/Adenine">adenine</a>, <a href="https://en.wikipedia.org/wiki/Guanine">guanine</a>, <a href="https://en.wikipedia.org/wiki/Cytosine">cytosine</a>, and <a href="https://en.wikipedia.org/wiki/Thymine">thymine</a>. There are actually <a href="https://www.scripps.edu/romesberg/publications.html">plenty of ways to engineer</a> different <a href="https://pubmed.ncbi.nlm.nih.gov/22850726/">unnatural base pair systems</a> by adding <a href="https://science.sciencemag.org/content/363/6429/884">artificial nucleotides</a>, and these can even be integrated into <a href="https://www.pnas.org/content/98/9/4922">transcription</a> and <a href="https://www.nature.com/articles/nature24659">translation</a>, but <a href="https://carlbrannen.wordpress.com/2007/06/13/why-does-dna-only-use-4-nucleotides/">for</a> <a href="https://dreamerbiologist.wordpress.com/2013/02/16/why-did-nature-settle-on-just-four-nucleotides/">whatever</a> <a href="https://www.pnas.org/content/114/32/E6476">reason</a>, these four <a href="https://www.nature.com/articles/s41467-018-07389-2">and not others</a> are <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3331698/">what life ultimately ended up with</a>.</p>

<p><img src="https://csvoss.com/images/nucleotides.png"></p>
<p><small>The four nucleotides in DNA.</small></p>

<p>The genome of Wuhan-Hu-1 is available from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>. Since SARS-CoV-2 is an RNA virus, each <code>T</code> in this string technically represents a <code>U</code>, for <a href="https://en.wikipedia.org/wiki/Uracil">uracil</a>, RNA’s information-equivalent of thymine. The genome sequence is therefore:</p>

<div><div><pre><code>1     AUUAAAGGUU UAUACCUUCC CAGGUAACAA ACCAACCAAC UUUCGAUCUC UUGUAGAUCU
61    GUUCUCUAAA CGAACUUUAA AAUCUGUGUG GCUGUCACUC GGCUGCAUGC UUAGUGCACU
121   CACGCAGUAU AAUUAAUAAC UAAUUACUGU CGUUGACAGG ACACGAGUAA CUCGUCUAUC

...

29761 ACAGUGAACA AUGCUAGGGA GAGCUGCCUA UAUGGAAGAG CCCUAAUGUG UAAAAUUAAU
29821 UUUAGUAGUG CUAUCCCCAU GUGAUUUUAA UAGCUUCUUA GGAGAAUGAC AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>

<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>That’s 29,903 nucleotides. Since there are only four possible nucleotides, we can estimate the information compression value of each nucleotide at approximately 2 bits; the virus’s genome therefore requires only 7.5 kilobytes to store. That’s roughly as much data, byte for byte, as there are characters in this essay up to this point!</p>

<!-- <img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/110/2016/05/02212445/Figure_03_05_03.png"> -->

<p>Lay out those 29,903 nucleobases along a ribose-phosphate backbone, reading them left to right <a href="https://en.wikipedia.org/wiki/Directionality_(molecular_biology)">from the 5’ end to the 3’ end</a>, and bam – if that single molecule* were teleported into a cell, that’s 100% chemically sufficient** to infect a person with the plague du jour.</p>

<p>*plus the 5’ cap, discussed below</p>

<p>**modulo viral load effects??</p>

<p><img src="https://csvoss.com/images/polynucleotide.png"></p>
<p><small>How to interpret the Wuhan-Hu-1 genome as a complete molecule.</small></p>

<h2 id="poly-a-tail">Poly-A tail</h2>

<p>First question, and perhaps the most obvious one to the naked eye – what’s with all the <code>AAAAA</code> at the end of the viral genome?</p>

<div><div><pre><code>29821 ...                                                ... AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>
<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>It’s… yelling at us? Is it… suffering? Should we <a href="https://reducing-suffering.org/is-there-suffering-in-fundamental-physics/">help</a>?</p>

<p>Simple: It’s a <a href="https://bioinformatics.stackexchange.com/questions/11227/why-does-the-sars-cov2-coronavirus-genome-end-in-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa">3’ poly-A tail</a>! This <a href="https://en.wikipedia.org/wiki/Polyadenylation">long tail of adenosine monomers</a> is extremely common in both our own cells and in RNA viruses.</p>

<p>Our own messenger RNA (mRNA) has a poly-A tail when it’s freshly produced in the nucleus so as to slow its degradation by the cell, allowing it to last long enough to be transcribed into protein. Naturally, if you’re a positive-strand RNA virus, you’re also going to want to last long enough to be transcribed into protein – so, you need the same feature, yourself.</p>

<p>Genome 0.11% explained. So far so good!</p>

<h2 id="5-cap">5’ cap</h2>

<p>While we’re discussing chemical features of mRNA, note that the viral genome presumably must also have a <a href="https://en.wikipedia.org/wiki/Five-prime_cap">5’ cap</a> – an extra <a href="https://en.wikipedia.org/wiki/7-Methylguanosine">7-methylguanosine</a> at the 5’ end of its RNA strand – just like mRNAs do.</p>

<p><img src="https://csvoss.com/images/5primecap.png"></p>
<p><small>A 5' cap, consisting of a 7-methylguanosine as well as methylation of the first two ribose sugars.</small></p>

<p>The cap is not directly shown in the viral genome sequence or mentioned in NCBI GenBank, but it is referenced in multiple papers discussing coronaviral genomes:</p>

<blockquote>
  <p>Since 2003, the outbreak of severe acute respiratory syndrome coronavirus has drawn increased attention and stimulated numerous studies on the molecular virology of coronaviruses. Here, we review the current understanding of the mechanisms adopted by coronaviruses to produce the 5′-cap structure and methylation modification of viral genomic RNAs.</p>
</blockquote>



<blockquote>
  <p>Coronaviruses possess a cap structure at the 5′ ends of viral genomic RNA and subgenomic RNAs, which is generated through consecutive methylations by virally encoded guanine-N7-methyltransferase (N7-MTase) and 2′-O-methyltransferase (2′-O-MTase). The coronaviral N7-MTase is unique for its physical linkage with an exoribonuclease (ExoN) harbored in nonstructural protein 14 (nsp14) of coronaviruses.</p>
</blockquote>



<blockquote>
  <p>Here, we have reconstituted complete SARS-CoV mRNA cap methylation <em>in vitro</em>.</p>
</blockquote>



<p>Like the poly-A tail, the 5’ cap helps the genome to be recognized and translated by ribosomes rather than destroyed by the cell’s immune response.</p>

<p>How does the virus even ensure that it receives a 5’ cap and a poly-A tail, not to mention its outer coat? Hopefully these questions will be resolved by our review of its genes… let’s move on to look at those!</p>



<p>Per the “Features” section of the genome, again from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>, here are the identifiable genes in this genome, in order:</p>

<ol>
  <li><code>Orf1ab</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269089">orf1ab polyprotein</a>)</li>
  <li><code>S</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269090">surface glycoprotein</a>)</li>
  <li><code>Orf3…</code></li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</a></em></p>]]>
            </description>
            <link>https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261853</guid>
            <pubDate>Mon, 24 Aug 2020 15:55:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being OK with not being extraordinary]]>
            </title>
            <description>
<![CDATA[
Score 709 | Comments 333 (<a href="https://news.ycombinator.com/item?id=24261826">thread link</a>) | @tmatthe
<br/>
August 24, 2020 | https://www.tiffanymatthe.com/not-extraordinary | <a href="https://web.archive.org/web/*/https://www.tiffanymatthe.com/not-extraordinary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>23.08.2020</time> — <a href="https://www.tiffanymatthe.com/tags/mindset">Mindset</a> — <span>2<!-- --> min read</span></p><section><img src="https://www.tiffanymatthe.com/static/c239dad4f9476bf8d02961e957aa71cf/a6c62/rock-climbing.jpg"><p>The internet always highlights the first place winners, the billionaires, the award-winning artists, the best-selling authors, the largest philanthropists, the extraordinary. Their stories are ones of success, of inspiration. They show us what is possible, and push us to achieve more.</p><p>But I don't feel inspired when I see extraordinary. I feel disappointed, jealous. My constant exposure to these amazing stories of success has normalized the extraordinary. I started comparing myself to these "normal" extraordinary people, and wondered why I was not them. This disappointment would incite me to take action, but after a few days of hard work, I would just quit. Quitting was easier; it helped me avoid thinking about the extraordinary and the negative dark clouds that I had shrouded it with.</p><p>This mentality was self-defeating. No one starts off as extraordinary, so that meant I quit a lot in the past. Over time, I came to realize two things:</p><ol><li>extraordinary as I perceived it was one-dimensional and unrealistic,</li><li>to improve, extraordinary could not be my end goal.</li></ol><p><strong>We need to redefine extraordinary.</strong> Extraordinary is often defined by the internet as a permanent trait someone has. They seemed to have been born with it, and extraordinary permeates their every pore. </p><p>But real extraordinary is nothing like this. Yes, it's exciting, but it also comes with sacrifices, limitations, and constraints. And it's not permanent. Extraordinary can disappear over time, just like you can achieve it over time.</p><p>Extraordinary also comes in many forms, and its value does not have to be measured in terms of money. You can be a tech giant who built their entire empire from scratch, just as you can be an amazing organizer who rallies entire communities together for a single cause. You can be a top-notch violinist player, or a inspiring storyteller. Extraordinary can be anything. Sometimes, when you realize what extraordinary really entails, you might not even want it. That's okay.</p><p><strong>Extraordinary should not be the end goal.</strong> I like to envision the extraordinary space in society as a small ledge at the top of a cliff. It gives you a beautiful view and a sense of accomplishment, but is also tight and oppressing. The sheer physical constraints means that not everyone will reach it. But that shouldn't stop you from putting a hand on the cliff and lifting yourself towards that ledge.</p><p>Why? Because the ledge is not the only thing that exists. There is a vast amount of space under it, other ledges, crooks, and crannies, that most people forget about. That space is just as valuable.</p><p>For example, someone starting out on Youtube might be disappointed that they don't have millions of subscribers. They don't think they have what it takes, so they quit. But most people don't only look at the channels with millions of subscribers. Smaller ones are as valuable for viewers, and the creators can get just as much value out of creating their original content and connecting with like-minded people.</p><p>So instead of searching for an extraordinary that is distorted and unrealistic, search to climb up to some space beneath the top ledge. You will be less disappointed and jealous, and you will still maintain some velocity in the right direction. Climbing to a higher vantage point can also unlock new forms of extraordinary that you might have never noticed before.</p><p>By consistently climbing and reassessing which direction to take, you might just reach your own extraordinary as a bonus.</p></section></div></div>]]>
            </description>
            <link>https://www.tiffanymatthe.com/not-extraordinary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261826</guid>
            <pubDate>Mon, 24 Aug 2020 15:53:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remains of 17th century bishop support Neolithic emergence of tuberculosis]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24261768">thread link</a>) | @benbreen
<br/>
August 24, 2020 | https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis | <a href="https://web.archive.org/web/*/https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>Bishop Peder Winstrup of Lund, Sweden passed away in the winter of 1679 at the age of 74 and was interred in a crypt at Lund Cathedral. Three centuries later, his astonishingly well-preserved remains provide insights to the origins of tuberculosis.</p>
  

  

  <p>In a recent study published in <em>Genome Biology</em>, researchers from the Max Planck Institute for the Science of Human History, Lund University and the Swedish Natural Historical Museum present analysis of the highest quality ancient Mycobacterium tuberculosis genome to date, suggesting the pathogen is much younger than previously believed.</p>
  
  
<figure data-description="Portrait of Bishop Peder Jensen Winstrup" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Portrait of Bishop Peder Jensen Winstrup
        </p>
        <p>
           © Orf3us / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)
        </p>
    </figcaption>
</figure>


<p>When Anthropologist Caroline Arcini and her colleagues at the Swedish Natural Historical Museum discovered small calcifications in the extremely well preserved lungs of Bishop Peder Winstrup, they knew more investigation was needed. “We suspected these were remnants of a past lung infection,” says Arcini, “and tuberculosis was at the top of our list of candidates. DNA analysis was the best way to prove it.”</p>
<p>Up to one quarter of the world’s population is suspected to have been exposed to bacteria of the <i>Mycobacterium tuberculosis</i> complex, which cause tuberculosis (TB). Bishop Winstrup would have been one of many to fall ill during the onset of the so-called “White Plague” TB pandemic that ravaged post-medieval Europe. Today, TB is among the most prevalent diseases, accounting for the highest worldwide mortality from a bacterial infection.</p>
<p>The global distribution of TB has led to the prevailing assumption that the pathogen evolved early in human history and reached its global distribution via the hallmark Out of Africa human migrations tens of thousands of years ago, but recent work on ancient TB genomes has stirred up controversy over when this host-pathogen relationship began. In 2014, a team led by scientists from the University of Tübingen and Arizona State University reconstructed three ancient TB genomes from pre-contact South America – not only were the ancient strains unexpectedly related to those circulating in present-day seals, but comparison against a large number of human strains suggested that TB emerged within the last 6000 years. Understandably, skepticism surrounded this new estimate since it was based entirely on ancient genomes that are not representative of the TB strains associated with humans today.</p>
<p>“Discovery of the Bishop’s lung calcification gave us the opportunity to revisit the question of tuberculosis emergence with data from an ancient European,” comments Kirsten Bos, group leader for Molecular Paleopathology at the Max Planck Institute for the Science of Human History (MPI-SHH), who co-led the study. “If we could reconstruct a TB genome from Bishop Winstrup, where we know his date of death to the day, it would give a secure and independent calibration for our estimates of how old TB, as we know it, actually is.”</p>
<p><b>The highest quality ancient TB genome to date&nbsp; </b></p>
<p>In a new study published this week in Genome Biology, Susanna Sabin of MPI-SHH and colleagues reconstruct a tuberculosis genome from the calcified nodule discovered in Bishop Winstrup's remains.</p>
<p>“The genome is of incredible quality – preservation on this scale is extremely rare in ancient DNA,” comments Bos.</p>

<figure data-description="Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB
        </p>
        <p>
           © NIAID
        </p>
    </figcaption>
</figure>


<p>Together with a handful of tuberculosis genomes from other work, the researchers revisit the question of the age of the Mycobacterium tuberculosis complex, with the year of the Bishop’s death as a fine-tuned calibration point. Using multiple molecular dating models, all angles indeed point to a relatively young age of the <i>Mycobacterium tuberculosis</i> complex.</p>
<p>“A more recent emergence of the tuberculosis pathogen complex is now supported by genetic evidence from multiple geographic regions and time periods,” comments Sabin, first author of the study. “It’s the strongest evidence available to date for this emergence having been a Neolithic phenomenon.”</p>
<p>This most recent shift in the narrative for when bacteria in the <i>Mycobacterium tuberculosis </i>complex became highly infectious to humans raises further questions about the context of its emergence, as it appears to have coincided with the rise of pastoralism and sedentary lifestyles.</p>
<p>“The Neolithic transition seems to have played an important role for the emergence of a number of human pathogens,” comments Denise Kühnert, group leader for disease transmission research at MPI-SHH who co-led the investigation.&nbsp;</p>
<p>“For TB in particular, stronger evidence could only come from an older genome, though these deeper time periods are unlikely to yield preservation on the scale of what we’ve seen for Bishop Winstrup,” adds Bos.</p>
<p>“Moving forward,” Sabin further comments, “the hope is we will find adequately preserved DNA from time periods close to the emergence of the complex, or perhaps from its ancestor.”</p>
  
</div></div>]]>
            </description>
            <link>https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261768</guid>
            <pubDate>Mon, 24 Aug 2020 15:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making money building Shopify micro-SaaS apps]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24261192">thread link</a>) | @gk1
<br/>
August 24, 2020 | https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Starting your first business can be a daunting task. There’s so many variables involved - which ones to solve for, which ones to figure out?</p><p>Typically as software engineers and product people, building the product and writing code is not where we falter. </p><p>Where we get stuck is with existential questions like:</p><ul role="list"><li>Does anybody want this app?</li><li>How will I get users?</li></ul><p>And from my little experience in entrepreneurship, I find these questions to be more important than actually designing and building the app. Trust me when I say this.</p><p>Since I’ve been answering questions on email and Twitter DMs around these topics already, writing a guide came as the natural next step.</p><h3>Who this guide is for</h3><ul role="list"><li>You are starting your first micro-SaaS business</li><li>You want to earn extra outside your job, or you want to eventually replace your job income with a business</li><li>You can design apps with a baseline level of UX, and you can write code. Or, you have a business partner who can do these</li><li>You have 10+ hours to allocate every week (initially, more is better) and are in it for the long haul (say 3-6 months before you start seeing significant income from the business)</li><li>You want to serve customer’s needs</li></ul><h3>Who this guide is NOT for</h3><ul role="list"><li>You want to become a millionaire quickly</li><li>You are in it for the short term gain but you don’t see building businesses as your long-term path</li><li>You don’t know the A of design or coding, and neither have a business partner who does</li><li>You don’t have the patience to struggle for 3-6 months when the results might be 0, before things suddenly start to work in your favour</li></ul><p>If this guide is for you, read on. I’ve laid out the index of topics covered in the post. </p><p>Depending on the stage of your journey, feel free to skip to the sections that are most relevant to you.<br></p><h3><strong>Topics covered in this post</strong></h3><ol role="list"><li>Make money building Shopify apps</li><li>Discover problems, niches, and Shopify app ideas</li><li>Standing out from competition</li><li>Shopify App Store optimisation basics</li><li>Find your #1 keyword</li><li>How to build a Shopify app</li><li>Getting customers to review your Shopify app (by delivering great customer support)</li><li>Getting the first customers for your Shopify app</li><li>Finding early users and beta testers for your Shopify app outside the App Store</li><li>Getting listed under the right categories &amp; collections, and getting featured on the Shopify App Store</li><li>The right pricing model for your Shopify app</li><li>Optimising for trials</li><li>Long term game plan in the Shopify App Store</li></ol><p>‍<br></p><h2><strong>Make money building Shopify apps</strong></h2><p>Shopify isn’t the only choice when it comes to picking an apps marketplace. There’s </p><ul role="list"><li><a href="https://slack.com/apps" target="_blank">Slack</a></li><li><a href="https://marketplace.atlassian.com/" target="_blank">Atlassian</a></li><li><a href="https://appexchange.salesforce.com/" target="_blank">Salesforce</a></li><li><a href="https://gsuite.google.com/marketplace" target="_blank">GSuite Marketplace</a></li><li><a href="https://chrome.google.com/webstore/category/extensions" target="_blank">Chrome Web Store</a></li><li><a href="https://play.google.com/store/apps" target="_blank">Google Play Store</a></li><li><a href="https://www.apple.com/in/ios/app-store/" target="_blank">Apple iOS App Store</a></li><li><a href="https://apps.apple.com/us/genre/mac/id39?mt=12" target="_blank">Mac App Store</a></li></ul><p>All these marketplaces are valid options for you to start. I would lean on a marketplace where there’s a combination of 2 factors</p><ol role="list"><li><strong>Familiarity with problems</strong> - You know what the core product is about, you understand or can empathise with its users maybe from using the tool at your previous workplace, you have an idea on the different kind of problems that exist in the ecosystem and don’t find it too boring to solve them</li><li><strong>Skillset to execute</strong> - If you don’t know how to build Android, iOS, or Mac apps, perhaps steer clear of it. Your goal is not to take on a hard challenge, it’s to take on a challenge where you have some advantage from skill and insight. The goal is to win.<br></li></ol><h3>Why you should pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Huge distribution:</strong> Marketing is often a big reason for a business’s failure, the App Store takes care of it. Shopify has 1mn+ merchants and tons of new signups every month who go to the app store browsing for solutions. <br>Shopify promotes apps within its product and has made it an integral part of its user journey. A new app is able to gain traction fairly easily in the app marketplace, which makes it friendly to newcomers. <br>Marketing is often a big reason for a business’s failure, the App Store takes care of it.</li><li><strong>Tons of app opportunities:</strong> E-commerce store owners have 101+ problems to be taken care of, and you can address any one and do a great job at it to build a sustainable business. It’s not hard (relative standards) to gain 200 paying customers paying you $10/mo to earn $2000/mo ($1600 after Shopify’s 20%)</li><li><strong>Ease of development:</strong> Shopify’s documentation and APIs are first-class, they get out of the way allowing you to build fast. Additionally, Shopify’s <a href="https://polaris.shopify.com/" target="_blank">Polaris UI framework</a> makes building app interfaces a piece of cake. It’s based on React and comes with a Sketch/Figma file to help you design and prototype solutions fast.</li><li><strong>Billing taken care of:</strong> Heads up, Shopify takes a 20% commission on all earnings. So if your app’s monthly subscription fees is $10, you get $8. In return, Shopify takes care of billing end to end.<br>You can charge monthly, annually, charge per activity, provide app credit, and issue refunds with very little effort. You don’t need to worry about failed payments, Shopify takes care of it. You don’t even need to generate an invoice, app bills are included in the merchant’s monthly Shopify invoice.</li><li><strong>Familiarity with ecommerce:</strong> If you’re someone who can jump into an industry and learn all about it, great. If not, you would want some familiarity with how an ecommerce store works, what are the typical problems faced by a merchant.<br>You can do this by creating a Shopify store and trying to sell your own products. Or you could have conversations with 10 different store owners and absorb from their experience. You could also find someone who works at an e-commerce agency for valuable insights. It’s not that hard.<br></li></ul><h3>Why you shouldn’t pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Copycat galore:</strong> You’re likely to copy an existing app and make a slight improvement in terms of product, pricing, or both. Guess what, the next smart person with the same idea can do the same to you. If you’re dependent on getting all or majority of your customers from the app store, be ready for stiff competition from copycats. <br>This doesn’t mean you cannot grow your app to $1k or $10k MRR. SaaS is not a winner take all market. It just means that it gets harder to grow as you grow. If this is something you are not mentally prepared for, steer clear. <br>There’s ways you can grow out of this by taking a long term strategy, either by taking a brand-centric approach (brand is not your name, but the experience that customers remember you by for which they’ll choose you over a copycat). <br>Or you can go upmarket and target large volume and Plus merchants, where ticket sizes are $200/mo or higher and switching does not happen often. </li><li><strong>Low-end, high-maintenance customers:</strong> Majority of Shopify merchants are people who don’t want to pay beyond $10-$15/mo and yet they expect world-class customer service. Some will ask for phone support or to jump on a video call. <br>You can tackle this by solving problems where the ticket sizes are higher, in the range of $50-$100/mo, but also expect it to be significantly harder to rank and fight existing competitors in such problem spaces. Example - <a href="https://apps.shopify.com/search?q=page+builder" target="_blank">page builders</a>, <a href="https://apps.shopify.com/search?q=product+reviews" target="_blank">product review</a> apps. <br>You can mitigate this by going in with the mindset that you’ll be serving $15/mo customers, so your app better be self-serve ready, have a dead simple UX and sufficient documentation or walkthrough videos. You can also aim to be the cost-leader of a segment, example - <a href="https://apps.shopify.com/judgeme" target="_blank">Judge.me</a> </li></ul><p>‍<br></p><h2><strong>Discover problems, niches, and Shopify app ideas</strong></h2><p>I’ve previously written about <a href="https://www.preetamnath.com/blog/shopify-micro-saas-growth" target="_blank">uncovering opportunities on Shopify</a> and I also shared all my research in my big <a href="https://docs.google.com/spreadsheets/d/1Hnpcl1VAlPC9MuFvvsl2UsU0yu1iM6aKR-iK30VtbwA/edit?usp=sharing" target="_blank">Shopify app ideas spreadsheet</a>. Let me reiterate on the advice shared there in a more structured manner that will hopefully better answer questions like:</p><ul role="list"><li>“How do you find niches in the app store in the first place?”</li><li>“How to find a problem worth solving within shopify? (worth solving=stressful enough for merchants &amp; competition not too tough)”<br></li></ul><p>There have been people who have asked me what kind of problems to solve, or what are the underserved niches. The thing is - if there's an obviously underserved niche and people have taken the time to research about it, they are probably busy solving it. If it's being posted in any blog post, know that it's no longer an underserved or hidden niche, because clearly anyone could find it.</p><p>Ultimately, only you can find an idea that you find worthy enough to pursue, whose various pros and cons are justified in your mind. And therefore, I can only provide a directional framework towards evaluating ideas. I can't list out ideas.</p><p>The best use of a directional framework is to</p><ol start="" role="list"><li><strong>First</strong> - cast a wide net, get to know what's out there</li><li><strong>Second</strong> - narrow down your search based on parameters you have decided</li></ol><p>This first section of the article will help you with casting a wide net. </p><p>As you go further along the article, I've shared ideas and techniques which you can use to narrow down your search.<br></p><h3>1- Browse the entire App Store</h3><p>I recommend this as the starting point for anyone new to the Shopify ecosystem. Start by browsing all the categories &amp; sub-categories of apps on the app store. You can do the same on <a href="https://sasi.unionworks.co.uk/categories" target="_blank">SASI</a>. </p><p>The purpose of browsing this way is to familiarise yourself with the different types of problems faced by merchants and being solved by apps. Ideally, you want to note down some interesting apps that you come across during your browsing adventure to investigate later on.</p><figure id="w-node-892fc283544a-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f1c114edd643e073591f8cc_browse%20categories%20shopify%20app%20store.png" alt=""></p></figure><h3>2- Go through every letter in search autocomplete</h3><p>Okay, this is a step I took when&nbsp;I was browsing the app store. I would type in "aa", "ab", "ac"... ... ... "zz" on the search bar, note the autocomplete terms and check the results of ones I found to be interesting.</p><p>Turns out, Shopify has since updated their algorithm. Autocomplete suggestions only show up after you type 3 letters now. So you can't recreate what I did with autocomplete and go through every letter. It's not feasible anymore.</p><p>Not to worry, it's still useful.</p><h4>Plug in keywords of shortlisted apps into the search bar</h4><p>From step 1, all the apps (hopefully at least a dozen) that you shortlisted for being interesting, extract the keywords used in the app's title or description. </p><p>Now, enter those keywords in search to find whether they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261192</guid>
            <pubDate>Mon, 24 Aug 2020 14:47:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Year of Nushell]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24259914">thread link</a>) | @rainworld
<br/>
August 24, 2020 | https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html | <a href="https://web.archive.org/web/*/https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <section>
      

      <p>Hard to imagine that it’s already been a year since Nu first went public. At the time, it was largely a demo of what could be possible, but still needed quite a bit of work to make it ready for everyday use. A year later and we’ve learned a lot, and made a few mistakes along the way. In this post, we look back over the year and see how we did and where we might be going in the future.</p>



<p>When Nu first started, it started with a simple idea: the output of <code>ls</code>, <code>ps</code>, and <code>sysinfo</code> should all output the same thing. Taking a page from PowerShell, we explored outputting structured data and quickly settled on a table design that would support the output of each of the three commands, with the added ability of streaming the output as it became available.</p>

<p>Around this idea, we then built a set of “filters”, like the <code>where</code> clause, borrowed from SQL, and a growing set of data types we would support natively.  Soon, we were able to write more complex statements like <code>ls | where size &gt; 10kb</code>. This became the crux of the idea - commands that output values from a core set of data types into a stream, composed together with the traditional UNIX pipe (<code>|</code>), so that you could build up a complex set of commands that work over the data as it streams through.</p>



<h2 id="contributors">Contributors</h2>

<p>Before we got started talking about Nushell today, we wanted to give a <em>big</em> “thank you!” to everyone who has contributed to Nu to get us to this point. Nu is what it is because of your help.</p>

<p>1ntEgr8, AaronC81, AdminXVII, aeosynth, aeshirey, aidanharris, almindor, Aloso, Amanita-muscaria, amousa11, andrasio, Andrew-Webb, arashout, arnaldo2792, avandesa, avranju, bailey-layzer, BatmanAoD, bndbsh, Bocom, boisgera, Borimino, BradyBromley, BurNiinTRee, Byron, candostdagdeviren, casidiablo, charlespierce, chhetripradeep, cjpearce, coolshaurya, cristicismas, DangerFunPants, daschl, daveremy, davidrobertmason, Delapouite, dependabot[bot], Detegr, devnought, Dimagog, djc, drmason13, DrSensor, elichai, eltonlaw, EmNudge, eoinkelly, equal-l2, est31, fdncred, filalex77, Flare576, gilesv, gorogoroumaru, GuillaumeGomez, hdhoang, he4d, hilias, HiranmayaGundu, hirschenberger, homburg, iamcodemaker, incrop, ineol, Jacobious52, jankoprowski, JCavallo, jdvr, jerodsanto, JesterOrNot, johnae, johnterickson, jonathandturner, JonnyWalker81, jonstodle, JosephTLyons, jzaefferer, k-brk, Kelli314, klnusbaum, kloun, kornelski, kubouch, kvrhdn, landaire, lesichkovm, LhKipp, lightclient, lincis, lord, luccasmmg, marcelocg, matsuu, mattclarke, mattyhall, max-sixty, mfarberbrodsky, mhmdanas, mike-morr, miller-time, mistydemeo, mlbright, mlh758, morrme, nalshihabi, naufraghi, nespera, neuronull, nickgerace, nmandery, notryanb, oknozor, orf, orientnab, oskarskog, oylenshpeegul, pag4k, Paradiesstaub, philip-peterson, piotrek-szczygiel, pizzafox, pka, pmeredit, pontaoski, Porges, pulpdrew, q-b, quebin31, rabisg0, ramonsnir, rimathia, ritobanrc, rnxpyke, romanlevin, routrohan, rrichardson, rtlechow, rutrum, ryuichi1208, Samboy218, samhedin, sandorex, sdfnz, sebastian-xyz, shaaraddalvi, shiena, siedentop, Sosthene-Guedon, Southclaws, svartalf, taiki-e, Tauheed-Elahee, tchak, thegedge, tim77, Tiwalun, twe4ked, twitu, u5surf, UltraWelfare, uma0317, utam0k, vsoch, vthriller, waldyrious, warrenseine, wycats, yaahc, yahsinhuangtw, yanganto, ymgyt, zombie110year</p>



<p>Nushell is an interactive programming language for working with your files, your system, and your data as a shell, a notebook, and more.</p>

<h2 id="nu-is-more-than-a-shell">Nu is more than a shell</h2>

<p>It’s easy to think of Nushell as just a shell. It’s even got ‘shell’ in the name. It’s the first and probably main way you’ll interact with it. So why say it’s “more than a shell”?</p>

<p>In truth, Nushell is actually two things at once: Nu and Nushell. Nu is an interactive language for processing streams of structured data, data that you’re probably getting from files, your system, a web address, etc.</p>

<p>So what’s Nushell?</p>

<p>Nushell is taking the Nu language and putting it into a shell, and building around it a set of shell features to make it feel comfortable to use as a login shell. Completions, pretty error messages, and the like.</p>

<p>When we say that “Nu is more than a shell”, does that imply that Nu can be used in other places, too? Absolutely. We’ve got two more hosts that let you run Nu, a <a href="https://github.com/nushell/nu_jupyter">jupyter-based</a> host that lets you run Nu in jupyter notebooks, and a <a href="https://github.com/nushell/demo">WebAssembly-based</a> host that we use to create the <a href="https://www.nushell.sh/demo/">Nu playground</a></p>

<p>The idea of Nu runs deeper than just the shell, to being a language that’s relatively easy to learn, yet powerful enough to do real work with your system, to process large amounts of data, to interactively let you iterate quickly on an idea, to invite exploration by building up a pipeline one piece at a time. There’s really no shortage of ambition for where we hope to go.</p>



<p>Nu’s original design has proven surprisingly robust thus far. Some of its core ideas are continuing to pay dividends a year later. Let’s look at the designs that still feel right.</p>

<h2 id="pipelines-are-infinite">Pipelines are infinite</h2>

<p>When we first started writing Nu, we took a few shortcuts that had us processing all the data in a pipeline at once. Very quickly, we realize this wasn’t going to work. External commands (think <code>cat /dev/random</code>) can output an infinite stream of data, and the system needs to be able to handle it. Understanding this, we transitioned to a different model: data flows between command as infinite streams of structured data. As the data is processed, we avoid collecting the data whenever possible to allow this streaming to happen.</p>

<p>Because the streams can be infinite, even the printing out of tables is done a batch at a time.</p>

<h2 id="separating-viewing-data-from-the-data-itself">Separating viewing data from the data itself</h2>

<p>Coming from other shells, the idea of running <code>echo</code> or <code>ls</code> goes hand-in-hand with printing something to the terminal. It’s difficult to see that there two steps going on behind the scenes: creating the information and then displaying it to the screen.</p>

<p>In Nu, these two steps are distinct. The <code>echo</code> command gets data ready to output into stream, but doesn’t do any work to print it to the screen. Likewise, <code>ls</code> gets ready to output a stream of file and directory entries, but doesn’t actually display this information.</p>

<p>That’s because both <code>echo</code> and <code>ls</code> are lazy commands. They’ll only do the work if the data is pulled from the stream. As a result, the step of viewing the data is separate from the step of creating it.</p>

<p>Behind the scenes, Nu converts a standalone <code>ls</code> to be the pipeline <code>ls | autoview</code>. The work of viewing comes from <code>autoview</code> and it handles working with the data and calling the proper viewer. In this way, we’re able to keep things as structured data for as long as possible, and only convert it to be displayed as the final step before being shown to the user. (note: the wasm-based demo and jupyter do a similar step, but instead of adding <code>autoview</code>, they add <code>to html</code>)</p>

<h2 id="rich-data-types">Rich data types</h2>

<p>In a similar way to working with structured data, rather than only plain text, Nu takes a different approach to data types as well. Nu takes the traditional set of basic types, like strings and numbers, and extends them into a richer set of basic data primitives.</p>

<p>Numbers are represented internally as big numbers and big decimals, rather than integers and floating point machine-based representations. This gives us more flexibility to do math more accurately, and generally removes the worry of whether the number you want to work with will fit in the integer or float size you have available.</p>

<p>We carry this further, by also representing values common in modern computer usage: URLs, file paths, file sizes, durations, and dates are all examples of built-in data types. By building them in, Nu can have better syntax and type checking with their use.</p>

<p>For example, in Nu it’s possible to write <code>= 1min + 1sec</code> to create a duration that is one minute one second long.  You can also use the file sizes, like being able to filter a directory list by the size of the file <code>ls | where size &gt; 10kb</code>.</p>

<p>Nu also can help if you try to mix types that shouldn’t. For example, if you had written: <code>= 1min + 1kb</code> it seems you didn’t mean to add time and file sizes together, and Nu gives you an error if you do:</p>

<div><div><pre><code>error: Coercion error
  ┌─ shell:1:3
  │
1 │ = 1min + 1kb
  │   ^^^^   --- filesize(in bytes)
  │   │       
  │   duration
</code></pre></div></div>

<p><em>note: we’ll be making this error better in the future</em></p>

<p>Data in Nu also isn’t just the value, but it’s also a set of metadata that comes with the value. For example, if you load data from a file using the <code>open</code> command, we track the place that it’s loaded along with the data that’s loaded. We can see this metadata using the <code>tags</code> command:</p>

<div><div><pre><code>open package.json | tags
───┬─────────────────┬──────────────────────────────────────────────────────────────────────────────
 # │      span       │                                    anchor                                    
───┼─────────────────┼──────────────────────────────────────────────────────────────────────────────
 0 │ [row end start] │ /home/jonathan/Source/servo/tests/wpt/web-platform-tests/webrtc/tools/packag 
   │                 │ e.json                                                                       
───┴─────────────────┴──────────────────────────────────────────────────────────────────────────────
</code></pre></div></div>

<p>This extra information allows us to know how to view the contents, and even save you time when you use the <code>save</code> command, as it will use the original location by default.</p>

<h2 id="keeping-it-fun">Keeping it fun</h2>

<p>Something we attached to early on was the idea that Nu should be fun. It should be fun to work on, it should be fun to contribute to, and it should be fun to use.</p>

<p>Nu is really about play. You play with your data, you play with the structures that make up your files and filesystem, you play with what web services give back to you. Everything about Nu is made to invite you to explore how things work and how data is put together. As you play, you learn more about Nu works and how to better use it. We firmly believe …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</a></em></p>]]>
            </description>
            <link>https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259914</guid>
            <pubDate>Mon, 24 Aug 2020 12:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why People Become Internet Trolls]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24259728">thread link</a>) | @Gedxx
<br/>
August 24, 2020 | https://dradambell.com/why-people-become-internet-trolls/ | <a href="https://web.archive.org/web/*/https://dradambell.com/why-people-become-internet-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1c056633" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<p><span>When I was 10 years old and first introduced to the miracle of the World Wide Web, chat rooms were by far my favorite thing. Talking to random people from all over the world about anything you want — what more could a bored kid ask for?</span></p>

<p><span>I’d spend hours in these chat rooms, asking my new friends how old they were, what they had for breakfast, and how much pocket money their parents gave them. I shared this experience with a friend who didn’t own a computer and had never used the internet.</span></p>

<p><span>He asked if he could have a go. “Sure!” I said, excited for him to experience the wonder of the internet. Without hesitation, he began typing the worst insults and swear words he could think of. Horrified I had awoken a dark and malevolent force, and fearing he had forever ruined my friendship with strawberry88, I shut down my computer and didn’t invite him to play on the internet again.</span></p>

<p><span>To this day, I remain baffled by this behavior. When faced with the endless possibility of the internet, my childhood friend’s first impulse was to verbally abuse strangers. This innocent 10-year-old had become a troll.</span></p>

<h4 id="02ff"><span>Wretched impulses</span></h4>

<p><span>John Oliver once described the internet as a “dark carnival of humanity’s most wretched impulses.” Was it these wretched impulses that had consumed my childhood friend?</span></p>

<p><span>The act of trolling is best described from where its name&nbsp;<a href="https://www.etymonline.com/word/troll" target="_blank" rel="noreferrer noopener">may have come from</a>&nbsp;— the form of fishing where a lure is dangled off a moving boat.</span></p>

<figure><span><img src="https://miro.medium.com/max/3200/0*f3HYZpvSGgrg1vHC" alt=""></span></figure>

<p><span>The troll casts his bait (the offensive comment) into the water of the internet. An unsuspecting fish (the targeted user) sees the bait and feels compelled to go for it (the defensive comment). Soon they are hooked and reeled in without mercy. But unlike trolling for fish, which delivers a clear and edible reward, the troll’s reward isn’t entirely clear.</span></p>

<p><span>Trolling is a hard concept to define because there are various methods of trolling and differing degrees of depravity. Some are abhorrent, like “suicide baiting,” where trolls encourage vulnerable users to kill themselves, or “RIP trolls” who vandalize Facebook memorial sites of the recently deceased. But others, like “griefers” who play online games in a manner that purposely disrupts other players, are more of a nuisance.</span></p>

<p><span>Who are these trolls, and what drives them?</span></p>

<h4 id="4d5f"><span>The dark tetrad</span></h4>

<p><span>Psychologists have found&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886914000324" target="_blank" rel="noreferrer noopener">a link between trollish behavior</a>&nbsp;and a set of personality traits called “the dark tetrad.”</span></p>

<figure><span><img src="https://miro.medium.com/max/2974/0*sAMy6kU4hSsBKYQy" alt=""></span></figure>

<p><span>The dark tetrad comprises:</span></p>

<ul>
<li><span>Sadism — deriving pleasure from another’s pain</span></li>
<li><span>Psychopathy — impairment of empathy and remorse</span></li>
<li><span>Machiavellianism — manipulative and emotionally “cold” behavior</span></li>
<li><span>Narcissism — self-involvement and a need for admiration</span></li>
</ul>

<p><span><a href="https://www.academia.edu/41115419/Loneliness_moderates_the_relationship_between_Dark_Tetrad_personality_traits_and_internet_trolling" target="_blank" rel="noreferrer noopener">In a recent study</a>, trolls were positively correlated with three of the four dark tetrad traits, with narcissism being the odd one out. They found trolls were manipulative, lacked empathy, and enjoyed hurting others. Men exhibited these traits more commonly than women and were more likely to troll. Loneliness was also a significant predictor of trolling when in the presence of Machiavellianism or psychopathy.</span></p>

<p><span>Most studies on trolls use internet surveys to collect data, which is questionable: Can we really trust trolls to complete surveys accurately? This method may also not account for those who don’t consider their behavior to be trollish or those unaware of their trollish behavior.</span></p>

<p><span>In the book&nbsp;<a href="https://www.hardiegrant.com/au/publishing/bookfinder/book/troll-hunting-by-ginger-gorman/9781743794357" target="_blank" rel="noreferrer noopener"><em>Troll Hunting</em></a>, journalist Ginger Gorman spends years building relationships with the worst trolls she can find in an attempt to understand what drives them. To her surprise, trolls were not uneducated lost souls who lacked social skills and lived in their mother’s basement. These trolls had partners, children, and full-time jobs. They showed leadership skills as commanders of&nbsp;<a href="https://www.theguardian.com/books/2019/jan/28/it-was-like-being-skinned-alive-ginger-gorman-goes-hunting-for-trolls" target="_blank" rel="noreferrer noopener">large trolling syndicates</a>. They were socially intelligent and able to pinpoint users’ weaknesses with vicious precision. But what was driving them?</span></p>

<p><span>Many saw trolling as a hobby — something that entertained or amused. Some were ideologically driven, attacking anybody opposing their belief system. But both types of troll tended to engage users that threatened their beliefs or sense of self.</span></p>

<p><span>Some of the trolls exhibited dark tetrad traits. In these trolls, she saw a common pattern — excessive internet use with little to no parental supervision between the ages of 11 and 16. But some trolls didn’t fit the dark tetrad personality type. These trolls were pleasant, friendly, and compassionate when she engaged them directly. How could these trolls behave so antisocially online yet appear to function as typical members of society offline?</span></p>

<h4 id="7160"><span>Empathy deficit</span></h4>

<p><span>The human brain was primarily designed for face-to-face interaction. It hasn’t had time to adapt to communication over the internet.</span></p>

<p><span>Nonverbal communication — facial expressions, gestures, and voice qualities — provides the precise social context of an interaction. While the claim that 93% of communication being nonverbal is&nbsp;<a href="https://cornerstone.lib.mnsu.edu/cgi/viewcontent.cgi?article=1000&amp;context=ctamj" target="_blank" rel="noreferrer noopener">inaccurate</a>, it is a crucial part of how we communicate. Words alone can only go so far. Even if we used the full&nbsp;<a href="https://englishlive.ef.com/blog/language-lab/many-words-english-language/" target="_blank" rel="noreferrer noopener">170,000 words</a>&nbsp;currently in use in the English language, we still couldn’t convey what an expressive face or a suggestive voice could.</span></p>

<p><span>Most internet discussions only allow words. Well, words and emojis and GIFs and stickers and all the other substitutes created to replace nonverbal cues.</span></p>

<p><span>If you say something mean to my face and make me cry, you will probably start to feel uncomfortable. Unless you’re especially mean or psychopathic, my distress will trigger an empathic response and lead you to have mercy. If you tweet something mean and make me cry, no amount of emojis can convey what the sight of a grown man weeping can. If there is no social cue to elicit an empathic response, you might continue your tirade of meanness.</span></p>

<p><span>The absence of nonverbal feedback leads to an “empathy deficit,” and this is what sociopaths suffer from.</span></p>

<h4 id="53a2"><span>Toxic disinhibition</span></h4>

<p><span>When you combine an empathy deficit with the anonymity of online interactions, you get “<a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect" target="_blank" rel="noreferrer noopener">toxic disinhibition</a>,” which is more than just the phenomenon of being rude to bar staff after that fifth shot of tequila.</span></p>

<p><span>Anonymity can lead to “<a href="https://en.wikipedia.org/wiki/Deindividuation" target="_blank" rel="noreferrer noopener">deindividuation</a>” — a temporary loss of one’s identity leading to behavior incongruent with one’s character. It explains why groups of civilized people can engage in riots. It also explains trolling. If a lack of nonverbal cues is what makes us detached from the other person’s suffering, deindividuation is what makes us detached from the awareness of our misconduct.</span></p>

<p><span>True anonymity offers protection from real-world social repercussions, and this has profound effects on human behavior. The image-based bulletin board 4chan, where registration isn’t possible and users remain anonymous, has been&nbsp;<a href="https://theconversation.com/4chan-raids-how-one-dark-corner-of-the-internet-is-spreading-its-shadows-68394" target="_blank" rel="noreferrer noopener">infamous as a troll incubator</a>&nbsp;for this reason. When there are no real-world consequences to your actions, it liberates you from a lifetime of societally inhibited behaviors. Society discourages antisocial behavior and encourages prosocial behavior, so it is antisocial behavior that seeks liberation.</span></p>

<p><span>We are a delicate balance between prosocial humans and antisocial primates. When society cannot enforce prosocial human behavior, the antisocial primate may come back into power. And thus the troll is created.</span></p>

<h4 id="f597"><span>Troll begets troll</span></h4>

<p><span>Researchers at Stanford and Cornell universities performed a large-scale data analysis on&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5791909/" target="_blank" rel="noreferrer noopener">over 16 million comments</a>&nbsp;from December 2012 to August 2013 on CNN.com and found 1 in 4 posts flagged as abusive were from users with no prior record of trollish behavior. This suggests trolling isn’t always a full-time occupation and that one may indulge sporadically.</span></p>

<p><span>The researchers could predict the likelihood of trolling based on the nature of other comments in the discussion and the user’s mood. If earlier comments were negative, the propensity to troll was greater. Like a bad mood, trolling is contagious. All it takes is another user’s trollish comment and a bad mood to create an environment in which our inner troll can blossom.</span></p>

<h4 id="b294"><span>The inner troll</span></h4>

<p><span>It is easier to view trolls as bad apples than see them as something inside all of us, waiting for the right environment to let loose. But when we condemn trolls as inherently malicious individuals, we limit our understanding of what may drive these behaviors.</span></p>

<p><span>While RIP trolls or suicide baiters are likely to be dark tetrad personality types who use the internet as an outlet to indulge their darkest impulses, lesser trolls may be part-time participants who will engage with the right combination of a bad day and a noxious environment. We have only begun to scratch the surface in our understanding of trolls, but the evidence we have suggests we may all be vulnerable.</span></p>

<p><span>Is anyone exempt from toxic disinhibition? Few respond to a tweet that offends them with “Excuse me, I really don’t want to be rude, but if I may could I please respectfully disagree with your opinion for these reasons …” While an offhand remark may appear harmless, the less empathic our online interactions collectively become, the greater risk we all stand of becoming trolls. The gentle ripples of impolite tweets may become crashing toxic waves of disinhibited hatred.</span></p>

<p><span>Trolling isn’t black and white, it is somewhere in the grey between prosocial human and antisocial primate. Ultimately, our propensity for antisocial behavior in the physical world is likely to predict similar online behavior.</span></p>

<h4 id="9272"><span>How can we manage our inner trolls?</span></h4>

<p><span>The more accountable we are for our behavior, the less potential we have of becoming trolls. Employing&nbsp;<a href="https://scholarspace.manoa.hawaii.edu/bitstream/10125/41373/1/paper0224.pdf" target="_blank" rel="noreferrer noopener">less anonymity may help</a>, but this raises privacy concerns for many. Anonymity can also be a good thing. Benign disinhibition — the friendly sibling of toxic disinhibition — is where users freely discuss their deepest insecurities and concerns with other users. This can be very therapeutic and shouldn’t be discouraged. But by using anonymity only where it is necessary, we reduce the likelihood of toxic disinhibition.</span></p>

<p><span>Empathy doesn’t come …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dradambell.com/why-people-become-internet-trolls/">https://dradambell.com/why-people-become-internet-trolls/</a></em></p>]]>
            </description>
            <link>https://dradambell.com/why-people-become-internet-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259728</guid>
            <pubDate>Mon, 24 Aug 2020 11:50:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Generators, Meet XPath]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24259688">thread link</a>) | @fanf2
<br/>
August 24, 2020 | https://jack.wrenn.fyi/blog/xpath-for-2020/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/xpath-for-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
<article>
    <header>
      
      <span>2020-08-22&nbsp;</span>
    </header>

    <p>Using Generators to Modernize a Geriatric Javascript API for <code>$CURRENT_YEAR</code></p>
<span id="continue-reading"></span>
<hr>
<p>How do you find-and-replace text on an HTML page?</p>
<pre><code><span>&lt;div&gt;</span><span>Hello, </span><span>&lt;span&gt;</span><span>human</span><span>&lt;/span&gt;</span><span>!</span><span>&lt;/div&gt;
</span></code></pre>
<p>If the text is neatly neatly isolated inside an HTML element, it's easy; this will do:</p>
<pre><code><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"span"</span><span>)</span><span>.textContent </span><span>= </span><span>"evolved ape"</span><span>;
</span></code></pre>
<p><strong>But here's a puzzle</strong>: how do you you change text that <em>isn't</em> neatly isolated in an HTML element?</p>
<p>You <em>could</em> use <code>innerHTML</code>:</p>
<pre><code><span>let </span><span>elt </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>;
</span><span>elt</span><span>.innerHTML </span><span>= </span><span>elt</span><span>.innerHTML.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>...but this will hose any event listeners registered on <code>elt</code>'s children.</p>
<p>You <em>could</em> grapple onto the nearest selectable element:</p>
<pre><code><span>let </span><span>node </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>.childNodes[</span><span>0</span><span>];
</span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>Yuck; this sort of child-node indexing feels <em>really</em> brittle.</p>
<p><strong>Why can't we just <em>directly</em> select the text nodes containing <code>Hello</code>?</strong></p>
<h2 id="xpath">XPath</h2>
<p><strong>We can!</strong> Enter: <a href="https://en.wikipedia.org/wiki/XPath">XPath</a>, the <em>excessively</em> powerful language for querying XML documents. It's usable in web-browsers with the, uh, <em>descriptively</em>-named method <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/evaluate"><code>document.evaluate</code></a>.</p>
<p>It's a <em>bit</em> of a production to use:</p>
<pre><code><span>let </span><span>xpath </span><span>= </span><span>"//text()[contains(., 'Hello')]"</span><span>; </span><span>// find text nodes containing 'Hello'
</span><span>let </span><span>context </span><span>= </span><span>document</span><span>.body; </span><span>// look in the body element
</span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>; </span><span>// some sorta xml voodoo
</span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE; </span><span>// DEFINITELY MAKE SURE YOU USE THIS

</span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

</span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>) {
  </span><span>let </span><span>node </span><span>= </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
}
</span></code></pre>
<p>Yes, you really need to write <em>all</em> of that. The <code>result_type</code> argument is technically optional, but omit it at your own peril: without it, you must instead stream results via <code>iterateNext</code>, and this will crash with an exception if you dare <em>modify</em> the queried elements!</p>
<p>It's no wonder <code>document.evaluate</code> is seldom used. <strong>Can we improve on it?</strong></p>
<h2 id="iterizing-xpath-queries">Iterizing XPath Queries</h2>
<p>Yes, with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators"><strong>generators</strong></a>! We can exploit the implicit iterability of generators to modernize this unwieldy API:</p>
<pre><code><span>Document</span><span>.</span><span>prototype</span><span>.xpath </span><span>= </span><span>Element</span><span>.</span><span>prototype</span><span>.</span><span>xpath </span><span>=
  </span><span>function* </span><span>xpath</span><span>(</span><span>xpath</span><span>) {
    </span><span>let </span><span>context </span><span>= </span><span>this </span><span>instanceof </span><span>Document </span><span>? </span><span>document</span><span>.documentElement </span><span>: </span><span>this</span><span>;
    </span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>;
    </span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE;
    </span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

    </span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>)
      </span><span>yield </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  };
</span></code></pre>
<p>And because the result of this function is iterable, we can use it with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax">spread syntax</a>:</p>
<pre><code><span>[</span><span>...</span><span>document</span><span>.</span><span>xpath</span><span>(</span><span>"//text()[contains(., 'Hello')]"</span><span>)</span><span>].
  </span><span>forEach</span><span>(</span><span>node </span><span>=&gt; </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>))</span><span>;
</span></code></pre>
</article>

        </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/xpath-for-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259688</guid>
            <pubDate>Mon, 24 Aug 2020 11:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of Venmo (2014)]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24259509">thread link</a>) | @saadalem
<br/>
August 24, 2020 | https://kortina.nyc/essays/origins-of-venmo/ | <a href="https://web.archive.org/web/*/https://kortina.nyc/essays/origins-of-venmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I often speak about the origins of Venmo in person and finally wrote down the story here to share with our latest intern class that started this week. (You can also watch an excellent video of Iqram speaking about even more of the history of Venmo <a href="https://www.youtube.com/watch?v=aX7JCCCmLJw">here</a>. It’s a good place to pickup the story where this post leaves off.)</p>

<p>My friend Iqram and I started Venmo to solve a very simple problem for ourselves and for our friends: we noticed that we were still using cash and checks to pay each other back and thought this was silly. Everyone should be using PayPal to pay each other back, but no one we knew was. We thought something must be not quite right about the PayPal experience for casual use, and we decided to design something that felt “right,” something that felt consistent with all of the other mobile tools we used to interact with our friends, like SMS, Gmail, Facebook, etc. This is the story of how we got to Venmo.</p>

<h2 id="penn">Penn</h2>

<p>Iqram and I met as randomly paired freshman year roommates at the University of Pennsylvania in 2001. We’ve been great friends ever since.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iqram-kortina-college.png">
<figcaption>Oldest pic I could find of me and Iqram.</figcaption>
</figure>

<p>Iqram studied computer science at Penn. I started in computer science, but found that much of the learning I was doing happened while I was doing homework exercises, and I was getting no additional value out of the University. I couldn’t justify tuition costs when I was only learning by spending time doing programming exercises, and I developed a hypothesis that I would maximize the value of tuition costs by studying the least practical subjects possible, the things I would not get to do after graduation / outside of University, like reading and discussing great books with a group of incredibly smart students and professors (this backfired, btw–liberal arts is very practical stuff!). I eschewed big lectures and things like On Campus Recruiting, and tried to spend as much time possible in seminars and writing workshops. I ended up with majors in Philosophy and Creative Writing and minors in Computer Science and Logic.</p>

<p>I remained interested in building things during this time, however, and always took the opportunity to build websites for various clubs I was in or for friends with bands, etc.</p>

<p>During our senior year, Iqram and I built our first real project together, a college classifieds site called My Campus Post. It was our first taste of all night coding sessions to get a product to market, and we learned a bunch about grassroots marketing and retention challenges that arise from products with seasonal usage.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/mycampuspost.png">
<figcaption>My Campus Post marketing paraphernalia.</figcaption>
</figure>

<p>I loved spending all of my time reading philosophy, working on fun side projects, and actively ignoring practical things like interviewing for jobs, but I clearly remember the day when my Mom was in town for graduation and she asked, “What are you doing after you graduate?” I was sitting on the floor of my dorm room, and I remember being very scared about the question, thinking, “I have no idea what I want to do with my life,” but also feeling OK about the short term, eventually answering, “I don’t have to move out of my dorm until 2 weeks after graduation. I’ll figure something out.”</p>

<h2 id="post-grad-door-to-door-sales">Post Grad Door to Door Sales</h2>

<p>Iqram ended up finding a cheap sublet in West Philly, and we spent the summer building websites for restaurants, salons, bars, etc. We went door to door selling, “Hey, you need a website. We’ll build it for $500…. $100? OK, deal.” We learned a lot as we tried to abstract the sites we were building into something modular, and we got a lot of experience pitching and hearing “no.” One “no” that I still regret more than most of the others I have subsequently heard (for much bigger deals) was for this amazing Pakistani restaurant, Kabobeesh, that served a chicken kabob sandwich on fresh naan bread for $3.50: we tried to sell them a site for 100 chicken rolls, but failed to close them.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/kabobeesh.png">
<figcaption>Kabobeesh: I recommend the chicken rolls and chicken karahi.</figcaption>
</figure>

<p>Once, we were chatting at a bar about how we might pad our sporadic income with some part time jobs. We noticed the bar was hiring, got two applications, and started filling them out. We spent a few minutes getting through all the basic background stuff, education, personal info, and got to the references section. We didn’t really have past employers to list at the time, so I put Iqram as a reference, and he put me. We were still rooming together at the time, so we had the same street address. We did not get a call back.</p>

<h2 id="swooge-and-philafunk">Swooge and Philafunk</h2>

<p>During this period, we were always also working on startup-y things, like a realtime website analytics tool called Swooge (which now reminds me of Chartbeat + Google Analytics) and a web based music selling platform, Philafunk (it was like iTunes + MySpace).</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/philafunk.jpg">
<figcaption>Philafunk site and flyer.</figcaption>
</figure>

<p>After working on a few of these, we realized we had a lot to learn about building a successful startup, so we decided to go find one and work there. Many of these projects we worked on were still in my opinion great ideas and solid evidence that execution matters much more than the idea.</p>

<h2 id="iminlikewithyou">iminlikewithyou</h2>

<p>So we found this NYC company, iminlikewithyou.com, that was just getting started out of Y Combinator, and we joined as 2 of the first 3 employees, all engineers starting together the day we moved to NYC. We had a talented team, built a really innovative, immersive web experience, and learned a bunch about doing startups for real. Eventually, the company pivoted from the original flirting-site idea into a casual games company (OMGPOP), and we both left because we weren’t interested in building games.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iminlikewithyou.png">
<figcaption>iminlikewithyou site.</figcaption>
</figure>

<h2 id="ticketleap-and-bitly">Ticketleap and Bit.ly</h2>

<p>Iqram worked at Ticketleap as the VP of Engineering for a few years, and I bounced around and ended up spending a bunch of time working at Betaworks, on Bit.ly.</p>

<p>We both learned a lot during this period, but I looked forward to the time when we would work on a new project together, with more knowledge and experience this time. Over the years, I often brought up this idea, but the timing was never quite right.</p>

<h2 id="exploring-new-product-ideas">Exploring New Product Ideas</h2>

<p>In early 2009, Iqram chatted me mentioning that he was feeling ready to move on from Ticketleap, and I remember thinking, “Great let’s do this.” We began getting together on weekends (he was in Philly and I was in NYC) to hack on different ideas.</p>

<h2 id="yogorino">Yogorino</h2>

<p>We had a friend in Philadelphia who was opening a yogurt shop, and while helping her get up and running technically, we realized how horrible traditional point of sales software was. We prototyped a web based point of sales software that would turn any laptop into a cash register with a $50 USB magtek swiper. As we thought about it more, it seemed like this would present a really challenging distribution problem (we remembered our days of door to door restaurant sales…). Plus, although this was designed to solve a problem for one of our friends, it wasn’t software that we would be using ourselves daily.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/cardswiper.png">
<figcaption>Web POS prototype.</figcaption>
</figure>

<h2 id="back-to-music">Back to Music</h2>

<p>Another idea we explored came to us at a local jazz show: we thought, “It would be awesome to be able to download this show by sending a text message to this band right now, and then have an mp3 show up in our email.” This was getting closer to the Venmo concept we ultimately arrived at, and the detailed wireframes we constructed for this definitely informed a lot of the original Venmo service.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/rootsbuy.png">
<figcaption>Wireframe for selling music downloads via SMS.</figcaption>
</figure>

<p>This concept even bore the Venmo name. Lots of people ask about the origin of the name. The brainstorming process was one of many we tried and was not important as the requirements. We were exploring the Latin root vendere “sell” and mo for mobile, but purely as a means to get to a name that (1) was short, 5-6 letters, (2) could be a verb, (3) didn’t have a unintuitive spelling, and (4) was cheap. Venmo was available on GoDaddy and met the important criteria, so we grabbed it.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/visionslide.png">
<figcaption>A slide from our deck for an SMS music service.</figcaption>
</figure>

<h2 id="discovering-venmo">Discovering Venmo</h2>

<p>One of the weekends we were getting together to work on this idea, Iqram was visiting me in NYC and left his wallet in Philly. I covered him for the whole weekend, and he ended up writing me a check to pay me back. It was annoying for him to have to find a checkbook to do this, and annoying for me to have to go to the bank if I wanted to cash it (I never did). We thought, “Why are we still doing this? We do everything else with our phones. We should definitely be using PayPal to pay each other back. But we don’t, and none of our friends do.”</p>

<p>So we decided, let’s just try to solve this problem, and build a way to pay each other back that feels consistent with all of the other experiences we have in apps we use with our friends.</p>

<p>We got pretty excited about this idea, and thought, “Surely someone else must be doing this.” We found a laptop and started googling, and soon came across Obopay: a way to send money to anyone directly from your cell phone. They had recently raised $70M from Nokia, and we thought, “Uh-oh.” But then we poked around the website and the product and found that there was no feel and it seemed a little clunky and not like something anyone we knew would ever use.</p>

<h2 id="evolution-of-the-note">Evolution of the Note</h2>

<p>We got a prototype working pretty quickly. It worked over SMS, and was dead simple. To send iqram $20, text “iqram 20” to our number (a hacked Google Voice account, because the alternative, Textmarks, required that you prefix every text message with a keyword–this was back in the days before Twilio…). The recipient saw “kortina paid you $20.”</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/gvhack.png">
<figcaption>Google Voice SMS hack.</figcaption>
</figure>

<p>Right after we got this working we decided we needed to have a note with each payment so we could keep track of what all of these random amounts were for: “iqram 20 for thai lunch at Nooch.”</p>

<p>The interface was SMS, so we immediately thought, of course it would only be natural for the person on the other end to see the message, so we updated …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kortina.nyc/essays/origins-of-venmo/">https://kortina.nyc/essays/origins-of-venmo/</a></em></p>]]>
            </description>
            <link>https://kortina.nyc/essays/origins-of-venmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259509</guid>
            <pubDate>Mon, 24 Aug 2020 11:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BPF Portability and CO-Re (Compile Once Run Everywhere)]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24259499">thread link</a>) | @nyellin
<br/>
August 24, 2020 | https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html | <a href="https://web.archive.org/web/*/https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>What does portability mean in BPF context? What are the challenges of writing portable BPF programs that developers need to deal with? This post will describe BPF portability problem and how BPF CO-RE (Compile Once – Run Everywhere) is helping to address this problem.</p>
<!--truncate-->

<h2>BPF: state of the art</h2>
<p>Since the inception of (e)BPF, it’s been a constant priority for the BPF community to simplify BPF application development as much as possible, make it as straightforward and familiar of an experience as it would be for a user-space application. And with the steady progress around BPF programmability, writing BPF programs has never been easier.</p>
<p>Despite these usability improvements, though, one aspect of BPF application development has been neglected (mostly for technical reasons): portability. What does "BPF portability" mean, though? We define <strong>BPF portability</strong> as the ability to write a BPF program that will successfully compile and pass kernel verification, and will work <strong>correctly</strong> across <em>different kernel versions</em> without the need to recompile it for each particular kernel.</p>
<p>This note describes the BPF portability problem and our solution to it: BPF CO-RE (Compile Once – Run Everywhere). First, we’ll look at the BPF portability problem itself, describing why it is a problem and why it’s important to solve it. Then, we will outline high-level components of our solution, BPF CO-RE, and will give a glimpse into the pieces of the puzzle that needed to be put together to make it happen. We’ll conclude with a tutorial of sorts, describing the user-visible API of the BPF CO-RE approach and demonstrating its application with examples.</p>
<h2>The problem of BPF portability</h2>
<p>A BPF program is a piece of user-provided code which is injected straight into a kernel. Once loaded and verified, BPF programs execute in kernel context. These programs operate inside kernel memory space with access to all the internal kernel state available to it. This is extremely powerful and is one of the reasons why BPF technology is successfully used in so many varied applications. However, this powerful capability also creates the BPF portability pains we have today: BPF programs do not control memory layout of a surrounding kernel environment. They have to work with what they get from independently developed, compiled, and deployed kernels.</p>
<p>Additionally, kernel types and data structures are in constant flux. Different kernel versions will have struct fields shuffled around inside a struct, or even moved into a new inner struct. Fields can be renamed or removed, their types changed, either into some trivially-compatible ones or completely different ones. Structs and other types can get renamed, or they can be conditionally compiled out (depending on kernel configuration), or just plain removed between kernel versions.</p>
<p>In other words, things change all the time between kernel releases and yet BPF application developers are expected to cope with this problem somehow. How is it even possible to do anything useful with BPF today considering this ever-changing kernel environment? There are a few reasons for this.</p>
<p>First, not all BPF programs need to look into internal kernel data structures. One example is <code>opensnoop</code> tool, which relies on kprobes/tracepoints to track which processes open which files, and just needs to capture a few syscall arguments to work. As syscall parameters offer a stable ABI, these don’t change between kernel versions and as such portability is not a concern to begin with. Unfortunately, applications like this are quite rare. These types of applications are also typically quite limited in what they can do.</p>
<p>So, additionally, BPF machinery inside kernel provides a limited set of "stable interfaces" that BPF programs can rely on to be stable between kernels. In reality, underlying structures and mechanisms do change, but these BPF-provided stable interfaces abstract such details from user programs.</p>
<p>As one example, for networking applications it is usually enough to look at a limited set of <code>sk_buff</code>'s attributes (and packet data, of course) to be extremely useful and versatile. To that end, BPF verifier provides a stable <strong><code>__sk_buff</code></strong> "view" (notice underscores in front), which shields BPF programs from changing <code>struct sk_buff</code> layout. All the <code>__sk_buff</code> field accesses are transparently rewritten into an actual <code>sk_buff</code> accesses (sometimes quite elaborate ones – doing a bunch of internal pointer chasing before finally fetching requested field). Similar mechanisms are available to a bunch of different BPF program types. They are done as program type-specific BPF contexts understood by BPF verifier. So, if you are developing a BPF program with such context, consider yourself lucky, you can blissfully live in a nice illusion of stability.</p>
<p>But as soon as you need to get a glimpse at any raw internal kernel data (e.g., very commonly a <code>struct task_struct</code> which represents a process/thread and contains a treasure trove of process information), you are on your own. It is commonly the case for tracing, monitoring, and profiling applications, which are a huge class of extremely useful BPF programs.</p>
<p>In such cases, how do you make sure you are not reading garbage data when some kernel added an extra field before the field you thought is, say, at offset 16 from the start of <code>struct task_struct</code>? Suddenly, for that kernel, you'll need to read data from, e.g., offset 24. And the problems don't end there: what if a field got renamed, as was the case with <code>thread_struct</code>'s <code>fs</code> field (useful for accessing thread-local storage), which got renamed to <code>fsbase</code> between 4.6 and 4.7 kernels. Or what if you have to run on two different configurations of a kernel, one of which disabled some specific feature and completely compiled out parts of the struct (a common case for additional accounting fields, which are optional, but extremely useful if present)? All this means that you can no longer compile your BPF program locally using kernel headers of your dev server and distribute it in compiled form to other systems, while expecting it to work and produce correct results. This is because kernel headers for different kernel versions will specify a different memory layout of data your program relies on.</p>
<p>So far, people have been dealing with this problem by relying on <a href="https://github.com/iovisor/bcc/">BCC</a> (BPF Compiler Collection). With BCC, you embed your BPF program C source code into your user-space program (control application) <em>as a plain string</em>. When control application is eventually deployed and executed on target host, BCC invokes its embedded Clang/LLVM, pulls in local kernel headers (which you have to make sure are installed on the system from correct <code>kernel-devel</code> package), and performs compilation on the fly. This will make sure that memory layout that BPF program expects is exactly the same as in the target host's running kernel. If you have to deal with some optional and potentially compiled-out stuff in kernel, you'll just do <code>#ifdef</code>/<code>#else</code> guarding in your source code to accommodate such hazards as renamed fields, different semantics of values, or any optional stuff not available on current configuration. Embedded Clang will happily remove irrelevant parts of your code and will tailor BPF program code to specific kernel.</p>
<p>This sounds great, doesn't it? Not quite so, unfortunately. While this workflow works, it's not without major drawbacks.</p>
<ul>
<li><p>Clang/LLVM combo is a big library, resulting in big fat binaries that need to be distributed with your application.</p></li>
<li><p>Clang/LLVM combo is resource-heavy, so when you are compiling BPF code at start up, you'll use a significant amount of resources, potentially tipping over a carefully balanced production workfload. And vice versa, on a busy host, compiling a small BPF program might take minutes in some cases.</p></li>
<li><p>You are making a big bet that the target system will have kernel headers present, which most of the time is not a problem, but sometimes can cause a lot of headaches. This is also an especially annoying requirement for kernel developers, because they often have to build and deploy custom one-off kernels as part of their development process. And without a custom-built kernel header package, no BCC-based application will work on such kernels, stripping developers of a useful set of tools for debugging and monitoring.</p></li>
<li><p>BPF program testing and development iteration is quite painful as well, as you are going to get even most trivial compilation errors only in runtime, once you recompile and restart your user-space control application. This certainly increases friction and is not helping to iterate fast.</p></li>
</ul>
<p>Overall, while BCC is a great tool, especially for quick prototyping, experimentation, and small tools, it certainly has lots of disadvantages when used for widely deployed production BPF applications.</p>
<p>We are stepping up the game of BPF portability with BPF CO-RE and believe this is a future of BPF program development, especially for complex real-world BPF applications.</p>
<h2>High-level BPF CO-RE mechanics</h2>
<p>BPF CO-RE brings together necessary pieces of functionality and data at all levels of the software stack: kernel, user-space BPF loader library (libbpf), and compiler (Clang) – to make it possible and easy to write BPF programs in a portable manner, handling discrepancies between different kernels within the same pre-compiled BPF program. BPF CO-RE requires a careful integration and cooperation of the following components:</p>
<ul>
<li><p>BTF type information, which allows to capture crucial pieces of information about kernel and BPF program types and code, enabling all the other parts of BPF CO-RE puzzle;</p></li>
<li><p>compiler (Clang) provides means for BPF program C code to express the intent and record relocation information;</p></li>
<li><p>BPF loader (<a href="https://github.com/libbpf/libbpf">libbpf</a>) ties BTFs from kernel and BPF program together to adjust compiled BPF code to specific kernel on target hosts;</p></li>
<li><p>kernel, while staying completely BPF CO-RE-agnostic, provides advanced BPF features to enable some of the more advanced scenarios.</p></li>
</ul>
<p>Working in ensemble, these components …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</a></em></p>]]>
            </description>
            <link>https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259499</guid>
            <pubDate>Mon, 24 Aug 2020 11:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My startup/idea validation process]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24259246">thread link</a>) | @NeilRamp
<br/>
August 24, 2020 | https://neilcocker.com/2020/08/22/my-startup-validation-process/ | <a href="https://web.archive.org/web/*/https://neilcocker.com/2020/08/22/my-startup-validation-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2340">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I’m very interested in how startups validate their ideas. I’m finding that actually a staggering amount of them barely do. Or just do it very badly.</p>



<p>There’s no one right way to validate a startup idea. And, even if you do it perfectly, it doesn’t guarantee success. But it does hugely reduce the risk of failure.</p>



<p>What I outline below is the method I’ve been using for a while. It’s <strong>not comprehensive</strong>, and each of the steps can be done in a much more detailed way. But it’s <strong>quick</strong>, captures good data, and gives you a very strong footing to start your journey.</p>



<p>TL;DR</p>



<ul><li>Define your customer – 1 hour</li><li>Read a book – 3 hours</li><li>Write your hypothesis – 1 hour</li><li>Create and distribute a survey – 4 hours</li><li>Speak to people (properly!) – 10+ hours</li></ul>



<figure><img data-attachment-id="2355" data-permalink="https://neilcocker.com/william-iven-gcsnospexfs-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg" data-orig-size="4193,2785" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="william-iven-gcsnospexfs-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=580" src="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@firmbee?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">William Iven</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>Here’s a quick breakdown of each one of these. </p>



<p>1 – Define your potential market, and your potential customer. You may already have a typical customer in mind, but try to drill down into something specific. It’s not enough to just say “This is for entrepreneurs”. Or “It’s for single mums”. You need to define them more clearly by their behaviours, as well as their primary characteristics. Try something like “Time-rich, cash-poor,&nbsp; freelancers who need extra sources of income”. Or “High net worth individuals who take more than ten flights for business a year”. </p>



<p>2 (Optional, but VERY strongly recommended) – Read <a href="http://momtestbook.com/">The Mom Test</a>. I think it’s the most important business book I’ve ever read, and it fundamentally changed how I talk to (potential) customers. It stopped me being obsessed with my product, and fall in love with the problem. I should get commission for how often I recommend it! If you have already read it, and are confident that you don’t need to refresh your memory, then move on to stage 3.</p>



<p>The Mom Test is a book that helps you speak to your customers in a way in which they can’t lie to you, subconsciously or otherwise. By talking about their life, and the problems they face around your area of interest, INSTEAD of your solution, you get an unfiltered, unbiased set of feedback about what they REALLY want to have solved. And not just feedback to the idea you have presented to them, which is probably a very different thing. This is a VERY important thing to understand, especially as “no market need” is the most often cited reason for startups failing.</p>



<p>Don’t let your ego get in the way of having a successful business. <strong>Your solution isn’t more important than their problem.</strong></p>



<p>If you don’t want to spend 3 hours reading the book, spend an hour<a href="https://www.youtube.com/watch?v=FG1Fa-t4AEQ&amp;t=0s"> watching the author talk about it</a>. If you don’t want to spend an hour watching that, spend three minutes watching<a href="https://www.youtube.com/watch?v=Hla1jzhan78"> this video</a>, or reading<a href="https://medium.com/@nataliekorotaeva/how-to-talk-with-your-users-3-takeaways-from-the-mom-test-by-rob-fitzpatrick-bbeb4a93ba07"> this blogpost</a>. Ideally you’ll do all of the above, just so you fully embrace the idea.</p>



<figure><img data-attachment-id="2359" data-permalink="https://neilcocker.com/nesa-by-makers-igur1ix0mqm-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg" data-orig-size="6720,4480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nesa-by-makers-igur1ix0mqm-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=580" src="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@nesabymakers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">NESA by Makers</a> on <a href="https://unsplash.com/s/photos/startup?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>3 – Write your hypothesis. I won’t write too much here, as there are lots of great blogposts out there that do a great job of explaining good ways of nailing this. In short, you’re looking to find a hypothesis that you can test with your customer conversations. There are several different templates for this, but this is a simple one to start with. </p>



<p><em>I believe [target market] will [engage in this behaviour / use this solution] for [this reason].</em></p>



<p>You can refine this as you go along, and as you speak to customers. After all, there’s a very good chance that your research will show you that your hypothesis is wrong – and therefore you’ve just saved yourself thousands of Pounds, Dollars, or Euros, and 2 years of your life. Yay!</p>



<p>If your hypothesis is proven wrong, you can come up with a new one, and start again. </p>



<p>4 – Design a survey that is easy to distribute, and easy to fill in (multiple choice here). The idea is to capture some rough data, but mainly it’s the top of a funnel for getting people on the phone to the real interviews. </p>



<p>Here’s <a href="https://docs.google.com/forms/d/e/1FAIpQLSdSwINF3uDxeD2fx0Y5sWaX9esyrG39HzCzeXSPMcwMRo5wnw/viewform?usp=sf_link">an example of a real, live survey</a> that I’m currently using to capture data from potential customers. Feel free to steal the format, and also <strong>feel free to fill it in if you’re an early stage founder, too</strong>.</p>



<p>I’ve used Google Forms in this example, but I also heartily recommend the services of <a href="https://doopoll.co/">Doopoll</a>.</p>



<p>Make it mainly multi-choice, to make it a low barrier to people filling t in, but if you feel like you want to devote one question to free-entry, then go ahead. It can sometimes be a simple “Is there anything else you would like to tell us?” thing at the end.</p>



<p>Distribute via the usual channels, and call in favours from people who can help you reach your target market.</p>



<p>Hint – <strong>Twitter is a search engine for human beings</strong>. Want to find people interested in, for example, medtech? There’s a ton of hashtags these people will use, and that info may also be in their bio. It wouldn’t take too long to tweet a few hundred of them with a polite message, asking them to give you 2 mins of their time to fill in the survey, as they’re interested in your area of research.</p>



<p>Bonus – it’s an email list for you to approach to be your beta users once you have an MVP up and running. But, be respectful. These people gave you their time for free, so don’t just add them to a never-ending drip campaign.</p>



<figure><img data-attachment-id="2357" data-permalink="https://neilcocker.com/daria-nepriakhina-zocdwpuirua-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg" data-orig-size="4032,2688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="daria-nepriakhina-zocdwpuirua-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=580" src="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@epicantus?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Daria Nepriakhina</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>4 – Speak to the ones you have chosen. Read The Mom Test *before* you speak to them. It’ll allow you to ask questions that get to the root of the real problems they face in this area, and not just answer questions that are limited to the scope of your proposed product. In an ideal world, they’ll end the session not having a clue what your product is. It’s all about them, NOT your product.</p>



<p>I’d strongly recommend speaking to at least 25 people. Preferably more like 50. If you have chosen a well-enough defined target (and not just something vague like “car owners” or “entrepreneurs”), and you listen carefully, clear trends will start to emerge. And these may well be problems that you can solve!</p>



<p>Hint – I strongly recommend Calendly (or similar) to provide a 15 or 20-min link to your interviewees, allowing them to book the relevant slot in your calendar. This will give them confidence that you intend to honour your 15 min promise. It also keeps you concise in your questioning, and get to the point. If they’re happy to keep talking, that’s great. But don’t abuse their goodwill.</p>



<p>Finally – Fall in love with the problem, not your product. The market, in a true economic sense, doesn’t care about your product. It only cares about you being able to solve a problem. Don’t succumb to Ugly Baby Syndrome, where you have come up with an idea that you LOVE, and you’re deaf to any market signals that tell you that it’s no good.</p>



<p>I know that I’ve made this mistake in the past. To be enthusiastic, and in love with your idea is a very normal thing. And it’s particularly typical of entrepreneurs, as we’re all out trying to change the world. But we’ve been mis-sold the concept that the moment of genius, and the idea itself, is sacrosanct. But successful entrepreneurship is about a disciplined process. And validation is an absolutely vital part of it.</p>



<p>I once had the “product-first instead of problem-first” way of doing things described to me as “<strong>designing a key (product) and running around trying to find a lock (problem) that it will open</strong>“. Surely it’s much better to find a lock, study it, understand it, then design a key to open it. </p>



<p>If you’ve done all the steps above, you now understand the lock MUCH better. Go make a key to open it.</p>



<p>Update – I’ve had a few people ask for my input on their ideas. If you’d like a free mentoring session, you can <a href="https://neilcocker.com/toughquestions/">book in here</a>.</p>
			
			
			
		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://neilcocker.com/2020/08/22/my-startup-validation-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259246</guid>
            <pubDate>Mon, 24 Aug 2020 10:30:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pieter Levels Makes $600k a Year from Nomad List and Remote OK]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24259201">thread link</a>) | @Pete-Codes
<br/>
August 24, 2020 | https://www.nocsdegree.com/pieter-levels-learn-coding/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/pieter-levels-learn-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p><a href="https://twitter.com/levelsio">Pieter Levels </a>makes about $600,000 a year. He taught himself to code and has an unconventional philosophy. This is not an interview but an analysis piece. Pieter defied the critics and built Nomad List and Remote OK into successful businesses without cutting edge tools like React or other modern frameworks. I send articles like this twice a week - <a href="https://nocsdegree.carrd.co/">join 2,000 developers that get the newsletter</a>.</p><h2 id="who-is-pieter-levels">Who is Pieter Levels</h2><p>Pieter is a self-taught developer from The Netherlands. He has an MBA but no coding qualifications. As we will see in today's article he has a rough and ready approach to coding but it pays off handsomely. </p><p>His <a href="https://www.nomadlist.com/">Nomad List</a> directory and community for digital nomads draws in over $300k a year and that's despite a recent fall in revenue due to people not travelling during the Corona virus crisis. </p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.30.06.png" alt=""></figure><p>His Remote Ok job board for remote workers made <a href="https://remoteok.io/open">$300,000 over the last 12 months</a></p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.23.51.png" alt="Revenue chart for Remote OK job board"></figure><p>So that's a total of $600,00 from the last 12 months! Not bad for a self-taught developer! Pieter is active on Twitter and has a very stong following there. </p><p>As he works for himself he is able to travel extensively and live where he choses. Although, rather than the common misconception of digital nomads being constantly on the move, Pieter recommends spending a few months in each place. This way you avoid travel burnout. </p><h2 id="how-did-pieter-levels-learn-to-code">How did Pieter Levels learn to code?</h2><p>Not a lot is known about his very earlies forays into coding apart from the fact that as a teenager he played around programming. His first attempt at a web business was an analytics service for Youtube which would let you see how all your videos/channels were performing in one place. Unfortunately, he worked on it for a year without making any money from it. </p><p>From that point Pieter adopted his now familar approach to coding and business - build websites quickly and monetize from the beginning. He only adds more features if there is money coming in and the idea is validated by the market.</p><p>Pieter takes the "search on Google" approach to Google. So when he wanted to connect a database to a website or make a button do something on his website he would just search the terms on Google and find solutions in places like Stackoverflow. Pieter is a strong critic of the approach of doing courses as he believes people learn best by doing and building. </p><p>One analogy would be different approaches to learning Spanish. One person might study a course, learn the correct grammar and then go to Spain. Whereas Pieter would go to Spain, ask for the words he needs to use and go from there. </p><p>When asked in the past why he didn't use modern frameworks like React he made the point that as he was a solo founder he couldn't afford to spend time re-building his websites as this would mean his project would stall. </p><!--kg-card-begin: markdown--><p><a href="https://gum.co/GGofo"><img src="https://www.nocsdegree.com/content/images/2020/08/monetize.png" alt="monetize"></a></p>
<!--kg-card-end: markdown--><h2 id="what-technologies-does-pieter-levels-use">What technologies does Pieter Levels use?</h2><p>Pieter is famous (or infamous) for having a rather eccentric choice of stack by modern standards. It's essentially the easiest, least glamorous tools you could imagine. But that's ok because Pieter makes $600k a year! </p><p>Here is his stack:</p><ul><li>HTML (hand coded so no template to make life easier)</li><li>CSS (He has used pre-processors like LESS and SASS in the past)</li><li>Javascript (No frameworks - this is sometimes referred to jokingly as Vanilla Javascript. There is no such thing as Vanilla JS though. It's just plain-old Javascript without a framework such as React, Vue or Angular) </li><li>jQuery (An unfashionable choice nowadays but it does the job)</li><li>PHP (He doesn't use any frameworks like Laravel)</li><li>SQLite - Pieter says it's super quick and swears by it. SQLite is a database written in a single file so Pieter doesn't need to set up a server for it. &nbsp;</li><li>his sites are hosted on a single VPS running Ubuntu with NGINX.</li></ul><p>Here are some modern options Pieter doesn't use </p><ul><li>React - he jokes a lot about how he never wants to learn it due to it's (perceived) complexity. </li><li>Node - for a time he considered using it but he's never used it in production</li><li>Angular/ Vue - he doesn't use any Javascript frameworks </li><li>SQL/ Postgres - he doesn't use any of the conventional databases </li></ul><h2 id="get-a-job-without-a-cs-degree-">Get a job without a CS degree 👇</h2><!--kg-card-begin: markdown--><p><a href="http://nocsok.com/"><img src="https://www.nocsdegree.com/content/images/2020/08/Screenshot-2020-08-07-at-17.35.28-2.png" alt="No-CS-OK-screenshot-1"></a></p>
<!--kg-card-end: markdown--><h2 id="what-results-has-pieter-had-with-this-approach-to-coding">What results has Pieter had with this approach to coding?</h2><p>Despite the technical critics, Pieter has been consistently making six figures since 2014. He currently makes approximately $600,000 a year which is far more than most developers. He has been able to live in countries with a low cost of living so he will likely be able to have financial independence and not need to work relatively soon. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">📈 Record sales yesterday of $2,342.04 on <a href="https://t.co/S9Qv34rpbP">https://t.co/S9Qv34rpbP</a> for no apparent reason (maybe companies are spending their EOY HR budgets?). Normal sales is like $299 or 1 post per day. <a href="https://t.co/8HukglDuiv">pic.twitter.com/8HukglDuiv</a></p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938699122445451265?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr"><a href="https://t.co/rORz8xdCQp">https://t.co/rORz8xdCQp</a> is a single PHP file called "index.php" generating $2,342.04 in a day. No frameworks. No libraries. 💖</p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938707166508154880?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><h2 id="what-is-pieter-levels-working-on-now">What is Pieter Levels working on now?</h2><p>He just released a new project, <a href="https://remoteworkers.dev/">Remote Workers</a>, where people can post their resumé. He "built in public" - that is to say he gave daily updates of his code on Twitter. This is also a great way for developers to build an audience! You can check out what people are saying about Remote Workers on <a href="https://www.producthunt.com/posts/remote-workers">Product Hunt</a>. </p><h2 id="conclusion">Conclusion</h2><p>Pieter is like a bare knuckle boxer so don't compare him to a Judo practioner going to the Olympics. One is going to win no matter what and one is going to follow the rules they have trained under and have finer technique. Neither is better or worse. It depends on the situation. </p><p>Pieter's approach would not be good if you were trying to get a job in a lot of companies. But Pieter isn't looking for a job and the proof for him is in his bank balance. So Pieter's scrappy technique is better suited if you are attracted to coding for entrepreneurship and being a solo founder who doesn't have to share their code with others to work on. He doesn't use Github to save his code, for instance and this is an industry standard that most employers expect. If you want to be an indie hacker/entrepreneur though then Pieter is a fine act to follow. </p><h3 id="if-you-enjoyed-this-article-please-send-it-to-a-friend">If you enjoyed this article please send it to a friend </h3><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="and-you-should-totally-sign-up-for-the-newsletter">And you should totally <a href="https://nocsdegree.carrd.co/">sign up for the newsletter</a> </h3>
                    </div>
                </section></div>]]>
            </description>
            <link>https://www.nocsdegree.com/pieter-levels-learn-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259201</guid>
            <pubDate>Mon, 24 Aug 2020 10:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of webpage speed, or throwing away React]]>
            </title>
            <description>
<![CDATA[
Score 343 | Comments 286 (<a href="https://news.ycombinator.com/item?id=24258855">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
  <p>Back in 2011, I happened to get a job writing <a href="https://backbonejs.org/">Backbone.js</a> app. If you never did that, don’t. I was complaining about difficulties with composition left and right to whoever would listen. As I started digging into alternatives for the front-end, I discovered <a href="https://en.wikipedia.org/wiki/Functional_reactive_programming">FRP</a> and <a href="https://www.flapjax-lang.org/">Flapjax</a>, and <a href="https://clojurescript.org/">ClojureScript</a>. The last one got me hooked on <a href="https://clojure.org/">Clojure</a>. I even did a <a href="https://fwdays.com/event/js-frameworks-day-2013/review/Functional-Reactive-Programming-&amp;-ClojureScript">successful talk</a> on FRP and ClojureScript (and precursor to <a href="https://hoplon.io/">Hoplon</a>, called hlisp).</p>
<h2 id="react">React</h2>
<p>Then in May 2013 React was released. I championed it on my new job and discovered during Clojure-themed hackaton (<a href="https://solovyov.net/blog/2013/clojurecup/">Clojure Cup 2013</a>) that CLJS and React are a great match. What’s so good about React though? To me, the main selling point is that it composes well.</p>
<p>When you use predecessors like jQuery or Backbone or Angular or whatever after just a year of development your code is a mess of event listeners and triggers. Don’t get me started on unobtrusive JS, code locality is non-existent with jQuery. Which handler is bound where and what it does? It’s too hard to discover to be a good base for a good codebase!</p>
<p>Then I started working at <a href="https://kasta.ua/">Kasta</a>, where web frontend was exactly that jQuery-ish mess. Nobody ever wanted to touch checkout, since you could spend hours, if not days, making the smallest change. Then QA would find more invalid states than you can dream of. And then users would report more bugs to our call center. It was just as awful as you can imagine.</p>
<p>So after some experiments, tests, and checks, I decided that we’re going React + ClojureScript way with server-side rendering done in Clojure.</p>
<h2 id="demise">Demise</h2>
<p>And for a while, things were looking good. We had this <a href="https://solovyov.net/blog/2017/server-side-rendering/">architecture</a> where our components are executed as Clojure on the backend, so no Node.js on the server, hurray! And developer UX is through the roof with the excellent live reload (thanks CLJS), ability to connect from your editor to browser REPL, and experiment there. It is just great!</p>
<p>To make a long story short, our frontend grew bigger and bigger. Incremental compilation started to become slower — it now routinely takes more than a second or two. And while there were few attempts on keeping the whole app performant, ultimately we failed. It’s a death by a thousand cuts. The application became too big and its boot time became too long. Server side rendering helps partially, but then hydration freezes the browser. On the older hardware or Androids it became unacceptable!</p>
<p>One of the main reasonings back in 2016 was that we take a hit on startup time, but in turn, get no page loads and have a rich web application with a lot of interactions. And for a while that worked! But startup time became longer and longer, leading to a shameful rating of 5/100 from Google’s PageSpeed (okay, it was sometimes up to ~25/100, whatever).</p>
<p>More than that, while doing what is described below, we’ve discovered that React also leads to some questionable practices. Like hovers in JS (rather than in CSS), drop-down menus in JS, not rendering hidden (under a hover) text (Google won’t be happy), weird complex logic (since it’s possible!), etc. You can have a React app without those problems, but apparently, you have to have better self-control than we had (nobody’s perfect!).</p>
<p>Also since then, the vast majority of our users switched to mobile apps. This made the web app the main entry point for new users. This means its main goal is rendering fast for a newcomer, because old-timers, which want more functionality, are on mobile app now. And <a href="https://web.dev/tti/">TTI</a> (time to interactive) is so much more important here.</p>
<h2 id="time-for-a-change">Time For A Change</h2>
<p>So given that circumstances have changed, what do we do? I read articles “how I survive on vanilla JS” since before React appeared and they usually don’t make sense — it’s either a pink-glassed rant about how great it is, disregarding all the problems (separation of concerns, cohesion, composability, code locality) or a project by one (or few) persons, who just keep everything in their head.</p>
<p>Somewhere back in February I stumbled upon <a href="https://intercoolerjs.org/">Intercooler.js</a>. I’m not sure if I ever saw it before — maybe I did but skimmed over — it does not matter. This time it captured my attention.</p>
<p>The idea is that all HTML is rendered on the server. And client updates parts of HTML, controlled by element’s attributes. Basically like HTML+XHR on steroids. You can’t do anything you want, but that’s partially the point: some limits are good so you won’t do crazy stuff. And you need some support from the server, so you can render partial results — just an optimization, but quite an important one.</p>
<p>There is an alternative library — <a href="https://unpoly.com/">Unpoly</a>. It has more features around layout and styling but has a little bit less thought out XHR stuff (hard to do a POST request with parameters without having a form, for example). And the library size is much bigger. And it’s written in CoffeeScript with lots of classes, <a href="https://solovyov.net/blog/2020/inheritance/">ugh</a>.</p>
<p>So I made a proof-of-concept implementation of our catalogue page in Intercooler and it worked! Except there was a dependency on jQuery and some other irritating stuff… As I was struggling to make a batch request for HTML fragments I understood one thing: when I wrote down a roadmap for catalogue the last point was “small intercooler-like thing for analytics”.</p>
<p>So why wait?</p>
<h2 id="twinspark">TwinSpark</h2>
<p>I liked Intercooler’s coherent approach to working around AJAX, so I decided to name the library after some automotive stuff as well, and TwinSpark seems like an appropriate name. So what’s the deal?</p>
<p><a href="https://github.com/kasta-ua/twinspark-js">TwinSpark</a> is a framework for declarative HTML enhancement: you put additional attributes on your element and TwinSpark does something with them. Like makes an AJAX call and replaces target with a response, or adds a class, or… well, see <a href="https://kasta-ua.github.io/twinspark-js/">examples</a>, shall you?</p>
<p>There are some differences with Intercooler, of course, because why would it exist? The most noticeable one is that there is no dependency on jQuery. It supports only modern browsers (not IE or Opera Mini) but drops that 88kb monster.</p>
<p>It also has:</p>
<ul>
<li>no inheritance — can’t stress that enough!</li>
<li>clear extension points for your directives</li>
<li>support for batching requests to a server</li>
<li>tighter attribute name convention (my own opinion, but <code>ic-get</code> and <code>ic-post</code> irritate me: do not make me change keys!)</li>
<li>much smaller payload (thanks to no jQuery!)</li>
<li>should be faster (thanks to no jQuery again)</li>
</ul>
<p>Honestly speaking, the main reasons are <a href="https://kasta-ua.github.io/twinspark-js/#batch">batching</a> and <a href="https://solovyov.net/blog/2020/inheritance/">no inheritance</a>. Inheritance is particularly painful here. In Intercooler, if you declared <code>ic-target</code> on the body, all tags inside will think it’s their target too. So you include a component somewhere in HTML tree and an attribute higher on tree changes this component behavior. I mean this is a freaking dynamic scope, I want none of that! :)</p>
<p>Funnily enough, after about a month of dabbling with TwinSpark, Intercooler’s author announced that he’s doing a jQuery-less modern version: <a href="https://htmx.org/">htmx</a>. :) It has really good extensions points, so maybe it’s possible to add batching… but inheritance is still there. :-(</p>
<h2 id="why-is-that-a-good-idea">Why is that a good idea</h2>
<p>We need to look at it from two sides: if it’s good for developers and if it’s good for users. React was great at former and terrible at later.</p>
<p>TwinSpark approach is much better in most cases for the user: less JavaScript, less jitter, more common HTML-like behavior. In the worst case, we would serve you 2.5MB of minified (non-gzipped) JS and 700KB of HTML (half of it were initial data for React) for catalogue. JS bundle is not that big because of embedded images or css or some other obscure stuff, it’s big because it’s the whole app, with a lot of views and logic.</p>
<p>Now it’s 40KB of minified non-gzipped JS (TwinSpark, analytics, some behavior, IntersectionObserver polyfill) and 350KB of HTML. Two orders of magnitude difference and even HTML is smaller! This is just like Christmas in childhood!</p>
<p>On the developer side, I think React is better still, but code locality is great, composability is much better (since you are forced in a limited world of working in a simplistic model) than with jQuery. Plus there are a lot of ways to improve it.</p>
<p>The good news is that the development process did not change that much! We’re still writing components that query necessary data from site-wide memory store (and make a call to API when needed), but they are executed only on the server. We effectively piggy-backend on our previous architecture, and this gives us the perfect ability to render “partial” HTML - since components do not wait for some “controller” to give them all necessary data. This is what allowed us to have both React and non-React versions to co-exist and make an A/B test without writing the markup twice.</p>
<h2 id="results">Results</h2>
<p>It took us four months since the first experiments to release. Not exactly the amount of time I imagined when we started (“should take two to three weeks at most!"), heh, but we were not exclusively doing that. It still took a lot of time and energy to remove React-isms from the code and wrangle our app to be a server-side citizen. It still could use some polishing, but we decided to release it despite that just to cut it short. And A/B test showed that we were right — especially for Android phones.</p>
<p>Google gives our catalogue 75/100 now instead of 5/100. Hurray, I guess? :)</p>

  </section></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258855</guid>
            <pubDate>Mon, 24 Aug 2020 09:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The GemRB project celebrates 20 year anniversary with a new release]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24258780">thread link</a>) | @Lightkey
<br/>
August 24, 2020 | https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html | <a href="https://web.archive.org/web/*/https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p>The GemRB team announces the availability of GemRB 0.8.7, a new minor release to kick off
a week of celebrations of the project’s founding anniversary. 20 years ago, on the 21st of
August, the project initiator Daniele Colantoni registered it on SourceForge to try to make
it a team effort. Many things have happened since, the path was convoluted and bumpy, but
GemRB has continued to grow throughout the years.</p>

<p>GemRB is a portable free/libre open-source implementation of Bioware’s Infinity Engine, which
powered classic CRPGs like Baldur’s Gate, Icewind Dale and Planescape: Torment. The goal of
the project is to make these games available on a wide range of platforms forever, fix or avoid
old bugs, add new features and provide a superb platform for mod (and eventually game) development.</p>

<p>It was started 20 years ago by a student fresh out of town, Daniele Colantoni:
<em>“I missed playing D&amp;D with my friends so much /…/ I wanted to create my game to play
via internet. So I started my personal reverse engineering process on the base files
from Baldur’s Gate.”</em></p>

<p>Predictably it turned out to be much more complicated and time consuming than first
imagined, but the effort continued. From its Windows-only 32-bit beginnings GemRB was
made to run on all common and many niche platforms (from AmigaOS to IRIX and Symbian;
x86 to PPC, ARM, MIPS and WebAssembly). This was largely made possible through use
of open source libraries that are themselves very portable (SDL, OpenAL, libpython, zlib).
Without an open development model and supporting infrastructure, the project would have
never succeeded.</p>

<figure>
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2-kuldahar-gem.jpg" title="IWD2 remains to be fully understood">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2-kuldahar-gem.jpg" alt="IWD2 GemRB battle screenshot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/10pp6.jpg" title="Larger player parties is one of the most popular features">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/10pp6.jpg" alt="10pp6.jpg">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2stylecombat2.jpg" title="IWD2-style combat output">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2stylecombat2.jpg" alt="IWD2-style combat output">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/goi.jpg" title="Glory of Istar game shot">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/goi.jpg" alt="Glory of Istar game shot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/sorcerer_monk.jpg" title="Sorcerer/monk multiclass">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/sorcerer_monk.jpg" alt="Sorcerer/monk multiclass">
      </a>
    
  
    
      <a href="https://lynxlynx.info/bugs/mushroom.madness.jpg" title="Sometimes things go hilariously wrong ...">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/fonts.png" alt="Sometimes things just go wrong ...">
      </a>
    
  
  
    <figcaption>Various screenshots.
</figcaption>
  
</figure>

<p>The engine can be used to play the full Baldur’s Gate saga, the first Icewind Dale and
Planescape: Torment. The latter requires more reverse engineering and polishing, but
one can finish the game already. Icewind Dale 2 is a different matter — while it
appears more polished than Torment, only the first two chapters of the game are
playable.</p>

<p>As GemRB marks its 20th anniversary, Jaka Kranjc, the current maintainer, is optimistic about
the project’s future. <em>“Our work is not finished, but this sort of thing is like an
ultramarathon — for most of the run the goal is not within reach. Companies come and go, but
FLOSS persists!”</em></p>

<p>The <a href="https://gemrb.org/2020/08/24/gemrb-0-8-7-released.html">new release</a>
brings over 500 changes manifested as bugfixes, smaller features, cleanups
and an improved setup experience. More than that, it introduces a new <a href="https://gemrb.org/2020/07/16/new-pathfinder-smarter-movement.html">smarter
pathfinder</a> with
bumping support and other movement related improvements. At the same time work continued
on the drawing and GUI handling rewrite — stay tuned for a deeper dive later this week.
With this anniversary release out of the way, finishing that rewrite is again the team’s
main priority.</p>

<p>Overall it’s clear that after all this time the GemRB effort is still active, slowly building
missing pieces of the Infinity Engine mosaic, revitalising older code, extending features and
working throughout the project to keep the effort vibrant for years to come. The team is
looking for <a href="https://github.com/gemrb/gemrb/blob/master/CONTRIBUTING.md">new contributors</a>,
especially programmers with OpenGL experience, who could help them finish a drawing backend
refactoring — for better performance and to remain available on a wide berth of platforms.</p>

<p>A pearl to you!</p>

<p><em>PS: check our news section in the following days for a daily retrospective with past maintainers and a look into the project’s future.</em></p>

<hr>
<p>Project links:</p>
<ul>
  <li>Web site: <a href="https://gemrb.org/">https://gemrb.org</a></li>
  <li>Downloads: <a href="https://gemrb.org/Install">https://gemrb.org/Install</a></li>
  <li>News: <a href="https://gemrb.org/News">https://gemrb.org/News</a> (RSS available)</li>
  <li>Screenshots: <a href="https://gemrb.org/Media">https://gemrb.org/Media</a></li>
</ul>

<p>If you want to be notified of further releases, subscribe to
<a href="https://sourceforge.net/projects/gemrb/lists/gemrb-release">gemrb-release</a> (low volume).</p>

<p>If you <em>need</em> to get in touch via email, write to &lt;registracije+gemrb20@lynxlynx.info&gt;.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258780</guid>
            <pubDate>Mon, 24 Aug 2020 09:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing Teams Through Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24258519">thread link</a>) | @jstanier
<br/>
August 24, 2020 | https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/ | <a href="https://web.archive.org/web/*/https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary" role="main">
		
<article id="post-1410">

			<!-- end .entry-header -->

		<div>
		
		<div>
			
<p><em>This article is part of a </em><a href="https://www.theengineeringmanager.com/managing-managers/"><em>series on managing managers</em></a><em>.</em></p>



<p>Making the switch to managing managers, and hence managing many teams, can be taxing on the brain. If you’ve not done it before, then you may look at others in more senior roles, potentially running organizations of hundreds of people, and wonder to yourself how they ever find any clock time or mental time for getting anything done.</p>



<p>If you’re used to running one team, that’s a reasonable thought to have. After all, running a team is a tough job. It involves balancing your time between managing others and making your own contributions, working with people outside of your team, deeply understanding the personalities and desires of your staff, and, of course, let’s not forget the most important thing: shipping software.</p>



<p>When viewed through this lens, the thought of having multiple teams may seem quite overwhelming. How are you meant to carry everything in your head that you did before, but at many times the scale? Well, the answer is that you <em>shouldn’t have to</em>. That’s exactly why you have managers reporting to you, which allows you to work at a higher level of abstraction.</p>



<p>Working at this higher level of abstraction allows you to focus your efforts on what’s important; whether that importance manifests in the <a href="https://www.theengineeringmanager.com/managing-managers/vp-director-what/">operational running of work streams or strategic planning for the future</a>. It allows you to step back and to focus your energy where it pays the greatest dividends: the outputs of tens, if not hundreds, of people.</p>



<p>Since those that read this website typically have a background in writing software, I’ll lean on a software engineering analogy in order to explain how you use your managers to work at this higher level of abstraction. We’re going to be looking at the interface between yourself and your managers by looking at, erm, <strong>interfaces</strong>. How handy.</p>



<h2>Interfaces</h2>



<p>The programming language that I have the most experience in is Java, so I’m going to lean on it for this particular analogy. An interface in Java, like in other languages, is a type that allows you to define abstract methods that other classes must have if they implement that interface.&nbsp;</p>



<p>So, for example, you may define an interface for a CurseGenerator:</p>



<pre><code>interface CurseGenerator {
  public String curse();
}</code></pre>



<p>Of which we could then implement a British version:</p>



<pre><code>public class BritishCurseGenerator implements CurseGenerator {
  public String curse() {
    return “Oh, bloody hell!”;
  }
}</code></pre>



<p>An interface allows extensibility in software systems because a particular piece of code can work with any class that implements a given interface, since the interface’s methods are checked to be present in the implementing class at compilation time.&nbsp;</p>



<p>Most importantly,&nbsp;the code that works with an interface <em>does not need to know the details of the implementation</em>.<em> </em>The implementing class can do whatever it wants as long as it abides by the contract of the method signatures. The interface <em>delegates </em>the implementation to the implementing class. </p>



<p>Do you see where this is going? I’m sure you do. Back to the management analogy:</p>



<ul><li><strong>As a manager of managers, you define what the interface that represents each of your teams looks like.</strong> For example, you may define particular measurements that are important, such as KPIs like application uptime, daily active users, and so on. You may also require that your managers hold weekly one to ones with each of their staff, write a report on progress to the rest of the company every two weeks, or to fix critical priority bugs in one business day.</li><li><strong>Each of your managers has the flexibility of deciding exactly how those teams are run, as long as they follow the interface contract.</strong> So the way in which they decide to tackle improving the uptime percentage or the number of daily active users is entirely up to them. Which member staff works on which part of the codebase is down to them and the team. How and when they schedule their one-to-ones and the content that they discuss is for them to decide. But fundamentally, they should be done to abide by the contract of the interface.</li></ul>



<p>Clear interfaces allow you to not have to worry about the exact implementation details of how each of your managers run their teams, but they allow you to make it clear <em>exactly what you expect of each of them in doing so, and therefore how you define success</em>. OK, I’ll stop the programming analogy now.</p>



<h2>Defining the interface</h2>



<p>So you start by defining that interface with each of your managers. There’s a neat exercise for your first one-to-one meetings (although you can do it at any time) called <a href="https://www.theengineeringmanager.com/management-101/contracting/">Contracting, that I’ve written about before</a>. You can expand on that Contracting exercise by having you both think about the answers to the following questions, which make up the interface:</p>



<ul><li><strong>What success looks like for the team.</strong> What measurements are being used to prove that the team is being successful? Is it working towards an outcome, or some KPI, or shipping particular projects on time? Does it also take into account the happiness, productiveness and psychological security of their staff? How will this information be gathered and made accessible to you?</li><li><strong>Which processes will be used to run the team.</strong> In order to be successful, how are they going to compose themselves? Will they use scrum, kanban, just get on with it, or something else? How do they intend to ship to production regularly? How will they prioritize and execute on their work? Each team of yours may operate differently depending on the skills and seniority of the people on each.</li><li><strong>How the manager interfaces with each of their own staff.</strong> They’ll need to think about the different personalities, skills and career development trajectories for each of their staff and consider what that means for how each of them can operate with autonomy, mastery and purpose. What is an acceptable cadence for one-to-ones? Do they prefer synchronous or asynchronous communication?&nbsp;</li><li><strong>How will you know if something is going wrong? </strong>Code throws errors or performs slowly, bringing problems to your attention. How will issues with the team be made visible so you can work on them together?</li><li><strong>Whether you’d occasionally like to inspect the implementation yourself.</strong> Although defining an interface is meant to hide the complexity from you, occasionally it’s interesting to look under the hood and see what’s going on there. You might have some suggestions to make it better, or you may even learn something new. You can arrange a cadence for skip-level meetings, occasionally pop-up in their group meetings to listen, and get feedback from the individuals and the team as a whole.</li></ul>



<p>With a little work up front on the interface, you can make it absolutely clear at what level of involvement you both feel comfortable with having in your relationship. This allows you to abstract away from issues you don’t need to know about as a manager of managers, and gives your direct report the freedom to run the team how they want, as long as the fundamentals that you expect are being implemented. And that’s great, because you can build a great coaching relationship from that foundation, rather than being at risk of micromanaging or firing and forgetting.</p>



<h2>Debugging problems</h2>



<p>Occasionally things will go wrong, as they do in code. You may need to get the debugger out to see what’s going on. But that’s OK, since you’ve already discussed the interface between you, your direct report, and their team. That interface gives you a number of methods to attach your debugger to.</p>



<p>Perhaps if the team’s cadence is slowing down, you can dig deeper into the processes that are being used to run the team. How often are they shipping? If that’s not very often, why is that? How does code get written, reviewed and deployed? You can keep <a href="https://www.theengineeringmanager.com/growth/first-principles-and-asking-why/">asking why</a> in order to get to the bottom of quirks that might be bugs. And then you can fix them together.</p>



<p>Sometimes it’s interesting to attach the debugger out of pure curiosity. You can do this in your one-to-ones with your direct report. Focus on one area of your interface and go deep into the implementation by asking questions. You’ll always find something worth discussing, and often there’s some neat performance optimizations to try out.</p>



<h2>Beginning with the end in mind</h2>



<p>So why have interfaces?&nbsp;</p>



<p>The ideal end state is that you have clear expectations and boundaries between yourself and the managers that are reporting into you. When you’ve made it clear which high-level functions that each of your managers should be performing, you can delegate the implementation to them so they can do so in whichever way they feel is best for them and their team.</p>



<p>This allows you to move away from details that you don’t need to spend your time focussing on, enabling you to work at a higher level of abstraction. If you were programming, this abstraction would allow you to concentrate on making the system surrounding the interface more efficient, extensible, performant and elegant. That’s exactly what you’ll be wanting to do with the organization, structure and strategic direction of teams as well.</p>



<p><a href="http://eepurl.com/cSMExr">You can sign up to my mailing list to hear when new posts are published.</a></p>
					</div><!-- end .entry-content -->

			</div><!-- end .entry-wrap -->

</article><!-- end .post-1410 -->
	<!-- #comments .comments-area -->
	</div></div>]]>
            </description>
            <link>https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258519</guid>
            <pubDate>Mon, 24 Aug 2020 08:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apparatus with Magnets]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24258396">thread link</a>) | @jiriro
<br/>
August 24, 2020 | https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e | <a href="https://web.archive.org/web/*/https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258396</guid>
            <pubDate>Mon, 24 Aug 2020 07:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM 5160]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24258010">thread link</a>) | @hwdegroot
<br/>
August 23, 2020 | https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/ | <a href="https://web.archive.org/web/*/https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <div>
            <blockquote>
<p>640 Kilobytes!!!!1!!1 I shit you not. That is like 10 times the size of Donald Trump’s brain.</p>
</blockquote>
<p>Recently I was trying to get my son enthousiastic for programming. He is currently 7 years old and getting interested in all kinds of electronics,
so I thought that getting acquainted with programming would not hurt him. And I like to think of myself as a parent that stimulates his kids, so I used that
as an excuse to look into older computers, because <em>nostalgics</em>.</p>
<p><a href="#show-me-the-pics">Show me them footage</a></p>
<p>My kids grew up with LED monitors and TV’s and never really saw a real cathode tube, except on the episodes of <a href="https://en.wikipedia.org/wiki/Pat_%26_Mat">Pat &amp; Mat</a>.
I still remember the soft fading sound of of the tv turning off and the graphics vanishing into this thin line.</p>



<figure id="6fe72747c83aa07dbdebd9927f00a3d7">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/mesmerizing-shutdown.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Mesmerizing shutdown. The terminal vanishes into a line.

        </small>
    </figcaption>
    
    </p>
</figure>


<p>Besides that, I am a fan of clicky keyboards. I have a <a href="https://www.daskeyboard.com/daskeyboard-4C-ultimate/">DasKeyboard 4C ultimate</a> tenkeyless with Cherry Blue switches and a <a href="https://www.daskeyboard.com/daskeyboard-4C-tenkeyless-professional/">4C Profressional</a> with brown switches. Sitting at home during the
corona period, made me google old skool stuff a lot.</p>
<p>So first I laid my eyes on a <a href="https://clickykeyboards.com/product/ibm-model-m2-1395300-made-by-ibm-06-30-1993/">IBM Model M2</a> and got this pretty cheap on
the dutch eBay. Getting this to work on my modern laptop was not rocket science, but not straight forward either. I warned my collegues
that the quiet days at the office were over. But this also opened up a window into vintage computers and computing. What if I could get a vintage computer, I thought. How awesome would that be?</p>
<p>How cool would it be to program a vintage computer with my collegues, or my kids. With all the speed we get nowadays, who still thinks about the limits of computing power. This will be totally different if you have just a fraction of the memory and chip available.</p>
<h2 id="ibm-5160">IBM 5160</h2>
<p>I am from 1983. So I was looking for a computer from that year. IBM was <em>the company</em> in those days for personal computing and when it came to makeing PC’s (I am NOT an apple fan). So I found that IBM produced the <a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer_XT"><strong>IBM PC XT</strong></a> in that year. I also found out that you could still get them online for a reasonable price.
Luckliy I was able to lay my hands on one, in a pretty good state. It came with an <a href="https://clickykeyboards.com/product-category/1986-1989-ibm-model-m-silver-label/">IBM Model M</a> keyboard with the silver label (the PC is from 1986). The sound of that is even better than than the <code>Model M2</code>.</p>


<figure id="c1eacc927bc26694d18237b77c9b6c5e">
    <p><audio controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/audio/IBM-model-m-oh-that-clicky-sound.mp3" type="audio/mpeg">
            Your browser does not support the audio tag.
        </audio>
    </p>
    
    <figcaption>
        <small>
            
Need I say more...

        </small>
    </figcaption>
    
</figure>


<p>After introducing my kids to th <code>DIR</code> command (it was the only one I was pretty sure about it would work), they wanted to type “words” on the old computer (first success).</p>
<h2 id="exiting-vim-is-hard">Exiting Vim is hard?</h2>
<p>So, I know the <code>DIR</code> command. But now what. Let’s see what commands are available.</p>
<ul>
<li>No tab completion. <code>TAB</code> just places the cursor somewhere down the line</li>
<li>No <code>HISTORY</code>. You can repeat the last command by pressing the right-arrow.</li>
</ul>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>This is incorrect. You say that you have IBM PC DOS 5. If so, this includes the DOSKEY command. This will give you a command-line history with editing. Just type <code>dos\doskey</code> to load it.</p>
</blockquote>
<p>For a starters, on <code>IBM DOS</code> (version 5.0) there is no <code>$PATH</code>. The executables are located in <code>C:\DOS</code> (or <code>c:\dos</code>, because <code>DOS</code> don’t care about casing). the most executables are located. After a day or two I figured this out, so I finally managed to open my first <code>BASIC</code> program. All fine, until I wanted to quit the program. It’s not that easy as <a href="https://stackoverflow.com/questions/11828270/how-do-i-exit-the-vim-editor">exiting <code>Vim</code></a>. It took me quite some time googling, until I finally found this <a href="https://stackoverflow.com/questions/44253055/how-can-i-exit-microsoft-gw-basic-ibm-basica-or-other-similar-old-dialects-of">lifesaver</a>.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>There certainly should be! DOS has 2 configuration files, which live in the root directory of the boot drive (A: or C:). They are called [1] CONFIG.SYS and [2] AUTOEXEC.BAT. In the 2nd, there should be a line:
<code>PATH=C:\DOS; C:\</code></p>
</blockquote>








<figure id="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen_hu03af1e9e4264eec2575cd1ba06f1e20e_255454_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Entering BASIC is peanuts

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><span id="close-1fadd62c83243e573af5941d4eb32c02">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic_hu7173749eb1353b22f37803cfee1222d6_251610_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Stuck in BASIC

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><span id="close-0e171f24d2705fcfc1f3dddef5ea66e3">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic.jpg" width="4032" height="3024"></p>
    </div>
</div>





<figure id="34bf581ec5de30d29fb4a52465d157a0">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/trying-stuff-in-qbasic.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    
    
    <figcaption>
        <small>
            
Trying to exit QBASIC. Epic fail

        </small>
    </figcaption>
    
    </p>
</figure>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>That is <em>not</em> <code>QBASIC</code>; <code>QBASIC</code> has a GUI. You were in either <code>BASICA</code> or <code>GWBASIC</code>. The command to quit is <code>syst em</code>, if I remember correctly after 30 years.</p>
</blockquote>
<p>So, now I can start a few commands, but getting all available commands is not that straight forward. There is a lot in the <code>DOS</code> directory, but there is no scrolling, and the monitor only is 25 lines.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>Yes there is [scrolling]. Type <code>dir /p</code> for page-by-page. <code>dir /w</code> gives a wide listing. You can combine these: <code>dir /w /p</code>. You can also do <code>dir | more</code></p>
</blockquote>
<blockquote>
<p>[the monitor is only 25 lines] This depends on the graphics card. If you have an MDA card, no, 25 lines is all. Try <code>mode con: lines=43</code> or <code>mode con: lines=50</code>. This will only work on a VGA-compatible card, though, and you will need ANSI.SYS installed, I think.</p>
</blockquote>
<p>So figuring out the available commands is using a lot of <code>DIR *.EXE</code>'s and <code>DIR *.COM</code>'s.</p>
<p>First class fun.</p>
<h2 id="show-me-the-pics">Show me the pics</h2>
<p>Not so long ago I was explaining my collegue (who is using a screensaver), <a href="https://en.wikipedia.org/wiki/Screensaver">where a screensaver got its name from</a>. Back in the days, when we were all running the <a href="https://www.youtube.com/watch?v=Uzx9ArZ7MUU">pipes</a> so the screen would not <span>fuck up</span>
.</p>
<p>But now, sit back and relax…</p>



<figure id="f3b027a374567777bfd8178001360334">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/insane-refresh-rate-oldskool-monitor.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Check this insane refresh rate of the cathode tube. The color of the terminal is magnificent! 😍

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="4cdf95e55b8fbd6e1c5e3ea1f0bd43bf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/more-refresh-rate.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
And more refresh rate. The mesmerizing fading away of the fonts into the background. Beautiful, just beautiful

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="6f82255ebe285b0963065fc046514bcf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 The startup is amazing as well. The sound of the fan, and the nostalgic beep.

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="43c3937b62bdb5325a2b1a8a57bc530d">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos-again.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 One more time. I could loop this forever.

        </small>
    </figcaption>
    
    </p>
</figure>










<figure id="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch_hu3a6de3285dc77b6df0e675474f4c7576_447189_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
un DOS tres. The fluorescence is soooo pretty.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><span id="close-01da5907dc0ec7a58dc42ca82d974286">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file_hu5af41f7c240e39ab901ff694320d0a39_288464_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
wppreview, I totally miss the point of this program. But, hey, it's there.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><span id="close-69f512f8bcce7a3b38b62b31e321231a">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file.jpg" width="4032" height="3024"></p>
    </div>
</div>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It [wppreview] is not part of DOS. Sounds like a WordPerfect preview program for use with mailmerge.</p>
</blockquote>
<h2 id="what-next">What next?</h2>
<p>So far I had to explain to my son what a <code>file(name)</code> and a <code>command</code> is (when they were typing “words” the IBM kept returning</p>
<p>So the experience is already educational :)</p>
<p>To be honest, I do not have a clear idea what I am going to do with it next. I will be playing with it for a while like an 8 year old with his trains.
After the <a href="https://twitter.com/hashtag/stayathome"><code>#stayathome</code></a> is over, hopefully I can take it to the office, so we can start doing real cool things with it.</p>
<p>I will definitely have to up my <a href="https://www.qb64.org/wiki/GOTO"><code>GOTO</code></a> skills :)</p>
<p>I will start using my Model M2 for work (sorry collegues), for sure. I will have to remap my function key in <a href="https://i3wm.org/"><code>i3</code></a>, because I am currently using the
windows key for this. But the Model M2 does not have one. But I will overcome.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It is easy to remap CapsLock to be a “Windows” (Super) key. This is how I use my IBM Model M in Linux. I suggest <code>xmodmap</code>.</p>
</blockquote>
<p>Besides that, I found this great archive with <a href="ihttps://archive.org/search.php?query=dos%20ibm">manuals</a> and <a href="http://www.retroarchive.org/dos/disks/">bootdisks</a> and even <a href="https://winworldpc.com/download/40c2a543-4218-c39a-11c3-a4e284a2c3a5">PC DOS 5.02</a>. Currently I am trying to get a VM up running PC DOS 5.0 (yes, that is possible in <a href="https://www.youtube.com/watch?v=xfjUkJMe_kw">virtualbox</a>)</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>If you are willing to change the DOS version, I suggest DR DOS 3.41. The reason is this: MS/PC DOS 5, 6 &amp; later are designed for 386 memory management. This is impossible on an 8088 chip, and as a result, you will have very little free memory. Many DOS programs won’t work.</p>
</blockquote>
<blockquote>
<p>DR-DOS is a better 3rd party clone of DOS, by the company that wrote the original OS (CP/M) that MS-DOS was ripped-off from. The first version is 3.41 (before that it had different names) and it is far more memory-efficient. <a href="https://winworldpc.com/product/dr-dos/3x">https://winworldpc.com/product/dr-dos/3x</a></p>
</blockquote>
<blockquote>
<p>But if you want to stay with an IBM original DOS, then IBM developed PC DOS all the way to version 7.1, which supports EIDE hard disks over 8GB, FAT32 and some other nice features. It is a free download.</p>
</blockquote>
<blockquote>
<p>I have described how to get it here: <a href="https://liam-on-linux.livejournal.com/59703.html">https://liam-on-linux.livejournal.com/59703.html</a></p>
</blockquote>
<blockquote>
<p>PC DOS 7 is a bit strange; IBM removed Microsoft’s GUI editor and replaced it with an OS/2-derived one called E, which has a weird UI. IBM also removed GWBASIC and replaced it with the Rexx scripting language.</p>
</blockquote>
<blockquote>
<p>Personally, I combine bits of PC-DOS 7.1 with Microsoft’s editor, Microsoft’s diagnostics, Scandisk disk-repair tool and some other bits, but that is more than I can cover in a comment!</p>
</blockquote>
<blockquote>
<p>There is a lot you can do to upgrade a 5160 if you wish. Here is a crazy example: <a href="https://sites.google.com/site/misterzeropage/">https://sites.google.com/site/misterzeropage/</a></p>
</blockquote>
<blockquote>
<p>I would not go that far, but a VGA card, VGA CRT, a serial mouse and an XTIDE card with a CF card in it, and it would be a lot easier to use…</p>
</blockquote>
<p>The downside, my Cherry MX blue switches feel like second class now.</p>
<h2 id="update">UPDATE</h2>
<p>When I was installing my VM with <code>PC DOS</code>, at the end of the installation I was aske if I wanted to start in <code>shell</code> mode. It turns out there is a command <code>DOSSHELL</code> (needs to be executed fron <code>C:\DOS</code>) which gives you a very fancy
gui.</p>








<figure id="8a76cf6b5c012a99a1bf166c516671c4">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/dosshell_hu8b1374a2b83ba8d4970af29e66446ddf_361223_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
😱 It …</small></figcaption></div></figure></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</a></em></p>]]>
            </description>
            <link>https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258010</guid>
            <pubDate>Mon, 24 Aug 2020 06:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GCD and the magic of subtraction]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24257871">thread link</a>) | @plumsempy
<br/>
August 23, 2020 | https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/ | <a href="https://web.archive.org/web/*/https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1295">

	

	
			<figure>
				<img width="1229" height="727" src="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1229" alt="" loading="lazy" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png 1229w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1024 1024w" sizes="(max-width: 1229px) 100vw, 1229px" data-attachment-id="1315" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-4/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png" data-orig-size="1229,727" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 4" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>The greatest common divisor is something I learned in school but it was one of those “so what?” subjects. But recently I revisited it and it is very interesting.</p>



<p><strong>Why is gcd cool?</strong></p>



<p>Every number, can be expressed as the product of prime numbers. This product for every number is unique; sort of like saying, every number has a fingerprint. This is called the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">fundamental theorem of arithmetic</a>. 36 is <code>4x9</code>, and 45 is <code>5x9</code>. This means that some numbers will have common parts with each other.</p>



<p>These common parts can divide both numbers, and thus they are common divisors. In the example above, 36 is <code>4x9</code> or <code>2x2x3x3</code>, while 45 is <code>5x3x3</code>; 3 is a common divisor of both, so is <code>3x3</code>, which is 9; but 9 is the greatest divisor of both 36 and 45.</p>



<p>One question I had when I was younger, was why we are talking about the “greatest” and not the smallest common divisor. We could, but soon, this gets boring: there is 1, the smallest common divisor of every number, then there are some common divisors in between 1 and the gcd. But what the gcd does so uniquely, is that it takes two numbers and gives us <em>all</em> the common parts of two numbers. </p>



<figure><img data-attachment-id="1328" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-1-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png" data-orig-size="1150,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 1" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png 1150w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>common and uncommon parts of 36(4×9) and 45(5×9). The gcd of 36 and 45 is 9.</figcaption></figure>



<p>This is cool! The uncommon parts are relatively prime! — meaning, they have nothing in common but the number 1. </p>



<p>So to find the gcd, then, we need to find all the common parts of the two numbers when written in terms of their prime factors. </p>



<p><code>36=3x3x2x2</code> and <code>45=3x3x5</code>, thus the gcd of 36 and 45 is <code>3x3</code>, which is 9. So 36 is 9(4) and 45 is 9(5). It is very interesting to look at numbers as multiples of gcds. Moreover, notice that these multipliers, 4 and 5 in the example above, are relatively prime. </p>



<p><strong>The magic of subtraction</strong></p>



<p>Subtracting two relatively prime numbers, will produce another number that, while not necessarily prime itself, will be relatively prime to both the previous numbers. As an example, <code>13-7=6</code>. 6 is not prime, but it is relatively prime to both 7 and 13. If we subtract 6 from 13 we will get 7 again which is not very interesting. But if we subtract 6 from 7, the smaller one, since 6 and 7 are relatively prime we should get another number that is relatively prime to them both; <code>7-6=1</code>, which is relatively prime to every other number, if keep doing this:</p>


<pre title="">13 -  7 = 6
7  -  6 = 1
6  -  1 = 5
5  -  1 = 4
4  -  1 = 3
3  -  1 = 2
2  -  1 = 1
1  -  1 = 0

(1, 0)
</pre>


<p>The final two numbers are 0 and 1. So whenever we start with two relatively prime numbers and do this on them, it will always end with 0 and 1. This is pretty strange and magical. I am still perplexed by it, but the way I convinced myself, is to think about it bottom up: if we start with the number 1, and try to build our way to any other number by addition, there are finite number of ways. So when we start subtracting, what we are doing is walking that path backwards towards 1. </p>



<figure><img data-attachment-id="1319" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png" data-orig-size="1226,634" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 3" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>There is a limited set of paths from any two numbers back to 1 by successive subtractions.</figcaption></figure>



<p>Now why do these two numbers need to be relatively prime? because if they are not relatively prime, that means that they have some parts in common, like 36 and 45 above, remember? they are 9(4) and 9(5). If we do the subtracting trick on them:</p>


<pre title="">9(5) - 9(4) = 9(1)
9(4) - 9(1) = 9(3)
9(3) - 9(1) = 9(2)
9(2) - 9(1) = 9(1)
9(1) - 9(1) = 9(0)

(9(1), 0)
</pre>


<p>So you see, the common part survives the subtractions, while the uncommon parts converge to 1. But 9 is <em>all</em> the common parts of 36 and 45, in other words the gcd of 36 and 45! </p>



<p>Can we keep subtracting any two numbers until we reach (X, 0) and then proclaim X is the greatest common divisor? yes, we can, and it is called the <em><a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclidean Algorithm</a></em>.</p>



<p>Here is a silly experiment, what if we subtract the partially common parts? for 36 and 45, what if we wrote them as 3(12) and 3(15)?</p>


<pre title="">3(15) -  3(12) = 3(3)
3(12) -  3(3)  = 3(9)
3(9)  -  3(3)  = 3(6)
3(6)  -  3(3)  = 3(3)
3(3)  -  3(3)  = 3(0)

(3(3), 0)
</pre>


<p>This is really funny. The algorithm basically told us that the gcd of 12 and 15 is 3. Now if we choose to multiply the other 3 that we have factored out before we started our subtraction, it will yield the same result: the gcd of 36 and 45 is 9.</p>



<p><strong>What just happened?</strong></p>



<p>We started by finding the gcd of two numbers, then subtracting the uncommon, relatively prime parts to realize we always reach 1, so if we always subtract any two numbers from each other repeatedly, since the gcd is a common factor of both, it will remain constant until the end, when the uncommon parts have reduced down to 1 and 0; and then what we are left with is the gcd. </p>



<p>Here is a recursive implementation of it in Python:</p>


<pre title="">def gcd(a,b):
    if a == 0: return b
    if b == 0: return a

    return gcd(abs(a-b), min(a,b))
</pre>


<p>If someone has a better explanation of why subtracting relatively prime numbers repeatedly will always result in one, please leave a comment or reach out and help me understand better.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257871</guid>
            <pubDate>Mon, 24 Aug 2020 05:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Tcl 8.7 Part 11: The ZIP virtual file system]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24257855">thread link</a>) | @systems
<br/>
August 23, 2020 | https://www.magicsplat.com/blog/tcl87-zipfs/ | <a href="https://web.archive.org/web/*/https://www.magicsplat.com/blog/tcl87-zipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <header>
                        
                        <p>
                            Published <time datetime="2020-08-23+0000">2020-08-23</time>
                        </p>
                    </header>
                    <p>
                        This is the eleventh in a series of <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">posts</a> about new features in the upcoming version 8.7 of Tcl. It is the first of a pair of posts describing core support for treating ZIP archives as virtual file systems within Tcl. This post focuses on base operations dealing with existing ZIP archives. The next describes the creation of ZIP archives and their use for building <em>zipkits</em> and single file executables.
                    </p><!-- more -->
                    <blockquote>
                        <p>
                            To take Tcl 8.7 for a spin, you can download the <a href="https://sourceforge.net/projects/tcl/files/Tcl/8.7a3/">source</a> distribution. Binary distributions for Windows are available from <a href="https://sourceforge.net/projects/magicsplat/files/barebones-tcl/">magicsplat</a> and <a href="http://www.bawt.tcl3d.org/download.html#tclbi">BAWT</a>.
                        </p>
                    </blockquote>
                    <p>
                        With Tcl 8.6, access to files in ZIP archives was already possible. Tcl itself offered the ability to compress and decompress data with the <code>zlib</code> command. The <code>zipfile</code> module in <code>tcllib</code> then made use of these to permit access to files within an archive.
                    </p>
                    <p>
                        Tcl 8.7 goes beyond these capabilities by treating ZIP archives as mountable <em>virtual file systems</em> (VFS). This makes access to the files within the archive much simpler through the standard Tcl channel commands <code>open</code>, <code>gets</code> etc.
                    </p>
                    <h2>
                        Mounting ZIP archives
                    </h2>
                    <p>
                        The first step to accessing ZIP archives is to mount them as a Tcl VFS. This is done with the <code>zipfs mount</code> command.
                    </p>
                    <pre><code>% zipfs mount mnt demo.zip</code></pre>
                    <p>
                        This results in the archive <code>demo.zip</code> being mounted as a VFS under the path <code>zipfs:/mnt</code>.
                    </p>
                    <p>
                        The root of all ZIP file systems is given by the <code>zipfs root</code> command.
                    </p>
                    <pre><code>% zipfs root
zipfs:/</code></pre>
                    <p>
                        This root is platform-specific, <code>zipfs:/</code> on Windows and <code>//zipfs:/</code> on Unix(y) systems.
                    </p>
                    <p>
                        Naturally, you can mount multiple archives or even the same archive multiple times. The mount points of course have to be different but one can be nested inside another. For example,
                    </p>
                    <pre><code>% zipfs mount mnt2 demo.zip
% zipfs mount mnt/nested demo2.zip</code></pre>
                    <p>
                        Invoking <code>zipfs mount</code> without any arguments will return the currently mounted ZIP archives as a flat list of mount points and the archive file path.
                    </p>
                    <pre><code>% zipfs mount
zipfs:/mnt demo.zip zipfs:/mnt/nested demo2.zip zipfs:/mnt2 demo.zip</code></pre>
                    <p>
                        ZIP archives may be protected with a password. In that case the password must be supplied as the last argument to the command.
                    </p>
                    <p>
                        When no longer needed the each VFS should be unmounted with <code>zipfs unmount</code>.
                    </p>
                    <pre><code>% zipfs unmount mnt2
% zipfs unmount mnt/nested
% zipfs mount
zipfs:/mnt demo.zip</code></pre>
                    <h2>
                        Introspecting archives
                    </h2>
                    <p>
                        Once mounted, the archives can be introspected.
                    </p>
                    <p>
                        The <code>zipfs list</code> command returns a list of the files in the ZIP file system. Optionally, regular expression or glob wildcard patterns may be specified to filter the returned paths.
                    </p>
                    <pre><code>% zipfs list
zipfs:/mnt/demo zipfs:/mnt zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/subdir zipfs:/mnt/demo/demo.txt
% zipfs list *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -glob *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -regexp {\.txt$}
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt</code></pre>
                    <p>
                        Notice there is no mount point specified above. The command lists all files and directories under the ZIP VFS root. To restrict to a specific archive, specify it as a pattern.
                    </p>
                    <p>
                        A similar command returns a list of all file paths under a specific directory.
                    </p>
                    <pre><code>% zipfs find zipfs:/mnt/demo/subdir
zipfs:/mnt/demo/subdir/file.txt</code></pre>
                    <p>
                        <strong>TIP:</strong> The <code>zipfs find</code> command will work with any file system, not just ZIP VFS'es.
                    </p>
                    <p>
                        Since the ZIP archive is mounted as a Tcl VFS, standard Tcl commands for retrieving generic file information can be used. For example,
                    </p>
                    <pre><code>% file size zipfs:/mnt/demo/demo.txt
12
% clock format [file atime zipfs:/mnt/demo/demo.txt]
Sun Aug 23 12:33:24 IST 2020</code></pre>
                    <p>
                        The <code>zipfs info</code> command returns additional information that is specific to the ZIP archive format.
                    </p>
                    <pre><code>% zipfs info zipfs:/mnt/demo/demo.txt
demo.zip 12 14 50</code></pre>
                    <p>
                        The returned list contains the name of the ZIP archive (as originally passed), the original file size, the compressed file size and the offset of the file's compressed data within the ZIP archive. (As an aside, note in our example that the "compressed" size is greater than the actual size as often happens for small files.)
                    </p>
                    
                    <p>
                        Data transfer from compressed files in the archive is achieved through the standard Tcl channel I/O commands.
                    </p>
                    <pre><code>% set chan [open zipfs:/mnt/demo/demo.txt]
zipfs_32_1
% gets $chan
Demo file 
% close $chan</code></pre>
                    <p>
                        You can also open the file for writing. However, the ZIP VFS does not support the append mode.
                    </p>
                    <h2>
                        Coming up
                    </h2>
                    <p>
                        Having described the basics of access to ZIP archives, in the next post I will illustrate the use of the new features for creating ZIP archives, zipkits and single-file executables.
                    </p>
                    <h2>
                        References
                    </h2>
                    <ol>
                        <li>
                            <p>
                                <a href="https://core.tcl-lang.org/tips/doc/trunk/tip/430.md">TIP 430: Add basic ZIP archive support to Tcl</a>
                            </p>
                        </li>
                        <li>
                            <p>
                                <a href="http://www.tcl-lang.org/man/tcl8.7/TclCmd/zipfs.htm">zipfs man page</a>
                            </p>
                        </li>
                    </ol>
                    <nav>
                        Tagged:
                        <ul>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl/">Tcl</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">Tcl 8.7</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tutorial/">tutorial</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/zip/">zip</a>
                            </li>
                        </ul>
                    </nav><!-- tags -->
                </section></div>]]>
            </description>
            <link>https://www.magicsplat.com/blog/tcl87-zipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257855</guid>
            <pubDate>Mon, 24 Aug 2020 05:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principal Component Analysis]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24257468">thread link</a>) | @keyboardman
<br/>
August 23, 2020 | https://leimao.github.io/article/Principal-Component-Analysis/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Principal-Component-Analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Principal components analysis (PCA) is one of a family of techniques for taking high-dimensional data, and using the dependencies between the variables to represent it in a more tractable, lower-dimensional form, without losing too much information. It has been widely used for data compression and de-noising. However, its entire mathematical process is sometimes ambiguous to the user.</p>



<p>In this article, I would like to discuss the entire process of PCA mathematically, including PCA projection and reconstruction, with most of the derivations and proofs provided. At the end of the article, I implemented PCA projection and reconstruction from scratch. After reading this article, there should be no more black box in PCA anymore.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="orthogonal-matrix">Orthogonal Matrix</h4>

<p>In linear algebra, an orthogonal matrix is a real square matrix whose columns and rows are orthogonal unit vectors (orthonormal vectors).</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\top}A = AA^{\top} = I
\end{align}\]

</p><p>By <a href="https://en.wikipedia.org/wiki/Invertible_matrix">the definition of invertible matrix</a>, this means matrix $A$ is invertible and $A^{-1} = A^{\top}$.</p>



<p>We could also view this from the perspective of determinant.</p>



<p>Because $A$ and $A^{\top}$ are square matrices and using <a href="https://en.wikipedia.org/wiki/Determinant#Properties_of_the_determinant">the properties of determinant</a></p><p>

\[\begin{align}
\det(I) &amp;= \det(A^{\top}A) \\
&amp;= \det(AA^{\top}) \\
&amp;= \det(A) \det(A^{\top}) \\
&amp;= \det(A) \det(A) \\
&amp;= \det(A)^2 \\
&amp;= \det(A^{\top})^2 \\
&amp;= 1 \\
\end{align}\]

</p><p>Since $\det(A) \neq 0$, matrix $A$ is invertible. We multiply $A^{-1}$ on both side of the orthogonal matrix definition.</p><p>

\[\begin{align}
A^{\top}A A^{-1} &amp;= I A^{-1}\\
A^{\top} I &amp;= A^{-1} \\
A^{\top} &amp;= A^{-1} \\
\end{align}\]

</p><p>We have also derived the conclusion that $A^{-1} = A^{\top}$.</p>



<p>Similarly, a complex square matrix $A$ is unitary if its transpose conjugate $A^{\dagger}$ is also its inverse.</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\dagger}A = AA^{\dagger} = I
\end{align}\]

</p><h4 id="symmetric-matrix">Symmetric Matrix</h4>

<p>Real symmetric matrix has the following useful properties:</p>



<p>If $A$ is a real symmetric matrix, all of its eigenvalues are real numbers.</p>



<p>Because of <a href="https://en.wikipedia.org/wiki/Complex_conjugate#Generalizations">the conjugate properties</a> and $\overline{A} = A$ since $A$ is a real value matrix,</p><p>

\[\begin{align}
\overline{Av} &amp;= \overline{\lambda v} \\
&amp;= \overline{A} \overline{v} \\
&amp;= A \overline{v} \\
&amp;= \overline{\lambda} \overline{v} \\
\end{align}\]

</p><p>We got $A \overline{v} = \overline{\lambda} \overline{v}$.</p>



<p>Let $\lambda \in \mathbb{C}$ be an eigenvalue of the symmetric matrix $A$. $Av = \lambda v$ and $v \neq 0$. We multiply $v^{\dagger}$ ($v^{\dagger} = \overline{v}^{\top}$) to the both sides, and because of $A^{\top} = A$ and the property we have just derived $A \overline{v} = \overline{\lambda} \overline{v}$,</p><p>

\[\begin{align}
v^{\dagger} A v &amp;= \lambda v^{\dagger} v \\
&amp;= v^{\dagger} A^{\top} v \\
&amp;= \overline{v}^{\top} A^{\top} v \\
&amp;= (A\overline{v})^{\top} v \\
&amp;= (\overline{\lambda} \overline{v})^{\top} v \\
&amp;= \overline{\lambda}^{\top} \overline{v}^{\top} v \\
&amp;= \overline{\lambda} v^{\dagger} v \\
\end{align}\]

</p><p>We have $\lambda v^{\dagger} v = \overline{\lambda} v^{\dagger} v$, thus $\lambda$ is real.</p>



<p>This concludes the proof.</p>

<h4 id="positive-semi-definite-matrix">Positive Semi-Definite Matrix</h4>

<p>The $n \times n$ symmetric matrix $A$ is defined to be positive semi-definite, if $x^{\dagger} A x \geq 0$ for $x \in \mathbb{C}^n$.</p>



<p>The positive semi-definite matrix has the following important property:</p>



<p>The eigenvalues of positive semi-definite matrix are non-negative.</p>



<p>Because $x^{\dagger} A x \geq$ for $x \in \mathbb{C}^n$, suppose $x$ is an eigenvector of $A$ and $Ax = \lambda x$ where $x \neq 0$,</p><p>

\[\begin{align}
x^{\dagger} A x &amp;= x^{\dagger} \lambda x \\
&amp;= \lambda x^{\dagger} x \\
&amp;\geq 0 \\
\end{align}\]

</p><p>Because $x^{\dagger} x$ must be real number and $x^{\dagger} x &gt; 0$, we have $\lambda \geq 0$.</p>



<p>This concludes the proof.</p>

<h4 id="covariance-matrix">Covariance Matrix</h4>

<p>The covariance matrix has the following important property:</p>



<p>Covariance matrix is positive semi-definite. This means that the eigenvalues of covariance matrix is non-negative.</p>



<p>The proof of that covariance must be positive semi-definite could be found in my previous post on <a href="https://leimao.github.io/blog/Multivariate-Gaussian-Covariance-Matrix/">Multivariate Gaussian and Covariance Matrix</a>.</p>

<h4 id="singular-values">Singular Values</h4>

<p>The singular values, $\sigma_1$, $\sigma_2$, $\cdots$, $\sigma_r$, of an $m \times n$ matrix $A$ are the square roots, $\sigma_i = \sqrt{\lambda_i}$, of non-negative eigenvalues of the associated Gram matrix $K = A^{\dagger}A$. The corresponding eigenvectors of $K$ are known as singular vectors of $A$.</p>



<p>Note that the associated Gram matrix $K = A^{\dagger}A$ is real and symmetric, so the eigenvalues of $K$ are all real.</p>



<p>$K = A^{\dagger}A$ is also positive semi-definite.</p>



<p>For any vector $x$</p><p>

\[x^{\dagger} (A^{\dagger} A) x = (Ax)^{\dagger} Ax\]

</p><p>Because $Ax$ is also a vector,</p><p>

\[\begin{align}
x^{\dagger} (A^{\dagger} A) x \geq 0
\end{align}\]

</p><p>Therefore, all the eigenvalues of $K = A^{\dagger}A$ are non-negative and they all have a corresponded singular value of $A$.</p>

<h4 id="singular-value-decomposition">Singular Value Decomposition</h4>

<p>In linear algebra, the singular value decomposition (SVD) is a factorization of a real or complex matrix that generalizes the eigendecomposition of a square normal matrix to any $ m\times n$ matrix via an extension of the polar decomposition.</p>



<p>Specifically, the singular value decomposition of an $m \times n$ real or complex matrix $M$ is a factorization of the form $U \Sigma V^{\dagger}$, where $U$ is an $m \times m$ real or complex unitary matrix, $\Sigma$ is a $m \times n$ rectangular diagonal matrix with non-negative real numbers on the diagonal, and $V$ is an $n \times n$ real or complex unitary matrix.</p>



<p>The diagonal entries $\sigma_{i}=\Sigma_{ii}$ of $\Sigma$ are known as the singular values of $M$. The number of non-zero singular values is equal to the rank of $M$.</p>



<p>In particular, for any matrix $A \in \mathbb{C}$,</p><p>

\[A_{m \times n} = U_{m\times m} \Sigma_{m \times n} V_{n \times n}^{\dagger}\]

</p><p>We will skip the proof for why every matrix has SVD and the algorithm for SVD.</p>

<h4 id="singular-value-decomposition-for-norm-matrix">Singular Value Decomposition for Norm Matrix</h4>

<p>For any matrix $A \in \mathbb{C}$, $A^{\dagger} A$ could be expressed as</p><p>

\[\begin{align}
A^{\dagger} A &amp;= (U \Sigma V^{\dagger})^{\dagger} U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} U^{\dagger}  U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} I \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} \Sigma V^{\dagger}
\end{align}\]

</p><p>We multiply $V$ at both side of the equation.</p><p>

\[\begin{align}
A^{\dagger} A V &amp;= V \Sigma^{\dagger} \Sigma V^{\dagger} V \\
&amp;=  V \Sigma^{\dagger} \Sigma I \\
&amp;=  V \Sigma^{\dagger} \Sigma \\
&amp;= \Sigma^{\dagger} \Sigma V \\
\end{align}\]

</p><p>Note that $\Sigma^{\dagger} \Sigma$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma^{\dagger} \Sigma$, including the zeros, are the eigenvalues of $A^{\dagger} A$. All the columns of $V$ are the corresponding eigenvectors of $A^{\dagger} A$.</p>



<p>Similarly, $A A^{\dagger}$ could be expressed as</p><p>

\[\begin{align}
A A^{\dagger} U &amp;= \Sigma \Sigma^{\dagger} U \\
\end{align}\]

</p><p>Note that $\Sigma \Sigma^{\dagger}$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma \Sigma^{\dagger}$, including the zeros, are the eigenvalues of $A A^{\dagger}$. All the columns of $U$ are the corresponding eigenvectors of $A A^{\dagger}$.</p>

<h3 id="mathematics-of-principal-components-analysis">Mathematics of Principal Components Analysis</h3>

<p>We start with $p$-dimensional vectors, and want to summarize them by projecting down into a $q$-dimensional subspace, where $q \leq p$. Our summary will be the projection of the original vectors on to $q$ directions, the principal axes, which span the subspace.</p>

<h4 id="minimizing-projection-residuals">Minimizing Projection Residuals</h4>

<p>Given a dataset $X \in \mathbb{R}^{n \times p}$ whose row is the centered data vectors $x_i \in \mathbb{R}^p$ for $0 \leq i \leq n-1$ ($\sum_{i=0}^{n-1} x_{i} = 0$), if we have a unit vector $w \in \mathbb{R}^p$ ($|w| = 1$) and we project the all the data vectors to this unit vector $w$.</p>



<p>The length of projection for data vector $x_i$ on $w$, by definition, is</p><p>

\[\begin{align}
|x_i| \cos \theta &amp;= \frac{\langle x_i, w \rangle}{|w|} \\
&amp;= \langle x_i, w \rangle \\
\end{align}\]

</p><p>where $\langle x_i, w \rangle$ is the inner product of $x_i$ and $w$.</p>



<p>The projection vector for data vector $x_i$ on $w$ is $\langle x_i, w \rangle w$.</p>



<p>The residual, which is the distance from data vector $x_i$ to $w$, is the length of vector $x_i - \langle x_i, w \rangle w$.</p>



<p>Let’s check what the residual square $| x_i - \langle x_i, w \rangle w | ^2$ is.</p><p>

\[\begin{align}
| x_i - \langle x_i, w \rangle w |^2 &amp;= \langle x_i - \langle x_i, w \rangle w, x_i - \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, \langle x_i, w \rangle w \rangle - \langle \langle x_i, w \rangle w, x_i \rangle + \langle \langle x_i, w \rangle w, \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, w \rangle \langle x_i, w \rangle - \langle x_i, w \rangle \langle w, x_i \rangle + \langle x_i, w \rangle ^2 \langle w,  w \rangle \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 |w| ^2 \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 \\
&amp;= \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \\
\end{align}\]

</p><p>The optimization goal of projection is to minimize mean squared error $\text{MSE}(w)$, which is the mean of the residual sum of squares.</p><p>

\[\begin{align}
\text{MSE}(w) &amp;= \frac{1}{n} \sum_{i=0}^{n-1} | x_i - \langle x_i, w \rangle w |^2 \\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \big( \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \big)\\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \langle x_i, x_i \rangle - \frac{1}{n} \sum_{i=0}^{n-1}  \langle x_i, w \rangle ^2\\
\end{align}\]

</p><p>Remember the relationship between variance and expected value, $\mathbb{V}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2$, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Principal-Component-Analysis/">https://leimao.github.io/article/Principal-Component-Analysis/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Principal-Component-Analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257468</guid>
            <pubDate>Mon, 24 Aug 2020 04:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an SSDP Directory in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24256984">thread link</a>) | @luu
<br/>
August 23, 2020 | https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir | <a href="https://web.archive.org/web/*/https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a href="https://netscape-browser.en.softonic.com/" target="_blank">
        <img src="https://quinnwilton.com/images/netscape_now.gif">
      </a>
    </header>
<a href="https://quinnwilton.com/blog"><img src="https://quinnwilton.com/images/back.png"></a>

<section>
  
  <h2>2020-02-26</h2>

<p>I used to spend all of my free time programming random toy projects. Over time, likely after spending a few years in industry, I started to spend so much time thinking about how to write maintainable code that I think I started to lose out on what makes programming fun: exploring new ideas and learning how to do things I’ve never done before. I’d like to rediscover that joy, and to do that, I need to stop being so much of a perfectionist.</p>
<p>I think that in an office setting, deadlines force me to move on and call things done, but in my personal life, lack of that kind of pressure means that I can spend literally forever architecting and rearchitecting the same piece of code until it’s perfect (it never is).</p>
<p>To fix this, I’m going to try blogging! If I can make myself excited to share my code with other people, imperfect and unfinished as it is, then maybe I can start to unlearn the paralysis that’s been plaguing me for the past few years.</p>
<p>To start, I just want to walk through a small program I wrote a few months ago. I wanted to learn how <a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol">SSDP</a> works, so I implemented an SSDP Directory! For those of you who aren’t aware, SSDP is a fairly simple protocol from the 90s that’s used to facilitate the discovery of network services. Nowadays, it’s also used by everything from smart TVs to Hue lights.</p>
<p>My implementation can be found <a href="https://github.com/QuinnWilton/ssdp_directory">here</a>, and the (very readable!) RFC is <a href="https://tools.ietf.org/html/draft-cai-ssdp-v1-03">here</a>.</p>
<p>If I run the application, it discovers all of the devices on my network:</p>
<pre><code>iex(1)&gt; SSDPDirectory.list_services
%{
  "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice" =&gt; %SSDPDirectory.Service{
    location: "http://192.168.0.150:60000/upnp/dev/b236f169-9c9d-db64-ffff-ffffcff91970/desc",
    type: "upnp:rootdevice",
    usn: "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice"
  },
  ...
}</code></pre>
<p>The key to SSDP is what’s called <a href="https://en.wikipedia.org/wiki/Multicast">multicast addressing</a>. Essentially, services broadcast their presence to a specially designated multicast address, and then anyone else on the network is able to listen for those presence notifications in order to track the appearance and disappearance of new services.</p>
<p>Fortunately, Elixir, my language of choice, makes subscribing to these notifications <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/multicast_channel.ex">easy</a>!</p>
<pre><code>defmodule SSDPDirectory.MulticastChannel do
  use GenServer

  alias __MODULE__

  alias SSDPDirectory.{
    Discovery,
    Presence
  }

  @multicast_group {239, 255, 255, 250}
  @multicast_port 1900

  def start_link(opts \\ []) do
    GenServer.start_link(__MODULE__, :ok, opts)
  end

  @spec broadcast(GenServer.name(), iodata) :: :ok
  def broadcast(channel \\ MulticastChannel, packet) do
    GenServer.cast(channel, {:broadcast, packet})
  end

  @spec init(:ok) :: {:ok, %{socket: port}}
  def init(:ok) do
    udp_options = [
      :binary,
      active: true,
      add_membership: {@multicast_group, {0, 0, 0, 0}},
      multicast_if: {0, 0, 0, 0},
      multicast_loop: false,
      reuseaddr: true
    ]

    {:ok, socket} = :gen_udp.open(@multicast_port, udp_options)

    {:ok, %{socket: socket}}
  end

  def handle_cast({:broadcast, packet}, state) do
    :ok = :gen_udp.send(state.socket, @multicast_group, @multicast_port, packet)

    {:noreply, state}
  end

  def handle_info({:udp, _socket, _ip, _port, data}, state) do
    Task.Supervisor.start_child(SSDPDirectory.DecodingSupervisor, fn -&gt;
      with {:ok, packet, rest} &lt;- :erlang.decode_packet(:http_bin, data, []),
           {:ok, handler} &lt;- packet_handler(packet),
           {:ok, decoded} &lt;- handler.decode(rest) do
        :ok = handler.handle(decoded)
      end
    end)

    {:noreply, state}
  end

  defp packet_handler({:http_request, "NOTIFY", _target, _version}),
    do: {:ok, Presence}

  defp packet_handler({:http_response, _version, 200, "OK"}),
    do: {:ok, Discovery.Response}

  defp packet_handler(_packet), do: :error
end</code></pre>
<p>Most of the magic happens in the <code>init/1</code> function. By opening a UDP socket and joining it to the protocol’s multicast group, our process is now able to receive packets that are broadcast to that group. That receiving logic is located in the <code>handle_info/2</code> function within the same file.</p>
<p>When receiving a packet, we spawn another process that is responsible for handling that packet. This process runs under a <code>Task.Supervisor</code> in order to isolate crashes of that process from the <code>MulticastChannel</code>. Also interesting, is that we’re able to decode the incoming packets using <a href="http://erlang.org/doc/man/erlang.html#decode_packet-3">:erlang.decode_packet/3</a>. This is a builtin function that allows us to decode a variety of packet formats, piece-by-piece. In this case, we’re using it to parse the packet as an HTTP packet. This is the same way that Elixir’s <a href="https://github.com/elixir-mint/mint/blob/master/lib/mint/http1/response.ex#L7">Mint</a> decodes HTTP responses too!</p>
<p>Based on the type of packet decoded, <code>packet_handler/1</code> then delegates the handling of that packet to another module. Either we’ve received an HTTP NOTIFY request, and we’re dealing with a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence.ex">presence notification</a>, or we’ve received a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/discovery/response.ex">response to a discovery request</a>.</p>
<p>Let’s take a look at the presence case. In case you’re curious, here’s an example presence notification:</p>
<pre><code>NOTIFY * HTTP/1.1
Host: 239.255.255.250:reservedSSDPport
NT: blenderassociation:blender
NTS: ssdp:alive
USN: someunique:idscheme3
AL: &lt;blender:ixl&gt;&lt;http://foo/bar&gt;
Cache-Control: max-age = 7393</code></pre>
<p>And here’s where we handle it:</p>
<pre><code>defmodule SSDPDirectory.Presence do
  require Logger

  alias __MODULE__
  alias SSDPDirectory.HTTP

  @type command :: Presence.Alive.t() | Presence.ByeBye.t()

  @spec decode(binary) ::
          :error
          | {:ok, command}
  def decode(data) do
    case HTTP.decode_headers(data, []) do
      {:ok, headers, _rest} -&gt;
        process_headers(headers)

      :error -&gt;
        _ = Logger.debug(fn -&gt; "Failed to decode NOTIFY request: " &lt;&gt; inspect(data) end)

        :error
    end
  end

  @spec handle(command) :: :ok
  def handle(%Presence.Alive{} = command) do
    Presence.Alive.handle(command)
  end

  def handle(%Presence.ByeBye{} = command) do
    Presence.ByeBye.handle(command)
  end

  defp process_headers(headers) do
    do_process_headers(headers, %{})
  end

  defp do_process_headers([], args) do
    case args do
      %{command: "ssdp:alive", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.Alive{
           usn: usn,
           type: type,
           location: Map.get(args, :location)
         }}

      %{command: "ssdp:byebye", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.ByeBye{
           usn: usn,
           type: type
         }}

      _ -&gt;
        :error
    end
  end

  defp do_process_headers([{"nts", command} | rest], args) do
    args = Map.put(args, :command, command)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"nt", type} | rest], args) do
    args = Map.put(args, :type, type)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"usn", usn} | rest], args) do
    args = Map.put(args, :usn, usn)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"al", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"location", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([_ | rest], args) do
    do_process_headers(rest, args)
  end
end</code></pre>
<p>It looks like there’s a lot going on here, but it’s actually pretty simple. Starting in <code>decode/1</code>, we continue decoding the packet from <code>MulticastChannel</code>. This time it’s the headers we’re interested in, so we decode those, and then process them in order to determine what kind of command we’re dealing with.</p>
<p>The processing step simply involves recursing over the list of headers, and accumulating the relevant ones in a map . Once we’ve done that, we just construct the corresponding command!</p>
<p>Lastly, the command handler delegates to a third module based on the type of command being processed. For example, in the case of an <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence/alive.ex">ssdp:alive</a> command:</p>
<pre><code>defmodule SSDPDirectory.Presence.Alive do
  require Logger

  alias __MODULE__

  alias SSDPDirectory.{
    Cache,
    Service
  }

  @enforce_keys [:usn, :type]
  defstruct [:location] ++ @enforce_keys

  @type t :: %Alive{}

  @spec handle(Alive.t()) :: :ok
  def handle(%Alive{} = command) do
    _ = Logger.debug(fn -&gt; "Handling ssdp:alive request: " &lt;&gt; inspect(command) end)

    service = %Service{
      usn: command.usn,
      type: command.type,
      location: command.location
    }

    :ok = Cache.insert(service)
  end
end</code></pre>
<p>Here we just construct a service using the parameters in the command, and then store it in our <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/cache.ex">cache</a>:</p>
<pre><code>defmodule SSDPDirectory.Cache do
  use GenServer

  require Logger

  alias __MODULE__
  alias SSDPDirectory.Service

  def start_link(opts \\ []) do
    GenServer.start_link(Cache, :ok, opts)
  end

  def contents(cache \\ Cache) do
    :ets.tab2list(cache)
    |&gt; Enum.into(%{})
  end

  def insert(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:insert, service})
  end

  def delete(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:delete, service})
  end

  def flush(cache \\ Cache) do
    GenServer.call(cache, :flush)
  end

  def init(:ok) do
    table = :ets.new(Cache, [:named_table, read_concurrency: true])

    {:ok, %{table: table}}
  end

  def handle_call({:insert, %Service{usn: usn} = service}, _from, data) when not is_nil(usn) do
    :ets.insert(data.table, {usn, service})

    _ = Logger.debug(fn -&gt; "Cached service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call({:delete, %Service{usn: usn}}, _from, data) when not is_nil(usn) do
    :ets.delete(data.table, usn)

    _ = Logger.debug(fn -&gt; "Evicted service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call(:flush, _from, data) do
    :ets.delete_all_objects(data.table)

    _ = Logger.debug(fn -&gt; …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</a></em></p>]]>
            </description>
            <link>https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-24256984</guid>
            <pubDate>Mon, 24 Aug 2020 02:09:41 GMT</pubDate>
        </item>
    </channel>
</rss>
