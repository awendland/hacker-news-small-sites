<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 01 Nov 2020 20:16:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 01 Nov 2020 20:16:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[LIL: Little Interpreted Language]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24949515">thread link</a>) | @marttt
<br/>
October 30, 2020 | http://runtimeterror.com/tech/lil/ | <a href="https://web.archive.org/web/*/http://runtimeterror.com/tech/lil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><b>LIL</b> (stands for <b>L</b>ittle <b>I</b>nterpreted <b>L</b>anguage)
is a small highly dynamic scripting language inspired by Tcl and
unix shells. LIL has two implementations, one written in <b>C</b>,
which consists of a pair of <tt>.c</tt> and <tt>.h</tt> files
and one in <b><a href="http://freepascal.org/">Free Pascal</a></b>,
which consists of a single <tt>pas</tt> file (a unit). Also a
<a href="http://lazarus-ide.org/">Lazarus</a> package for the
latter is provided.</p>

<h2>Contents</h2>

<menu>
  <li><a href="#downloads">Downloads</a>
  <menu>
    <li><a href="#latestversion">Latest version</a>
    </li><li><a href="#olderversions">Older versions</a>
    </li><li><a href="#winlil">WinLIL</a>
    </li><li><a href="#lilgui">LILGUI</a>
  </li></menu>
  </li><li><a href="#stability">API stability and compatibility</a>
  </li><li><a href="#documentation">Documentation</a>
  </li><li><a href="#status">Status</a>
  </li><li><a href="#license">License</a>
</li></menu>

<h2><a name="downloads"></a>Downloads</h2>

<p>LIL is currently available as source code snapshots of both
the C and the Free Pascal version combined in a single ZIP file.
These snapshots are versioned using their release date. Note that
the interpreter's reflect version command will report <i>0.1</i>
regardless of date versioning. Both of these will change at some
point in the future to provide proper versioned releases.</p>

<h3><a name="latestversion"></a>Latest version</h3>

<p>The latest version of LIL is <a href="http://runtimeterror.com/tech/lil/lil20190821.zip">lil20190821.zip</a>
(159KB). This is an extract from my private Fossil repository
(the files are mostly the same as the older archives, but this
also includes a full changelog from the repository going back
to 2010 and the LIL logo as an XCF image which can be opened with
GIMP).</p>

<p>Please note that <b>20190821</b> contains slightly altered
behavior for line breaking during list parsing that <i>could</i>
affect some scripts, especially with lists that contain code inside
square brackets, however the previous behavior was completely
broken (e.g. having multiple commands inside brackets in a list
would merge all commands into a single one and if a semicolon
was used for the multiple commands, the entire command wouldn't
be parsed properly). Because of that i expect any reliance on
the previous behavior to be accidental (and in practice i do not
really expect any such script to even exist). Also in the same
version a Bash script is introduced to check the differences between
different executables by running the same scripts under both and
comparing the results, which show that FPLIL contains a few incompatibilities
with C LIL. At this moment FPLIL doesn't implement the changes
mentioned so far - all these incompatibilities and changes will
be fixed in a later release.</p>

<h3><a name="olderversions"></a>Older versions</h3>

<p>Some older versions are also available in case you need them.
LIL should be mostly backwards compatible (see below), but right
now there is no promise for strict API or ABI compatibility.</p>

<ul>
  <li><a href="http://runtimeterror.com/tech/lil/lil20190819.zip">lil20190819.zip</a> (155KB)<a href="http://runtimeterror.com/tech/lil/lil20190818.zip"></a>
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190818.zip">lil20190818.zip</a> (154KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20190114.zip">lil20190114.zip</a> (91KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20161129.zip">lil20161129.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160812.zip">lil20160812.zip</a> (88KB)
  </li><li><a href="http://runtimeterror.com/tech/lil/lil20160603.zip">lil20160603.zip</a> (88KB)
</li></ul>

<h3><a name="winlil"></a>WinLIL</h3>

<p>If you are using Windows you can also download <b>WinLIL</b>,
a small Windows-based environment with editor, console and extra
graphics functions that can be used to experiment with LIL. It
is self-contained in a single executable, including the LIL documentation.</p>

<p>The latest version is <a href="http://runtimeterror.com/tech/lil/winlil14.zip">WinLIL 1.4</a>
(204KB) based on <i>C LIL 20190821</i>. <a href="http://runtimeterror.com/tech/lil/winlil.png">Here
is a screenshot</a> of it in action. Also a small doodle program
can be <a href="http://runtimeterror.com/tech/lil/doodle.lil">downloaded here</a> and a <a href="http://runtimeterror.com/tech/lil/doodle.gif">screenshot
seen here</a>. <a href="http://runtimeterror.com/tech/lil/winlil20190821231511.zip">This archive</a>
(45KB) contains the source code, but note that it uses the original
Borland C++ Builder and to compile with a newer version (such
as the free Community Edition) you'll need to recreate the project
file and make a few modifications to the code.</p>

<p>Older versions of WinLIL can be found in these files: <a href="http://runtimeterror.com/tech/lil/winlil13.zip">winlil13.zip</a>
(1.3 binary), <a href="http://runtimeterror.com/tech/lil/winlil20190524200539.zip">winlil20190524200539.zip</a>
(1.3 source), <a href="http://runtimeterror.com/tech/lil/winlil20170425.zip">winlil20170424.zip</a>
(binary), <a href="http://runtimeterror.com/tech/lil/winlilsrc20161220.7z">winlilsrc20161220.7z</a>
(source).</p>

<h3><a name="lilgui"></a>LILGUI</h3>

<p><b>LILGUI</b> is an experimental API specification for GUI
applications that provide scripting functionality through LIL
to expose a simple GUI API. It is mainly intended for creating
embeddable GUIs (e.g. a panel in a sidebar) although it can also
be used for popup windows and dialogs. Currently the only implementation
for LILGUI is <b>LazLILGUI</b>, which is a component for Lazarus
that uses LCL to provide the actual GUI functionality.</p>

<p>The latest version of LILGUI files (which include the API spec,
LazLILGUI and a couple of examples) can be <a href="http://runtimeterror.com/tech/lil/lilgui20190708215135.zip">downloaded
here</a> (85KB). A 64bit windows binary for <b>LazLILGUI Notepad</b>,
a text editor that provides a sidebar to try out LILGUI code,
can be <a href="http://runtimeterror.com/tech/lil/llgnotepad20190708.zip">downloaded here</a> (1.3MB).
Also you can see the screenshots of program in action under <a href="http://runtimeterror.com/tech/lil/llgnotepadwin.png">Windows</a>, <a href="http://runtimeterror.com/tech/lil/llgnotepadlin.png">Linux</a>
and <a href="http://runtimeterror.com/tech/lil/llgnotepadosx.png">Mac OS X</a> and also the <a href="http://runtimeterror.com/tech/lil/llgcce.png">Custom Control Example</a> under Windows.</p>

<h2><a name="stability"></a>API stability and compatibility</h2>

<p>Generally speaking, both the C and Free Pascal implementation
APIs are stable <i>for the most part</i>. The <b>C API</b> was
broken only once in middle 2010 when <code>lil_command_t</code>
was renamed to <code>lil_func_t</code> and the <b>C ABI</b> for
the Windows DLL is also backwards compatible since late 2010.
The <b>Free Pascal</b> implementation has a less stable API but
as Free Pascal itself does not support ABI stability, this is
less of a concern.</p>

<p>In the foreseeable future the C API should be stable, but i'd
recommend <i>against</i> building a system-wide shared version
of the library before a proper versioned release is made. Once
a versioned release is made, both the API and ABI will remain
stable for as long as it is technically possible.</p>

<p>Script code should be backwards compatible even as new commands
are introduced since scripts and host applications will redefine
any conflicting functions anyway. The only time script code was
broken was in 2012 when the multiline comments were introduced
so any script that used a comment line like <code>#####</code>
was broken. This was addressed in a fix in 2014 that added a special
check for such cases so that multiline comments can only start
and end with two <code>#</code>s but not three or more (while
this could have broken any script that used three or more <code>#</code>s
to start and end multiline comments, the chances for such a script
are very slim).</p>

<p>Like with the C API, the script backwards compatibility currently
is mostly stable, but minor changes (like the multiline comment
changes mentioned above) might be made until a versioned release
is made or fixes to the script behavior to be closer to what is
described in the documentation or simply fix broken behavior.
At that point no changes will be made that may affect backwards
compatibility.</p>

<p>LILGUI and LazLILGUI are more experimental and may see backwards
incompatible changes in the future.</p>

<h2><a name="documentation"></a>Documentation</h2>

<p>Currently the only documentation is the (lengthy) <tt>readme.txt</tt>
file that <a href="http://runtimeterror.com/tech/lil/readme.txt">you can read here</a> or as part
of the archive containing the source code. At some point i'll
write better formatted documentation. Free Pascal has its own
API documentation <a href="http://runtimeterror.com/tech/lil/pasreadme.txt">readable here</a> and
also as a part of the archive containing the source code.</p>

<p>The LILGUI API can be <a href="http://runtimeterror.com/tech/lil/api.txt">found here</a> and
the documentation for LazLILGUI can be <a href="http://runtimeterror.com/tech/lil/llgreadme.txt">found
here</a>. Both are also part of the LILGUI archive.</p>

<p>Also <a href="http://www.slideshare.net/badsectoracula/lil-presentation">an
old LIL presentation can be found on SlideShare</a>. Please note
that the URLs in the presentation are not valid anymore.</p>

<h2><a name="status"></a>Status</h2>

<p>LIL is practically <i>feature-complete</i> and i do very little
development of it. I do not plan on making it a big and bloated
library that tries to provide everything - if anything, in the
future i might add some conditionals to remove bits of the library
for users who do not need, e.g, the string or list functions.</p>

<p>Further work is mostly "around" LIL and not on the
language itself: improving the documentation, writing a test suite
(currently there are several examples which i run after making
changes and almost half of them come from bug fixes, but i'd like
somethnig more automated), fixing some issues with the Free Pascal
implementation, adding more functions on the C API to access LIL's
state, etc.</p>

<h2><a name="license"></a>License</h2>

<p>Both the C and Free Pascal implementations as well as WinLIL
are licensed under the zlib license below:</p>

<blockquote>
  <pre>LIL - Little Interpreted Language
Copyright (C) 2010-2019 Kostas Michalopoulos

This software is provided 'as-is', without any express or implied
warranty.  In no event will the authors be held liable for any damages
arising from the use of this software.

Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:

1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required.
2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.
3. This notice may not be removed or altered from any source distribution.</pre>
</blockquote>



</div>]]>
            </description>
            <link>http://runtimeterror.com/tech/lil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24949515</guid>
            <pubDate>Sat, 31 Oct 2020 06:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Better Mousetrap – Converting WebPages to Web APIs]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24948779">thread link</a>) | @shanselman
<br/>
October 30, 2020 | https://turnerj.com/blog/a-better-mousetrap | <a href="https://web.archive.org/web/*/https://turnerj.com/blog/a-better-mousetrap">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="article">
<p>Today is a big day for me as after many months (or years depending how you look at it), I've <a href="https://www.producthunt.com/posts/brandvantage">finally launched the first product for my business, BrandVantage</a>.
This post is the story of how I started with one idea and ended up launching with a different one.</p>
<h2>The Original Idea: Let's build a digital brand expert!</h2>
<p>I worked as a web developer for a local web development agency for a number of years and in that time, I learnt a lot about how a variety of different businesses operated online.</p>
<p>There were a few key "problems" I found in common across many of those businesses:</p>
<ul>
<li>Under-utilising analytics</li>
<li>Misunderstanding analytics</li>
<li>Not keeping on top of industry information</li>
<li>Lack of competitor analysis/understanding</li>
<li>Difficulty with Search Engine Optimization (SEO)</li>
</ul>
<p>In moderate-to-large companies where you have marketing departments, most of this stuff can be covered by one or more staff dedicated to these things.
In smaller companies, the business owner is normally the one where these tasks fall on to, but they are already wearing many different hats.
It felt like something was here - if I could automate some of these tasks in different ways, I could both help business owners and earn myself some money along the way.</p>
<p>Automation of tasks, especially ones in analytics or SEO spaces, isn't a new idea.
In fact, I've seen many businesses in a similar space launch on Product Hunt over the years since starting, but that didn't deter me.
I was building <a href="https://idioms.thefreedictionary.com/a+better+mousetrap"><em>a better mousetrap</em></a> and wanting to launch it at a lower price, not something truly innovative so it was going to be an uphill battle.
This area though, helping small businesses online be as efficient in tasks as some bigger businesses can, is something I felt passionately about so I proceeded anyway.</p>
<h3>Attempt One: Very Hacky (in PHP)</h3>
<p>Way back in 2015/16/17, while still at my full-time job, I spent nights and weekends building and tinkering on solutions to the problems business owners face.
It was a hacky PHP solution pulling real-time information from sources like Twitter, Google Analytics and Facebook.
A hacky approach seemed like a good idea as that seemed to be the way people launched things, do the quickest and hackiest thing you can to get it out the door.</p>
<p>While working on it, I had a few interested parties though what I built could barely be considered a prototype.
The thing was a mess.
I could do some basic queries, but it wasn't what I considered sellable and definitely not user-friendly, something I considered key to the product.
I was also running into technical problems with scale - any sufficiently complex query was performed real-time, which was getting more complicated.
Real-time processing had to be out.
I needed to pre-compute and store it in a database.</p>
<p>I wanted to take this more seriously and I didn't feel like a "quick and hacky" approach to building a product was right for me.
With this in mind, it seemed like a good opportunity to change the tech stack to something that would be better long term.</p>
<h3>Attempt Two: Slightly Less Hacky (in .NET)</h3>
<p>Moving to .NET felt like the smart move for me as at my job I had spent a lot more time working in .NET than PHP, plus I vastly prefered the tooling in .NET vs PHP.
That said, the .NET code I had worked on to-date would definitely be considered "legacy code".</p>
<p>My first version in .NET (specifically .NET Framework), predating my use of version control, was trying to keep costs low by using MySQL through Entity Framework.
After a lot of pain and suffering with that, I had a short stint of MSSQL before I settled upon MongoDB.</p>
<p>MongoDB might seem like a weird choice - there are some people that have very strong opinions about which type of database you should use.
Honestly it came down to a gut feel after messing around with it - it seemed more compatible to the way I was approaching problems than a relational database would.
I liked the code-first approach to Entity Framework so much though that I recreated the "feel" of Entity Framework for MongoDB with some custom code.
This later became an open source project of mine called <a href="https://www.mongoframework.com/">MongoFramework</a>.</p>
<p>I'm not going to lie, progress was... slow.
While I was putting quite a lot of time into working on it, it was still an extremely ambitious project.
I have strong feelings about building "MVPs" where some people focus too much on the "minimum" without enough focus on the "viable".
At the end of the day people buy products that meet their needs, and cutting too much out would meet no-ones needs.
If someone was going to use this, in a market with many competitors of varying quality, it had to do its job well.
There didn't seem much I could reasonably cut to make it any more minimal if I wanted people to buy it.</p>
<p>I kept working at it every night, building pieces to extract and store data from a variety of sources.
I was pulling in data from Google Analytics, Google Webmaster Tools (now called Google Search Console), Twitter, Facebook, IP Geolocation, DNS information and also from news articles.
What I thought I could do is once I had the different data sources together, I would write custom rules that could infer insights from individual or combined data sets.
These insights would form the basis of the "digital brand expert".
After all, that was the goal of the idea, something that could help out small business owners.</p>
<p>After 2 years of working on this in my spare time, it felt the right time to leave my job and go into this full time.
I felt like I was <em>so close</em> to launching and I just needed something more than the same day-to-day work.
So I did it - <a href="https://turnerj.com/blog/i-left-my-job-today-after-seven-years">I left my job after 7 years</a>.</p>
<h3>Going Full-time into the Idea</h3>
<p>Right out of the gate, I had moved from .NET Framework to .NET Core, was working on UI/UX improvements for the application and launched the website for it.
I worked with an accountant and a lawyer to setup the business, bought a trade mark for the product name, and I felt good like I was only a few months away from launching.
This feeling didn't last though...</p>
<p>Over time, it felt like I was taking two steps forward then one step back - some technical, some business related.
Sure, that is still progress, but having new issues crop up every day or so can really crush your motivation.</p>
<p>My best/happiest/most productive days were days I ignored or avoided different issues I had.
If I had a problem with the login system, I would focus on how the UX of the menus worked.
If I had a problem with data gathering, I would add more tests to the codebase.
While I didn't entirely ignore the problem, I would wait a week or two before I looked at it again, somewhat hoping it would solve itself - unfortunately that isn't how things work.</p>
<p>In time though, I got to a stage where it felt like I could launch and was hyping myself up until reality struck: I didn't actually build what I set out to build.</p>
<p>The UI/UX was good, I had strategies for deployment and plans for next steps, but it wasn't a "digital brand expert".
It was instead a glorified data store for information that people could better access through existing tools.
That's kinda a big problem!</p>
<p><img src="https://turnerj.com/blog/2020/images/a-better-mousetrap-ive-made-a-huge-mistake.gif" alt="Gob Bluth saying &quot;I've made a huge mistake.&quot; from the TV Show &quot;Arrested Development&quot;"></p>
<p>When realising this I poured time into fixing that huge lapse in judgement, but I couldn't do it.
No matter how I tried, I just couldn't figure out how to build this rules engine.
It was like my entire thought process was just clouded.
I couldn't see the solution to the problem like I can for most other things.</p>
<p>This was depressing and I ended up having a month or so hiatus from working on it.
When I have had stints of not feeling like or not being able to do programming in the past, I try and spur it on again by watching some show or movie which has some strong relation to technology (fictional or not).
My go-to is usually something like <a href="https://www.imdb.com/title/tt0371746/">Iron Man</a>, but this time I was rewatching <a href="https://www.imdb.com/title/tt2543312/">Halt and Catch Fire</a> where I found some inspiration.</p>
<h2>The Pivot: An API to the Internet</h2>
<p>Later in the series a lot of the focus is around the Web, and it was in these episodes where my thoughts about the Internet and the data on it have changed.
There is a quote from one of the main characters at the end of Season 3 that resonates with me:</p>
<div>
<blockquote>
<p>"The moment we decide what the Web is, we've lost. The moment we try to tell people what to do with it, we've lost.
All we have to do is build a door and let them inside."</p>
<p>- Joe MacMillan (Season 3, Episode 10)</p>
</blockquote>
</div>
<p>The Internet is a treasure trove of information, it is searchable but generally unstructured.
People have managed to create all sorts of different pages in HTML, but in the process of making a website everything is designed for a human user.
It is this way for obvious reasons, <em>we</em> are the consumers of web pages after all... aren't we?</p>
<p>Behind these user-friendly web pages are usually other specific bits of markup, providing some level of structured data for specific situations.
Sometimes it is a description metatag for search engines, other times it might be <a href="https://ogp.me/">Open Graph</a> metatags for social media links.
We build these things to help aid computers processing our web pages.</p>
<p>In 2011, <a href="https://schema.org/">Schema.org</a> was created.
This was a collaborative effort between Google, Bing and Yahoo (later that year, Yandex as well) with the mission to "create, maintain, and promote schemas for structured data on the Internet, on web pages, in email messages, and beyond".
Through 3 different encodings (<a href="https://turnerj.com/blog/what-is-microdata-and-why-should-i-care">Microdata</a>, <a href="http://rdfa.info/">RDFa</a> and <a href="https://json-ld.org/">JSON-LD</a>), websites could express detailed structured data.</p>
<p>There is another quote from Halt and Catch Fire which I like:</p>
<div>
<blockquote>
<p>"Computers aren't the thing. They're the thing that gets us to the thing."</p>
<p>- Joe MacMillan (Season 1, Episode 1)</p>
</blockquote>
</div>
<p>As much as I like computers and programming, they are used to help us achieve other goals.
From my attempts of trying to build a "digital brand expert", I knew that data is fundamental to help build more advanced systems and give new insights.
Having easier access to other forms of data from web pages around the world may allow new and different tools to be built.</p>
<p>So I decided rather than try and solve a problem that I was clouded by, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turnerj.com/blog/a-better-mousetrap">https://turnerj.com/blog/a-better-mousetrap</a></em></p>]]>
            </description>
            <link>https://turnerj.com/blog/a-better-mousetrap</link>
            <guid isPermaLink="false">hacker-news-small-sites-24948779</guid>
            <pubDate>Sat, 31 Oct 2020 02:49:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complexity in Operating Systems]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24945856">thread link</a>) | @fcambus
<br/>
October 30, 2020 | https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html | <a href="https://web.archive.org/web/*/https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Over the last years I’ve been working on very different operating
systems. Operating systems are usually incredibly complex beasts. I
think there are mainly three drivers of this complexity. Surprisingly
enough, neither of these is having to deal with hardware.</p>

<p>The first one is resource <strong>discovery</strong>, i.e. figuring out how the
computer the OS is running on actually looks like. On x86, this
involves parsing countless bitfields, tables, executing byte code
provided by the firmware, probing individual features, etc. The most
painful example of this I’ve seen so far is figuring out which
interrupt a particular PCI interrupt line is routed to. It’s worth a
set of posts, but until then, feel free to checkout <a href="https://habr.com/en/post/501912/">this
description</a>. (If it’s down, it’s
also cached by
<a href="https://webcache.googleusercontent.com/search?q=cache:CXZUV61m7hwJ:https://habr.com/en/post/501912/+&amp;cd=1&amp;hl=en&amp;ct=clnk">Google</a>.)</p>

<p>The second issue is <strong>resource management</strong>. Essentially, how do you
hand out and eventually reclaim all the resources you discovered. For
some workloads performance matters here, so this code is usually
written with speed in mind.</p>

<p>The third reason is that at compile time the <strong>workload</strong> is
unclear. So the kernel has to assume the worst. It must be ready to
start a couple of hundred VMs or create a thousand TCP sockets in a
blink of an eye, because there is no way to know what’s going to
happen or what the actual requirements are.</p>

<p>A fun exercise is to checkout the <a href="https://elixir.bootlin.com/linux/v5.9.1/source/virt/kvm/kvm_main.c#L739">KVM code for creating
VMs</a>. Try
to follow
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/x86.c#L9904">the</a>
<a href="https://elixir.bootlin.com/linux/v5.9.1/source/arch/x86/kvm/vmx/vmx.c#L7059">code</a>
to where the actual VM is created in hardware. <em>Spoiler:</em> There is
none. It’s all figuring out what the platform can do and then setting
up a bunch of spinlock, mutexes, lists, arrays, structs, …</p>

<p>I don’t want to pick on KVM in particular. I think it’s pretty ok as
far as Linux kernel code goes. Operating System kernel code is mostly
like this: A lot of really mind numbing platform discovery and
resource management code written for speed assuming the worst case
requirements in a language that doesn’t do parsing, resource
management or concurrency well (among other things).</p>

<p>People take this all for granted. But when I look around, I see many
systems that don’t need this complexity and where it is only a safety
and security burden. Consider most appliance-type products, e.g. a
Wi-Fi router. Or a system that runs one service on a cloud VM. You
know everything in advance!</p>

<p>If you read until this point, you are probably asking yourself, where
I am going with this. If you think <a href="https://en.wikipedia.org/wiki/Separation_kernel">separation
kernel</a>, you are
right. My rough plan to write a couple of more posts to flesh out the
idea of doing all the complicated OS parts at compile time and how
this results in an incredibly simple, secure, and efficient system at
runtime. There will be <a href="https://riscv.org/">RISC-V</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://dhall-lang.org/">Dhall</a>,
and <a href="https://www.rust-lang.org/">Rust</a> content.</p>

<p>Stay tuned.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://x86.lol/generic/2020/10/30/complexity-in-operating-systems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945856</guid>
            <pubDate>Fri, 30 Oct 2020 19:20:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Neighbourly Solution to the 'X Is Deprecated? ' Conundrum]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24945538">thread link</a>) | @zdw
<br/>
October 30, 2020 | https://www.divergent-desktop.org/blog/2020/10/29/improving-x/ | <a href="https://web.archive.org/web/*/https://www.divergent-desktop.org/blog/2020/10/29/improving-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <article lang="en">
          
          <p>Recent posts about the state of Xorg and its future has been stirring the
internets as of late and, as almost always, it is best to stay clear of the
comments sections. The more insightful post is <a href="https://ajaxnwnk.blogspot.com/2020/10/on-abandoning-x-server.html">On Abandoning the X Server</a>.</p>

<p>There are a few details in it that should be emphasised before we move on.</p>

<div><div><pre><blockquote>Though the code happens to implement an unfortunate
specification, the code itself is quite well structured, easy to hack on, and
not far off from being easily embeddable.</blockquote></pre></div></div>

<p>From my own experiences with Xorg internals, I agree completely. A whole lot
of the code there is noticably better than corresponding paths in certain
Wayland compositors. There is more thought; domain expertise; engineering and
pure elbow grease behind it than you might have been led to believe -- if you
have only listened in to the collective moans in various discussion groups.</p>

<div><div><pre><blockquote>So is Xorg abandoned? To the extent that means using it to actually
control the display, and not just keep X apps running, I'd say yes. But xserver
is more than xfree86. Xwayland, Xwin, Xephyr, Xvnc, Xvfb: these are projects
with real value that we should not give up. A better way to say it is that we
can finally abandon xfree86.</blockquote></pre></div></div>

<p>There are some nuances here that many will miss as it requires you to know
something about the architecture of the X server. The main thing is to not
conflate ‘xfree86’ with rest of what you think of as X, hence why the blog post
separates out XFree86-the-project from 'xfree86 the hardware driver'. It is
unfortunate that the predecessor to Xorg was also called XFree86. Naming
things is hard and all that.</p>

<p>If you look at the xorg code, recommended reading for many who can
understand the language, you will see that the device-dependent code used to
drive displays (hw/ in the source tree) has a few backends, mentioned above.
Venture into the hw/xfree86 part and you will hopefully see why Adam Jackson
and others deserve the software engineering equivalent of a Purple Heart for
their service to your desktop, possibly alongside anyone that ever had to work
on ASN.1.</p>

<p>
<i>Rightfully throw Xorg-xfree86 into the fires of Mt. Doom. If you
still need Xorg-xfree86 to be your graphics card driver, you have bigger things
to worry about, such as plain old bitrot.</i></p>

<p>Is there something else? Yes. I’m not going to say <a href="https://arcan-fe.com/">Arcan</a> – it is <i>very</i> likely that there
is only a small percentage of the stakeholders we would ever get along with.
That is fine. The goals and agenda reach much further than many will ever care
to travel -- unless you really want to push the boundaries of computing, or you
are actively targeted by nefarious individuals; our funding is not based on
popularity or mass adoption, but rather sticking to the shadows.</p>

<h2>The Compromise</h2>
<p>So what can we do instead? The current Wayland maintainer has
<a href="https://github.com/emersion/libliftoff">libliftoff</a> for smoothing
over the rather ‘unergonomic’ APIs that are used to get the open, modern,
graphics stack up and running. <em>Write a DDX backend that uses it.
hw/liftoff!</em></p>

<p>This will get liftoff the lift-off and mileage it needs to become good
enough for Wayland compositors to use as their default, and as a slightly more
polite migration path in order for NVIDIA to be less contemptible in the
unlikely event that they are one day struck by some capitalist version of
religious insight. Thus, it improves parts of the Wayland compositor situation
that is, politely put, chaotic.</p>

<p>Those that don’t care about what Wayland tries to achieve can stay with X and
not worry about their graphics breaking after a kernel update, or well, more
than usual -- Linux gotta Linux. NVIDIA blob users can continue down that path
and stop bothering Wayland developers, yet still run their Steam games without
submitting to open source ideals.</p>

<p>Next steps. This is for the window managers. Take libarcan-shmif-server and
embed as a module in Xorg, fork it off even. If you are unaware, this is the
IPC system part of Arcan. Both the server and the client sides of it are fairly
trivial to use and are written with developers, not toolkits, in mind.</p>

<p>It is beyond feature parity with the rest of X, but has a comparable view on
capabilities and division of responsibility. You will only get a fraction of
the benefits of Arcan as a display server, but without other dependencies or
friction - many of the problems that X clients are plagued with can be worked
around while leaving the X11 protocol and its family of extensions to rest.
Hacks relying on facilities like uinput can be put down.</p>

<p>The security around these clients will be much tighter and they can be
gradually tuned to the specification of the developer. It lets XFCE, AwesomeWM,
WindowMaker and the tens to hundreds of others WM projects to continue to
improve their respective ecosystems, specialized widgets and other tools,
rather than to burn resources they don't have to rewrite themselves with bugs
that won't be discovered or fixed in time to matter.</p>

<p>It also gives the conservative side of BSDs a portable way of improving
their use of the graphics stack without reworking fundamentals they care little
about. The OpenBSD fork 'Xenocara' can be dropped.</p>

<p>This way, the heritage is preserved and kept alive, with a band aid to live
out another decade or three. It will still work for the marginalized that have
little interest- or option- in going elsewhere. It will be less painful to
maintain and work with.</p>

<h2>The Reality</h2>
<p>Wayland only is not an option that will ever work across the board. It is
not a replacement, it is a fundamental change of principles. Stop trying to
market it as some kind of inevitable transition. There are strong differences
that will not get smoothed over regardless of how many 'protocols' you define;
<i>Wayland is Policy over Mechanism, X11 is Mechanism over Policy</i>. This is
the real barrier. Not unsubstantiated claims of 'security'. It is a tectonic
shift and no matter your feelings about that, we won't all be in the same
country or continent anymore.</p>

<p>Heralding a 'Screenshot Protocol' and similar exercises as the fix that will
bridge this gap will only serve to distract from the fact that the power of all
these little tools and hacks from the crowd of X11 users comes from the
'screenshot' being just one case of <i>'give me the contents of a specific
window and all of its children'</i> or <i>'composite these windows to an
offscreen buffer and send me the results'</i> as the building blocks
available to be creative with.

</p><p>The mechanism approach provides a huge set of possibilities and opens up for
experimentation and 'works for me' kind of hacks. The downside is that it
surrenders control on the server side and are much harder to make robust.</p>

<p>The policy aproach will only do what both sides agree to, and <i>that
	agreement has the final say</i>. If you violate this contract, you are to be
blamed. However, that contract has to be bikeshedded to near state-space
exhaustion and carefully screened for conflicts as more contracts are added to
the pile.</p>

<p>The current trajectory is Gnomelanders and Swaylanders and Kwinners and so
on continuing to lock down singular uses cases and with political gunplay try
to push that as the one solution that will convince a few more bread crumbs.
The hand that controls the toolkit will eventually just decide. <i> This will
erode the strength of the policy contract</i>.</p>

<p>This has already led to a substantial amount of dissonance -- it turns out
that the 'opting-server-side decoration protocol' in the mix had implications
for how to interpret the 'subsurface protocol' and the 'redshift gamma
protocol' will clash with whatever 'color management protocol' that materialize
and so on. To get a feel for how involved such policies become, just <a href="https://github.com/wayland-project/wayland-protocols/blob/3a74660e94d85fde24f504cc9d4375d42192e84a/stable/xdg-shell/xdg-shell.xml#L402">
read the specification</a> and you will see why no implementation arrives at
the same calculation.</p>

<p>Take the perspective of a client developer chasing after the tumbleweed of
'protocols' drifting around and try to answer 'what am I supposed to implement
and use'? To me it looked like like a Picasso painting of ill-fitting- and
internally conflicted ideas. Let this continue a few cycles more and X11 will
look clean and balanced by comparison. Someone should propose a desktop icon
protocol for the sake of it, then again, someone probably already has.</p>

<h2>In Conclusion</h2>
<p>This approach will force Wayland to demonstrate its worth through the
virtues of its properties alone or by inventing actually compelling features
rather than by throwing shade on the elderly; or reimplementing the past
through rebranded and traced outlines from shadows cast by grander window
managers of yore.</p>

<p>The proposal leaves us with three well-defined paths.</p>

<ul>
<li>Wayland lets your own solipsist thiefdoms expand towards the horizon,
while trying to save embedded from the Android expanse.</li>
<li>People that have invested their hearts and souls into the X ecosystem can
continue to use their computers without fear of a kernel upgrade leaving them
with broken graphics, or a switch of display server paradigm leaving them with
an incompatible mental model of how system graphics work, and perhaps, one day,
stop whining about Wayland ruining their day and leave the devs alone.</li>
<li>Arcan lets you play with crazy ideas at a low initial cost. The ones
that might revolutionise your world or fail miserably. It will continue to
pushing things towards whatever is beyond the Twilight Zone in order to answer
profound questions such as 'what happens to productivity if your heartbeat
aligns with the blink rate of the cursor' (well that's actually be done since
forever and the RESULTS WOULD SHOCK YOU! - but it still illustrates the
point).</li>
</ul>

<p>It might even turn out so well that one of these paths will have a
fighting chance against the open desktop being further marginalised as a thin
client in the Azure clouded future; nothing more than a silhouette behind
unwashed Windows, a virtualized ghost of its former self.</p>

        </article>
	     </div>
     </div></div>]]>
            </description>
            <link>https://www.divergent-desktop.org/blog/2020/10/29/improving-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945538</guid>
            <pubDate>Fri, 30 Oct 2020 18:45:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New social media platform, Lighf, looking forward to welcoming its future users]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24945358">thread link</a>) | @imanonymous
<br/>
October 30, 2020 | https://lighf.com/request-lighf/ | <a href="https://web.archive.org/web/*/https://lighf.com/request-lighf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div text-align:="" center;"=""><p><span>lighf</span> doesn’t store your IP address or any other identifiable data about you. By default your layers (privacy) are to set to <em>None</em> but you can add additional layers.</p>
<p><em>Encrypted</em>, means your email address is encrypted the second you create an account and only unencrypted, with your permission, at times when you need to recover your password.Â&nbsp; The draw back is you won’t be able to get <span>lighf</span> updates by email, only In-App and Push (coming soon).</p>
<p>To go <em>Email-less</em> means no email address is linked to your <span>lighf</span> Account. Like the Encrypted option, you won’t receive any updates by email, only In-App and Push (coming soon). The draw back is that you won’t be able to reset your password or <span>lighf</span>Name (username) or recover your Account.</p>
<p><a title="Tap this link to close." href="#">Got It!</a></p>
</div>
</div></div>]]>
            </description>
            <link>https://lighf.com/request-lighf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24945358</guid>
            <pubDate>Fri, 30 Oct 2020 18:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recovering Lost Roam Notes]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24944574">thread link</a>) | @jchen42
<br/>
October 30, 2020 | https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/ | <a href="https://web.archive.org/web/*/https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post dives deep into a scary data loss scenario - we'll cover identifying the data loss, investigating the root cause, and finally recovering the data.</p>
<p><strong>This bug affected Readwise users who exported their highlights (both manually &amp; automatically) to Roam on 10/27. If you are one of those users, you should contact Roam support &amp; use <a href="https://github.com/jchen1/roam-restore" target="_blank" rel="nofollow noopener noreferrer">my recovery code</a> ASAP!</strong></p>
<h2>Background</h2>
<p><a href="https://roamresearch.com/" target="_blank" rel="nofollow noopener noreferrer">Roam</a> is a "note-taking tool for networked thought". It supports all sorts of cool things - what's relevant here is that it automatically creates a new page for every day, your Daily Notes. Recently, I started using <a href="https://readwise.io/" target="_blank" rel="nofollow noopener noreferrer">Readwise</a>, which ingests Kindle highlights and uses <a href="https://en.wikipedia.org/wiki/Spaced_repetition" target="_blank" rel="nofollow noopener noreferrer">spaced repetition</a> to help you remember what you read. Readwise has a Roam integration, which automatically adds Kindle highlights to Roam. Unfortunately, since Roam doesn't have a public API yet, Readwise's integration seems to be effectively using Selenium - clicking on elements and pasting highlights which is inherently flaky.</p>
<p>Yesterday, I woke up without my Daily Notes from the day before. Disaster! Fortunately, with the help of the Roam Slack group and Tristan from Readwise, I was able to isolate the cause of note deletion and even restore my lost data. Here's what happened:</p>
<!-- excerpt -->
<h2>Roam architecture</h2>
<p>Roam uses <a href="https://github.com/tonsky/datascript" target="_blank" rel="nofollow noopener noreferrer">Datascript</a> for its client-side database. Like Datomic, Datascript stores data as a <code>datom</code>, defined as <code>[e a v tx]</code>, or <code>entity</code>, <code>attribute</code>, <code>value</code>, and <code>transaction-id</code> (incrementing integer). If you're interested in learning more, <a href="https://tonsky.me/blog/datascript-internals/" target="_blank" rel="nofollow noopener noreferrer">Datascript's author has an excellent overview</a>.</p>
<p>Importantly for us, Roam differs from other webapps in that it doesn't store all state and history in its backend. Instead, Roam's backend just stores a snapshotted Datascript database (updated ~daily as far as I can tell) and the list of transactions since that last snapshot. If we can download those two things before Roam's next snapshot, we have two breadcrumbs towards recovery: 1. We can find the transaction that deleted my Daily Notes page 2. We can also reconstruct our Datascript database, replaying transactions up until the point of deletion, and recover our Daily Notes from that!</p>
<h2>Capturing state</h2>
<p>Our first step is to store Roam's database snapshot and transaction list. Instead of REST API calls, Roam uses a Websocket connection to send these to its web client. This complicates things for us: instead of just saving API responses with <code>curl</code>, we need to download a <a href="https://en.wikipedia.org/wiki/HAR_%28file_format%29" target="_blank" rel="nofollow noopener noreferrer">HAR file</a>, which, fortunately for us, includes Websocket traffic with more recent Chrome versions. HAR files are just JSON archives stored in chronological order - it's easy to select just the Websocket traffic:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)]
    ws-data))</code></pre>
<p>Inspecting this data more closely, it appears that Roam's websocket messages are generally JSON strings (and occasionally numbers). When a message is more than 16KB, it's split into multiple messages without wrapping - so we'll need to stitch these bigger messages together. One way to detect a non-split-message is to just try and parse it as JSON - if it's valid, we can say it's non-split. (There's an edge case we're unlikely to hit here: if the 16KB chunk just so happens to be valid JSON as well we'll be out of luck. Lucky for us, I didn't run into this!) Now, we can extend <code>parse-har</code> as follows:</p>
<pre><code>(<span><span>defn</span></span> parse-har
  [harfile]
  (<span><span>let</span></span> [json (<span>json/parse-string</span> (<span><span>slurp</span></span> harfile) <span>true</span>)
        ws-messages (<span><span>-&gt;&gt;</span></span> json <span>:log</span> <span>:entries</span> (<span><span>filter</span></span> #(<span>some?</span> (<span>:_webSocketMessages</span> %))) second <span>:_webSocketMessages</span>)
        ws-data (<span><span>map</span></span> <span>:data</span> ws-messages)
        try-parse #(<span><span>try</span></span> (<span>json/parse-string</span> % <span>true</span>)
                        (<span>catch</span> Throwable _ <span>nil</span>))
        
        
        
        ws-json (<span><span>reduce</span></span> (<span><span>fn</span></span> [{<span>:keys</span> [done partial]} next]
                          (<span><span>let</span></span> [potential-json-str (<span><span>str</span></span> partial next)]
                            (<span><span>if-let</span></span> [json (<span>try-parse</span> potential-json-str)]
                              {<span>:done</span> (<span><span>conj</span></span> done json)
                               <span>:partial</span> <span>""</span>}
                              {<span>:done</span> done
                               <span>:partial</span> potential-json-str})))
                        {<span>:done</span> [] <span>:partial</span> <span>""</span>}
                        ws-data)]
    (<span><span>assert</span></span> (<span><span>=</span></span> (<span>:partial</span> ws-json) <span>""</span>))
    (<span>:done</span> ws-json)))</code></pre>
<h2>Finding the culprit</h2>
<p>Armed with our parsed websocket messages, we can see that many of them look like transactions. One that looks particularly suspicious has a nested field named <code>tx-meta</code> with the value <code>delete-page</code>! The transaction looks something like this:</p>
<pre><code>{<span>:app-version</span> <span>"0.7.4"</span>,
 <span>:email</span> <span>"hello@jeff.yt"</span>,
 <span>:session-id</span> <span>"uuid95d98efd-c8fa-4412-87a4-e7b7201bee24"</span>,
 <span>:t</span> <span>1603947791561</span>,
 <span>:time</span> <span>1603947791542</span>,
 <span>:tx</span> <span>"[[\"^ \",\"~:block/uid\",\"ogCRjInhE\",\"~:block/string\",\"some-text-here\",\"~:edit/time\",1603947791363,\"~:edit/email\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"4CpSytRnt\",\"^1\",\"Highlights first synced by #Readwise October 28th, 2020\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"^ \",\"^0\",\"C-IOsE50G\",\"^1\",\"New highlights added October 28th, 2020 at 11:03 PM\",\"^2\",1603947791364,\"^3\",\"hello@jeff.yt\"],[\"~:db.fn/retractEntity\",[\"^0\",\"hLBqaz4gS\"]],[\"^4\",[\"^0\",\"vwD08rqdT\"]],[\"^4\",[\"^0\",\"6VWOGgeAd\"]],[\"^4\",[\"^0\",\"P56-fWN2O\"]],[\"^4\",[\"^0\",\"SffV3NfN2\"]],[\"^4\",[\"^0\",\"qnZBZCGCv\"]],[\"^4\",[\"^0\",\"10-28-2020\"]]]"</span>,
 <span>:tx-meta</span> {<span>:event-id</span> <span>"uuid719b009f-b969-47b6-b2db-41542d10b328"</span>,
           <span>:event-name</span> <span>"delete-page"</span>,
           <span>:tx-id</span> <span>"uuid289e80fc-4c27-4d54-9df4-d83ac0ceeaed"</span>,
           <span>:tx-name</span> <span>"delete-page"</span>}}</code></pre>
<p>I omitted ~90% of the transaction to save space - but it's more of the same. This definitely looks like the transaction that deleted my Daily Notes page: I see <code>db.fn/retractEntity</code> as well as <code>10-28-2020</code> in the transaction. Interestingly, this transaction captures two Readwise interactions as well. It's not a smoking gun, but it's definitely suspicious that Readwise was operating on my database at the <strong>exact same time</strong> that my page was mysteriously deleted!</p>
<p>Let's pause here, and check in with the Roam Slack group. Someone else has already started a thread about data loss! They and others quickly confirm that they also all have Readwise's auto-export enabled. Again, it's not confirmation that Readwise is to blame, but it's enough for me to stop what I'm doing and disable my Readwise integration! We'll also share our knowledge in the Slack thread and ask affected users to save their Roam HAR file like we did.</p>
<p>Later, <a href="https://twitter.com/homsiT" target="_blank" rel="nofollow noopener noreferrer">Tristan, founder of Readwise</a>, pops into Slack and quickly confirms that <a href="https://twitter.com/homsiT/status/1321856588022513665" target="_blank" rel="nofollow noopener noreferrer">a recent Roam behavior change combined with the Readwise integration can cause deleted pages</a>. Huge props to Tristan who responds perfectly: he triages the issue, disables the feature to prevent any more users from hitting it, and fixes &amp; re-enables auto-export all within a couple hours! Tristan also remains communicative and takes full responsibility, even offering refunds, though I'd argue that these hiccups are bound to happen when Roam still hasn't opened up their public API.</p>
<h2>Deserializing the database</h2>
<p>Peeking again at our parsed HAR file, we see what appears to be our serialized database - it's stored like this:</p>
<pre><code>{<span>:split-db</span> {<span>0</span> <span>"transit-encoded-str-0"</span>
            <span>1</span> <span>"transit-encoded-str-1"</span>
            ...}}</code></pre>
<p>Each string looks something like this:</p>
<pre><code>[\\\"^P\\\",[1641,\\\"^H\\\",\\\"zeciaTJfg\\\",536877373]],[\\\"^P\\\",[1641,\\\"^17\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^18\\\",1583270770601,536877373]],[\\\"^P\\\",[1641,\\\"^R\\\",\\\"hello@jeff.yt\\\",536877373]],[\\\"^P\\\",[1641,\\\"^S\\\",1583270784121,536877377]],[\\\"^P\\\",[1642,\\\"^E\\\",1643,536877384]]
</code></pre>
<p>This looks like Transit! <a href="https://github.com/cognitect/transit-format" target="_blank" rel="nofollow noopener noreferrer">Transit</a> is a JSON-like format for sending data between applications (<a href="https://blog.klipse.tech/clojure/2016/09/22/transit-clojure.html" target="_blank" rel="nofollow noopener noreferrer">this post</a> is a good introduction). Datascript has its own <a href="https://github.com/tonsky/datascript-transit/" target="_blank" rel="nofollow noopener noreferrer">set of Transit handlers</a> - let's import that and see if we get a working database! Of course, we'll also need to combine <code>split-db</code> by smashing the Transit-encoded strings together.</p>
<pre><code>(<span>require</span> '[datascript.transit <span>:as</span> dt])

(<span><span>defn</span></span> parse-db
  [parsed-har]
  (<span><span>let</span></span> [db-str (<span><span>-&gt;&gt;</span></span> parsed-har
                    
                    (<span><span>filter</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>))
                    first <span>:d</span> <span>:b</span> <span>:d</span> <span>:split-db</span>
                    vals
                    (<span>string/join</span> <span>""</span>))]
    (<span>dt/read-transit-str</span> db-str)))</code></pre>
<p>Voila - a real Datascript database! We can confirm it's my Roam database by querying it:</p>
<pre><code>(<span>require</span> '[datascript.core <span>:as</span> d])
(<span><span>let</span></span> [db (<span><span>-&gt;</span></span> harfile (<span>parse-har</span>) (<span>parse-db</span>))
      conn (<span>d/conn-from-db</span> db)]
  (<span>d/q</span> '[<span>:find</span> ?e <span>:where</span> [?e <span>:node/title</span> <span>"Daily Template"</span>]] @conn))

</code></pre>
<p>With a working Roam database, our next step is to apply all of the transactions we have up until the deletion event. Transactions are Transit-encoded, and we'll have to do quite a bit of data manipulation to get a list of them. Once we have that list, we can sort the transactions and apply them sequentially:</p>
<pre><code>(<span><span>defn</span></span> apply-transactions-until
  [db parsed-har until-time]
  (<span><span>let</span></span> [transactions-to-apply (<span><span>-&gt;&gt;</span></span> parsed-har
                                   (<span><span>map</span></span> #(<span>some-&gt;</span> % <span>:d</span> <span>:b</span> <span>:d</span>))
                                   (<span><span>filter</span></span> seqable?)
                                   (<span><span>apply</span></span> concat)
                                   (<span><span>filter</span></span> #(<span>string/starts-with?</span> (<span><span>-&gt;</span></span> % first name) <span>"-MK"</span>))
                                   (<span><span>map</span></span> second)
                                   (<span><span>filter</span></span> #(<span><span>&lt;</span></span> (<span>:time</span> %) until-time))
                                   (<span><span>sort-by</span></span> <span>:time</span>)
                                   (<span><span>map</span></span> <span>:tx</span>)
                                   (<span><span>map</span></span> dt/read-transit-str))
        conn (<span>d/conn-from-db</span> db)]
    (<span><span>doseq</span></span> [tx transactions-to-apply]
      (<span>d/transact!</span> conn tx))
    (<span>d/db</span> conn)))</code></pre>
<p>Here, <code>until-time</code> is the time of the deletion transaction. We're so close now! We've managed to materialize my Roam database from <strong>right before my notes were deleted</strong>! All we need to do now is pull that deleted page, and we'll be done!</p>
<h2>Recoverin…</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/">https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</a></em></p>]]>
            </description>
            <link>https://jeffchen.dev/posts/Recovering-Lost-Roam-Notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944574</guid>
            <pubDate>Fri, 30 Oct 2020 17:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KDE.org migrated to Hugo]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 71 (<a href="https://news.ycombinator.com/item?id=24944537">thread link</a>) | @ognarb
<br/>
October 30, 2020 | https://carlschwan.eu/2020/10/30/kde-org-hugo.html | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2020/10/30/kde-org-hugo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><img src="https://carlschwan.eu/assets/img/heading_hugo.png" alt="Screenshot KDE.org"></p>

<p><a href="https://kde.org/">KDE.org</a> now uses <a href="https://gohugo.io/">Hugo</a>. Hugo is a fast and modern static site
generator written in Go. It provides a few improvements over the old system that was
using plain PHP. A large part of the work was done by Anuj during GSoC 2020. This
was a massive work, converting the repository storing more than 20 years of KDE
history.</p>

<p>The website is now generated once and no longer uses PHP to generate itself at runtime.
This improves the loading speed of the website, but the speed boost is not significant,
since the PHP code used before was quite small and KDE’s servers are powerful.</p>

<p>But the biggest improvement is in terms of features. We are now working with markdown
files instead of raw HTML files, this makes the life of the promo team much easier.</p>

<p>The internationalization of the website now creates a unique URL per language, this
should allow Google to link to the version of the website using the correct language.
A <a href="https://kde.org/fr/">French</a>, <a href="https://kde.org/uk/">Ukrainian</a>,
<a href="https://kde.org/ca/">Catalan</a>, <a href="https://kde.org/nl/">Dutch</a>, and a few more languages
are already available. There is also a proper language selector! We also don’t need
to manually tag each string for translations.</p>

<p>There is also now an <a href="https://kde.org/announcements/index.xml">RSS feed</a> with all the
latest announcements. Another big improvement is that the announcements list is
autogenerated and no longer modified by hand and with the help of the release scripts.</p>

<p>Another nice change for website developers is that now the SCSS code for the individual
pages is located in the kde-org repository itself instead of another repository.
Overall the developer experience is much better, there is no need to set up an apache
server and to the PHP configs to include the <a href="https://invent.kde.org/websites/capacity">capacity framework</a>, just to get the
website running locally. Now you only need to download the Hugo binary from their
release page and run it on the repo.</p>

<h2 id="hugo-and-gettext">Hugo and Gettext</h2>

<p>The internationalization of KDE.org was quite a challenge. When working on a multilingual
website with Hugo, Hugo expects a markdown document per language for each translated
page.</p>

<div><div><pre><code>plasma-desktop.md
plasma-desktop.es.md
plasma-desktop.fr.md
plasma-desktop.uk.md
...
</code></pre></div></div>

<p>The problem is that traditional translations workflow rely on a string-based approach,
where a document is split in paragraphs and translated individually. So I couldn’t
just put each file markdown file as big blobs in the po files. To solve this problem,
I created a python script splitting the markdown files in paragraphs, simplifying
the markdown syntax (removing leading <code>#</code> and <code>+</code> for heading and list item). This
script also handles Hugo shortcodes transforming:</p>

<div><div><pre><code>
{{&lt; img caption="My figure caption" alt="My accessible description" src="..." &gt;}}

</code></pre></div></div>

<p>in two strings:</p>

<ul>
  <li>My figure caption</li>
  <li>My accessible description</li>
</ul>

<p>The script can obliviously put the individual strings back in place. The scripts also
handle the menu translation, and the translations of the strings in the footers.
For now, the script is just a file in the kde-org repository, but I would like to
transform it to a standalone library so that other gettext and Hugo users can
translate their website.</p>

<p>Using Hugo API, the language selector was trivial to write:</p>

<div><div><pre><code>
&lt;ul class="navbar-nav ml-auto"&gt;
  {{ if .IsTranslated }}
    &lt;li class="nav-item dropdown" aria-describedby="language-picker-description"&gt;
      &lt;p class="sr-only" id="language-picker-description"&gt;{{ i18n "Select-your-language" }}&lt;/p&gt;
      &lt;a class="nav-link dropdown-toggle" href="#" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"&gt;
        &lt;img src="/Language-Icons/icon20x24px-exported-transparent.png" alt="" /&gt;
        &lt;span&gt;{{ i18n "translations" }}&lt;/span&gt;
      &lt;/a&gt;
      &lt;div class="dropdown-menu dropdonw-trans" role="listbox"&gt;
        &lt;a class="dropdown-item" aria-selected="true" hreflang="{{ .Site.Language.Lang }}" role="option" lang="{{ .Site.Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Site.Language.LanguageName }}&lt;/a&gt;
        {{ range .Translations }}
          &lt;a class="dropdown-item" hreflang="{{ .Language.Lang }}" role="option" lang="{{ .Language.Lang }}" href="{{ .Permalink }}"&gt;{{ .Language.LanguageName }}&lt;/a&gt;
        {{ end }}
      &lt;/div&gt;
    &lt;/li&gt;
  {{ end }}
&lt;/ul&gt;

</code></pre></div></div>

<p>This is a bit verbose because this selector is also fully accessible for screen readers.</p>

<p>There are a few more tricks employed in kde.org to improve the internationalization, for
example when a page doesn’t exist in a language, there is an Apache rule redirecting it
to the English version. Another nice trick is that there is a special Hugo shortcode
called <code>i18n_var</code> and used to parametrize the strings. For example:</p>

<div><div><pre><code>
{{&lt; i18n_var "Today KDE releases a bugfix update to KDE Plasma 5, versioned %[1]s" "5.20.2" &gt;}}

</code></pre></div></div>

<p>And the extractor is clever and only extract the part that needs to be translated.</p>

<p><a href="https://invent.kde.org/websites/kde-org/-/blob/master/translations.py">The script</a></p>

<p>You can comment this post on <a href="https://www.reddit.com/r/kde/comments/jl1pim/kdeorg_migrated_to_hugo/?">r/kde</a>
and <a href="https://news.ycombinator.com/item?id=24944537">HN</a>.</p>
</section></div>]]>
            </description>
            <link>https://carlschwan.eu/2020/10/30/kde-org-hugo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24944537</guid>
            <pubDate>Fri, 30 Oct 2020 17:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mendoza: Use stack machines to compute efficient JSON diffs]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24943775">thread link</a>) | @evenw
<br/>
October 30, 2020 | https://www.sanity.io/blog/mendoza | <a href="https://web.archive.org/web/*/https://www.sanity.io/blog/mendoza">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When we started work on the recently released feature <a href="https://www.sanity.io/blog/review-changes">Review Changes</a>, we needed a way to keep a significant part of the edit history of a document in the browser memory to be able to respond quickly to different user interface states. As the user picked various document versions to compare we wanted to be able to quickly reconstruct a specific section of the history of a document. </p><figure><div role="button"><div data-has-aspect="false"></div></div><figcaption>Review Changes for Sanity Studio. Powered by Mendoza.</figcaption></figure><p>For text diffs, we use the <a href="https://github.com/google/diff-match-patch">diff-match-patch format</a>, and we just assumed someone would have implemented a similarly efficient and compact diff format for JSON documents, but no such luck. If we wanted a general JSON diff format that was super compact and fast to apply, we would have to invent it ourselves. And thus, Mendoza, the totally non-human readable diff format for structured JSON documents, was born.</p><p>Mendoza is:</p><ul><li>Lightweight JSON format</li><li>A flexible format that can accommodate more advanced encodings in the future</li><li>As a Go library for encoding and decoding</li><li>A JavaScript library for decoding</li><li>Efficient handling of the renaming of fields</li><li>Efficient handling of reordering of arrays</li><li>Not designed to be human-readable</li></ul><p>Mendoza differs (hah!) from normal diffs as they are:</p><ul><li>Made for humans to read and understand and based on simple operations (like keep, insert, and delete text)</li><li>Possible to apply even if the source has changed a bit by including some of the contexts around every part that has changed</li><li>Designed for text, and not structured documents</li></ul><p>Now, this is great when you are collaborating with humans on code development and use something like git to track your changes. What it isnâ€™t great for, however, is expressing differences between structured documents (such as JSON) in a compact manner that can be efficiently transferred over the network and parsed in JavaScript inside of browsers.</p><div data-block-key="27e85758c59a"><h2><a id="most-diffs-arent-meant-for-machines-27e85758c59a"></a><a href="#most-diffs-arent-meant-for-machines-27e85758c59a"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>Most diffs aren't meant for machines</h2></div><p>Most diff formats are made to be human-readable. Take these two documents, where a key and the array have some changes between them:</p><p>If these where two commits, the Git diff between them would be expressed like this:</p><p>This makes it somewhat practical for humans to understand what is going on when the latter change is applied. But as you can see, in terms of pure data, there is a lot of repetition going on. and expressing all changes with only plusses and minuses isn't very efficient.</p><p>The same diff with Mendoza is expressed like this:</p><p>Mendoza constructs a minimal recipe for transforming a document into another. All it really does is to compare two JSON documents and figure out the most minimal way to express their difference as strings and integers in an array. You can use this difference to reconstruct the first document to the other.</p><div data-block-key="308db67aa205"><h2><a id="how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"></a><a href="#how-to-read-a-mendoza-patch-even-though-you-shouldnt-308db67aa205"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 20 24"><path d="M0 0h24v24H0z" fill="none"></path><path fill="currentColor" d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76 0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71 0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71 0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76 0 5-2.24 5-5s-2.24-5-5-5z"></path></svg></a>How to read a Mendoza patch (even though you shouldn't)</h2></div><p>A Mendoza patch consists of an array of integers and strings. The integers are <em>opcodes</em> (short for â€œoperation codesâ€�), 8-bit numbers that correspond to an operation. Opcodes take parameters as strings, positive numbers, or JSON values (that is: the actual data that is changing). The list of available opcodes is as follows, notice that 10-18 are composites of the preceding ones:</p><ul><li>0 <code>Value<!-- -->â€‹ </code></li><li>1 <code>Copy<!-- -->â€‹ </code></li><li>2 <code>Blank<!-- -->â€‹</code></li><li>3 <code>ReturnIntoArray<!-- -->â€‹ </code></li><li>4 <code>ReturnIntoObject<!-- -->â€‹ </code></li><li>5 <code>ReturnIntoObjectSameKey<!-- -->â€‹ </code></li><li>6 <code>PushField<!-- -->â€‹ </code></li><li>7 <code>PushElement<!-- -->â€‹ </code></li><li>8 <code>PushParent<!-- -->â€‹ </code></li><li>9 <code>Pop<!-- -->â€‹ </code></li><li>10 <code>PushFieldCopy</code></li><li>11 <code>PushFieldBlank</code></li><li>12 <code>PushElementCopy</code></li><li>13 <code>PushFieldBlank</code></li><li>14 <code>ReturnIntoObjectPop</code></li><li>15 <code>ReturnIntoObjectSameKeyPop</code></li><li>16 <code>ReturnIntoArrayPop</code></li><li>17 <code>ObjectSetFieldValue</code></li><li>18 <code>ObjectCopyField</code></li><li>19 <code>ObjectDeleteField</code>â€‹ </li><li>20 <code>ArrayAppendValue</code>â€‹ </li><li>21 <code>ArrayAppendSlice<!-- -->â€‹</code></li><li>22 <code>StringAppendString<!-- -->â€‹</code></li></ul><p>Mendoza reads these opcodes from the patch and produces the resulting document from them. Depending on the patch, Mendoza might choose not to strictly follow the opcodes but take a simpler path. If every field and value has changed, for example, itâ€™s more efficient just to replace the whole document with the new data without going through all the operations. Or if you have a list of objects where one has moved to another position and changed a key-value, Mendoza will manage to go back to the original and represent the change in a cheap way.</p><p>Mendoza is implemented in Go and can be found in this <a href="https://github.com/sanity-io/mendoza">GitHub repository</a>. We have also made <a href="https://github.com/sanity-io/mendoza-js">a parser for Mendoza patches in JavaScript</a>, that you can use in your own application. </p><p>Of course, you can dive into <a href="https://github.com/sanity-io/sanity/blob/a3f7158016d63728a9b435e6ab444ff2b90fd424/packages/%40sanity/desk-tool/src/panes/documentPane/documentHistory/history/timeline.ts#L421">the source code for the Sanity Studio</a> and explore how Mendoza is used there. If you want a slightly simpler use-case, you can also <a href="https://github.com/sanity-io/groq-store/blob/main/src/patch.ts">check out how weâ€™re using Mendoza to simulate a part of Sanityâ€™s real-time datastore</a> in the browser to power the <a href="https://github.com/sanity-io/next-sanity">real-time preview for Next.js</a>. </p><p>Naming a project is always difficult. Since this project is focused on representing changes between <em>JSON</em> documents I naturally started thinking about names like "JSON differ, JSON changes, JSON patch, â€¦". However, most of these names have already been used by existing projects. While I was muttering "JSON, JSON, JSON" it suddenly turned into "JSON, JSON, Jason, Jason Mendoza".</p><p>Jason Mendoza is a character from the show The Good Place, and while this project has little in common with the stupidest DJ from Florida, at least it's short and catchy.</p><p>Since a Mendoza patch is just describing the effect of a change it is also limited to work for the documents it was based on. It doesnâ€™t come with guarantees for consistency if the document you apply it on has changed from the original in meanwhile. This is one of the tradeoffs that we needed to do to make it really compressed. </p></div></div></div>]]>
            </description>
            <link>https://www.sanity.io/blog/mendoza</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943775</guid>
            <pubDate>Fri, 30 Oct 2020 16:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pondering Amazon's Manyrepo Build System]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24943737">thread link</a>) | @nephics
<br/>
October 30, 2020 | http://beza1e1.tuxen.de/amazon_manyrepo_builds.html | <a href="https://web.archive.org/web/*/http://beza1e1.tuxen.de/amazon_manyrepo_builds.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>A while ago,
<a href="http://beza1e1.tuxen.de/monorepo_vcs.html">I pondered monorepo version control systems</a>.
This article is at the opposite end of the spectrum: Manyrepos.</p>
<h2>Why Manyrepo?</h2>
<p>Monorepos are alluring since Google, Facebook, and Microsoft use that approach.
Is that a part of their secret sauce or accidental?
There is another big tech company which does the opposite.
At Amazon, teams work more independently.
Some use different version control systems which are not git
like Subversion and Perforce.
I guess that most companies do <em>not</em> have a monorepo
because it is really easy to split of a separate project
but hard to merge them just from an organizational point of view.
So maybe we can learn more from Amazon than Google?</p>
<p>A common pattern is that Amazon like the others built its own infrastructure
and engineers love it and miss it after they leave.</p>
<blockquote>
<p>I've heard descriptions and seen blog entries about many other large companies build systems, but to be honest, nothing even comes close to the amazing technology Amazon has produced.
I would probably argue that what Google, Facebook, and most other companies of comparable size and larger do is at best objectively less good and at worst wasting millions of dollars of lost productivity.
–<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">terabyte</a></p>
<p>Once you understand the build and deployment tools you first wonder how you ever did anything before and then start to fear how you'll do anything once you leave.
–<a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">hohle</a></p>
</blockquote>
<p>Just like Ex-Googlers reinvented their build system on the outside
with <a href="https://www.pantsbuild.org/docs">Pants</a>
and <a href="https://buck.build/">Buck</a>.
Likewise <a href="https://qbtbuildtool.com/">QBT</a> reinvents the Amazon build system.
Unfortunately, QBT is less known and less mature.</p>
<h2>Amazon's Build System</h2>
<p>There is less information about Amazon unfortunately.
Mine is from <a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0">this gist</a>
and discussions on 
<a href="https://news.ycombinator.com/item?id=24722214">HN</a> and
<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system">lobste.rs</a>.
If I got something wrong, please tell me.
The short version is that Amazon's "Brazil" tool is
more of a package system than a build system.
It is closer to Nix than to Bazel.</p>
<p><a href="https://gist.github.com/terabyte/15a2d3d407285b8b5a0a7964dd6283b0#gistcomment-3356000">Brazil delegates the actual build process to language-specific tools</a>.
Tools, like tmux, are also packaged with Brazil.
The interesting part is how packages are managed
and the core concept to understand is <em>version set</em>.</p>
<p>If you create a package at Amazon,
you specify an <em>interface version</em> like "1.1".
As long as changes are backwards-compatible,
the interface version is not changed.
When Brazil builds a package,
it appends an additional number to turn it into a <em>build version</em>
like "1.1.3847523".
You can only specify dependencies on interface versions.</p>
<p>Another thing Brazil does when building a package
is to record the transitive closure of dependencies
with their build versions.
Modern packaging tools differ between
"dependencies you want"
and "dependencies you actually used".
For example, <a href="https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html">Cargo.toml and Cargo.lock in Rust</a>.</p>
<p>A <em>version set</em> is a collection of packages.
The "live" package is the special global one
which corresponds to a trunk branch in version control.
When you build a package "against" a version set,
the tests of all packages in the version set are executed,
and the version set is incremented.
Thus the individual package is updated
(or published if it was not part of the version set before).</p>
<p>Brazil dependencies are classified as runtime, build, and test dependencies.
So for deployment, it can strip everything but the runtime dependencies
from a version set.</p>
<p>Dependencies must be carefully managed in this environment
as a "dependency hell" scenario is possible.</p>
<blockquote>
<p>One of the biggest ways that brazil was misused was around handling of major versions [aka interface version].
For context, only a single major version of a package is allowed to exist in a versionset at a time. If you tried to merge in a different major version of a package into your versionset, your pipeline would fail to build due to "Major version conflicts". One of the biggest sins was around bumping the major versions of the dependencies in a library without bumping the major version of that library at the same time. This would lead to many broken pipelines. Let's say you have a library Foo-1.0 with a bunch of users on other teams. You decide to bump up the Guava version from 25 to 29 and publish the new version of Foo-1.0. Anyone consuming Foo-1.0 would automatically pick up the new version of that lib because it's just a minor version change, however the merge would fail with a "major version conflict" because the major version of Guava they're using in their versionset is still 25. This means you would either have to pin that library back at a previous version, or bump your dependency on Guava in all of you packages to 29.
–<a href="https://news.ycombinator.com/item?id=24731537">pentlander</a></p>
</blockquote>
<p>This is an insight that generalizes:
Updating a dependency major version is a breaking change
even if your API is stable.</p>
<h2>The Point?</h2>
<p>Overall, it sounds a lot like a distribution package manager like apt or Nix.
The difference of version sets is
that they provide a branching mechanism
and this is how teams can work independently.
How is that unique though?
You can fork with apt and Nix as well.
In a monorepo, it would be a branch.
It must be about something different.</p>
<p>One advantage of monorepos is that one can track all users.
Version sets in Brazil provide a similar mechanism
since it is a <em>central</em> database.
This is important in case of security updates, for example.
Unfortunately, in manyrepo environments this information is usually not available
and when an issue arise it must be arduously researched.
So maybe companies should build such infrastructure
instead of dreaming about monorepos?</p>
<p>Coming back to the advantage of manyrepos,
refering to Amazon we can describe it concretely:
Version sets allow you to use multiple interface versions of the same package
at once (not multiple build versions though).
This mixture is not technically possible with a git monorepo
(but with Subversion or Perforce).
This is at least one example of the general tradeoff.</p>
<blockquote>
<p>I don’t really think there’s a better or worse between the Amazon and Google/FB style build/deploy/source control systems, it’s primarily a reflection of the org/team structure and what they prioritize - there’s tension between team independence/velocity and crosscutting changes that optimize the whole codebase.
–<a href="https://lobste.rs/s/ykk54d/amazon_s_build_system#c_fzyzg6">revert</a></p>
</blockquote>
<p>I would like to see more discussion online about this.
Many companies should value the team independence over the crosscutting changes.
So the question is:
How to get the advantages we currently uniquely attribute to monorepos
in a manyrepo setting?
Amazon's Brazil has valuable ideas to contribute
and should be more widely known.</p>

</article><p>Amazon's build system provides valuable insights for manyrepo environments.</p></div>]]>
            </description>
            <link>http://beza1e1.tuxen.de/amazon_manyrepo_builds.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943737</guid>
            <pubDate>Fri, 30 Oct 2020 16:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye IFTTT]]>
            </title>
            <description>
<![CDATA[
Score 332 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24943685">thread link</a>) | @todsacerdoti
<br/>
October 30, 2020 | https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ | <a href="https://web.archive.org/web/*/https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I was a power user of <a href="https://ifttt.com/">IFTTT</a> for many years, so I had mixed
feelings recently about <a href="https://archive.is/zpx2r">their decision</a> to change
their pricing model. Under IFTTT's new pricing, you can only have 3 “custom”
actions created/enabled at any time – which is quite a downgrade from the
current unlimited free plan. On the one hand, I'm glad to see IFTTT take
necessary steps to ensure it has long-term financial stability, but on the other
hand, I don't personally get enough value from their service anymore to justify
a recurring cost. (The plan will likely be
$4/month<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, but if you sign up before a deadline, you
can lock in a price as low as $2/month)</p>
<p>IFTTT was an awesome and uniquely easy-to-use service when it first came out,
but now there are better options for personal automation for people like me, who
like to tinker with this sort of thing. Systems like
<a href="https://nodered.org/">node-red</a> and iOS shortcuts can be self hosted or run on
device, and they provide more sophisticated logic for workflows than IFTTT.</p>
<p>I stayed on IFTTT this long mostly due to inertia, and it's fantastically long
list of supported services. If I needed to throw together a quick
spreadsheet-recording automation, or cron-like trigger, IFTTT was a great
starting place. However, it does have limitations. Until now (though it seems
like this might change with their premium offering), IFTTT basically only did
what its name implied: “if this, then that”. No “if X then Y else Z”, no “if X
and Z then Y”, etc. Often times, you don't need any complicated logic or
filtering, but it was frustrating that there wasn't the option for more advanced
automation. Ultimately, IFTTT had a great “on-ramp”, but once you were on board
with their system, you realize how shallow it is. Excellent breadth, mediocre
depth.</p>
<p>Similarly, in the past couple years IFTTT's UI has leaned heavily into the
“applet” metaphor, with these big goofy toggle switches to enable/disable
automations. The site also transitioned towards a focus on community- (or, more
often corporate-) created automations, at the expense of the experience for
creating your own applets. Like seriously, why is 30% of the UI for an applet
<em>details page</em> (!) taken up by the connection status toggle?</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt_hu1a43e8a517283105e03bcbb0c4894a01_37903_0x300_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>The settings page, too, is woefully information sparse. As a user, this makes me
feel that desktop-usability was not high on IFTTT's design priorities. You have
to scroll the page to begin to start to see what the automation is doing:</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings.png">
        
            
                
                
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/ifttt-settings_hub4acc09d90c5c0c4cbf3054a07fa3040_91989_0x400_resize_lanczos_2.png" loading="lazy"> 
        </a>
</figure>

<p>Eventually, the UI got to the point where it felt like using
<a href="https://en.wikipedia.org/wiki/Lego_Duplo">Duplos</a> or something. It didn't have
to be this way! There are great low-to-no-code tools that have much more usable
interfaces, like
<a href="https://en.wikipedia.org/wiki/Scratch_(programming_language)">Scratch</a>.</p>
<figure>
    
    <a href="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png">
        
            
        
        <img src="https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/scratch.png" loading="lazy"> 
        </a>
</figure>

<p>So, I decided to migrate away, since the move to premium was already going to
substantially limit what I could do with IFTTT. In going through my catalog of
IFTTT “applets”, I identified 3 main patterns of automations that I used IFTTT
for: (1) triggering an action to happen at a specific time, (2) triggering an
action to happen in response to a location change (i.e. geofencing), or (3)
triggering an action to happen in response to an event in a web service.</p>
<p>Of these 3 buckets, iOS shortcuts readily handles the first 2: as of iOS 14,
Shortcuts can be triggered in the background at a specific time of day, or in
response to entering/leaving a geofence. Shortcuts also has a much more
sophisticated integration with iOS than any of IFTTT's apps, so more exciting
mobile automation becomes possible – for example, setting my phone to Low Power
Mode once the battery drops below a certain threshold. Of course, you are
restricted to apps/services that support Shortcuts, and the number of supported
services is considerably smaller than IFTTT.</p>
<p>Node-red handles buckets 1 and 3: it has good support for time-based actions,
and can receive webhooks to respond to events from external services. It also
has a great plugin ecosystem, so it's support begins to rival IFTTT's impressive
selection of supported services. Additionally, node-red has many “escape
hatches” that IFTTT does not: you can use it to make raw HTTP requests and write
your own plugins/logic in Javascript, allowing for much more complex automation.</p>
<p>Neither node-red nor iOS shortcuts are as easy to use as IFTTT for putting
together a simple automation, which is a shame. However, between them (and other
alternative automation frameworks that I've trialed, like <a href="https://n8n.io/">n8n</a>
and <a href="https://github.com/huginn/huginn">huginn</a>), I've more than covered my
personal automation needs.</p>
<p>And so, goodbye IFTTT! ðŸ‘‹ I'm not put off by them charging for their service; I
think charging for software is a good thing! It's just that this was the nudge I
needed to move my automations to infrastructure that I have more control over,
which has other benefits outside the scope of this article. I'm thankful that a
service like IFTTT continues to exist; I still think it's a fantastic tool to
“on-ramp” less technical folks into automation and no-code tools.</p>
<p><em>Cover art:
<a href="https://artvee.com/dl/the-village-of-murnau/">The Village Of Murnau (1908)</a></em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>A previous version of this article stated that the price for IFTTT Pro was
$10/month. While the original press release, as covered <a href="https://www.theverge.com/2020/9/10/21430265/ifttt-pro-subscriptions-free-controversy">here</a> indicated a $10/month
price, and the current suggested price for IFTTT Pro on their signup form is
$10/month, it seems like going forward the Pro price will be $4/month. I
apologize for the inaccuracy. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

        </div></div>]]>
            </description>
            <link>https://benjamincongdon.me/blog/2020/10/30/Goodbye-IFTTT/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943685</guid>
            <pubDate>Fri, 30 Oct 2020 16:07:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Peer Assessment Bias]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24943216">thread link</a>) | @rmulholland21
<br/>
October 30, 2020 | https://www.ryansmulholland.com/writing/peer-assessment-bias | <a href="https://web.archive.org/web/*/https://www.ryansmulholland.com/writing/peer-assessment-bias">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-63067710b8dc43d7e49b"><div><p><strong>What’s the difference between you and an expert?</strong></p><p>It’s kind of obvious, isn’t it? Television appearances, thousands of dollars, and an audience of fans that accept ideas as thought leadership.</p><p>But seriously, what even <em>is</em> an expert?</p><p>Experts are peers who’ve had their ideas catch on through hard work, exhibition of talent, or luck.</p><p>I believe that statement, but it drastically simplifies everything that’s gone into someone establishing themselves as an expert. It’s not easy to get to the place where people assume you know what you’re talking about. It takes time, effort, and passion to get there. Overnight experts only exist in viral moments, it takes real expertise to have staying power.</p><p>The experts of the pre-internet age almost always hailed from academia. Earning credentials and conducting research was the only way to prove to others that you know what the hell you’re talking about. There was a gatekeeper to every distribution vessel and no public forum where a great idea from anyone could win the day.</p><p>Now we have that forum. The internet is full of people who are trying to be experts — people who think they’re experts — and as a result, there’s a monsoon of content on any given topic. And with access to information on anything, it’s the top 1% of information that we rely on, which usually belongs to...experts.</p><p>But experts are peers, remember? Just really fancy ones.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_6131"><div><p>So why don’t we consider the ideas of our peers in the same way we adopt the ideas of established thinkers?</p><p>To you, my peers, I’d like to present Peer Assessment Bias.</p><h3><strong>Peer Assessment Bias</strong></h3><p>Peer Assessment Bias is why this essay won’t be read tens of thousands of times. It’s why your best original ideas aren’t being talked about in bestselling books. It’s why you read something that a friend wrote and thought, “hmm, that was pretty good,” but not, “press the pause button on life, I need to take notes!”</p><p><strong>Peer Assessment Bias is the natural inclination to be more skeptical of the ideas of those perceived as peers, more so than the ideas of those perceived as experts.</strong></p><p>Simply put, when it’s your friend’s idea it’s solid, but when it’s coming from Peter Thiel, it’s genius.</p><p>There’s an overlap here with another bias that you may be familiar with. Survivorship Bias.</p><p>Survivorship Bias is a cognitive error that occurs when a successful subgroup is mistaken as an <em>entire</em> group due to the visibility of the successful group and the invisibility of the unsuccessful group (<a href="https://fs.blog/2020/10/sharks-survivorship-bias/" target="_blank">link here to illustrate</a>).</p><p>As it applies here, most of the ideas we consume come from experts. This is because they’ve already defeated the gatekeeper and have been elevated to the point where their thoughts matter more than others. They’re the successful survivors.</p><p>So what’s the difference between my idea of Peer Assessment Bias and good old Survivorship Bias? And how do they overlap?</p><p>Survivorship Bias is a layer of Peer Assessment Bias, but they’re not the same.</p><p>Survivorship Bias, as it relates to assessment, would lead us to believe that the best ideas come from the people who have the largest audiences. We perceive these successful survivors as experts and give more weight to the ideas they produce, even those unrelated to why they became successful in the first place. This doesn’t explain what happens on the peer side of the equation.</p><p>Peer Assessment Bias is about how we perceive those “at the same level” as us, and it’s especially focused on those who are unestablished. “Experts” were once peers and have now moved on to an evolved state. Becoming an expert takes time, and many of the strong ideas that experts share are ideated during the time when they were an unheard of “peer.”</p><p>Peer Assessment Bias has less to do with the success of the idea and more to do with the source of it. It’s different because we may very well look a great idea straight in the face and treat it as a commoner instead of as the royalty that it is.</p><h3><strong>PAB Awareness</strong></h3><p>Why does any of this matter?</p><p>Because it’s important to recognize good ideas when you hear them.</p><p>There are two sides to Peer Assessment Bias to be aware of.</p><ol data-rte-list="default"><li><p><strong>Don’t automatically elevate ideas from experts</strong></p></li><li><p><strong>Don’t automatically dismiss ideas from peers</strong></p></li></ol><p>Experts, the people we look up to, are placed on a pedestal. They’re given status as infallible.&nbsp;</p><p>This is wrong.</p><p>Yes, the people who’ve earned their expertise are most likely to keep producing thoughts or content that’s worth consuming, but never blindly. “Because Musk said it,” is not reason enough to accept an idea.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_8762"><div><p>But you know this already, you’re a responsible human. So let’s take a look at the other side of Peer Assessment Bias, the side that doesn’t come naturally.</p><p><strong>Don’t automatically dismiss ideas from peers.</strong></p><p>Pay attention to those around you. They can have ideas that are just as strong as those who’ve already earned the world’s attention. Often it’s not perfectly polished, not precisely explained, and never published in the Washington Post, but it could be just as good.</p><p>Allow me to illustrate.</p><p>This is Ayomide:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1604023959443_10888"><div><p>Sure, he’s a doctor, so he’s a proven smart guy, but the point is that you don’t know him. Ayomide is in my writing community, <a href="https://writersblochq.com/" target="_blank">Writer’s Bloc</a>, and I’ve had the pleasure of reading some of his work in the draft phase.</p><p>In August, he wrote this essay called “<a href="https://docayomide.com/love/" target="_blank">Love Your Neighbor Doesn’t Mean What We Think</a>.” It’s excellent, you should read it. But to summarize, it comes down to this one sentence:</p><blockquote><p>“Act in your neighbor’s interest as if it was your own.”</p></blockquote><p>That’s an objectively brilliant way of reframing “love your neighbor as yourself.” It may not seem like it, but that little tweak makes things click mentally in a different way than we’re used to.</p><p>Ayomide isn’t an established personality. He’s not looked upon by thousands as a brilliant mind to be listened to or read each week.</p><p>But he has some fantastic ideas worth reading, and so do your peers.&nbsp;</p><h3><strong>Empower Your Peers</strong></h3><p>The moral of this story is to cut your peers some slack.</p><p>The path to expertise is filled with early days of thoughts sent out into an empty void and then slowly adopted by a group of early fans. Those early fans are peers, and peer fans are the most important fans you can have. A show of support, a reliable voice for feedback, or a bit of help from someone promoting your work is sometimes all you need to keep pushing on to the point where you become an expert.</p><p>I’m no scientist, but there’s no doubt we’re harsher critics of our peers than we are of others we don’t know. Does this stem from personal self-doubt (I couldn’t do that, so they couldn’t do it either), a hint of jealousy, or another psychological misplacement? Maybe. But it does happen.</p><p>We have a mental bias to keep peers as peers and experts as experts. This is a bias like any other. One worthy of acknowledging and defeating.</p><p>Cut your peers some slack. Read their work. Promote their content. Champion their ideas. Stand behind them. Encourage their efforts.</p><p>To steal from my peer Ayomide; believe in your peer’s work the same way you believe in your own.</p><p>Now, go forth and lift up your peers.</p></div></div></div>]]>
            </description>
            <link>https://www.ryansmulholland.com/writing/peer-assessment-bias</link>
            <guid isPermaLink="false">hacker-news-small-sites-24943216</guid>
            <pubDate>Fri, 30 Oct 2020 15:25:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MCS-48: The quest for 16-bit division on the 8-bit CPU which can’t divide]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24941189">thread link</a>) | @noexani
<br/>
October 30, 2020 | http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/ | <a href="https://web.archive.org/web/*/http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4862">
	
	<!-- .entry-header -->

		<div>
		
<p>Recently while working on my <a href="http://tech.mattmillman.com/projects/an-intel-mcs-48-based-dual-temperature-sensor/">MCS-48 temperature sensor</a> project I had to confront one of the largest challenges, which is to implement an option where changing a jumper displayed Fahrenheit instead of Celsius. The output from the DS18B10 temperature sensors is Celsius only, as it should be, so a conversion would need to be performed.</p>



<figure><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/CodeCogsEqn.gif" alt=""><figcaption>A quick reminder of the conversion needed to be performed</figcaption></figure>



<p>In my case it’s +320 as I’m using fixed point arithmetic i.e. 15.3° = 153. This is a tough conversion to perform on an MCS-48 as we’ve got a bunch of different operations needed here:</p>



<ul><li>16-bit negate (more about that below)</li><li>16-bit unsigned multiply</li><li>16-bit unsigned divide</li><li>16-bit add with wrap-around</li></ul>



<p>A tall order for a CPU which has just <em>one </em>math instruction: 8-bit add. To perform all of this, one must sling a long sequence of primitive instructions together. Since this is an assembly language only architecture, I couldn’t cheat by compiling it in C and pinching the resulting instructions as I have done for PIC16 in the past.</p>



<p>The best place to find such examples is in the MCS-48 assembly language manual:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual.jpg"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-800x638.jpg 800w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-300x239.jpg 300w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-150x120.jpg 150w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-768x612.jpg 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-1536x1224.jpg 1536w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/manual-2048x1633.jpg 2048w" sizes="(max-width: 800px) 100vw, 800px"></a></figure>



<p>(A scan of it can be viewed <a href="http://www.nj7p.org/Manuals/PDFs/Intel/9800255D.pdf">here</a>). Everything I needed was in there, except how to divide. There is no mention whatsoever in that manual of how to perform any kind of division operation, <em>but</em>, tacked in the back of the 1980 edition MCS-48 handbook, I found this:</p>



<figure><a href="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png"><img src="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png" alt="" srcset="http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-623x800.png 623w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-233x300.png 233w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-117x150.png 117w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-768x987.png 768w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv-1195x1536.png 1195w, http://techmattmillman.s3.amazonaws.com/wp-content/uploads/2020/10/isisdiv.png 1263w" sizes="(max-width: 623px) 100vw, 623px"></a><figcaption>Woohoo! A working divide routine for MCS-48. It wouldn’t OCR, so I typed it up.</figcaption></figure>



<p>Unfortunately that routine only has an 8-bit quotient, which isn’t much use for my application because it would overflow in most cases.</p>



<p>I was easily able to work around that with the following implementation (pseudo code):</p>



<pre><code>if (celsius &lt; 0)
{   // If negative, note it, and make it positive
    // so we can work with simpler unsigned routines below
    celsius = -celsius;
    is_negative = 1;
}

fahrenheit = multiply_16x8r16(celsius, 9);

// Divide by 50 so the result of divide_16x8r8 doesn't overflow
fahrenheit = divide_16x8r8(fahrenheit, 50, &amp;remainder);

// Multiply it back up
fahrenheit = multiply_16x8r16(fahrenheit, 10);

// Factor remainder
remainder = multiply_16x8r16(remainder, 10);

// Divide and add remainder
fahrenheit += divide_16x8r8(remainder, 50, NULL);

if (is_negative)
{   // Make it negative again, if it was previously
    is_negative = 1;
}

// Add 32. Requires a 16-bit add with wrap around to
// correctly handle negative temperatures
fahrenheit += 320</code></pre>



<p>While that does the job, it’s poo poo. What I really want is that complicated looking divide routine to have a 16-bit quotient, so I can do the division in a single operation. To help me understand it, I translated it to C code:</p>



<pre><code>uint8_t mcs48_divide(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    if ((dividend &gt;&gt; 8) &gt;= divisor)
        goto mcs48_div_exit; // Impossible. Result would
                             // overflow. Bail.

    for (int i = 0; i &lt; 8; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit15_was_set = 0;

        if (dividend &amp; 0x8000)
            bit15_was_set = 1; // Note if this was set,

        dividend &lt;&lt;= 1; // Next bit

        msb = (dividend &gt;&gt; 8);
        if (msb &gt;= divisor || bit15_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            dividend = (((msb - divisor) &lt;&lt; 8) | (dividend &amp; 0xFF)) + 1;
        }
    }

mcs48_div_exit:
    *remainder = (dividend &gt;&gt; 8);
    return (dividend &amp; 0xFF);
}</code></pre>



<p>It’s immediately clear that it’s a <a href="https://www.wikihow.com/Divide-Binary-Numbers">binary division</a> implementation. What wasn’t immediately clear is how to make the change I wanted. I put the question to <a href="https://stackoverflow.com/questions/64544654/can-anyone-figure-out-how-to-extend-this-software-divide-routine-to-have-a-16-bi/64549557#64549557">stack overflow</a>, and on the face of it, it looked like a dumb question, i.e. just double the integer type sizes, <em>stupid</em>. predictably I got punished with a bunch of down-votes.</p>



<p>Yes we can do that, but it’s not what I want to do to the assembly routine that I’m trying to modify, so perhaps I didn’t quite ask the question as well as I could have done. The answer provided sent me in the right direction, in that the working accumulator needs to be larger, 24-bits in my case, and the 16-bit shift needs to be a 24-bit.</p>



<pre><code>uint16_t mcs48_div16(uint16_t dividend, uint8_t divisor, uint8_t *remainder)
{
    uint32_t accumulator = dividend;

    for (int i = 0; i &lt; 16; i++) // One pass for each bit of result
    {
        uint8_t msb;
        uint8_t bit24_was_set = 0;

        if (accumulator &amp; 0x800000)
            bit24_was_set = 1; // Note if this was set,
                               // can't check if after shift.

        accumulator &lt;&lt;= 1; // Next bit
        accumulator &amp;= 0xFFFFFF; // Simulate 24 bit type

        msb = (accumulator &gt;&gt; 16);
        if (msb &gt;= divisor || bit24_was_set)
        {
            // Subtract remainder from MSB,
            // preserve and increment quotient
            accumulator = (((msb - divisor) &lt;&lt; 16) | (accumulator &amp; 0xFFFF)) + 1;
        }
    }

mcs48_div_ext_exit:
    *remainder = (accumulator &gt;&gt; 16);
    return (accumulator &amp; 0xFFFF);
}</code></pre>



<p>Above is the pseudo code of my routine after the changes. In the final implementation registers A, R1 and R2 hold the 24-bit accumulator, so this doesn’t translate too well to C because there isn’t a 24-bit integer type.</p>



<p>The final changes to the routine can be viewed <a href="https://github.com/inaxeon/mcs48temp/compare/e006467..a531d32">here</a>.</p>



<p>Ah, that’s better.</p>
	</div><!-- .entry-content -->
	
	</article></div>]]>
            </description>
            <link>http://tech.mattmillman.com/mcs-48-the-quest-for-16-bit-division-on-the-8-bit-cpu-which-cant-divide-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24941189</guid>
            <pubDate>Fri, 30 Oct 2020 11:39:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Awk: `Begin { ` Part 1]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 96 (<a href="https://news.ycombinator.com/item?id=24940661">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://jemma.dev/blog/awk-part-1 | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/awk-part-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, I was watching Bryan Cantrill’s 2018 talk, <a href="https://www.youtube.com/watch?v=2wZ1pCpJUIM">Rust, and Other Interesting Things</a>, and he made an offhanded comment while discussing values of different programming languages and communities. He said, “If you get the <a href="https://www.gnu.org/software/gawk/manual/gawk.html">awk programming language manual</a>…you’ll read it in about two hours and then you’re done. That’s it. You know all of awk.”</p>

<p>Only two hours to learn an entire language?! …. Challenge accepted!</p>

<p>I had previously used snippets of awk here and there. Most of them were given to me by Stack Overflow answers when googling for niche data file manipulations. But, I did not know enough to successfully write an awk program from scratch. I definitely did not have a real grasp on the language nor its power. And, a couple of hours sounded like a relatively small time investment to learn what Bryan Cantrill said was a language he used three times a day.</p>

<p>It turns out it takes more than two hours to learn awk, and I am by no means an expert… yet (growth mindset!). But, I now know enough to write a little about the essentials. Here goes!</p>

<h3 id="what-is-awk-useful-for">What is awk useful for?</h3>

<p>Awk is useful for data file manipulation. Already, having used it for a few days only, I wish I had invested time in learning it earlier. My usual workflow when encountering a data file is to import it into Google Sheets and use their builtin functions. If those weren’t enough, I would write little code snippets to somewhat awk..wardly get the information I want. Awk is way more powerful than what I was doing before. Let’s take a look:</p>

<h3 id="running-awk-programs">Running awk programs</h3>

<p>If we’re going to learn awk, we need to know how to run an awk program. The syntax to run an awk program in a shell is:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'awk_program_contents'</span> data-file-1 data-file-2
</code></pre></div></div>
<p>We can also write a longer awk program to run instead of writing the awk code inline. We could write a file with awk codeand then pass inline to awk with <code>-f &lt;awk-program-filename&gt;</code></p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-f</span> awk-program.awk data-file-1 data-file-2
</code></pre></div></div>

<h3 id="awk-program-contents">awk program contents</h3>

<p>Well, what is an awk program? We know it is best used for simple data reformatting or manipulation. The way it does this is by performing different actions on different patterns within a data file. The basic syntax of an awk program depends on these pattern and actions.</p>

<div><div><pre><code>pattern <span>{</span> action <span>}</span>
pattern <span>{</span> action <span>}</span>
...
</code></pre></div></div>

<p>We can give as many <code>pattern { action }</code> pairs as we want. Each pair will be executed independently of the others. This means if a line matches more than one pattern, it will have more than one corresponding action. In the example above we use newlines to separate distinct pairs. Similar to bash, we can also use <code>;</code> to separate commands and put everything on one line: <code>pattern { action }; pattern { action }</code></p>

<h3 id="awk-with-data-files">awk with data files</h3>

<p>But, it turns out awk is much more useful (and fun!) with a data file. The UN has a few <a href="https://data.un.org/">publicly available datasets</a>. I picked <a href="https://data.un.org/_Docs/SYB/CSV/SYB62_309_201906_Education.csv">this one</a> on education at the primary, secondary and tertiary levels to delve into first.</p>

<p>Let’s start by using awk to get a sense of what the data looks like.  <code>NR</code> is a predefined variable which records the number of rows read in a file so far. We can use it to look at the first few lines of a program. In this case, our pattern will be <code>NR &lt;= 5</code>, and by not including an action, the implied action will be <code>print</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5'</span> education.csv
T07,<span>"Enrolment in primary, secondary and tertiary education levels"</span>,,,,,
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,<span>"Total, all countries or areas"</span>,2005,Students enrolled <span>in </span>primary education <span>(</span>thousands<span>)</span>,<span>"678,991.6070"</span>,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollement ratio - Primary <span>(</span>male<span>)</span>,104.9360,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
1,<span>"Total, all countries or areas"</span>,2005,Gross enrollment ratio - Primary <span>(</span>female<span>)</span>,99.9214,,<span>"United Nations Educational, Scientific and Cultural Organization (UNESCO), Montreal, the UNESCO Institute for Statistics (UIS) statistics database, last accessed March 2019."</span>
</code></pre></div></div>
<p>Okay, so looks like this is giving us a bit of information about our file. Notably:</p>
<ol>
  <li>There are two header rows: a title row, and a row telling us what the fields are</li>
  <li>The file is comma separated</li>
  <li>… except there are sometimes commas within double quoted strings: <code>"Total, all countries or areas"</code></li>
</ol>

<p>Let’s address these one by one!</p>



<p>We can ignore the first two header rows by using our nifty <code>NR</code> moving forward. We can pattern match that <code>NR &gt; 2</code>. Note: awk is 1-indexed.</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &gt; 2'</span> education.csv
</code></pre></div></div>

<h3 id="field-separators">Field Separators</h3>

<p>awk’s <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Default-Field-Splitting">default field separator</a> is a space. We can actually see this by printing the first field. To access the value of a field, we use <code>$&lt;field_index&gt;</code>. So <code>$1</code> is the first field, <code>$2</code> the second, and so on. <code>$0</code> refers to the entire row.</p>

<p>If we try this:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07,<span>"Enrolment
Region/Country/Area,,Year,Series,Value,Footnotes,Source
1,"</span>Total,
1,<span>"Total,
1,"</span>Total,
</code></pre></div></div>
<p>we can confirm that we’re splitting on spaces. awk has the option to specify a different field separator with the <code>-F 'separator'</code> flag:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $1 }'</span> education.csv
T07
Region/Country/Area
1
1
1
</code></pre></div></div>

<p>Great! But…. we had commas embedded within strings with double quotes. Sure enough, if we print the second field (<code>$2</code>), we see:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>-F</span> <span>','</span> <span>'NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary

"</span>Total
<span>"Total
"</span>Total
</code></pre></div></div>

<p>Hmmm. What we want here is to split fields by <em>content</em>. Which awk does not have, but gawk (GNU awk) does: <a href="https://www.gnu.org/software/gawk/manual/gawk.html#Splitting-By-Content">FPAT</a>! From the gawk manual: “All properly written awk programs should work with gawk. So most of the time, we don’t distinguish between gawk and other awk implementations.”</p>

<p>Sounds like we can use gawk here instead then. Let’s try pattern matching. I’m not going to go into regex here, but the pattern we want, defined by <code>"[^,]*|\"[^\"]+\""</code> is anything that either starts with a non-comma character, or starts with a double quote, contains only non-quote characters, and ends with a double quote:</p>

<div><div><pre><code><span>$ </span>gawk <span>'BEGIN { FPAT = "[^,]*|\"[^\"]+\"" } NR &lt;= 5 { print $2 }'</span> education.csv
<span>"Enrolment in primary, secondary and tertiary education levels"</span>

<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
<span>"Total, all countries or areas"</span>
</code></pre></div></div>

<p>I snuck a <code>BEGIN</code> in there without explaining it. Let’s go on a brief tangent…</p>

<h3 id="begin--tangent-">BEGIN { tangent }</h3>

<p>Beyond the pattern and actions, awk also has a concept of <code>BEGIN</code> and <code>END</code> blocks. The <code>BEGIN</code> is executed before any of the data is processed. It can be useful for declaring variables or printing text to appear at the beginning. Analogously, the <code>END</code> is executed after the data is processed. It can be useful for performing manipulations on aggregates of the data, like averaging a sum.</p>

<p>This means if we wanted to write a little “Hello, awk!” program, we could do it without even needing a data file.</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'BEGIN { print "Hello, awk!" }'</span>
Hello, <span>awk</span><span>!</span>
</code></pre></div></div>

<h3 id="end--tangent-">END { tangent }</h3>

<p>…back to our example. In our case, we used a <code>BEGIN</code> block to declare the <code>FPAT</code> <em>before</em> reading our data file.</p>

<p>But, we’ve only looked at the first 5 lines. For all we know, the rest of the file could look completely different. Let’s use <code>NR</code> again to see some more of the file. First, let’s figure out how long the file is. We can use the <code>END</code> block here. After we’ve parsed the whole file, we can see what the value of <code>NR</code> is, and that’ll tell us how many lines it is:</p>

<div><div><pre><code><span>$ </span><span>awk</span> <span>'END { print NR }'</span> education.csv
8630
</code></pre></div></div>

<p>Okay, so maybe if we print every 500 lines, we’ll get a sense of what data we’re looking at. We can set our pattern to be only if <code>NR</code> is a multiple of <code>500</code>:</p>
<div><div><pre><code><span>$ </span><span>awk</span> <span>'NR % 500 == 0'</span> education.csv
</code></pre></div></div>

<p>… and I’m going to leave this blog post on a real cliff hanger. Mostly because it already feels too long! There’s <a href="https://jemma.dev/blog/awk-part-2">a second post</a> about awk actually looking at the data and manipulating it to figure out which countries have stark differences in number of males and females that they educate.</p>

<h3 id="tldr-or-tlskimmed-far-enough-to-get-here-please-give-me-the-shorter-version">TL;DR or TL;Skimmed far enough to get here, please give me the shorter version:</h3>
<p>To rehash what we’ve learned about awk:</p>
<ul>
  <li>awk is run using <code>awk 'awk_program' data-file</code></li>
  <li>awk programs have the form <code>pattern { action }; pattern { action };</code></li>
  <li><code>BEGIN</code> blocks are executed before reading data files</li>
  <li><code>END</code> blocks are executed after reading data files</li>
  <li><code>NR</code> is a variable that tells us the number of rows read</li>
  <li><code>-F '&lt;separator&gt;'</code> is how we can define a field separator for a file</li>
  <li>Space is the default field separator</li>
  <li><code>FPAT="..."</code> is a way to use regex to define a pattern for each field</li>
  <li><code>FPAT</code> is only defined in gawk</li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/awk-part-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940661</guid>
            <pubDate>Fri, 30 Oct 2020 09:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Backtest Trading Strategies: A Quantopian Alternative]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24940644">thread link</a>) | @hydershykh
<br/>
October 30, 2020 | https://www.tradytics.com/backtester | <a href="https://web.archive.org/web/*/https://www.tradytics.com/backtester">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
          <p>
            <h4>Trading Strategies Backtester</h4>
            <h5>Backtest your favorite technical analysis based strategies with our backtester.</h5>
          </p>
          
        </div>

        <div>
          

          <div>
            <div>
              <p>
                <h5>Buy Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonBuy">
                    <p onclick="make_current_ta('RSI')">RSI</p>
                    <p onclick="make_current_ta('CCI')">CCI</p>
                    <p onclick="make_current_ta('MFI')">MFI</p>
                    <p onclick="make_current_ta('MACD')">MACD</p>
                    <p onclick="make_current_ta('ATR')">ATR</p>
                    <p onclick="make_current_ta('ADX')">ADX</p>
                    <p onclick="make_current_ta('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremade">
                    <p onclick="make_current_strategy('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy('lband < Price')">LowerBollinger &lt; Price</p>
                    <!--<p class="dropdown-item" onclick="make_current_strategy('At Support')">At Support</p>
                    <p class="dropdown-item" onclick="make_current_strategy('At Resistance')">At Resistance</p>-->
                  </div>
                </div>
                </div>
            </div>
          </div>



          <div>
            <div>
              <p>
                <h5>Sell Strategy</h5>
              </p>
              <div>
                <div>
                  
                  <div aria-labelledby="dropdownMenuButtonSell">
                    <p onclick="make_current_ta_sell('RSI')">RSI</p>
                    <p onclick="make_current_ta_sell('CCI')">CCI</p>
                    <p onclick="make_current_ta_sell('MFI')">MFI</p>
                    <p onclick="make_current_ta_sell('MACD')">MACD</p>
                    <p onclick="make_current_ta_sell('ATR')">ATR</p>
                    <p onclick="make_current_ta_sell('ADX')">ADX</p>
                    <p onclick="make_current_ta_sell('STOCHS')">STOCHS</p>
                  </div>
                </div>
                
                
                </div>
              <div>
                <h6>Pre-made</h6>
                <div>
                  <div aria-labelledby="dropdownMenuButtonPremadeSell">
                    <p onclick="make_current_strategy_sell('EMA9 > EMA20')">9EMA &gt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > EMA50')">20EMA &gt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA9 < EMA20')">9EMA &lt; 20EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 < EMA50')">20EMA &lt; 50EMA</p>
                    <p onclick="make_current_strategy_sell('EMA20 > Price')">20EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 > Price')">50EMA &gt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA20 < Price')">20EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('EMA50 < Price')">50EMA &lt; Price</p>
                    <p onclick="make_current_strategy_sell('obv_slope > 0')">Pos OBV Slope</p>
                    <p onclick="make_current_strategy_sell('obv_slope < 0')">Neg OBV Slope</p>
                    <p onclick="make_current_strategy_sell('VWAP > Price')">VWAP &gt; Price</p>
                    <p onclick="make_current_strategy_sell('VWAP < Price')">VWAP &lt; Price</p>
                    <p onclick="make_current_strategy_sell('SIGNAL > MACD')">Signal &gt; MACD</p>
                    <p onclick="make_current_strategy_sell('SIGNAL < MACD')">Signal &lt; MACD</p>
                    <p onclick="make_current_strategy_sell('hband > Price')">UpperBollinger &gt; Price</p>
                    <p onclick="make_current_strategy_sell('lband < Price')">LowerBollinger &lt; Price</p>
                  </div>
                </div>
                </div>
            </div>
          </div>
          
          
        </div> <!-- row -->


         <!-- row -->

         <!-- row -->

         <!-- row -->

        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="activity"></i> Win Rate</h6>
                </p>
                <p>Win rate of this strategy.</p>
                
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="corner-right-down"></i> Biggest Drawdown</h6>
                </p>
                <p>Highest loss incurred in a trade.</p>
                
              </div>
            </div>
          </div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="navigation-2"></i> Biggest Win</h6>
                </p>
                <p>Highest profit gained in a trade.</p>
                
              </div>
            </div>
          </div>
        </div> <!-- row -->


        <div>
          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-up"></i> Long Only</h6>
                </p>
                <p>Profits and losses from long positions.</p>
                
              </div> 
            </div>
          </div>

          <div>
            <div>
              <div>
                <p>
                  <h6><i data-feather="arrow-down"></i> Short Only</h6>
                </p>
                <p>Profits and losses from short positions.</p>
                
              </div> 
            </div>
          </div>
        </div> <!-- row -->

        
        

      </div></div>]]>
            </description>
            <link>https://www.tradytics.com/backtester</link>
            <guid isPermaLink="false">hacker-news-small-sites-24940644</guid>
            <pubDate>Fri, 30 Oct 2020 09:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24939875">thread link</a>) | @quyleanh
<br/>
October 30, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope — rust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don’t need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It’s not about implementing crazy lock-free schemes, it’s about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn’t have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of “your code” vs “framework code” when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don’t really believe this :)
rust-analyzer started from zero, it didn’t have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it’s hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust’s surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It’s easy to characterize Kotlin’s learning curve — it is nearly zero.
I’ve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it’s hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that “why no one does modules right?” is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate’s public API matters, and it is crystal clear what crate’s public API is.
Moreover, crates are anonymous, so you don’t get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it’s not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project’s build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust’s build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It’s not perfect, but it is a breath of fresh air after Java’s <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo’s trick is that it doesn’t try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It’s impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I’ve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle’s user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for “perfect” library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts — structs, enums, functions, etc.
This is not specific to Rust — any ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch — which code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It’s better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust’s humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24939875</guid>
            <pubDate>Fri, 30 Oct 2020 07:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Audio Visualizations Working with Web Audio API]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24938292">thread link</a>) | @arcatech
<br/>
October 29, 2020 | https://dwayne.xyz/post/audio-visualizations-web-audio-api | <a href="https://web.archive.org/web/*/https://dwayne.xyz/post/audio-visualizations-web-audio-api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>Web Audio API</h2>
<p>I’ve been working on getting WebRTC video chat working here on the website for a few weeks now. I finally got to the point where both text, video chat, and screen sharing all work really well, but somewhere in the back of my mind I kept thinking about complaints about “<a href="https://www.psychologytoday.com/us/blog/brain-waves/202007/why-zoom-fatigue-is-real-and-what-you-can-do-about-it">Zoom fatigue</a>” during the pandemic:</p>
<blockquote>
<p>Zoom fatigue, Hall argues now, is real. “Zoom is exhausting and lonely because you have to be so much more attentive and so much more aware of what’s going on than you do on phone calls.” If you haven’t turned off your own camera, you are also watching yourself speak, which can be arousing and disconcerting. The blips, delays and cut off sentences also create confusion. Much more exploration needs to be done, but he says, “maybe this isn’t the solution to our problems that we thought it might have been.” Phone calls, by comparison, are less demanding. “You can be in your own space. You can take a walk, make dinner,” Hall says.</p>
</blockquote>

<p>It’s kind of an interesting thing to have on your mind while spending weeks writing/debugging/testing video chat code.</p>
<p>So I decided to add an audio-only mode. And if I was gonna do that, I had to show something cool in place of the video. So I figured I would try to add audio visualizations when one or both of the users didn’t have video on. Using the relatively recent<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> seemed like the right way to go.</p>
<p>Here’s what I came up with:</p>
<div><video controls="" muted="" autoplay="" playsinline="" loop=""><source src="https://media.dwayne.xyz/blog/audio-visualization.mp4" type="video/mp4"></video><p>Screen recording of the local audio visualization. I cycle through bar graph in light mode, bar graph in dark mode, sine wave in dark mode, then sine wave in light mode.</p></div>
<h2>Creating and hooking up an AnalyserNode</h2>
<p>To create audio visualizations, the first thing you’ll need is an <code>AnalyserNode</code>, which you can get from the <code>createAnalyser</code> method of a <code>BaseAudioContext</code>. You can get both of these things pretty easily<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> like this:</p>
<pre><span>1</span><span>const</span> audioContext <span>=</span> <span>new</span> <span>window</span>.AudioContext();
<span>2</span><span>const</span> analyser <span>=</span> audioContext.createAnalyser();
</pre><p>Next, create a <code>MediaStreamAudioSourceNode</code> from an existing data stream (I use either the local or remote data streams from either <code>getUserMedia</code> or from the ‘track’ event of <code>RTCPeerConnection</code> respectively) using <code>AudioContext.createMediaStreamSource</code>. Then you can connect that audio source to the analyser object like this:</p>
<pre><span>1</span><span>const</span> audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(stream);
<span>2</span>audioSource.connect(analyser);
</pre>
<h2>Using requestAnimationFrame</h2>
<p><code>window.requestAnimationFrame</code> is nice. Call it, passing in your drawing function, and then inside that function call <code>requestAnimationFrame</code> again. Get yourself a nice little recursive loop going that’s automatically timed properly by the browser.</p>
<p>In my situation, there will either be 0, 1, or 2 visualizations running, since either side can choose either video chat, audio-only (…except during screen sharing), or just text chat. So I have one loop that draws both. It looks like this:</p>
<pre><span>1</span><span>const</span> drawAudioVisualizations <span>=</span> () =&gt; {
<span>2</span>    audioCancel <span>=</span> <span>window</span>.requestAnimationFrame(drawAudioVisualizations);
<span>3</span>    localAudioVisualization.draw();
<span>4</span>    remoteAudioVisualization.draw();
<span>5</span>};
</pre><p>I created the class for those visualization objects, and they handle whether or not to draw. They each contain the analyser, source, and context objects for their visualization.</p>
<p>Then when I detect that loop doesn’t have to run anymore, I can cancel it using that <code>audioCancel</code> value:</p>
<pre><span>1</span><span>window</span>.cancelAnimationFrame(audioCancel);
<span>2</span>audioCancel <span>=</span> <span>0</span>;
</pre>
<h2>Configuring the Analyser</h2>
<p>Like in the <a href="https://github.com/mdn/voice-change-o-matic/blob/gh-pages/scripts/app.js">example you’ll see a lot</a> if you look at the MDN documentation for this stuff, I provide options for two audio visualizations: frequency bars and a sine wave. Here’s how I configure the analyser for each type:</p>
<pre><span> 1</span><span>switch</span> (<span>this</span>.type) {
<span> 2</span>    <span>case</span> <span>'frequencybars'</span><span>:</span>
<span> 3</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span> 4</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span> 5</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.85</span>;
<span> 6</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>256</span>;
<span> 7</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.frequencyBinCount;
<span> 8</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span> 9</span>        <span>break</span>;
<span>10</span>    <span>default</span><span>:</span>
<span>11</span>        <span>this</span>.analyser.minDecibels <span>=</span> <span>-</span><span>90</span>;
<span>12</span>        <span>this</span>.analyser.maxDecibels <span>=</span> <span>-</span><span>10</span>;
<span>13</span>        <span>this</span>.analyser.smoothingTimeConstant <span>=</span> <span>0.9</span>;
<span>14</span>        <span>this</span>.analyser.fftSize <span>=</span> <span>1024</span>;
<span>15</span>        <span>this</span>.bufferLength <span>=</span> <span>this</span>.analyser.fftSize;
<span>16</span>        <span>this</span>.dataArray <span>=</span> <span>new</span> Uint8Array(<span>this</span>.bufferLength);
<span>17</span>        <span>break</span>;
<span>18</span>}
</pre><div><p>I’ve adjusted these numbers a lot, and I’m gonna keep doing it. A note about <code>fftSize</code> and <code>frequencyBinCount</code>: <code>frequencyBinCount</code> is set right after you set <code>fftSize</code> and it’s usually just half the <code>fftSize</code> value. These values are about the amount of data you want to receive from the main analyser functions I’m about to talk about next. As you can see, they directly control the size of the data array that you’ll use to store the audio data on each draw call.
</p></div>
<h2>Using the Analyser</h2>
<p>On each draw call, depending on the type of visualization, call either <code>getByteFrequencyData</code> or <code>getByteTimeDomainData</code> with the array that was created above, and it’ll be filled with data. Then you run a simple loop over each element and start drawing. Here’s my sine wave code:</p>
<pre><span> 1</span><span>this</span>.analyser.getByteTimeDomainData(<span>this</span>.dataArray);
<span> 2</span><span>this</span>.ctx.lineWidth <span>=</span> <span>2</span>;
<span> 3</span><span>this</span>.ctx.strokeStyle <span>=</span> audioSecondaryStroke;
<span> 4</span>
<span> 5</span><span>this</span>.ctx.beginPath();
<span> 6</span>
<span> 7</span><span>let</span> v, y;
<span> 8</span><span>for</span> (<span>let</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>this</span>.bufferLength; i<span>++</span>) {
<span> 9</span>    v <span>=</span> <span>this</span>.dataArray[i] <span>/</span> <span>128.0</span>;
<span>10</span>    y <span>=</span> v <span>*</span> height <span>/</span> <span>2</span>;
<span>11</span>
<span>12</span>    <span>if</span> (i <span>===</span> <span>0</span>) {
<span>13</span>        <span>this</span>.ctx.moveTo(x, y);
<span>14</span>    } <span>else</span> {
<span>15</span>        <span>this</span>.ctx.lineTo(x, y);
<span>16</span>    }
<span>17</span>
<span>18</span>    x <span>+=</span> width <span>*</span> <span>1.0</span> <span>/</span> <span>this</span>.bufferLength;
<span>19</span>}
<span>20</span>
<span>21</span><span>this</span>.ctx.lineTo(width, height <span>/</span> <span>2</span>);
<span>22</span><span>this</span>.ctx.stroke();
</pre><div><p>The fill and stroke colors are dynamic based on the website color scheme.
</p></div>
<h2>Good ol' Safari</h2>
<p>So I did all of this stuff I just talked about, but for <strong>days</strong> I could <em>not</em> get this to work in Safari. Not because of errors or anything, but because both <code>getByteFrequencyData</code> and <code>getByteTimeDomainData</code> just filled the array with 0s every time. No matter what I did. I was able to get the audio data in Firefox just fine.</p>
<p>So at first, I figured it just didn’t work at all in Safari and I would just have to wait until Apple fixed it. But then I came across <a href="https://mdn.github.io/voice-change-o-matic/">this sample audio project</a> and noticed it worked just fine in Safari.</p>
<div><p>So I studied the code for an hour trying to understand what was different about my code and theirs. I made a lot of changes to my code to make it more like what they were doing. One of the big differences is that they’re connecting the audio source to different audio distortion nodes to actually change the audio. I just want to create a visualization so I wasn’t using any of those objects.
</p></div>
<h3>Audio Distortion Effects</h3>
<p>The <code>BaseAudioContext</code> has a few methods you can use to create audio distortion objects.</p>
<ul>
<li><code>WaveShaperNode</code>: Use <code>BaseAudioContext.createWaveShaper</code> to create a non-linear distortion. You can use a custom function to change the audio data.</li>
<li><code>GainNode</code>: Use <code>BaseAudioContext.createGain</code> to control the overall gain (volume) of the audio.</li>
<li><code>BiquadFilterNode</code>: Use <code>BaseAudioContext.createBiquadFilter</code> to apply some common audio effects.</li>
<li><code>ConvolverNode</code>: Use <code>BaseAudioContext.createConvolver</code> to apply reverb effects to audio.</li>
</ul>
<p>Each one of these objects has a <code>connect</code> function where you pass another context, output, or filter. Each one has a certain number of inputs and outputs. Here’s an example from that sample project of connecting all of them:</p>
<pre><span>1</span>source <span>=</span> audioCtx.createMediaStreamSource(stream);
<span>2</span>source.connect(distortion);
<span>3</span>distortion.connect(biquadFilter);
<span>4</span>biquadFilter.connect(gainNode);
<span>5</span>convolver.connect(gainNode);
<span>6</span>gainNode.connect(analyser);
<span>7</span>analyser.connect(audioCtx.destination);
</pre><p><strong>Note</strong>: Don’t connect to your audio context <code>destination</code> if you’re just trying to create a visualization for a call. The user will hear themselves talking.</p>
<div><p>Anyway, I tried adding these things to my code to see if that would get it working in Safari, but I had no luck.
</p></div>
<h2>Figuring out the Safari issue</h2>
<p>I was starting to get <em>real</em> frustrated trying to figure this out. I was gonna let it go when I thought Safari was just broken (because it usually is), but since I knew it <em>could</em> work in Safari, I couldn’t leave it alone.</p>
<p>Eventually I downloaded the actual HTML and Javascript files from that sample and started removing shit from their code, running it locally and seeing if it worked. Which it did. So now I’m editing my own code, and <em>their code</em>, to get them to be pretty much the same. Which I did. And <strong>still</strong> theirs worked and mine didn’t.</p>
<p>Next I just started desperately logging every single object at different points in my code to figure out what the fuck was going on. Then I noticed something.</p>
<div><p><img src="https://media.dwayne.xyz/blog/audio-context-suspended.png" alt="Dev console showing the output of logging this.audioContext. The state attribute is shown as suspended"></p><p>Output of logging the audio context object.</p></div>
<p>The <code>state</code> is “suspended”? Why? I don’t know. I did the same log in the sample code (that I had downloaded and was running on my machine) and it was “running”.</p>
<p>This is the code that fixes it:</p>
<pre><span>1</span><span>this</span>.audioSource <span>=</span> <span>this</span>.audioContext.createMediaStreamSource(<span>this</span>.stream);
<span>2</span><span>this</span>.audioSource.connect(<span>this</span>.analyser);
<span>3</span><span>this</span>.audioContext.resume(); <span>// Why??????
</span></pre><div><p>Calling <code>resume</code> changes the state and then everything works. To this day I still don’t know why the sample code didn’t need that line.
</p></div>
<h2>Drawing the image and supporting light/dark modes</h2>
<p>Like everything else on my site, all of this must support different color schemes (and screen sizes, and mobile devices). That was surprisingly difficult when trying to draw an SVG on the canvas.</p>
<p>I’m using <a href="https://fontawesome.com/">FontAwesome</a> for all my icons on the site. I wanted to use one of them for these visualizations. The FontAwesome files are all SVGs (which is great), but I didn’t know how to draw the image in different colors in Javascript. The way I decided to do this was to load the SVG file into a Javascript <code>Image</code> object, then draw that onto the canvas each draw call.</p>
<p>That worked, but it only drew it black even after changing the fill and stroke colors. So after some web searching I read about someone deciding to draw out an image on an offscreen canvas, reading all the image data, and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dwayne.xyz/post/audio-visualizations-web-audio-api">https://dwayne.xyz/post/audio-visualizations-web-audio-api</a></em></p>]]>
            </description>
            <link>https://dwayne.xyz/post/audio-visualizations-web-audio-api</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938292</guid>
            <pubDate>Fri, 30 Oct 2020 01:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantbase – Deploy your own algo trader in 5 minutes with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24938082">thread link</a>) | @tjs8rj
<br/>
October 29, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users’ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24938082</guid>
            <pubDate>Fri, 30 Oct 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vega-Lite: A Grammar of Interactive Graphics]]>
            </title>
            <description>
<![CDATA[
Score 223 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24937954">thread link</a>) | @tosh
<br/>
October 29, 2020 | https://vega.github.io/vega-lite/ | <a href="https://web.archive.org/web/*/https://vega.github.io/vega-lite/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <section>
    <p>
  <strong>Vega-Lite</strong> is a high-level grammar of interactive graphics. It provides a concise, declarative JSON syntax to create an expressive range of visualizations for data analysis and presentation.
</p>

<p><span>
  <span>
    Vega-Lite specifications describe visualizations as encoding mappings from data to <strong>properties of graphical marks</strong> (e.g., points or bars).
    The Vega-Lite compiler <strong>automatically produces visualization components</strong> including axes, legends, and scales.
    It determines default properties of these components based on a set of <strong>carefully designed rules</strong>.
    This approach allows Vega-Lite specifications to be concise for quick visualization authoring, while giving user control to override defaults and customize various parts of a visualization.
    As we also designed Vega-Lite to support data analysis, Vega-Lite supports both <strong>data transformations</strong> (e.g., aggregation, binning, filtering, sorting) and <strong>visual transformations</strong> (e.g., stacking and faceting).
    Moreover, Vega-Lite specifications can be <strong>composed</strong> into layered and multi-view displays, and made <strong>interactive with selections</strong>.
  </span>
  <span>
  <a href="https://vega.github.io/vega-lite/tutorials/getting_started.html">Get started<br><small>Latest Version: 4.17.0</small></a>
  <a href="https://vega.github.io/editor/#/custom/vega-lite">Try online</a>
  </span>
</span></p>

<p>Compared to <a href="https://vega.github.io/vega">Vega</a>, Vega-Lite provides a more concise and convenient form to author common visualizations. As Vega-Lite can compile its specifications to Vega specifications, users may use Vega-Lite as the <em>primary</em> visualization tool and, if needed, transition to use the lower-level Vega for advanced use cases.</p>

<p>For more information, read our <a href="https://medium.com/@uwdata/de6661c12d58">introduction article to Vega-Lite v2 on Medium</a>, watch our <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">OpenVis Conf talk about the new features in Vega-Lite v2</a>, see the <a href="https://vega.github.io/vega-lite/docs/">documentation</a> and take a look at our <a href="https://vega.github.io/vega-lite/examples/">example gallery</a>. Follow us on <a href="https://twitter.com/vega_vis">Twitter at @vega_vis</a> to stay informed about updates.</p>

<h2 id="example">Example</h2>



<h2 id="additional-links">Additional Links</h2>

<ul>
  <li>Award winning <a href="https://idl.cs.washington.edu/papers/vega-lite">research paper</a> and <a href="https://www.youtube.com/watch?v=9uaHRWj04D4">video of our OpenVis Conf talk</a> on the design of Vega-Lite</li>
  <li>Listen to a Data Stories episode about <a href="http://datastori.es/121-declarative-visualization-with-vega-lite-and-altair-with-dominik-moritz-jacob-vanderplas-kanit-ham-wongsuphasawat/">Declarative Visualization with Vega-Lite and Altair</a>
</li>
  <li>
<a href="http://json-schema.org/">JSON schema</a> specification for <a href="https://github.com/vega/schema">Vega-Lite</a> (<a href="https://vega.github.io/schema/vega-lite/v4.json">latest</a>)</li>
  <li>Ask questions about Vega-Lite on <a href="https://stackoverflow.com/tags/vega-lite">Stack Overflow</a> or <a href="https://bit.ly/join-vega-slack-2020">Slack</a>
</li>
  <li>Fork our <a href="https://bl.ocks.org/domoritz/455e1c7872c4b38a58b90df0c3d7b1b9">Vega-Lite Block</a>, or <a href="https://beta.observablehq.com/@domoritz/vega-lite-demo">Observable Notebook</a>.</li>
</ul>

<h2 id="users">Users</h2>

<p>Vega-Lite is used by thousands of data enthusiasts, developers, journalists, data scientists, teachers, and researchers across many organizations. Here are some of them. Learn about integrations on our <a href="https://vega.github.io/vega-lite/ecosystem.html">ecosystem page</a>.</p>



<h2 id="team">Team</h2>

<p>The development of Vega-Lite is led by the alumni and members of the <a href="https://idl.cs.washington.edu/">University of Washington Interactive Data Lab</a> (UW IDL), including <a href="https://twitter.com/kanitw">Kanit “Ham” Wongsuphasawat</a> (now at Apple), <a href="https://twitter.com/domoritz">Dominik Moritz</a> (now at CMU / Apple), <a href="https://twitter.com/arvindsatya1">Arvind Satyanarayan</a> (now at MIT), and <a href="https://twitter.com/jeffrey_heer">Jeffrey Heer</a> (UW IDL).</p>

<p>Vega-Lite gets significant contributions from its community–in particular <a href="https://willium.com/">Will Strimling</a>, <a href="https://github.com/YuhanLu">Yuhan (Zoe) Lu</a>, <a href="https://github.com/invokesus">Souvik Sen</a>, <a href="https://github.com/chanwutk">Chanwut Kittivorawong</a>, <a href="https://github.com/mattwchun">Matthew Chun</a>, <a href="https://github.com/AkshatSh">Akshat Shrivastava</a>, <a href="https://github.com/Saba9">Saba Noorassa</a>, <a href="https://github.com/sirahd">Sira Horradarn</a>, <a href="https://github.com/donghaoren">Donghao Ren</a>, and <a href="https://github.com/haldenl">Halden Lin</a>. Please see the <a href="https://github.com/vega/vega-lite/graphs/contributors">contributors page</a> for the full list of contributors.</p>

  </section>
</div></div>]]>
            </description>
            <link>https://vega.github.io/vega-lite/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937954</guid>
            <pubDate>Fri, 30 Oct 2020 00:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bizarre Design Choices in Zoom’s End-to-End Encryption]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24937298">thread link</a>) | @notRobot
<br/>
October 29, 2020 | https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Zoom recently announced that they were going to make end-to-end encryption available to all of their users–not just customers.</p>



<figure><div>

</div></figure>



<p>This is a good move, especially for people living in countries with <a href="https://soatok.blog/2020/07/02/how-and-why-america-was-hit-so-hard-by-covid-19/">inept leadership that failed to address the COVID-19 pandemic</a> and therefore need to conduct their work and schooling remotely through software like Zoom. I enthusiastically applaud them for making this change.</p>



<div><figure><img data-attachment-id="1333" data-permalink="https://soatok.blog/soatoktelegrams2020-08/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-08" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-08.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>End-to-end encryption, on by default, is a huge win for everyone who uses Zoom. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>The end-to-end encryption capability arrives on the heels of their acquisition of <a href="https://keybase.io/">Keybase</a> in earlier this year. Hiring a team of security experts and cryptography engineers seems like a good move overall.</p>



<p>Upon hearing this news, I decided to be a good neighbor and take a look at their source code, with the reasoning, “If so many people’s privacy is going to be dependent on Zoom’s security, I might as well make sure they’re not doing something ridiculously bad.”</p>



<p>Except I couldn’t find their source code anywhere online. But they did publish <a href="https://github.com/zoom/zoom-e2e-whitepaper">a white paper on Github</a>…</p>







<h2>Disclaimers</h2>



<p>What follows is the opinion of some guy on the Internet with a fursona–so whether or not you choose to take it seriously should be informed by this context. It is not the opinion of anyone’s employer, nor is it endorsed by Zoom, etc. Tell your lawyers to calm their nips.</p>



<p>More importantly, I’m not here to hate on Zoom for doing a good thing, nor on the security experts that worked hard on making Zoom better for their users. The responsibility of security professionals is to the users, after all.</p>



<p>Also, these aren’t zero-days, so don’t try to lecture me about “responsible” disclosure. (That term is also <a href="https://adamcaudill.com/2015/11/19/responsible-disclosure-is-wrong/">problematic</a>, by the way.)</p>



<p>Got it? Good. Let’s move on.</p>







<h2>Bizarre Design Choices in Version 2.3 of Zoom’s E2E White Paper</h2>



<p>Note: I’ve altered the screenshots to be white text on a black background, since my blog’s color scheme is darker than a typical academic PDF. You can find the source <a href="https://github.com/zoom/zoom-e2e-whitepaper/blob/d3be2a5a3e16be04f1199b92630f180ba79cb51c/zoom_e2e.pdf">here</a>.</p>



<h3>Cryptographic Algorithms</h3>



<div><figure><img data-attachment-id="1744" data-permalink="https://soatok.blog/zoom-e2e-02/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" data-orig-size="784,652" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-02.png" alt=""></figure></div>



<p>It’s a little weird that they’re calculating a signature over SHA256(Context) || SHA256(M), considering Ed25519 uses SHA512 internally.</p>



<p>It would make just as much sense to sign Context || M directly–or, if pre-hashing large streams is needed, SHA512(Context || M).</p>



<div><figure><img data-attachment-id="1740" data-permalink="https://soatok.blog/zoom-e2e-01/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" data-orig-size="1039,788" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-01" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-01.png" alt=""></figure></div>



<p>At the top of this section, it says it uses libsodium’s <code>crypto_box</code> interface. But then they go onto… not actually use it.</p>



<p>Instead, they wrote their own protocol using HKDF, two SHA256 hashes, and XChaCha20-Poly1305.</p>



<p>While secure, this isn’t <em>really</em> using the crypto_box interface.</p>



<p>The only part of the libsodium interface that’s being used is <code><a href="https://github.com/jedisct1/libsodium/blob/927dfe8e2eaa86160d3ba12a7e3258fbc322909c/src/libsodium/crypto_box/curve25519xsalsa20poly1305/box_curve25519xsalsa20poly1305.c#L35-L46">crypto_box_beforenm()</a></code>, which could easily have been a call to <code>crypto_scalarmult()</code>instead (since they’re passing the output of the scalar multiplication to HKDF anyway).</p>







<p>Also, the SHA256(a) || SHA256(b) pattern returns. Zoom’s engineers must love SHA256 for some reason.</p>



<p>This time, it’s in the additional associated data for the XChaCha20-Poly1305. </p>



<p>Binding the ciphertext and the signature to the same context string is a sensible thing to do, it’s just the concatenation of SHA256 hashes is a bit weird when SHA512 exists.</p>



<h3>Meeting Leader Security Code</h3>



<div><figure><img data-attachment-id="1746" data-permalink="https://soatok.blog/zoom-e2e-03/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" data-orig-size="760,733" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-03" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-03.png" alt=""></figure></div>



<p>Here we see Zoom using the a SHA256 of a constant string (“<code>Zoombase-1-ClientOnly-MAC-SecurityCode</code>“) in a construction that tries but fails to be HMAC.</p>



<p>And then they concatenate it with the SHA256 hash of the public key (which is already a 256-bit value), and then they hash the whole thing again.</p>



<p>It’s redundant SHA256 all the way down. The redundancy of “MAC” and “SecurityCode” in their constant string is, at least, consistent with the rest of their design philosophy.</p>



<p>It would be a real shame if double-hashing carried the risk of <a href="https://eprint.iacr.org/2013/382">invalidating security proofs</a>, or if <a href="https://cseweb.ucsd.edu/~mihir/papers/kmd5.pdf">the security proof for HMAC</a> required a high Hamming distance of padding constants and this design decision also later <a href="https://eprint.iacr.org/2012/684.pdf">saved HMAC from related-key attacks</a>.</p>



<h3>Hiding Personal Details</h3>



<figure><img data-attachment-id="1750" data-permalink="https://soatok.blog/zoom-e2e-04/" data-orig-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png" data-orig-size="739,603" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="zoom-e2e-04" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=580" src="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=739" alt="" srcset="https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png 739w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=150 150w, https://soatok.files.wordpress.com/2020/10/zoom-e2e-04.png?w=300 300w" sizes="(max-width: 739px) 100vw, 739px"></figure>



<p>Wait, you’re telling me Zoom was aware of HMAC’s existence this whole time?</p>



<div><figure><img data-attachment-id="1202" data-permalink="https://soatok.blog/soatoktelegrams2020-02/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-02" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png 512w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatoktelegrams2020-02.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>I give up!</figcaption></figure></div>



<h2>Enough Pointless Dunking, What’s the Takeaway?</h2>



<p>None of the design decisions Zoom made that I’ve criticized here are security vulnerabilities, but they do demonstrate an early lack of cryptography expertise in their product design.</p>



<p>After all, the weirdness is almost entirely contained in section 3 of their white paper, which describes the “Phase I” of their rollout. So what I’ve pointed out here appears to be mostly legacy cruft that wasn’t risky enough to bother changing in their final design.</p>



<p>The rest of their paper is pretty straightforward and pleasant to read. Their design makes sense in general, and each phase includes an “Areas to Improve” section.</p>



<p>All in all, if you’re worried about the security of Zoom’s E2EE feature, the only thing they can really do better is to publish the source code (and link to it from the whitepaper repository for ease-of-discovery) for this feature so independent experts can publicly review it.</p>



<p>However, they seem to be getting a lot of mileage out of the experts on their payroll, so I wouldn’t count on that happening.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2020/10/28/bizarre-design-choices-in-zooms-end-to-end-encryption/?hac</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937298</guid>
            <pubDate>Thu, 29 Oct 2020 23:23:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The most advanced VPN and unblocker with industry-first features]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24937073">thread link</a>) | @Oeck
<br/>
October 29, 2020 | http://www.oeck.com/features/ | <a href="https://web.archive.org/web/*/http://www.oeck.com/features/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<!--XF:EXTRA_OUTPUT-->

		

		

		
	

		
	<!--[if lt IE 9]><div class="blockMessage blockMessage&#45;&#45;important blockMessage&#45;&#45;iconic">You are using an out of date browser. It  may not display this or other websites correctly.<br />You should upgrade or use an <a href="https://www.google.com/chrome/browser/" target="_blank">alternative browser</a>.</div><![endif]-->


		
			<div>
			
				
					
				

				
					<p>The things that make us different.</p>
				
			
				
			</div>
		

		<div>
			

			<div>
				
				<div>

	



	
	
	










	<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/smartRouting.png">
			</p>
			<div>
				<div>
					<p><img src="http://www.oeck.com/assets/images/web/png/500/smartRouting.png"></p><p>
					<span>smartRouting</span>
					<br>
					Oeck takes away the need of connecting to a specific region to access streaming content. Get access to the latest shows from around the world without ever switching regions. Our revolutionary smartRouting unblocks some of the most popular services from around the globe. Enjoy fast, automated access to itv in the UK - Hulu in the US - iView in Australia and many more. Simply connect to the VPN location closest to you and we take care of the rest! 
					</p>
					
				</div>				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/deviceProfiles.png"></p><p>
				<span>Device Profiles</span>
				<br>
				Device Profiles allow you to take your VPN functionality to the next level. This handy feature allows you to set preferences for streaming services and traffic filtration on a per-device level.
					By doing this you can quickly set up a childs device to block adult content whilst keeping your other devices untouched. It also allows you to set up devices with different streaming regions.
					For example, you can have Netflix USA on one device, Netflix UK on another and Netflix Germany on yet another, whilst all the while being connected to the VPN region closest to you!
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/deviceProfiles.png">
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/adBlocker.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/adBlocker.png"></p><div>
				<p><span>Cerberus</span>
				<br>
				Get powerful device-level filtering to prevent dangerous content reaching your family and devices. Our unique online guardian Cerberus is the must-have feature for families and individuals. Choose which content to block and prevent threats before they occur. Simply create a profile for your device and select the Cerberus services required.
					</p><p>
					
					You can filter Ads, Malware and Phishing, Adult and Social Networking sites individually or combined!
				</p></div>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div>
		<div>
			<div>
				<p><span>Security</span>
					<br>
					<span>Built deep into our network and culture.</span>
				</p>
				<div data-aos="fade-up"><p>
					We secure your privacy using industry-leading encryption standards, on servers that we own. Our zero hard drive system won’t store any of your data, ever! Quickly block dangerous sites and services at the DNS level to prevent ads, malware, phishing sites and more.
					</p>
					
				</div>
			</div>
		</div>
	</div>	
</div>

<div>
	<div>
		<div data-aos="fade-up">
			<p><span>AES-256</span>
				<br>
				<span>Encryption</span>
			</p>
			<p><span>4096-bit</span>
				<br>
				<span>Key Exchange</span>
			</p>
			<p><span>Zero</span>
				<br>
				<span>Hard Drives</span>
			</p>
			<p><span>Zero</span>
				<br>
				<span>Logging</span>
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/portForwarding.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/portForwarding.png"></p><p>
				<span>Advanced Port Forwarding</span>
				<br>
				This is a simple but handy feature with a twist. We issue you ports and you enable ports you select on your device profile(s). Then you simply tell us which port you would like to forward to. No need to configure your client or software to suit us. As an added bonus, you get your very own custom domain name per port. Regardless of which VPN region you connect to, your port-forwarding will always work!
				</p>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/customFilter.png"></p><p>
				<span>Custom DNS Filter</span>
				<br>
				Our built-in DNS filter allows you to decide what internet traffic you want hitting your device(s). Simply populate your filter list with websites that you want blocked and Oeck's VPN will follow those rules and block the traffic. Domain black lists can be set on a per-device level, which makes is perfect for parents who would like to restrict what their children can access. Best of all, it is completely unique to you.
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/customFilter.png">
			</p>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/customDNS.png">
			</p>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/customDNS.png"></p><p>
				<span>Secondary DNS</span>
				<br>
				A feature built for advanced users. Secondary DNS allows you to specify a DNS service to use that will bypass Oeck's DNS. To further simplify the feature, you can still allow Oeck to take control of some of the DNS queries and leave others up to your Secondary DNS.
				</p>
				
			</div>
		</div>
	</div>
</div>

<div>
	<div data-aos="fade-up">
		<div>
			<div>
				<p><img src="http://www.oeck.com/assets/images/web/png/500/serverSelection.png"></p><p>
				<span>Automatic Server Selection</span>
				<br>
				When selecting a VPN region to connect to, our network runs a check of the available servers and resources within that region. It then calculates which server will be the best server for you to connect to. It takes into account the available system resources of each server and so it will always connect you to the best available server. No more server surfing ever again!
				</p>
				
			</div>
			<p><img src="http://www.oeck.com/assets/images/web/png/500/serverSelection.png">
			</p>
		</div>
	</div>
</div>




	




</div>
				
			</div>

			
		</div>

		

		
	</div>
</div></div>]]>
            </description>
            <link>http://www.oeck.com/features/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937073</guid>
            <pubDate>Thu, 29 Oct 2020 22:53:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sun is more active now than over the last 8000 years (2004)]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24937001">thread link</a>) | @firebaze
<br/>
October 29, 2020 | https://www.mpg.de/research/sun-activity-high | <a href="https://web.archive.org/web/*/https://www.mpg.de/research/sun-activity-high">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  
  <p>An international team of scientists has reconstructed the Sun's activity over the last 11 millennia and forecasts decreased activity within a few decades</p>
  

  

  <p>The activity of the Sun over the last 11,400 years, i.e., back to the end of the last ice age on Earth, has now for the first time been reconstructed quantitatively by an international group of researchers led by Sami K. Solanki from the Max Planck Institute for Solar System Research (Katlenburg-Lindau, Germany). The scientists have analyzed the radioactive isotopes in trees that lived thousands of years ago. As the scientists from Germany, Finland, and Switzerland report in the current issue of the science journal "Nature" from October 28, one needs to go back over 8,000 years in order to find a time when the Sun was, on average, as active as in the last 60 years. Based on a statistical study of earlier periods of increased solar activity, the researchers predict that the current level of high solar activity will probably continue only for a few more decades.</p>
  
  
<figure data-description="A large sunspot observed on the Sun in early September 2004. The field of view encompasses around 45,000 by 30,000 km of the Sun’s surface - the entire earth would fit into the area several times over. Sunspots appear dark because the strong magnetic field in the them suppresses the transport of energy through gas flow. In the central dark area of the sunspot (umbra) the magnetic field is perpendicular to the surface, whereas in the lighter coloured periphery (penumbra) the magnetic field is largely horizontal to the surface. The image was captured by Vasily Zakharov with a one-meter solar telescope on the island of La Palma. The telescope is operated by the Institute for Solar Physics of the Royal Swedish Academy of Sciences." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          A large sunspot observed on the Sun in early September 2004. The field of view encompasses around 45,000 by 30,000 km of the Sun’s surface - the entire earth would fit into the area several times over. Sunspots appear dark because the strong magnetic field in the them suppresses the transport of energy through gas flow. In the central dark area of the sunspot (umbra) the magnetic field is perpendicular to the surface, whereas in the lighter coloured periphery (penumbra) the magnetic field is largely horizontal to the surface. The image was captured by Vasily Zakharov with a one-meter solar telescope on the island of La Palma. The telescope is operated by the Institute for Solar Physics of the Royal Swedish Academy of Sciences.
        </p>
        <p>
          © Max Planck Institute for Solar System Research
        </p>
    </figcaption>
</figure>


<p>The research team had already in 2003 found evidence that the Sun is more active now than in the previous 1000 years. A new data set has allowed them to extend the length of the studied period of time to 11,400 years, so that the whole length of time since the last ice age could be covered. This study showed that the current episode of high solar activity since about the year 1940 is unique within the last 8000 years. This means that the Sun has produced more sunspots, but also more flares and eruptions, which eject huge gas clouds into space, than in the past. The origin and energy source of all these phenomena is the Sun's magnetic field.</p>

<p>Since the invention of the telescope in the early 17th century, astronomers have observed sunspots on a regular basis. These are regions on the solar surface where the energy supply from the solar interior is reduced owing to the strong magnetic fields that they harbour. As a consequence, sunspots are cooler by about 1,500 degrees and appear dark in comparison to their non-magnetic surroundings at an average temperature of 5,800 degrees. The number of sunspots visible on the solar surface varies with the 11-year activity cycle of the Sun, which is modulated by long-term variations. For example, there were almost no sunspots seen during the second half of the 17th century.</p>

<p>For many studies concerning the origin of solar activity and its potential effect on long-term variations of Earth's climate, the interval of time since the year 1610, for which systematic records of sunspots exist, is much too short. For earlier times the level of solar activity must be derived from other data. Such information is stored on Earth in the form of "cosmogenic" isotopes. These are radioactive nuclei resulting from collisions of energetic cosmic ray particles with air molecules in the upper atmosphere. One of these isotopes is C-14, radioactive carbon with a half life of 5730 years, which is well known from the C-14 method to determine the age of wooden objects. The amount of C-14 produced depends strongly on the number of cosmic ray particles that reach the atmosphere. This number, in turn, varies with the level of solar activity: during times of high activity, the solar magnetic field provides an effective shield against these energetic particles, while the intensity of the cosmic rays increases when the activity is low. Therefore, higher solar activity leads to a lower production rate of C-14, and vice versa.</p>

<p>By mixing processes in the atmosphere, the C-14 produced by cosmic rays reaches the biosphere and part of it is incorporated in the biomass of trees. Some tree trunks can be recovered from below the ground thousands of years after their death and the content of C-14 stored in their tree rings can be measured. The year in which the C-14 had been incorporated is determined by comparing different trees with overlapping life spans. In this way, one can measure the production rate of C-14 backward in time over 11,400 years, right to the end of the last ice age. The research group have used these data to calculate the variation of the number of sunspots over these 11,400 years. The number of sunspots is a good measure also for the strength of the various other phenomena of solar activity.</p>

<p>The method of reconstructing solar activity in the past, which describes each link in the complex chain connecting the isotope abundances with the sunspot number with consistent quantitative physical models, has been tested and gauged by comparing the historical record of directly measured sunspot numbers with earlier shorter reconstructions on the basis of the cosmogenic isotope Be-10 in the polar ice shields. The models concern the production of the isotopes by cosmic rays, the modulation of the cosmic ray flux by the interplanetary magnetic field (the open solar magnetic flux), as well as the relation between the large-scale solar magnetic field and the sunspot number. In this way, for the first time a quantitatively reliable reconstruction of the sunspot number for the whole time since the end of the last ice age could be obtained.</p>
<figure data-description="Top: Reconstructed sunspot activity (10 year average) for the last 11,400 years based on C-14 data (blue curve) and the directly observed historical sunspot data since 1610 (red curve). The reliable C-14 data ends around the year 1900 so that the sharp increase in sunspot activity in the 20th century does not appear in the graph. The reconstruction shows clearly that a comparable period of high sunspot activity previously existed over 8000 years ago. Below: An enlarged section of the upper graph (hatched area) with several episodes of higher sun activity; comparable to the 20th century." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Top: Reconstructed sunspot activity (10 year average) for the last 11,400 years based on C-14 data (blue curve) and the directly observed historical sunspot data since 1610 (red curve). The reliable C-14 data ends around the year 1900 so that the sharp increase in sunspot activity in the 20th century does not appear in the graph. The reconstruction shows clearly that a comparable period of high sunspot activity previously existed over 8000 years ago. Below: An enlarged section of the upper graph (hatched area) with several episodes of higher sun activity; comparable to the 20th century.
        </p>
        <p>
          © Max Planck Institute for Solar System Research
        </p>
    </figcaption>
</figure>


<p>Because the brightness of the Sun varies slightly with solar activity, the new reconstruction indicates also that the Sun shines somewhat brighter today than in the 8,000 years before. Whether this effect could have provided a significant contribution to the global warming of the Earth during the last century is an open question. The researchers around Sami K. Solanki stress the fact that solar activity has remained on a roughly constant (high) level since about 1980 - apart from the variations due to the 11-year cycle - while the global temperature has experienced a strong further increase during that time. On the other hand, the rather similar trends of solar activity and terrestrial temperature during the last centuries (with the notable exception of the last 20 years) indicates that the relation between the Sun and climate remains a challenge for further research.</p>
  
</div></div>]]>
            </description>
            <link>https://www.mpg.de/research/sun-activity-high</link>
            <guid isPermaLink="false">hacker-news-small-sites-24937001</guid>
            <pubDate>Thu, 29 Oct 2020 22:44:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't contribute anything relevant in web forums]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24934569">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://karl-voit.at/2020/10/23/avoid-web-forums/ | <a href="https://web.archive.org/web/*/https://karl-voit.at/2020/10/23/avoid-web-forums/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<ul>
<li>Updates
<ul>
<li>2020-10-25 Comment by Erik</li>
</ul></li>
</ul>

<p>

If you're, for example, contributing to a <a href="https://en.wikipedia.org/wiki/Reddit">reddit</a> thread about something which is irrelevant or anything with only a short-term relevance, this article does not apply to you right now.

</p>

<p>

However, as soon as you're helping somebody solving an interesting issue, summarize your experiences with something or write anything that might be cool to be around in a couple of years as well, you do provide potential high-value content. My message to all those authors is: <b>don't use web-based forums</b>.

</p>

<p>

TL;DR: all of the content of closed, centralized services will be lost in the long run. Choose the platform you contribute to wisely now instead of learning through more large data loss events later-on.

</p>

<p>

The longer version is worth your time:

</p>

	  <header><h2>What Do I Mean With Web-Based Forums Here?</h2></header>

<p>

In this article, I'm using the term "web-based forums" as an umbrella term for closed, centralized services like <a href="https://en.wikipedia.org/wiki/Reddit">Reddit</a>, <a href="https://en.wikipedia.org/wiki/Hacker_News">Hacker News</a>, <a href="https://en.wikipedia.org/wiki/Slashdot">Slashdot</a>, Facebook, or any other web-based forum where you are able to add comments, articles, and so forth in most cases only after creating an account.

</p>

<p>

Typically, those services don't provide any possibility to extract or synchronize content. They don't offer open APIs that allow users to choose among different and open user interfaces. They are owned and operated by private companies.

</p>

<p>

Please note that when I'm going to mention more or less only reddit as an example in the next sections, this is because reddit is the only web-based forum <a href="https://www.reddit.com/user/publicvoit">I'm familiar with</a> to a certain level. This does not mean that reddit is worse than other closed, centralized web-based forums. Not at all.

</p>

	  <header><h2>So What's the Issue With Web-Based Forums?</h2></header>

<p>

There is not one issue. There are several things where web-based forums don't qualify for being a platform for quality content. Let's take a look at some of them.

</p>

<p>

I'm glad you're still reading this article and I hope you bear with me until the end of it. Most people will realize and learn about having contributed lots and lots of high-value information only when platforms are down for good. And this is what makes me really sad. It is just like you know that one building of the Library of Alexandria is going to burn down in a few years and people still bring many unique copies of high-quality books into its shelves, unaware of destroying knowledge this way.

</p>

	  <header><h3>Issue: No Backup, No Distribution</h3></header>

<p>

For reasons and examples stated <a href="https://karl-voit.at/cloud">in this article</a>, any centralized web-based service will go offline some day. Some sooner, some later. Popularity is not even a guarantee that a service gets continued, as you can see with <a href="https://killedbygoogle.com/">hundreds of (partly) very well known and used Google services that were shut down</a>. Nothing will be on the web forever. Most people are not aware of this fact. The books set on this machine are more likely to survive history than all of your reddit/Facebook/... contributions:

</p>

<figure>
<img src="https://karl-voit.at/2020/10/23/avoid-web-forums/2019-10-05T22.56.47%20Buchdruckmuseum%20-%20Linotype%20-%20Tastatur%20--%20cliparts%20typography%20history%20publicvoit%20-%20scaled%20width%20630.jpg" alt="" width="630">
<figcaption>A Linotype machine.</figcaption>
</figure>

<p>

So when you begin to be aware of this fact, you might want to think of things you can do to mitigate data loss when services are discontinued or "sunrized" as some marketing experts say.

</p>

<p>

You could, for example, back-up the data of this service. By providing the information on multiple servers, chances are high that not all of them are lost at the same time.

</p>

<p>

This requires certain properties. For example, you need to be able to duplicate the service on multiple servers. To be able to do so, you'll need not only the data but also the software that is providing access to the service. When different organization are running mirrored servers, it is required to openly share the data and software. This can be ensured by using Open Source software or at least open APIs and a business model that does not rely on keeping data and technical things a secret.

</p>

<p>

All major commercial services such as reddit, Facebook and so forth keep everything a secret that is not ultimately necessary to use their services. Their software is a secret, they don't offer open APIs or only very crippled ones, you don't have the possibility to get to the raw data. So no luck there. You do have <a href="https://en.wikipedia.org/wiki/Vendor_lock-in">a lock-in situation</a>.

</p>

<figure>
<img src="https://karl-voit.at/2020/10/23/avoid-web-forums/2020-10-23%20Oatmeal_-_reaching_people_on_the_internet%20--%20publicvoit%20-%20scaled%20width%20630.png" alt="" width="630">
<figcaption>https://theoatmeal.com/comics/reaching_people</figcaption>
</figure>

<p>

Even with personal blogs, "fragile" as they are, you are able to use the <a href="https://archive.org/web/">Wayback Machine of the Internet Archive</a> to back up your blog. For example, every page on my blog contains a link to its archive in the page footer. This ensures that you can not only browse the latest version of all of my blog articles in case of a server breakdown. This also enables you to browse all previous version, probably changed over time. Go ahead, try a few "Archive" links of my articles. If any of my articles start with an "Updates:" section, you know for sure that there are older versions accessible via the Internet Archive.

</p>

<p>

The Wayback Machine does not archive reddit threads. It can not properly back up Facebook pages. <a href="https://help.archive.org/hc/en-us/articles/360004651732-Using-The-Wayback-Machine">It's blinded by corporate secrecy</a> when it comes to archive content for the upcoming generations:

</p>

<blockquote>Why isn't the site I'm looking for in the archive?<br>
Some sites may not be included because the automated crawlers were
unaware of their existence at the time of the crawl. It's also
possible that some sites were not archived because they were password
protected, blocked by robots.txt, or otherwise inaccessible to our
automated systems. Site owners might have also requested that their
sites be excluded from the Wayback Machine.</blockquote>

<p>

Summarizing the things mentioned above: without very good support for data export, service duplication, open standards, any content you provide in closed web-based services will be lost just as <a href="https://www.nytimes.com/2019/03/19/business/myspace-user-data.html">MySpace already lost twelve years of content just so</a>, just to mention one big example.

</p>

	  <header><h3>Issue: User Interface Dictatorship</h3></header>

<p>

When you grew up only knowing centralized web-based forums, you can not imagine the many advantages of having the freedom to choose your preferred user interface. While some people might think this is a minor issue, let me explain a few examples where this makes a huge difference.

</p>

<p>

The first example starts with something that might only annoy people. With comments like on <a href="https://www.reddit.com/r/emacs/comments/hfamm7/those_who_have_tried_out_multiple_zettelkasten/fvx9vu5/">this thread</a>, you clutter up other people's interface for personal gain. It's selfish and distracts from the information consumption.

</p>

<p>

The reason why people are using such reminder bots is multi-fold. First, they don't use a proper todo management system that would be able to remind them to read a certain article in a few days. They externalize this inability to the web-based forum and all of its other users. <a href="https://karl-voit.at/tags/pim">I'm working on fixing these educational issues</a>. Secondly, there is no way to have features that you can use that do not affect other people's interface.

</p>

<p>

Consider people with visual impairment do have special needs. <a href="https://tinyurl.com/y6ncgvjt">The WHO reports</a> an estimate of 285 million people that do are visually impaired, ninety percent of them living in developing countries. Those are not numbers you can simply ignore. It is obvious that they do need different kind of interfaces. Either they have to use a high-contrast interface, highly unusual interface scaling factors, an interface that avoids certain color combinations, text-to-speech systems or <a href="https://en.wikipedia.org/wiki/Braille#Braille_reading">Braille readers</a> that are able to extract the content properly.

</p>

<p>

If a web-based services that - remember from before - does not offer proper open APIs and which does not implement said features, all those people simply can not participate and you can not profit from their knowledge and experience.

</p>

<p>

And even when you think that this is just a minority I can provide examples where everybody profits from choosing his or her own interface.

</p>

<p>

Some services are providing interfaces that aren't working properly on small displays or mobile devices in general. In these cases, without any ability to switch to an alternative app or web-page, you are locked out even with perfect eyesight.

</p>

<p>

When you're using an web-based forum that does not provide the feature that already read articles are marked or collapsed, you need to skim though a thread completely and re-read content to find out new postings when re-visiting the thread after a while. Our time should not spent on senseless tasks like this.

</p>

<p>

Alternative interfaces might provide advanced rating features based on your personal taste and choice so that you are able to filter out the most relevant articles easily and do not clutter your view with irrelevant articles at all. This is also called "scoring". It can be based on keywords, the amount of personal contributions to a longer thread, friendship relationships from your contact management, and so forth.

</p>

<p>

Some people prefer navigating using the keyboard. Either by personal taste or by physical restrictions. If the web-based centralized service only supports mouse-based navigation, you can not use this service.

</p>

<p>

I could continue with examples like that. The common theme is: when one particular centralized web-based forum is not implementing all of those nice features you need or like, you can not use them properly.

</p>

	  <header><h3>Issue: Rule Monopoly and Subjective Censorship</h3></header>

<p>

When you do live in a society with certain set of (legal) rules, providers of relevant web-based forums have to follow and enforce some of them. However, the issue is that this kind of censorship is and will always be related to a particular culture and society at a specific time.

</p>

<p>

For example, in Germany and Austria, being a <a href="https://en.wikipedia.org/wiki/Nazism">Nazi</a> is punishable by law. In the USA, freedom-loving people think fans of the human monsters that tortured and murdered millions of Jews in the Second World War need the possibility to express their personal "opinion". As you can see, there is a different point of view in-between the lines when I write about Nazis compared to an author from the USA who values "freedom of speech" higher than "being a die-hard fan of mass murders". It's a very difficult topic you can not enforce with a world-wide service.

</p>

<p>
</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karl-voit.at/2020/10/23/avoid-web-forums/">https://karl-voit.at/2020/10/23/avoid-web-forums/</a></em></p>]]>
            </description>
            <link>https://karl-voit.at/2020/10/23/avoid-web-forums/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934569</guid>
            <pubDate>Thu, 29 Oct 2020 19:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A12 – Advancing Network Transparency on the Desktop]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24934296">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/ | <a href="https://web.archive.org/web/*/https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>This article is is the main course to the appetiser that was <a href="https://arcan-fe.com/2018/11/16/the-x-network-transparency-myth/">The X Network Transparency Myth</a> (2018). In it, we will go through how the pieces in the Arcan ecosystem tie together to advance the idea of network transparency for the desktop and how it sets the stage for a fully networked desktop.</p>



<p>Some of the points worth recalling from the X article are:</p>



<ol><li>‘transparency’ is evaluated from the perspective of the user; it is not even desirable for the underlying layers to be written so that they operate the same for local rendering as they would across a network. The local-optimal case is necessarily different from the remote one, the mechanisms are not the same and the differences will keep on growing organically with the advancement of hardware and display/rendering techniques.</li><li>side-band protocols splitting up the desktop into multiple IPC systems for audio, meta, fonts, … increases the difficulty to succeed with anything close to a transparent experience, as the network layer needs to take all of these into consideration as well as trying to synchronise them.</li></ol>



<p>To add a little to the first argument: it should also not be transparent to the window manager as some actions have drastically different impact on the user interface side to security and expectations. For example, Clipboard/DND locally is not (supposed to be) a complicated thing. When applied across a network, however, such things can degrade the experience for anything else. Other examples is that you want to block some sensitive inputs from being accidentally forwarded to a networked window and so on, it has happened in the past that the wrong sudo password has, indeed, been sent to the wrong ssh session.</p>



<p>This target has been worked on for a long time, as suggested by this part from the <a href="https://www.youtube.com/watch?v=3O40cPUqLb">old demo</a> from 2012/2013. Already back then the drag/slice to compose-transform-and-share case exposed out of compositor sharing and streaming; something that only now is appearing elsewhere in a comparably limited form.</p>



<p>We are on the third or fourth re-implementation of the idea, and the first one that is considered having a good enough of a design to commit to using and building upon. There are many fascinating nuances to this problem that only appear when you ‘try to go to 11’.</p>



<p>As per usual, parts of this post will be quite verbose and technical. Here are some shortcuts to jump around so that you don’t lose interest from details that seem irrelevant to you.</p>



<ul><li><a href="#primitives">Basic primitives: Arcan-net, A12 and SHMIF</a></li><li><a href="#usecases">Example Usecases</a></li><li><a href="#protocol">Protocol State and Development</a></li><li><a href="#explained">Demo Explained</a></li></ul>



<h2 id="demo">Demos</h2>



<p>Starting with some short clips of the development progress – and then work through the tools and design needed to make this happen. It might be short, but there is a whole world of nuance and detail to it.</p>



<p>(~early 2019) – forced compression, OSX viewer, (bad) audio:</p>



<figure></figure>



<p>Composited Xarcan (desktop to pinephone), compression based on window type:</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/CIWZdEkgPfM?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Here is a native arcan client with crypto, local GPU “hot-unplug” to software rendering handover and compression negotiation (h264):</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/_RSvk7mmiSE?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Here is ‘server-side’ text rendering of text-only windows, font, style and size controlled by presenting device — client migrates back when window is closed:</p>



<figure></figure>



<p><span>In the videos, you can see (if you squint) instances of </span><em>live migration</em><span> between display servers over a network, with a few twists. For example, the decorations, input mapping, font preferences and other visuals change to match the machine that the client is currently </span><em>presenting</em><span> on and that audio also comes along, because </span><a href="https://arcan-fe.com/2017/10/05/awk-for-realtime-multimedia/">Arcan does multimedia</a><span>, not only video. </span></p>



<p><span>What is less visible is that the change in border colour, a security feature in </span><a href="http://durden.arcan-fe.com/">Durden</a><span>, is used to signify that the window comes from a networked source, a property that can also be used to filter sensitive actions. The neo-vim window in the video even goes so far as to have its text surfaces rendered server side, as its </span><a href="https://github.com/letoram/nvim-arcan">UI driver</a><span> is written using our terminal-protocol liberated </span><a href="https://github.com/letoram/arcan/wiki/TUI">TUI API.</a> This is also why the font changes; it is the device you&nbsp;<em>present</em> on that defines visuals and input response, not the device you run the program on.</p>



<p>Also note how the clients “jumps” back when the window is closed on the remote side; this is one of the many payoffs from having a systemic mindset when it comes to&nbsp; ‘<a href="https://arcan-fe.com/2017/12/24/crash-resilient-wayland-compositing/">crash resilience</a>‘ – the IPC system itself is designed in such a way that <em>necessary</em> state can b<span>e reconstructed and&nbsp;</span><em>dynamic</em><span>&nbsp;state is tracked and renegotiated when needed. The effect is that a client is forcefully detached from the current display server with the instruction of switching to another.</span> The keystore (while a work in progress) allows you to define the conditions for when and how it jumps to which machines and picks keys accordingly.</p>



<p>That dynamic state is tracked and can be renegotiated as a ‘reset’ matters on the client level as well, the basic set of guaranteed features when a client opens a local connection roughly generalises between all imaginable window management styles. Those that are dynamically (re-) negotiated cannot be relied upon. So when a client is migrated to a user that has say, accessibility needs, or is in a <a href="https://arcan-fe.com/2018/03/29/safespaces-an-open-source-vr-desktop/">VR environment</a>, the appropriate extras gets added when the client connects there, and then removed when it moves somewhere else. This is an essential primitive for network transparency as a collaboration feature.</p>



<h2 id="primitives">Basic Primitives: Arcan-net, SHMIF and A12</h2>



<p>There are three building blocks in play here, a tool called <em>arcan-net&nbsp;</em>which combines the two others:&nbsp;<em>A12</em> and <a href="https://github.com/letoram/arcan/wiki/SHMIF">SHMIF</a>.</p>



<p>A12 is a <span>‘work in progress’ protocol – it’s not </span><em>the</em><span>&nbsp;</span><a href="https://www.x.org/wiki/Development/X12/">X12</a><span> that some people called for, but it’s “</span><em>a”</em><span> twelve. It strives to be remote optimal – compression tactics based on connectivity, content type and context of use, deferred (presentation side) rendering with data-native representation when possible (pixel buffers as a last resort, not the default); support caching of common states such as fonts; handle cancellation of normally ‘atomic’ operations such as clipboard cut and paste and so on.</span></p>



<p>SHMIF is the IPC system and API used to work with most other parts of Arcan. It is designed to be locally optimal: shared memory and system ABI in lock free ring-buffers preferred over socket/pipe pack/unpack transfers; minimal sustained set of system calls needed (for least-privilege sandboxing); resource allocations on a strict regimen (DoS prevention and exploit mitigation); fixed based set of necessary capabilities and user-controlled opt-in for higher level ones.</p>



<p><span>SHMIF has a large number of features that were specifically picked for correcting the wrongs done to X- like network transparency by the gradual introduction of side-bands and good old fashioned negligence. Part of this is that <em>all necessary and sufficient data exchange</em> used to compose a desktop goes over <em>the same</em> IPC system — one that is free of unnecessary Linuxisms to boot. While it would hurt a bit and take some effort, there are few stops for packing our bags and going someplace else, heck it used to run on Windows and still works on OSX. Rumour has it there are iOS and Android versions hidden away somewhere.</span></p>



<p><span>Contrast this with other setups where you need a large weave of IPC systems to get the same job done; Wayland for video and some input and some metadata; PulseAudio for audio; PipeWire for some video and some audio; D-Bus for some metadata and controls; D-Conf for some other metadata; Spice/RFB(VNC)/RDP for composited desktop sharing; Waypipe for partial Wayland sharing, X11 for partial X / XWayland sharing: SSH+VT***+Terminal emulator for CLI/TUI and less unsafe Waypipe / X11 transport; Synergy for mouse and keyboard and clipboard and so on. Each of these with their own take (or lack thereof) on authentication and synchronization, implementing many of the most difficult tasks again and again in incompatible ways yet still end up with features missing and exponentially more lines of code when compared to the solution here.</span></p>



<p>Back to Arcan-net. It exposes an a12 server and an a12 client, as well as acting as a shmif server, a shmif client and taking care of managing authentication keys. In that sense it behaves like any old network proxy. While not going too far into the practical details, showing off some of the setup might help.</p>



<p>On the active display server side:</p>



<pre>void@123.213.132.1# arcan-net -l 31337</pre>



<p>This will listen for incoming connections on the marked port, and map them to the currently active local connection point. <span>To dive further into the connection point concept, either read the comparison between </span><a href="https://arcan-fe.com/2018/10/17/arcan-versus-xorg-approaching-feature-parity/">Arcan vs Xorg</a><span> or simply think ‘Desktop UI address’; The WM exports named connection points and assigns different policies based on that.</span></p>



<p><span>On the client side we can have the complex-persistent option that forwards new clients as they come:</span></p>



<pre><em>arcan-net</em> -s <em>netdemo</em> <em>123.213.132.1 31337</em><br>ARCAN_CONNPATH=netdemo one_arcan_client &amp;<br>ARCAN_CONNPATH=netdemo another_arcan_client &amp;</pre>



<p>Or the one-time simpler version which forks/exec arcan-net and inherits the connection primitive needed to setup a SHMIF connection:</p>



<pre>ARCAN_CONNPATH=a12://keyid@host:port one_arcan_client</pre>



<p>Or, and this is important for understanding the demo, an api function through the WM:</p>



<pre>target_devicehint(client_vid,"a12://keyid@", true)</pre>



<p>This triggers the SHMIF implementation tied to the window of a client to disconnect from the current display server connection, connect to a remote one through arcan-net, then tell the application part of the client to rebuild essential state as the previous connection has, in a sense, ‘crashed’. The same mechanism is then used to define a fallback (‘should the connection be lost, go here instead’). This is the <em>self-healing</em> aspect of proper <em>resilience</em>.</p>



<p>There are WM APIs for all the possible network sharing scenarios so it can be handled as user interfaces without any command line work.</p>



<p>I mentioned ‘authentication’ before, where is that happening? So this is another part of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/">https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/</a></em></p>]]>
            </description>
            <link>https://arcan-fe.com/2020/10/28/a12-advancing-network-transparency-on-the-desktop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934296</guid>
            <pubDate>Thu, 29 Oct 2020 19:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Great Business: Advice You Won't Take (and Will Regret Not Taking)]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24934026">thread link</a>) | @rjyoungling
<br/>
October 29, 2020 | https://www.younglingfeynman.com/essays/advice | <a href="https://web.archive.org/web/*/https://www.younglingfeynman.com/essays/advice">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ba050bc6dcf9223f8459"><div><p>A while ago, I was talking to a founder of a startup. We were talking about his experience before and after finding product/market fit.</p><p>I asked him if he could boil down his experience into 1 piece of important advice I could share with The Younglings. He did.</p><p>But it was the way he said it, rather than what he said, that stuck with me.</p><p><em>His answer, because I don’t wanna leave you hanging, was that ‘you will overbuild and it will be a mistake’.</em></p><p>The way he said it was: ‘It is impossible to follow this advice but…’</p><p>That made me think of the advice I could give that I know is impossible to take yet true. The result of that is the essay you’re reading right now.</p><p><em>The irony that this essay is a list is not lost on me. My hatred for superficial business insider listicles has become a running joke. That said, I think this will be a worthwhile exception.</em></p><p>Let’s get right into it.</p><p>If you’re extremely ambitious, the prospect of the ‘disruptive innovation’ of an industry can seem daunting. Where do you even start?</p><p>I am not a big fan of TAM at all. VC’s (and other investors) are biased. They’ll give you self-serving advice. They want you to think big.</p><p><em>More on TAM in: </em><a href="https://www.younglingfeynman.com/essays/tam" target="_blank"><em>Should You Worry About TAM And SAM?</em></a></p><p>Why? Because they don’t care about you as an individual. You’re fungible. As long as of the 100 investments they make, a few become unicorns, that’s perfectly fine!&nbsp;</p><p>While I do think there’s a good case to be made for thinking big and solving the hardest problems on the planet, it’s actually incredibly rare for a founder to start there.</p><p>Take Elon Musk, for example. Tesla, SpaceX, The Boring Company, Neuralink, etc. All incredibly ambitious.</p><p>But his first company? A videogame when he was in his early teens. His first startup? A precursor to Google maps.&nbsp;</p><p>That’s all much more doable.</p><p>He even said in an interview that he probably wouldn’t have been able to start with SpaceX and that he advises against starting with a company that is that capital intensive.&nbsp;</p><p><em>I’ve been unable to find the source. I’ll continue to search for the video on YouTube and I’ll add it to the references if I find it.</em></p><p>In fact, I don’t know of a single founder that started their company with this huge vision. What usually happens is lying. Founders (or PR) will whitewash their history ex-post facto.</p><p>Something that <a href="https://mashable.com/article/mark-zuckerberg-lying-about-facebook/?europe=true" target="_blank">Zuckerburg was recently called out</a> for.</p><p>The Collinson brothers have often <a href="https://www.youtube.com/watch?v=9DUQ7_7Pj_c" target="_blank">pointed out that had they known Stripe would’ve been this hard, they might not have started it at all</a>.</p><p>So to come back to my question in the first paragraph, where do you even start?</p><p>With 1 person. You!&nbsp;</p><p>Think about a problem you have. Or think about something that you really want to see in the world.</p><p>Then try to see if there are other people like you.&nbsp;</p><p>Forget about scale. Forget about world domination. Forget about Fortune lists.&nbsp;</p><p>Focus on your tiny audience and just build something that improves their lives. According to them, not according to you.&nbsp;</p><p>Get to a point where they love it. Get to a point where they would be deeply sad if your solution went away.</p><p><em>More on architecting user love in: </em><a href="https://www.younglingfeynman.com/essays/deeplove" target="_blank"><em>Do You Have Customers Who Deeply Love You?</em></a></p><p><em>In case you’re suffering from a restless, intellectual brain that just can’t stop asking: ‘But how do I scale?’, the answer is: ‘Keep finding more people’. How much you make people’s lives better (on the X-axis) multiplied by a lot of people (on the Y-axis), is what’ll create a large business.</em></p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1592418092968_20301"><div><p><em>Avoid the red bar, and start with the bright blue bar. Even if your company is already creating revenue, you might not have that bright blue bar… a small set of raving fans that absolutely love your product. Then grow that bright blue bar along the Y-axis. In theory, you could also grow the red bar along the X-axis to get the same surface area. In practice that never works out.</em></p><p>There are a small number of ‘non-obvious, capital intensive startups’ (to borrow <a href="https://en.wikipedia.org/wiki/Chamath_Palihapitiya" target="_blank">Chamath</a>’s lexicon).&nbsp;</p><p>In those cases, you probably can’t be profitable from the beginning.&nbsp;</p><p><em>Unless you’re very creative and have a long time horizon. For example, one might have been able to start Tesla by starting Boosted Boards, then launching into new categories until you eventually get to cars. Dyson did a similar thing from vacuums to hand dryers to fans to blow dryers to cars. </em><a href="https://www.bbc.com/news/business-50004184" target="_blank"><em>Unfortunately, they’ve announced they’re pulling out</em></a><em>.</em></p><p>But I believe most small businesses and startups should be profitable from the beginning and scale or hover just below profitability.</p><p>It’s a mistake to solely focus on growth in hopes of one day pulling the magical profitability lever and suddenly being profitable.</p><p>Hope makes for a poor business strategy and the reason you hear about Google is that it’s so rare. More often than not it just doesn’t work out. [1]</p><p>If you do decide to put growth over profitability, you should know your numbers and be clearly able to articulate why it’s a good idea.</p><p>I’d rather see a Lambda School than a Homejoy.</p><p><em>Austen raised after being profitable (= knowing his LTV, CAC, churn etc.) in order to fund faster growth and compress the timeline. Adora raised while not knowing exactly what LTV and CAC would end up being. Although there are always many factors, the biggest one was that acquiring customers was too expensive and they had poor retention. This obviously doesn’t mean Austen is better than Adora. Adora is a legend and she added many leaves to the tree of entrepreneurial science. It just means that Adora took a more risky approach and that has a smaller chance of working out.</em></p><p>You know who obsessively focuses on the competition? People that have run out of ideas.</p><p>If you:</p><ol data-rte-list="default"><li><p>Have a clear grasp of what fucking sucks in this world.&nbsp;</p></li><li><p>A good solution for fixing it.&nbsp;</p></li><li><p>And, a group of people that love your product,</p></li></ol><p>then that’ll take up all of your time.</p><p>Obviously, the competition sucks otherwise the problem or the need wouldn't exist. They would’ve solved it. [2]</p><p>Correctly identifying a real problem, or a need that a certain audience has as well, and then building a solution that they love, is already hard enough.</p><p>Trying to simultaneously focus on what the competition is doing (or even worse, might do) is near impossible. [3]</p><p>If you're doing your job correctly, you’ll hear what the competition is up to anyway. But if that heavily affects your decision-making process, you’re doing it wrong.</p><p><em>1 important exception to this is if your company relies mainly on psychological innovation. Oatly struggled even though they had a great product. It wasn’t until </em><a href="https://thechallengerproject.com/blog/2016/oatly" target="_blank"><em>they brought in a guy with the necessary expertise in psychological innovation</em></a><em> (John Schoolcraft) that they were able to scale. He realized that they were mimicking the competition and by looking at what they were doing, he could make sure Oatly steered clear of that and develop its own voice.</em></p><p><em>More on psychological innovation in this essay series: </em><a href="https://www.younglingfeynman.com/essays/illogical" target="_blank"><em>Why Your Business Needs More Weird Ideas</em></a><em>.</em></p><p>Young companies don’t get killed by big companies. They fail to follow point 1 on this list. They make something mediocre, or they solve a problem that doesn’t exist, or they build something to address a need that no one has.</p><p>When Jack Dorsey built Twitter, he wasn’t solving a problem. He was addressing a need… his own. It’s possible that in an alternate but nearly identical universe, he is an outlier and people just aren’t that into Twitter.&nbsp;</p><p>But as it so happens, his colleagues at <a href="https://www.businessinsider.com/how-twitter-was-founded-2011-4?international=true&amp;r=US&amp;IR=T" target="_blank">Odeo</a> loved it and it started to spread.</p><p>Keep iterating your business model canvas, or pivot, until you've succeeded in making a product that makes people bang down your door to get it. [4]</p><p>To quote Andy Rachleff (created modern product/market fit theory inspired by Don Valentine):</p><blockquote><p>‘[…]if you’re really good at execution but the dogs don’t want to eat the dog food, you have no chance of winning.’</p></blockquote><p>I thought it would be nice to end this list on the advice that kicked it off.</p><p>Get your idea into the hands of users as quickly as humanly possible. Your brain is lying to you when it tells you that the first impression should be polished and amazing and that Reid Hoffman is wrong when he says:</p><blockquote><p>‘If you’re not embarrassed by the first version of your product, you’ve launched too late!’</p></blockquote><p>Remember that your brain is wrong in this case. It’s your friend, but like an overprotective mom, it doesn’t want you to get hurt. So it’ll try to trick you (successfully I might add) that you should do anything except the things that actually matter.</p><p>This is the core insight of Noah Kagan’s eminent <a href="https://www.youtube.com/watch?v=BwbtSPQ8jAY" target="_blank">Validation Theory</a>.</p><p>The reason why you shouldn’t overbuild is because you’re making a lot of assumptions, and nearly all of those assumptions are wrong.</p><p>The quicker you’re able to identify which ones are wrong the better because it’ll save resources.</p><p>Imagine spending 6 years and $500K engineering a $3500 robot that walks dogs and picks up dog poop. When you try to sell it you learn ‘ain’t nobody wanna spend $3.5K on your dog walking pooper scooper’. You could’ve avoided this by presenting a few people with your idea and ask them to prepay. When you inevitably hear: ‘yeah… uhm, that’s gonna be a hard pass for me chief!’, then you can iterate to something that would be <strong>excited</strong> to pay for.</p><p>Don’t feel bad about ignoring the advice on this list. While everything is true, your brain will find some excuse and you will buy into it. We all do, myself included.</p><p>This seems to be like parents warning you about a bad girl/boy when you’re a teenager. You just need to experience it before it sinks in.</p><p>Then why did I write this essay?</p><p>Because part of me hopes there are a few competitive people that’ll be like: ‘Don’t tell me what I can’t do!’</p><p>And for the rest of the people reading this, when you make these mistakes, I hope you’re able to recognize that you’re making them sooner and are able to course-correct faster.</p><p><em>[1] Again, be mindful of who gives you this advice. VC’s most likely. For them, it’s a win/win situation. If they give you an A round and push you to grow hard, your paper valuation will increase, they can use that to raise more capital. That means they’ll make more money because of their management fee.&nbsp;</em></p><p><em>T…</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.younglingfeynman.com/essays/advice">https://www.younglingfeynman.com/essays/advice</a></em></p>]]>
            </description>
            <link>https://www.younglingfeynman.com/essays/advice</link>
            <guid isPermaLink="false">hacker-news-small-sites-24934026</guid>
            <pubDate>Thu, 29 Oct 2020 18:47:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mall real estate company collected 5M images of shoppers]]>
            </title>
            <description>
<![CDATA[
Score 259 | Comments 173 (<a href="https://news.ycombinator.com/item?id=24933583">thread link</a>) | @voisin
<br/>
October 29, 2020 | https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images — and used facial recognition technology without customers' knowledge or consent —&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5499879.1584406507!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/covid-19-pandemic-stores-closed.JPG"></p></div><figcaption>Cadillac Fairview, the real estate company behind some of Canada's most popular shopping centres, embedded cameras inside its digital information kiosks at 12 shopping malls across Canada, according to a new investigation.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>The real estate company behind some of Canada's most popular shopping centres embedded cameras inside its digital information kiosks at 12 shopping malls in major Canadian cities&nbsp;to collect millions of images — and used facial recognition technology without customers' knowledge or consent —&nbsp;according to a new investigation by the federal, Alberta and B.C. privacy commissioners.</p>  <p>"Shoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis," said federal Privacy Commissioner Daniel Therrien&nbsp;in a statement.</p>  <p>"The lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity."</p>  <p>According to the report, the technology&nbsp;Cadillac Fairview used&nbsp;— known as "anonymous video analytics" or AVA— took temporary digital images of the faces of individuals within the field of view of the camera in the directory.</p>  <p><strong><em>WATCH: Shoppers' privacy violated at major Canadian malls: Privacy commissioners:</em></strong></p>  <p><span><span><div><div role="button" tabindex="0" title="Shoppers’ privacy violated at major Canadian malls: Privacy commissioners"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/949/527/mall-privacy-daigle-291020.jpg" alt=""></p></div></div></div><span>Cadillac Fairview, the real estate company behind some of Canada’s biggest malls, violated the privacy of shoppers by collecting five million images without consent from cameras inside digital information kiosks, an investigation by federal, British Columbia and Alberta privacy commissioners found.<!-- --> <!-- -->2:01</span></span></span></p>  <p>It then used facial recognition software to convert those images into biometric numerical representations of&nbsp;individual faces, about five million images&nbsp;in total.</p>  <p>That sensitive personal information could be used to identify individuals based on their unique facial features, said&nbsp;the commissioners.</p>    <p>The report said the company also kept about 16 hours of video recordings, including some audio, which it had captured during a testing phase at two malls.</p>  <p>Cadillac Fairview said it&nbsp;used AVA technology&nbsp;to assess foot traffic and track shoppers' ages and genders&nbsp;— but not to identify individuals.&nbsp;</p>  <p>The company also argued shoppers were made aware of the activity through decals it placed on shopping mall entry doors that warned cameras were being used for "safety and security" and included the web address for Cadillac Fairview's&nbsp;privacy policy.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/chinook-centre-directory.jpg 300w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/chinook-centre-directory.jpg 460w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/chinook-centre-directory.jpg 620w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg 780w,https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/chinook-centre-directory.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4762407.1533648115!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/chinook-centre-directory.jpg"></p></div><figcaption>This directory in Chinook Centre mall in south Calgary uses facial recognition technology.<!-- --> <!-- -->(Sarah Rieger/CBC)</figcaption></figure></span></p>  <p>But the commissioners said that&nbsp;wasn't good enough and did not meet the standard for meaningful consent.&nbsp;</p>  <p>"An individual would not, while using a mall directory, reasonably expect their image to be captured and used to create a biometric representation of their face, which is sensitive personal information, or for that biometric information to be used to guess their approximate age and gender," they wrote.</p>  <p>The privacy watchdogs also took issue with the way the&nbsp;five&nbsp;million images were stored.</p>  <p>Cadillac Fairview&nbsp;said the&nbsp;images taken by camera were briefly analyzed then deleted&nbsp;—&nbsp;but investigators found that the sensitive biometric information generated from the images was being stored in a centralized database by&nbsp;a third-party company,</p>  <p>"Our investigation revealed that&nbsp;[Cadillac Fairview Corporation Limited's]&nbsp;AVA&nbsp;service provider had collected and stored approximately five million numerical representations of faces on&nbsp;CFCL's behalf, on a decommissioned server, for no apparent purpose and with no justification," notes the investigation.</p>  <p>"Cadillac Fairview stated that it was unaware that the database of biometric information existed, which compounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors."</p>  <h2>Company&nbsp;says technology couldn't identify people</h2>  <p>The company said the technology was used&nbsp;to detect the presence of a human face and&nbsp;assign it&nbsp;"within milliseconds"&nbsp;to an approximate age and gender category and maintains it&nbsp;did not store any images during the pilot program and was not capable of recognizing anyone.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/eaton-centre-decal.jpg 300w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/eaton-centre-decal.jpg 460w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/eaton-centre-decal.jpg 620w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg 780w,https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/eaton-centre-decal.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5782324.1604000638!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/eaton-centre-decal.jpg"></p></div><figcaption>The decal found on the entrance doors of the CF Toronto Eaton Centre<!-- --> <!-- -->(Office of the Privacy Commissioner report)</figcaption></figure></span></p>  <p>"The five million representations referenced in the [Office of the Privacy Commissioner]&nbsp;report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera's view," Cadillac Fairview spokesperson Jess Savage&nbsp;said in a statement to CBC News.</p>  <p>"The&nbsp;OPC report concludes there is no evidence that CF was using any technology for the purpose of identifying individuals."</p>  <p>CF&nbsp;suspended its&nbsp;use of cameras&nbsp;back in 2018&nbsp;when provincial and federal privacy commissioners launched their probe&nbsp;<a href="https://www.cbc.ca/news/canada/calgary/calgary-malls-1.4760964">following a CBC investigation</a>.</p>  <p>In a statement to CBC News on Thursday, the company said it has deleted the data.</p>  <p>"We subsequently deactivated directory cameras and the numerical representations and associated data have since been deleted," said&nbsp;Savage.</p>  <p>"We take the concerns of our visitors seriously and wanted to ensure they were acknowledged and addressed."</p>  <p>However, the three commissioners said they have concerns about the company's plans going forward.</p>    <p>"The commissioners remain concerned that Cadillac Fairview refused their request that it commit to ensuring express, meaningful consent is obtained from shoppers should it choose to redeploy the technology in the future," said&nbsp;the commissioners'&nbsp;statement.</p>  <h2>No fines under Canadian law</h2>  <p>Savage said Cadillac Fairview&nbsp;accepted and implemented all the recommendations&nbsp;"with the exception of those that speculate about hypothetical future uses of similar technology."</p>  <p>The investigation found the technology was used&nbsp;in five provinces&nbsp;at the following malls:</p>  <ul>   <li>CF Market Mall (Calgary)</li>   <li>CF Chinook Centre (Calgary)</li>   <li>CF Richmond Centre (Richmond, B.C.)</li>   <li>CF Pacific Centre (Vancouver)</li>   <li>CF Polo Park (Winnipeg)</li>   <li>CF Toronto Eaton Centre (Toronto)</li>   <li>CF Sherway Gardens (Toronto)</li>   <li>CF Fairview Mall (Toronto)</li>   <li>CF Lime Ridge (Hamilton, Ont.)</li>   <li>CF Markville Mall (Markham, Ont.)</li>   <li>CF Galeries d'Anjou&nbsp;(Montreal)</li>   <li>CF Carrefour Laval (Laval, Que.)</li>  </ul>  <p>Ann Cavoukian,&nbsp;executive director at the Global Privacy and Security by Design Centre,&nbsp;said a case like this would lead to millions of dollars in fines if it had happened&nbsp;in the United States.</p>  <p>"The commissioners are doing the best they can with the limited resources they have," she said.</p>  <p>"What we have to insist upon is that private&nbsp;sector entities like Cadillac Fairview step up and protect their customers' privacy. Otherwise, why are the customers going to continue shopping there?"</p>  <p>B.C. Information and Privacy Commissioner&nbsp;Michael McEvoy&nbsp;said&nbsp;the fact he and his counterparts can't issue a fine in a&nbsp;case like this should make the case for stronger powers at both the federal and provincial levels.</p>  <p>"Fines in a case like this would have been a consideration. It is an incredible shortcoming of Canadian law," he said.</p>  <p>"We as privacy regulators don't have any authority to levy fines on companies that violate peoples'&nbsp;personal information and that should really change."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/cadillac-fairview-5-million-images-1.5781735?cmp=rss</link>
            <guid isPermaLink="false">hacker-news-small-sites-24933583</guid>
            <pubDate>Thu, 29 Oct 2020 18:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Fexprs and Defmacro]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24932701">thread link</a>) | @sea6ear
<br/>
October 29, 2020 | https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt | <a href="https://web.archive.org/web/*/https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.brinckerhoff.org/scraps/joe-marshall-on-FEXPRS-and-DEFMACRO.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932701</guid>
            <pubDate>Thu, 29 Oct 2020 17:09:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open-source, fully customizable voice and chat widgets for the web]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24932588">thread link</a>) | @JanKoenig
<br/>
October 29, 2020 | https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2 | <a href="https://web.archive.org/web/*/https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/jovo-for-web.jpg"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/jovo-for-web.jpg" alt="Jovo for Web Open Source Voice and Chat" title="Introducing Jovo for Web: Customizable Voice and Chat for the Browser"></a></p><p>With the release <code>v3.2</code> of the <a href="https://github.com/jovotech/jovo-framework">Jovo Framework</a>, we're excited to present a completely revamped web integration.</p><p><em>Jovo for Web</em> allows you to build fully customizable voice and chat apps that work in the browser. And it even comes with 4 open source templates (gifs below!) that help you get started.</p><ul>
<li><a href="#jovo-for-web-features">Jovo for Web Features</a></li>
<li><a href="#select-from-4-starter-templates">Select from 4 Starter Templates</a>
<ul>
<li><a href="#standalone-voice-experience">Standalone Voice Experience</a></li>
<li><a href="#voice-overlay">Voice Overlay</a></li>
<li><a href="#chat-widget">Chat Widget</a></li>
<li><a href="#embedded-chat">Embedded Chat</a></li>
</ul></li>
<li><a href="#more-new-features">More New Features</a></li>
<li><a href="#how-to-update">How to Update</a>
<ul>
<li><a href="#breaking-changes">Breaking Changes</a></li>
</ul></li>
<li><a href="#a-big-thank-you">A Big Thank You</a></li>
</ul><p><em>Like what we're doing? <a href="https://opencollective.com/jovo-framework">Support us on Open Collective!</a></em> </p><h2 id="jovo-for-web-features"><a href="#jovo-for-web-features">Jovo for Web Features</a></h2><p>Let's build voice and chat apps for the browser!</p><p>In our <a href="https://www.context-first.com/introducing-jovo-v3-the-voice-layer/">v3 announcement</a>, we already mentioned that Jovo works with web apps and websites thanks to the <a href="https://www.context-first.com/introduction-voice-multimodal-interactions/">RIDR Lifecycle</a> and <a href="https://www.jovo.tech/news/www.jovo.tech/marketplace">Jovo Marketplace</a>.</p><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/jovo-web-ridr-lifecycle.jpg"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/jovo-web-ridr-lifecycle.jpg" alt="Jovo for Web RIDR Lifecycle" title="Integrate ASR and NLU into Web Apps with Jovo and RIDR"></a></p><p>Today, we're thrilled to announce a completely improved verson of our <strong>Jovo for Web</strong> platform.</p><p>Features include:</p><ul>
<li>Support for speech, text, and touch input</li>
<li>Multimodal: Complex visual and audio output possible</li>
<li>Open source and fully customizable</li>
<li><a href="#select-from-4-starter-templates">4 starter templates</a> built with modern technologies like Vue.js and Tailwind CSS</li>
</ul><p>We can't wait to see and hear what you build with this!</p><h2 id="select-from-4-starter-templates"><a href="#select-from-4-starter-templates">Select from 4 Starter Templates</a></h2><p>To help you get started quickly, we built 4 templates with Vue.js and Tailwind CSS that implement use cases for both voice and chat.</p><h3 id="standalone-voice-experience"><a href="#standalone-voice-experience">Standalone Voice Experience</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-standalone">github.com/jovotech/jovo-starter-web-standalone</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-standalone.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-standalone.gif" alt="Jovo Starter: Standalone Voice Experience" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter brings your voice experiences into the browser as a standalone web app. This can be seen as an experience equivalent to a smart display. Many Alexa Skills and Google Actions like voice games can be brought to the web using this template.</p><p>The starter includes:</p><ul>
<li>a push-to-talk button</li>
<li>a display of the transcribed speech above the button</li>
<li>app output at the top of the screen</li>
<li>conversational logic that switches to dark/light mode using custom web actons</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-standalone">Check out the demo here!</a> Hold the button and say "<em>switch to dark mode.</em>"</p><h3 id="voice-overlay"><a href="#voice-overlay">Voice Overlay</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-overlay">github.com/jovotech/jovo-starter-web-overlay</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-overlay.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-overlay.gif" alt="Jovo Starter: Voice Overlay" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a speech input button as an overlay to an existing website or web app. Voice interactions like search, customizations, and deep access of features could be added using the overlay.</p><p>The starter includes:</p><ul>
<li>a push-to-talk button</li>
<li>a display of the transcribed speech left to the button</li>
<li>conversational logic that switches to dark/light mode using custom web actons</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-overlay">Check out the demo here!</a> Hold the button and say "<em>switch to dark mode.</em>"</p><h3 id="chat-widget"><a href="#chat-widget">Chat Widget</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-chatwidget">github.com/jovotech/jovo-starter-web-chatwidget</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-chatwidget.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-chatwidget.gif" alt="Jovo Starter: Open Source Chat Widget" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a classic chat widget to your website. Think chatbots and conversational experiences for customer support and more.</p><p>The starter includes:</p><ul>
<li>a bottom-right toggle button</li>
<li>text input and quick replies</li>
<li>conversational logic that asks the user to open the Jovo Docs (redirect not working on iOS due to platform limitations)</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-chatwidget">Check out the demo here!</a></p><h3 id="embedded-chat"><a href="#embedded-chat">Embedded Chat</a></h3><blockquote>
<p>Find this starter on GitHub: <a href="https://github.com/jovotech/jovo-starter-web-embeddedchat">github.com/jovotech/jovo-starter-web-embbeddedchat</a></p>
</blockquote><p><a href="#" data-featherlight="/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-embeddedchat.gif"><img src="https://www.jovo.tech/img/news/2020-10-29-jovo-for-web-v3-2/starter-web-embeddedchat.gif" alt="Jovo Starter: Open Source Embedded Chat" title="Introducing Jovo for Web: Customizable Voice and Chat in the Browser"></a></p><p>This starter adds a customizable chat interface to your website that can be used for things like conversational landing pages, FAQs, mobile chat support, and much more.</p><p>The starter includes:</p><ul>
<li>fullsize chat component that can be embedded into an existing website</li>
<li>text input and quick replies</li>
<li>conversational logic that asks the user to open the Jovo Docs (redirect not working on iOS due to platform limitations)</li>
</ul><p><a href="https://www.jovo.tech/demos/starter-web-embeddedchat">Check out the demo here!</a></p><h2 id="more-new-features"><a href="#more-new-features">More New Features</a></h2><p>Alongside the big launch of Jovo for Web, we also shipped some other improvements and bug fixes with the help of our community. <a href="https://github.com/jovotech/jovo-framework/blob/master/CHANGELOG.md">You can find the full changelog here</a>.</p><ul>
<li>We released Google Conversational Actions. <a href="https://www.jovo.tech/news/2020-10-08-google-conversational-actions-builder">Find the announcement here</a>.</li>
<li>New analytics integration: <a href="https://www.jovo.tech/marketplace/jovo-analytics-onedash">OneDash</a>. <em>Thanks to <a href="https://github.com/StepanU">StepanU</a>!</em></li>
<li><a href="https://github.com/jovotech/jovo-framework/pull/838">Dialogflow Genesys integration</a>. <em>Thanks to <a href="https://github.com/dominik-meissner">Dominik Meissner</a>!</em></li>
</ul><h2 id="how-to-update"><a href="#how-to-update">How to Update</a></h2><blockquote>
<p><a href="https://www.jovo.tech/docs/installation/upgrading">Learn more in the Jovo Upgrading Guide</a>.</p>
</blockquote><p>To update to the latest version of Jovo, use the following commands:</p><h3 id="breaking-changes"><a href="#breaking-changes">Breaking Changes</a></h3><p>The "Jovo Web Client" and "Jovo Web Platform" were completely refactored for this release.</p><h2 id="a-big-thank-you"><a href="#a-big-thank-you">A Big Thank You</a></h2><p>Thanks a lot to all the contributors of this release. Everyone of the Jovo core team worked together to make this happen! Special thanks to Max who started working on the web integration more than a year ago as part of his bachelor's thesis.</p><p>Community and core contributors:</p><ul>
<li><a href="https://github.com/StepanU">StepanU</a></li>
<li><a href="https://github.com/dominik-meissner">Dominik Meissner</a></li>
<li><a href="https://github.com/rubenaeg">Ruben Aegerter</a></li>
<li><a href="https://github.com/KaanKC">Kaan Kilic</a></li>
<li><a href="https://github.com/m-ripper">Max Ripper</a></li>
<li><a href="https://github.com/aswetlow">Alex Swetlow</a></li>
</ul><p>And to everyone else who helped with ideas and feature requests in the <a href="https://www.jovo.tech/slack">Jovo Slack</a> and <a href="https://community.jovo.tech/">Jovo Community Forum</a>!</p>
</article></div>]]>
            </description>
            <link>https://www.jovo.tech/news/2020-10-29-jovo-for-web-v3-2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932588</guid>
            <pubDate>Thu, 29 Oct 2020 16:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5M Canadian shoppers' images collected at mall kiosks]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24932467">thread link</a>) | @anonymousab
<br/>
October 29, 2020 | https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>OTTAWA -- 
	Without customers’ knowledge, more than five million images of Canadian shoppers were collected through facial recognition software used by Cadillac Fairview, a parent company of malls across the country, <a href="https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2020/pipeda-2020-004/" target="_blank">according to an investigation by privacy officials.</a></p>
<p>
	The federal privacy commissioner reported Thursday that Cadillac Fairview contravened federal and provincial privacy laws by embedding cameras inside digital information kiosks at 12 shopping malls across Canada, and captured users’ images without their consent.</p>
<p>
	The facial recognition software installed in Cadillac Fairview’s “wayfinding” directories was called “Anonymous Video Analytics (AVA) and through cameras installed behind protective glass, was used in Canadian malls for a brief testing period in 2017 and then was in-use between May and July of 2018.</p>
<p>
	The software took temporary digital images of the faces of any individual within the field of view of the camera inside the directory and converted the images into biometric numerical representations of each face and used that information to compile demographic information about mall visitors.</p>
<p>
	According to the report, the technology was used in directories at the following locations:</p>
<ul>
	<li>
		CF Market Mall in Alberta</li>
	<li>
		CF Chinook Centre in Alberta</li>
	<li>
		CF Richmond Centre in British Columbia</li>
	<li>
		CF Pacific Centre in British Columbia</li>
	<li>
		CF Polo Park in Manitoba</li>
	<li>
		CF Toronto Eaton Centre in Ontario</li>
	<li>
		CF Sherway Gardens in Ontario</li>
	<li>
		CF Lime Ridge in Ontario</li>
	<li>
		CF Fairview Mall in Ontario</li>
	<li>
		CF Markville Mall in Ontario</li>
	<li>
		CF Galeries d’Anjou in Quebec</li>
	<li>
		CF Carrefour Laval in Quebec</li>
</ul>
<p>
	According to a statement from Privacy Commissioner of Canada Daniel Therrien, the company said the goal of its cameras was to “analyze the age and gender of shoppers and not to identify individuals.”</p>
<p>
	The corporation said that it did not collect personal information because the images were briefly looked at and then deleted, however the information generated from the images was being stored by a third-party contractor called Mappedin, which Cadillac Fairview said it was unaware of.</p>
<p>
	“When asked the purpose for such collection, Mappedin was unable to provide a response, indicating that the person responsible for programming the code no longer worked for the company,” reads the report.</p>
<p>
	Therrien notes in his report that Cadillac Fairview not being aware of Mappedin’s storage of the information “compounded the risk of potential use by unauthorized parties or, in the case of a data breach, by malicious actors.”</p>
<p>
	In an interview on CTV’s Power Play, Deputy Commissioner Brent Homan called it a “massive invasion of privacy” and not one that shoppers would have expected while at the mall. Homan said that one of the lessons Canadians should take away from this report is that facial recognition software is available for companies to use, and while they encourage entities to ask for consent before deploying it on the public, that’s not always the case.&nbsp;</p>
<p>
	Cadillac Fairview—one of the largest owners and operators of retail and other properties in North America—“expressly disagreed” with the investigation’s findings, telling the commissioners that there were decals placed on shopping mall entry doors noting their privacy policy.</p>
<p>
	These stickers directed visitors to visit guest services to obtain a copy of the company’s privacy policy, but when the investigators asked a guest services employee at the Eaton location in Toronto, the employee was “confused by the request” and so Therrien found the stickers to be an “insufficient” measure.</p>
<p>
	“Shoppers had no reason to expect their image was being collected by an inconspicuous camera, or that it would be used, with facial recognition technology, for analysis,” said Therrien in a statement. “The lack of meaningful consent was particularly concerning given the sensitivity of biometric data, which is a unique and permanent characteristic of our body and a key to our identity.”</p>
<p>
	The investigation was launched in 2018, following several media reports about information kiosks in malls being equipped with unmarked cameras to monitor visitor demographics. Their examination in this case included visiting Cadillac Fairview’s Toronto headquarters to interview key personnel, viewing the AVA technology inside the wayfinding directories in action, and extracting records from the directories for forensic analysis.</p>
<p>
	The existence of the software came to light after a user posted an image to Reddit of a display screen at the CF Chinook Centre in Calgary showing coding language including “FaceEncoder” and “FaceAnalyzer.”</p>
<p>
	Commissioner Therrien’s office worked with Alberta Information and Privacy Commissioner Jill Clayton as well as the Information and Privacy Commissioner of British Columbia Michael McEvoy on the investigation.</p>
<p>
	“Not only must organizations be clear and up front when customers’ personal information is being collected, they must also have proper controls in place to know what their service providers are doing behind the scenes with that information,” Clayton said in a statement.</p>
<p>
	The trio of commissioners have expressed concern that the company hasn’t accepted their request to commit to ensuring meaningful and express consent is obtained from shoppers in the future should it choose to redeploy similar technology in the future.</p>
<p>
	In a statement provided to CTV News, Cadillac Fairview notes that the issue has been resolved, the data deleted, and the cameras have been deactivated. As well, the facial recognition software is no longer in use, but the company says it will not commit to its approach to “hypothetical future uses of similar technology.”</p>
<p>
	“The five million representations referenced in the OPC report are not faces. These are sequences of numbers the software uses to anonymously categorize the age range and gender of shoppers in the camera’s view,” the company said. “We thank the Privacy Commissioner for the report and recommendations on how to further strengthen our privacy practices and agree that the privacy of our visitors must always be a top priority.”&nbsp;</p>
                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/canada/5-million-canadian-shoppers-images-collected-at-mall-kiosks-privacy-commissioner-1.5166162</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932467</guid>
            <pubDate>Thu, 29 Oct 2020 16:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large inequality in international energy footprints between income groups]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24932205">thread link</a>) | @tonyedgecombe
<br/>
October 29, 2020 | https://sci-hub.tf/10.1038/s41560-020-0579-8 | <a href="https://web.archive.org/web/*/https://sci-hub.tf/10.1038/s41560-020-0579-8">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sci-hub.tf/10.1038/s41560-020-0579-8</link>
            <guid isPermaLink="false">hacker-news-small-sites-24932205</guid>
            <pubDate>Thu, 29 Oct 2020 16:25:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Semgrep and r2c]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24931985">thread link</a>) | @pabloest
<br/>
October 29, 2020 | https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>Free, fast, <a href="https://github.com/returntocorp/semgrep" target="_blank" rel="noopener">open-source</a>, offline, customizable. These are not often words that describe code scanning tools, and that's a shame.</p>
<p>We founded r2c to bring world-class security tools to developers based on our conviction that software will run the most exciting parts of the future: everything from medical equipment to robots to autonomous cars. The security process should not be the foe but rather the enabler of rapid software development. If developers lack tooling that is easy to set up and understand—or if a developer has to convince their manager to spend a few million dollars on advanced security tools each time they change jobs, the future is bleak.</p>
<p>Before founding r2c, we worked on security and developer tools for large companies and governments. It was eye-opening to see that despite massive budgets, their security programs were generally a generation or more behind the tech giants. When it came to security tools for developers, most teams were jaded about scanning code for vulnerabilities; they hated the tools they had to use and usually ignored them beyond doing the minimum necessary to satisfy a compliance checkbox.</p>
<p>What about code scanning at places like Facebook, Apple, Amazon, Netflix, and Google? They don't generally use traditional commercial security tools which ask "how can we find every bug?" Instead, they focus on custom tooling that can build guardrails for developers. This doesn't require million-dollar tools, PhDs in program analysis, or days of compute time. It looks much more like unit tests for security.</p>
<p>We believe there is a gap between traditional compliance tools and simple linters that's ripe for a new approach, and we were fortunate to find partners from Redpoint Ventures and Sequoia Capital who agreed. With them, we raised a $13M Series A round of funding to build a security tool that developers might actually love. We've been working on it quietly for a while now, and we're finally ready to announce it to the world!</p>
<h2>Semgrep</h2>
<p><a href="https://semgrep.dev/" target="_blank" rel="noopener">Semgrep</a>, our open-source product, is specifically designed for eradicating bug classes.
Developers and security engineers can say "this is the safe pattern we always use for (e.g. parsing XML)", write a rule in a few minutes, and enforce that on every editor save, commit, and pull request.</p>
<p>Semgrep is ideal for building security guardrails: start by using frameworks designed with security in mind, then automatically flag code that strays from the <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">secure-by-default path</a>. This is an approach used by <a href="https://landing.google.com/sre/resources/foundationsandprinciples/srs-book/" target="_blank" rel="noopener">Google</a>, <a href="https://about.fb.com/news/2019/01/designing-security-for-billions/" target="_blank" rel="noopener">Facebook</a>, <a href="https://homes.cs.washington.edu/~mernst/pubs/continuous-compliance-ase2020.pdf" target="_blank" rel="noopener">Amazon</a>, Dropbox, Stripe, <a href="https://medium.com/@NetflixTechBlog/scaling-appsec-at-netflix-6a13d7ab6043" target="_blank" rel="noopener">Netflix</a>, and others—a topic <a href="https://events.bizzabo.com/OWASPGlobalAppSec/agenda/session/315858" target="_blank" rel="noopener">Clint Gibler and I presented on at Global AppSec 2020</a>. This approach increases developer productivity, reduces attack surface, minimizes the areas for human inspection and audit, and allows the security team to scalably protect code written by thousands of developers.</p>
<p>The idea behind Semgrep is simple: it feels like a regular search (grep) but is syntax-aware. You can <a href="https://semgrep.dev/learn" target="_blank" rel="noopener">learn Semgrep</a> in a few minutes! And Semgrep can be used for <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">more than just security</a> issues: performance, internationalization, or just annoyances <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns" target="_blank" rel="noopener">committed by accident</a>.</p>
<p><span>
      <a href="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Semgrep pattern example" title="Semgrep pattern example" src="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png" srcset="https://r2c.dev/static/730ca8541e43ed871d2edb7c02226b0c/bde6a/semgrep-foo-small.png 283w" sizes="(max-width: 283px) 100vw, 283px" loading="lazy">
  </a>
    </span></p>
<p><code>$ semgrep -e foo(1)</code> matches all equivalent variations. <a href="https://semgrep.dev/s/ievans:python-exec" target="_blank" rel="noopener">See a live example of matching <em>exec</em> calls</a></p>
<h2>What's Next?</h2>
<p>Semgrep started as an open-source project at Facebook and we're lucky to have its original author, Yoann Padioleau, on our team at r2c. Since we released the first post-Facebook version (0.4) earlier this year, we've released 25 new versions, added support for 8 new languages, reworked the parsers so we could collaborate with Github on <a href="https://tree-sitter.github.io/" target="_blank" rel="noopener">tree-sitter</a>, been joined by thousands of enthusiastic GitHub followers, and seen over 100K pulls of the Semgrep Docker image.</p>
<p>Our roadmap contains more program analysis features to support the sorts of secure-by-default enforcement that large technology companies are already leveraging so heavily (constant propagation, taint tracking, and more), as well as support for many more languages.</p>
<h2>Batteries Included</h2>
<p>Along with this release of Semgrep, we're announcing the availability of <a href="https://semgrep.dev/" target="_blank" rel="noopener">Semgrep Community</a>, a free, hosted service for managing Semgrep CI as well as Semgrep Teams, a paid service which adds additional features for managing Semgrep that are useful for enterprises. Both these offerrings provide SaaS infrastructure for operating a modern AppSec program. They enable central definition of code standards for your projects and show results where you already work: GitHub, GitLab, Slack, Jira, VS Code, and more.</p>
<p>We're also excited that <a href="https://semgrep.dev/explore" target="_blank" rel="noopener">Semgrep Registry</a> already has 900+ rules written by r2c and the community—you can start running on your project right now! Or if you like to DIY, <a href="https://semgrep.dev/editor" target="_blank" rel="noopener">try writing your own</a>.</p></div></div></div></section></div>]]>
            </description>
            <link>https://r2c.dev/blog/2020/introducing-semgrep-and-r2c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931985</guid>
            <pubDate>Thu, 29 Oct 2020 16:07:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizations as a Company of One]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24931633">thread link</a>) | @jnfr
<br/>
October 29, 2020 | https://lunchbag.ca/company-of-one/ | <a href="https://web.archive.org/web/*/https://lunchbag.ca/company-of-one/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2020-05-18 16:00:00 +0000 UTC">May 18, 2020</time>
			</span>
		</p>
		

<p>Hello! 👋 My name is Jen and I’m the founder, engineer, designer and customer support at <a href="https://lunchmoney.app/">Lunch Money</a>, a personal finance and budgeting web app.</p>

<p>In short, I am a company of one. I answer the customer support emails and I code and deploy new features. I also manage the <a href="https://developers.lunchmoney.app/" target="_blank">API docs</a> and <a href="https://support.lunchmoney.app/" target="_blank">knowledge base</a>, poke around the logs when there are issues, write the <a href="https://lunchmoney.app/sample_newsletter" target="_blank">bi-monthly newsletters</a> and I designed the logo!</p>

<p>As the company scales, so too must all aspects of my work which I break down into 4 parts: customer support, engineering, product and marketing.</p>

<p><strong>Finding opportunities for process optimization is honestly one of the more fun parts of running a business</strong>. I greatly attribute these to how I’ve been able to stay both solo &amp; sane up until now, currently with 600+ users and $45,000 ARR. In this post, I’m excited to share some of my most successful strategies along with anecdotes from my experience working on Lunch Money.</p>



<p>In the last 14 days, here’s what I got done across all departments:</p>

<ul>
<li><strong>Product:</strong> Launched an internal beta testers program and two sets of new features to test</li>
<li><strong>Engineering:</strong> Wrapped up a 2-week long refactor of some core components on the client-side</li>
<li><strong>Engineering:</strong> Launched a major feature: advanced transaction filters</li>
<li><strong>Engineering:</strong> Closed 13 tickets related to feature improvements and bug fixes</li>
<li><strong>Marketing:</strong> Sent out a newsletter outlining the latest new features</li>
<li><strong>Marketing:</strong> This blog post</li>
<li><strong>Marketing:</strong> Added new pages to the marketing site (<a href="https://lunchmoney.app/features/rules">Rules</a> and <a href="https://lunchmoney.app/features/collaboration">Collaboration</a>) and updated the icons in <a href="https://lunchmoney.app/features">Features</a></li>
<li><strong>Support:</strong> Received 239 inbound support tickets and sent out 358 emails</li>
</ul>

<p>What makes all this work bearable for me is the fact that there is so much variety (which, of course, is the spice of life!). I love being able to switch between tasks to keep the job interesting and my mind refreshed while still being productive overall.</p>

<p><em>Case in point: I just finished a major refactor and pushed out 2 major features to beta, so writing this blog post right now feels like a vacation for my brain.</em></p>

<p>To state the obvious, I enjoy being hyper-efficient (without burning myself out, of course). Even though I am a single person, I can still automate, optimize and parallelize processes.</p>



<h2 id="implement-safeguards">Implement safeguards</h2>

<p><i>Ah, the blissful beginnings of Lunch Money when I’d push code directly to production several times a day.</i></p>

<p>At 500+ users now, those days are long gone and I’ve since needed to adopt the more boring but responsible approach of implementing safeguards to prevent shipping faulty code.</p>

<p>For one, <b>I’ve been thoroughly reviewing my own code before every change</b>. Every major feature, improvement and bug fix lives in a feature branch that I still, by habit from the corporate days, prepend with <code>jen/</code>. After verifying everything works great locally, I make sure to take a break first, whether that’s working on a completely unrelated task, going for a meal or going to bed. The point of this is to ensure that I’m code reviewing with a clear head.</p>

<p>While adhering to these standards of code reviewing myself may add extra time to my overall process, it potentially saves hours of bug-fixing, answering related support tickets and self-loathing (I’m half-kidding here) down the line if I accidentally ship bad code.</p>

<center><blockquote><p lang="en" dir="ltr">New phase of Lunch Money– no more pushing major features straight to production 🤯😂 <a href="https://t.co/RYsz7BnU3L">https://t.co/RYsz7BnU3L</a></p>— Jen (@lunchbag) <a href="https://twitter.com/lunchbag/status/1256987437600927744?ref_src=twsrc%5Etfw">May 3, 2020</a></blockquote> </center>

<p><b>I also recently implemented an internal beta-testing program open to Lunch Money subscribers.</b> With more users accessing my app on a regular basis, the stakes are higher to ship a version that’s as bug-free as possible.</p>

<p>As an engineering team of one, it’s nearly impossible to always get it right the first time, despite having tests (what if I missed an edge case?) or testing locally extensively (how I think my users will use a feature is not always so).</p>

<p>The beta-testing program has provided some additional benefits. It’s nice to have a cohort of users with whom I can have a more candid conversation about Lunch Money and it’s also a great way to show users that their feedback is valued!</p>

<h2 id="automate-later-than-you-need-to">Automate later than you need to</h2>

<p>While automating tasks can save a lot of time in the long-term, it doesn’t always make sense to automate right off the bat.</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png"><span>Obligatory XKCD comic (<a href="https://xkcd.com/1205/" target="_blank">link</a>)</span></p>

<p>Automating too late is not a bad thing. I’ll have done the manual work enough times to understand how to eventually automate the task and what edge cases to look out for. I equate it to doing a job yourself before hiring someone– it’s always better to grok the requirements first to some degree so you can understand how to best utilize who you’ve brought on (and appreciate them more!).</p>

<p>I manually triggered the emails for bi-monthly account summaries for months because I wasn’t confident the sending cadence was reasonable. After observing open rates and collecting user feedback, these are now automated to go out on the 5th &amp; 25th of every month.</p>

<p>Something that I’m glad I didn’t spend the time to automate at all was the referral program. If an existing user refers a new user and the new user subscribes to a plan, then both users will receive credit for 1 month.</p>

<p>In the end, the referral program only brought on 11 extra users. It was not a pain at all to manually process rewards for those who did. If I had spent time conjuring up all the edge cases and automating this process, it would not have been worth the time investment.</p>

<h2 id="keep-low-hanging-fruits-in-the-back-pocket">Keep low-hanging fruits in the back pocket</h2>

<p>In my task management system, I use a tag (🍏) to denote which tasks are low-hanging fruits. For the uninitiated, low-hanging fruits are quick tasks that are easy to knock out, such as one-liners or 5-minute fixes.</p>

<p><img src="https://media.giphy.com/media/YP1Jb0JNc7kqFDbdjm/giphy.gif"></p>

<p>I find that keeping these around and tackling them on days when you feel generally unmotivated can really help raise spirits. Still being able to get something completed and shipped is a great way to get out of a slump.</p>



<h2 id="timing-marketing-pushes">Timing marketing pushes</h2>

<p>At Lunch Money, a big part of the business is using the services of Plaid for bank syncing. Plaid charges on a monthly basis which means that if a user signs up on April 30, connects a bank account immediately and doesn’t end up subscribing at the end of their 14-day trial, they will charge me for this user in both April &amp; May’s invoices.</p>

<p>This realization coupled with my intense aversion to paying more than I need to has shaped a lot of practices at Lunch Money.</p>

<p>For one, the data retention policy used to be 30 days which means if your trial ends and you didn’t put in your billing information, your data will be deleted in 30 days. This certainly guarantees that I’ll be overpaying for churned users and is the reason why the data retention policy has since been revised to 5 days.</p>

<p>In total, a user who does not end up subscribing can spend up to 26 days in the Lunch Money system. This comprises of a 14-day trial, the potential for a 1 week trial extension and a 5 day grace period. Assuming enough users connect their bank accounts, the best way to minimize my costs for churned users is to ensure their lifetimes are within one calendar month.</p>

<p><img src="https://lunchbag.ca/uploads/calendar-1.png"></p>

<p>As a result, I always schedule marketing pushes such as blog posts and product launches in the first few days of the month. When I came to this realization, my next Plaid bill went down for the first time.</p>

<h2 id="merging-marketing-and-engineering-for-a-combo-win">Merging marketing and engineering for a combo win</h2>

<p>Taking this a step further, the perk of having a spike in new users is that their trial periods more-or-less overlap. Usually when a new user signs up, they will poke around the product and maybe send in a bug report, a feature request or another piece of feedback. If I reply and address their feedback by putting in a fix or shipping their requested feature within days, more often than not, they end up converting into a happy customer.</p>

<p>I’ve therefore identified the following cycle to maximize potential conversions from spikes in user signups:</p>

<p><img src="https://lunchbag.ca/uploads/gantt-2.png"></p>

<p>After a marketing push, let’s say a product launch, I will see an immediate increase in signups lasting about 3 days and then slowly trailing off.</p>

<p>Over the next few days, I’ll start hearing from these new users via support tickets. I prioritize responding to them and I get to work. Showing these users that I’m committed to improving Lunch Money based on their feedback is a great and honest sales tactic.</p>

<p>About 3 days before the initial wave of user trials ends, I wrap up my engineering sprint and send out a newsletter detailing the latest features and improvements. This re-enforces to new users that the product is under continuous development.</p>

<p>Finally, I have a drip campaign that automatically notifies users a few days before their trial expires and on the actual date of expiry. This period of time is when I typically see most users convert 🤞.</p>



<p>I used to think that if I were to hire someone, it would first be a customer support agent but I’ve since been moving away from that idea. Users are constantly surprised (in a good way!) when they realize the founder is responding to their bug reports or feature requests directly.</p>

<p><strong>Consistently providing great customer support is a long-term investment for Lunch Money</strong> as it is undoubtedly a great way to turn customers into champions. As I receive and respond to support tickets, I’m also able to identify and overhaul the common sources of trouble for users.</p>

<p>I’ve always believed that customer support would be the most important and the hardest part of the business to scale, especially if I have the goal of staying a company of one.</p>

<p>Corroborating data from <a href="https://emailmeter.com/">EmailMeter</a> and my database, it seems my changes are making a difference. Despite a growing user base, inbound support emails remain fairly steady!</p>

<p><img src="https://lunchbag.ca/uploads/screen-shot-2020-05-21-at-4-20-15-pm.png"><span>Handling support on my own should be sustainable at least for the foreseeable future!</span></p>

<h2 id="how-do-support-tickets-work-at-lunch-money">How do support tickets work at Lunch Money?</h2>

<p>A feedback button is located at the bottom right corner of every page. Clicking on it opens up a text area wherein users can submit feature requests, questions, bug …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunchbag.ca/company-of-one/">https://lunchbag.ca/company-of-one/</a></em></p>]]>
            </description>
            <link>https://lunchbag.ca/company-of-one/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931633</guid>
            <pubDate>Thu, 29 Oct 2020 15:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Labelled procedure calls]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24931577">thread link</a>) | @tekknolagi
<br/>
October 29, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-11/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><span data-nosnippet="">
<em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-10/">previous</a></em>
</span></p>

<p>Welcome back to the Compiling a Lisp series. Last time, we learned about Intel
instruction encoding. This time, we’re going to use that knowledge to compile
procedure calls.</p>

<p>The usual function expression in Lisp is a <code>lambda</code> — an anonymous function
that can take arguments and close over variables. Procedure calls are <em>not</em>
this. They are simpler constructs that just take arguments and return values.</p>

<p>We’re adding procedure calls first as a stepping stone to full closure support.
This will help us get some kind of internal calling convention established and
stack manipulation figured out before things get too complicated.</p>

<p>After this post, we will be able to support programs like the following:</p>

<div><div><pre><code><span>(</span><span>labels</span> <span>((</span><span>add</span> <span>(</span><span>code</span> <span>(</span><span>x</span> <span>y</span><span>)</span> <span>(</span><span>+</span> <span>x</span> <span>y</span><span>)))</span>
         <span>(</span><span>sub</span> <span>(</span><span>code</span> <span>(</span><span>x</span> <span>y</span><span>)</span> <span>(</span><span>-</span> <span>x</span> <span>y</span><span>))))</span>
    <span>(</span><span>labelcall</span> <span>sub</span> <span>4</span> <span>(</span><span>labelcall</span> <span>add</span> <span>1</span> <span>2</span><span>)))</span>
<span>; =&gt; 1</span>
</code></pre></div></div>

<p>and even this snazzy factorial function:</p>

<div><div><pre><code><span>(</span><span>labels</span> <span>((</span><span>factorial</span> <span>(</span><span>code</span> <span>(</span><span>x</span><span>)</span> 
            <span>(</span><span>if</span> <span>(</span><span>&lt;</span> <span>x</span> <span>2</span><span>)</span> <span>1</span> <span>(</span><span>*</span> <span>x</span> <span>(</span><span>labelcall</span> <span>factorial</span> <span>(</span><span>-</span> <span>x</span> <span>1</span><span>)))))))</span>
    <span>(</span><span>labelcall</span> <span>factorial</span> <span>5</span><span>))</span>
<span>; =&gt; 120</span>
</code></pre></div></div>

<p>These are fairly pedestrian snippets of code but they demonstrate some new
features we are adding, like:</p>

<ul>
  <li>A new <code>labels</code> form that all programs will now have to look like</li>
  <li>A new <code>code</code> form for describing procedures and their parameters</li>
  <li>A new <code>labelcall</code> expression for calling procedures</li>
</ul>

<p>Ghuloum does not explain why he does this, but I imagine that the <code>labels</code> form
was chosen over allowing multiple separate top-level bindings because it is
easier to parse and traverse.</p>

<h3 id="big-ideas">Big ideas</h3>

<p>In order to compile a program, we are going to traverse every binding in the
<code>labels</code>. For each binding, we will generate code for each <code>code</code> object.</p>

<p>Compiling <code>code</code> objects requires making an environment for their parameters.
We’ll establish a calling convention later so that our compiler knows where to
find the parameters.</p>

<p>Then, once we’ve emitted all the code for the bindings, we will compile the
body. The body may, but is not required to, contain a <code>labelcall</code> expression.</p>

<p>In order to compile a <code>labelcall</code> expression, we will compile all of the
arguments provided, save them in consecutive locations on the stack, and then
emit a <code>call</code> instruction.</p>

<p>When all of these pieces come together, the resulting machine code will look
something like this:</p>

<div><div><pre><code>mov rsi, rdi  # prologue
label0:
  label0_code
label1:
  label1_code
main:
  main_code
</code></pre></div></div>

<p>You can see that all of the <code>code</code> objects will be compiled in sequence,
followed by the body of the <code>labels</code> form.</p>

<s>
Because I have not yet figured out how to start executing at somewhere other
than the beginning of the generated code, and because I don't store generated
code in any intermediate buffers, and because we don't know the sizes of any
code in advance, I do this funky thing where I emit a `jmp` to the body code.

If you, dear reader, have a better solution, please let me know.
</s>

<p><strong>Edit:</strong> <em>jsmith45</em> gave me the encouragement I needed to work on this again.
It turns out that storing the code offset of the beginning of the <code>main_code</code>
(the <code>labels</code> body) adding that to the <code>buf-&gt;address</code> works just fine. I’ll
explain more below.</p>

<h3 id="a-calling-convention">A calling convention</h3>

<p>We’re not going to use the System V AMD64 ABI. That calling convention requires
that parameters are passed first in certain registers, and then on the stack.
Instead, we will pass all parameters on the stack.</p>

<p>This makes our code simpler, but it also means that at some point later on, we
will have to add a different kind of calling convention so that we can call
foreign functions (like <code>printf</code>, or <code>exit</code>, or something). Those functions
expect their parameters in registers. We’ll worry about that later.</p>

<p>If we borrow and adapt the excellent diagrams from the Ghuloum tutorial, this
means that right before we make a procedure call, our stack will look like
this:</p>

<blockquote>
  <p>Stack illustration courtesy of <a href="https://leonardschuetz.ch/">Leonard</a>.</p>
</blockquote>

<p>You can see the first return point at <code>[rsp]</code>. This is the return point placed
by the caller of the <em>current</em> function.</p>

<p>Above that are whatever local variables we have declared with <code>let</code> or perhaps
are intermediate values from some computation.</p>

<p>Above that is a blank space reserved for the second return point. This is the
return point for the <em>about-to-be-called</em> function. The <code>call</code> instruction will
fill in after evaluating all the arguments.</p>

<p>Above the return point are all the outgoing arguments. They will appear as
locals for the procedure being called.</p>

<p>Finally, above the arguments, is untouched free stack space.</p>

<p>The <code>call</code> instruction decrements <code>rsp</code> and then writes to <code>[rsp]</code>. This means
that if we just emitted a <code>call</code>, the first local would be overwritten. No
good. Worse, the way the stack would be laid out would mean that the locals
would look like arguments.</p>

<p>In order to solve this problem, we need to first adjust <code>rsp</code> to point to the
last local. That way the decrement will move it below the local and the return
address will go between the locals and the arguments.</p>

<p>After the <code>call</code> instruction, the stack will look different. Nothing will have
actually changed, except for <code>rsp</code>. This change to <code>rsp</code> means that the callee
has a different view:</p>

<blockquote>
  <p>Stack illustration courtesy of <a href="https://leonardschuetz.ch/">Leonard</a>.</p>
</blockquote>

<p>The empty colored in spaces below the return point indicate that the values on
the stack are “hidden” from view, since they are above (higher addresses than)
<code>[rsp]</code>. The called function will <em>not</em> be able to access those values.</p>

<p>If the called function wants to use one of its arguments, it can pull it off
the stack from its designated location.</p>

<blockquote>
  <p>One unfortunate consequence of this calling convention is that Valgrind does
not understand it. Valgrind cannot understand that the caller has placed data
on the stack specifically for the callee to read it, and thinks this is a
move/jump of an uninitialized value. This means that we get some errors now
on these labelcall tests.</p>
</blockquote>

<p>Eventually, when the function returns, the <code>ret</code> instruction will pop the
return point off the stack and jump to it. This will bring us back to the
previous call frame.</p>

<p>That’s that! I have yet to find a good tool that will let me visualize the
stack as a program is executing. GDB probably has a mode hidden away somewhere
undocumented that does exactly this. Cutter sort of does, but it’s finicky in
ways I don’t really understand. Maybe one day <a href="http://akkartik.name/">Kartik</a>’s
x86-64 Mu fork will be able to do this.</p>

<h3 id="building-procedure-calls-in-small-pieces">Building procedure calls in small pieces</h3>

<p>In order for this set of changes to make sense, I am going to explain all of
the pieces one at a time, top-down.</p>

<p>First, we’ll look at the new-and-improved <code>Compile_entry</code>, which has been
updated to handle the <code>labels</code> form. This will do the usual Lisp entrypoint
setup and some checks about the structure of the AST.</p>

<p>Then, we’ll actually look at compiling the <code>labels</code>. This means going through
the bindings one-by-one and compiling their <code>code</code> objects.</p>

<p>Then, we’ll look at what it means to compile a <code>code</code> object. Hint: it’s very
much like <code>let</code>.</p>

<p>Last, we’ll tie it all together when compiling the body of the <code>labels</code> form.</p>

<h3 id="compiling-the-entrypoint">Compiling the entrypoint</h3>

<p>Most of this code is checking. What used to just compile an expression now
validates that what we’ve passed in at least vaguely looks like a well-formed
<code>labels</code> form before picking it into its component parts: the <code>bindings</code> and
the <code>body</code>.</p>

<div><div><pre><code><span>int</span> <span>Compile_entry</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>node</span><span>)</span> <span>&amp;&amp;</span> <span>"program must have labels"</span><span>);</span>
  <span>// Assume it's (labels ...)</span>
  <span>ASTNode</span> <span>*</span><span>labels_sym</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>node</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>labels_sym</span><span>)</span> <span>&amp;&amp;</span> <span>"program must have labels"</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_symbol_matches</span><span>(</span><span>labels_sym</span><span>,</span> <span>"labels"</span><span>)</span> <span>&amp;&amp;</span>
         <span>"program must have labels"</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>args</span> <span>=</span> <span>AST_pair_cdr</span><span>(</span><span>node</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>bindings</span> <span>=</span> <span>operand1</span><span>(</span><span>args</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>)</span> <span>||</span> <span>AST_is_nil</span><span>(</span><span>bindings</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>body</span> <span>=</span> <span>operand2</span><span>(</span><span>args</span><span>);</span>
  <span>return</span> <span>Compile_labels</span><span>(</span><span>buf</span><span>,</span> <span>bindings</span><span>,</span> <span>body</span><span>,</span> <span>/*labels=*/</span><span>NULL</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p><code>Compile_entry</code> dispatches to <code>Compile_labels</code> for iterating over all of the
labels. <code>Compile_labels</code> is a recursive function that keeps track of all the
labels so far in its arguments, so we start it off with an empty <code>labels</code>
environment.</p>

<h3 id="compiling-labels">Compiling labels</h3>

<p>In <code>Compile_labels</code>, we have first a base case: if there are no labels we
should just emit the body.</p>

<div><div><pre><code><span>int</span> <span>Compile_labels</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                   <span>Env</span> <span>*</span><span>labels</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>buf</span><span>-&gt;</span><span>entrypoint</span> <span>=</span> <span>Buffer_len</span><span>(</span><span>buf</span><span>);</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kEntryPrologue</span><span>,</span> <span>sizeof</span> <span>kEntryPrologue</span><span>);</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>/*stack_index=*/</span><span>-</span><span>kWordSize</span><span>,</span> <span>/*varenv=*/</span><span>NULL</span><span>,</span>
                   <span>labels</span><span>));</span>
    <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kFunctionEpilogue</span><span>,</span> <span>sizeof</span> <span>kFunctionEpilogue</span><span>);</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>We also set the buffer entrypoint location to the position where we’re going to
emit the body of the <code>labels</code>. We’ll use this later when executing, or later in
the series when we emit ELF binaries. You’ll have to add a field <code>word
entrypoint</code> to your <code>Buffer</code> struct.</p>

<p>We pass in an empty <code>varenv</code>, since we are not accumulating any locals along
the way; only labels. For the same reason, we give a <code>stack_index</code> of
<code>-kWordSize</code> — the first slot.</p>

<p>If we <em>do</em> have labels, on the other hand, we should deal with the first label.
This means:</p>

<ul>
  <li>pulling out the name and the code object</li>
  <li>binding the name to the <code>code</code> location (the current location)</li>
  <li>compiling the <code>code</code></li>
</ul>

<p>And then from there we deal with the others recursively.</p>

<div><div><pre><code><span>int</span> <span>Compile_labels</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                   <span>Env</span> <span>*</span><span>labels</span><span>)</span> <span>{</span>
  <span>// ....</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_code</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>word</span> <span>function_location</span> <span>=</span> <span>Buffer_len</span><span>(</span><span>buf</span><span>);</span>
  <span>// Bind the name to the location in the instruction stream</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>function_location</span><span>,</span> <span>labels</span><span>);</span>
  <span>// Compile the binding function</span>
  <span>_</span><span>(</span><span>Compile_code</span><span>(</span><span>buf</span><span>,</span> <span>binding_code</span><span>,</span> <span>&amp;</span><span>entry</span><span>));</span>
  <span>return</span> <span>Compile_labels</span><span>(</span><span>buf</span><span>,</span> <span>AST_pair_cdr</span><span>(</span><span>binding…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-11/">https://bernsteinbear.com/blog/compiling-a-lisp-11/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24931577</guid>
            <pubDate>Thu, 29 Oct 2020 15:31:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I built a dashboard template and sold it for $90k]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24930252">thread link</a>) | @pixelcave
<br/>
October 29, 2020 | https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd | <a href="https://web.archive.org/web/*/https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
                        <p>I bought my first PC back in 1998 and started experimenting with web design a few years later. It was amazing how easily you could create web pages with rich content and navigate between them just like in interactive desktop apps. Let’s not talk about all those texture backgrounds along with animated gifs that no one could resist using. It was a playground and I loved it.</p>

<p>Microsoft Frontpage and Macromedia Dreamweaver (which was later acquired by Adobe) were the first tools I used to design and code websites just for the fun of it. At first, it was a more ‘what you see is what you get’ (WYSIWYG) approach but soon, I started playing more directly with HTML and CSS through Dreamweaver’s code editor.</p>

<p>A passion was born with various fun web projects being built on the side. I loved that aspect and while I was studying for my bachelor’s degree in Informatics, I got involved with all the web projects I could find. Those included web development and helped me improve my skills in those areas as well.</p>

<p>The idea that I might be able to work online from my home quickly became an obsession back then. In 2009, demand for web applications was rising, so I started experimenting with dashboard templates and eventually, 3 projects were created and released in the next 3 years.</p>

<p>I built them in my free time while I was working with a tech company on a few web apps and studying for my master’s degree at the same time. They did just ok but a whole new world was opened in front of me.</p>

<p>Unfortunately, due to the various responsibilities I had at the time, I kept postponing any further action but I eventually did a dynamic comeback in 2013 when I was ready to put all my energy into designing and coding dashboard templates full-time.</p>

<h3>Passionate with UI design</h3>

<p>You’ve heard before that you need to love your work if you would like to be successful but that’s only half the story. Loving what you do can motivate you, inspire you and make things a bit easier but that’s not necessarily enough in the long run.</p>

<p>I was and I am extremely passionate with UI design and coding. Back then, I used Photoshop to design each project and afterwards, I did my best to code it into HTML/CSS and make sure it works great in each major desktop and mobile browser. I used to spend so many hours testing and making sure that the result would be as perfect as possible based on my skills.</p>

<p>In 2013, I was able to build and release 3 more projects which were built with love and care. That’s also when the mottos “Crafted with love” and “Happy coding” came to life and follow pixelcave since then. The templates did good but unfortunately it was nothing sustainable.</p>

<p>I loved what I was doing and felt really good designing and coding but that on its own wasn’t enough. I needed to start thinking differently because if the whole plan didn’t work out, pixelcave most probably wouldn’t exist today.</p>

<h3>What people need</h3>

<p>I knew that I needed to deliver value to the people using those projects and save them time, so I had to do a far better job researching their needs before even start creating the next project, <a href="https://pixelcave.com/products/proui">ProUI</a>. It might seem obvious now but wasn’t the case back then.</p>

<p>I went through all the feedback (emails and comments) I had received from the first 3 projects and kept putting together a list of all the things people liked, struggled with, or wish they had. A few things on the list kept coming back, so I knew that those were crucial, and I had to prioritize them.</p>

<p>Next up, I researched public feedback regarding similar projects and got a feeling of what didn’t work and the problems most of the people were having when using such products. There were many issues that also kept coming back, so I’ve already had a good list of features and solutions that I had to work on ProUI.</p>

<p>What kept me researching for a while was the feeling that creating another project in the same way, would give me the same mediocre results. You can’t expect to have a different outcome when doing the same things repeatedly. I’m glad I’ve followed that path before getting my hands dirty and start coding the new template.</p>

<h3>Deliver under pressure</h3>

<p>This project was everything back then because its success or failure would completely change my life. If it didn’t work, it was the end of my working from home career and I had to completely change my approach and start looking for alternatives. There was no money or time to waste and for my mind, it was a matter of survival, I wanted it to succeed so much.</p>

<p>That was the perfect timing and the pressure helped me take it very seriously. I tried to be positive and passionate about the result and kept working day and night towards making a great product. It’s funny how pressure can help or harm your work. I have experienced both outcomes in the past but thankfully it was one of the things that pushed me forward, helped me overcome my fears and boosted my creativity. ProUI was live and the pressure had delivered. Sales started coming in, a new world appeared in front of my eyes and I knew that nothing was going to be the same again.</p>

<h3>Be original</h3>

<p>ProUI was designed and coded from scratch by hand. In contrary to the way other products were created by only using readymade layouts, navigation elements and other major building blocks, ProUI foundation was based on a solid structure built exclusively for it. I think that’s what gave it an identity in the first place and helped it in the long run.</p>

<p>I did my best to implement many popular features, provide solutions to issues people were experiencing, make a template that is straightforward, easy to use and most importantly that works as advertised. When inspiration hit, personal design touches were applied to make the design original and give it the feeling of a fresh experience.</p>

<h3>Test everything like crazy</h3>

<p>Testing was one of the main features of ProUI and continue being for all current projects. It might be simpler now with most popular browsers being chromium-based but that wasn’t the case back in the days. Internet Explorer 8 was the baseline and the newly introduced popularity of mobile browsers with their own set of issues wasn’t making things any better.</p>

<p>Responsive design was in its glory days and started becoming mainstream back in 2013 but testing tools weren’t on par yet. I still remembered resizing the browser like 1000 times each day to ensure that all content would appear as supposed to from mobile screens up to desktop monitors.</p>

<p>Testing on devices was also a big issue because I only had access to 2 older smartphones. New devices kept releasing at the time with various browsers popping up, so my solution was to visit stores for testing on their promo devices! I uploaded versions of the work-in-progress template to the demo server and tested it against various devices, from Macbooks to iPhones, iPads, and latest Android devices.</p>

<p>One of the main issues people were experiencing at the time was the poor mobile performance, so I was determined to make ProUI as fast and responsive as possible. During my visits, I kept notes and tried to fix the bugs when I got back home on the fly hoping that they will work. Of course, that wasn’t always the case, so visiting the stores became part of my weekly work schedule! I switched stores occasionally, so it doesn’t get too awkward...</p>

<p>Thankfully, the effort fulfilled its purpose and ProUI was released in a good stable state. I kept visiting the stores for a few months though (before I was able to get my hands on my own testing devices) to handle any reported bugs. My goal was to always reply in less than 24hrs during business days to support requests (something that I still do), so there were days of me rushing through stores to handle the situation. I tried to keep it cool with my responses despite the store situation (how professional is to test against demo devices in a store?) but in the end, I want to believe that the effort and care I gave, really paid off and helped ProUI be as bug free as possible.</p>

<h3>Balance time and delivery</h3>

<p>I learned that you must keep a balance between the features you want to implement in your project and the time it takes you to do it. It’s far better to integrate less and put your project out there sooner than trying to make it as complete as possible.</p>

<p>While building ProUI, bills kept coming in, which in the end I think helped me because I had to put it out there as quickly as possible. That might not made it the perfect release I might had in my mind but in the end, ProUI provided value and helped people in their projects.</p>

<h3>Not knowing stuff</h3>

<p>This is important and seems to apply in everything I do. As you learn more about your product’s market or about the tech you are using, it gets harder and harder to put something out there. You analyze everything way too much and easily spot the things that might go, or you do wrong.</p>

<p>There was this guy, who started selling WordPress plugins without knowing much about the market but focused on creating great products. After managing to reach 1 million in sales, he stated that if he knew the things he discovered afterwards, he would probably have never started selling WordPress plugins in the first place because it would be too difficult for him.</p>

<p>It was early days, and this is how I felt when I was building ProUI. It was liberating not analyzing what works and what doesn’t and focus on the product itself. Since then, I try to keep a balance between the things I discover and the things I want to experiment with when working on something. It’s exactly like the designer who redesigns his website and before he even finishes, he already finds the new design awful. Don’t be like that, try to fight back!</p>

<h3>Being perfect is subjective</h3>

<p>I would describe myself as perfectionist, but I try not to. Thankfully, the characterization does not apply, most of the time. When you are aiming for perfection, the only one you satisfy is yourself. You set the bar of perfection based on the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd">https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd</a></em></p>]]>
            </description>
            <link>https://pixelcave.com/blog/how-i-built-a-dashboard-template-and-sold-it-for-90000-usd</link>
            <guid isPermaLink="false">hacker-news-small-sites-24930252</guid>
            <pubDate>Thu, 29 Oct 2020 13:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Page Load Time Comparison of Raspberry Pi 3 and 4 Web Servers]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24929444">thread link</a>) | @sT370ma2
<br/>
October 29, 2020 | https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/raspberry-pi-3-4-web-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929444</guid>
            <pubDate>Thu, 29 Oct 2020 11:43:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Complex Applications, Rust Is as Productive as Kotlin]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24929335">thread link</a>) | @todsacerdoti
<br/>
October 29, 2020 | https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>In this article, we will compare one apple (IntelliJ Rust) to one orange (rust-analyzer) to reach general and sweeping conclusions.
Specifically, I want to present a case study supporting the following claim:</p>
<p>For complex applications, Rust is as productive as Kotlin.</p>
<p>For me, this is an unusual claim to argue: I always thought exactly the opposite, but I am not so sure now.
I came to Rust from C++.
I was of the opinion that this is a brilliant low-level language and always felt puzzled at people writing higher-level things in Rust.
Clearly, choosing Rust means taking a productivity hit, and using Kotlin, C# or Go just makes much more sense if you can afford GC.
My <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">list of Rust criticisms</a> starts with this objection.</p>
<p>What moved my position in the other direction was my experience as the lead developer of rust-analyzer and IntelliJ Rust.
Let me introduce the two projects.</p>
<p><a href="https://github.com/intellij-rust/intellij-rust"><strong>IntelliJ Rust</strong></a> is the plugin for IntelliJ Platform, providing Rust support.
In effect, it is a Rust compiler front-end, written in Kotlin and making use of language-support features of the platform.
These features include lossless syntax trees, a parser generator, persistence and indexing infrastructure, among others.
Nonetheless, as programming languages differ lot, the bulk of logic for analyzing Rust is implemented in the plugin itself.
Presentational features like completion list come from the platform, but most of the language semantics is hand-written.
IntelliJ Rust also includes a bit of a Swing GUI.</p>
<p><a href="https://github.com/rust-analyzer/rust-analyzer"><strong>rust-analyzer</strong></a> is an implementation of
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> for Rust.
It is a Rust compiler front-end written from scratch with an eye towards IDE support.
It makes heavy use of <a href="https://github.com/salsa-rs/salsa">salsa</a> library for incremental computations.
Beyond the compiler itself, rust-analyzer includes code for managing long-lived multithreaded process of the language server itself.</p>
<p>The projects are essentially equivalent in scope — rust compiler front-ends suitable for IDEs.
The two biggest differences are:</p>
<div>
<ul>
<li>
<p>IntelliJ Rust is a plugin, so it can re-use code and design patterns of the surrounding platform.</p>
</li>
<li>
<p>rust-analyzer is the second system, so it leverages experience of IntelliJ Rust for a from-scratch design.</p>
</li>
</ul>
</div>
<p>The internal architecture of the two projects also differs a lot.
In terms of <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">Three Architectures</a>, IntelliJ Rust is map-reduce, and rust-analyzer is query-based.</p>
<p>Writing an IDE-ready compiler is a high-level task.
You don’t need to talk to the operating system directly.
There are some fancy data structures and concurrency here and there, but they are also high-level.
It’s not about implementing crazy lock-free schemes, it’s about maintaining application state and sanity in the multithreaded world.
The bulk of the compiler is symbolic manipulation, arguably best suited for lisp.
Picking a VM-based language for such task (for example, OCaml), doesn’t have any intrinsic downsides.</p>
<p>At the same time, the task is pretty complex and unique.
The ratio of “your code” vs “framework code” when implementing features is much higher than in a typical CRUD backend.</p>
<p>Now that the projects are introduced, lets take two roughly equivalent slices of history.</p>

<p>Both are about 2 years old, with 1-1.5 developers working full time and vibrant and thriving community of open-source contributors.
There are 52k lines of Kotlin and 66k lines of Rust.</p>
<p>Both delivered roughly equivalent feature sets at that time.
To be honest, I still don’t really believe this :)
rust-analyzer started from zero, it didn’t have a decade worth of Java classes to bootstrap from, and the productivity drop between Kotlin and Rust is supposed to be huge.
But it’s hard to argue with reality.
Instead, let me try to reflect on my experience building both, and to try to explain Rust’s surprising productivity.</p>
</div>
</div>
<div>
<h2 id="_learning_curve">Learning Curve</h2>
<div>
<p>It’s easy to characterize Kotlin’s learning curve — it is nearly zero.
I’ve started IntelliJ Rust without Kotlin experience and never felt that I need to specifically learn Kotlin.</p>
<p>When I switched to rust-analyzer, I was pretty experienced with Rust.
I would say that one definitely needs to deliberately learn Rust, it’s hard to pick it up on the go.
Ownership and aliasing control are novel concepts (even if you come from C++), and taking holistic approach to learning them pays off.
After the initial learning step the ride is generally smooth.</p>
<p>By the way, this is the perfect place to plug our Rust courses and tailor-made <a href="https://ferrous-systems.com/training/">trainings</a> :-)
The next <a href="https://ferrous-systems.com/training/#package-intro-training">introduction to Rust</a> is happening this December!</p>
</div>
</div>
<div>
<h2 id="_modularity">Modularity</h2>
<div>
<p>This I think is the biggest factor.
Both projects are moderately large in terms of scope as well as in terms of amount of source code.
I believe that the only way to ship big things is to split them in independent-ish chunks and implement the chunks separately.</p>
<p>I also find most of the languages I am familiar with to be pretty horrible with respect to modularity.
More generally, I am amused with FP vs OO debate, as it seems that “why no one does modules right?” is a more salient issue.</p>
<p>Rust is one of the few languages which has first-class concept of libraries.
Rust code is organized on two levels:</p>
<div>
<ul>
<li>
<p>as a tree of inter-dependent modules inside a crate</p>
</li>
<li>
<p>and as a directed acyclic graph of crates</p>
</li>
</ul>
</div>
<p>Cyclic dependencies are allowed between the modules, but not between the crates.
Crates are units of reuse and privacy: only crate’s public API matters, and it is crystal clear what crate’s public API is.
Moreover, crates are anonymous, so you don’t get name conflicts and dependency hell when mixing several versions of the same crate in a single crate graph.</p>
<p>This makes it very easy to make two pieces of code <strong>not</strong> depend on each other (non-dependencies are the essence of modularity): just put them in separate crates.
During code review, only changes to Cargo.tomls need to be monitored carefully.</p>
<p>At the time of comparison, rust-analyzer is split into 23 internal crates, with a handful general-purposed ones released on crates.io.
In contrast, IntelliJ Rust is a single Kotlin module, where everything can depend on everything else.
Although internal organization of IntelliJ Rust is pretty clean, it’s not reflected in the file system layout and build system, and needs constant maintenance.</p>
</div>
</div>
<div>
<h2 id="_build_system">Build System</h2>
<div>
<p>Managing project’s build takes significant amount of times, and has multiplicative effect on everything else.</p>
<p>Rust’s build system, <a href="https://doc.rust-lang.org/cargo/index.html">Cargo</a>, is very good.
It’s not perfect, but it is a breath of fresh air after Java’s <a href="https://gradle.org/">Gradle</a>.</p>
<p>Cargo’s trick is that it doesn’t try to be a general purpose build system.
It can only build Rust projects, and it has rigid expectation about the project structure.
It’s impossible to opt out of the core assumptions.
Configuration is a static non-extensible TOML file.</p>
<p>In contrast, Gradle allows free-form project structure, and is configured via a Turing complete language.
I feel like I’ve spend more time learning Gradle than learning Rust!
Running <code>wc -w</code> gives 182_817 words for Rust book, and 280_506 for Gradle’s user guide.</p>
<p>Additionally, Cargo is just faster than Gradle in most cases.</p>
<p>Of course, the biggest downside is that custom build logic is not expressible in Cargo.
Both projects needs substantial amount of logic beyond mere compilation to deliver the final result to the user.
For rust-analyzer, this is handled by hand-written Rust script, which works perfectly at this scale.</p>
</div>
</div>
<div>
<h2 id="_ecosystem">Ecosystem</h2>
<div>
<p>Language-level support for libraries and top-notch build system/package manager allow for a thriving ecosystem.
rust-analyzer relies on third-party libraries much more than IntelliJ Rust.
Some parts of rust-analyzer are also published to crates.io for other projects to reuse.</p>
<p>Additionally, low-level nature of the Rust programming language often allows for “perfect” library interfaces.
Interfaces which exactly reflect the underlying problem, without imposing intermediate language-level abstractions.</p>
</div>
</div>
<div>
<h2 id="_basic_conveniences">Basic Conveniences</h2>
<div>
<p>I feel that Rust is significantly more productive when it comes to basic language nuts and bolts — structs, enums, functions, etc.
This is not specific to Rust — any ML-family language has them.
However, Rust is the first industrial language which wraps these features in a nice package, not constrained by backwards compatibility.
I want to list specific features which I think allow producing maintainable code faster in Rust</p>
<p><em>Emphasis on data over behavior</em>.
Aka, Rust is not an OOP language.
The core idea of OOP is that of dynamic dispatch — which code is invoked by a function call is decided at runtime (late binding).
This is a powerful pattern which allows for flexible and extensible system.
The problem is, extensibility is costly!
It’s better only to apply it in certain designated areas.
Designing for extensibility by default is not cost effective.
Rust puts static dispatch front and center: it is mostly clear whats going on by just reading the code, as it is independent of runtime types of the objects.</p>
<p>One small syntactic thing I enjoy about Rust is how it puts fields and methods into different blocks syntactically:</p>
<div>
<div>
<pre><code data-lang="rust"><span>struct</span> <span>Person</span> <span>{</span>
  <span>first_name</span><span>:</span> <span>String</span><span>,</span>
  <span>last_name</span><span>:</span> <span>String</span><span>,</span>
<span>}</span>

<span>impl</span> <span>Person</span> <span>{</span>
    <span>fn</span> <span>full_name</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span>...</span>
    <span>}</span>
<span>}</span></code></pre>
</div>
</div>
<p>Being able to see at a glance all the fields makes understanding the code much simpler.
Fields convey much more information than methods.</p>
<p><em>Sum types</em>.
Rust’s humbly named enums are full algebraic data types.
This means that you can express the idea of disjoint union:</p>
<div>
<div>
<pre><code data-lang="rust"><span>enum</span> <span>Either</span><span>&lt;</span><span>A</span><span>,</span> <span>B</span><span>&gt;</span> <span>{</span> <span>A</span><span>(</span><span>A</span><span>),</span> <span>B</span><span>(</span><span>B</span><span>)</span> <span>}</span></code></pre>
</div>
</div>
<p>This is hugely useful in day-to-day programming in the small, and some times during programming in the large as well.
To give one example, one of the core concepts for an IDE are references and definitions.
A definition a like <code>let foo = 92;</code> assigns a name to an entity which can be used down a line.
A reference like <code>foo + 90</code> <em>refers</em> to some definition.
When you ctrl-click on reference, you go to the definition.</p>
<p>Natural way to model that in Kotlin is by adding <code>interface Definition</code> and <code>interface Reference</code>.
The problem is, some things are …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/">https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</a></em></p>]]>
            </description>
            <link>https://ferrous-systems.com/blog/rust-as-productive-as-kotlin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24929335</guid>
            <pubDate>Thu, 29 Oct 2020 11:27:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[  You will need a subscription license to access Qt 6 (non-LGPL)]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24928720">thread link</a>) | @deng
<br/>
October 29, 2020 | https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription | <a href="https://web.archive.org/web/*/https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span><span>Yes. If your </span><span>Qt licenses are perpetual, you may continue to use the product in perpetuity after your maintenance expires.&nbsp; Access to product and technical support will only be available via the purchase of an Extended Maintenance Contract for software releases that are end-of-life. If you opt not to renew, please note that Qt will not guarantee to support software versions acquired with a perpetual license.</span></span></p>
<p><span><span>Please note, you will need a subscription license to access Qt 6.</span></span></p>
<!--more-->
<p><span><span>Qt versions can be viewed <a href="https://wiki.qt.io/QtReleasing" rel="noopener">here</a>.</span></span></p>
</span></p></div>]]>
            </description>
            <link>https://www.qt.io/faq/what-happens-to-my-perpetual-licenses-once-i-convert-to-subscription</link>
            <guid isPermaLink="false">hacker-news-small-sites-24928720</guid>
            <pubDate>Thu, 29 Oct 2020 09:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Image Scaling Attacks]]>
            </title>
            <description>
<![CDATA[
Score 427 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24927655">thread link</a>) | @wendythehacker
<br/>
October 28, 2020 | https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This post is part of a series about machine learning and artificial intelligence. Click on the blog tag “huskyai” to see related posts.</p>
<ul>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-walkthrough/">Overview</a>: How Husky AI was built, threat modeled and operationalized</li>
<li><a href="https://embracethered.com/blog/posts/2020/husky-ai-threat-modeling-machine-learning/">Attacks</a>: Some of the attacks I want to investigate, learn about, and try out</li>
</ul>
<p>A few weeks ago while preparing demos for my GrayHat 2020 - Red Team Village presentation I ran across “Image Scaling Attacks” in <a href="https://www.usenix.org/system/files/sec20-quiring.pdf">Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning</a> by Erwin Quiring, et al.</p>
<p>I thought that was so cool!</p>
<h2 id="what-is-an-image-scaling-attack">What is an image scaling attack?</h2>
<p>The basic idea is to hide a smaller image inside a larger image (it should be about 5-10x the size). The attack is easy to explain actually:</p>
<ol>
<li>Attacker crafts a malicious input image by hiding the desired target image inside a benign image</li>
<li>The image is loaded by the server</li>
<li>Pre-processing resizes the image</li>
<li>The server acts and makes decision based on a different image then intended</li>
</ol>
<p>My goal was to hide a husky image inside another image:</p>
<p><a href="https://embracethered.com/blog/images/2020/image-rescale-attack.gif"><img src="https://embracethered.com/blog/images/2020/image-rescale-attack.gif" alt="Image Rescaling Attack"></a></p>
<p>Here are the two images I used - before and after the modification:
<a href="https://embracethered.com/blog/images/2020/image-rescaling-attack-schoenbrunn.png"><img src="https://embracethered.com/blog/images/2020/image-rescaling-attack-schoenbrunn.png" alt="Image Rescaling Attack"></a></p>
<p>If you look closely, you can see that the second image does have some strange dots all around. But this is not noticable when viewed in smaller version.</p>
<p>You can find the code on <a href="https://github.com/EQuiw/2019-scalingattack">Github</a>. I used Google Colab to run it, and there were some errors initialy but it worked - let me know if interested and I can clean up and share the Notebook also.</p>
<h2 id="rescaling-and-magic-happens">Rescaling and magic happens!</h2>
<p>Now, look what happens when the image is loaded and resized with <code>OpenCV</code> using default settings:</p>
<p><a href="https://embracethered.com/blog/images/2020/image-rescaling-attack.png"><img src="https://embracethered.com/blog/images/2020/image-rescaling-attack.png" alt="Image Rescaling Attack"></a></p>
<p>On the left you can see the original sized image, and on the left the same image downsized to 128x128 pixels.</p>
<p><strong>That’s amazing!</strong></p>
<p>The downsized image is an entirely different picture now! Of course I picked a husky, since I wanted to attack “Husky AI” and find another bypass.</p>
<h2 id="implications">Implications</h2>
<p>This can have a set of implications:</p>
<ol>
<li><strong>Training process:</strong> Images that poisen the training data (as pre-processing rescales images)</li>
<li><strong>Model queries:</strong> The model might predict on a different image than the one the user uploaded</li>
<li><strong>Non ML related attacks:</strong> This can also be an issue in other, non machine learning areas.</li>
</ol>
<p>I guess security never gets boring, there is always something new to learn.</p>
<h2 id="mitigations">Mitigations</h2>
<p>Turns out that Husky AI uses PIL and that was not vulnerable to this attack by default.</p>
<p>I got lucky, because initially Husky AI did use <code>OpenCV</code> and it’s default settings to resize images. But for some reason I changed that early on (not knowing it would also mitigate this attack).</p>
<p>If you use <code>OpenCV</code> the issue can be fixed by using the <code>interpolation</code> argument when calling the <code>resize</code> API to not have it use the default.</p>
<p>Hope that was useful and interesting.</p>
<p>Cheers,
Johann.</p>
<p><a href="https://twitter.com/wunderwuzzi23">@wunderwuzzi23</a></p>
<h2 id="references">References</h2>
<ul>
<li>Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning (<a href="https://www.usenix.org/system/files/sec20-quiring.pdf">https://www.usenix.org/system/files/sec20-quiring.pdf</a>) (Erwin Quiring, TU Braunschweig)</li>
<li><a href="https://github.com/EQuiw/2019-scalingattack">https://github.com/EQuiw/2019-scalingattack</a></li>
</ul>

  </section></div>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/husky-ai-image-rescaling-attacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927655</guid>
            <pubDate>Thu, 29 Oct 2020 05:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sale of Amateur Radio AMPRnet TCP/IP Addresses Raised $108M]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24927037">thread link</a>) | @todsacerdoti
<br/>
October 28, 2020 | https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m | <a href="https://web.archive.org/web/*/https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-7b3dd6c3950208794ea7"><div><p>President of Amateur Radio Digital Communications (ARDC) has confirmed they received $108 million from Amazon for 4 million amateur radio TCP/IP addresses </p><p>Since its allocation to Amateur Radio in the mid-1980s, Internet network 44 (44.0.0.0/8), known as the AMPRNet™, has been used by amateur radio operators to conduct scientific research and to experiment with digital communications over the radio with a goal of advancing the state of the art of Amateur Radio networking, and to educate amateur radio operators in these techniques.</p><p>Amateur Radio Digital Communications (ARDC) is a non-profit California corporation formed to further these goals.</p><p>In mid-2019 a block (44.192.0.0/10) of approximately four million AMPRNet™ IP addresses, out of the 16 million available, was sold to Amazon by ARDC but it is only now that the sale price has been released. Amazon paid $27 for each IPv4 address.</p></div></div></div>]]>
            </description>
            <link>https://www.icqpodcast.com/news/2020/10/25/sale-of-amateur-radio-amprnet-tcpip-addresses-raised-108m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927037</guid>
            <pubDate>Thu, 29 Oct 2020 03:57:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to walk upright and stop living in a cave]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24927008">thread link</a>) | @taylorlunt
<br/>
October 28, 2020 | https://taylor.gl/blog/9/ | <a href="https://web.archive.org/web/*/https://taylor.gl/blog/9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
    <div>
      
<p>
<a href="https://taylor.gl/">Home</a>

  
  
  <a href="https://taylor.gl/"> </a>

  
  
  »
  
  <a href="https://taylor.gl/blog/"> Blog</a>

</p>

<p><span>
  Reading time: 9 minutes.

  Written in 2020.
</span></p>

<p>Call me arrogant, but I’d rather optimize my indoor environment than try to spend more time in the capricious outdoors. I think it’s defeatism to give up on improving our indoor spaces and resign ourselves to the fickle weather and seasons. </p>
<p>If I was going to create an ideal environment for a human, I think there are several things I would include that we routinely fail to include in our homes and offices.</p>
<h3 id="lighting">Lighting</h3>
<p>Our indoor lighting situation usually sucks. The fact that “natural lighting” is a selling point in real estate shows how terrible a job we are doing in this department. We rely on the sun naturally providing us with sufficient light, and if it’s an overcast day or the days have grown shorter in the winter, then I guess we’re shit out of luck. </p>
<p>Usually, indoor areas are around 50-500 lux. This is hundreds of times dimmer than the sunlight. Clearly, we weren’t designed to thrive in such dim environments, and science does verify a connection between brighter light and alertness. If we don’t want to be sleepy like it’s nighttime, we shouldn’t light our rooms like it’s nighttime. For some, the effects of dim lighting go beyond simple lethargy and, especially in the winter, cause serious mood problems like seasonal affective disorder or the winter blues. This is common, but it’s not necessary. Bright light, particularly blue light, can also generally boost mood and may be a comparable stimulant to caffeine. (Those who are prone to mania should be careful, as intense light can trigger mania or hypomania in those predisposed.) Brighter lighting can also help circadian rhythm issues (which I, for example, have struggled with for years), both by entraining your circadian rhythm so your body better knows when it’s day, and by shortening it if it’s too long. </p>
<p>Lighting isn’t as expensive as it used to be, so we can do better than we have in the past. The cost of electricity for LED lighting is now negligible, and the only real factor is the cost of the bulbs themselves. Reaching for the full 100,000 lux of sunlight would still be prohibitively expensive, but going for at least 10,000 lux is doable with only a few hundred dollars. I won’t go into specifics here, but you can get more information on specific lighting setups <a href="https://www.lesswrong.com/posts/hC2NFsuf5anuGadFm/how-to-build-a-lumenator">here</a> or <a href="https://meaningness.com/metablog/sad-light-lumens">here</a>. In particular, get bulbs with a color temperature close to sunlight (5600k), but make sure the bulbs have a <span>good<span>good means 90+</span></span> Color Rendering Index (CRI), otherwise the light will feel harsh.</p>
<p>I recommend putting any bright lighting you buy for your home on electrical timers so you don’t accidentally leave them on during the evening and screw up your sleep. You may also want to set your phone/computer brightness on a timer, if you can. The goal is to mimic the natural day/night cycle of our evolutionary environment, but without all the pesky volatility of nature. You can get programs like f.lux too, which reduce the amount of blue light emitted by your device in the evening, but in my experience this isn’t good enough and reducing the actual brightness of the device at night is also important.</p>
<p>“But what about vitamin D? Just go outside!” This is terrible advice, and I hear it too often. Sunlight is a powerful carcinogen, and vitamin D supplements are not, and they’re cheap. </p>
<h3 id="carbon-dioxide">Carbon dioxide</h3>
<p>Carbon MON-oxide is the deadly one you probably already have a monitor for in your house. Carbon DI-oxide is the feeble cousin of carbon monoxide, but it still has a negative effect on human health: <span>high (but common)<span>1,000 ppm or higher</span></span> levels impairs our ability to think. Just what you don’t want in an office. High levels may also have a negative long-term impact in other areas of our health. </p>
<p>Hold your breath. When it sucks and you decide to start breathing again, it’s carbon dioxide buildup, not lack of oxygen, causing you to feel panic and the need to breath. Carbon dioxide is a toxin. And we breath it out into poorly ventilated rooms, where the levels can rise to double or triple what they are <span>outdoors<span>around 400 ppm</span></span>.</p>
<p>Several studies have shown significant (temporary) cognitive impairments due to carbon dioxide levels over 1,000 ppm, but such levels are <span>common<span>I recently bought a carbon dioxide meter and found such levels in my home.</span></span> in poorly ventilated shared spaces. Fortunately, the solution is simple: open a window. Unfortunately, this doesn’t work when it’s raining, or when it’s too hot outside, or when it’s too cold outside… In particular, I have to contend with Canadian winters, which means opening the window is a valid strategy for a minority of the year unless I buy an expensive heat recovery ventilator. I don’t have a good solution for mitigating carbon dioxide buildup in the winter. Let me know if you do.</p>
<p>And, by the way, plants won’t work. They won’t suck up nearly enough carbon dioxide. You would need hundreds of plants per person, or roughly a dozen full-size trees per person, to offset the carbon dioxide exhaled by humans in a room.</p>
<p>A fun fact: if we don’t stop pumping carbon dioxide into the atmosphere, then in about a century, carbon dioxide <em>outdoors</em> may reach cognitively impairing levels. Then what do we do? </p>
<h3 id="temperature-and-humidity">Temperature and Humidity</h3>
<p>High/low humidity and high/low temperature both lead to discomfort and lower scores on concentration measures. People generally have temperature under control, or at least it’s something they’re aware of. Humidity is less common to measure, but a $10 hygrometer should help you get your indoor space to the ideal 30-50% humidity range if it isn’t already. Air conditioners also tend to reduce humidity as well as temperature, so air-condition in the summer and use a humidifier in the winter.</p>
<p>At night, drop the temperature a few degrees if you can; It’s easier to sleep in a cool room. I wonder how many hours of sleep have been reclaimed already due to the advent of smart thermostats.</p>
<h3 id="background-noise">Background Noise</h3>
<p>I imagine this factor is more subjective than the others, but too loud is distracting, even aggrivating; too quiet makes your sniffles and sighs painfully audible to others, and so is distracting. Uneven background noise like traffic is worse than the uniform background noise of white noise or trickling water. Bad background noise leads to poorer cognition and focus.</p>
<p>It’s easy to be bothered by noise and not realize it until the noise stops and a wave of relief finally makes you aware of how annoyed you were by the sound. Noise issues are happily easy to control: earplugs or noise-cancelling headphones will generally do the trick. It would be utopic to eliminate bothersome noise from the environment altogether, but it’s not necessary. </p>
<h3 id="segregation-of-activities">Segregation of Activities</h3>
<p>A heroin addict who normally takes their dose in their car decides one day to inject in their bathroom. They die of an overdose, even though they took the same amount they normally do. Why? Our brains maintain associations with different environments. If you normally inject heroin when you get in your car, then your body starts to prepare you for the drug as soon as you get in the car. Drug tolerance, then, is partly environmental. (This <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1196296/">actually happened</a> and happens regularly.) Your mind and body are affected by your environment due to Pavlovian conditioning. When the bell rings, the dog salivates. When the lunch bell rings, so do you. </p>
<p>One common piece of advice given by doctors to insomniacs is to only use your bed for sleeping and for sex, and it’s good advice. If you use your bed for reading, studying, and watching TV, then your mind will not form a strong association between the bed and sleep, and you will have a harder time falling asleep. </p>
<p>Likewise, if you do all your slacking off at the same desk you do your work at, you will probably have a harder time focusing. Even having your smartphone within your field of view while you work has been shown to reduce focus. So it wouldn’t hurt to have different areas for work and play, and to not eat at your desk. (And even different user accounts on your computer for work and non-work, if you don’t find that idea to be a pain in the ass like I do.)</p>
<p>We also form associations not just with space, but with time. Hence another piece of common sleep hygeine advice: go to sleep at the same time every night. Your body will learn to expect sleep at that time. Likewise, people who eat at the same time every day eat with their bodies prepared to receive food, and so are less likely to become obese. Studies have shown this. Unfortunately, setting every aspect of your life to a clock can make you feel like a robot, so I usually don’t tolerate such rigidity in my life. But it’s worth thinking about.</p>
<h3 id="conclusion">Conclusion</h3>
<ul>
<li>Brighter lights for your poor eyes</li>
<li>Better ventilation for your poor lungs</li>
<li>Optimal temperature and humidity for your poor skin</li>
<li>Less distracting background noise for your poor ears</li>
<li>Activity-specific areas for your poor brain</li>
</ul>
<p>I also think the aesthetics of most of our indoor environments could use an upgrade, but I don’t have much to say on the subject besides simply saying so. (Though I would bet: green lush &gt; grey drab.)</p>
<p>We sometimes act like we are just <span>machines<span>caffeine in ⟶ code out</span></span>, but we are not. We’re mushy creatures with delicate bodies and delicate minds, too. And we evolved for one specific environment. There is no guarantee that the indoor environment which is cheapest to produce is going to be just as good for us as a bespoke imitation of our evolutionary environment, and in fact it is not. I think life would be more pleasant if people took these factors more serously when designing indoor environments, and our work would be more efficient and less prone to mistakes.</p>


    </div>
  </section></div>]]>
            </description>
            <link>https://taylor.gl/blog/9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24927008</guid>
            <pubDate>Thu, 29 Oct 2020 03:52:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods programmers believe about addresses (2013)]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24926417">thread link</a>) | @gk1
<br/>
October 28, 2020 | https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/ | <a href="https://web.archive.org/web/*/https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Perhaps you've read posts like <a href="http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/">Falsehoods Programmers Believe About Names</a>
and <a href="http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time">Falsehoods programmers believe about time</a>.
Maybe you've also read <a href="http://wiesmann.codiferes.net/wordpress/?p=15187&amp;lang=en">Falsehoods programmers believe about geography</a>.</p>

<p>Addressing is a fertile ground for incorrect assumptions, because everyone's used to dealing with addresses and 99% of the time they seem so simple.
Below are some incorrect assumptions I've seen made, or made myself, or had reported to me.
(If you want to look up an address for a UK postcode or vice-versa to confirm what I'm telling you, try the <a href="http://www.royalmail.com/postcode-finder/">Royal Mail Postcode Finder</a>)</p>

<!-- Composition of building numbers -->

<ul>
<li><p><strong>An address will start with, or at least include, a building number.</strong></p>

<p>Counterexample: Royal Opera House, Covent Garden, London, WC2E 9DD, United Kingdom.</p></li>
<li><p><strong>When there is a building number, it will be all-numeric.</strong></p>

<p>Counterexample: 1A Egmont Road, Middlesbrough, TS4 2HT</p>

<p>4-5 Bonhill Street, London, EC2A 4BX</p></li>
<li><p><strong>No buildings are numbered zero</strong></p>

<p>Counterexample: 0 Egmont Road, Middlesbrough, TS4 2HT</p></li>
<li><p><strong>Well, at the very least no buildings have negative numbers</strong></p>

<p>Guy Chisholm provided this counterexample: Minusone Priory Road, Newbury, RG14 7QS</p>

<p>(none of the databases I've checked render this as -1)</p></li>
<li><p><strong>We can put those funny numbers into the building name field, as no buildings have both a name and a funny number</strong></p>

<p>Counterexample: Idas Court, 4-6 Princes Road, Hull, HU5 2RD</p></li>
<li><p><strong>When there's a building name, there won't be a building number (or vice-versa)</strong></p>

<p>Counterexample: Flat 1.4, Ziggurat Building, 60-66 Saffron Hill, London, EC1N 8QX, United Kingdom</p></li>
<li><p><strong>A building number will only be used once per street</strong></p>

<p>The difference between 50 Ammanford Road, Tycroes, Ammanford, SA18 3QJ and 50 Ammanford Road, Llandybie, Ammanford, SA18 3YF is about 4 miles (<a href="https://maps.google.co.uk/maps?q=SA18+3QJ+to+SA18+3YF">Google Maps</a>).</p></li>
<li><p><strong>When there's line with a number in an address, it's the building number.</strong></p>

<p>Counterexample: Flat 18, Da Vinci House, 44 Saffron Hill, London, EC1N 8FH, United Kingdom</p>

<p>You also get suite numbers, floor numbers, unit numbers, and organisations with numbers in their names.</p>

<p>Adrien Piérard contributes an address from Japan with fifteen digits in six separate numbers (five if you count the zip code as a single number). The format is: 980-0804 (zip code), Miyagi-ken (prefecture) Sendai-shi (city) Aoba-ku (ward) Kokubuncho (district) 4-10-20 (sub-district-number block-number lot-number) Sendai (building name) 401 (flat number).</p></li>
<li><p><strong>OK, the first line starting with a number then</strong></p>

<p>Counterexample: 3 Store, 311-318 High Holborn, London, WC1V 7BN</p></li>
<li><p><strong>A building will only have one number</strong></p>

<p>Benton Lam offers this address from the Hong Kong Special Administrative Region - it has both a number on its road (14) and in its group of buildings (3): 15/F, Cityplaza 3, 14 TaiKoo Wan Road, Island East, HKSAR</p></li>
<li><p><strong>The number of buildings is the difference between the highest and lowest building numbers</strong></p>

<p>Tibor Schütz points out building numbers may be skipped - for example, on a street where even-numbered buildings are on one side, odd numbers on the other; multiple buildings sharing the same number (such as where a new house has been built) and buildings with more than one number.</p>

<p>Cyrille Chépélov and Sami Lehtinen tell me in Antibes, France and rural Finland some buildings are numbered based on the distance from the start of the road - such as Longroad 65 for the building 750m from the start of longroad.</p></li>
<li><p><strong>If the addresses on the left of the road are even, the addresses on the right must be odd</strong></p>

<p>Cyrille Chépélov points out that in places, <a href="https://maps.google.fr/maps?q=48.857415,2.467167">Boulevard Théophile Sueur, Montreuil, Seine-Saint-Denis, France</a> has evens-only on both sides. The two sides are also in different cities and Départements.</p></li>
<li><p><strong>A building name won't also be a number</strong></p>

<p>Ben Tilly reports on Ten Post Office Sq, Boston MA 02109 USA - which is not, reportedly, the same as 10 Post Office Sq, Boston MA 02109 USA.</p></li>
<li><p><strong>Well, at least you can omit leading zeros</strong></p>

<p>Shaun Crampton reports living at 101 Alma St, Apartment 001, Palo Alto - where apartments 1 and 001 were on different floors.</p></li>
<li><p><strong>A street with a building A will not also have a building Alpha</strong></p>

<p>Douglas Perreault reports he lived in a block within a condo association; it was a large association, with blocks A through Z then Alpha, Beta, Gamma, Delta, and Theta. Mail and deliveries were often misrouted from block Alpha to block A and vice-versa. His address at the time was: 14100 N 46th St., Alpha 39, Tampa, FL 33613</p></li>
</ul>

<!-- Composition of street names -->

<ul>
<li><p><strong>A street name won't include a number</strong></p>

<p>8 Seven Gardens Burgh, WOODBRIDGE, IP13 6SU (pointed out by Raphael Mankin)</p></li>
<li><p><strong>OK, but numbers in street names are expressed as words, not digits</strong></p>

<p>Jan Jongboom reports streets can be numbered in the Netherlands - for example, Plein 1944 in Nijmegen.</p></li>
<li><p><strong>When there's a numbered street and a house number, there will be a separator between them</strong></p>

<p>Another from Jan Jongboom: Gondel 2695, Lelystad, means area Gondel, street 26, number 95</p></li>
<li><p><strong>Street names always end in descriptors like 'street', 'avenue', 'drive', 'square', 'hill' or 'view'</strong></p>

<p>They don't always - for example: Piccadilly, London, W1J 9PN</p></li>
<li><p><strong>OK, but when they do have a descriptor there will only be one</strong></p>

<p>A street name can be entirely descriptors: 17 Hill Street, London, W1J 5LJ or <a href="https://en.wikipedia.org/wiki/Avenue_Road">Avenue Road, Toronto, Ontario</a>.</p></li>
<li><p><strong>OK, but when they do have a descriptor it will be at the end</strong></p>

<p>French addresses use prefix descriptors like 'rue', 'avenue', 'place' and 'allee'.</p></li>
<li><p><strong>OK, but if there's a descriptor it'll be at the start or end of the street name.</strong></p>

<p>Or the middle, like 3 Bishops Square Business Park, Hatfield, AL10 9NA</p></li>
<li><p><strong>OK, but at the very least you wouldn't name a town Street</strong></p>

<p><a href="https://maps.google.co.uk/maps?q=Street,+Somerset">Actually there's a town called Street in Somerset, UK</a>.</p></li>
<li><p><strong>Street numbers (and building numbers) don't contain fractions</strong></p>

<p>Dan, Fred Kroon, David Underwood and Daniel Dickison submitted examples of fractional street numbers like <a href="https://maps.google.com/maps?q=43rd%20%C2%BD%20st,%20Pittsburgh,%20PA">43rd ½ St, Pittsburgh, PA</a>, and of fractional building numbers. These can be written in unicode (43rd ½ St), as a fraction with a slash (43 1/2) or as a decimal (43.5)</p>

<p>Gene Wirchenko reports a fractional building number: 1313 1/2 Railroad Ave Bellingham WA 98225-4729</p></li>
<li><p><strong>Street names don't recurr in the same city</strong></p>

<p><a href="https://maps.google.co.uk/maps?q=from:W3+6LJ+to:W5+5DB+to:N8+7PB+to:SE25+6EP+to:E13+0AJ+to:E17+7LD+to:NW10+4LX+to:N1+9TR+to:E1+6PG+to:NW1+0JH+to:W14+8NL+to:SE13+6AD+to:SW19+5DX+to:E11+2AJ+to:SW19+2AE+to:E6+2HJ+&amp;saddr=W3+6LJ&amp;daddr=W5+5DB+to:N8+7PB+to:SE25+6EP+to:E13+0AJ+to:E17+7LD+to:NW10+4LX+to:N1+9TR+to:E1+6PG+to:NW1+0JH+to:W14+8NL+to:SE13+6AD+to:SW19+5DX+to:E11+2AJ+to:SW19+2AE+to:E6+2HJ">Here's a map of the following addresses:</a></p>

<ul>
<li>High Street, London, W3 6LJ</li>
<li>High Street, London, W5 5DB</li>
<li>High Street, London, N8 7PB</li>
<li>High Street, London, SE25 6EP</li>
<li>High Street, London, E13 0AJ</li>
<li>High Street, London, E17 7LD</li>
<li>High Street, London, NW10 4LX</li>
<li>Islington High Street, London, N1 9TR</li>
<li>Shoreditch High Street, London, E1 6PG</li>
<li>Camden High Street, London, NW1 0JH</li>
<li>Kensington High Street, London, W14 8NL</li>
<li>Lewisham High Street, London, SE13 6AD</li>
<li>High Street Wimbledon, London, SW19 5DX</li>
<li>High Street Wanstead, London, E11 2AJ</li>
<li>High Street Colliers Wood, London, SW19 2AE</li>
<li>High Street North, London, E6 2HJ </li>
</ul></li>
<li><p><strong>But street names don't recurr in close proximity</strong></p>

<p>Julian Fleischer provides an example from Bocholt in Germany showing several roads in close proximity all called <a href="https://maps.google.com/maps?q=51.853945,6.615334">Up de Welle</a>.</p></li>
<li><p><strong>An address will be comprised of road names</strong></p>

<p>Kirk Kerekes spent several years using an address of the form "2 mi N then 3 mi W of Jennings, OK 74038" which regularly got successful deliveries. Mike Riley used to mail the Very Large Array radio telescope at "50 miles (80 km) West of Socorro, New Mexico, USA"</p>

<p>Sam pointed me to <a href="http://www.menomoneefallsnow.com/news/99857214.html">Menomonee Falls</a> where houses are addressed using Milwaukee County's grid system instead of house numbers - giving addresses like N88 W16541 Foobar St.</p>

<p>Andy Monat sent the following address example, from a <a href="http://ciapa.tulane.edu/uploads/1_EE_2012_Acceptance_Packet_INFORMATION-1340749206.pdf">semester abroad program at Tulane University </a>: CIAPA, 50 meters north of the Hypermas/Walmart of Curridabat, San Jose, Costa Rica. Adrien Piérard and Luke Allardyce point out street names are seldom used in Japan - instead, districts and blocks and lot numbers are used (more info on the <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system">Wikipedia entry for the Japanese addressing system</a>).  A <a href="http://www.worldpress.org/Americas/592.cfm">2002 World Press Review report</a> gave this sample address: From where the Chinese restaurant used to be, two blocks down, half a block toward the lake, next door to the house where the yellow car is parked, Managua, Nicaragua. Shaun Crampton sent <a href="https://vianica.com/nicaragua/practical-info/14-addresses.html">an article with more details and examples of the Nicaraguan system</a>. Stig Brautaset pointed out <a href="http://www.bbc.co.uk/news/magazine-14806350">a BBC article about post in Kabul</a> gives this example: "Hamid Jaan, behind Darul-Aman palace". Nathan Fellman reports similar addressing is used in Nicaragua and Costa Rica.</p>

<p>Paul Puschmann and Tibor Schütz pointed out the city of <a href="http://de.wikipedia.org/wiki/Quadratestadt">Mannheim in Germany is sometimes called Quadratestadt (City of Squares)</a> as the city centre is arranged in a grid, with blocks assigned a letter (along the north-south axis) and a number (along the east-west axis) then buildings numbered by block number. So an example address at numbers 6 to 13 on block R 5 would be: Institut für Deutsche Sprache, R 5, 6-13, D-68161 Mannheim </p>

<p>Leoni Lubbinge gives an example of a South African address: Part 84, Strydfontein 306 JR, Pretoria which means the 84th plot of the farm Strydfontein 306 JR.</p></li>
</ul>

<!-- Elements being present or absent -->

<ul>
<li><p><strong>A road will have a name</strong></p>

<p>Plenty of roads like driveways, onramps and the aisles of carparks don't have names. Some roads in Japan also don't have names, as <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system">the prevalent addressing system works on districts, subdistricts, blocks, lots and lot numbers</a>.</p>

<p>Peter Kenway points out in America some homes are addressed as Rural Routes, where numbers are allocated to boxes on a route covering multiple roads. For example: Box 1234, R.R. 1, Winthrop, ME 04364.</p></li>
<li><p><strong>A road will only have one name</strong></p>

<p>Many different roads, from Goswell Road in London to Regent Road in Edinburgh, make up the 410 mile <a href="https://en.wikipedia.org/wiki/A1_road_%28Great_Britain%29">A1</a>. And while there may only be one "1 Goswell Road" and only one "1 Regent Road" there are multiple buildings numbered 1 on the road designated A1.</p>

<p>Roads may also be named in multiple languages. For example, in Ireland roads may be named in both English and Irish</p></li>
<li><p><strong>Addresses will only have one street</strong></p>

<p>The Royal Mail have what they call a 'dependent street' - for example: 6 Elm Avenue, Runcorn Road, Birmingham, B12 8QX, United Kingdom (Runcorn Road is the street, Elm Avenue is the stubby 'dependent street' and isn't unique within the city. <a href="http://maps.google.co.uk/maps?q=B12+8QX">Google Maps</a> )</p>

<p>Another counterexample: Rogue Hair, 1 Hopton Parade, Streatham High Road, London, SW16 …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/">https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/</a></em></p>]]>
            </description>
            <link>https://www.mjt.me.uk/posts/falsehoods-programmers-believe-about-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926417</guid>
            <pubDate>Thu, 29 Oct 2020 02:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Violated a Code of Conduct]]>
            </title>
            <description>
<![CDATA[
Score 1193 | Comments 903 (<a href="https://news.ycombinator.com/item?id=24926214">thread link</a>) | @tosh
<br/>
October 28, 2020 | https://www.fast.ai/2020/10/28/code-of-conduct/ | <a href="https://web.archive.org/web/*/https://www.fast.ai/2020/10/28/code-of-conduct/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span>Written: 28 Oct 2020 by <i>Jeremy Howard</i></span></p><blockquote>
<p><em>Update Oct 20, 2020</em>: NumFOCUS <a href="https://numfocus.org/blog/jeremy-howard-apology">has apologized</a> to me. I accept their apology. I do not accept their assertion that “At the time of the interview, the committee had not determined that there was a violation of the code of conduct, only that there were two complaints filed and being examined.” The email to set up the call said “We would like to schedule a meeting so that we can discuss the results of our investigation with you” - nothing further. During the call, the committee stated the list of violations, and said “that is what the reporters stated, and what we found”. I asked why they didn’t take a statement from me before that finding, and they said “we all watched the video, so we could see for ourselves the violation”. The committee offered in their apology email to me to have a follow-up discussion, and I declined the offer.</p>
</blockquote>
<blockquote>
<p>Summary: NumFOCUS found I violated their Code of Conduct (CoC) at JupyterCon because my talk was not “kind”, because I said Joel Grus was “wrong” regarding his opinion that Jupyter Notebook is not a good software development environment. Joel (who I greatly respect, and consider an asset to the data science community) was not involved in NumFOCUS’s action, was not told about it, and did not support it. NumFOCUS did not follow their own enforcement procedure and violated their own CoC, left me hanging for over a week not even knowing what I was accused of, and did not give me an opportunity to provide input before concluding their investigation. I repeatedly told their committee that my emotional resilience was low at the moment due to medical issues, which they laughed about and ignored, as I tried (unsuccessfully) to hold back tears. The process has left me shattered, and I won’t be able to accept any speaking requests for the foreseeable future. I support the thoughtful enforcement of Code of Conducts to address sexist, racist, and harassing behavior, but that is not what happened in this case.</p>
</blockquote>
<h2 id="overview">Overview</h2>
<p>In my recent JupyterCon keynote, “I Like Jupyter Notebooks” (re-recording provided at the bottom of this post, if you’re interested in seeing it for yourself), I sought to offer a rebuttal to Joel Grus’ highly influential JupyterCon presentation “<a href="https://www.youtube.com/watch?v=7jiPeIFXb6U">I Don’t Like Notebooks</a>”. Joel claimed in his talk that Jupyter is a poor choice for software development and teaching, and I claimed in my talk that it is a good choice. The NumFOCUS committee found me guilty of violating their code of conduct for having not been “kind” in my disagreement with Joel, and for “insulting” him. The specific reasons given were that:</p>
<ul>
<li>I said that Joel Grus was “wrong”</li>
<li>I used some of his slides (properly attributed) and a brief clip from one of his videos to explain why I thought he was wrong</li>
<li>That I made “a negative reference” to his prior talk</li>
<li>I was also told that “as a keynote speaker” I would “be held to a higher standard than others” (although this was not communicated to me prior to my talk, nor what that higher standard is)</li>
</ul>
<p>Code of Conducts can be a useful tool, when thoughtfully created and thoughtfully enforced, to address sexism, racism, and harassment, all of which have been problems at tech conferences. Given the <a href="https://medium.com/tech-diversity-files/if-you-think-women-in-tech-is-just-a-pipeline-problem-you-haven-t-been-paying-attention-cb7a2073b996">diversity issues in the tech industry</a>, it is important that we continue the work of making conferences more inclusive, particularly to those from marginalized backgrounds. Having a code of conduct with explicit rules against violent threats, unwelcome sexual attention, repeated harassment, sexually explicit pictures, and other harmful behavior is the first step towards addressing and stopping those behaviors. The JupyterCon code provides the following examples of unacceptable behavior, none of which are at all similar to what I did (i.e. saying that someone was wrong on a technical topic, and explaining how and why):</p>
<ul>
<li>Violent threats or violent language directed against another person</li>
<li>Discriminatory jokes and language</li>
<li>Posting sexually explicit or violent material</li>
<li>Posting (or threatening to post) other people’s personally identifying information (“doxing”)</li>
<li>Personal insults, especially those using racist or sexist terms</li>
<li>Unwelcome sexual attention</li>
<li>Advocating for, or encouraging, any of the above behavior</li>
<li>Repeated harassment of others. In general, if someone asks you to stop, then stop</li>
</ul>
<p>My experience with the NumFOCUS code of conduct raises a few key issues:</p>
<ul>
<li>The CoC enforcement process involved conflicting &amp; changing information, no opportunity for me to give input, the stress of a long wait of unknown duration with no information about what I was accused of or what would happen next, and the committee members violated their own CoC during the process</li>
<li>There were two totally different Codes of Conduct with different requirements linked in different places</li>
<li>I was held to a different, undocumented and uncommunicated standard</li>
<li>The existence of, or details about, the CoC were not communicated prior to confirmation of the engagement</li>
<li>CoC experts recommend avoiding requirements of politeness or other forms of “proper” behavior, but should focus on a specific list of unacceptable behaviors. The JupyterCon CoC, however, is nearly entirely a list of “proper” behaviors (such as “Be welcoming”, “Be considerate”, and “Be friendly”) that are vaguely defined</li>
<li>CoC experts recommend using a CoC that focuses on a list of unacceptable behaviors. Both the codes linked to JupyterCon have such a link, and none of the unacceptable behavior examples are in any way related or close to what happened in this case. But NumFOCUS nonetheless found me in violation.</li>
</ul>
<p>I would rather not have to write this post at all. However I know that people will ask about why my talk isn’t available on the JupyterCon site, so I felt that I should explain exactly what happened. In particular, I was concerned that if only partial information became available, the anti-CoC crowd might jump on this as an example of problems with codes of conduct more generally, or might point at this as part of “cancel culture” (a concept I vehemently disagree with, since what is referred to as “cancellation” is often just “facing consequences”). Finally, I found that being on the “other side” of a code of conduct issue gave me additional insights into the process, and that it’s important that I should share those insights to help the community in the future.</p>
<h2 id="details">Details</h2>
<p>The rest of this post is a fairly detailed account of what happened, for those that are interested.</p>
<h3 id="my-talk-at-jupytercon">My talk at JupyterCon</h3>
<p>I recently gave a talk at <a href="https://jupytercon.com/">JupyterCon</a>. My partner Rachel gave a <a href="https://www.youtube.com/watch?v=frc7FgheUj4">talk at JupyterCon</a> a couple of years ago, and had a wonderful experience, and I’m a huge fan of Jupyter, so I wanted to support the project. The conference used to be organized by O’Reilly, who have always done a wonderful job of conferences I’ve attended, but this year the conference was instead handled by <a href="https://numfocus.org/">NumFOCUS</a>.</p>
<p>For my talk, I decided to focus on Jupyter as a literate and <a href="https://www.fast.ai/2019/12/02/nbdev/">exploratory programming environment</a>, using <a href="https://nbdev.fast.ai/">nbdev</a>. One challenge, however, is that two years earlier Joel Grus had given a brilliant presentation called <a href="https://www.youtube.com/watch?v=7jiPeIFXb6U">I Don’t Like Notebooks</a> which had been so compelling that I have found it nearly impossible to talk about programming in Jupyter without being told “you should watch this talk which explains why programming in Jupyter is a terrible idea”.</p>
<p>Joel opened and closed his presentation with some light-hearted digs at me, since I’d asked him ahead of time <em>not</em> to do such a presentation. So I thought I’d kill two birds with one stone, and take the opportunity to respond directly to him. Not only was his presentation brilliant, but his slides were hilarious, so I decided to directly parody his talk by using (with full credit of course) some of his slides directly. That way people that hadn’t seen his talk could both get to enjoy the fantastic content, and also understand just what I was responding to. For instance, here’s how Joel illustrated the challenge of running cells in the right order:</p>
<figure>
<img srcset="https://www.fast.ai/images/numfocus/joel-order.png 2w" sizes="1px" src="https://www.fast.ai/images/numfocus/joel-order.png">
</figure>
<p>I showed that slide, explaining that it’s Joel’s take on the issue, and then followed up with a slide showing how easy it actually is to run all cells in order:</p>
<figure>
<img srcset="https://www.fast.ai/images/numfocus/jeremy-order.png 2w" sizes="1px" src="https://www.fast.ai/images/numfocus/jeremy-order.png">
</figure>
<p>Every slide included a snippet from Joel’s title slide, which, I explained, showed which slides were directly taken from his presentation. I was careful to ensure I did not modify any of his slides in any way. When first introducing his presentation, I described Joel as “a brilliant communicator, really funny, and wrong”. I didn’t make any other comments about Joel (although, for the record, I think he’s awesome, and highly recommend <a href="https://www.amazon.com/Data-Science-Scratch-Principles-Python/dp/1492041130">his book</a>.</p>
<h3 id="the-code-of-conduct-violation-notice">The Code of Conduct violation notice</h3>
<p>A week later, I received an email telling me that two CoC reports were filed regarding my JupyterCon keynote presentation. I was told that “The Code of Conduct Enforcement Team is meeting tomorrow to review the incident and will be contacting you to inform you of the nature of the report and to understand your perspective”.</p>
<p>The CoC wasn’t mentioned at all until after I’d been invited to speak, had accepted, and had completed the online registration. I had reviewed it at that time, and had been a bit confused. The email I received linked to a <a href="https://jupytercon.com/codeofconduct/">JupyterCon Code of Conduct</a>, but that in turn didn’t provide much detail about what is and isn’t OK, and that in turn linked to a different <a href="https://numfocus.org/code-of-conduct">NumFOCUS Code of Conduct</a>. A link was also provided to <a href="https://numfocus.typeform.com/to/ynjGdT">report violations</a>, which also linked to and named the NumFOCUS CoC.</p>
<p>I was concerned that I had done something which might be viewed as a violation, and looked forward to hearing about the nature of the report and having a chance to share my perspective. I was heartened that JupyterCon documented that they follow the <a href="https://numfocus.org/code-of-conduct/response-and-enforcement-events-meetups">NumFOCUS Enforcement Manual</a>. I was also heartened that the manual has a section “Communicate with the Reported Person about the Incident” which says they will “Let the reported person tell someone on the CoC response team their side of the story; the person who receives their side of the story should be prepared to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fast.ai/2020/10/28/code-of-conduct/">https://www.fast.ai/2020/10/28/code-of-conduct/</a></em></p>]]>
            </description>
            <link>https://www.fast.ai/2020/10/28/code-of-conduct/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24926214</guid>
            <pubDate>Thu, 29 Oct 2020 01:47:55 GMT</pubDate>
        </item>
    </channel>
</rss>
