<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 09 Dec 2020 08:33:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 09 Dec 2020 08:33:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The CIA's Deadly Deceits and the Vietnam War, with Ralph McGehee (1986)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25329913">thread link</a>) | @AndrewBissell
<br/>
December 6, 2020 | https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee | <a href="https://web.archive.org/web/*/https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-bolt-field="body"><p><iframe allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/BDZv57p1Ixk"></iframe></p>



<p><b>Ralph W. McGehee:</b> It's a real honor for me to be here today. I don't often say that, but I really mean it. I like to start off my talk by mentioning two things. One, please don't believe anything I'm going to tell you. The American people are so inundated by misinformation, there's absolutely no reason you should believe anything anybody tells you, particularly the evening news. Of course, with everything there is an exception, and I think in my case, I have a fairly valid exception. Because of the process that I had to go through to clear my book, I had to prove that everything I am saying is in the public domain. I still go down to the Agency about twice a month and turn in new material to let them clear it. And in doing that process, I have to produce or pull out from government documents that particular information, because they inevitably will say, "You can't say it, it's classified." And I will inevitably locate that information in the public domain.</p> 
 
<p>So if you doubt me, and I hope you will, there is a way to check up on me. Go to the library and look in the back of my book, and almost every major conclusion that I will be talking about here today will be documented to an official government document. I've drawn upon the Pentagon Papers. Are you all familiar with the Pentagon Papers? And the Senate and House investigations of the Agency and a variety of other material. So don't believe what I say, but if you want to check up on me, the information is available.</p> 
 
<p>Secondly, I'd like to say my message is basically a real downer. It is real negative, but I don't want to leave you with that impression, because I just returned from a two week speaking trip in Iowa, where I was going to testify at the court case there in Iowa City for the protesters, and in Nebraska. And I've been in Arizona and various other places speaking, and wherever you go, you find concerned groups. So I am encouraged. I know during the Vietnam War for the first ten years, we didn't even know what was going on. And then eleven or twelve years later, people began to protest. But this time in Latin America, the protest was almost instantaneous. The substructure is there. The only reason we got out of Vietnam, of course, is because of the student protests. So I am very encouraged. My message is negative, but I don't want to leave you with that impression. I am very, very encouraged.</p> 
 
<p>I think I should talk in three basic phases. One, walk you very quickly through my career with the Agency up to right now where I am today, and back up and walk you through Vietnam a little bit or walk you through my career in a little more detail, including Vietnam. Now I do that not to talk about Vietnam but because the processes that are followed today in Central America, in the Middle East and in Africa have all been used in Vietnam. I'll take out three or four incidences, and they are documented by the way, and show you that these are sort of typical of what the Agency does around the world since the very beginning in '47, what it's doing today in '86.</p> 
 
<p>Then I'll go back and review the Agency's domestic operations, and I'll do that for one purpose, because everything they were doing up to the mid-seventies they are now doing again. The only difference now is under President Reagan's Executive Order 12333 of December '81, they can do the things legally that they were doing illegally before. It's the only difference. Then I would like to talk, sort of bring it all together in Central America and talk about El Salvador, Grenada, and particularly Nicaragua, and then come to my conclusion. So that's basically the approach I'll take.</p> 
 
<p>I went to the University of Notre Dame. I played on four undefeated football teams, three national championships, and then I tried out with the Green Bay Packers. And to this day, I can't understand what's the matter with the coaches up there. When I was cut, I received a cable, "Would you be interested in an important government position similar to the State Department in function?" My football background was not irrelevant. When I went down to Washington, I found that the class before me, my class, and the class after me were basically rejects from the National Football League, not the standard concept of an intelligent (He does say "intelligent" here, I think as a joke about football players) officer.</p> 
 
<p>Well, I served in the Agency for 25 years. The first 15 or 16 years, I believed that the CIA was sort of like a missionary organization, out saving the world for democracy and religion and gathering good intelligence to help our policymakers make good decisions. When I'd go into work in the morning, I'd feel a real pride that I'm part of the great crusade to stop the international communist conspiracy. All that began to change for me in Vietnam. That's when I began protesting.</p> 
 
<p>I should mention that I served my entire 25 years in the Directorate of Operations. Now, the Agency is broken down to basically four directorates, Administration, Science and Technology, Intelligence, and Operations. Administrators administrate. Science and Technology, they devise the sophisticated collection devices and monitor the results. The Directorate of Intelligence, that's the scholars who sit and read the reports that come in from around the world and then put out the final reports. And the Operators operate. The Directorate of Operations has two basic functions, covert operations and gathering intelligence covertly.</p> 
 
<p>Since it's my contention that the Agency is little more than a covert action agency, I will dwell a little bit on it. Now, covert action operations in broadest context can be described as those operations designed to overthrow or support foreign governments. Overthrow operations have four basic components, economic warfare, political warfare, psychological warfare, and economic warfare. In my 25 years in the Agency, I served overseas in Japan, in the Philippines, in Taiwan, six years or three tours in Thailand, and two years as the chief police adviser to the head of the Vietnamese Special Police. That's the equivalent of our FBI.</p> 
 
<p>As I said, my period of protests began around the Vietnam War. I for the next period within the Agency began protesting, and having no luck with those protests, I finally left the Agency in 1977. Now, in a stroke of real irony at this particular point, because they had assigned me to the CIA’s Siberia. When you escalate your protest, you become persona non grata. In '77 in a stroke of irony, they awarded me the Career Intelligence Medal and the Honorable Service Medal. Of course, I think I know why. They knew they had a loose cannon and they wanted to kind of damp me down, appease me a little bit. And I think that was the purpose of giving them to me.</p> 
 
<p>But I also earlier had won awards, two Vietnam service awards, a commendation from the director for devising a program of counterinsurgency and intelligence, and a variety of other CIA and foreign awards. Well, when I left the Agency, I testified before the Senate and House intelligence committees and before a variety of other Senate and House committees, all related to CIA activities.</p> 
 
<p>I immediately set about writing a book about my experiences. It took me three years to research and write the book, and then like all CIA officers, when you join the Agency, you have to sign a secrecy agreement. And as I said, I must now submit everything to the CIA for pre-publication review. I did, and they came back and they said they have identified approximately 400 security violations in my manuscript. And they returned it in little bits and pieces of paper, because some of these deletions ran up to several pages in length.</p> 
 
<p>Well, to defeat this process, I went through going through the public record and pulling out the identical information. And ultimately with this effort, I got virtually everything reinstated. There are a few little specifics that I didn't get reinstated, but for the most part they were all reinstated. I did in a few cases, they had deleted some very boring information, so I said rather than fight them over this one, let's just leave this comment, "Seven words deleted." It looks a lot sexier than mine. So I didn't fight them on all of them.</p> 
 
<p>Then I went looking for a publisher, a long hard process, and finally one publisher said, "You know, you've written a nice legal brief here. You make your points and then you have your citations to your information. But boy, it's dull as mud. Who would want to read a legal brief? So we will publish it if you'll rewrite it as a autobiography," which I did. I then resubmitted it to the CIA for pre-publication review. I didn't put any more secret details in there. I just added my personal life.</p> 
 
<p>At this time, William Casey had become Director of the CIA, and they in essence told me, "We're not going to let you publish a book." And I said, "Well, you can't stop me. Everything that's in the book, you have not only cleared for other people, it's not only in the public record, but you also cleared for me before. And the laws that you operate under say you may not reclassify information once it's been declassified and released." And their response in essence, "Well, that's tough. We're doing it anyhow. There's nothing you can do about it." Well, this was a very critical period. I just didn't know what to do. I really worried about this, because if they would've stopped me with that, then I would not be able to speak to you here this evening, because everything would have been classified.</p> 
 
<p>So I called <i>The Washington Post</i>, and <i>The Washington Post</i> ran a long exposé of how the CIA was violating the law by reclassifying information that was in the public domain, a violation of the law of the land. This public exposure forced the Agency to relent, and the book was finally released. Subsequent to the release of the book, I then traveled to Cuba, where we stayed about a week, and to Grenada, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee">https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee</a></em></p>]]>
            </description>
            <link>https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee</link>
            <guid isPermaLink="false">hacker-news-small-sites-25329913</guid>
            <pubDate>Mon, 07 Dec 2020 06:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TeX: A Tale of Two Worlds]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25329049">thread link</a>) | @Bella-Xiang
<br/>
December 6, 2020 | https://bitbashing.io/tex.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/tex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!-- for XeTeX -->


<p>Best viewed in <del>Internet Explorer 6</del>
<a href="https://assets.bitbashing.io/papers/tex-tale-of-two-worlds.pdf">PDF</a>
because… well… read the damn thing.</p>

<!--
It all started when a college friend told me about a cool program for typesetting
papers. Now typography books litter my apartment and I can't read a menu
without noticing bad kerning. Thanks, Max. This is all your fault.
-->

<hr>

<p>Most serious programmers have heard of Donald Knuth,
the man who coined the term <em>analysis of algorithms</em> in 1968
and pioneered many of the computer science fundamentals we use today.
Knuth is perhaps most famous for his ongoing magnum opus,
<em>The Art of Computer Programming</em>.</p>

<p>When the first volume of TAOCP was released that same year,
it was printed the way most books had been since the turn of the century:
with <em>hot metal</em> type.
Each individual letter was cast from molten lead,
then arranged into its line.</p>

<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/7/72/Matrixcase-bembo-16pts.jpg" alt="Monotype matrix case" height="400">
<figcaption>
A case of letter molds—or <em>matrices</em>—used by the Monotype caster,
the most commonly-used machine for printing books in the days of hot metal type.
Its main contemporary, the Linotype, molded entire lines at a time,
and was often used for printing newspapers.
</figcaption>
</figure>

<p>These lines were clamped together to form pages of the book,
which were finally inked and pressed against paper.
By March of 1977, Knuth was ready for a second run of TAOCP, Volume&nbsp;2,
but he was horrified when he received the proofs.
Hot metal typesetting was an expensive, complicated, and time-consuming process,
so publishers had replaced it with phototypesetting,
which works by projecting characters onto film.
The new technology, while much cheaper and faster,
didn’t provide the same level of quality he had come to expect.</p>

<p>The average author would have resigned themselves to the change and moved on,
but Knuth took great pride in print quality,
especially for the mathematics in his books.
Around this time, he discovered an exciting new technology:
digital typesetting.
Instead of working with metal or film,
letters and shapes were built from tiny dots,
often packed together at over 1,000 per inch.
Inspired by this burgeoning tech and frustrated with the current state of affairs,
Knuth set off on one of the greatest yak shaves of all time.
For years, he paused all work on his books to create his own
digital typesetting system.
When the dust settled in 1978, Knuth had the first version of
<span>T<sub>e</sub>X</span>
.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>It’s hard to understand how much of a revolution <span>T<sub>e</sub>X</span>
 was,
especially looking back from a time where anybody with a copy
of Word can be their own desktop publisher.
Adobe’s PDF wouldn’t exist for another decade, so Knuth
invented a device-independent format, DVI.
Scalable fonts were uncommon at the time, so Knuth created a system,
<span>METAFONT</span>
, to rasterize his characters into dots on the
page.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Perhaps most importantly, Knuth and his graduate students designed algorithms
to automatically hyphenate and justify lines of text into
beautifully-typeset paragraphs.</p>

<p>Here is where the timelines diverge.
In one, <span>T<sub>e</sub>X</span>
 was just the beginning.
Computer typography evolves rapidly as the decades go by,
building on Knuth’s prior work and
taking advantage of the million-fold increases we’ve seen in computing power.
Browsers, e-readers, and word processors deliver beautiful type
to every person who looks at a screen, with almost no effort from authors.</p>

<p>In the darker timeline… none of this happens.
<span>T<sub>e</sub>X</span>
 is still some of the best we’ve got for computer typesetting.
It’s seen some impressive improvements,<sup id="fnref:3"><a href="#fn:3">3</a></sup>
but its core hasn’t changed much in decades.
To this day,
it doesn’t lay out more than one page at a time because 1980s computers didn’t
have enough RAM to do any better.<sup id="fnref:4"><a href="#fn:4">4</a></sup>
Almost no other software—except for a handful of professional layout
programs like Adobe InDesign—leverages any of the advances
<span>T<sub>e</sub>X</span>
 made in line breaking and hyphenation.
Layout in Word, browsers, and even e-readers is a sad joke.</p>

<figure>
<img src="https://assets.bitbashing.io/images/exa.png" alt="Mobile browser layout example" height="400">
<figcaption>
State of the art text layout in today's browsers. Mind the gaps.
</figcaption>
</figure>

<p>I’m not sure what to make of this.
Maybe most people, outside a small cadre of designers and
enthusiasts, just don’t care about typography very much.
After all, the human brain is incredibly good glossing over minor details and
im<span>p</span>erfections when reading.
But even the design world seems largely unaware or indifferent to Knuth’s work.
Despite collaborations with famous type designers like Hermann Zapf,
you’ll find no mention of him in renowned books and documentaries on
the subject.<sup id="fnref:5"><a href="#fn:5">5</a></sup>
And parametric font families—just like the ones <span>METAFONT</span>
 offered in 1983—are
heralded in 2017 as “a new era of type design”.<sup id="fnref:6"><a href="#fn:6">6</a></sup>
It’s bizarre.</p>

<p>Good typography can make almost anything more enjoyable to read,
and it feels like such a shame that better layout isn’t
available to the masses
when so much of the groundwork was laid almost forty years ago.
In an age when the average American reads from a screen they keep in their pocket
dozens of times a day,
and where each one of those devices holds more processing power than you could
fit in several rooms back when Donald Knuth
wrote <span>T<sub>e</sub>X</span>
, surely we can—and <em>should</em>—do better.</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/tex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25329049</guid>
            <pubDate>Mon, 07 Dec 2020 03:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Cheers for Solutionism?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25328149">thread link</a>) | @panic
<br/>
December 6, 2020 | https://aelkus.github.io/theory/2020/12/03/solu.html | <a href="https://web.archive.org/web/*/https://aelkus.github.io/theory/2020/12/03/solu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Economist Noah Smith <a href="https://noahpinion.substack.com/p/climate-change-isnt-that-hard">is fed up with</a> generic critiques of technological “solutionism,” specifically what he calls the “2010s consensus that technology is a sideshow compared to social movements.”</p>

<blockquote>
  <p>In the last decade, we’ve basically been taught to deride “solutionism” — while Silicon Valley techbros were bending their genius toward figuring out ways to sell more ads or lower taxi drivers’ wages, inequality was running rampant and parents were struggling to feed their kids. Instead of trusting wizardry to solve the world’s problems, we were supposed to place our faith in politics, in mass action, and in cultural change.</p>

  <p>Except then consider what happened with COVID. Our leaders failed to fight the virus effectively, and the President actively sabotaged containment efforts. Culturally, we screeched our heads off about masks and herd immunity and “just the flu” and beach parties and school closings and bar closings and restaurant closings and dorm closings and so on and so forth. We didn’t implement strict lockdowns and we protested against lockdowns and we didn’t even obey the half-assed lockdowns we did implement. We became one of the planet’s worst-hit countries, despite having the planet’s most expensive health care system. We died in the red states, we died in the blue states. We died in droves, in hundreds of thousands. Collectively, as a society, we wrung our hands and ran in circles and screeched and died and screeched and died and screeched and died until scientists made vaccines against the virus.</p>
</blockquote>

<p>Is this correct? In some ways, Smith stacks the deck in his favor. Scientific breakthroughs on vaccines can be produced by small groups of experts insulated from public pressure and the clown show of 21st century American politics. This was never the case with non-pharmaceutical interventions, even if I share Smith’s sense out of outrage and horror over America’s failed response to COVID.</p>

<p>Comparing them is a little akin to comparing World War II’s military-technical research achievements to the great campaigns of Europe and the Pacific War. The latter required extensive political and organizational coordination on a hitherto unprecedented scale, and buy-in from millions of ordinary people. The former were not exactly a bunch of eggheads in a seminar room, but they represent at least crudely processes that are largely autonomous from the need to attain large-scale consensus and cooperation.</p>

<p>Come next year, when we enter into the challenge of rolling out vaccines while preserving basic social distancing measures, we will get a reminder of how different these two kinds of activities are. I’m more optimistic that next year will be significantly better than 2020 was, but only guardedly. However, Smith is also on to something larger when he notes the dubious framing of how the answer to engineering our way to nirvana is supposed to be large-scale political and cultural change driven by mass popular mobilization.</p>

<p>‘Political solution’ in this framing seems to be a euphemism for either a deliberative process that harmonizes competing views or (more often) the imposition of one’s will on the body politic via political struggle. Neither look particularly promising in a polarized society in which merely putting on a piece of cloth held together with string has become a <a href="https://www.pewresearch.org/politics/2020/06/25/republicans-democrats-move-even-further-apart-in-coronavirus-concerns/">partisan issue</a>. Moreover, Smith <a href="https://www.bloomberg.com/opinion/articles/2019-10-17/california-is-back-on-the-brink-of-being-a-failed-state">observes elsewhere</a> that even in my home state of California – where GOP opposition has been virtually eradicated – single-party dominance has failed to resolve basic governance issues.</p>

<p>Certainly most thoughtful critics of techno-determinism likely will say that they aren’t categorically against the use of technology, but rather criticize a particular mindset that uncritically postulates that objective solutions can be discovered to objectively framed problems and then objectively implemented and accepted by a mostly cooperative public. However, it is hard to tell if they are talking about the technologists or themselves when they make this criticism. Statements like “if only we had the political will” to do something of interest are just as naive as “if only we had the right app.”</p>

<p>Technologists are often criticized for wanting to ‘route around’ the US political system, but <a href="https://www.pewresearch.org/fact-tank/2019/07/22/key-findings-about-americans-declining-trust-in-government-and-each-other/">given</a> low institutional trust and increasingly low interpersonal trust, it is difficult to be entirely critical of that desire. The biggest problem with it is that it often devolves into fantasies of taking one’s toys and exiting into an autonomous space free of the need to gain mass consensus (seasteading!) or instituting impersonal mechanisms that suppress political resistance (make the AI president!) There are idiots. Look around. But we’re all idiots in some shape or form and we’re stuck with each other. What do we do next?</p>

<p>First, somewhat of a meta-point: indirection often is a very underrated way of creating change. Part of what this post is looking to encourage is something I sometimes refer to as the “Andrew Marshall style” of change. For decades, Marshall headed up the Office of Net Assessment (ONA) within the United States Department of Defense. Most people interested in defense and strategy, including yours truly, have in some way directly or indirectly benefited from ONA and its projects. But Marshall did so largely below the radar.</p>

<p>Demanding only autonomy, a tiny (by Pentagon standards) budget, a small office, and the freedom to report directly to the Secretary of Defense, Marshall at first glance took a rather counter-intuitive approach. But this was actually critical to his success. He was not a threat to other people’s bureaucratic rice bowls. But he preserved his own autonomy. And by slowly building up a network of relationships and becoming a hub for innovative work, ONA ended up exercising a profound influence on American national security and defense.</p>

<p>What is remarkable about Marshall’s success is that he propagated his particular institutional relationships forward through decades of changing political, economic, and bureaucratic turmoil while slowly altering the surrounding environment around him. It would be ridiculous to assert that Marshall is singularly responsible for any particular major shift in American national security and defense, but it is also very evident that ONA’s presence and persistence changed the boundary conditions of the US defense and security system.</p>

<p>While many technologists often valorize another Cold War American defense icon – John Boyd – Marshall is also a model worth emulating. Technology is complicated, frustrating, and more often than not disappointing relative to our ambitions. But it can change the boundary conditions of problems. Tweaking the boundary conditions of problems is a big part of how meaningful change can happen overall.</p>

<p>Getting 2-3 promising vaccines in under a year is a great example. Vaccines do not change the massive amount of political and institutional failures America has experienced since the COVID-19 outbreak began. However, consider the alternative world without vaccines that we were in only a short time ago. We had all of those problems but without any kind of roadmap as to how we might escape them. Now we have a <a href="https://www.forbes.com/sites/carlieporterfield/2020/11/15/heres-when-experts-say-things-could-get-back-to-back-to-normal-after-coronavirus/?sh=3f66c9d936ed">hazy but nonetheless meaningful</a> idea of how long it could take to get back to normal, even if there is no really coherent shared idea of ‘normality.’ This is worth celebrating!</p>

<p>Even without a vaccine, we would be much worse off than we are now if everything from the physical network backbone to distributed work solutions did not perform well under significant stress. The Internet, also created originally in part for the purpose of scientific collaboration, enabled scientific researchers around the world to work together at breakneck speed to learn as much as possible about a novel virus and figure out how to attack it. Outside of the US and most <a href="https://www.atlanticcouncil.org/blogs/new-atlanticist/lessons-from-taiwans-experience-with-covid-19/">successfully in Taiwan</a>, governments have also found success in working together with the private sector to manage information flows during the pandemic.</p>

<p>Beyond COVID, what might this mean? Even in the best of times, the <a href="https://texaspolitics.utexas.edu/archive/html/bur/features/0303_02/muddling.html">most</a> we can often accomplish on the most intractable social problems is to <a href="https://texaspolitics.utexas.edu/archive/html/bur/features/0303_02/muddling.html">muddle through</a>. They have <a href="https://link.springer.com/article/10.1007/BF01405730">no inherent point</a> at which they officially stop being problems, and often no inherently correct shared framing. It doesn’t mean that action is pointless, but true students of politics often understand that politics is a secular activity instead of a means of bringing about religious salvation.</p>

<p>It seems unwise to stake our hopes on some kind of decisive reckoning at which political solutions will somehow materialize and then be imposed on our friends, neighbors, and co-workers. Much for the same reason that many of us find that we cannot get even members of our own family to take sensible COVID precautions no matter how much we plead, cajole, and threaten them. Still, we have also seen what happens when we simply stand still and do nothing.</p>

<p>“Techno-scientific” changes in the surrounding environment can do a number of salient things. They can provide tools we did not have before to mitigate problems. They can subtly influence or even shift the dynamics of particular interpersonal and institutional relationships and interactions. New frontiers to explore can distract people that otherwise would make trouble, and a bigger pie can make people feel more generous than they otherwise would be. While much has been made of the costs of technological disruption, breaking up established social hierarchies can be necessary for the system as a whole to survive and grow.</p>

<p>Preventing stasis and injecting more slack into the system are both means to the same end: propagating the system forward into the future. So technological “solutionism” (a term I have always disliked due to its imprecision), is both more and less important than ever. It certainly falls short of the hopes of its biggest boosters and the fears of its opponents. But if you are a technologist looking to make a difference now is as good of a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aelkus.github.io/theory/2020/12/03/solu.html">https://aelkus.github.io/theory/2020/12/03/solu.html</a></em></p>]]>
            </description>
            <link>https://aelkus.github.io/theory/2020/12/03/solu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25328149</guid>
            <pubDate>Mon, 07 Dec 2020 00:40:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Procedurally Generated Music Is Awful]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25327533">thread link</a>) | @mproud
<br/>
December 6, 2020 | https://devlog.groovelet.com/p/procedurally-generated-music-is-awful | <a href="https://web.archive.org/web/*/https://devlog.groovelet.com/p/procedurally-generated-music-is-awful">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>"I don't think that this could ever create something that I wouldn't mute" </p><p><em>- Voxel, laying down the hard truths about music generation in general and my music generator in specific</em></p></blockquote><p>In groovelet32.exe, I’d like for the art assets to be capable of wiggling and booping in time with the music. </p><p>That’s seemingly simple sounding, but that simple idea contains, uh, <em>multitudes</em>.</p><p>This can be accomplished in one of a few different ways: </p><ol><li><p>Buy, commission, or write music, transcribe the music whole into the execution environment and play the music with locally available music generation tools (Tone.js in JavaScript, Helm or wwise in Unity) </p></li><li><p>Buy, commission, or write music, transcribe important moments in written music into software language, have instrument hits trigger effects.</p></li><li><p>Buy, commission, or write music, use automated analysis (Koreographer in Unity) to guess when dynamics are occcuring in the music and use those to trigger effects.</p></li><li><p>Buy, commission, or write music, output music as midi, play music while using midi engine to drive effects. </p></li><li><p>Generate music entirely in place, have instrument hits directly trigger effects.</p></li></ol><p>Each strategy has its ups and downs. Notably, the first four strategies start with the simple-sounding but imposing “buy, commission, or write music”. Buying music - well, it’s hard to build a whole game around stock music - especially if music is as fundamental to the experience as it should be in a game about musical robots. </p><p>Commissioning music is simply too expensive, if I’m planning on paying my composer fairly (which I would be, if I had any money).</p><p>Writing music on my own would imply a strong upgrade in my own personal music production skills, because currently I’m operating at somewhere near the “Three Blind Mice” level. A number of my family members are talented musically - my younger brother married into a “music teacher” family - but I don’t think any of them have ever cracked open a <a href="https://en.wikipedia.org/wiki/Digital_audio_workstation">DAW</a>, and they’re pretty busy with their own lives, so that’s a hard tree to shake and expect that video-game ready tunes will fall out.</p><p>So that leaves me with <strong>procedurally generated music</strong>. It’s perhaps naive to think that I, a person who can’t even write a regular song, could build a computer that could write music for me, but hey - if I’m good at anything¹ , it’s programming.</p><h2>A Basic Architecture for Procgen Music</h2><p>Some time back, I watched this inspiring JSConf talk: </p><p id="youtube2-_0ij8vY2gzE" data-attrs="{&quot;videoId&quot;:&quot;_0ij8vY2gzE&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/_0ij8vY2gzE?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><em>so cool</em></p><p><strong>tl;dr</strong> “we built a tool called <a href="https://magenta.tensorflow.org/js-announce">Magenta.js</a> that allows you to tensorflow up some tunes”</p><p>I like tensorflow! I like tunes!</p><p>Setting upon the task with some zeal I managed to get Magenta.js generating tunes, slowly. I had a simple plan for how I would take slowly-generated 8-second tunes and convert them into longer songs:</p><ol><li><p>Have a background server process generate 8-second three-part-tune clips</p></li><li><p>Use some basic heuristics to guess at the key signature (“C# major”) of the clips, evaluate their intensity (lots of drum hits? loads of notes?) and save them in a huge clip database.</p></li><li><p>Create a search interface for the clip database.</p></li><li><p>Have the client request clips from the server in a specific key and intensity.</p></li><li><p>Weave two or three clips together, repeating them a couple of times, to make a full “song”.</p></li><li><p>Add tools to control the requested key signature, intensity, and change instrument, tempo, and what-have-you at the last second.</p></li><li><p>Take the output and make it sound like real human music that people would listen to on purpose.</p></li></ol><p>Now, there are some definite problems with this scheme. One of them is <a href="https://tonejs.github.io/">Tone.js</a> - an unbelievably powerful synth workbench written for people who have read<a href="http://msp.ucsd.edu/techniques/latest/book-html/"> the entire book on Digital Signal Processing</a>, and <em>no other people</em>.</p><p>I actually took and passed a senior-level course in DSP for music generation, some 12 years ago. I have less of an excuse than the average person to be absolutely garbage at attaching oscillators to things. I’m still garbage, mind you, I just have less of an excuse.</p><p>Anyways, after some serious effort, I got steps 1-6 working.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png&quot;,&quot;height&quot;:749,&quot;width&quot;:624,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41766,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Look at that! Sliders! Tempo! Intensity! Configurable per-channel instruments and levels! </p><div><p>Here’s the first song that ever sounded remotely passable, produced by the system.</p><p>It’s… <em>okay</em>, right? Not <em>bad</em>. That’s where the system was a year ago.</p></div><p>Here’s another song from just a few days ago: </p><div><p>Admittedly, I haven’t been working on the procgen engine for that entire year, but it hasn’t evolved much in the interim, huh?</p><p>I figured I might be able to shape the musicality of the output with simple heuristic rules and adjustments and embellishments, but - I can’t. An extremely talented musician/producer might be able to, but as we’ve established, I’m worse at finding C than <a href="https://www.youtube.com/watch?v=VCr91EwGGxk">the salty pirates of landlocked Saskatchewan</a>. </p></div><p>Most of my clever changes would make the output sound better… some of the time. And worse, some of the time. Sometimes, rarely, the system produces something that, if you weren’t paying a terrible lot of attention, you might confuse for real music. A lot of the time it produces something bland and amusical. About as often it produces something <em>actively unpleasant</em>.</p><p>One idea I’ve had is building an underlying voting system to try to clear “bad” tunes out of the system - if my music generation system is actually powered by a thousand clips that sound pretty good under most any circumstances because all of the ones that sound bad have been downvoted out of existence, well, that’s one way of doing things.</p><p>But even at it’s best, the output isn’t… terribly good. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp&quot;,&quot;height&quot;:577,&quot;width&quot;:534,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:138006,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><p>And a big part of the problem is just that composing music is <em>hard</em>. If you take the simplest musical style that you can think of, there’s someone online explaining in painful detail that the soundtrack to Fart Chalice IV <em>actually</em> takes advantage of phrygian pentameter and post-modern phrasing to create artificial dissonance between the fourth and sixteenth notes in an alternating jazz-inspired progression.</p><p>I can just <em>barely</em> read music. I can’t deal with that! </p></div><p>There isn’t a simple set of rules for what will sound good when music is involved - people are too different from one another. There are dozens of conflicting sets of rules, and because there are so many ways to break those rules and still have music come out sounding good (or follow the rules and still have music come out sounding bad) a lot of music theory isn’t so much “helpful guidelines” as it is “endless taxonomy”, and most of that taxonomy has been compiled over the last 500 years by mostly Germans and Italians.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg&quot;,&quot;height&quot;:960,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:125325,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><em>I am literally more afraid of music theory than digital signal processing.</em></p><h2>The Many Flaws of Procedural Generation</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg&quot;,&quot;height&quot;:500,&quot;width&quot;:331,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41426,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I love this book. I’ve read it cover-to-cover, more than once. Even the chapter on music generation - the author cleverly chose a scheme where they fudged it by picking a pentatonic scale where everything sounds pretty nice together and then bonking around pretty-much randomly. (A lot of procedurally generated/input driven music uses a technique like this).</p><p>It’s packed with cool ideas involving graphs and rules engines and a bunch of stuff that gets me actively excited. One of the contributing authors uses the term “gestalt” a few too many times.</p><p>A big part of the book was just talking about <strong>when</strong> to use procedural generation.</p><p>I’d summarize the book’s answer as “if you’re reading this, less than you imagine”.    </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/bc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp&quot;,&quot;height&quot;:529,&quot;width&quot;:910,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:9114,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><em>this, for example, is probably too big a promise, unless they mean just the clouds</em></p><p>The benefits of generated content are obvious. Infinite content - even infinite bland content, is still <em>infinite</em>. This is why people still go to buffet restaurants - unlimited bad food is still pretty compelling. </p><p>So, some of the problems of procgen:</p><ul><li><p>If you restrict the output-space too aggressively, your procgen output will feel bland and samey. <em>When I restricted the output of my music generator using too many Music Theory rules, it could only produce like, 6 different songs, which all felt very bland and similar.</em></p></li><li><p>If you don’t restrict the output-space enough, your output will feel formless and unfair. <em>When I turned off the Music Theory rules, the amount of garbage output got out of control.</em></p></li><li><p>In order to produce procedurally generated output that’s meaningful, you must understand the problem space very well, and work hard at crafting intelligent rules.</p></li><li><p>It is orders of magnitude more work than just making good output.</p></li></ul><p>Or, to put it bluntly, “<strong>don’t try to procedurally generate something that you can’t already create, dummy</strong>”.</p><p>If I play with the generator long enough, I hit little patches of vaguely almost-listenable music, but most of the time the output is more of a formless mush:</p><p>Even worse, after listening to it for long stretches of time, I’d manage to convince myself that <strong>maybe I actually had something good on my hands</strong> - usually it would take either playing it for Voxel, who <em>knows what music is supposed to sound like</em> - or listening to some actual human-generated music on my own, to remind me that I had been listening to a droning mess of nothing for several consecutive hours and it was starting to melt my brain into a puddle.</p><h2>So, You’re Giving Up, Then?</h2><p>Yeah - maybe not permanently, but sometimes it’s important to know when to throw in the towel. This part of the project has, I think, failed, and it’s reaching the point where more effort is being met with <em>diminishing returns</em>.</p><div><p>I think I’m going to try a new plan from my list - “buy, commission, or write music, output music as midi, play music while using the midi data to silently drive effects”.</p><p>I’ll probably write some basic drum-loop first-fifteen-minutes-of-the-FruityLoops-tutorial jams to get the project off the ground, and then find someone competent to compose music if I ever feel like the project is within biting distance of actually shipping. </p></div><p>Anyways, Groovelet Music Engine, you’ve got one last chance to shine. Play yourself off! Preferably with something a little sad.</p><h2>A Goodbye From the Groovelet Music Engine</h2><p>… god dammit.</p></div></div>]]>
            </description>
            <link>https://devlog.groovelet.com/p/procedurally-generated-music-is-awful</link>
            <guid isPermaLink="false">hacker-news-small-sites-25327533</guid>
            <pubDate>Sun, 06 Dec 2020 23:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Sauerbraten 2020 Edition Released]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25327267">thread link</a>) | @silentmars
<br/>
December 6, 2020 | http://www.sauerworld.org/new-sauerbraten-2020-edition-released/ | <a href="https://web.archive.org/web/*/http://www.sauerworld.org/new-sauerbraten-2020-edition-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div role="main">
<div>
<article id="post-6949" data-id="6949">
<div>
<p>Dear all, we are happy to announce that the long-awaited <strong>Sauerbraten 2020 Edition</strong> is finally available! You can find it on the Sauerbraten homepage (<a href="http://sauerbraten.org/" target="_blank" rel="noopener noreferrer">http://sauerbraten.org/</a>)</p>
<p>The full changelog is here: <a href="http://sauerbraten.org/docs/history.html#_2020_11_29">http://sauerbraten.org/docs/history.html</a></p>
<h3>New Features!</h3>
<ul><li>Almost 200 (yes, 200) new maps!</li><li>A fully configurable HUD gameclock</li><li>Color coded health display</li><li>Teammate health bars for easy communication</li><li>Pickup icons display over players in item modes</li><li>Configurable HUD ammobar</li><li>Explosion brightness can now be changed in-game</li><li>Water quality has been improved</li></ul>
<h3>Game Improvements!</h3>
<ul><li>Update from SDL 1 to SDL 2</li><li>Hold has received an update. The flag counter now does not reset upon dropping the flag, but the time starts to increase back to 20 for every second it is not picked up. The enemy team picking up the flag still resets the counter for your team.</li><li>An improved design for sound radius</li><li>A new, more intelligent spawn system</li><li>The Health Boost mechanic has been redesigned – it lasts only until death and provides +100 health up to 150 for the first pickup, and up to 200 for any subsequent pickups before dying</li></ul>
<h3>Editing Stuff!</h3>
<ul><li>Atmospheric effects</li><li>Multiplayer undo in coop-edit</li><li>vcommands now work without sendmap</li><li>More user friendly editing menus</li><li>Mapmodel menu now previews the mapmodels and their animations</li><li>Texture menu now previews the texture path</li><li>Hundreds of new assets!</li></ul>
<h3>Server and Demos</h3>
<ul><li>Demos can now be named when saving</li><li><code>/seekdemo</code> allows you to fast forward, like <code>/demotime</code> in Community Edition</li><li>Default server has settings for overtime and persistent teams</li><li>Blue armour in Regen Capture can (and should) now be disabled as a server setting</li></ul>
<p>And much, much more!</p>
<p>Happy fragging!</p>

 
</div>
</article>


</div>
</div>
</div>

</div></div>]]>
            </description>
            <link>http://www.sauerworld.org/new-sauerbraten-2020-edition-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25327267</guid>
            <pubDate>Sun, 06 Dec 2020 22:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ad-tech as a bubble overdue for a bursting]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25325974">thread link</a>) | @samizdis
<br/>
December 6, 2020 | https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1669">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
shock doctrine, labor, ad-tech, freakonomics, podcasts, spoken word, bubbles, surveillance capitalism, india, labor, modi, neoliberalism, sovkitsch, paleocomputing, urbex,

Summary:
Ad-tech as a bubble overdue for a bursting; The largest strike in human history; Soviet computing graveyard

URL:
https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/

Title:
Pluralistic: 06 Dec 2020 surveillance-tulip-bulbs

Bullet:
🧦

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/), Slashdot (https://slashdot.org/).

--><br>
<a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/"><img src="https://i2.wp.com/craphound.com/images/06Dec2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/06Dec2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">Ad-tech as a bubble overdue for a bursting</a>: Upton Sinclair was an optimist.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#modi-miscalulation">The largest strike in human history</a>: The Shock Doctrine's breaking-point.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#paleocomputing-sovkitsch">Soviet computing graveyard</a>: Recovering a Saratov-2 from presumed extinction.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#retro">This day in history</a>: 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="adtech-bubble"></a><br>
<img src="https://i0.wp.com/craphound.com/images/9780374538651_FC.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/9780374538651_FC.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>In my book "How to Destroy Surveillance Capitalism" I point out that the claims for Big Tech powers of behavior modification powers emanate from the companies' own self-serving boasts pitched to bring in new ad-tech customers.</p>
<p><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
<p>I point to the thinness of the external research on ad-tech's efficacy, and the replication failures of its research foundations on things like "sentiment analysis," "microexpressions" and "Big 5 Personalities" – the whole panoply of digital phrenology.</p>
<p>Meanwhile, there are undeniable, easily measured means by which Big Tech modifies our behavior that don't require us to treat marketing puffery as ground truth.</p>
<ul>
<li>If you want to talk to your friends you have to use Facebook because Mark Zuckerberg is holding them hostage with monopoly tactics
</li>
<li>
<p>Google uses monopoly rents to buy its way to search default on every platform, so the answer to every question you ask comes from Google</p>
</li>
<li>
<p>Apple gets to decide which apps you're allowed to use, who can fix your devices, and when you have to throw them away and buy new ones, thanks to DRM and lavish spending to kill dozens of Right to Repair initiatives</p>
</li>
</ul>
<p>These are mass-scale, persistent behavior modifications that have nothing to do with psychological manipulation and everything to do with economic chicanery.</p>
<p>This week on the Freakonomics podcast, Stephen Dubner turns an economic lens on Big Tech's ad-tech boasts.</p>
<p>He talks to Steve Tadelis, an academic economist who once headed a program at Ebay to evaluate the efficacy of ad spending. First they tried eliminating "brand" advertising (that is, advertising buys for the word "ebay") and found that there was no drop in their revenues.</p>
<p>The logic behind Ebay buying ads for "ebay" is that if they don't, their competitors will, so a search for "ebay" will bring up links to Amazon. That happened…and people scrolled right past the Amazon ads to the "organic" Ebay link below the ads.</p>
<p>But Ebay also buys a bunch of keyword ads for products, like "guitar" or "washing machine" or "picture frame." They estimated 5% of their revenue came from these ads, and that every $1 they spent on them brought in $1.50.</p>
<p>Tadelis designed another experiment and found that these ads were actually responsible for 0.5% of their revenue – an order of magnitude less than their estimate – and that every $1 they spent generated $0.60 in <em>losses</em>. They cut $100m from their ad-spending.</p>
<p>But despite publication of these findings, the world increased its ad-tech spending. Tadelis attributes this to the fact that the major players in ad-tech are all incentivized to repeat the unsubstantiated tale of ad-tech's efficacy.</p>
<p>Ad-tech companies, publishers, and ad-tech buying consultancies are all compromised and unable to objectively assess whether ads work (cue Upton Sinclair: "It's difficult to get a man to understand something when his salary depends on his not understanding it").</p>
<p>And, of course, now Big Tech's critics have joined the ranks of those who insist that ad-tech works with spooky, devastating efficacy.</p>
<p>For evidence, all of them point to how much money the industry generates.</p>
<p>Why would people buy these products if they didn't work? Well, the obvious answer is, "That happens all the time." See:</p>
<ul>
<li>Multivitamins
</li>
<li>
<p>Hedge funds</p>
</li>
</ul>
<p>But there's another answer: "it's a bubble."</p>
<p>A recent, excellent book on the ad-tech bubble is Tim Hwang's SUBPRIME ATTENTION CRISIS:</p>
<p><a href="https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost">https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost</a></p>
<p>Hwang tells Dubner that in a bubble, "the red lights are flashing but everybody in the industry just refuses to take a look at the real data."</p>
<p>Bubbles thrive on opacity and complexity. Think of the 2008 financial crisis, where the lack of transparency in "toxic assets" was compounded by their complexity, which led people – including "sophisticated" regulators and investors – to trust them.</p>
<p>They assumed that the manifest absurdity of the claims made by CDO salespeople must reflect their own ignorance. After all, all those OTHER people wouldn't spend trillions on derivatives if they weren't safe enough to buy yourself and exercise regulatory forbearance over.</p>
<p>But as Hwang points out, the ad-tech market is built on garbage. By Google's own reckoning, 60% of the ads that are charged for are never seen by any human being – literally the majority of the industry's product is a figment of feverish machine imaginations.</p>
<p>While Google's own research (and that of other Big Tech players) show that ad-tech works, independent researchers find the opposite: switching from "behavioral" (surveillance) ads to "contextual" ads only reduces clickthrough by 5%.</p>
<p>Behavioral ad clickthroughs are 0.01-0.03%, and much of that is bot activity.</p>
<p>The industry is opaque and incestuous. Ad agencies – nominally working for advertisers – get massive kickbacks from ad-tech platforms for bringing them business.</p>
<p>Proctor and Gamble – the company that invented the concept of brand ads – tried taking $200m out of its online ad spend and saw <em>zero</em> change in sales.</p>
<p>And yet, ad-tech spending continues to rise.</p>
<p>Hwang says we need a "punk rock" National Bureau of Economic Research, an org that will neutrally measure ad-tech performance and slowly deflate the bubble rather than bursting it, because an ad-tech collapse would kill ad-supported media.</p>
<p>All this is kind of a microcosm for the problems of economics in general. For decades, economics was dominated by the neoclassical idea of "homo economicus," a rational utility maximizer whose bad choices were good, actually.</p>
<p>(That's still the cartoon that undergrads get)</p>
<p>Advertising – especially brand ads – is grounded in the idea that irrationality is universal and exploitable, that you can trick people into paying a 50,000% markup by slapping a logo on a t-shirt.</p>
<p>But advertisers – and the industry – assume <em>they</em> are immune to irrationality, that they don't need to worry that they themselves will be suckered by slick sales-patter from ad tech, or their agencies.</p>
<hr>
<p><a name="modi-miscalulation"></a><br>
<img src="https://i2.wp.com/craphound.com/images/indiastrikedemocracynow2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/indiastrikedemocracynow2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Last week, the largest organized strike in human history shut down India. 250,000,000 people struck against Indian PM Narendra Modi's neoliberal reforms to the agricultural sector.</p>
<p><a href="https://www.democracynow.org/2020/12/3/india_protests_modi_neoliberal_reforms">https://www.democracynow.org/2020/12/3/india_protests_modi_neoliberal_reforms</a></p>
<p>These reforms don't just remove the collective bargaining and price controls that protect the ag sector (which employs more than half the Indian working population), but also stripped multinational corporations and government of liability for harms to their workers.</p>
<p>All this while unemployment is at 27%, and 76% of rural Indians lack the funds to cover their basic nutritional needs. Meanwhile Indian billionaires have increased their wealth by 35% during the pandemic. India's richest man, Mukesh Ambani, has made $12m per <em>hour</em> since March.</p>
<p>The strike didn't just turn out unemployed people and farmers: the turnout was driven by acts of solidarity from ever sector of society.</p>
<p>In his discussion with Amy Goodman on Democracy Now, P Sainath offers some really important political context.</p>
<p>Modi has had a comfortable Congressional majority for two years and has three years left to go in his mandate, so why did he wait for the pandemic to make this far-reaching power-grab?</p>
<p>Sainath: "The reasoning was, these blokes are on their knees now. They can’t organize. They can’t hit back. And in fact, many leading neoliberal intellectuals, economists and journalists, editors, incited the government, saying, 'Never waste a good crisis.'"</p>
<p>It's shock doctrine shit, in other words. But Modi badly misjudged the moment: rather than being beating beyond resistance, Indians have been beaten to the sticking point, and will no longer be fooled by religious bigotry and neoliberal fairy tales.</p>
<p>Right wing movements around the world are grounded in the idea that some people are born to rule and the rest of us are born to be ruled over. Antimajoritarian philosophy isn't compatible with democracy, because it requires sustained turkeys-voting-for-Christmas to survive.</p>
<p>As India shows, the traditional tools of antimajoritarianism – xenophobia, sectarianism, armed violence – are unstable in the long run. Eventually there comes a point when you can't just shout "Muslims are scary!" at starving people and expect them to take that for an answer.</p>
<p>Indians have been slaughtered by both covid and mismanagement. They are at the breaking point. They are rising up.</p>
<hr>
<p><a name="paleocomputing-sovkitsch"></a><br>
<img src="https://i0.wp.com/craphound.com/images/6.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/6.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>In the 1970s, the Soviet Union started to clone DEC's PDP workhorse minicomputers, especially the PDP-8, which was replicated in the USSR as the Saratov-2. Today, the Saratov-2 is a distant memory, with not even a single high-quality photo of the system online.</p>
<p>Until now. Russian urban explorer Ralph Mirebs's photos of a "Soviet Computing Cemetery" (location undisclosed) that features the rotting remains of a Saratov-2 amid the ashes and fire-suppresant residue of a long-ago data-center blaze.</p>
<p><a href="https://rusue.com/cemetery-of-soviet-computers/">https://rusue.com/cemetery-of-soviet-computers/</a></p>
<p>The Saratov-2 was wild: it didn't have a microprocessor; rather, it was broken down into components, each in its own drawer: a 12-bit computing unit, I/O, RAM (ferromagnetic cubes).</p>
<p>Also present in the cemetery: an Electronics 100/25 – the Soviet version of the PDP-11 – and some DVK-2Ms (early personal computers).</p>
<p>The author recalls their own computer science education in 1993, when "one teaching DVK could distribute programs for a couple of dozen Spectrums through the network."</p>
<p>One of my last trips before the crisis hit was my visit to the Computer History Museum's boneyard – a massive warehouse filled …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325974</guid>
            <pubDate>Sun, 06 Dec 2020 19:31:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thought Leaders and Chicken Sexers]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25325716">thread link</a>) | @michael_fine
<br/>
December 6, 2020 | https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>From the moment I started paying attention to the tech industry, Paul Graham was there.  My first job out of college was in SoMa, around the corner from the Justin.tv offices, and his essays were just floating around in the ether, impossible to ignore.  His popularization of Lisp was a small part of why I tried Clojure, and a big part of why Clojure was successful.</p>

<p>I recognized that he had a tendency towards <a href="http://www.paulgraham.com/avg.html">self-aggrandizement</a> and <a href="http://www.paulgraham.com/nerds.html">awkward flattery of his readers</a>, but at worst he seemed harmless.  As his writing became increasingly focused on startups, and I became increasingly sure I didn’t want to be a founder, he simply drifted out of view.</p>

<p>Recently, however, his writing has taken a reactionary turn which is hard to ignore.  He’s <a href="http://www.paulgraham.com/mod.html">written</a> about the need to defend “moderates” from bullies on the “extreme left”, <a href="https://twitter.com/paulg/status/1334441961147822081">asserted</a> that “the truth is to the right of the median” because “the left is culturally dominant,” and <a href="https://pbs.twimg.com/media/EjGX2-bU4AAWkUX?format=jpg&amp;name=medium">justified</a> Coinbase’s policy to ban discussion of anything deemed “political” by saying that it “will push away some talent, yes, but not very talented talent.”</p>

<p>I went back to the essays I had read a decade before, to see if I had missed something.  It turned out that I had.  There was a consistent intellectual framework underpinning all his writing, from his very first essays on Lisp and language design.  In many ways, those early essays contained the clearest articulation of his framework; it just took me ten years to see it.</p>

<hr>

<p>In April 2001, six years after the release of the Java language, Paul Graham weighed in:</p>

<blockquote>
  <p><a href="http://paulgraham.com/javacover.html">I’ve never written a Java program, never more than glanced over reference books about it, but I have a hunch that it won’t be a very successful language.</a></p>
</blockquote>

<p>He followed up with a number of observations about Java, such as the fact that it was designed by committee, infantilizes its users, and owed its initial success to an ailing corporate sponsor.  But, he wrote, this wasn’t an analysis of Java so much as introspection on his own “hacker’s radar”.  This radar was the aesthetic response of an expert programmer, drawn from epiphenomena surrounding the language and the opinions of other experts in his social circle.</p>

<p>A month later, in an essay on why languages are popular, he doubled down on the importance of his personal intuition:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">Programming languages are <em>for</em> hackers, and a programming language is good as a programming language (rather than, say, an exercise in denotational semantics or compiler design) if and only if hackers like it.</a></p>
</blockquote>

<p>The quality of a language can only be judged by experts (“a tiny minority, admittedly, but that tiny minority write all the good software”), and adoption by those experts will drive adoption by everyone else.  Ultimately, “a programming language probably becomes about as popular as it deserves to be.”</p>

<p>The context for both essays was that Graham was creating his own language, <a href="http://www.paulgraham.com/arc.html">Arc</a>.  He wanted it to be popular, and was working out how to make that happen.</p>

<p>The first intrinsic driver of popularity he named was “brevity”:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">It would not be far from the truth to say that a hacker about to write a program decides what language to use, at least subconsciously, based on the total number of characters he’ll have to type.</a></p>
</blockquote>

<p>He called back to this when discussing the importance of libraries, which can reduce any program to a single invocation:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">Of course the ultimate in brevity is to have the program already written for you, and merely to call it. And this brings us to what I think will be an increasingly important feature of programming languages: library functions. Perl wins because it has large libraries for manipulating strings.</a></p>
</blockquote>

<p>It appears that Graham was referring to Perl’s core library functions, not the much larger set of library functions that were even then available via <a href="https://www.cpan.org/">CPAN</a>, because he placed this responsibility wholly upon the shoulders of the language designer, saying language design would become increasingly focused on “how to design great libraries.”</p>

<p>Graham named other drivers of popularity in this essay, but he returned to brevity <a href="http://www.paulgraham.com/langdes.html">again</a> and <a href="http://www.paulgraham.com/power.html">again</a> over the next year, culminating in an essay on the singular importance of brevity, now dubbed “succinctness”:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/power.html">My hypothesis is that succinctness is power, or is close enough that except in pathological examples you can treat them as identical.</a></p>
</blockquote>

<p>Drawing from studies that found “programmers seemed to generate about the same amount of code per day regardless of the language”, he declared that “the only way to get software written faster was to use a more succinct language”.</p>

<p>Nowhere, however, did he mention libraries.  The next month, he explained that given a sufficiently succinct language, users could simply write their own libraries:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/icad.html">As for libraries, their importance also depends on the application. For less demanding problems, the availability of libraries can outweigh the intrinsic power of the language. Where is the breakeven point? Hard to say exactly, but wherever it is, it is short of anything you’d be likely to call an application. If a company considers itself to be in the software business, and they’re writing an application that will be one of their products, then it will probably involve several hackers and take at least six months to write. In a project of that size, powerful languages probably start to outweigh the convenience of pre-existing libraries.</a></p>
</blockquote>

<p>This was a significant departure from his earlier writings.  Only a year before, he had stated that “[i]t’s hard to design good libraries. It’s not simply a matter of writing a lot of code.”  He had emphasized that library design was a key part of language design, and even a year later he would tell us “[d]esign usually has to be under the control of a single person to be any good.”</p>

<p>Now he argued that the language designer only need provide a barebones language of sufficient brevity, and all else would follow.  Library design can’t be both critically important and an incidental part of someone else’s six-month software project.  Despite this, Graham never mentioned libraries ever again.</p>

<p>A year later, he explained that Arc was trying to be a “hundred-year language”.  “It may seem presumptuous,” he wrote, but “[l]anguages evolve slowly because they’re not really technologies. Languages are notation. A program is a formal description of the problem you want a computer to solve for you.”  He asserted the most important part of the language were the “fundamental operators”, because the rest of the language “could in principle be written in terms of these fundamental operators”.</p>

<p>What, then, makes a language ready for the 22nd century?  Certainly not any concerns about performance, since “[e]ven if [computers] only end up being a paltry million times faster, that should change the ground rules for programming languages substantially.”  Not data structures, since they’re just a premature optimization of the humble list.  Not a mechanism (or even notation) for parallel computation, since a simple description of the problem will “ignore any advantages to be got from parallel computation, just as they will ignore advantages to be got from specific representations of data.”</p>

<p>A hundred-year language <em>should</em>, however, be succinct.  First “write down the program you’d like to be able to write, regardless of whether there is a compiler that can translate it or hardware that can run it.”  And of course the program you’d really like to write is the shortest one possible:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/hundred.html">[T]he algorithm for language design becomes: look at a program and ask, is there any way to write this that’s shorter?</a></p>
</blockquote>

<p>“If we had the hundred-year language now,” Graham wrote, “it would at least make a great pseudocode.”  Confusingly, he asserted that since it will need to perform well on its million-times-faster future processor, “presumably it could generate code efficient enough to run acceptably well on our hardware.”</p>

<p>“When you see these ideas laid out like that,” he wrote, “it’s hard not to think, why not try writing the hundred-year language now?”</p>

<hr>

<p>Four years later, in 2008, Arc was released.  It was a <a href="https://en.wikipedia.org/wiki/Common_Lisp#The_function_namespace">Lisp-1</a> with shorter names and fewer parentheses than most other Lisps, and some reader macros to make anonymous functions easier to define.  All primitives were defined in terms of MzScheme, a different Lisp, which provided the compiler and other tooling.  It also came with a barebones web framework which used continuations, reminiscent of the Smalltalk-based <a href="https://en.wikipedia.org/wiki/Seaside_(software)">Seaside framework</a> which had been around since 2002.</p>

<p>It was, in all, underwhelming.  There were many paths that could have led Graham to his professed goals, and he took none of them.</p>

<p>He had written that strings were premature optimization, and should be replaced by lists of characters.  If he had done so, and made the characters full <a href="https://en.wikipedia.org/wiki/Code_point">Unicode code points</a>, Arc could have been one of the few languages not suffering from a half-century hangover stretching all the way back to <a href="https://en.wikipedia.org/wiki/EBCDIC">EBCDIC</a>.  Instead, the initial release used byte strings which only supported the ASCII character set.</p>

<p>Graham had asked “[h]ow many times have you heard hackers speak fondly of how in, say, APL, they could do amazing things with just a couple lines of code? I think anything that really smart people really love is worth paying attention to.”  But the undeniably succinct primitives and composition rules of array programming languages were nowhere to be found.</p>

<p>Server-based deployment of software was a <a href="http://www.paulgraham.com/road.html">central theme</a> in Graham’s essays, and his continuation-based web framework was an interesting and fairly novel way to create continuity across multiple requests in a single session.  But since each link on the page was a continuation, and each continuation was stored in-memory in a single process, this created a single, memory-hungry point of failure.  For years, <a href="https://news.ycombinator.com/news">Hacker News</a> would simply display “unknown or expired link” if you waited too long to click a link.  If Arc had its own runtime, it could have supported …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html">https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html</a></em></p>]]>
            </description>
            <link>https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325716</guid>
            <pubDate>Sun, 06 Dec 2020 19:04:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker's Second Death]]>
            </title>
            <description>
<![CDATA[
Score 287 | Comments 246 (<a href="https://news.ycombinator.com/item?id=25325056">thread link</a>) | @alexellisuk
<br/>
December 6, 2020 | https://www.tariqislam.com/posts/kubernetes-docker-dep/ | <a href="https://web.archive.org/web/*/https://www.tariqislam.com/posts/kubernetes-docker-dep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h3>Docker's Second Death</h3></p><h3 id="feels-like-forever">Feels Like Forever</h3><p>Perhaps not quite forever, but the history with Docker <em>feels</em> really long in good and bad ways. I had joined Red Hat in the summer of 2015, the same summer that OpenShift 3.0 went GA. This was a remarkable event because it marked a redesign of the platform onto Kubernetes which itself had just gone to v1.0 (this is the same timeframe that GKE went GA, if you can believe it’s that old). Like many, I had no clue what Kubernetes or OpenShift were, and I definitely didn’t know much about Docker. I knew <em>of</em> containers. By fall I was neck deep in all three, and in love with the ecosystem a few months after.</p><p>The next spring was my first “real” encounter with Docker Inc. I didn’t attend Red Hat Summit 2016, but I distinctly remember that being the year that Docker really made its first outward antagonistic move against Red Hat OpenShift, at Red Hat’s own event. They were giving out the following shirt:</p><p><img src="https://www.tariqislam.com/images/dockerpatch.jpg" alt="docker-shirt"></p><p>To briefly summarize, this was an attack on Red Hat’s model of backporting patches to older versions of software (also known as “enterprise support”). Red Hat at that time shipped a version of Docker that was just slightly behind the latest cut, whereas Docker shipped their latest. I won’t go into the details of why that matters because there is still a debate today about whether backporting patches is better for an organization versus staying on the latest version of a thing (the latter has gotten considerably better in recent times). This was significant because up until that time, Docker was an integral part of the OpenShift narrative. We sold one with the other and the underlying assumption by most if not all of us was that Docker was just a great tech. In retrospect, this should have been expected as Docker Inc. started making its moves into the enterprise space and suddenly stopped being just great tech.</p><h3 id="it-was-inevitable">It Was Inevitable</h3><p>The early platform wars, as I call them, were primarily focused around OpenShift, Docker, and Pivotal. Pivotal had made significant inroads into enterprise organizations early on, and for good reason: the platform experience was pretty great. Couple that with Pivotal Labs and you had some pretty good mojo. Docker was the up and comer. It was the industry darling making a splash and it had the tech that everyone wanted or that everyone was already using. Kubernetes was still a bit of a question mark. I spent a lot of my time talking to organizations about the nuts and bolts of Kubernetes and why it mattered, or more accurately: why it should matter to them. The move by Docker to knock on OpenShift forced Red Hat messaging to over-index on Kubernetes and Linux over and above anything else. It worked and the industry caught up.</p><p>Docker, still in its industry darling state, responded quickly with Docker Swarm but never really caught on. Swarm was eventually overwhelmed (pun intended) by the uptake of Kubernetes across the industry, and this was when it died the first time: it lost the platform wars and became the very first commodity in the cloud native ecosystem. The second half of 2016 is really when Kubernetes edged out Swarm. This was made evident by the keynote demo at DockerCon 2017 in the following Spring when the presenters showcased Docker’s integration with Kubernetes on the big stage. Notably, that was the last “big” DockerCon that made a splash. From there on out, it was the Kubernetes/CNCF show.</p><h3 id="docker-debt">Docker Debt</h3><p>In all this time, Docker was always an integral part of Kubernetes. This was the relationship:</p><p><img src="https://www.tariqislam.com/images/dockershim.png" alt="dockershim"></p><p>And for the last 19 releases, that chain is what has been supported in Kubernetes. All that just to spin up a pod with a container in it. Docker went from necessity to technical debt. And out of all that, the community laboured until now where Docker will be deprecated in the next release of 1.20. The community has (rightfully) carried the technical debt of Docker for years to ensure the industry had what it needed for the most seamless experience given the ubiquity of the docker daemon. Here is what’s been around for a little while, but will be officially prime time in 1.20 and beyond:</p><p><img src="https://www.tariqislam.com/images/withoutdocker.png" alt="withoutdocker"></p><p>It’s a great simplification, and a return to consistency. To help visualize why this was necessary, I encourage you to view Docker as a platform abstraction on top of containers which are just an aggregate of some Linux constructs. Part of this abstraction involved an integration between the docker platform and containerd, the latter of which lives on today as arguably the most popular container runtime. Docker was never the runtime. Docker simply made containerd and other Linux constructs easy to work with so that container management would be a breeze. Instead of a dozen lines of code to create and deploy a running container, all you needed was:</p><pre><code>docker run
</code></pre><p>But like any platform, that convenience comes with a lot of bloat and technical debt. Especially over time. The removal of docker and the optimization of containerd marks a cultural shift of sorts for the cloud native landscape. None of this is meant to dismiss Docker Inc. Kubernetes today would not be where it is without Docker Inc. That’s a fact. The technologies and the competition that Docker Inc drove were some of the best things to ever happen to the industry. Now as far as turning a profitable business model out of open source technology goes, Docker Inc will likely be studied as a cautionary flash in the pan. Still, it’s important that we separate out the company’s contributions versus its business model. What’s left of the Docker platform, at this point, are its shadows within Kubernetes platforms. Though it does live on strongly within CI/CD ecosystems and, ostensibly, the inner loop of development thanks to the de facto standard Dockerfile. It is a testament to the power that Docker Inc once had, that its technology lived on far beyond the obsolescence of the company until community innovation caught up to it. With all the years of bloat baked into the platform, it’s really just a matter of time before other areas to the left of the platform shed the debt of the Docker daemon.</p><p>While it had an amazing journey and an indelible impact to the industry, practically speaking Docker is dead and dying.</p></div></div>]]>
            </description>
            <link>https://www.tariqislam.com/posts/kubernetes-docker-dep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325056</guid>
            <pubDate>Sun, 06 Dec 2020 17:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speaker Snitch tells you when your smart speaker is listening in on you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25324440">thread link</a>) | @nickbild
<br/>
December 6, 2020 | https://www.hackster.io/nickbild/speaker-snitch-26a642 | <a href="https://web.archive.org/web/*/https://www.hackster.io/nickbild/speaker-snitch-26a642">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><h3 id="toc-speaker-snitch-0"><span>Speaker Snitch</span></h3><p><span>How can you </span><em>really</em><span> know when your smart speaker is listening and sending data to the cloud? There have been </span><a href="https://content.sciendo.com/view/journals/popets/2020/4/article-p255.xml?language=en" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;documented cases &quot;,&quot;href&quot;:&quot;https://content.sciendo.com/view/journals/popets/2020/4/article-p255.xml?language=en&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">documented cases </a><span>in which up to a minute of speech has been transferred to the cloud without a wake-word having been spoken.</span></p><p>Speaker Snitch can give an absolute answer to this question by sniffing local network traffic and flashing a light sitting next to the speaker any time there is traffic between the speaker and the vendor's cloud service.</p>
<h3 id="toc-how-it-works-1"><span>How It Works</span></h3><p>A Raspberry Pi computer promiscuously sniffs packets on the local network. A Python script parses these packets, looking for any communication between the smart speaker and the vendor's cloud service. When detected, an API endpoint on an Arduino Nano 33 IoT microcontroller development board is accessed. This causes an LED attached to the Arduino to flash, thus alerting you to a speaker sending data to the vendor.</p><p>A single Raspberry Pi can trigger alerts on a number of Speaker Snitch devices all throughout your home.</p>
<h3 id="toc-use-2"><span>Use</span></h3><p><span>Packet parsing and control of the Speaker Snitch devices is handled by a simple </span><a href="https://github.com/nickbild/speaker_snitch/blob/main/snitch.py" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;Python script.&quot;,&quot;href&quot;:&quot;https://github.com/nickbild/speaker_snitch/blob/main/snitch.py&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">Python script.</a><span> From the Raspberry Pi, the script is launched with:</span></p><p><code>sudo tcpdump -U -i wlan0 host [SPEAKER IP ADDRESS] | stdbuf -o0 python3 -u snitch.py</code></p><p>For example:</p><p><code>sudo tcpdump -U -i wlan0 host 192.168.1.196 | stdbuf -o0 python3 -u snitch.py</code></p><p><span>The Arduino devices are controlled by </span><a href="https://github.com/nickbild/speaker_snitch/tree/main/speaker_snitch_alert" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;this sketch.&quot;,&quot;href&quot;:&quot;https://github.com/nickbild/speaker_snitch/tree/main/speaker_snitch_alert&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">this sketch.</a></p><h3 id="toc-media-3"><span>Media</span></h3><p>YouTube: </p><p>Speaker Snitch, top: </p>
<p>Speaker Snitch, angle: </p>
<p>Raspberry Pi 3 B+: </p>
<h3 id="toc-bill-of-materials-4"><span>Bill of Materials</span></h3><ul><li>1 x Raspberry Pi 3 B+ (or similar)</li><li>1 x Arduino Nano 33 IoT</li><li>1 x NeoPixel RGB LED</li><li>1 x Battery pack (for Arduino)</li><li>Miscellaneous wires</li></ul><h3 id="toc-about-the-author-5"><span>About the Author</span></h3><p><a href="https://nickbild79.firebaseapp.com/#!/" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;Nick A. Bild, MS&quot;,&quot;href&quot;:&quot;https://nickbild79.firebaseapp.com/#!/&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">Nick A. Bild, MS</a></p></div></div>]]>
            </description>
            <link>https://www.hackster.io/nickbild/speaker-snitch-26a642</link>
            <guid isPermaLink="false">hacker-news-small-sites-25324440</guid>
            <pubDate>Sun, 06 Dec 2020 16:20:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf 2020 Talks]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25324311">thread link</a>) | @AlexeyBrin
<br/>
December 6, 2020 | https://emacsconf.org/2020/talks/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/talks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p><a href="https://emacsconf.org/2020/emacsconf-2020.m3u">Download an .m3u playlist</a></p>

<p>EmacsConf 2020 was on November 28 (Sat) and November 29 (Sun), 2020 from 9am-5pm Toronto/EST time; equivalently, 6am-2pm PST, 2pm-10pm UTC, 3pm-11pm Zurich/CET.</p>

<p>Many of the talks include accompanying material such as slides, questions, and notes. When present, these material are included or linked to on the talk page.</p>

<table><thead><tr><th>Duration</th><th>Title</th><th>Speakers</th></tr></thead><tbody><tr><td colspan="3">Talks</td></tr>
<tr><td colspan="3">NOVEMBER 28 (Saturday)</td></tr>
<tr><td>7:04</td><td><a href="https://emacsconf.org/2020/talks/00">Day 1 opening remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier</td></tr><tr>
</tr><tr><td>3:58</td><td><a href="https://emacsconf.org/2020/talks/01">Emacs News Highlights</a></td><td>Sacha Chua</td></tr><tr>
</tr><tr><td>24:15</td><td><a href="https://emacsconf.org/2020/talks/02">An Emacs Developer Story: From User to Package Maintainer</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>14:50</td><td><a href="https://emacsconf.org/2020/talks/03">Idea to Novel Superstructure: Emacs for Writing</a></td><td>Bala Ramadurai</td></tr><tr>
</tr><tr><td>8:26</td><td><a href="https://emacsconf.org/2020/talks/04">Music in Plain Text</a></td><td>Jonathan Gregory</td></tr><tr>
</tr><tr><td>29:50</td><td><a href="https://emacsconf.org/2020/talks/05">Bard Bivou(m)acs - Building a bandcamp-like page for an album of music</a></td><td>Grant Shangreaux</td></tr><tr>
</tr><tr><td>13:41</td><td><a href="https://emacsconf.org/2020/talks/06">Trivial Emacs Kits</a></td><td>Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>22:05</td><td><a href="https://emacsconf.org/2020/talks/07">Beyond Vim and Emacs: A Scalable UI Paradigm</a></td><td>Sid Kasivajhula (countvajhula)</td></tr><tr>
</tr><tr><td>17:19</td><td><a href="https://emacsconf.org/2020/talks/08">Building reproducible Emacs</a></td><td>Andrew Tropin (abcdw)</td></tr><tr>
</tr><tr><td>47:08</td><td><a href="https://emacsconf.org/2020/talks/21">On why most of the best features in eev look like 5-minute hacks</a></td><td>Eduardo Ochs (edrx)</td></tr><tr>
</tr><tr><td>14:09</td><td><a href="https://emacsconf.org/2020/talks/09">Orgmode - your life in plain text</a></td><td>Rainer König</td></tr><tr>
</tr><tr><td>8:18</td><td><a href="https://emacsconf.org/2020/talks/10">Lead your future with Org</a></td><td>Andrea</td></tr><tr>
</tr><tr><td>15:18</td><td><a href="https://emacsconf.org/2020/talks/11">the org-gtd package: opinions about Getting Things Done</a></td><td>Aldric</td></tr><tr>
</tr><tr><td>16:38</td><td><a href="https://emacsconf.org/2020/talks/12">One Big-ass Org File or multiple tiny ones?  Finally, the End of the debate!</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>12:05</td><td><a href="https://emacsconf.org/2020/talks/13">Experience Report: Steps to "Emacs Hyper Notebooks"</a></td><td>Joseph Corneli, Raymond Puzio, and Cameron Ray Smith</td></tr><tr>
</tr><tr><td>19:41</td><td><a href="https://emacsconf.org/2020/talks/14">README-Driven Design</a></td><td>Adam Ard</td></tr><tr>
</tr><tr><td>25:00</td><td><a href="https://emacsconf.org/2020/talks/15">Moving from Jekyll to OrgMode, an experience report</a></td><td>Adolfo Villafiorita</td></tr><tr>
</tr><tr><td>21:56</td><td><a href="https://emacsconf.org/2020/talks/16">Org-roam: Presentation, Demonstration, and What's on the Horizon</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>21:15</td><td><a href="https://emacsconf.org/2020/talks/17">Org-mode and Org-Roam for Scholars and Researchers</a></td><td>Noorah Alhasan</td></tr><tr>
</tr><tr><td>21:26</td><td><a href="https://emacsconf.org/2020/talks/18">Org-roam: Technical Presentation</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>8:13</td><td><a href="https://emacsconf.org/2020/talks/19">Sharing blogs (and more) with org-webring</a></td><td>Brett Gilio</td></tr><tr>
</tr><tr><td>22:50</td><td><a href="https://emacsconf.org/2020/talks/20">OMG Macros</a></td><td>Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>15:47</td><td><a href="https://emacsconf.org/2020/talks/40">Day 1 closing remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier, Corwin Brust</td></tr><tr>
</tr><tr><td colspan="3">NOVEMBER 29 (Sunday)</td></tr>
<tr><td>11:47</td><td><a href="https://emacsconf.org/2020/talks/41">Day 2 opening remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier</td></tr><tr>
</tr><tr><td>5:07</td><td><a href="https://emacsconf.org/2020/talks/38">Emacs development update</a></td><td>John Wiegley</td></tr><tr>
</tr><tr><td>29:06</td><td><a href="https://emacsconf.org/2020/talks/22">Powering-up Special Blocks</a></td><td>Musa Al-hassy</td></tr><tr>
</tr><tr><td>43:54</td><td><a href="https://emacsconf.org/2020/talks/23">Incremental Parsing with emacs-tree-sitter</a></td><td>Tuấn-Anh Nguyễn</td></tr><tr>
</tr><tr><td>20:46</td><td><a href="https://emacsconf.org/2020/talks/24">Analyze code quality through Emacs: a smart forensics approach and the story of a hack</a></td><td>Andrea</td></tr><tr>
</tr><tr><td>9:52</td><td><a href="https://emacsconf.org/2020/talks/25">Traverse complex JSON structures with live feedback</a></td><td>Zen Monk Alain M. Lafon</td></tr><tr>
</tr><tr><td>53:38</td><td><a href="https://emacsconf.org/2020/talks/39">NonGNU ELPA</a></td><td>Richard Stallman</td></tr><tr>
</tr><tr><td>14:57</td><td><a href="https://emacsconf.org/2020/talks/26">Emacs as a Highschooler: How It Changed My Life</a></td><td>Pierce Wang</td></tr><tr>
</tr><tr><td>21:26</td><td><a href="https://emacsconf.org/2020/talks/27">State of Retro Gaming in Emacs</a></td><td>Vasilij "wasamasa" Schneidermann</td></tr><tr>
</tr><tr><td>1:09:00</td><td><a href="https://emacsconf.org/2020/talks/28">Welcome To The Dungeon</a></td><td>Erik Elmshauser and Corwin Brust</td></tr><tr>
</tr><tr><td>(combined with previous)</td><td><a href="https://emacsconf.org/2020/talks/29">Pathing of Least Resistance</a></td><td>Erik Elmshauser and Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>11:30</td><td><a href="https://emacsconf.org/2020/talks/30">A tour of vterm</a></td><td>Gabriele Bozzola (@sbozzolo)</td></tr><tr>
</tr><tr><td>16:50</td><td><a href="https://emacsconf.org/2020/talks/31">Lakota Language and Emacs</a></td><td>Grant Shangreaux</td></tr><tr>
</tr><tr><td>23:57</td><td><a href="https://emacsconf.org/2020/talks/32">Object Oriented Code in the Gnus Newsreader</a></td><td>Eric Abrahamsen</td></tr><tr>
</tr><tr><td>39:16</td><td><a href="https://emacsconf.org/2020/talks/33">Maxima a computer algebra system in Emacs</a></td><td>Fermin MF</td></tr><tr>
</tr><tr><td>22:22</td><td><a href="https://emacsconf.org/2020/talks/34">Extend Emacs to Modern GUI Applications with EAF</a></td><td>Matthew Zeng</td></tr><tr>
</tr><tr><td>16:02</td><td><a href="https://emacsconf.org/2020/talks/35">WAVEing at Repetitive Repetitive Repetitive Music</a></td><td>Zachary Kanfer</td></tr><tr>
</tr><tr><td>36:29</td><td><a href="https://emacsconf.org/2020/talks/42">Day 2 closing remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier, Corwin Brust</td></tr><tr></tr></tbody></table>




</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/talks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25324311</guid>
            <pubDate>Sun, 06 Dec 2020 16:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust makes cross compilation child's play]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25323560">thread link</a>) | @susam
<br/>
December 6, 2020 | https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/ | <a href="https://web.archive.org/web/*/https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<h2 id="why-do-i-care-about-this">Why do I care about this</h2>

<p>Recently I solved <a href="https://github.com/dandavison/delta/issues/396">this</a> delta issue,
where the maintainer asked to switch from Travis CI to GitHub actions.</p>

<p>These are all the pull requests I’ve done if you want to have a look at this journey:
<a href="https://github.com/dandavison/delta/pull/399">#399</a>, <a href="https://github.com/dandavison/delta/pull/400">#400</a>,
<a href="https://github.com/dandavison/delta/pull/409">#409</a>, <a href="https://github.com/dandavison/delta/pull/411">#411</a>,
<a href="https://github.com/dandavison/delta/pull/413">#413</a>, <a href="https://github.com/dandavison/delta/pull/417">#417</a>
and finally <a href="https://github.com/dandavison/delta/pull/418">#418</a>.</p>

<p>And yes..As you can see I like small incremental work and early feedback instead of giant pull requests. 😁</p>

<p>Anyway, the delta project has a lot of compilation targets and the binaries are automatically released in the
GitHub releases <a href="https://github.com/dandavison/delta/releases">page</a> every time the project is tagged. Sweet. 😌</p>

<p><img src="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/delta.png" alt="delta releases" title="Releases"></p>

<p>From an x86_64 architecture (TLDR: common 64 bit Intel or AMD processors) it is really straightforward to
compile for a different operating system with <code>cargo</code> if you are targeting the same architecture.
For example if you want to compile for macOS you just need to run:</p>

<pre><code>rustup target add x86_64-apple-darwin
cargo build --target x86_64-apple-darwin
</code></pre>

<p>The problems start to arise when you want to compile for a different architecture, such as i686 (32 bit) or ARM processors.
In this case, you have to install some dependencies and set some environment variables, which may be painful.
For example, in the old continuous integrations scripts of delta,
<a href="https://github.com/dandavison/delta/blob/15d06cbf7584570ec3b5beaba99cb8898f9ec3dc/etc/ci/before_install.sh">this</a>
was the way dependencies were installed. Ugly, I know. As rust developers we are used to great tools,
so there must be a better way right?</p>

<h2 id="meet-cross">Meet Cross</h2>

<blockquote>
<p>“Zero setup” cross compilation and “cross testing” of Rust crates.</p>
</blockquote>

<p>This is the description of the <a href="https://github.com/rust-embedded/cross">Cross</a> tool.</p>

<p>The TLDR is that it let you compile and test rust projects for architectures other than i686 and x86_64.</p>

<p>Instead of doing <code>cargo build --target &lt;YOUR_TARGET&gt;</code> you simply do <code>cross build --target &lt;YOUR_TARGET&gt;</code>.
Based on the target, in fact, cross will run a docker image that has all the right dependencies already
installed and configured by the rust-embedded team itself. 😉
And that’s it..just run <code>cargo install cross</code> and you are ready to cross-compile for all
<a href="https://github.com/rust-embedded/cross#supported-targets">these</a> targets in rust, no other dependency
is required, except docker of course!</p>

<p>Obviously this was not an exhaustive overview about cross and I encourage you to have a look at the GitHub page
if you are interested.</p>

<h2 id="cross-in-github-actions">Cross in GitHub actions</h2>

<p>Of course, after a whole morning getting mad trying to setup weird ubuntu dependencies for the delta issue,
when I found out about cross I felt very stupid for not knowing it in advance and I tried to integrate it in the
Continuous Deployment delta pipeline.</p>

<p>It turns out that this is like the easiest thing in the world! The <a href="https://github.com/actions-rs/cargo">action-rs/cargo</a> action
I was already using had built-in <a href="https://github.com/actions-rs/cargo#cross-compilation">support</a> for cross.
Now I even felt more stupid, but anyway..you just need to set the <code>use-cross</code> variable to <code>true</code> and you are done!</p>

<p><a href="https://github.com/dandavison/delta/blob/e198c0d841d9fb660e59e0329235a8601b407c69/.github/workflows/cd.yml#L32-L37">This</a>
is the step that builds the whole delta project for all its different targets..easy, right? 😀</p>

<h2 id="cross-in-rust-github-template">Cross in Rust GitHub template</h2>

<p>You may or (probably) may not be aware of <a href="https://rust-github.github.io/">Rust GitHub Template</a>.</p>

<blockquote>
<p>Rust GitHub Template is a template for cargo generate that aims to be a starting point suitable for the vast majority of rust projects that will be hosted on GitHub.</p>
</blockquote>

<p>Beyond all its nice goodies, this template will setup Continuous Deployment for you, therefore whenever
you tag your project, it will be published on <code>crates.io</code> and the binaries will be released in the GitHub Releases page,
just like in delta. 😁</p>

<p>Until today, Rust GitHub template only supported x86_64 windows, linux and mac, but after I found out Cross I couldn’t resist
and I added support for i686 and aarch64 linux architectures, which are both two <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">tier 1</a> rust targets.
In practice, this means your “old thinkpad” and “raspberry pi” users will thank you a lot. 😛</p>

<p><img src="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/rust-gh.png" alt="gh template releases" title="Releases"></p>

<p><a href="https://github.com/rust-github/rust-gh-example/blob/01e0aae91f83e1e932f4498a0eddb2905c8fffc3/.github/workflows/cd.yml#L57-L63">This</a>
is an example of the resulting Continuous Deployment step.</p>

<p>And that was it, after I spent a lot of <em>very useful</em> time trying to setup compilation dependencies basically I just wanted to share my love for the <code>cross</code>
tool with the rest of the world in order to avoid this pain to as many people as possible. 😅</p>

<p>Thanks for reading this far! You can find me on <a href="https://twitter.com/MarcoIeni">twitter</a> or <a href="https://www.youtube.com/MarcoIeni">YouTube</a>, bye! 👋</p>

  </div></div>]]>
            </description>
            <link>https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323560</guid>
            <pubDate>Sun, 06 Dec 2020 14:11:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-Driving Cars with Duckietown: Learning Autonomy on the Jetson Nano]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25323435">thread link</a>) | @ArtWomb
<br/>
December 6, 2020 | https://www.duckietown.org/mooc | <a href="https://web.archive.org/web/*/https://www.duckietown.org/mooc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section data-id="1b90ddb2" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="5f45efba" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}" data-element_type="section">
<div>
<div>
<div data-id="44184fe1" data-element_type="column">
<div>
<div>
<div data-id="56f50bc1" data-element_type="heading.default">
<div>
<h2>The Duckietown Massive Online Open Course</h2>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="7257d191" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="3f17e26e" data-element_type="column">
<div>
<div>
<section data-id="5f5f08f5" data-element_type="section">
<div>
<div>
<div data-id="2a891138" data-element_type="column">
<div>
<div>
<div data-id="6e068eec" data-element_type="text-editor.default">
<div>
<div>
<p>The Duckietown Foundation presents the first <b>hardware based massive online open course (MOOC) in AI and robotics: “Self-driving cars with Duckietown”</b>, free on edX.</p>
<p>Learn autonomy hands-on by making real robots take their own decisions and accomplish broadly defined tasks. Step by step from the theory, to the implementation, to the deployment in simulation as well as on Duckiebots.</p>
<p>Leverage the power of the new NVIDIA’s Jetson Nano powered Duckiebot to see your algorithms come to life!</p>
</div></div>
</div>
</div>
</div>
</div>

</div>
</div>
</section></div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6430b354" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="30390fb8" data-element_type="column">
<div>
<div>
<section data-id="26e3c22d" data-element_type="section">
<div>
<div>
<div data-id="47641e95" data-element_type="column">
<div>
<div>

<div data-id="3a9d956c" data-element_type="icon-list.default">
<div>
<ul>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Name: Self-driving cars with Duckietown</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Start: February 2021</span>
									</li>
<li>
					<a href="https://www.edx.org/course/self-driving-cars-with-duckietown">						<span><br>
							<br>
						</span><br>
										<span>Platform: edX</span><br>
											</a>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Cost: free to attend</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Instructors:<br>
Swiss Federal Institute of Technology in Zurich (ETHZ),<br>
Université de Montréal (UdM),<br>
Toyota Technological Institute at Chicago (TTIC)</span>
									</li>
</ul></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>
</div>
</div>
<div data-id="4b76852" data-element_type="column">
<div>
<div>
<section data-id="585e3d9" data-element_type="section">
<div>
<div>
<div data-id="a83ae57" data-element_type="column">
<div>
<div>

<div data-id="7a50f136" data-element_type="icon-list.default">
<div>
<ul>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Basic Linux, Python, Git</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Elements of linear algebra, probability, calculus</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Elements of kinematics, dynamics</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Computer with native Ubuntu installation</span>
									</li>
</ul></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>
</div>
</div>
<div data-id="70e2b69" data-element_type="column">
<div>
<div>
<section data-id="75a50f3" data-element_type="section">

</section>
<div data-id="e239b41" data-element_type="icon-list.default">
<div>
<ul>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Computer Vision</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Robot operations</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Object Detection</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Onboard localization</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Robot Control</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Planning</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Reinforcement Learning</span>
									</li>
</ul></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6b005adf" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}" data-element_type="section">

</section>
<section data-id="1b3409a" data-element_type="section">
<div>
<div>
<div data-id="660d899" data-element_type="column">
<div>
<div>
<div data-id="3f7c8d3" data-settings="{&quot;speed&quot;:750,&quot;slides_per_view&quot;:&quot;1&quot;,&quot;show_arrows&quot;:&quot;yes&quot;,&quot;pagination&quot;:&quot;bullets&quot;,&quot;autoplay&quot;:&quot;yes&quot;,&quot;autoplay_speed&quot;:5000,&quot;loop&quot;:&quot;yes&quot;,&quot;pause_on_interaction&quot;:&quot;yes&quot;,&quot;space_between&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:10},&quot;space_between_tablet&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:10},&quot;space_between_mobile&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:10}}" data-element_type="testimonial-carousel.default">
<div>
<div>
<div>
<div>
<div>
<div>
<div>
<p>
						“I’m thrilled that ETH, with UMontreal, the Duckietown Foundation, and the Toyota Technological Institute in Chicago, are collaborating to bring this course in self-driving cars and robotics to the 35 million learners on edX. This emerging technology has the potential to completely change the way we live and travel, and the course provides a unique opportunity to get in on the ground floor of understanding and using the technology powering autonomous vehicles.”					</p>
</div>
<div>
<p><img src="https://www.duckietown.org/wp-content/uploads/2020/10/anant-1.jpeg" alt="Anant Agarwal">
					</p>
<p>								<cite><span>Anant Agarwal</span><span>Founder and CEO of edX,  Professor at the Massachussetts Institute of Technology (MIT)​</span></cite>			</p></div>
</div>
</div>
<div>
<div>
<div>
<p>
						“The new NVIDIA Jetson Nano 2GB is the ultimate starter AI computer for educators and students to teach and learn AI at an incredibly affordable price. Duckietown and its EdX MOOC are leveraging Jetson to take hands-on experimentation and understanding of AI and autonomous machines to the next level.”					</p>
</div>
<div>
<p><img src="https://www.duckietown.org/wp-content/uploads/2020/10/talla.jpeg" alt="Deepu Talla">
					</p>
<p>								<cite><span>Deepu Talla</span><span>Vice President and General Manager of Edge Computing at NVIDIA</span></cite>			</p></div>
</div>
</div>
<div>
<div>
<div>
<p>
						“The Duckietown educational platform provides a hands-on, scaled down, accessible version of real world autonomous systems. Integrating NVIDIA’s Jetson Nano power in Duckietown enables unprecedented access to state-of-the-art compute solutions for learning autonomy.”					</p>
</div>
<div>
<p><img src="https://www.duckietown.org/wp-content/uploads/2020/10/emilio-2-1.jpeg" alt="Emilio Frazzoli">
					</p>
<p>								<cite><span>Emilio Frazzoli</span><span>Professor at the Swiss Federal Institute of Technology in Zurich (ETHZ)​</span></cite>			</p></div>
</div>
</div>
</div>



</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="5da441a" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="d824e20" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="3632c2b8" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="79390ce6" data-element_type="column">
<div>
<div>
<div data-id="6be6d720" data-element_type="image.default">
<div>
<p><img width="480" height="259" src="https://www.duckietown.org/wp-content/uploads/2020/10/ezgif.com-gif-maker-1-1-1-2.gif" alt="">											</p>
</div>
</div>
<div data-id="30b88b59" data-element_type="text-editor.default">
<div>
<p><b>Robot Perception</b>: Duckiebots detect lane marking on the fly and use mathematical models of their camera and environment to estimate their position and orientation in the lane.&nbsp;</p></div>
</div>
</div>
</div>
</div>
<div data-id="41466e10" data-element_type="column">
<div>
<div>
<div data-id="3b538f06" data-element_type="image.default">
<div>
<p><img width="480" height="259" src="https://www.duckietown.org/wp-content/uploads/2020/10/duckietown_duckiebot_detection-4712_cropped-1-2.gif" alt="">											</p>
</div>
</div>
<div data-id="6d1ade5e" data-element_type="text-editor.default">
<div>
<p><strong>Duckiebot Detection</strong>: driving in Duckietown is fun but safety should always be paramount. DuckieBots can detect other vehicles and estimate their relative poses to avoid collisions.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="5a0d068c" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="6d62786b" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="4bed0569" data-element_type="column">
<div>
<div>
<div data-id="897e1e0" data-element_type="image.default">
<div>
<p><img width="600" height="338" src="https://www.duckietown.org/wp-content/uploads/2020/10/planning-smaller-1-2.gif" alt="">											</p>
</div>
</div>
<div data-id="77a7938e" data-element_type="text-editor.default">
<div>
<p><strong>Robot Planning</strong>: as Duckietowns grow bigger, smart Duckiebots plan their path in town. Traffic signs at intersections provide landmarks to localize on the global map and determine next turns.</p></div>
</div>
</div>
</div>
</div>
<div data-id="6a7565d5" data-element_type="column">
<div>
<div>
<div data-id="4587f56f" data-element_type="image.default">
<div>
<p><img width="600" height="338" src="https://www.duckietown.org/wp-content/uploads/2020/10/ezgif.com-gif-maker-1-2-2.gif" alt="">											</p>
</div>
</div>
<div data-id="6869aae7" data-element_type="text-editor.default">
<div>
<p><b>Pedestrian detection</b>: there are many obstacles in Duckietown – some move and some don’t. Being able to detect pedestrians (duckies) is important to guarantee safe driving.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="03ac2c5" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="cfaabf3" data-element_type="column">
<div>
<div>
<div data-id="1ab4146" data-element_type="image.default">
<div>
<p><img width="300" height="250" src="https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-300x250.png" alt="" srcset="https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-300x250.png 300w, https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-160x133.png 160w, https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-768x641.png 768w, https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-1024x854.png 1024w" sizes="(max-width: 300px) 100vw, 300px">											</p>
</div>
</div>
</div>
</div>
</div>
<div data-id="e250367" data-element_type="column">
<div>
<div>
<div data-id="1fb98e7" data-element_type="image.default">
<div>
<p><img width="200" height="83" src="https://www.duckietown.org/wp-content/uploads/2020/10/edx-logo-registered-1.png" alt="" srcset="https://www.duckietown.org/wp-content/uploads/2020/10/edx-logo-registered-1.png 200w, https://www.duckietown.org/wp-content/uploads/2020/10/edx-logo-registered-1-160x66.png 160w" sizes="(max-width: 200px) 100vw, 200px">											</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div></div>]]>
            </description>
            <link>https://www.duckietown.org/mooc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323435</guid>
            <pubDate>Sun, 06 Dec 2020 13:49:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Management Strategies: A Compendium of 58 Effective Techniques and Methods]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25323248">thread link</a>) | @Geeflow
<br/>
December 6, 2020 | https://www.focalityapp.com/en/resources/time-management-strategies/ | <a href="https://web.archive.org/web/*/https://www.focalityapp.com/en/resources/time-management-strategies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<div>
						<div>
							<div>

								<!-- ![Goal Setting Questions](/assets/img/goal-setting-questions.jpg) -->
<!-- # Goal Setting Questions:<br> Discover, Prioritize and Refine Goal Ideas -->

<h2>A Compendium of 58 Effective Strategies, Techniques and Methods</h2>
<p><img src="https://www.focalityapp.com/assets/img/mood/glenn-carstens-peters-RLw-UC03Gwc-unsplash.1920.jpg" alt="Time Management Strategies"></p>
<p>Managing your own time is an essential skill in today’s fast-paced world. It's also more challenging than ever. Fortunately, there are many <strong>time management strategies that can help you become organized and efficient</strong>. Use this overview of 58 strategies and techniques to find the ones that work best for you.</p>
<!-- It’s hard to keep track of all the time management strategies out there. Productivity gurus tend to create their own, building on the massive fundus of existing strategies. So to get you ready for the next time someone mentions their favorite but obscure time management technique, here is an exhaustive overview of more than 50 strategies. -->
<h2>Deep Planning</h2>
<!-- <img src="/assets/img/funktionsgrafik-play-store-2019-10-18.jpg" alt="Plan, Reflect, Improve"/> -->
<!-- <img src="/assets/img/values-finder-banner.jpg" alt="Plan, Reflect, Improve" style="max-width: 100%"/> -->
<p><a href="https://www.focalityapp.com/en/time-management-app/"><img src="https://www.focalityapp.com/assets/img/plan-reflect-improve-banner.jpg" alt="Time Management App"></a></p>
<!-- Did we just complain about everybody creating their own time management strategy? Well, obviously it’s all right if we do it, isn’t it? :) -->
<p>Most plans are strictly sequential. When you invariably have to adjust your plan to reality, you have to update the whole lengthy sequence. Time-consuming at best, motivation consuming at worst. With deep planning, you create a simple hierarchy instead.</p>
<p>Think about what you want to achieve this year. Based on that, what do you want to achieve this month? This week? Today? This way you create a long-term strategy and still adjust your plans with little effort.</p>
<!-- At the end of each period, take a step back and reflect. What went well? What not? What can I do differently next time? -->
<p>Curious? Then take a look at <a href="https://www.focalityapp.com/en/time-management-app/">Focality, our time management app</a>. Focality combines deep planning, self-reflection and data-driven insights to let you constantly improve your time management skills.</p>
<h2>The complete list of time management strategies</h2>
<p>Without further ado, here comes the complete list of time management techniques in alphabetic order:</p>
<h3>1-3-5 rule</h3>
<p>For every day, create a list of one big thing, three medium things and five small things that you want to accomplish this day. This brings clarity into your workday and helps not to get buried by an endless flood of to-do items.</p>
<h3>2-Hour Solution</h3>
<p>See Two-Hour Solution.</p>
<h3>2-Minute Rule</h3>
<p>There are two 2-Minute Rules:</p>
<ol>
<li>
<p>If you want to establish a new habit, make sure that it requires no more than 2 minutes in the beginning. Work yourself up from there.</p>
</li>
<li>
<p>In the Getting Things Done methodology (see below), if a task takes only 2 minutes or less, then do it right away instead of organizing it.</p>
</li>
</ol>
<h3>10-Minute Rule</h3>
<p>If you are putting something off, force yourself to do it for just 10 minutes. Chances are that you will continue past the 10 minutes.</p>
<h3>18 Minutes</h3>
<p>Start your day by planning what you will do that day for 5 minutes. Every hour, take one minute, review your progress and refocus. At the end of the day, take 5 minutes to reflect and evaluate your day.</p>
<h3>4Ds of Time Management</h3>
<p>This method helps you to quickly decide what to do with a task. Either Do it, Defer it, Delegate it or Drop it.</p>
<h3>7 Minute Life</h3>
<p>Spend 7 minutes in the morning to plan your day. Then another 7 minutes in the evening to reflect. Accompanied by many <a href="https://the7minutelife.com/member-tools/">templates</a>.</p>
<h3>80/20 Rule</h3>
<p>The 80/20 rule, also known as the Pareto Principle, is a rule of thumb that states that 80% of the effect step from 20% of the causes. Applied to time management it means that you can get 80% of the results with just 20% of the work. Getting to 100% will require disproportionately more work. Perfect is the enemy of done.</p>
<h3>90-Minute Rule / 90-Minute Focus Sessions / 90-Minute Solution</h3>
<p>Align your work with your <a href="https://en.wikipedia.org/wiki/Basic_rest%E2%80%93activity_cycle">basic rest–activity cycle</a> by doing focused work for approximately 90 minutes, followed by a 20-minute break. The following article sums it up nicely: <a href="https://medium.com/better-humans/avoid-burnout-and-increase-awareness-using-ultradian-rhythms-5e64158e7e19">Avoid Burnout and Increase Awareness Using Ultradian Rhythms</a></p>
<h3>ABCDE Method</h3>
<p>Created by Brian Tracy, ABCDE is a method for setting priorities. Basically assign each task a priority from A to E. A: Very important, must do. B: Important, should do. C: Nice to do, without consequence if skipped. D: Delegate. E: Eliminate.</p>
<h3>Action Method</h3>
<p>Leave every meeting, workshop or other event with a set of concrete tasks that need to be performed, called “action steps”. These should be kept separately from accompanying information (“reference items”). Everything that can’t / shouldn’t be approached right now becomes a “backburner item” to be possibly revived later. The method was developed by Behance. There used to be an online tool that implemented the action method, but it  was discontinued in 2015.</p>
<h3>Agile Results</h3>
<p>The <a href="http://jdmeier.com/agile-results-on-a-page/">Agile Results</a> technique is heavily inspired by software development frameworks like Scrum. At the beginning of the week, identify three wins that you want to achieve. Each day, identify three wins for that day. Use Fridays to recognize three things that are going well and three things to improve. Accompanied by a set of further practices to improve your time management like 30 day improvement sprints, reference collections and more.</p>
<h3>Autofocus</h3>
<p><a href="http://markforster.squarespace.com/autofocus-system/">Autofocus</a> is a to-do list methodology by Mark Forster which tries to use as little structure as possible. Dump everything in a ruled notebook. Scan your list and work on what stands out for as long as you feel like it. Then cross the item off the list. If you haven’t finished it, add it to the bottom again. Repeat. If you pass through a whole page (except the latest page) without anything standing out, dismiss all items on that page.</p>
<h3>Batching / Time Batching / Task Batching</h3>
<p>Work on batches of similar tasks instead of mixing unrelated ones. It reduces friction by minimizing context switching.</p>
<h3>Biological Prime Time</h3>
<p>Track your energy levels and identify your most energetic times of the day. Schedule your most important work for those times. First described by Sam Carpenter in his book <a href="https://www.goodreads.com/book/show/6019060-work-the-system">Work the System</a>.</p>
<h3>Bullet Journal</h3>
<p>A bullet journal combines to-do list, planning and journaling. The name bullet journal comes from the extensive use of bullet(ish) points to structure and mark information.</p>
<h3>COPE</h3>
<p>The Clear-Organized-Productive-Efficient technique helps you to eliminate low-value activities and prioritize everything so that you can focus on the things with the most impact.</p>
<h3>Don’t break the chain</h3>
<p>See Seinfeld Strategy.</p>
<h3>Eat That Frog</h3>
<p>Tackle the biggest and/or most difficult and/or most disliked task first thing in the morning. Then you won’t waste energy or distract yourself the rest of the day because you are secretly dreading that task. <a href="https://www.briantracy.com/blog/time-management/the-truth-about-frogs/">Eat That Frog</a> was created by Brian Tracy who named it after a quote by Mark Twain: “Eat a live frog first thing in the morning and nothing worse will happen to you the rest of the day.”</p>
<h3>Eisenhower Matrix / Box / Method / Principle</h3>
<p>Former U.S. president Dwight D. Eisenhower used to rate his problems by the two criteria urgency and importance. These criteria are commonly used as axis on a 2x2 matrix with 4 quadrants:</p>
<ol>
<li>Urgent and important</li>
<li>Not urgent and important</li>
<li>Urgent but not important</li>
<li>Not urgent and not important</li>
</ol>
<p>The Eisenhower Matrix helps you to better prioritize your tasks and avoid the urgency trap where you fill your day with everything that’s urgent and neglecting the important.</p>
<h3>Final Version</h3>
<p>Start with a list of tasks. Select the first one on the list. Think about which other task from the list you would rather do. Select that one but remember/mark the first. Repeat until you no longer want to do anything before the currently selected task. Then work on the tasks in this chain - but in reverse order! Once you are done with the chain start the process again with the next open task on the list. Reference: <a href="http://archive.constantcontact.com/fs004/1100358239599/archive/1109511856508.html">The Final Version newsletter</a></p>
<h3>Flowtime Technique</h3>
<p>Work on only one task at a time. When you start, write down the time. Continue working on the task until you feel that you need a break. If you are exhausted or can’t focus anymore, take a break. Write down the stop time. Decide how long this break should be and set a timer for it. Repeat.</p>
<h3>Fresh or Fried</h3>
<p>At the end of the day, when your brain is fried, prioritize your tasks for the next day. Schedule important tasks to the beginning of the day, when your brain is still fresh. Schedule less important or easier tasks towards the later parts of the day when your brain fries again.</p>
<p>Reference: <a href="https://thefyslife.com/article/fresh-or-fried-productivity/">Dominate Your Day With the “Fresh or Fried” Prioritization System</a></p>
<h3>Getting Things Done (GTD)</h3>
<p>Getting Things Done is a famous method created by David Allen. It makes extensive use of to-do lists and techniques to manage them. At its core it employs five basic activities to bring structure to your task management:</p>
<ol>
<li>Capture everything: Don’t keep tasks in your head, write everything down.</li>
<li>Clarify: Make sure all your items are clear and actionable.</li>
<li>Organize: Use categories, priorities and due dates to bring structure to your lists.</li>
<li>Review: Frequently go over your lists. Update priorities, remove outdated items, etc.</li>
<li>Engage: Do it.</li>
</ol>
<h3><a href="https://www.focalityapp.com/en/resources/goal-setting/">Goal Setting</a></h3>
<p>Goal setting is the process of defining what you want to achieve in the long-term (or mid-term). Instead of focusing just on tasks, it helps you getting direction in life. If you don’t have clear goals, you are basically adrift. And you hardly get to where you want to be by accident.</p>
<p>We have compiled an <a href="https://www.focalityapp.com/en/resources/goal-setting/">extensive guide to personal goal setting</a> which will help you to understand the topic in depth. Learn why it is important, what types of goals to set, attributes of well-defined goals and much, much more.</p>
<h3>Inbox Zero</h3>
<p>This strategy focuses on managing your email inbox with maximum efficiency. According to its creator, Merlin Mann, the name Inbox Zero does not refer to the number of emails in your inbox, but “how long it takes to use the inbox”. Basically, you run every incoming email through a short process in which you do one of the following things: Delete, delegate, respond, defer (to do later), do (immediately).</p>
<h3>Ivy Lee Method</h3>
<p>This time management strategy has been created in 1918 by productivity consultant Ivy Lee. He recommends writing down six tasks at the end of each day that you want to accomplish the next day. Order them by importance. Then, on the next day, work your way down the list. At the end of the day, move any uncompleted task to the list for the next day. Repeat.</p>
<h3>Medium Method</h3>
<p>Combine the strengths of digital and paper tools. Chad Hall’s <a href="https://todoist.com/productivity-methods/medium-method">Medium Method</a> employs paper notebooks, post-it notes, a task-management app, an online calendar and a note app.</p>
<h3>MIT: Most Important Tasks</h3>
<p>Write down the most important tasks for the next day. Up to three. At the beginning of the day, focus on those and do nothing else until your MITs are completed.</p>
<h3>MoSCow Prioritization</h3>
<p>Borrowed from requirements management this technique helps you prioritize your tasks. Give each task a priority of …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.focalityapp.com/en/resources/time-management-strategies/">https://www.focalityapp.com/en/resources/time-management-strategies/</a></em></p>]]>
            </description>
            <link>https://www.focalityapp.com/en/resources/time-management-strategies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323248</guid>
            <pubDate>Sun, 06 Dec 2020 13:03:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the preprocessor still needed in C++? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25322891">thread link</a>) | @appehuli
<br/>
December 6, 2020 | https://foonathan.net/2017/05/preprocessor/ | <a href="https://web.archive.org/web/*/https://foonathan.net/2017/05/preprocessor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>

<section>


</section>
</header>
<a id="content"></a>
<p>The C++, eh C, preprocessor is wonderful.</p>
<p>Well, no - it isn’t wonderful.</p>
<p>It is a primitive text replacement tool that must be used to work with C++.
But is “must” really true?
Most of the usage has become obsolete thanks to new and better C++ language features.
And many more features like modules will come soon™.
So can we get rid of the preprocessor?
And if so, how can we do it?</p>
<a id="more"></a>
<p>Much of the preprocessor use is already bad practice:
Don’t use it for symbolic constants, don’t use it for inline functions etc.</p>
<blockquote>
<p>As this gained a lot of traction, let me clarify something:
I’m not advocating for removing the preprocessor with this post.
Some people in the C++ community and many on the standardization committee want to do that, however,
so I wanted to explore the feasibility.</p>
</blockquote>
<p>But there still a few ways it is used in idiomatic C++.
Let’s go through them and see what alternative we have.</p>

<p>Let’s start with the most common usage:
<code>#include</code> a header file.</p>
<h3 id="why-is-the-preprocessor-needed">Why is the preprocessor needed?</h3>
<p>In order to compile a source file, the compiler needs to see the declarations of all functions that are being called.
So if you define a function in one file,
and want to call it in another, you have to declare it in that file as well.
Only then can the compiler generate the appropriate code to call the function.</p>
<p>Of course, manually copying the declaration can lead to errors:
If you change the signature you have to change all declarations as well.
So, instead of manually copying the declarations,
you write them in a special file - the header file,
and let the preprocessor copy it for you with <code>#include</code>.
Now you still need to update all declarations, but just in one place.</p>
<p>But plain text inclusion is dumb.
It can sometimes happens that the same file gets included twice,
which leads to two copies of that file.
This is no problem for function declarations,
but if you have class definitions in an header file,
that’s an error.</p>
<p>To prevent that, you have to use include guards or the non-standard <code>#pragma once</code>.</p>
<h2 id="how-can-we-replace-it">How can we replace it?</h2>
<p>With current C++ features, we can’t (without resorting to copy pasta).</p>
<p>But with the <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4647.pdf">Modules TS</a> we can.
Instead of providing header files and source files,
we can write a module and <code>import</code> that.</p>
<p>If you want to learn more about modules, I highly recommend the <a href="https://www.youtube.com/watch?v=Wjvh127abfw">most recent CppChat</a>.</p>
<h2 id="conditional-compilation">Conditional Compilation</h2>
<p>The second most common job of the preprocessor is conditional compilation:
Change the definitions/declarations by defining or not defining a macro.</p>
<h3 id="why-is-the-preprocessor-needed-1">Why is the preprocessor needed?</h3>
<p>Consider the situation where you’re writing a library that provides a function <code>draw_triangle()</code>
which draws a single triangle on the screen.</p>
<p>Now the declaration is straightforward:</p>
<div><pre><code data-lang="cpp"><span>// draws a single triangle
</span><span></span><span>void</span> <span>draw_triangle</span><span>();</span>
</code></pre></div><p>But the implementation of the function changes depending on your operating system, window manager, display manager
and/or moon phase (for exotic window manager).</p>
<p>So you need something like this:</p>
<div><pre><code data-lang="cpp"><span>// use this one for Windows
</span><span></span><span>void</span> <span>draw_triangle</span><span>()</span>
<span>{</span>
    <span>// create window using the WinAPI 
</span><span></span>    <span>// draw triangle using DirectX
</span><span></span><span>}</span>

<span>// use this one for Linux
</span><span></span><span>void</span> <span>draw_triangle</span><span>()</span>
<span>{</span>
    <span>// create window using X11
</span><span></span>    <span>// draw triangle using OpenGL
</span><span></span><span>}</span>
</code></pre></div><p>The preprocessor helps there:</p>
<div><pre><code data-lang="cpp"><span>#if _WIN32
</span><span></span>    <span>// Windows triangle drawing code here 
</span><span></span><span>#else
</span><span></span>    <span>// Linux triangle drawing code here
</span><span></span><span>#endif
</span></code></pre></div><p>The code in the branch that is not taken will be deleted before compilation,
so we won’t get any errors about missing APIs etc.</p>
<h3 id="how-can-we-replace-it-1">How can we replace it?</h3>
<p>C++17 adds <code>if constexpr</code>, this can be used to replace simple <code>#if … #else</code>:</p>
<p>Instead of this:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>do_sth</span><span>()</span>
<span>{</span>
    <span>#if DEBUG_MODE
</span><span></span>        <span>log</span><span>();</span>
    <span>#endif
</span><span></span>    <span>…</span>
<span>}</span>
</code></pre></div><p>We can write this:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>do_sth</span><span>()</span>
<span>{</span>
    <span>if</span> <span>constexpr</span> <span>(</span><span>DEBUG_MODE</span><span>)</span>
    <span>{</span>
        <span>log</span><span>();</span>
    <span>}</span>

    <span>…</span>
<span>}</span>
</code></pre></div><p>If <code>DEBUG_MODE</code> is <code>false</code>, then the branch will not be compiled properly,
it will only check for syntax errors, similar to the checking done for a not yet instantiated template.</p>
<blockquote>
<p>This is not correct, as was pointed out.
It will still be fully checked if outside a template.
It doesn’t matter here though, as it still doesn’t have any runtime overhead.</p>
</blockquote>
<p>This is even better than <code>#if</code> as it will spot obvious errors in the code without checking all macro combinations.
Another benefit with <code>if constexpr</code> is that <code>DEBUG_MODE</code> can now be a normal <code>constexpr</code> variable,
instead of a constant coming from a macro expansion.</p>
<blockquote>
<p>And if you don’t have <code>if constexpr</code>, you can use class template specializations,
or <a href="https://foonathan.net/blog/2015/11/16/overload-resolution-3.html">tag dispatching</a>.</p>
</blockquote>
<p>Of course, there are downsides to <code>if constexpr</code>:
You can’t use it to constrain preprocessor directives, i.e. <code>#include</code>.
For the <code>draw_triangle()</code> example, the code needs to include the proper system header.
<code>if constexpr</code> can help, so you’d need true conditional compilation there or manually copy the declarations.</p>
<blockquote>
<p>This is better than normally as system header declarations are usually pretty stable.
But it’s still not recommended.</p>
</blockquote>
<p>And modules can’t help either as the system headers do not define any module you can import.
Furthermore, you can’t conditionally import a module (as far as I know).</p>
<h2 id="passing-configuration-options">Passing configuration options</h2>
<p>On a related note, you sometimes want to pass some configuration options to a library.
You might want to enable or disable assertions, precondition checks, change some default behavior…</p>
<p>For example, it might have a header like this:</p>
<div><pre><code data-lang="cpp"><span>#ifndef USE_ASSERTIONS
</span><span></span>    <span>// default to enable
</span><span></span>    <span>#define USE_ASSERTIONS 1
</span><span>#endif
</span><span></span>
<span>#ifndef DEFAULT_FOO_IMPLEMENTATION
</span><span></span>    <span>// use the general implementation
</span><span></span>    <span>#define DEFAULT_FOO_IMPLEMENTATION general_foo
</span><span>#endif
</span><span></span>
<span>…</span>
</code></pre></div><p>When building the library you can then override the macros either when invoking the compiler,
or through CMake, for example.</p>
<h3 id="how-can-we-replace-it-2">How can we replace it?</h3>
<p>Macros are the obvious choice here, but there are is an alternative:</p>
<p>We could use a different strategy to pass options,
like <a href="https://en.wikipedia.org/wiki/Policy-based_design">policy-based design</a>,
where you pass a policy to a class template that defines the chosen behavior.
This has the benefit that it doesn’t force a single implementation to all users,
but of course has <a href="https://foonathan.net/blog/2017/02/08/policy-based-design-problem.html">its own downsides</a>.</p>
<p>But what I’d really like to see is the ability to pass these configuration options when you <code>import</code> the module:</p>
<div><pre><code data-lang="cpp"><span>import</span> <span>my</span><span>.</span><span>module</span><span>(</span><span>use_assertions</span> <span>=</span> <span>false</span><span>);</span>
<span>…</span>
</code></pre></div><p>This would be the ideal replacement for:</p>
<div><pre><code data-lang="cpp"><span>#define USE_ASSERTIONS 0
</span><span>#include</span> <span>"my_library.hpp"</span><span>
</span></code></pre></div><p>But I don’t think that’s technically feasible without sacrificing the benefits modules provide,
i.e. pre-compiling modules.</p>
<h2 id="assertion-macros">Assertion macros</h2>
<p>The macro you’ll most commonly use probably does some kind of assertion.
And macros are the obvious choice here:</p>
<ul>
<li>You’ll need to conditionally disable assertions and remove them so they have zero overhead in release.</li>
<li>If you have a macro, you can use the pre-defined <code>__LINE__</code>, <code>__FILE__</code> and <code>__func__</code> to get the location where the assertion is
and use that in the diagnostic.</li>
<li>If you have a macro, you can also stringify the expression that is being checked and use it in the diagnostic as well.</li>
</ul>
<p>That’s why almost all assertions are macros.</p>
<h3 id="how-can-we-replace-it-3">How can we replace it?</h3>
<p>I’ve already explored how conditional compilation can be replaced and how you can specify whether or not they should be enabled,
so that’s no problem.</p>
<blockquote>
<p>Using policy-based design here also allows customization of how the diagnostic is reported to the user.</p>
</blockquote>
<p>Getting the file information is also possible in the Library Fundamentals TS v2 as it adds <code>std::experimental::source_location</code>:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>my_assertion</span><span>(</span><span>bool</span> <span>expr</span><span>,</span> <span>std</span><span>::</span><span>experimental</span><span>::</span><span>source_location</span> <span>loc</span> <span>=</span> <span>std</span><span>::</span><span>experimental</span><span>::</span><span>source_location</span><span>::</span><span>current</span><span>())</span>
<span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>expr</span><span>)</span>
        <span>report_error</span><span>(</span><span>loc</span><span>.</span><span>file_name</span><span>,</span> <span>loc</span><span>.</span><span>line</span><span>,</span> <span>loc</span><span>.</span><span>function_name</span><span>);</span>
<span>}</span>
</code></pre></div><p>The function <code>std::experimental::source_location::current()</code> expands to the information about the source file at the point of writing it.
Furthermore, if you use it as a default argument, it will expand to the caller location.
So the second point is no problem either.</p>
<p>The third point is the critical one:
You can’t stringify the expression and print it in the diagnostic without using a macro.
If you’re okay with that, you can implement your assertion function today.</p>
<p>But otherwise you still need a macro for that.
Check out <a href="https://foonathan.net/blog/2016/09/16/assertions.html">this blog post</a> how you could implement an (almost) macro-less assertion function,
where you can control the level with <code>constexpr</code> variables instead of macros.
You can find the full implementation <a href="https://github.com/foonathan/debug_assert">here</a>.</p>
<h2 id="compatibility-macros">Compatibility macros</h2>
<p>Not all compilers support all C++ features, which makes porting a real pain,
especially if you don’t have access to a compiler for a testing and need to do the “change a line, push to CI, wait for CI build, change another line” cycle just because some compiler really doesn’t like an important C++ feature!</p>
<p>Anyways, the usual compatibility problems can be solved with macros.
The implementations even define certain macros once they’ve implemented a feature,
making checking trivial:</p>
<div><pre><code data-lang="cpp"><span>#if __cpp_noexcept
</span><span></span>    <span>#define NOEXCEPT noexcept
</span><span></span>    <span>#define NOEXCEPT_COND(Cond) noexcept(Cond)
</span><span></span>    <span>#define NOEXCEPT_OP(Expr) noexcept(Expr)
</span><span>#else
</span><span></span>    <span>#define NOEXCEPT
</span><span></span>    <span>#define NOEXCEPT_COND(Cond)
</span><span></span>    <span>#define NOEXCEPT_OP(Expr) false
</span><span>#endif
</span><span></span>
<span>…</span>

<span>void</span> <span>func</span><span>()</span> <span>NOEXCEPT</span>
<span>{</span>
    <span>…</span>
<span>}</span>
</code></pre></div><p>This allows a portable usage of features even though not all compilers have them already.</p>
<h2 id="how-can-we-replace-it-4">How can we replace it?</h2>
<p>We can’t do that in any other way.
Workaround missing features requires some kind of preprocessing tool to get rid of not-supported features.
We have to use macros here.</p>
<h2 id="boilerplate-macros">Boilerplate macros</h2>
<p>C++’s templates and TMP go a long way to eliminate a lot of boilerplate code you otherwise need to write.
But sometimes, you just need to write a lot of code that is the same but not <em>quite</em> the same:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>less</span>
<span>{</span>
    <span>bool</span> <span>operator</span><span>()(</span><span>const</span> <span>foo</span><span>&amp;</span> <span>a</span><span>,</span> <span>const</span> <span>foo</span><span>&amp;</span> <span>b</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>a</span><span>.</span><span>bar</span> <span>&lt;</span> <span>b</span><span>.</span><span>bar</span><span>;</span>
    <span>}</span>
<span>};</span>

<span>struct</span> <span>greater</span>
<span>{</span>
    <span>bool</span> <span>operator</span><span>()(</span><span>const</span> <span>foo</span><span>&amp;</span> <span>a</span><span>,</span> <span>const</span> <span>foo</span><span>&amp;</span> <span>b</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>a</span><span>.</span><span>bar</span> <span>&gt;</span> <span>b</span><span>.</span><span>bar</span><span>;</span>
    <span>}</span>
<span>};</span>

<span>…</span>
</code></pre></div><p>Macros can generate that boilerplate for you:</p>
<div><pre><code data-lang="cpp"><span>#define MAKE_COMP(Name, Op) \
</span><span>struct Name \
</span><span>{ \
</span><span>    bool operator()(const foo&amp; a, const foo&amp; b) \
</span><span>    { \
</span><span>        return a.bar Op b.bar; \
</span><span>    } \
</span><span>};
</span><span></span>
<span>MAKE_COMP</span><span>(</span><span>less</span><span>,</span> <span>&lt;</span><span>)</span>
<span>M…</span></code></pre></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://foonathan.net/2017/05/preprocessor/">https://foonathan.net/2017/05/preprocessor/</a></em></p>]]>
            </description>
            <link>https://foonathan.net/2017/05/preprocessor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322891</guid>
            <pubDate>Sun, 06 Dec 2020 11:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Programming Is Hard to Fundamentally Improve (2017)]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25322656">thread link</a>) | @mpweiher
<br/>
December 6, 2020 | https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9 | <a href="https://web.archive.org/web/*/https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@aidandcunniffe?source=post_page-----4101612d4ad9--------------------------------" rel="noopener"><img alt="Aidan Cunniffe" src="https://miro.medium.com/fit/c/96/96/1*26JtOGzXJBiOCbDzaKjrWg.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="cb76"><em>and why I’m still trying…</em></p><p id="5880">One of the curious things about being human is the ability to hold two contradictory views simultaneously. When I’m in analysis mode I try to understand what market, technical and social forces have lead to the status quo. To do this effectively, or at least to induce useful principles for later use, you have to believe that things are the way they are for good reasons. As soon as I put my innovator hat on however, I get all jazzed up and think “screw that! X would be so much better if Y”. I’ve learned over the last year that balancing these two perspectives is essential to an inventor.</p><p id="9c7d">This week I watched Bret Victor’s <a href="http://worrydream.com/dbx/" rel="noopener">Future of Programming</a> lecture from July 2013 and it compelled me to put these thoughts down on paper. During the lecture, Bret uses an overhead projector and pretends its 1973. He proudly presents the latest in programming research for the time and explains why it’d be really silly if we aren’t using them in 40 years. To Victor’s credit he remains in character the whole time as he satirically paints the ideal world we’ll soon enter — one the audience knows doesn’t really exist.</p><p id="cbac">The future Bret showed off included direct manipulations of the output (result) instead of the code, programming via constraints/goals, spatial (visual) programming paradigms, and massively parallel programming approaches. Declarative programming, functional programming, microservice architectures and WYSIWYG editors check some of those boxes, but not nearly at the level of their potential. All that being said, there’s no argument against real progress having been made the last 40 years, just not the progress many expected.</p><p id="f16a">So now I’ll put on my analysis hat and work through why the art of programming is so hard to advance beyond its current levels.</p><p id="a3f1">Many blame the lack of advancements on developers. We built shinny thing X, but developers are too arrogant, stubborn, busy, dismissive or all of the above to adopt it. I’ve even heard people accuse developers of selfishly protecting their future job prospects by trying to stifle the adoption of new programming mediums. Heck, I’ve said this before…</p><p id="f628">^ This is just wrong. In my experience developers are very rational beings. Their job is to find the most efficient way of solving problems every single day and if you create a tool that provides that they’ll be all over it. They’ll even volunteer their time to help you build it for free. If you move forward accepting that developers are mostly rational actors and have good reasons for adopting something / not adopting something you can learn a lot to inform future design.</p><p id="33a0">So I did that. I actually sat down with people over the last 3 months and asked them why they failed to adopt a variety of tools. I overwhelmingly got rational explanations to why switching to something new was irrational.</p><h2 id="99cb">Better Hammer Tradeoff</h2><p id="8f1e">Imagine you’re building a log cabin by hand with a bad, but usable hammer. When you’re 90% of the way finished a magical genie comes and offers you a better hammer. Great! But there’s a tradeoff: If you take the new shinny hammer, you have to start the house from scratch…oh and he turns back humanity to the stone age. You can get your new hammer, but you’ll have to do without bandsaws, your pickup truck, and yes, nails.</p><p id="3e8b">What’s the rational choice? Hint, it involves the old hammer.</p><p id="7f24">That parable emerged from summarizing all the interviews I conducted and highlights the frustrations developers have had with many of the new ‘solve all your problems’ tools they’ve tried. For context these tools fit into two categories: new programming languages including some flow &amp; graph based paradigms and no-code visual builders.</p><p id="6a39">There are two areas of value to consider when choosing a programming paradigm: the developer experience of the [language, tooling, GUI] and the strength of the ecosystem (what common problems have been solved already). Many of the new paradigms, while often built on sound principles, miss out on the massive body of work that already exists is language X. How do you weight these two areas when picking your paradigm? 30–70? 90–10? 1–99? Most people I spoke with rated the ecosystem as 2–3x more important than DX.</p><p id="9ab3">Tool-builders usually only focus on DX and [assume, hope, pray] that a community comes along and builds an ecosystem. This still can happens, but it was much much more common in the 90s than it is today. There are network effects in programming and a beautiful virtuous cycle quickly emerges among the most used tools. When a user shares functionality openly it makes paradigm more capable, which attracts new users, who continue to improve that paradigm. Boom! Node module for everything.</p><p id="0b6c">When you look at the languages that have really caught on recently, they tend to share one thing in common: they tap into an existing body of work. Look at TypeScript, the most popular language released after 2000, which interoperates with Javascript. Then there’s Swift, the second most popular language released after 2000. Just imagine where Swift would be today if it hadn’t been interoperable with Objective-C and the Cocoa legacy or if TypeScript’s ecosystem was a blue ocean from day one.</p><p id="272c">There are consequences for tool makers building an entirely new base abstraction, be it visual, text based or otherwise. If you choose not to interoperate with an existing ecosystem, you or your community will need to spend years coming up from the stone age to modernity. Programming is just learning to use a bunch of stacked abstractions. Even if you have an objectively better base abstraction, one that would have clearly won out over everything else had it been introduced in 1992, people will have few incentives to adopt it if there’s no ecosystem.</p><h2 id="749d">Sunk Cost…Sensibility</h2><p id="5881">Most people complete the phrase “Sunk cost _____” with “fallacy”. The classic economics thought experiment usually involves a couple staying at a concert they hate just because they paid face value for the tickets. An enlightened economist would, as the story goes, leave as soon as they became unhappy with the concert and reclaim a few precious hours. But if you had to pay $50k, $50M or $5B to leave the concert early, you’d probably stay. When the switching costs are that high, there’s good reason to stay and the largest employers of programmers in the world have enormous switching costs. This keeps mainstream programmers anchored to the status quo.</p><p id="2c6d">This is another completely rational choice developers make when sticking to the paradigms they know. The combined costs of hiring new people, training, rewriting the code, and the opportunity cost of choosing these actions over improving your product almost always outweigh the benefits of making the change. <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/" rel="noopener">Joel has a classic article about code rewrites that expands on this more.</a></p><p id="ccc1">Young companies without much in the way of legacy or those with no other choice have the luxury of picking new paradigms, but few of these companies end up becoming incumbents. Those who do make it are the kingmakers. Both Facebook and Twitter were first built on technologies that were inadequate for their eventual scale (PHP and Ruby). Facebook became so attached to PHP that they enhanced the language to suit their needs with Hack and other tools. Similarly, Twitter switched over to Scala which one could argue is a key reason for Scala’s mainstream success.</p><h2 id="a2d4">Solving the Least Important Problems</h2><p id="513f">Tool makers must strike a balance between learnability and productivity. A visual programming environment like MIT’s <a href="https://scratch.mit.edu/" rel="noopener">Scratch</a> is incredibly learnable. I’ve seen 4-5 year old kids build games with it after just a few hours. The drag/drop interface and shape based constraints are really easy to learn and prevent Scratch from ever being in a broken state. This is great for kids and individuals trying to learn programming.</p><p id="bb8d">The same things that make Scratch easy to learn also make it an unproductive environment for more serious programmers. For a professional, programming with drag and drop is way slower than keying in code — that’s just a fact.</p><p id="cad2">These tradeoffs must be considered whenever building a new tool. If you build something super learnable that is not productive you’ll get a lot of praise, but little follow through. If you build something that’s too difficult to learn, but very productive you’ll turn a lot of people off. To reach mainstream programmers you need to make something that is both learnable and productive.</p><p id="5100">I think most of the stalled innovations in programming focused disproportionally on learnability. The problem is, within a few weeks of using any paradigm developers usually have built a repository of habits that keep them from making mistakes. For instance, if a new visual logic builder prides itself on preventing all syntax errors, that’s really cool, but most developers have learned to do that automatically.</p><p id="742f">Truth is, every tool you have ever used is flawed and every new tool will also be flawed. Humans subconsciously come up with ways to cope with their tools so they can keep themselves focussed on the bigger conceptual issues. That isn’t going to change anytime soon. If professionals already have habits in place to cope with things that have been made easier/more learnable by new tooling, those new tools do not have much value to them. It’s like offering a 40 year old who’s been driving manual her whole life an automatic car — yeah that’s great, but it’s not needed and she certainly won’t pay a premium for it to be included.</p><h2 id="6e7a">Things Have Been Getting Better</h2><p id="10b2">No good analysis fails to include a few words from the Advocatus Diaboli.</p><p id="e04a">Things have been getting better. The growth has just been in the ecosystems and not the paradigms themselves. We’ve been building this amazing tower of abstraction since the early days of programming that provide really useful abstractions for things like:</p><ul><li id="fb86">Charging a credit card, which has gone from a 20 person team to processor.charge()</li><li id="b32b">Configuring a massive cluster of servers is done with a short text file instead of …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9">https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9</a></em></p>]]>
            </description>
            <link>https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322656</guid>
            <pubDate>Sun, 06 Dec 2020 10:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose Boring Technology]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 188 (<a href="https://news.ycombinator.com/item?id=25322651">thread link</a>) | @amzans
<br/>
December 6, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Note: the ideas in this post have already been covered numerous times in the past. One article that has greatly influenced my perspective over the years is <a href="https://mcfunley.com/choose-boring-technology" target="_blank" rel="noopener">McKinley's Choose Boring Technology</a>. Below I'll explore the topic from my own experience, and how I ended up using Kubernetes for a recent project.</p><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring is less surprising</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>Boring is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit the problem at hand better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Exploit vs explore</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit" target="_blank" rel="noopener">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware it can be overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it works well for me, and I have been running production workloads with it for several years already. Please do not just blindly follow my path. Use what you already know best.</p><p>Kubernetes allowed me to simplify the operational aspects tremendously, and I feel comfortable debugging issues with it after having the pleasure of putting down multiple production fires for my employer over the years. It has also been around several years, there's lots of documentation, and a huge helpful community who can help. It'd argue that there's more documentation available than for any home-grown deployment system, or even EC2/Lambda/DigitalOcean for that matter.</p><p>As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><h2>Let complexity come over time</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322651</guid>
            <pubDate>Sun, 06 Dec 2020 10:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sugar – a typed lispy language targeting webasm/wat]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25322596">thread link</a>) | @marksmillibend
<br/>
December 6, 2020 | https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html | <a href="https://web.archive.org/web/*/https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a href="https://ph1lter.bitbucket.io/index.html">(home)</a> <span>2020-12-06</span>
<p>Despite what I may have said in an earlier post, it's not <em>all</em> that nice to code directly in wat.
So I've started work on a compiler. A very thin compiler. The language should feel very similar to our, beloved, <code>wat</code>, but save us from
typing all those <code>i32.const, local.get</code>.
</p>
<p>Some points up front:
</p>
<ul><li>
the compiler targets <code>WAT</code> (not <code>WASM</code>). This means using <code>WABT::wat2wasm</code>.
</li><li>
not self hosting <span>come on people, I don't even have malloc to play with yet, let alone a buggy, poorly implemented, partial copy of common lisp.</span>
</li><li>
the compiler is written in common lisp (specifically, sbcl). <span>hereinafter CL</span>.
</li><li>
syntax checking is state-of-the-art and errors are output in a readable format (i.e. you will get a cryptic <code>sbcl</code> debug trace if you make the
slightest mistake).
</li><li>
why <strong>sugar</strong>? It was either that or <code>watson, watsup, watsamatta, watulookin</code>. <span>Also cos it's just syntactical sugar, get it?</span>
</li><li>
internet searches are to be done using <code>sugarlang</code> <span>or sugarland if you prefer</span>.
</li><li>
there is no manual; not even mul/div or all the relation operators (e.g. &lt;=) are written yet!
</li><li>
the compiler output is not a standalone executable but a <code>wasm</code> file. The <em>best</em> standalone wasm runtime I've found so far is <code>wasm-interp</code>.
Please don't say node.js. You can say <code>v8</code>, maybe.
</li></ul>
<blockquote><strong>node.js/npm</strong><br>That feeling when ...<br>People say <em>Minimalist System</em><br>Then say "just use npm install ..."<br></blockquote><h2> sugar example</h2>
<p>Here is the <code>malloc.wat</code> example from the previous blog post on webasm re-written in <code>sugar</code>.
It's quite a bit more concise and convenient than the original raw <code>wat</code> (see below).
</p>
<p>(previous post on <code>wat</code>
<a href="https://ph1lter.bitbucket.io/blog/2020-12-03-webasm-forth-with-lisp-syntax.html">/blog/2020-12-03-webasm-forth-with-lisp-syntax.html</a>
)
</p>
<pre>; malloc.sugar - sugar example code
(memory (import "js" "mem") 10)
(import "console" "log" (func js_log (i i32)))
(global memend i32 #x1000)
(global sbrk (mut i32) 0)
; ----- allocate some memory in wasm-space
(defun (export "malloc") (len i32) :result i32
  (locals (i32 (newbrk (+ sbrk len)) (mem sbrk)))
  (if (&gt;= newbrk memend) (return 0))
  (set sbrk newbrk)
  mem)
; ----- write bytes in wasm-space memory using js callback
(defun (export dump_range) (start i32 len i32)
  (locals (i32 i (end (+ start len))))
  (for (i start end)
    (js_log (get.u8* i))))
</pre>
<p>And this is what you would have written if you were coding directly in <code>wat</code>.
</p>
<pre>(module
  (memory (import "js" "mem") 10)
  (import "console" "log" (func $js_log (param $i i32)))
  (global $memend i32  (i32.const 4096))
  (global $sbrk (mut i32)  (i32.const 0))
  ;; ----- allocate some memory in wasm-space
  (func (export "malloc") (param $len i32) (result i32)
    (local $newbrk i32)
    (local $mem i32)
    (local.set $newbrk (i32.add (global.get $sbrk) (local.get $len)))
    (if (i32.ge_u (local.get $newbrk) (global.get $memend))
      (return (i32.const 0)))
    (local.set $mem (global.get $sbrk))
    (global.set $sbrk (local.get $newbrk))
    (local.get $mem))
  ;; ----- write bytes in wasm-space memory using js callback
  (func (export "dump_range") (param $start i32) (param $len i32)
    (local $i i32)
    (local $end i32)
    (local.set $end (i32.add (local.get $start) (local.get $len)))
    (local.set $i (local.get $start))
    (block $break2 (loop $head1
      (br_if $break2 (i32.eq (local.get $i)  (local.get $end)))
      (call $js_log (i32.load8_u (local.get $i)))
      (local.set $i (i32.add  (i32.const 1) (local.get $i)))
      (br $head1)))))
</pre>
<h2> using sugar</h2>
<p>Write a <code>your-source.sugar</code> source file in your favorite text editor. Then run <code>sugar</code> on it to produce <code>your-source.wat</code>
</p>
<p>This is how I use sugar (with a makefile for calling sugar, then wat2wasm):
<a href="https://ph1lter.bitbucket.io/src/sugar.mk">/src/sugar.mk</a>
</p>
<pre>$ mk malloc.wasm
./sugar malloc.sugar &gt;malloc.wat
summary: globals:2 functions:3 macros:2
wat2wasm malloc.wat
</pre>
<p>(see below for installing common lisp)
</p>
<h2> compiler</h2>
<p>The compiler is very small and may be interesting to read, for that reason.
<a href="https://ph1lter.bitbucket.io/src/sugar">/src/sugar</a>
</p>
<p>It includes a macro system, which I have used to implement <code>inc</code> and <code>for</code> but it's not yet available for use from sugar
itself. <span>Also the full CL defmacro/destructuring-bind lambda list syntax is non trivial to replicate; not to mention backquote.</span>
</p>
<h3> compiler structure</h3>
<p>Here is the overall compiler structure
</p>
<pre>loop:
  read a form [from source file]
  (compile form) =&gt; stdout
compile form:
  integer =&gt; (i32.const int)
  symbol =&gt; (local/global.get varname) [check in environment/scope]
  list/s-expr/cons =&gt;
    if (is-macro? form)
      (compile (expand-macro form))
    else:
      is-special? form =&gt; (compile-special form) [defun/import/export/global/set...]
      is-function? =&gt;
        for all args (compile arg)
        call func with args
      otherwise =&gt; error undefined function
</pre>
<h3> common lisp?</h3>
<p>Too many brackets?
</p><blockquote>Rule 1: There are no brackets, only indentation.<br>Rule 0: We suffer the brackets cos it gives us defmacro and that's worth a lot of suffering.<br></blockquote><p>Did you ever generate code? Did you think that was cool? You'll love common lisp. Try it for 2 weeks.
Money back guarantee if not satisfied.
</p>
<h3> value-if</h3>
<p>Lisp has value-IF i.e. you can use IF anywhere you use a value. That's like C's ternary but more powerful.
At first I thought WAT doesn't have it, but (if) has an optional
<code>(result type)</code> clause, like (func) so that it's branches
can return (type matched) values. So you can do clever things like this:
<span>note the (result i32) clause between if and condition.</span></p>
<pre>(set x
  (if (result i32) (&gt;= z limit)
    (comp-true-value y)
    (comp-false-value s 14 q)))
</pre>
<p><code>wat (select)</code> is like the C ternary operator although it can have blocks/statement sequences inside.</p><p>select v if: select has all 3 clauses always evaluated while (if) has only the conditional and the chosen branch evaluated. The other
(if) branch is not evaluated.
</p>
<h2> future directions</h2>
<h3> user accessible macros (defmacro)</h3>
<p>Implement (defmacro ...) for sugar.
</p>
<h3> shortcut and/or</h3>
<p>At the moment I only have the bitwise and/or operators '&amp;' and 'bor' and next on the list is having shortcutting logical <code>and/or</code> operators
like CL.
</p>
<p>Ideally I'd like to have lisp-style <code>and/or</code> where the expression value is
returned rather than just 0 or 1. Also standalone <code>and/or</code> so we can have things like
</p>
<pre>(and (file-existsp fname) (process-file fname))
(or (setup-completep) (error setup-failed))
</pre>
<span>Shortcut <code>and/or</code> actually compile to nested (if) expressions.</span><h3> missing operators/functions</h3>
<p>A whole slew of function counterparts for other types (i64,f32,f64) are missing. The compiler cannot type-infer which one (see below)
so these would have explicit names like <code>+f64, set.f64</code> etc.
</p>
<p>There are many other relops missing etc. They are fairly trivial to add.
</p>
<h3> arrays</h3>
<p>Currently I'm using pointer <code>get*/set*</code> but I'd like to have <code>aref</code> and implicit index to pointer arithmetic.
</p>
<h3> loops</h3>
<p>Some more loops. <code>while repeat</code> etc. The underlying <code>block, loop, br_if, br</code> are exposed so writing loops is possible.
It would only be the case of adding some more macros to enable:
</p>
<pre>(while condition body...)
(forever body...)
</pre>
<p>Also <code>continue, break</code> would be nice.
</p>
<h3> structures / defstruct</h3>
<p>Some kind of struct might be nice to have. Even if all the fields had to be i32 initially i.e. just a vector with named,
instead of numbered, fields.
</p>
<h3> better syntax/semantic checking</h3>
<p>Even the current error messages drop you into the SBCL debugger, which can be a scary place - [<code>ctrl-d</code>] to exit.
</p>
<h3> type tracing</h3>
<p>Knowing the types of values would allow the compiler to check signatures of calls of user functions and builtins.
It would also allow me to infer the correct type for <code>set</code> rather than requiring <code>set.f32</code> etc.
</p>
<h3> LET</h3>
<p>Locals <em>must</em> be defined at the start of a function. This means implementing LET (scoped blocks with local variables) is not trivial.
The current, single-pass, compiler would need to become far more complex to first decide how many locals are required in a function,
then allocate them up-front and possibly rename them if there are clashes.
</p>
<h3> self hosting</h3>
<p>The <em>holy grail</em> of compiler writers is that they rewrite their compiler in their new language. Common Lisp is <em>so far</em> above
the level of <code>wat</code> that this would be a large undertaking. First I'd need to write malloc...
</p>
<h2> installing common lisp</h2>
<p>Setting up sugar/common lisp may be trivial or hard depending on how familiar with common lisp you are :)
</p>
<p>Installing common lisp (I use SBCL) is outside the scope of this post. (Tell me it's harder than npm ...)
</p>
<p>I refer you to [Zach Beane's]
<a href="https://www.quicklisp.org/beta/">https://www.quicklisp.org/beta/</a>
</p>
<p>SBCL might even be in your package manager:
</p>
<pre>$ pacman -Ss sbcl
</pre>
<p><code>sugar</code> is run as a unix script. I've made a custom sbcl core since I prefer <code>iterate</code> over <code>loop</code>.
Here is a very brief explanation of how to make such a core, starting with <em>plain, vanilla</em> sbcl.
</p>
<pre>$ sbcl
* (ql:quickload '#:iterate)
* (sb-ext:save-lisp-and-die "sbcl-iterate")
$ sudo mv sbcl-iterate /usr/share/sbcl/sbcl-iterate
</pre>
<h2> source</h2>
<ul><li>
<a href="https://ph1lter.bitbucket.io/src/malloc.sugar">/src/malloc.sugar</a>
</li><li>
<a href="https://ph1lter.bitbucket.io/src/sugar">/src/sugar</a>
</li></ul>
<h2> mistakes</h2>
<p>[2020-12-07] My original compiler structure had a macro expansion bug. I was misled since I was in a block where I had just checked that
(form) was a consp/list and I assumed this remained true inside that block.
However, I missed the fact that I am modifying the form inside the block, with (expand-macro).
It's possible (expand-macro) returns a non-list e.g. a symbol. Then my list assumptions break.
</p>
<pre>compile form:
  ...
  list/s-expr/cons =&gt;
    while: (is-macro? form)
      form := (expand-macro form) &lt;---- bug: this can change form into a non-list
    is-special? form =&gt; ...
    is-function? =&gt; ...
</pre>
<p>First I fixed this with an extra list check in is-macro and also in the is-special/is-function parts, and a recursive call to compile
for non-list forms.
</p>
<p>I later thought if I had used a functional approach and avoided the mutation, I would not have made this mistake. My visual hint
that I was dealing with a list would have remained true. It turns out the functional solution is even more elegant than the original
and doesn't have the bug (+1 to functional purists).
</p>
<p>The functional solution, doesn't loop, it recurses on compile. Then compile gets the chance to decide again
what type of form expand-macro returned (nested macros …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html">https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html</a></em></p>]]>
            </description>
            <link>https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322596</guid>
            <pubDate>Sun, 06 Dec 2020 10:36:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Peer-to-Peer Git Forges with Radicle]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25322584">thread link</a>) | @todsacerdoti
<br/>
December 6, 2020 | http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html | <a href="https://web.archive.org/web/*/http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Git is a distributed version control system and does not require a central server. Although repositories are usually published at a well-known location for convenient cloning and fetching of the latest changes, this is actually not necessary. Each clone can have the full commit history and evolve independently. Furthermore, code changes can be exchanged via email or other means. Finally, even the clone itself does not need to be made from a well-known domain that hosts a git repository (see <tt>git-bundle(1)</tt>).</p>

<p>Given that git itself is already fully decentralized one would think there is no further work to do. I came across the <a href="https://radicle.xyz/">Radicle</a> project and its somewhat psychedelic website. Besides having a website with a wild color scheme, the project aims to offer a social coding experiment or git forge functionality using a peer-to-peer network architecture. According to the <a href="https://docs.radicle.xyz/docs/what-is-radicle">documentation</a> the motivation seems to be that git's built-in functionality works but is not user-friendly enough to make it accessible. In particular, it lacks social coding features.</p>

<p>The goal is to add git forge features like project and developer discovery, issue trackers, wikis, etc. Additional, distinctly decentralized functionality, is also touched on involving Ethereum as a way to anchor project metadata, pay contributors, etc. Radicle is still in early development so these features are not yet implemented. Here is my take on the <a href="https://radicle.xyz/">How it Works</a> documentation, which is a little confusing due to its early stage and some incomplete sentences or typos. I don't know whether my understanding actually corresponds to the Radicle implementation that exists today or its eventual vision, because I haven't studied the code or tried running the software. However, the ideas that the documentation has brought up are interesting and fruitful in their own right, so I wanted to share them and explain them in my own words in case you also find them worth exploring.</p>

<h2>The git data model</h2>
<p>Let's quickly review the git data model because it is important for understanding peer-to-peer git forges. A git repository contains a <tt>refs/</tt> subdirectory that provides a namespace for local branch heads (<tt>refs/heads/</tt>), local and remotely fetched tags (<tt>refs/tags/</tt>), and remotely fetched branches (<tt>refs/remotes/&lt;remote&gt;/</tt>). Actually this namespace layout is just a convention for everyday git usage and it's possible to use the <tt>refs/</tt> namespace differently as we will see. The git client fetches refs from a remote according to a <i>refspec</i> rule that maps remote refs to local refs. This gives the client the power to fetch only certain refs from the server. The client can also put them in a different location in its local <tt>refs/</tt> directory than the server. For details, see the <tt>git-fetch(1)</tt> man page.</p>

<p>Refs files contain the commit hash of an <i>object</i> stored in the repository's object database. An object can be a commit, tree (directory), tag, or a blob (file). Branch refs point to the latest commit object. A commit object refers to a tree object that may refer to further tree objects for sub-directories and finally the blob objects that make up the files being stored. Note that a git repository supports <i>disjoint</i> branches that share no history. Perhaps the most well-known example of disjoint branches are the GitHub Pages and GitLab Pages features where these git forges publish static websites from the HTML/CSS/JavaScript/image files on a specific branch in the repository. That branch shares no version history with other branches and the directories/files typically have no similarity to the repository's main branch.</p>

<p>Now we have covered enough git specifics to talk about peer-to-peer git forges. If you want to learn more about how git objects are actually stored, check out my article on the <a href="http://blog.vmsplice.net/2016/05/git-internals-of-how-objects-are-stored.html">repository layout and pack files</a>.</p>

<h2>Identity and authority</h2>
<p>Normally a git repository has one or more owners who are allowed to push refs. No one else has permission to modify the refs namespace. What if we tried to share a single refs namespace with the whole world and everyone could push? There would be chaos due to naming conflicts and malicious users would delete or change other users' refs. So it seems like an unworkable idea unless there is some way to enforce structure on the global refs namespace.</p>

<p>Peer-to-peer systems have solutions to these problems. First, a unique identity can be created by picking a random number with a sufficient number of bits so that the chance of collision is improbable. That unique identity can be used as a prefix in the global ref namespace to avoid accidental collisions. Second, there needs to be a way to prevent unauthorized users from modifying the part of the global namespace that is owned by other users.</p>

<p><a href="https://en.wikipedia.org/wiki/Public-key_cryptography">Public-key cryptography</a> provides the primitive for achieving both these things. A public key or its hash can serve as the unique identifier that provides identity and prevents accidental collisions. Ownership can be enforced by verifying that changes to the global namespace are signed with the private key corresponding to the unique identity.</p>

<p>For example, we fetch the following refs from a peer:</p>
<pre>&lt;identity&gt;/
  heads/
    main
  metadata/
    signed_refs
</pre>

<p>This is a simplified example based on the Radicle documentation. Here <tt>identity</tt> is the unique identity based on a public key. Remember no one else in the world has the same identity because the chance of generating the same public key is improbable. The <tt>heads/</tt> refs are normal git refs to commit objects - these are published branches. The <tt>signed_refs</tt> ref points to an git object that contains a list of commit hashes and a signature generated using the public key. The signature can be verified using the public key.</p>

<p>Next we need to <i>verify</i> these changes to check that they were created with the private key that is only known to the identity's owner. First, we check the signature on the object pointed to by the <tt>signed_refs</tt> ref. If the signature is not valid we reject these changes and do not store them in our local repository. Next, we look up each ref in <tt>heads/</tt> against the list in <tt>signed_refs</tt>. If a ref is missing from the list then we reject these refs and do not allow them into our local repository.</p>

<p>This scheme lends itself to peer-to-peer systems because the refs can be propagated (copied) between peers and verified at each step. The identity owner does not need to be present at each copy step since their cryptographic signature is all we need to be certain that they authorized these refs. So I can receive refs originally created by identity A from peer B and still be sure that peer B did not modify them since identity A's signature is intact.</p>

<p>Now we have a global refs namespace that is partitioned so that each identity is able to publish refs and peers can verify that these changes are authorized.</p>

<h2>Gossip</h2>
<p>It may not be clear yet that it's not necessary to clone the entire global namespace. In fact, it's possible that no single peer will ever have a full copy of the entire global namespace! That's because this is a distributed system. Peers only fetch refs that they care about from their peers. Peers fetch from each other and this forms a network. The network does not need to be fully connected and it's possible to have multiple clusters of peers running without full global connectivity.</p>

<p>To bootstrap the global namespace there are <i>seed</i> repositories. Seeds are a common concept in peer-to-peer systems. They provide an entry point for new peers to learn about and start participating with other peers. In BitTorrent this is called a "tracker" rather than a "seed".</p>

<p>According to the Radicle documentation it is possible to directly fetch from peers. This probably means a <tt>git-daemon(1)</tt> or <tt>git-http-backend(1)</tt> needs to be accessible on the public internet. Many peers will not have sufficient network connectivity due to <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a> limitations. I guess Radicle does not expect every user to participate as a repository.</p>

<p>Interestingly, there is a <i>gossip</i> system for propagating refs through the network. Let's revisit the refs for an identity in the global namespace:</p>
<pre>&lt;identity&gt;/
  heads/
    main
  metadata/
    signed_refs
  remotes/
    &lt;another-identity&gt;/
      heads/
        main
        foo
      metadata/
        signed_refs
      remotes/
        ...
</pre>

<p>We can publish identities that we track in <tt>remotes/</tt>. It's a recursive refs layout. This is how someone tracking our refs can find out about related identities and their refs.</p>

<p>Thanks to git's data model the commit, tree, and blob objects can be shared even though we duplicate refs published by another identity. Since git is a <a href="https://en.wikipedia.org/wiki/Content-addressable_storage">content-addressable</a> object database the data is stored once even though multiple refs point to it.</p>

<p>Now we not only have a global namespace where anyone can publish git refs, but also ways to build a peer-to-peer network and propagate data throughout the network. It's important to note that data is only propagated if peers are interested in fetching it. Peers are not forced to store data that they are not interested in.</p>

<h2>How data is stored locally</h2>
<p>Let's bring the pieces together and show how the system stores data. The peer creates a local git repository called the <i>monorepo</i> for the purpose of storing portions of the global namespace. It fetches refs from seeds or direct peers to get started. Thanks to the <tt>remotes/</tt> refs it also learns about other refs on the network that it did not request directly.</p>

<p>This git repository is just a data store, it is not usable for normal git workflows. The conventional <tt>git branch</tt> and <tt>git tag</tt> commands would not work well with the global namespace layout and verification requirements. Instead we can clone a local file:/// repository from the monorepo that fetches a subset of the refs into the conventional git refs layout. The files can be shared because <tt>git-clone(1)</tt> supports hard links to local repositories. Thanks to <tt>githooks(5)</tt> and/or extensible <tt>git-push(1)</tt> remote helper support it's possible to generate the necessary global namespace …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html">http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html</a></em></p>]]>
            </description>
            <link>http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322584</guid>
            <pubDate>Sun, 06 Dec 2020 10:34:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handy tips for staying secure on the go]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322461">thread link</a>) | @henrikwm
<br/>
December 6, 2020 | https://security.christmas/2020/6 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://images.unsplash.com/photo-1517400508447-f8dd518b86db?w=1226&amp;h=400&amp;fit=crop&amp;crop=edges" alt=""><div><section><p>We wrote about <a href="https://security.christmas/2019/21">"Safe travels for the road warrior"</a> last year. This year we offer one more trick, and expand our list for staying safe and secure on the road.</p>
<p>Watch out for shoulder surfers, and protect your equipment if you have to leave it in for example your hotel room.</p>
</section><article><section><p><em>PANDEMIC WARNING: Stay at home if you can. A virus has for the better part of 2020 attacked physical infrastructure (people). We have no patch or hotfix, so while that is being worked out, we advice you to travel as little as possible.</em> </p>
<h2>Shoulder surfers:</h2>
<p>Be aware of your surroundings and reduce the risk of shoulder surfers. A shoulder surfer is someone who is peaking over your shoulder to get information. We can spot people prone to this type of social engineering attack all the time. When people are visiting a cafee, are on public transport, or on air planes they will use their laptop for work stuff. And they don’t notice, or care if someone is looking.</p>
<p>To protect your information, you can, and should invest in a privacy shield for you screen. They cost next to nothing, but reduce/limit the viewing angle of your display.</p>
<p><img src="https://cdn57.androidauthority.net/wp-content/uploads/2019/04/privacy-screen-protector-angle-2.jpg" alt="privacy screen protector"></p>
<p>Reduce the number of apps visible on your computer. On a Mac I recommend that you use <a href="https://www.macbartender.com/">Bartender</a>, but there are Windows and *Nix options as well. The point of this application is that it hides all the running apps from the menu bar, so that it looks like this: </p>
<p><img src="https://i.imgur.com/QsbNjHu.png" alt="a neat menu bar"></p>
<p>rather than this abomination of a menu bar: </p>
<p><img src="https://eshop.macsales.com/blog/wp-content/uploads/2019/05/1password1280.jpg" alt="an untidy and talkative menue bar"></p>
<p>The reason for hiding this information from shoulder surfers is that it reveals many of your attack vector. If someone knows what applications you are running, they know a lot about you. Developer tools, Automator scripts, and a password manager? You presumably work in IT. Bluetooth enabled, an old version of Outlook and a TorrentClient? The bad guys already have tools for these applications.  </p>
<h2>Mikado security</h2>
<p>The other tip is to not leave your computer laying around. This may seem obvious, but there are times when this is impossible. There will be events where you have super secret stuff on your computer, and must step away for a period of time. For instance in a hotel room while you are away for an hour, or go to a resturant.</p>
<p>If an adversary has physical access to your device, they can do all sort of damage. <a href="https://www.theregister.com/2013/12/11/poker_pros_call_shenanigans_over_hotel_malware_infections/">A poker player had this happen to him</a>, where someone broke into his hotel room to install malware on his laptop. This is only one of the cases, but we suspect there are many more based on  the fact that hotel room locks are <a href="https://youtu.be/-Bazy3Ew6D4">ridiculously insecure</a>, and <a href="https://youtu.be/RX-O4XuCW1Y">easy to bypass</a>.<br>
So to combat this problem, we have devised a nice little trick to help you stay safe if you have to leave your device behind.</p>
<p><img src="https://live.staticflickr.com/5475/9350249910_6aeb4b5d85_h.jpg">
<a href="https://flic.kr/p/ffftxm">Mikado</a> by <a href="https://www.flickr.com/photos/kobakpontorg/">Balazs Koren</a>, on Flickr</p>
<p>Mikado (also known as “pick-up sticks game”) is a game where players drop a bundle of sticks as a loose bunch onto a table top. Each player in turn tries to remove a stick from the pile without disturbing any of the others.</p>
<p>MikadoSecurity is where you spread the sticks over the object that you want to protect. You then take a picture of it, and when you return, you can verify that no one has tampered with your device.
In the event that the sticks are not as you left them, you can escalate the problem. Either to do forensics, or discard the computer if you need to.</p>
<p>This trick relies on the same principles as we rely on for computer security. Prime number factoring, traveling salesman problem and SAT are hard to solve if P != NP, but easy to verify.
An example of this is a sudoku board. It is hard for both humans and computers to solve, but if I hand you a board, it is easy for you to verify if I did it correct. </p>
<p><img src="https://i.imgur.com/fibOzob.png" title="Hard to solve / Easy to verify"></p></section></article></div></article><section><ul><li></li><li></li><li></li></ul></section></main></div></div>]]>
            </description>
            <link>https://security.christmas/2020/6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322461</guid>
            <pubDate>Sun, 06 Dec 2020 10:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Good Patterns Go Bad: The False Positive Regex]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25322343">thread link</a>) | @jsnell
<br/>
December 6, 2020 | https://blog.donbowman.ca/2020/12/04/when-good-patterns-go-bad-the-false-positive-regex/ | <a href="https://web.archive.org/web/*/https://blog.donbowman.ca/2020/12/04/when-good-patterns-go-bad-the-false-positive-regex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3099" itemscope="" itemtype="https://schema.org/CreativeWork"><div><p><img width="795" height="485" src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png" alt="When Good Patterns Go Bad: The False Positive Regex" loading="lazy" itemprop="thumbnailUrl" srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png 795w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-768x469.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-150x92.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-450x275.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-600x366.png 600w" sizes="(max-width: 795px) 100vw, 795px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png" data-lazy-srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png 795w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-768x469.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-150x92.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-450x275.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-600x366.png 600w"></p><div itemprop="text"><p>I once worked for a company that used regular expression matching (pattern matching) on network traffic. A big source of angst was the amount of “unknown traffic”, things which matched no patterns. Our sales team wanted this less. Our customers wanted it less. Our competitors had less. Why couldn’t we?</p><p>I used to answer this question as follows. “You know, I can put in one bad pattern, that mis-matches, a false positive. The amount of unknown will go down. Will that make it better? I can make 0% unknown right now.”. Interestingly, some would agree with the statement “sure, lets do that”. Some would say “don’t be ridiculous, I want 100% known, and 0% incorrect.”. I would answer the last question as “what if you made your own proprietary protocol, the license-plate protocol. You, and only you use it. The data in the stream is ciphered from your license plate. Would you expect a pattern for that?”. They would usually say no, I would then point out that 0% unknown as a false goal, the real goal was 0% incorrectly known and as much known as feasible. Still didn’t stop the competitor from using weak false positives to get to higher <code>known</code> amount.</p><p>Yesterday I received an email from the good people at Google. They are launching a new document leakage tool. It scans your shared documents for sensitive things (emails, medical, that sort of thing). Mine is below. Its alarming. 7% of my shared files contain sensitive information! O no!</p><div><figure><img loading="lazy" width="1024" height="624" src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png" alt="" srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png 1024w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-768x468.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-150x91.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-450x274.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-600x366.png 600w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-900x549.png 900w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2.png 1158w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png" data-lazy-srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png 1024w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-768x468.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-150x91.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-450x274.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-600x366.png 600w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-900x549.png 900w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2.png 1158w"></figure></div><p>But then I started reading… Its the same pattern match technology. I can guarantee my company deals with 0% “FDA Approved Prescription” information. We also have 0% IBAN and SWIFT and Credit Card Number.</p><p>Now, from the report there must be a way to find the offending documents, right? Wrong. You get a number: “9% of your documents shared have Global Gender Identity”. What does that even mean?</p><p>This is how you make data untrustworthy and less than useless. I spent time trying to figure out what the call to action was. Eventually I realised the call to action was to ignore: someone at Google has written a few bad regex. They’ve run them on my documents. They’ve shared the categories and counts, but not the links. Their false positive engine cost me time and adds nothing to the universe.</p><p>Sadly, I think there are people out there buying pattern engines for all sorts of things, and, pushing towards the false goal of 0% unknown. It must match, right? Wrong.</p></div></div></article></div>]]>
            </description>
            <link>https://blog.donbowman.ca/2020/12/04/when-good-patterns-go-bad-the-false-positive-regex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322343</guid>
            <pubDate>Sun, 06 Dec 2020 09:42:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Perils of File Typing]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25322288">thread link</a>) | @panic
<br/>
December 6, 2020 | https://invisibleup.com/articles/34/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/34/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/34/thumb.gif" alt="The Perils of File Typing thumbnail">
	
	

	
<p>Corrections added to the Creator/Type code section thanks to user "Somebody" on Hacker News</p>

<p>Suppose you double-click on a file on your computer. You're doing this so you can open the file and work with it. But does your operating system know what that means? How does it know <em>what</em> to open the file <em>in</em>? Let's look at some solutions that have been proposed over the years to solving this issue.</p>
<p>(fun fact: this originally started as a touchup of <a href="https://invisibleup.com/articles/2/">one of my oldest articles</a> before just kinda becoming this whole <em>thing</em>, so expect a bit of retreading.)</p>
<h2>Nothing</h2>
<p><img alt="IBM 709 in use" src="https://invisibleup.com/articles/34/IBM709.jpg"></p>
<p><strong>Used in</strong>: Early mainframes such as the <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a>, etc.</p>
<p>(Image credit: <a href="https://www.computer-history.info/Page4.dir/pages/IBM.704.dir/">Lawrence Livermore National Laboratory</a>)</p>
<p>What's a "file", anyways? It's a sequence of bytes on a disk, possibly floppy. Or a tape. (Cassette or paper, your choice.) Or on stacks of cards with holes in them. Or toggled in by hand on a front panel.</p>
<p>File types weren't relevant because <em>files</em> weren't really a thing. In the mainframe era, you typically 
1. loaded a program on to your computer from punch cards or a tape
2. fed input into that program either from a teletype terminal or from a different tape/card deck
3. received output from the teletype, a line printer, or yet another tape/card deck</p>
<p>Computers weren't complicated enough where there was any confusion as to what a file on a certain medium <em>was</em>, simply because there was so little to work with. If you had a stack of punchcards, that was your "file". Hope you labeled the box you put it in!</p>
<p>Tapes are more interesting, because they hold substantially more data. (A whopping 5.76 megabytes, stored on 3/4 of a kilometer of magentic tape. How exciting!) That said, storing more than one file on a tape was a strange task. Operating systems weren't really a <em>thing</em> yet. The best that existed were programming languages such as FORTRAN or COBOL that had statements for hardware tasks such as reading from or writing to a tape or punch card. For example, <a href="http://archive.computerhistory.org/resources/text/Fortran/102649787.05.01.acc.pdf">here's the manual for FORTRAN for the IBM 704.</a> We have several commands such as <code>READ</code> (from the punch card reader), <code>READ TAPE</code>, <code>PUNCH</code> (new cards), <code>PRINT</code> (to the printer), etc.</p>
<p>On the IBM tape units of the time (ex: the <a href="https://en.wikipedia.org/wiki/IBM_727">IBM 727</a>), tapes were separated into <em>files</em> and <em>records</em>. In FORTRAN, records were created on every <code>WRITE TAPE</code> command, and could be read with <code>READ TAPE</code> later. Records could be overwritten by using the <code>BACKSPACE</code> statement and then writing again. Files were collections of records, and could be created with an <code>END FILE</code> command.</p>
<p>As an aside, later programming languages such as C still share their heritage from this era. This is why we draw text to the screen with <a href="http://www.cplusplus.com/reference/cstdio/printf/"><code>printf</code></a> which long ago would have literally printed to a <a href="https://en.wikipedia.org/wiki/Teletype_Model_33">teletype terminal</a>, why we read files using <a href="http://www.cplusplus.com/reference/cstdio/rewind/"><code>rewind</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fseek/"><code>fseek</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fread/"><code>fread</code></a>, and <a href="http://www.cplusplus.com/reference/cstdio/fwrite/"><code>fwrite</code></a> as if we were on a tape drive still. Even <a href="http://www.asciitable.com/">ASCII</a>, the encoding most commonly used for the basic Latin alphabet, has code points for file, group, record, and unit separators. (This may also be related to block terminals, something that will be discussed in a future article.)</p>
<p>As mainframes moved onto more advanced batch processing and later interactive time-share operating systems like UNIX, <a href="https://en.wikipedia.org/wiki/OS/360_and_successors">OS/360</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Terminal_System">Michigan Terminal System</a>, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System">ITS</a>, etc., they gained more sophisticated methods of dealing with files than raw tape drive access. But then came the microcomputers.</p>
<h2>Type Codes</h2>
<p><img alt="Apple DOS file listing" src="https://invisibleup.com/articles/34/appledos.gif"></p>
<p><strong>Used in</strong>: <a href="https://en.wikipedia.org/wiki/Apple_DOS">Apple DOS for Apple II</a> (1978-1980), <a href="https://www.hpmuseum.org/hp28c.htm">HP-28</a> and <a href="https://www.hpmuseum.org/hp48s.htm">HP-48</a> series, etc.</p>
<p>We have floppy disks now. They can store a lot of files, rename them, delete them, etc. without too much issue. There's this neat computer called the Apple II that just came out. It uses these new-fangled disks, so it needs to figure out how to store files on it.</p>
<p>The way that Apple DOS (the Apple II's disk operating system for most of it's life) stored files is somewhat interesting. Each file has a name (up to 30 characters) and also a <em>type code</em>. 8 of them were defined but only 4 of them mattered:</p>
<ul>
<li>I (Integer BASIC program)</li>
<li>A (Applesoft BASIC program)</li>
<li>B (Binary files; either assembled programs or data)</li>
<li>T (ASCII text files)</li>
</ul>
<p>Apple DOS had some specific commands that interacted with these types. For instance, the <code>RUN</code> command worked on both Interger BASIC and Applesoft BASIC programs, and chose which one to use. <code>BRUN</code>, <em>binary run</em>, only worked on binary files. <code>OPEN</code>, <code>READ</code>, <code>WRITE</code>, and <code>CLOSE</code> all worked only on ASCII text files.</p>
<p><strong>The types more served as a way to help the operating system more so than you.</strong> This is especially evident in the late 80's and early 90's HP calculators such as the HP-28c and the HP-48GX. These calculators didn't have disks, but they did have persistent memory that could store objects into folders much like a computer.</p>
<p>These calculators used Reverse Polish Notation. Essentially, you do math by placing objects on the stack and then executing commands, which take things from the stack and put a new thing on. An <em>object</em> in RPN is something you placed on the stack. The HP-48's Advanced User's Reference Manual lists 32 distinct types, including real numbers, complex numbers, character strings, arrays, lists, variable names, executable programs, graphics objects, directories, etc. A <em>command</em> could be, say, <code>ADD</code> or some fancy plotting calculus stuff. Whatever they were, they needed to know what types they were dealing with so that they could either reject the input or properly work with it.</p>
<p>Like the Apple II, just having an integer for a type is perfectly okay because the types don't serve the user. They're just there so the operating system knows what a given chunk of bytes on the stack <em>is</em>. There are a few reserved spots for custom types, but for the most parts new types aren't expected to ever be added, nor should they be.</p>
<h3>File Extensions</h3>
<p><img alt="CP/M disk listing as seen on an Amstrad CPC" src="https://invisibleup.com/articles/34/cpm.gif"></p>
<p><strong>Used in</strong>: AMSDOS (Amstrad CPC), CP/M, MS-DOS, etc.</p>
<p>Microcomputers really started to gain in popularity with the likes of the ZX Spectrum, the Amstrad CPC and the Commodore 64 among others. These were fairly cheap and simple computers. When first launched, these came with nothing but cassette tape inputs, as disks were too expensive.</p>
<p>On these computers, you'd attach a cassette player using a standard AUX cord (although some, like the CPC, had a cassette player built in), and the computer would instruct you when to start and stop the tape. These cassette players usually came with a little counter that rolled up as the tape progressed, to help you tell where the tape was. When you insert a tape, you reset the counter to zero. When you want to <em>make</em> a file, you'd write down what the counter read, then save the file. To <em>load a specific file</em>, you'd seek the tape until you're at the location you've written down, then start reading.</p>
<p>More advanced computers such as the Amstrad CPC instead saved <a href="http://www.cpcwiki.eu/index.php/AMSDOS_Header">a header</a> with each file containing, among other things, a file name and extension. If asked for a specific file it could just read the tape until it found it. Later these computers gained disk drives, and any ad-hoc tape fiddling was replaced with a proper file system such as <a href="https://en.wikipedia.org/wiki/File_Allocation_Table">FAT</a> or <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a> that stored <em>where</em> a file was on a given disk and <em>what is was called</em>.</p>
<p>File codes are limited. It is nigh-on impossible to add more ones. What you have is what you got. So... what if we just made the codes out of letters? A couple of them? And they could be anything. Then programmers could come up with whatever file extensions they want and that's okay.</p>
<p>Suppose, in MS-DOS, you have a file named <code>REPORT.TXT</code>. <code>REPORT</code> is the file name, <code>TXT</code> is the extension. <strong>File extensions give an easy, consistent indicator of what a file contains.</strong> A <code>TXT</code> file contains text, a <code>BMP</code> file is a bitmap, etc. </p>
<p>Some file extensions, like <code>EXE</code>, <code>BAT</code>, <code>SYS</code> and <code>COM</code> had special meaning much in the same way that the Apple DOS codes had special meanings, but other than that they're just there to help the user. <strong>The user had to manually choose which program to use.</strong> This allowed for the user to choose what view or editor to use depending on what would be the most helpful. Unfortunately, there were no default programs. If the user didn't know which program, say, a <code>VIZ</code> file is for, they're out of luck. Is it a visualization? Some manga thing? The digital manifestation of a cute internet ghost who's staying up way too late geeking out about old computers? <em>The world may never know...</em></p>
<h3>Creator Codes</h3>
<p><strong>Used in:</strong> Classic Mac OS</p>
<p><img alt="File properties dialog on Classic Mac OS" src="https://invisibleup.com/articles/34/macinfo.gif"></p>
<p>Let's hop on over to the Macintosh for a quick second. It was a newfangled thing in 1984, and it had the opportunity to reinvent the wheel and break compatibility with CP/M and mainframe traditions. And so it did.</p>
<p>The original 128K Macintosh used 400K floppy disks, a not-completely-terrible amount of space for the time. It used the <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a>, which didn't support directories but <em>did</em> support files. It was also completely graphically driven. The Finder was supposed to be the primary way of interacting with files, and the <code>File &gt; Open</code> command could launch the program that made the file. How'd it do that?</p>
<p><strong>Instead of file extensions, the Macintosh used type and creator codes</strong>. These were 4-byte identifiers, much like file extensions, but there were two of them each with a different meaning. The type code was mean to represent the format the data was stored in, used to filter files in the Finder's "Open" dialog. The creator code was meant to indicate the application that created the file, and used by the Finder to choose which specific application to launch. Now, these weren't normally visible to the user. They just saw the file name and a icon for that type.</p>
<p>To do that, the system kept a database of codes and their associated icons and programs. When ran for the first time or moved from disk to disk, <strong>the Finder would read the program data and register in a database what creator codes and file types it supported.</strong> The Finder would then save this information on the disk containing the application. Later, <strong>when the user opened a file, the OS would check its type and creator code against its stored list to determine which application to use.</strong> This worked pretty well.</p>
<p><img alt="ResEdit view" src="https://invisibleup.com/articles/34/macresedit.gif"></p>
<p>A similar system was used for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/34/">https://invisibleup.com/articles/34/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/34/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322288</guid>
            <pubDate>Sun, 06 Dec 2020 09:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monopoly Technology Platforms Are Colonizing Education]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25322202">thread link</a>) | @partingshots
<br/>
December 6, 2020 | https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/ | <a href="https://web.archive.org/web/*/https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-746">
	<div>
		
		<div>
			<p>Perspectives<em>&nbsp;is an opportunity for Fellows and others to share their ideas in short, accessible essays.&nbsp;IPE/BC Fellows hold a range of views and interests relative to public education.</em></p>
<p><strong>Monopoly Technology Platforms are Colonizing Education</strong></p>
<p><strong>By Larry Kuehn</strong></p>
<p>The exposés of abuse by social media corporations like Google and Facebook have finally brought attention to the dangers of monopolies over our communications. The way these monopolies have been colonizing public education has, however, gone almost unnoticed. This is rampant privatization sneaking in as essential to “21<sup>st</sup> Century learning.”</p>
<p>The top five global capital corporations are technology platforms—Apple, Google, Microsoft, Amazon and Facebook. Platforms are a host for a variety of services and uses. All of the big five platform corporations have become too large in a short period of time to have any significant competition outside of this group. They compete against one another, adding services to secure their monopoly by offering users everything they do online.</p>
<p>If a new service is developed that seems to be gaining users, or that competes with an element of their platform, it is purchased and integrated into the platform—avoiding new competitors. Alternatively, they use their massive resources to develop a comparable app and push the potential competitor aside.</p>
<p>Snicek, in <a href="https://www.wiley.com/en-us/Platform+Capitalism-p-9781509504862"><em>Platform Capitalism</em></a>, points out that the development of these monopolies “introduces new tendencies within capitalism that pose significant challenges to a post-capitalist future.” Building public cooperative platforms becomes an impossible dream.</p>
<p>No surprise—these platforms have moved to colonize education. Public education represents a big chunk of potential revenue. Just as importantly, schools are where one can find most of the future potential consumers and users of the platform services.</p>
<p>Colonization is a process where a significant force moves into an area and dominates. It takes over not only the production and resources, but imposes—often by stealth and power—the processes and approaches and even values of the social and cultural environment. And, dominate is what the monopoly platforms are on track to do in public education.</p>
<p><img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-400x200.png" alt="" width="262" height="131" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-400x200.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education-768x384.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/G-Suite-For-Education.png 800w" sizes="(max-width: 262px) 100vw, 262px">The most successful colonizer has been Google. A recent report indicates that Google’s <em>G-Suite for Education</em> is being used by half the teachers and students in the U.S. Canada is fast approaching the same level of use. It includes a range of free software tools that can be used by students and teachers—word processing, presentations, spread sheets and the like. G-Suite incorporates “Classroom,” an integrated learning management system that keeps track of grades, attendance and more. And, of course, YouTube is linked to student use.</p>
<p>New elements are added frequently. “Google Sites” is promoted for student e-portfolios, because “every student should publish for the world.” Google acquired Workbench, integrated with Google Classroom to give “lessons connected to a variety of ‘maker’ activities focused on STEM.” It is part of Google’s plan to “help schools and educators address their universal needs around education content.”</p>
<p>Google, rather than democratic public institutions, therefore shapes what is on offer. Google’s position as colonizer is strengthened by the hardware increasingly used in schools—the Google Chromebook. <img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-400x222.png" alt="" width="346" height="192" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-400x222.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000-768x425.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/CB_canada.max-1000x1000.png 1000w" sizes="(max-width: 346px) 100vw, 346px">It is less expensive than other computers because much of what it needs to operate is supplied by Google in the cloud—operating software, applications and memory. No need to build those into the computer.&nbsp; According to market reports, Chromebooks make up the majority of all computers sold to schools in the U.S. and are marketed globally.</p>
<p>However, one must have a gmail account to use these Google tools—so if a parent wants to protect the privacy of their child and refuses a gmail account that kid is left out while the rest of the class works away on their Chromebook and other Google tools. (See <a href="http://s3.documentcloud.org/documents/4497822/GAFE-Information-Letter-and-Consent-Form-page2.pdf">here</a> the kind of consent form parents are asked to sign, giving Google access to acquire and store student information outside of Canada.)</p>
<p><img src="http://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-400x70.png" alt="" width="657" height="115" srcset="https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-400x70.png 400w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-768x135.png 768w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM-1024x180.png 1024w, https://instituteforpubliceducation.org/wp-content/uploads/2019/01/Screen-Shot-2018-12-31-at-4.20.52-PM.png 1238w" sizes="(max-width: 657px) 100vw, 657px"></p>
<p>Google has even taken up teaching “internet safety,” with a program aimed at reaching 5 million students. Its core is a game for students in Grades three to six to teach them to avoid “schemers, hackers and other bad actors.” However, as critics point out, it doesn’t talk about privacy concerns when users’ personal information and actions are tracked online. Google conveniently ignores its role as a “bad actor.”</p>
<p>A <a href="https://journals.sagepub.com/doi/abs/10.1177/1474904116654917">Swedish study </a>of Google’s strategy concluded that “By making an implicit demarcation between two concepts (your) ‘data’ and (collected) ‘information’ Google can disguise the presence of a business model for online marketing and, at the same time, simulate the practices and ethics of a free public service institution.”</p>
<p>In “<a href="http://2017trends.hackeducation.com/data.html">The Weaponization of Education Data</a>,” Audrey Watters points out “the risk isn’t only hacking.&nbsp; It’s amassing data in the first place. It’s profiling. It’s tracking. It’s surveilling.”</p>
<p>Google isn’t alone in the business of colonizing education and student data—just the most successful so far. One competitor is Microsoft 365 Education, with a promise of “empowering every student on the planet to achieve more” and that it will “unlock limitless learning.”</p>
<p>It’s not an accident that it is “Microsoft 365” that is being pushed. It offers a cloud-based software and cloud storage for your work. It is the new business model for Microsoft: they don’t sell you software, you rent it—and you keep paying for it. And your work isn’t saved on your own computer, so you have to keep up your subscription. Like Google, they are hoping that students will keep using their tools when they finish being students.</p>
<p>Microsoft is imitating much of what Google offers, but by charging for the service rather than trading it for data. It offers apps, educator training and STEM lessons “to enrich science, technology, engineering and math classes.” They offer “budget friendly” Windows 10 devices with licences for Microsoft 365 Education.</p>
<p>The other major tech corporations have programs as well. Apple, for example, was the first into education with the Apple IIe and the “Apple Classroom of Tomorrow” way back in the 1980s. More recently it depended on the ease of use of the iPad, despite its cost, to sell classroom sets along with Pearson curriculum in an <a href="https://www.wired.com/2015/05/los-angeles-edtech/">ill-fated project with Los Angeles schools</a>.</p>
<p>Venture capitalists are hoping to find the magic app that will make a fortune. The potential market is indicated by expenditure of hundreds of millions each year on developing new products. The “winners” are likely to be bought up by one of the major corporations—or find their product idea taken by the monopolies.</p>
<p>Not enough attention is paid by education authorities or researchers to the shaping and distortion of education that is possible—even likely—by this colonization of education by technology monopolies.</p>
<p><em><strong>Larry Kuehn</strong>&nbsp;is an IPE/BC Fellow, IPE/BC director and Director of Research &amp; Technology for the British Columbia Teachers’ Federation.&nbsp;</em></p>


		</div><!-- .entry-content -->

		<!-- .entry-footer -->

		
<!-- .entry-auhtor -->
	</div><!-- .hentry-wrapper -->
</article></div>]]>
            </description>
            <link>https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322202</guid>
            <pubDate>Sun, 06 Dec 2020 09:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VisiData in 60 Seconds]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25322091">thread link</a>) | @luu
<br/>
December 6, 2020 | https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/ | <a href="https://web.archive.org/web/*/https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TL;DR? Here’s a three-step introduction to VisiData.</p><div id="step-1-use-vd-to-open-a-data-file">
<h2>Step 1: Use <code><span>vd</span></code> to open a data file<a href="#step-1-use-vd-to-open-a-data-file" title="Permalink to this headline">¶</a></h2>
<p>Download <a download="" href="https://jsvine.github.io/intro-to-visidata/_downloads/83e70cf67e909f3ac177575439e5f3c5/faa-wildlife-strikes.csv"><code><span>faa-wildlife-strikes.csv</span></code></a>, a dataset of all aircraft-wildlife collisions <a href="https://wildlife.faa.gov/database.aspx">reported to the Federal Aviation Adminsitration</a> between 2010 and mid-2016.</p>
<p>From your terminal, move into the directory where you downloaded the dataset. Then run the following command:</p>
<div><div><pre><span></span>vd faa-wildlife-strikes.csv
</pre></div>
</div>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>|</span><span></span><span> ATYPE        </span><span></span><span>|</span><span></span><span> INCIDENT_DATE     </span><span></span><span>|</span><span></span><span> STATE </span><span></span><span>|</span><span></span><span> AIRPORT            </span><span></span><span>|</span><span></span><span> PHASE_OF_FLT</span><span></span><span>&gt;</span><span> 
</span><span></span><span> BUSINESS           </span><span></span><span></span><span>| PA-28        | 05/22/15 00:00:00 | FL    | VERO BEACH MUNICIP…| APPROACH     ║
</span><span></span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> BE-1900</span><span>      </span><span>|</span><span> 06/18/15 00:00:00 </span><span>|</span><span> AK    </span><span>|</span><span> KENAI MUNICIPAL AR…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> PA-46 MALIBU </span><span>|</span><span> 09/20/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> DAVID WAYNE HOOKS …</span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-717-200    </span><span>|</span><span> 11/07/15 00:00:00 </span><span>|</span><span> MO    </span><span>|</span><span> LAMBERT-ST LOUIS I…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> BE-90 KING   </span><span>|</span><span> 12/17/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> POMPANO BEACH AIRP…</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-757</span><span>        </span><span>|</span><span> 07/17/15 00:00:00 </span><span>|</span><span> VI    </span><span>|</span><span> HENRY E ROHLSEN AR…</span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-717-200    </span><span>|</span><span> 08/02/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> SAN ANTONIO INTL   </span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-414</span><span>        </span><span>|</span><span> 08/03/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> LONE STAR EXECUTIV…</span><span>|</span><span> DEPARTURE    </span><span>║
</span><span></span><span> ALLEGIANT AIR      </span><span></span><span>|</span><span> MD-80</span><span>        </span><span>|</span><span> 09/02/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> TAMPA INTL</span><span>         </span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> TRANS STATES AIRLI…</span><span></span><span>|</span><span> EMB-145</span><span>      </span><span>|</span><span> 09/07/15 00:00:00 </span><span>|</span><span> MO    </span><span>|</span><span> LAMBERT-ST LOUIS I…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-172</span><span>        </span><span>|</span><span> 11/28/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> OPA-LOCKA EXECUTIV…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> GOVERNMENT         </span><span></span><span>|</span><span> EC120</span><span>        </span><span>|</span><span> 12/08/15 00:00:00 </span><span>|</span><span> CA    </span><span>|</span><span> NORMAN Y. MINETA S…</span><span>|</span><span>              </span><span>║
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>|</span><span> A-321</span><span>        </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> FORT LAUDERDALE/HO…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>|</span><span> CRJ100/200   </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span> AR    </span><span>|</span><span> FORT SMITH REGIONA…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> MESA AIRLINES      </span><span></span><span>|</span><span> CRJ900</span><span>       </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> AR    </span><span>|</span><span> BILL AND  HILLARY …</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> HELICOPTER   </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span>       </span><span>|</span><span> UNKNOWN</span><span>            </span><span>|</span><span> En Route     </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> A-320</span><span>        </span><span>|</span><span> 05/07/15 00:00:00 </span><span>|</span><span> CA    </span><span>|</span><span> METRO OAKLAND INTL </span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> A-320</span><span>        </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> UT    </span><span>|</span><span> SALT LAKE CITY INTL</span><span>|</span><span>              </span><span>║
</span><span></span><span> LUFTHANSA          </span><span></span><span>|</span><span> A-380</span><span>        </span><span>|</span><span> 05/10/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> GEORGE BUSH INTERC…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-172</span><span>        </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> ORLANDO SANFORD IN…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> SPIRIT AIRLINES    </span><span></span><span>|</span><span> A-319</span><span>        </span><span>|</span><span> 05/10/15 00:00:00 </span><span>|</span><span> IL    </span><span>|</span><span> CHICAGO O'HARE INT…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>|</span><span> EMB-145</span><span>      </span><span>|</span><span> 05/11/15 00:00:00 </span><span>|</span><span> AL    </span><span>|</span><span> BIRMINGHAM-SHUTTLE…</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span>1› faa-wildlife-strikes| user_macros | saul.pw/VisiData v2.1 | opening datasets/        73448 rows </span><span> </span>
</pre>
</div>
</div><div id="step-2-test-drive-a-frequency-table">
<h2>Step 2: Test-drive a frequency table<a href="#step-2-test-drive-a-frequency-table" title="Permalink to this headline">¶</a></h2>
<p>One of VisiData’s strengths is how quickly it lets you summarize your data. Frequency tables are a great example. To create one, press <kbd>Shift+F</kbd>.</p>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>║</span><span></span><span>↓count♯</span><span></span><span>|</span><span></span><span> percent%</span><span></span><span>|</span><span></span><span> histogram                                         ~</span><span></span><span>║</span><span>        
</span><span></span><span> UNKNOWN            </span><span></span><span></span><span>║ 23076 |   31.42 | ************************************************** ║</span><span>        
</span><span></span><span> SOUTHWEST AIRLINES </span><span></span><span>║</span><span>  7752 </span><span>|</span><span>   10.55 </span><span>|</span><span> ****************</span><span>                                   </span><span>║</span><span>        
</span><span></span><span> BUSINESS           </span><span></span><span>║</span><span>  5868 </span><span>|</span><span>    7.99 </span><span>|</span><span> ************</span><span>                                       </span><span>║</span><span>        
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>║</span><span>  4337 </span><span>|</span><span>    5.90 </span><span>|</span><span> *********</span><span>                                          </span><span>║</span><span>        
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>║</span><span>  2817 </span><span>|</span><span>    3.84 </span><span>|</span><span> ******</span><span>                                             </span><span>║</span><span>        
</span><span></span><span> FEDEX EXPRESS      </span><span></span><span>║</span><span>  2709 </span><span>|</span><span>    3.69 </span><span>|</span><span> *****   </span><span>                                           </span><span>║</span><span>        
</span><span></span><span> UNITED AIRLINES    </span><span></span><span>║</span><span>  2194 </span><span>|</span><span>    2.99 </span><span>|</span><span> ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> US AIRWAYS         </span><span></span><span>║</span><span>  1885 </span><span>|</span><span>    2.57 </span><span>|</span><span> ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> UPS AIRLINES       </span><span></span><span>║</span><span>  1773 </span><span>|</span><span>    2.41 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> SKYWEST AIRLINES   </span><span></span><span>║</span><span>  1769 </span><span>|</span><span>    2.41 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> JETBLUE AIRWAYS    </span><span></span><span>║</span><span>  1740 </span><span>|</span><span>    2.37 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>║</span><span>  1347 </span><span>|</span><span>    1.83 </span><span>|</span><span> **   </span><span>                                              </span><span>║</span><span>        
</span><span></span><span> AMERICAN EAGLE AIR…</span><span></span><span>║</span><span>  1041 </span><span>|</span><span>    1.42 </span><span>|</span><span> **</span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> ENVOY AIR          </span><span></span><span>║</span><span>   883 </span><span>|</span><span>    1.20 </span><span>|</span><span> *   </span><span>                                               </span><span>║</span><span>        
</span><span></span><span> ALASKA AIRLINES    </span><span></span><span>║</span><span>   835 </span><span>|</span><span>    1.14 </span><span>|</span><span> * </span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> REPUBLIC AIRLINES  </span><span></span><span>║</span><span>   804 </span><span>|</span><span>    1.09 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> MESA AIRLINES      </span><span></span><span>║</span><span>   693 </span><span>|</span><span>    0.94 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> AIR WISCONSIN AIRL…</span><span></span><span>║</span><span>   623 </span><span>|</span><span>    0.85 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PSA AIRLINES       </span><span></span><span>║</span><span>   577 </span><span>|</span><span>    0.79 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PRIVATELY OWNED    </span><span></span><span>║</span><span>   516 </span><span>|</span><span>    0.70 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PHI INC            </span><span></span><span>║</span><span>   491 </span><span>|</span><span>    0.67 </span><span>|</span><span> *     </span><span>                                             </span><span>║</span><span>        
</span><span></span><span> SHUTTLE AMERICA    </span><span></span><span>║</span><span>   467 </span><span>|</span><span>    0.64 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span>2› faa-wildlife-strikes_OPERATOR_freq|</span><span>                         </span><span></span><span> </span><span>        </span><span></span><span>        F         282 bins </span><span> </span>
</pre>
</div>
</div><div id="step-3-read-visidata-s-manual-page">
<h2>Step 3: Read VisiData’s manual page<a href="#step-3-read-visidata-s-manual-page" title="Permalink to this headline">¶</a></h2>
<p>VisiData’s “<a href="http://visidata.org/man/">quick reference guide</a>” enumerates all of VisiData’s commands and features. You can <a href="http://visidata.org/man/">read it online</a> or access it from anywhere within VisiData by pressing the <kbd>F1</kbd> key or typing <kbd>Control-h</kbd>:</p>
<div>
<pre>vd(1)                        Quick Reference Guide                       vd(1)                      
<span>NAME</span>                     
     <span>VisiData</span> -- a terminal utility for exploring and arranging tabular data                        
<span>SYNOPSIS</span>                 
     <span>vd</span> [<span>options</span>] [<span>input</span> ...]                     
     <span>vd</span> [<span>options</span>] <span>--play</span> <span>cmdlog</span> [<span>-w</span> <span>waitsecs</span>] [<span>--batch</span>] [<span>-o</span> <span>output</span>] [<span>field</span><span></span><span></span><span>=</span><span></span><span></span><span>value</span>]                   
     <span>vd</span> [<span>options</span>] [<span>input</span> ...] <span>+</span><span></span><span></span><span>toplevel</span>:<span>subsheet</span>:<span>col</span>:<span>row</span>                                            
<span>DESCRIPTION</span>              
     <span>VisiData</span> is an easy-to-use multipurpose tool to explore, clean, edit, and restructure          
     data. Rows can be selected, filtered, and grouped; columns can be rearranged, trans-           
     formed, and derived via regex or Python expressions; and workflows can be saved, doc-          
     umented, and replayed.                       
   <span>REPLAY</span> <span>MODE</span>           
     <span>-p</span>, <span>--play</span>=<span>cmdlog</span>       replay a saved <span>cmdlog</span> within the interface                             
     <span>-w</span>, <span>--replay-wait</span>=<span>seconds</span>                    
                             wait <span>seconds</span> between commands                                          
     <span>-b</span>, <span>--batch</span>             replay in batch mode (with no interface)                               
     <span>-o</span>, <span>--output</span>=<span>file</span>       save final visible sheet to <span>file</span> as .tsv                               
:                        
</pre>
</div>
<div>
<p>Note</p>
<p>If you open the manual from within VisiData it will launch in your terminal’s “pager” program —&nbsp;typically the <a href="https://en.wikipedia.org/wiki/Less_(Unix)">less program</a>. To move around:</p>
<table>
<colgroup>
<col width="55%">
<col width="45%">
</colgroup>
<thead>
<tr><th>Keystroke(s)</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr><td><kbd>Space</kbd> / <kbd>b</kbd></td>
<td>Scroll forward/backward</td>
</tr>
<tr><td><kbd>/</kbd> + <em>search term</em> + <kbd>Enter</kbd></td>
<td>Search for <em>search term</em></td>
</tr>
<tr><td><kbd>n</kbd> / <kbd>N</kbd></td>
<td>Go to next/previous search match</td>
</tr>
<tr><td><kbd>q</kbd></td>
<td>Exit and return to VisiData</td>
</tr>
</tbody>
</table>
<p>You can find additional commands <a href="https://en.wikipedia.org/wiki/Less_(Unix)#Frequently_used_commands">here</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322091</guid>
            <pubDate>Sun, 06 Dec 2020 08:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Airbnb Thanksgiving Burglary]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25321770">thread link</a>) | @dsr12
<br/>
December 5, 2020 | https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html | <a href="https://web.archive.org/web/*/https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://habrastorage.org/webt/mm/dk/wp/mmdkwpapgwobqrzcauk213qoglk.png" alt=""></p>



<p>I used <a href="https://www.airbnb.com/">Airbnb</a> for years in Russia, Germany, and the United States. All the time, the experience was great. At some point, I read a <a href="https://amzn.to/3o9JywH">book about Airbnb</a> to understand the company better.</p>

<p>For Thanksgiving week (November 21-29), five of my friends and I rented a house in Las Vegas.</p>

<p>The total price for nine days: <strong>$2543</strong>.</p>

<p>Previously people went to Vegas to spend time in casinos or walk on The Strip. This year, <a href="https://www.worldometers.info/coronavirus/">the pandemic</a> made it impossible.</p>

<p>It was not a problem for us. We did not plan to socialize; we were going rock climbing.</p>

<p><a href="https://www.mountainproject.com/area/105731932/red-rock">Red Rocks</a>, located next to Vegas, is an excellent place for traditional, sport, bouldering, multi-pitch climbing.</p>

<p>The plan was for some people to take days off and climb every day, and for others to work three days remotely and join the gang during the rest.</p>

<h2 id="incident">Incident</h2>

<p>We moved in on Saturday night. The next morning, excited, we woke up at 6am, had breakfast, verified that we closed back and front doors and at 7am drove to the Red Rocks Park.</p>

<p>We had a fantastic day of climbing, but after the sunset, we went home to realize that the window in one of the rooms was open and some of our belongings had disappeared.</p>

<ul>
  <li>Three work Macbook Pro (I do not include the price, they are replaced by our employees for free)</li>
  <li>One personal <a href="https://amzn.to/33uWB3F">Macbook Pro</a> ($1550)</li>
  <li><a href="https://amzn.to/2JCZWqE">Oculus Quest 2</a>. I just bought it. Really cool. Wanted to share the experience. ($399)</li>
  <li><a href="https://amzn.to/2VnyrUt">GoPro Hero 6</a> ($194)</li>
  <li><a href="https://amzn.to/36oMMGz">Lenovo Tab 4, 10.1in Android Tablet</a> ($190)</li>
  <li><a href="https://amzn.to/3lms9is">Sony WH1000XM3 Noise Cancelling Headphones</a> ($348)</li>
  <li><a href="https://amzn.to/3qbPNSm">Bose Quietcontrol 30 Wireless Headphones</a> ($169)</li>
  <li><a href="https://amzn.to/3fVzzIh">Bose Noise Cancelling Wireless Bluetooth Headphones 700</a> ($339)</li>
  <li><a href="https://amzn.to/37qgsSN">BlueTooth ledger</a> ($118)</li>
  <li>Two backpacks. (2 x $100)</li>
</ul>

<p><img src="https://habrastorage.org/webt/kz/an/pd/kzanpdzeno_6rkrjjgbrhbscbbs.jpeg" alt=""></p>

<p>I called the host, told her about the situation. She shared a set of images from the cameras and the next day sent the whole video.</p>

<!-- Courtesy of embedresponsively.com //-->

<p>
    <iframe src="https://www.youtube-nocookie.com/embed/cg3Z9ZxtKGw" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </p>

<p>We believe this is what happened:</p>

<p>At 8:55am, two hours after we left, someone</p>
<ol>
  <li>Openly came to the front door.</li>
  <li>Knocked in the door.</li>
  <li>Waved Lexus car keys at the camera. (We do not have Lexus.)</li>
  <li>Ringed the bell.</li>
  <li>Waited to verify that no one was at home.</li>
  <li>Got to the back of the house.</li>
  <li>Put gloves and balaclava on.</li>
  <li>Checked if the back door was open. It was not.</li>
  <li>Checked if he can open the window. And it was possible.
10 Moved the pool chair below the window.</li>
  <li>Got into the house.</li>
</ol>

<p>We called the police, and in two hours an officer came. He was polite and professional. He got the list of the stolen items, our version of the incident in the written form, and left.</p>

<p>I was curious, how did the burglar open the window? I checked, and the answer was simple: <strong>the lock on the window was not operational.</strong> No need to break anything, anyone can open the window from the outside!</p>

<p>If the weather was warmer, we would probably try to open windows the night we came. In that case we would discover the problem, but the night was cold and we did not touch the windows.</p>

<p>Till this moment, I was chill. Bad things happen. Burglars get into houses, and no one could be protected from it. We were safe in this incident, and from the money perspective, our loss was not huge.</p>

<p>But the fact that the lock on that window was not functioning is an issue (few more windows had the same problem). If the front door lock was broken it would be worse but even windows that could not be locked are sketchy.</p>

<p>In general, I prefer to blame myself for bad things that happen to me. This time I cannot figure out what was my fault. For sure, we could check all the locks in the house, but it is an overkill.</p>

<p>I am ok with making mistakes and paying for them. But this time, we paid for the host’s errors and Airbnb’s as a company.</p>

<ul>
  <li><strong>Host</strong>: the house was not ready for hosting the guests.</li>
  <li><strong>Airbnb</strong>: limitations of the onboarding policy. I believe there is a list of things that the house owner needs to mark to become a host, and either functioning window locks are not on the list, or it is not enforced.</li>
</ul>

<p>After we told the host about our discovery, she sent a person to lock all the windows completely. From now on, no one would be able to open them from inside or outside.</p>



<p>I wanted to reach out to Airbnb, tell them about the situation, and ask about the next steps.</p>

<p>Safety comes first. Hence I assumed that even if you are under stress and your brain is not functioning well, it is obvious how to contact the support team.</p>

<p>To my surprise, it is not the case.</p>

<p>I spent some time on the Airbnb website but could not figure out which phone number I should call.</p>

<p><strong>Message to AirBnb</strong>: It would be great if you simplify the design of the support page. When we talk about safety, it should be about efficiency and not about the visual appeal or cuteness level.</p>

<p>I would like it to be:</p>

<ul>
  <li>I open the Airbnb website =&gt; I see an obvious button/link to the support page.</li>
  <li>I open the support page =&gt; I see an obvious button/link to the hotline phone number.</li>
</ul>

<p>I posted the tweet about the incident and tagged Airbnb and Las Vegas police in it.</p>

<blockquote>— Vladimir Iglovikov (@viglovikov) <a href="https://twitter.com/viglovikov/status/1330741490759266304?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>


<p>A miracle happened. Airbnb contacted me and asked for my email to identify the account and to get more details.</p>

<p>My guess is that the Marketing team at Airbnb has alarms that trigger when someone mentions the company on social media.</p>

<p>Finally, after two hours, we got into the conversation about the incident, but the path to get there was not obvious at all.</p>

<p>Imagine how many people got into trouble in similar situations and did not leverage this communication channel?</p>

<p>I got an email:</p>

<blockquote>
  <p>My name is XXX, from the Airbnb claims team.</p>

  <p>I am contacting you regarding the incident that occurred during your reservation with YYY.</p>

  <p>As my colleague informed you in the previous email, we are only able to offer up to $500 for any stolen property. In order to proceed with this refund, I will need the following:</p>

  <p>*Original purchase invoice for the stolen items.</p>

  <p>This is requested as “proof of ownership”, if you don’t have the original purchase invoice, a picture of you where the item can be seen will also be accepted as proof of ownership.</p>
</blockquote>

<p>All this story is not about money. But getting compensated for the host’s and Airbnb’s mistake with cash or AirBnB credits would be nice. It does not address the issue with window locks but sweetens the situation.</p>

<p>We interpreted the email as: “We will compensate up to $500 per stolen item”. Using the numbers from the invoices, it summed to $2600.</p>

<p>We collected invoices, sent them to Airbnb, and got the reply with words: “After additional review, I’m happy to report that we have just released a payout in the amount of $500 to your Airbnb account. You can confirm in your Airbnb Transaction History.”</p>

<p>The guess about up to $500 per item was overly optimistic.</p>

<p>After the end of the stay, I got a message from the host:</p>

<blockquote>
  <p>Hi Vladimir,</p>

  <p>Thank you again for choosing our home for your vacation stay.</p>

  <p>I hope the home met (and even surpassed) your expectations. It was a sincere pleasure hosting you, and I really hope to host you again in the near future. I would be truly grateful for a 5 star review of your stay when you have a spare moment and I would definitely do the same for you.</p>

  <p>Also, please in the private comments if there is something, the home or myself can approve of please let me know.</p>
</blockquote>

<p>I understand that this is a standard template, but under the circumstances, it sounds strange and
does not fit the story and overall experience.</p>

<p>I did not plan to share the actual address of the property. The harm to the renting business could be material. But after this text, I changed my mind. It does not look like the host plans to revise the house and look for things that can and should be fixed. For example, the front door lock is barely working. The door could be open with a good push.</p>



<p>We had a great vacation. The weather was good, and the red rocks are remarkable. We had a lot of fun and plan to come back sometime soon.</p>

<p>Work laptops were replaced. We accepted the loss of personal items.</p>

<p>The Airbnb experience was not as smooth as we expected. Our things got stolen, and even on the other days, we did not feel comfortable leaving belongings in the house.</p>

<p>The host was responsive, but it is not enough. Communicating with guests and collecting money should not be the only responsibility. It is worth inspecting the house and fixing things that do not work as expected proactively, without waiting till the universe gives you feedback.</p>

<p>Overall, I believe that staying at AirBnB is safe, and such incidents are the exception rather than the rule, but, for sure, Airbnb has some work to do to improve communication and increase the guests’ safety. The compensation of $500 for all the stolen items does not look fair either.</p>

<p>I would like to end the story with some action items like: “<strong>Next time, when I rent a place, I will do XXX</strong>.” Nothing reasonable comes to my mind.</p>

<p>When I sit in front of the computer in San Francisco, the only thing that comes to my mind is to build a Face Recognition system and check the burglar’s face in it. Something similar to Clearview. Machine Learning is my expertise; creating such a system is straightforward but will take some time. Tempting. Thinking about it.</p>

<p>What would be your action item after such an experience?</p>

        
      </section></div>]]>
            </description>
            <link>https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321770</guid>
            <pubDate>Sun, 06 Dec 2020 07:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons for Early Stage Founders]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25321667">thread link</a>) | @sarathyweb
<br/>
December 5, 2020 | https://calv.info/early-stage-lessons | <a href="https://web.archive.org/web/*/https://calv.info/early-stage-lessons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In Segmentâ€™s early days, we hit countless problems as a founding team. And at the time, I thought those problems were unique to our own special snowflake of a founding journey. I chalked it up to us being new grads and first-time founders.</p><p>But as I've worked with more and more startups, I've realized just how wrong I was.</p><p>Over the past five years, I've made about 25 different seed-stage investments. In doing so, it's taught me a <em>LOT</em> about the common errors that startup founders make. Even across different industries and levels of experience, I see founders hitting the exact same set of problems we encountered in the early days of Segment!</p><p>This post shares a handful of the top lessons that benefit todayâ€™s early stage founders. Itâ€™s a list of the things I wish weâ€™d figured out earlier at Segment. [1]</p><p>This sounds incredibly boring... but the #1 mistake I see startups making is that they donâ€™t set goals. If you take one thing from this post, it's that you should set goals for where you want to be.</p><p>For the longest time at Segment, we didn't have goals. We moved ahead in various (often random) directions, and we would launch features consistently... but we never really set goals at all.</p><p>As we grew the company, we started to lose momentum. Teams were spending time on a bunch of stuff that frankly just didn't really matter to the overall business.</p><p>It wasn't until we hired our VP Eng, Tido, that we finally started setting focused and audacious product goals. Just by verbalizing where we wanted to go and then grading our results, our velocity improved by an order of magnitude.</p><p>I don't care if you call them OKRs, sprints, or something else entirely. Just set a deadline when you want to have something done and a metric you want to move or some other concrete result.</p><p>When early stage founders do attempt to set goals, I often see them agonize over what specific goals to choose. In practice, a "pretty good goal" is way better than "no goals at all". Perfect is the enemy of good.</p><p>If you don't yet have product-market fit, your goal should probably be getting your first 3-5 customers using the product. If you've hit the level where you now have dozens of users, your goal should be growing by an order of magnitude. It's better to get in the habit of setting and driving towards goals rather than being too worried about their exact semantics. Worst case, you just pick a better goal later.</p><p>A great set of goals answers the question: <em><strong>"what would have to be true in order for us to feel good about our progress at the end of the month?"</strong></em><em> [2]</em></p><p>If each teammate can independently answer "what are our goals for the month?" in the same way, you'll know you've succeeded. If youâ€™re looking for prior art, read <a href="https://www.amazon.com/Measure-What-Matters-Google-Foundation/dp/0525536221">Measure What Matters</a>. </p><p>If you strictly focus on making things true by a certain date, you are bound to make at least some progress towards your end result. </p><p>At the end of the day, every billion-dollar startup is really just the sum of many small deltas.</p><p>Let's get one thing straight: your investors won't know everything. But investors won't know <em>anything</em> if you don't keep them updated on how things are going.</p><p>For the longest time, we were fearful of our Segment investors, to the point that we wouldn't bother sending them emails unless they asked about us. I can say now with confidence that this was 100% the wrong approach.</p><p>We worried that investors would think that we were screwing up (true) and failing (true as well!). And while that might be the case, a founder-friendly investor won't think that way. Investors, especially angels, invested because they believe in <em>you</em>. If I didn't think a team would go somewhere, I wouldn't put money in.</p><p>With each investor, <strong>include the goals you're working towards, as well as the asks for them</strong>. I think monthly is about the right cadence for this in the early days, moving to quarterly around Series A/B time when you start partnering more with a few board members.</p><p>Simply writing the updates should clarify your own thinking tremendously. If it takes you more than 1-2h to put together an update on the most important things happening at the company, it's probably a sign that you should be doing more thinking about the big picture.</p><p>When asking for help, the things that our investors have been able to help us with evolved quite a bit over time. But here's a good rule of thumb for what to ask for:</p><ul><li><p><u>Seed/Pre-seed</u>: user-testing, intros to beta users, hiring</p></li><li><p><u>Series A</u>: hiring, early customers, go-to-market</p></li><li><p><u>Series B/C+</u>: comparables at other companies, senior/exec hires, specific expertise around things like management, infrastructure, systems, etc.</p></li></ul><p>Not all investors will be able to help with everything. But at the very least, sending them information will help you be top of mind. I've lost track of how many times a moment of serendipity where I'm catching up with an old friend has led to a meaningful conversation for a company I've invested in.</p><p>As an extra bonus, the strongest startups send these updates to everyone on their team. It's amazing how much putting the goals in writing helps everyone stay on the same page about what's most important.</p><p>One other note here: take pictures. I now wish we had far more pictures of Segment at every stage of the company. They help turn investor updates into cherished memories.</p><p>Okay, this lesson is taken directly from the YC playbook. And YET, I see so many founders (including YC founders) fail to launch their product. </p><p>If no one notices your launch... just ignore it and then launch again. If you're doing things right, you'll never run out of stuff to launch! [3]</p><p>Why is launching so important? Let me share a personal story...</p><p>We spent about 1.5 years building different iterations of analytics tools. For every iteration, we had a waitlist that users could sign up to use. We personally reached out to the users who we thought were the best fits, and then tried to set up time to use the product. </p><p>The result? Nobody cared. We had no users. We never launched. </p><p>When we finally launched Segment in it's current incarnation, we threw out that approach entirely. We put up a self-service flow, and let anyone who wanted to sign up for it.</p><p>That's when something strange happened... we attracted an entirely new set of developers who just were crawling out of the woodwork and excited to use the new product we'd built. They were coming from companies far outside of SV that we'd never heard of.</p><p>It floored me.</p><p><strong>Lesson learned: the people you happen to be talking to now are probably not the people who have the biggest problem in your space. Do everything you can to reach the folks with the biggest problem, and then, reduce any barriers they might encounter.</strong></p><p>I expect a bunch of you reading this post to ignore this advice, just like we did in the early days. It takes a certain confidence to launch something you've built and put it out there for the world to see. Ultimately though, the rewards are worth it. You'll see users coming from communities you've never even heard of.</p><p>Let me tell you a tale of two startups.</p><p><strong>Startup A</strong> is constantly putting up interesting content on their blog. Their founders are sharing product launches, engineering posts, and creatively brainstorming about what it takes to solve problems in their market.</p><p><strong>Startup B</strong> is operating in stealth. You can't find much about them online, but one of the founders reached out with a nice personalized email mentioning their funding by a top-tier VC. </p><p>Suppose you're looking for a job... do you pick Startup A or Startup B? In my experience, A almost always wins. Momentum is a compounding force.</p><p><strong>Unless you are working in a space that heavily depends on IP, you should probably be publishing more content about what you are doing.</strong> This could be open source, it could be a weekly newsletter, it could be a changelog. [4]</p><p>Whatever it is, it's going to help you both hire <em>and</em> attract customers. So much of the internet is merely about consuming, that just by putting ideas out there, youâ€™ll have a leg up on the competition.</p><p>In the early days of Segment, our <a href="https://segment.com/blog/show-hn-to-series-d/">user acquisition was powered by open source projects and blog posts</a>. But I've seen founders have success with Twitter, Substacks, Podcasts and a variety of different channels.</p><p>If you're looking for inspiration, the <a href="https://railway.app/changelog">Railway</a> and <a href="https://linear.app/changelog">Linear</a> changelogs are epic examples. Companies like <a href="https://baremetrics.com/blog/i-sold-baremetrics">Baremetrics</a> and <a href="https://buffer.com/resources/shareholder-update-q2-2020-and-july/">Buffer</a> differentiated themselves by just being open and honest. <a href="https://stripe.com/blog/globe">Stripe</a> and <a href="https://www.figma.com/blog/behind-the-feature-the-making-of-the-new-auto-layout/">Figma's blogs</a> not only share what they build, but how they built it.</p><p>There are three big inputs that all startups need to continue growing</p><ol><li><p>product capabilities</p></li><li><p>customers and users</p></li><li><p>hiring</p></li></ol><p>I've put them in roughly the order that most teams encounter them. </p><p>Startups begin with a small product that has a modicum of utility. It starts attracting a handful of customers organically. And as more and more customers start using the product, the founders realize that they need extra help to stay on top of all of those requests.</p><p>Remember though, the real goal here is #2. Itâ€™s not the size of your team, itâ€™s the value youâ€™re able to provide to the world. [5]</p><p>I see hiring a big team before you have product-market fit as a red flag. If the company doesn't yet have a set direction, it's going to be harder to pivot with 10 people than it is with 3.</p><p>But, I've worked with startups who have traction and runway... and just seem to be spinning their wheels under load from existing customers.</p><p>I get it. Hiring isn't the most fun, especially for an introvert. It's a lot of interviewing and feeling like there's a lot of rejection. Rejecting people sucks. Losing candidates sucks. For many of our roles at Segment, we've had to talk with 50-100 different people to make an eventual hire.</p><p><strong>If you have 24 months of runway, and a clear list of things youâ€™d do if you had more copies of yourself: you probably aren't spending time to hire the people you need.</strong></p><p>At Segment, my co-founder <a href="https://twitter.com/ivolo">Ilya</a> fulfilled this role. It was back in 2014, we were 12 people at the time, had raised a $10m Series A, and had $1m in revenue.</p><p>Thing…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calv.info/early-stage-lessons">https://calv.info/early-stage-lessons</a></em></p>]]>
            </description>
            <link>https://calv.info/early-stage-lessons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321667</guid>
            <pubDate>Sun, 06 Dec 2020 06:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic segmentation algorithms do not generalize to off-road datasets]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25321540">thread link</a>) | @srik901
<br/>
December 5, 2020 | https://unmannedlab.github.io/research/RELLIS-3D | <a href="https://web.archive.org/web/*/https://unmannedlab.github.io/research/RELLIS-3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
<a href="https://www.tamu.edu/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/tamu_logo.png" alt="Texas A&amp;M University" height="90px" width="450px"></a>    <a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="CCDC Army Research Laboratory" height="90px" width="270px"></a></p>
<p>
Peng Jiang<sup>1</sup>, Philip Osteen<sup>2</sup>, Maggie Wigness<sup>2</sup> and Srikanth Saripalli<sup>1</sup><br>
1. <a href="https://www.tamu.edu/">Texas A&amp;M University; </a> 2. <a href="https://www.arl.army.mil/">CCDC Army Research Laboratory</a><br>
<a href="https://unmannedlab.github.io/research/RELLIS-3D">[Website]</a> <a href="https://arxiv.org/abs/2011.12954">[Paper]</a> <a href="https://github.com/unmannedlab/RELLIS-3D">[Github]</a> 
</p>
<h2 id="overview">Overview</h2>
<p>Semantic scene understanding is crucial for robust and safe autonomous navigation, particularly so in off-road environments. Recent deep learning advances for 3D semantic segmentation rely heavily on large sets of training data; however, existing autonomy datasets represent urban environments or lack multimodal off-road data. We fill this gap with RELLIS-3D, a multimodal dataset collected in an off-road environment containing annotations for <strong>13,556 LiDAR scans</strong> and <strong>6,235 images</strong>. The data was collected on the Rellis Campus of Texas A\&amp;M University and presents challenges to existing algorithms related to class imbalance and environmental topography. Additionally, we evaluate the current state of the art deep learning semantic segmentation models on this dataset. Experimental results show that RELLIS-3D presents challenges for algorithms designed for segmentation in urban environments. Except for the annotated data, the dataset also provides full-stack sensor data in ROS bag format, including <strong>RGB camera images</strong>, <strong>LiDAR point clouds</strong>, <strong>a pair of stereo images</strong>, <strong>high-precision GPS measurement</strong>, and <strong>IMU data</strong>. This novel dataset provides the resources needed by researchers to develop more advanced algorithms and investigate new research directions to enhance autonomous navigation in off-road environments.</p>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/data_example.png">
</p>
<h3 id="recording-platform">Recording Platform</h3>
<ul>
  <li><a href="https://clearpathrobotics.com/warthog-unmanned-ground-vehicle-robot/">Clearpath Robobtics Warthog</a></li>
</ul>

<h3 id="sensor-setup">Sensor Setup</h3>
<ul>
  <li>64 channels Lidar: <a href="https://ouster.com/products/os1-lidar-sensor">Ouster OS1</a></li>
  <li>32 Channels Lidar: <a href="https://velodynelidar.com/vlp-32c.html">Velodyne Ultra Puck</a></li>
  <li>3D Stereo Camera: <a href="https://nerian.com/products/karmin2-3d-stereo-camera/">Nerian Karmin2</a> + <a href="https://nerian.com/products/scenescan-stereo-vision/">Nerian SceneScan</a></li>
  <li>RGB Camera: <a href="https://www.baslerweb.com/en/products/cameras/area-scan-cameras/ace/aca1920-50gc/">Basler acA1920-50gc</a> + <a href="https://www.edmundoptics.com/p/16mm-focal-length-hp-series-fixed-focal-length-lens/28990/">Edmund Optics 16mm/F1.8 86-571</a></li>
  <li>Inertial Navigation System (GPS/IMU): <a href="https://www.vectornav.com/products/vn-300">Vectornav VN-300 Dual Antenna GNSS/INS</a></li>
</ul>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/sensor_setup.png">
</p>
<h2 id="annotated-data">Annotated Data:</h2>
<h3 id="ontology">Ontology:</h3>
<p>With the goal of providing multi-modal data to enhance autonomous off-road navigation, we defined an ontology of object and terrain classes, which largely derives from <a href="http://rugd.vision/">the RUGD dataset</a> but also includes unique terrain and object classes not present in RUGD. Specifically, sequences from this dataset includes classes such as mud, man-made barriers, and rubble piles. Additionally, this dataset provides a finer-grained class structure for water sources, i.e., puddle and deep water, as these two classes present different traversability scenarios for most robotic platforms. Overall, 20 classes (including void class) are present in the data.</p>

<p><strong>Ontology Definition</strong> (<a href="https://drive.google.com/file/d/1K8Zf0ju_xI5lnx3NTDLJpVTs59wmGPI6/view?usp=sharing">Download 18KB</a>)</p>

<h3 id="images-statics">Images Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/img_dist.png">
</p>
<h3 id="image-download">Image Download:</h3>

<p><strong>Image with Annotation Examples</strong> (<a href="https://drive.google.com/file/d/1wIig-LCie571DnK72p2zNAYYWeclEz1D/view?usp=sharing">Download 3MB</a>)</p>

<p><strong>Full Images</strong> (<a href="https://drive.google.com/file/d/1F3Leu0H_m6aPVpZITragfreO_SGtL2yV/view?usp=sharing">Download 11GB</a>)</p>

<p><strong>Full Image Annotations</strong> (<a href="https://drive.google.com/file/d/16URBUQn_VOGvUqfms-0I8HHKMtjPHsu5/view?usp=sharing">Download 94MB</a>)</p>

<p><strong>Image Split File</strong> (<a href="https://drive.google.com/file/d/1zHmnVaItcYJAWat3Yti1W_5Nfux194WQ/view?usp=sharing">44KB</a>)</p>

<h3 id="lidar-scans-statics">LiDAR Scans Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/pt_dist.png">
</p>

<h3 id="lidar-download">LiDAR Download:</h3>

<ul>
  <li>
    <p>LiDAR with Annotation Examples (<a href="https://drive.google.com/file/d/1QikPnpmxneyCuwefr6m50fBOSB2ny4LC/view?usp=sharing">Download 24MB</a>)</p>
  </li>
  <li>
    <p>LiDAR with Color Annotation PLY Format (<a href="https://drive.google.com/file/d/1BZWrPOeLhbVItdN0xhzolfsABr6ymsRr/view?usp=sharing">Download 26GB</a>)</p>
  </li>
  <li>
    <p>LiDAR SemanticKITTI Format (<a href="https://drive.google.com/file/d/1lDSVRf_kZrD0zHHMsKJ0V1GN9QATR4wH/view?usp=sharing">Download 14GB</a>)</p>
  </li>
  <li>
    <p>LiDAR Annotation SemanticKITTI Format (<a href="https://drive.google.com/file/d/1LUmmO2imJ4m5uCtGv1FYusCo-bEPDbBx/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Scan Poses files (<a href="https://drive.google.com/file/d/1cyVqJEnlzO9ANOP7hU8GJk28ckPDUSGv/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Split File (<a href="https://drive.google.com/file/d/1raQJPySyqDaHpc53KPnJVl3Bln6HlcVS/view?usp=sharing">75KB</a>)</p>
  </li>
</ul>

<h3 id="calibration-download">Calibration Download:</h3>
<ul>
  <li>
    <p>Camera Instrinsic (<a href="https://drive.google.com/file/d/1NAigZTJYocRSOTfgFBddZYnDsI_CSpwK/view?usp=sharing">Download 2KB</a>)</p>
  </li>
  <li>
    <p>Camera to LiDAR (<a href="https://drive.google.com/file/d/1Xra1E8Bc4l5VwjjNm7o41nDFO29nmx-u/view?usp=sharing">Download 3KB</a>)</p>
  </li>
</ul>

<h2 id="benchmarks">Benchmarks</h2>

<h3 id="image-semantic-segmenation">Image Semantic Segmenation</h3>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vr3g6lCTKRM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h3 id="lidar-semantic-segmenation">LiDAR Semantic Segmenation</h3>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/wkm8UiVNGao" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2 id="ros-bag-raw-data">ROS Bag Raw Data</h2>

<p>Data included in raw ROS bagfiles:</p>

<table>
  <thead>
    <tr>
      <th>Topic Name</th>
      <th>Message Tpye</th>
      <th>Message Descriptison</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>/img_node/intensity_image</td>
      <td>sensor_msgs/Image</td>
      <td>Intensity image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/noise_image</td>
      <td>sensor_msgs/Image</td>
      <td>Noise image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/range_image</td>
      <td>sensor_msgs/Image</td>
      <td>Range image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/imu/data</td>
      <td>sensor_msgs/Imu</td>
      <td>Filtered imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/data_raw</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/nerian_stereo/left_image</td>
      <td>sensor_msgs/Image</td>
      <td>Left image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/nerian_stereo/right_image</td>
      <td>sensor_msgs/Image</td>
      <td>Right image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/odometry/filtered</td>
      <td>nav_msgs/Odometry</td>
      <td>A filtered local-ization estimate based on wheel odometry (en-coders) and integrated IMU from Warthog</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/imu</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>Point cloud data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/imu_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw imu data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/lidar_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw lidar data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/vectornav/GPS</td>
      <td>sensor_msgs/NavSatFix</td>
      <td>INS data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/IMU</td>
      <td>sensor_msgs/Imu</td>
      <td>Imu data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Odom</td>
      <td>nav_msgs/Odometry</td>
      <td>Odometry from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Pres</td>
      <td>sensor_msgs/FluidPressure</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/vectornav/Temp</td>
      <td>sensor_msgs/Temperature</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/velodyne_points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>PointCloud produced by the Velodyne Lidar</td>
    </tr>
  </tbody>
</table>

<h3 id="ros-bag-download">ROS Bag Download</h3>

<p><strong>ROS Bag Examples</strong> (<a href="https://drive.google.com/file/d/163pEtjMhcM1OJo36ZOi6_zDHpuPSL8us/view?usp=sharing">2GB</a>)</p>

<p><strong>Sequence 00000</strong>: Synced data: (<a href="https://drive.google.com/file/d/10dHPMCschg1dMeb_Y6pcPvC-HZQZ8_ek/view?usp=sharing">12GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1d-t4P1idWkfxDEkodBrsbd4B2nAc8rZ3/view?usp=sharing">23GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1IZ-Tn_kzkp82mNbOL_4sNAniunD7tsYU?usp=sharing">29GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qc7IepWGKr8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00001</strong>: Synced data: (<a href="https://drive.google.com/file/d/1I98lEog0xFFAVVZ_AEBvXzIEcFQ2bGRl/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1LogHRN1ElE2xryILMPU3OtnV6VCnjs52/view?usp=sharing">16GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1hf-vF5zyTKcCLqIiddIGdemzKT742T1t?usp=sharing">22GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nO5JADjDWQ0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00002</strong>: Synced data: (<a href="https://drive.google.com/file/d/1yhohyWOIIf00YLUZ1RT7ouq3B-iaOU91/view?usp=sharing">14GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1F_8yviLHcAVmBpWEyCITFd1nRgPRmkVX/view?usp=sharing">28GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1R8jP5Qo7Z6uKPoG9XUvFCStwJu6rtliu?usp=sharing">37GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aXaOmzjHmNE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00003</strong>:Synced data: (<a href="https://drive.google.com/file/d/1poY5eaKKhmjUQpF1rsoL4mm4wO7T8CJM/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1HDbtqaYhfeyLoq9UsxOhgCJl2urGVKUc/view?usp=sharing">15GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1iP0k6dbmPdAH9kkxs6ugi6-JbrkGhm5o?usp=sharing">19GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Kjo3tGDSbtU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00004</strong>:Synced data: (<a href="https://drive.google.com/file/d/1xLvai6rorpjxRZXraZK7qPsA1vYMkTHJ/view?usp=sharing">7GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1usxAjxHrw89R6rMA0GtmYQRtzIP-QGJF/view?usp=sharing">14GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1WV9pecF2beESyM7N29W-nhi-JaoKvEqc?usp=sharing">17GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/lLLYTI4TCD4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h2 id="full-data-download">Full Data Download:</h2>
<p><a href="https://drive.google.com/drive/folders/1aZ1tJ3YYcWuL3oWKnrTIC5gq46zx1bMc?usp=sharing">Access Link</a></p>

<h2 id="citation">Citation</h2>
<div><div><pre><code>@misc{jiang2020rellis3d,
      title={RELLIS-3D Dataset: Data, Benchmarks and Analysis}, 
      author={Peng Jiang and Philip Osteen and Maggie Wigness and Srikanth Saripalli},
      year={2020},
      eprint={2011.12954},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre></div></div>

<h2 id="collaborator">Collaborator</h2>
<p><a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="The DEVCOM Army Research Laboratory"></a></p>

<h2 id="license">License</h2>
<p>All datasets and code on this page are copyright by us and published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License.</p>



<p><a href="https://unmannedlab.github.io/research/SemanticUSL">SemanticUSL: A Dataset for Semantic Segmentation Domain Adatpation</a></p>

<p><a href="https://unmannedlab.github.io/research/LiDARNet">LiDARNet: A Boundary-Aware Domain Adaptation Model for Lidar Point Cloud Semantic Segmentation</a></p>

  </article></div>]]>
            </description>
            <link>https://unmannedlab.github.io/research/RELLIS-3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321540</guid>
            <pubDate>Sun, 06 Dec 2020 06:15:43 GMT</pubDate>
        </item>
    </channel>
</rss>
