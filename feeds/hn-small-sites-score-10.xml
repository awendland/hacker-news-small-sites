<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 24 Aug 2020 08:22:27 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 24 Aug 2020 08:22:27 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How Nat Traversal Works]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24241105">thread link</a>) | @signa11
<br/>
August 21, 2020 | https://tailscale.com/blog/how-nat-traversal-works/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/how-nat-traversal-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>We covered a lot of ground in our post about <a href="https://tailscale.com/blog/how-tailscale-works/"><em>How Tailscale
Works</em></a>.  However, we glossed over how we can get through NATs
(Network Address Translators) and connect your devices directly to
each other, no matter what‚Äôs standing between them. Let‚Äôs talk about
that now!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-intro.png">
    
    
</figure>

<p>Let‚Äôs start with a simple problem: establishing a peer-to-peer
connection between two machines. In Tailscale‚Äôs case, we want to set
up a WireGuard¬Æ tunnel, but that doesn‚Äôt really matter. The
techniques we use are widely applicable and the work of many people
over decades. For example, <a href="https://webrtc.org/">WebRTC</a> uses this bag of tricks to
send peer-to-peer audio, video and data between web browsers. VoIP
phones and some video games use similar techniques, though not always
successfully.</p>
<p>We‚Äôll be discussing these techniques generically, using Tailscale and
others for examples where appropriate. Let‚Äôs say you‚Äôre making your
own protocol and that you want NAT traversal. You need two things.</p>
<p>First, the protocol should be based on UDP. You <em>can</em> do NAT traversal
with TCP, but it adds another layer of complexity to an already quite
complex problem, and may even require kernel customizations depending
on how deep you want to go. We‚Äôre going to focus on UDP for the rest
of this article.</p>
<p>If you‚Äôre reaching for TCP because you want a stream-oriented
connection when the NAT traversal is done, consider using QUIC
instead. It builds on top of UDP, so we can focus on UDP for NAT
traversal and still have a nice stream protocol at the end.</p>
<p>Second, you need direct control over the network socket that‚Äôs sending
and receiving network packets. As a rule, you can‚Äôt take an existing
network library and make it traverse NATs, because you have to send
and receive extra packets that aren‚Äôt part of the ‚Äúmain‚Äù protocol
you‚Äôre trying to speak. Some protocols tightly integrate the NAT
traversal with the rest (e.g. WebRTC). But if you‚Äôre building your
own, it‚Äôs helpful to think of NAT traversal as a separate entity that
shares a socket with your main protocol. Both run in parallel, one
enabling the other.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-deep-integration.png">
    
    
</figure>

<p>Direct socket access may be tough depending on your situation. One
workaround is to run a local proxy. Your protocol speaks to this
proxy, and the proxy does both NAT traversal and relaying of your
packets to the peer. This layer of indirection lets you benefit from
NAT traversal without altering your original program.</p>
<p>With prerequisites out of the way, let‚Äôs go through NAT traversal from
first principles. Our goal is to get UDP packets flowing
bidirectionally between two devices, so that our other protocol
(WireGuard, QUIC, WebRTC, ‚Ä¶) can do something cool. There are two
obstacles to having this Just Work: stateful firewalls and NAT
devices.</p>
<h3 id="figuring-out-firewalls">Figuring out firewalls</h3>
<p>Stateful firewalls are the simpler of our two problems. In fact, most
NAT devices include a stateful firewall, so we need to solve this
subset before we can tackle NATs.</p>
<p>There are many incarnations to consider. Some you might recognize are
the Windows Defender firewall, Ubuntu‚Äôs ufw (using iptables/nftables),
BSD‚Äôs pf (also used by macOS) and AWS‚Äôs Security Groups. They‚Äôre all
very configurable, but the most common configuration allows all
‚Äúoutbound‚Äù connections and blocks all ‚Äúinbound‚Äù connections. There
might be a few handpicked exceptions, such as allowing inbound SSH.</p>
<p>But connections and ‚Äúdirection‚Äù are a figment of the protocol
designer‚Äôs imagination. On the wire, every connection ends up being
bidirectional; it‚Äôs all individual packets flying back and forth. How
does the firewall know what‚Äôs inbound and what‚Äôs outbound?</p>
<p>That‚Äôs where the stateful part comes in. Stateful firewalls remember
what packets they‚Äôve seen in the past and can use that knowledge when
deciding what to do with new packets that show up.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-1a.png">
    
    
</figure>

<p>For UDP, the rule is very simple: the firewall allows an inbound UDP
packet if it previously saw a matching outbound packet. For example,
if our laptop firewall sees a UDP packet leaving the laptop from
<code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, it‚Äôll make a note that incoming
packets from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code> are also fine. The
trusted side of the world clearly intended to communicate with
<code>7.7.7.7:5678</code>, so we should let them talk back.</p>
<p>(As an aside, some <em>very</em> relaxed firewalls might allow traffic from
anywhere back to <code>2.2.2.2:1234</code> once <code>2.2.2.2:1234</code> has communicated
with anyone. Such firewalls make our traversal job easier, but are
increasingly rare.)</p>
<h4 id="firewall-face-off">Firewall face-off</h4>
<p>This rule for UDP traffic is only a minor problem for us, as long as
all the firewalls on the path are ‚Äúfacing‚Äù the same way. That‚Äôs
usually the case when you‚Äôre communicating with a server on the
internet. Our only constraint is that the machine that‚Äôs <em>behind</em> the
firewall(s) must be the one initiating all connections. Nothing can
talk to it, unless it talks first.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-2.png">
    
    
</figure>

<p>This is fine, but not very interesting: we‚Äôve reinvented client/server
communication, where the server makes itself easily reachable to
clients. In the VPN world, this leads to a hub-and-spoke topology: the
hub has no firewalls blocking access to it and the firewalled spokes
connect to the hub.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-3.png">
    
    
</figure>

<p>The problems start when two of our ‚Äúclients‚Äù want to talk
directly. Now the firewalls are facing each other. According to the
rule we established above, this means both sides must go first, but
also that neither can go first, because the other side has to go
first!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-4.png">
    
    
</figure>

<p>How do we get around this? One way would be to require users to
reconfigure one or both of the firewalls to ‚Äúopen a port‚Äù and allow
the other machine‚Äôs traffic. This is not very user friendly. It also
doesn‚Äôt scale to mesh networks like Tailscale, in which we expect the
peers to be moving around the internet with some regularity. And, of
course, in many cases you don‚Äôt have control over the firewalls: you
can‚Äôt reconfigure the router in your favorite coffee shop, or at the
airport. (At least, hopefully not!)</p>
<p>We need another option. One that doesn‚Äôt involve reconfiguring
firewalls.</p>
<h4 id="finessing-finicky-firewalls">Finessing finicky firewalls</h4>
<p>The trick is to carefully read the rule we established for our
stateful firewalls. For UDP, the rule is: <strong>packets must flow out
before packets can flow back in.</strong></p>
<p>However, nothing says the packets must be <em>related</em> to each other
beyond the IPs and ports lining up correctly. As long as <em>some</em> packet
flowed outwards with the right source and destination, any packet that
<em>looks like</em> a response will be allowed back in, even if the other
side never received your packet!</p>
<p>So, to traverse these multiple stateful firewalls, we need to share
some information to get underway: the peers have to know in advance
the <code>ip:port</code> their counterpart is using. One approach is to
statically configure each peer by hand, but this approach doesn‚Äôt
scale very far. To move beyond that, we built a <a href="https://tailscale.com/blog/how-tailscale-works/#the-control-plane-key-exchange-and-coordination">coordination
server</a> to keep the <code>ip:port</code> information synchronized in a
flexible, secure manner.</p>
<p>Then, the peers start sending UDP packets to each other. They must
expect some of these packets to get lost, so they can‚Äôt carry any
precious information unless you‚Äôre prepared to retransmit them. This
is generally true of UDP, but especially true here. We‚Äôre <em>going</em> to
lose some packets in this process.</p>
<p>Our laptop and workstation are now listening on fixed ports, so that
they both know exactly what <code>ip:port</code> to talk to. Let‚Äôs take a look at
what happens.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5a.png">
    
    
</figure>

<p>The laptop‚Äôs first packet, from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, goes
through the Windows Defender firewall and out to the internet. The
corporate firewall on the other end blocks the packet, since it has no
record of <code>7.7.7.7:5678</code> ever talking to <code>2.2.2.2:1234</code>. However,
Windows Defender now remembers that it should expect and allow
responses from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code>.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5b.png">
    
    
</figure>

<p>Next, the workstation‚Äôs first packet from <code>7.7.7.7:5678</code> to
<code>2.2.2.2:1234</code> goes through the corporate firewall and across the
internet. When it arrives at the laptop, Windows Defender thinks ‚Äúah,
a response to that outbound request I saw‚Äù, and lets the packet
through! Additionally, the corporate firewall now remembers that it
should expect responses from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, and
that those packets are also okay.</p>
<p>Encouraged by the receipt of a packet from the workstation, the laptop
sends another packet back. It goes through the Windows Defender
firewall, through the corporate firewall (because it‚Äôs a ‚Äúresponse‚Äù to
a previously sent packet), and arrives at the workstation.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5c.png">
    
    
</figure>

<p>Success! We‚Äôve established two-way communication through a pair of
firewalls that, at first glance, would have prevented it.</p>
<h4 id="creative-connectivity-caveats">Creative connectivity caveats</h4>
<p>It‚Äôs not always so easy. We‚Äôre relying on some indirect influence over
third-party systems, which requires careful handling. What do we need
to keep in mind when managing firewall-traversing connections?</p>
<p>Both endpoints must attempt communication at roughly the same time, so
that all the intermediate firewalls open up while both peers are still
around. One approach is to have the peers retry continuously, but this
is wasteful. Wouldn‚Äôt it be better if both peers knew to start
establishing a connection at the same time?</p>
<p>This may sound a little recursive: to communicate, first you need to
be able to communicate. However, this preexisting ‚Äúside channel‚Äù
doesn‚Äôt need to be very fancy: it can have a few seconds of latency,
and only needs to deliver a few thousand bytes in total, so a tiny VM
can easily be a matchmaker for thousands of machines.</p>
<p>In the distant past, I used XMPP chat messages as the side channel,
with great results. As another example, WebRTC requires you to come up
with your own ‚Äúsignalling channel‚Äù (a name that reveals WebRTC‚Äôs IP
telephony ancestry), and plug it into the WebRTC APIs. In Tailscale,
our coordination server and fleet of DERP (Detour Encrypted Routing
Protocol) servers act as ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/how-nat-traversal-works/">https://tailscale.com/blog/how-nat-traversal-works/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241105</guid>
            <pubDate>Sat, 22 Aug 2020 02:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to Zero-Knowledge Proofs with Hands-On Examples]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24240915">thread link</a>) | @mariorz
<br/>
August 21, 2020 | https://dochdoch.gitlab.io/snark_intro/snark_intro_front/ | <a href="https://web.archive.org/web/*/https://dochdoch.gitlab.io/snark_intro/snark_intro_front/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dochdoch.gitlab.io/snark_intro/snark_intro_front/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240915</guid>
            <pubDate>Sat, 22 Aug 2020 01:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bread, How Did They Make It? Part IV: Markets, Merchants and the Tax Man]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24240677">thread link</a>) | @Kednicma
<br/>
August 21, 2020 | https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>As the fourth and final part (<a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">I</a>, <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">II</a>, <a href="https://acoup.blog/2020/08/06/collections-bread-how-did-they-make-it-part-iii-actually-farming/">III</a>) of our look at the basic structure of food production in the pre-modern world (particularly farming grain to make bread), this week we‚Äôre going to look at how at least some of the delicious food we made in the last post might make its way into the hands of people who are <em>not</em> <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>or even<a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/"> farm owners</a>.</p>



<p>In the previous three posts, I have mostly just used the magic word ‚Äòmarkets‚Äô to describe how the food produced in the countryside gets to the cities and people who are not farmers.  As we‚Äôll see in this post, that is a bit of an oversimplifying fib, both in that the phrase ‚Äòmarkets‚Äô covers a <em>lot </em>of complexity, but also (as we‚Äôll see) some of the major drivers of moving that food from the countryside into towns doesn‚Äôt involve money <em>or</em> market interactions.  That said, we‚Äôre going to <em>start</em> with market transactions, because while they are actually the minority-type in many of these societies, they are more readily familiar and understandable, I suspect, to modern readers.  Then we‚Äôll move to <em>extraction</em> as the other category.</p>



<p>Speaking of extraction, as always, if you like what you are reading here, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreo</a>n. And if you want updates whenever a new post appears, you can click the button below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts, as well as my occasional ancient history, foreign policy or pop-culture thoughts.</p>






<h2>Point of Sale</h2>



<p>I want to start by leaning on (with small modifications for clarity) Paul Erdkamp‚Äôs taxonomy of the various options by which food might get into the stream of commerce.  A small farmer might sell their grain (I) directly to city-dwellers, (II) indirectly, via urban middlemen and grain merchants, either in the market or (III) ‚Äòat the gate‚Äô (meaning selling to merchants who come out to the farm in order to buy; the difference being who transports the food to the city), (IV) to itinerant traders at periodic rural markets or (V) to other local small farmers.  As we‚Äôll see, <em>large </em>landholders have a <em>somewhat</em> larger range of options within this taxonomy, but the fundamentals are the same.</p>



<p>While all of these sale methods certainly happened, in every society I have looked at, Option I ‚Äì selling directly to city-dwellers ‚Äì is fairly rare for grains and other bulk agricultural goods.  Market <em>gardeners</em>, selling fruits, vegetables (and sometimes flowers) often do sell this way, maintaining a high-intensity garden near town and a shop or stall in the town market.  Likewise, while Option V ‚Äì small-scale trade between farmers ‚Äì absolutely happens, it is typically non-monetary: the banqueting of neighbors discussed in the first post.  Where it is monetary, it is typically quite small scale and very short distance.  By and large, small and mid-sized farmers hadn‚Äôt the time, expertise or infrastructure to sell their goods directly.  They needed to be farming, not manning a market stall or trying to figure out how to store their goods close to the point of sale.  And of course large landowners, being rich, aren‚Äôt going to stand in the market square either (and in many cases don‚Äôt want their obvious representative doing so either,  see below).  So while I and V happen, they‚Äôre not too common or too large a portion of total trade and we may lay them aside for this discussion.</p>



<p>That leaves Options II, III and IV, all of which involve selling grain to a middle-man merchant of some sort.  The main difference is the location of sale (in town, at the gate, or at periodic rural markets).  Outside of large cities and major ports, markets were likely to be <em>periodic</em>, occurring only on certain days (typically around once per week).  In Roman Italy, these were the <em>nundinae</em> (‚Äòninth days,‚Äô although it was an 8-day cycle as the Romans count inclusively); the <em>nundinae</em> were minor festivals, days of rest and merrymaking, but they were also the days when the rural markets would be open ‚Äì the rest-day from agricultural labor enabled farmers to head into local towns to buy or sell whatever they needed (interestingly, at Rome, the <em>nundinae</em> were <em>dies nefasti</em> ‚Äì state business couldn‚Äôt generally be conducted on them ‚Äì so poor farmers hoping to use their day off to participate politically were out of luck).  Similar periodic markets are common in the Middle Ages (and even today; most ‚Äòfarmer‚Äôs markets‚Äô in the United States are periodic, <a href="http://www.carrborofarmersmarket.com/">including my town‚Äôs</a>).  The periodic nature of these markets is an adaptation to agricultural rhythms; for a market to function there need to be a lot of people together all at once and the small towns that dotted the countryside simply didn‚Äôt have the density to do that all of the time.</p>



<figure><img data-attachment-id="4249" data-permalink="https://acoup.blog/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg" data-orig-size="2325,663" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:Fresco_from_the_House_of_Julia_Felix,_Pompeii_depicting_scenes_from_the_Forum_market.JPG">Via Wikipedia</a>, a fresco showing market activity, with merchants showing off wares of fabric (left) and goods in pots (center) from the House of Julia Felix at Pompeii, first century CE.  Please note: the importance of pottery in modern archaeology has given many students and the general public the idea that the ancients were always shipping pots around for sale, as if there was a vast market in pottery.  <strong>Generally, people were buying what was in the pot, not the pot itself</strong>.</figcaption></figure>



<p>But as noted, our farmers are unlikely to be selling their grain directly to customers.  Instead, they are likely to be using some sort of middle-man merchant, which brings us to:</p>



<h2>Merchants!</h2>



<p>Merchants are a bit of a break from the people we have so far discussed in that they, by definition, live in the realm of the <em>market</em> (in the economic sense, although often also in a physical sense).  As we‚Äôve seen so much of the world of our farmers and even our millers and bakers was governed by <em>non-market</em> interactions: horizontal and vertical social ties that carried expectations that weren‚Äôt quite transactional and certainly not monetized.  By contrast, merchants work with transactions and tend to be the <em>first</em> group in any society to attempt to monetize their operations once money becomes available.  I find students are often quick to feel identity with the merchant class, because these folks are more likely to travel, more likely to use money, more likely to employ or be employed in wage-labor; they feel more like modern people.</p>



<p>It thus tends to come as something of a surprise that with <em>stunning</em> consistency, <strong>the merchant class tended to be at best cordially disliked and at worst <em>despised</em> by the broader community</strong> (although not typically to the point of suffering legal disability, as did some other jobs; see S. Bond, <em>Trade and Taboo: Disreputable Professions in the Roman Mediterranean</em> (2016) for this in Rome).  This often strikes students as strange, both because we tend to think rather better of our own modern merchants but also because the image they have of the merchant class certainly looks elite.</p>



<figure><img data-attachment-id="4257" data-permalink="https://acoup.blog/britlibaddms35166apocalypseunkfolio3sealblackhorse/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg" data-orig-size="1134,766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="britlibaddms35166apocalypseunkfolio3sealblackhorse" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg 1134w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:BritLibAddMS35166ApocalypseUnkFolio3SealBlackHorse.jpg">Via Wikipedia</a>, a manuscript illustration showing the Horseman of Famine depicted as a grain merchant (from Revalations 6:5-6), holding the scales he would use to measure out grain.</figcaption></figure>



<p>For the farmers who need to sell their crops (for reasons we will get to in a moment) and purchase the things they need that they cannot produce, the merchant feels like an adversary: always pushing his prices to his best advantage.  We expect this, but remember that our pre-modern farmers are just <em>not that exposed to market interactions</em>; most of their relationships are reciprocal, not transactional ‚Äì the horizontal relationships we discussed before.  The merchant‚Äôs ‚Äòmoney-grubbing‚Äô feels like a betrayal of trust in a society where you banquet your neighbors in the good years so they‚Äôll help you in the bad years.  <strong>The necessary function of a merchant is to transgress the ‚Äòrules‚Äô of village interactions which ‚Äì and this <em>resounds</em> from the sources ‚Äì the farmers tend to understand as being ‚Äòcheated.‚Äô</strong></p>



<p>At the same time, <strong>while most merchant types are humble, the high-risk and potentially high-reward involved in trade meant that <em>some</em> merchants </strong>(again, a small number) <strong>could become <em>very</em> rich</strong>.  That, as you might imagine, <strong>did not go over well for the traditionally wealthy in these societies</strong>, the large landholders.  Again, the values here often strike modern readers as topsy-turvy compared to our own, but to the elite large landholders (who dominate the literary and political culture of their societies), the <em>morally correct</em> way to earn great wealth is to inherit it (or capture it in war).  The <em>morally correct</em> way to hold that wealth is with large landed estates.  Anything else is <em>morally</em> suspect, and so the idea that a successful merchant could ‚Äì by a process that again, strikes the large landholder, just like the small farmer, as ‚Äòcheating‚Äô ‚Äì leap-frog the social pyramid and skip to the top, without putting in the work at either having distinguished wealthy ancestors <em>or</em> tremendous military success was an open insult to elite values.  Often laws were put in place to limit the ability of wealthy non-aristocrats (likely merchants or successful artisans) from displaying their wealth (<a href="https://en.wikipedia.org/wiki/Sumptuary_law">sumptuary laws</a>) so as to keep them from competing with the aristocrats; at Rome, senators were forbidden from owning ships with much the same logic (Roman senators being clever, they still invested in trade through proxies while at the same time disapproving of the activity in public politics).</p>



<p>Such disdain appears, with varying justification, in the sources of every pre-modern agrarian society I‚Äôve studied, to one degree or another.  One commonplace of Greek and Roman thinking ‚Äì despite these being very active, maritime societies ‚Äì was that the first production of ships and the first sailing was in some essential way a profanation of the divine realm of the sea, a space humans ought not have ever ventured into ‚Äì and certainly not for anything as mean as profit (e.g. Euripides, <em>Medea</em> 1-6; Catullus. 64.1-20; Valerius Flaccus, <em>Argonautica</em> 627-632; Seneca, <em>Medea</em> 1-12; 301-379, <em>inter alia</em> ‚Äì thanks to my old grad school pals <a href="https://www.usf.edu/arts-sciences/departments/world-languages/about-us/hedrick.aspx">Buddy Hedrick</a> and <a href="http://gdrsd.org/gdrhs/faculty/michael-hoffman/">Michael Hoffman </a>for ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240677</guid>
            <pubDate>Sat, 22 Aug 2020 01:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Traceroute in Go ‚Äì Blog]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24239371">thread link</a>) | @rbanffy
<br/>
August 21, 2020 | https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/ | <a href="https://web.archive.org/web/*/https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><em>(<a href="https://github.com/kalbhor/tracesite">link</a> for all the code)</em></p>
<h3 id="what-is-traceroute">What is traceroute?</h3>
<p>If you‚Äôve fiddled with networks you must be familiar with the famous <code>traceroute</code> tool. Its a script that traces the path to a host and prints info on every hop it encounters. To give an example if you run <code>traceroute kalbhor.xyz</code> you should see something like this :</p>
<pre><code>‚ùØ traceroute kalbhor.xyz
traceroute to kalbhor.xyz (18.140.218.13), 64 hops max, 52 byte packets
 1  dlinkrouter.dlink (192.168.0.1)  2.035 ms  1.276 ms  1.097 ms
 2  10.194.0.1 (10.194.0.1)  5.985 ms  4.006 ms  3.817 ms
 3  broadband.actcorp.in (49.207.47.201)  4.320 ms  4.715 ms  4.243 ms
 4  broadband.actcorp.in (49.207.47.225)  5.115 ms  5.390 ms  4.893 ms
 5  14.142.187.85.static-delhi.vsnl.net.in (14.142.187.85)  3.789 ms  3.746 ms  4.004 ms
 6  172.31.180.57 (172.31.180.57)  40.903 ms  41.661 ms  41.531 ms
 7  * * ix-ae-4-2.tcore1.cxr-chennai.as6453.net (180.87.36.9)  177.280 ms
 8  if-ae-13-2.tcore1.svw-singapore.as6453.net (180.87.36.83)  164.288 ms  176.561 ms  82.274 ms
 9  180.87.106.5 (180.87.106.5)  81.871 ms  84.931 ms  83.477 ms
10  52.93.11.197 (52.93.11.197)  82.368 ms  84.777 ms
    52.93.11.211 (52.93.11.211)  82.945 ms
11  52.93.11.79 (52.93.11.79)  83.587 ms
    52.93.11.67 (52.93.11.67)  78.292 ms
    52.93.11.87 (52.93.11.87)  79.452 ms
12  52.93.11.80 (52.93.11.80)  82.862 ms
    52.93.11.82 (52.93.11.82)  86.355 ms
    52.93.11.72 (52.93.11.72)  88.732 ms
13  52.93.9.161 (52.93.9.161)  83.706 ms
    52.93.9.95 (52.93.9.95)  82.498 ms
    52.93.9.139 (52.93.9.139)  84.551 ms
14  203.83.223.77 (203.83.223.77)  84.500 ms
    52.93.10.95 (52.93.10.95)  79.663 ms  79.812 ms
</code></pre><p>These might differ for you but for me this is the route my computer takes to connect to <code>kalbhor.xyz</code>. A few interesting details here include <code>dlinkrouter.dlink (192.168.0.1)</code>. Yes, that looks similar! It is my routers local IP, which means my router at home is the first machine to process my request. That‚Äôs pretty obvious.</p>
<p>Next we see <code>broadband.actcorp.in (49.207.47.201)</code> which is my ISP. We can also see that my request forwards to a ISP router in Delhi (most probably a regional level ISP) and further moves through Chennai and Singapore (kalbhor.xyz is hosted on an AWS Singapore server).</p>
<p>This tool is very useful to inspect network paths and solve problems. But aside from that, this tool is extremely interesting and its actual implementation is pretty simple.</p>
<hr>
<h3 id="how-does-traceroute-work">How does traceroute work?</h3>
<p>Now that we understand what traceroute does, lets take a look under the hood. Every TCP/UDP packet that travels has a bunch of headers containing info about the packet. One such header is the <code>ttl</code> header which is the number of hops the packet travels before being dropped. So if we set this <code>ttl</code> header to 1 our packet will reach the first hop and be dropped, if we set it to 2 our packet will reach the second hop and drop, and so on.</p>
<p>Now that we know how our packets can reach any of the hops between us and our destination, how do we collect info on the hop?
When a server/router drops a packet, it returns a  <code>ICMP Time Exceeded</code> message back. Parsing this message will allow us to retrieve info on the particular hop. Once the destination is reached (last hop) we are returned a <code>ICMP Destination Unreachable</code> message.</p>
<hr>
<h3 id="implementing-traceroute">Implementing traceroute</h3>
<p>Now that we understand what‚Äôs happening under the hood, we can roughly design a way to implement traceroute.
The steps to implement it should look something like this:</p>
<ul>
<li>Open a socket connection between us and our destination and send UDP packets</li>
<li>Start from TTL=1 and keep increasing the TTL value on the UDP packets</li>
<li>Open a socket that listens for the ICMP messages and parses them</li>
</ul>
<hr>
<h3 id="writing-a-go-application-that-implements-traceroute">Writing a Go application that implements traceroute</h3>
<p>Now we know what we want and all we need to do is implement it in any language. I‚Äôm implementing this in Go. The <code>net</code> and <code>syscall</code> package will help us along the way.</p>
<p><em>Note: I will be using minimal code just to show the main implementation (so you probably wont see me handling errors, etc here). For a more refinded well developed version of this code check out <a href="https://github.com/kalbhor/tracesite">the repository</a>.</em></p>
<p>Lets start by creating the sockets we‚Äôll use for sending and recieving data.</p>
<pre><code>sendSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM, syscall.IPPROTO_UDP)
recvSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_ICMP)
defer syscall.Close(recvSocket)
defer syscall.Close(sendSocket)
</code></pre><p>Lets create a ttl variable which we‚Äôll iterate and a timevalue variable that defines our timeout</p>
<pre><code>ttl := 1
// For 2000Ms
tv := syscall.NsecToTimeval(1000 * 1000 * (int64)(2000)) 
</code></pre><p>Next lets set the ttl and timeout value for the packets we‚Äôll send in the socket</p>
<pre><code>syscall.SetsockoptInt(sendSocket, 0x0, syscall.IP_TTL, ttl)
syscall.SetsockoptTimeval(recvSocket, syscall.SOL_SOCKET, syscall.SO_RCVTIMEO, &amp;tv)
</code></pre><p>At this point our sockets are ready to send and recieve data. What we need to do is find the destination address for our <code>sendSocket</code> and a network interface on our machine for our <code>recvSocket</code></p>
<pre><code>func socketAddr() ([4]byte, error) {
    socketAddr := [4]byte{0, 0, 0, 0}
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        return socketAddr, err
    }

    for _, a := range addrs {
        if ipnet, ok := a.(*net.IPNet); ok &amp;&amp; !ipnet.IP.IsLoopback() {
            if len(ipnet.IP.To4()) == net.IPv4len {
                copy(socketAddr[:], ipnet.IP.To4())
                return socketAddr, nil
            }
        }
    }
    err = errors.New("Not connected to the Internet")
    return socketAddr, err
}

func destAddr(dest string) ([4]byte, error) {
    destAddr := [4]byte{0, 0, 0, 0}
    addrs, err := net.LookupHost(dest)
    if err != nil {
        return destAddr, err
    }
    addr := addrs[0]

    ipAddr, err := net.ResolveIPAddr("ip", addr)
    if err != nil {
        return destAddr, err
    }
    copy(destAddr[:], ipAddr.IP.To4())
    return destAddr, nil
}
</code></pre><p>And in our main function we use these functions the get the addresses our sockets will use</p>
<pre><code>destAddr, err := destAddr("google.com")
socketAddr, err := socketAddr()
</code></pre><p>Lets bind our <code>recvSocket</code> so that it can recieve messages and lets send a null byte to our destination through our <code>sendSocket</code>. We connect to the port 33434.</p>
<pre><code>syscall.Bind(recvSocket, &amp;syscall.SockaddrInet4{Port: 33434, Addr: socketAddr})
syscall.Sendto(sendSocket, []byte{0x0}, 0, &amp;syscall.SockaddrInet4{Port: 33434, Addr: destAddr})
</code></pre><p>Now we need to parse the messages being sent on our <code>recvSocket</code></p>
<pre><code>p := make([]byte, options.Int(56)) // The integer here is the packet size
n, from, err := syscall.Recvfrom(recvSocket, p, 0)

ip := from.(*syscall.SockaddrInet4).Addr
ipString := fmt.Sprintf("%v.%v.%v.%v", ip[0], ip[1], ip[2], ip[3])
host, err := net.LookupAddr(ipString)

fmt.Println(host)
fmt.Println(ipString)
</code></pre><p>The Recvfrom method returns a <code>Sockaddr</code> type to our <code>from</code> variable. Hence if we parse our <code>from</code> variable we can get the IP info on the hop. We can use this with <code>net.LookupAddr</code> to run a reverse search and get the hostname (domain name) through the IP.</p>
<p>We‚Äôre almost done! All we need to do is wrap this functionality in a for loop and keep updating the <code>ttl</code> variable.</p>
<pre><code>func main() {
    sendSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM, syscall.IPPROTO_UDP)
    recvSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_ICMP)
    defer syscall.Close(recvSocket)
    defer syscall.Close(sendSocket)

    ttl := 1
    tv := syscall.NsecToTimeval(1000 * 1000 * (int64)(2000)) // For 2000Ms

    for {
        syscall.SetsockoptInt(sendSocket, 0x0, syscall.IP_TTL, ttl)
        syscall.SetsockoptTimeval(recvSocket, syscall.SOL_SOCKET, syscall.SO_RCVTIMEO, &amp;tv)

        destAddr, err := destAddr("google.com")
        socketAddr, err := socketAddr()
        destAddrString := fmt.Sprintf("%v.%v.%v.%v", destAddr[0], destAddr[1], destAddr[2], destAddr[3]) 


        syscall.Bind(recvSocket, &amp;syscall.SockaddrInet4{Port: 33434, Addr: socketAddr})
        syscall.Sendto(sendSocket, []byte{0x0}, 0, &amp;syscall.SockaddrInet4{Port: 33434, Addr: destAddr})

        p := make([]byte, options.Int(56)) // The integer here is the packet size
        n, from, err := syscall.Recvfrom(recvSocket, p, 0)

        ip := from.(*syscall.SockaddrInet4).Addr
        ipString := fmt.Sprintf("%v.%v.%v.%v", ip[0], ip[1], ip[2], ip[3])
        host, err := net.LookupAddr(ipString)
        
        fmt.Println(host)
        fmt.Println(ipString)
        
        // We stop our loop if we reach destination or reach max value for ttl
        if ipString == destAddrString || ttl &gt;= 56 { 
                break
        }

        ttl += 1

    }

}
</code></pre><p>Note that we added an if statement block to end our for loop once we reach the destination address or exceed max value for hops.</p>
<hr>
<h3 id="conclusion">Conclusion</h3>
<p>This is definitely not the most elegant solution but it explains how simple the implementation of <code>traceroute</code> actually is. If you want to check out a more refinded version of this code that compiles well and has many options like set ttl, max hops, timeout, etc check out - <a href="https://github.com/kalbhor/tracesite">My Github Repo</a></p>
<h5 id="voila----we-just-implemented-the-traceroute-tool">Voila  üí´  we just implemented the traceroute tool</h5>

      
      
      
    </div></div>]]>
            </description>
            <link>https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239371</guid>
            <pubDate>Fri, 21 Aug 2020 22:08:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Practical Python ‚Äì Python projects for beginners]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24239266">thread link</a>) | @sixhobbits
<br/>
August 21, 2020 | https://www.codewithrepl.it/python-projects-for-beginners.html | <a href="https://web.archive.org/web/*/https://www.codewithrepl.it/python-projects-for-beginners.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
        <p>
          <h2>
            Python projects for beginners
          </h2>
        </p>
        <div>
          <div>
            <h3>
              Learn to code by example
            </h3>
            <p>
              If you're learning Python, you might have asked "what should I build?" This site is for you. We walk you through 15+ projects using Python (and sometimes NodeJS). By the end, you'll not only have significantly improved your Python skills, but you'll also have some useful apps to use and put in your portfolio.
            </p>
            <p>
            Prefer offline? You can download all of the tutorials in Code with Repl.it in <a href="https://codewithrepl.it/static/code-with-replit.epub">.epub</a>, <a href="https://codewithrepl.it/static/code-with-replit.mobi">.mobi</a> or <a href="https://codewithrepl.it/static/code-with-replit.pdf">.pdf</a> formats, or access each tutorial directly below.
            </p>
            <p>
            You can follow the whole set in order, or pick the ones that look the most interesting and dive right in.
            </p>
            <p>
            Each project uses the online IDE and coding platform <a href="https://repl.it/">repl.it</a> for all examples, so all you'll need to follow along is a free account there.
            </p>
          </div>
          <div>
            <a href="https://github.com/sixhobbits/ritza/blob/master/showcase/repl.it/assets/coding-with-replit.epub?raw=true" target="_blank" rel="noreferrer noopener">
            <p><img alt="Code With Repl.it" src="https://d2sofvawe08yqg.cloudfront.net/coding-with-replit/hero?1596050711">
            </p>
          </a>
          </div>
        </div>
      </section>

      <section id="section-features">
        <p>
          <h2>
            Part 1: Beginner Python projects and Repl.it basics
          </h2>
        </p>

        
          
      </section>

      <section id="section-lessons">
        <p>
          <h2>
            Part 2: Intermediate Python projects and advanced Repl.it
          </h2>
        </p>

        
          
      </section>
      <section id="section-features">
        <p>
          <h2>
            Part 3: Python Projects
          </h2>
        </p>

        
          
            
      </section>
    </div></div>]]>
            </description>
            <link>https://www.codewithrepl.it/python-projects-for-beginners.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239266</guid>
            <pubDate>Fri, 21 Aug 2020 21:53:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over three billion people worldwide now play video games, study reports]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 247 (<a href="https://news.ycombinator.com/item?id=24239234">thread link</a>) | @Gamermeme
<br/>
August 21, 2020 | https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/ | <a href="https://web.archive.org/web/*/https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">
			
			<p><img width="588" height="330" src="https://nintendosmash.com/wp-content/uploads/2020/08/gamers-588x330.jpg" alt="Three billion people worldwide now play video games, study reports">		</p>
	
		


			<div>

							

						
<p>
		
	
	
		
	<span><i></i>1 week ago</span>	
	<span><i></i><a href="https://nintendosmash.com/category/news/" rel="category tag">News</a></span>
	
	
</p>

			
				<div>
					
					
					
<p>By mid-2020, the number of people playing video games had grown to 3.1 billion, according to <a href="https://www.dfcint.com/product/video-game-consumer-segmentation-2/">DFC Intelligence</a>. Considering that in July the total population of the Earth exceeded 7.8 billion, just under 40% are familiar with games.</p>




<p>Analysts point out that almost half of the accounted three billion are those who play only on smartphones or mobile devices. This segment is also ahead of all others in terms of growth.</p>



<p>However, only about 250 million people are active console users who regularly buy new games for them. Although they represent only 8% of the total number of gamers, this is the group with the highest revenue per person.</p>



<p>1.5 billion are playing on PC ‚Äì 48% of all gamers. However, this number includes not only regular users but also those who also enjoy video games on consoles and mobile platforms.</p>



<p>More than half of the world‚Äôs gamers live in Asia ‚Äì there are 1.42 billion players there. Moreover, this region also accounts for 53% of people who play only on smartphones. The top four also include Europe (668 million), Latin America (383 million) and North America (261 million).</p>



<ul><li><figure><img src="https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user.jpg" alt="" data-id="4920" data-link="https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/smartphome-user/" srcset="https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user.jpg 510w, https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user-300x231.jpg 300w" sizes="(max-width: 510px) 100vw, 510px"></figure></li></ul>

 
















<!-- AI CONTENT END 3 -->
					
									</div><!-- .entry /-->
								
				
				 <!-- .share-post -->				
			</div><!-- .post-inner -->
		</article><section id="check-also-box">
		<a href="#" id="check-also-close"><i></i></a>

		<p>
			<h3>Check Also</h3>
		</p>

				<div>
						
			<p><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/zelda-skyword-310x165.jpg" alt="King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/" rel="bookmark">King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch</a></h2>
			<p>In recent days, a rumor has been circulating the network that Zelda: Skyward Sword was ‚Ä¶</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/animal-crossing-granny-island-310x165.jpg" alt="FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/" rel="bookmark">FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND</a></h2>
			<p>Animal Crossing fans may remember Audrey, the 89-year-old grandmother who has famously clocked more than ‚Ä¶</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/04/crysis-for-the-switch-310x165.jpg" alt="Crysis Remastered Coming To PC And Consoles On September 18">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/" rel="bookmark">Crysis Remastered Coming To PC And Consoles On September 18</a></h2>
			<p>Crytek not only announced the release date of the remaster, but also a teaser comparing ‚Ä¶</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/hitman-3-has-become-a-temporary-egs-exclusive/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/hitman3-310x165.jpg" alt="Hitman 3 has become a temporary EGS exclusive">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/hitman-3-has-become-a-temporary-egs-exclusive/" rel="bookmark">Hitman 3 has become a temporary Epic Game Store exclusive</a></h2>
			<p>The developers decided to make a deal with Epic, since they publish the third part ‚Ä¶</p>
		</div>
			</section></div>]]>
            </description>
            <link>https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239234</guid>
            <pubDate>Fri, 21 Aug 2020 21:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F (2006)]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24238846">thread link</a>) | @tosh
<br/>
August 21, 2020 | http://www.nsl.com/k/f/f.htm | <a href="https://web.archive.org/web/*/http://www.nsl.com/k/f/f.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><a href="http://www.nsl.com/k/f/f.k">F</a> is a pure functional concatenative 
language originally designed as an extension of <a href="http://www.nsl.com/papers/false.htm">False</a>. F contains the list-operations of <a href="http://www.kx.com/">K3</a> and the <em>dip</em> combinator 
of <a href="http://www.latrobe.edu.au/philosophy/phimvt/joy.html">Joy</a>. Floating-point and symbolic datatypes are supported. One-time assignment
is enforced in syntax. A theory of function-valence and -charge is outlined. F also contains a general continuation
primitive $, and the pattern sublanguage of <a href="http://www.nsl.com/k/xy/xy.htm">XY</a>.  <a href="http://www.nsl.com/k/f/g.k">G</a> is a variant of F in which the K3 adverbs are implemented as primitives.</p>

<h2>0. Introduction</h2>

<p>F has the following properties:</p>

<blockquote>
    <ul>
        <li>The language is concatenative</li>
        <li>The language is purely functional</li>
        <li>All K verbs are implemented</li>
        <li>All primitives are denoted by single symbols</li>
        <li>Primitive symbols are as mnemonic as possible</li>
    </ul>
</blockquote>

<p><em>The language is concatenative.</em> F tokens are words,
words denote functions, and the concatenation of words denotes
the composition of functions. In classical concatenative
languages, everything is a function from stacks to stacks. In F,
everything is a function from triples of
(environment;stack;queue) to triples of
(environment;stack;queue).</p>

<p><em>The language is purely functional.</em> There are no
side-effects. F has assignment, but not reassignment. This means
that you can't use a variable to store dynamic state. F
assignment associates names with values in an environment which
is passed as an argument and returned as a value. F also has
commands for interacting with the run-time environment and the
file-system, but these operations are notationally differentiated
from the operators of F: "h", "r", &amp;c.
They are intended as debugging aids only.</p>

<p><em>All K verbs are implemented.</em> Some K verbs are
implemented as primitives, and some are derived in the F prelude.
For example, the <em>atom</em> primitive @ of K is defined as
[#ints~]; i.e. shape matches the empty integer vector. Where K
provides a pair of functions, one of which is easily defined in
terms of the other, F implements one as a primitive and derives the
other. For example, <em>and</em> is primitive (&amp;) and <em>or</em>
is derived.  The criterion for dividing related pairs is simply
this:  the derived definition must not be egregiously inefficient
when compared to the primitive it supplants.</p>

<p><em>All primitives are denoted by single symbols.</em>
Although list-notation ([x y z]) is supported, any list can be
constructed functionally with ' (<em>quote</em>) and , (<em>join</em>).</p>

<p><em>Primitive symbols are as mnemonic as possible.</em> There
are five ways the mapping of a function to a symbol can be
mnemonic:</p>

<blockquote>
    <ol>
        <li>The symbol is in common use for the mapped function
            (e.g. + for addition)</li>
        <li>The symbol is mapped to that function in K (e.g. ?
            for <em>find</em>) or False (e.g. ! for <em>unquote</em>)</li>
        <li>The name of the symbol is a homonym for the mapped
            function (e.g. ' for <em>quote</em>)</li>
        <li>A pair of related functions (inverses, or
            near-inverses) are mapped to a pair of related
            symbols (e.g. / and \ for <em>take</em> and <em>drop</em>)</li>
        <li>Where several K primitives are mapped to one symbol,
            the primitives should form an easily remembered group
            based on some common property; e.g. both <em>upgrade</em>
            and <em>enum</em> return indices based on an
            ascending relation, so both are mapped to &lt;. </li>
    </ol>
</blockquote>

<h2>1. Datatypes</h2>

<p>The initial state of the interpreter consists of an
environment containing the F words of the prelude, an empty
result stack, and a string (character-vector) to be evaluated.
The input string is tokenized and parsed to obtain the initial
queue. </p>

<p>The input queue is a K list, possibly containing integers,
floats, symbols, <em>null</em>, functions, and lists
("quotations"). The result stack is initially empty.
The environment is a K dictionary. F processes the environment,
stack, and queue repeatedly until the queue is empty. </p>

<p>If the first item on the queue is an integer, float, <em>null</em>,
the prototype symbol `, or a list, the item is pushed onto the
stack.</p>

<p>If the first item is an undefined symbol, then if it's a <em>shuffle</em>
it's applied; otherwise, a variable is created (in the environment)
having the top of the stack as the value. </p>

<p>If the first item is a defined symbol, its value is
retrieved (from the environment) and pushed onto the stack.</p>

<p>If the first item is a function, then it is applied to the
environment, stack, and queue to produce a new environment,
stack, and queue.</p>

<p>Observe that the domain of the result stack is a proper subset
of the domain of the input queue. On the queue we may find
character-atoms, such as "r", and strings, such as
"blah". But character-atoms are executed away when they
are evaluated, and no F primitive ever produces one, and strings
are comments, which are not processed.</p>

<p>The <em>trace</em> command displays the stack and queue for
selected objects in the trace list T:</p>

<blockquote>
    <pre>F&gt;[fac] "t"

F&gt;3 fac!
                                       3 ‚ô¶ fac !
                                     3 2 ‚ô¶ fac ! *
                                   3 2 1 ‚ô¶ fac ! * *
6
F&gt;

F&gt;[fac cond] "t"

F&gt;3 fac!
                                       3 ‚ô¶ fac !
       3 [1 =] [] [dup ! pred ! fac ! *] ‚ô¶ cond !
                                     3 2 ‚ô¶ fac ! *
     3 2 [1 =] [] [dup ! pred ! fac ! *] ‚ô¶ cond ! *
                                   3 2 1 ‚ô¶ fac ! * *
   3 2 1 [1 =] [] [dup ! pred ! fac ! *] ‚ô¶ cond ! * *
6
F&gt;

F&gt;[] "t"

F&gt;3 fac!
6</pre>
</blockquote>

<h2>2. Primitives</h2>

<h3>Operators (O)</h3>

<blockquote>
    <pre>09*-		int		123 -&gt; 123
09*.09*-	float		123.45 -&gt; 123.45

az.AZ*		name		myName -&gt; value or null
az*-AZ*		shuffle		10 20 ab-ba -&gt; 20 10

[..]		list		[10 + [3 a]] -&gt; [10 + [3 a]]

+		add		1 2 + -&gt; 3
-		sub		2 3 - -&gt; 1
*		mul		3 4 * -&gt; 12
%		div		5 3 % -&gt; 1.666667
^		power		2 3 ^ -&gt; 8
_		floor		3.2 _ -&gt; 3

=		equal		2 2 = -&gt; 1
&gt;		more		4 6 &gt; -&gt; 0
&amp;		and/min		4 3 &amp; -&gt; 3

~		match		[1 2][1 2] ~ -&gt; 1

#		shape		[1 2 3] # -&gt; [3]

|		reverse		[1 2 3] | -&gt; [3 2 1]

@		where		[0 1 1 0 1] @ -&gt; [1 2 4]
@		flip		[[1 2 3][4 5 6]] @ -&gt; [[1 4][2 5][3 6]]

/		take		2[1 2 3] / -&gt; [1 2]
/		reshape		[3 2][1 2 3] / -&gt; [[1 2][3 1][2 3]]

\		drop		2[1 2 3] \ -&gt; [3]
\		cut		[0 2][1 2 3] \ -&gt; [[1 2][3]]
\		rotate		[1 2 3 4] 2 \ -&gt; [3 4 1 2]

?		find		[10 20 30] 20 ? -&gt; 1
?		mod		2 [3 4 5] ? -&gt; [1 0 1]

;		unique		[10 20 10 10 30] ; -&gt; [10 20 30]
:		group		[10 20 10 10 30] : -&gt; [[0 2 3][1][4]]

&lt;		enum		3 &lt; -&gt; [0 1 2]
&lt;		upgrade		[10 30 20] &lt; -&gt; [0 2 1]

.		infra		1 2 [[2 3 +]] . 3 4 -&gt; 1 2 [5] 3 4
.		index		[[1 2 3][[1 0]]] . -&gt; [2 1]
.		monad		[[1 2 3][[1 0]][-1*]] . -&gt; [-1 -2 3]
.		dyad		[[1 2 3][[1 0]]+[3 8]] . -&gt; [9 5 3]

!		unquote		2 [3 +] ! -&gt; 5
`		dip		2 3 4 [+] ` -&gt; 5 4
'		quote		'+ -&gt; [+]

,		join  		[1][2 3] , -&gt; [1 2 3]

$		state		1 2 3 '\ $ 4 5 6 -&gt; 4 5 6 1 2 3

)		s -&gt; s		stack-&gt;stack pattern
(		s -&gt; q		stack-&gt;queue pattern

}		q -&gt; s		queue-&gt;stack pattern
{		q -&gt; q		queue-&gt;queue pattern</pre>
</blockquote>

<h3>System Functions (K)</h3>

<p>The K system functions have reserved names:</p>

<blockquote>
    <pre>type (4::)
log exp abs sqr sqrt floor dot mul inv lsq
sin cos tan asin acos atan sinh cosh tanh
draw
in lin bin binl dv dvl di vs sv</pre>
</blockquote>

<h3>Literals (L)</h3>

<p>F has nine reserved names for literals:</p>

<blockquote>
    <pre>Nan		minint (0N)
Inf		maxint (0I)

nan		NaN (0n)
inf		infinity (0i)

null		null (_n)
sym		prototype sym (`)

ints		empty integer vector (!0)
floats		empty float vector (0#0.)
syms		empty sym vector (0#`)</pre>
</blockquote>

<h3>Commands (I)</h3>

<p>F has the following interactive commands:</p>

<blockquote>
    <pre>".."		comment		1 "skip" 2	comment not processed

"b"		break		'x "b"		signal error ('x)
"c"		clear		1 2 "c" 3 4	clear, load f, prelude
"d"		defined		'foo "d"	is foo defined?
"e"		error		0 "e"		set/unset error trap (\e)
"f"		F		"f" 2 unit!	set F semantics, clear
"j"		Joy		"j" 2 unit	set Joy semantics, clear
"k"		K		1 2 "k" 3 4	exit to K
"l"		load		'x "l"		load f/x.f|x.j
"m"		measure		[10&lt;] "m"	measure time in ms
"o"		words		'map "o"	show word form
"p"		precision	3 "p"		print precision (\p)
"r"		read		1 2 "r" 3 4	read, parse, eval
"s"		store		y 'x "s"	store f/x.f|x.j
"t"		trace		null "t" 3 4	set trace-list (T)
"u"		undefine	x "u"		undefine vars in x
"v"		variables	1 2 "v" 3 4	show vars (!environment)
"x"		exit		1 2 "x" 3 4	_exit 0
"w"		write		1 2 "w" 3 4	format, write
"z"		halt		1 2 "z" 3 4	: to continue
</pre></blockquote>

<h3>Names and numbers</h3>

<p>Spaces (<em>blank</em>, <em>tab</em>, <em>return</em>) are
necessary to separate names from names and numbers from numbers,
but not names from numbers.</p>

<p>A name must begin with a letter and may contain letters, .,
or a single -.  A name containing a - is a shuffle-symbol.</p>

<p>A numerical expression must begin with either a digit or - 
followed by a digit, and must end with a digit.  A floating-point 
numerical expression must contain exactly one . which
must be flanked by digits.</p>

<h3>Operators</h3>

<p>The math, logic, and relational operators are <em>atomic
functions</em>. For example,</p>

<blockquote>
    <pre>F&gt;[1 2 3][[4 5 6] 7 8]+
[[5 6 7] 9 11]</pre>
</blockquote>

<p>In several instances, distinct K operations have been mapped
to one symbol: </p>

<blockquote>
    <pre>int &lt;			enum			!x
~atom &lt;			upgrade			&lt;x
atom &lt;			nonce

int/ints @		where			&amp;x
list @			flip			+x
			nonce

atom y ?		mod			y!x
~atom y ?		find			x?y

list atom \		rotate			y!x
atom list \		drop			x _ y
atom atom \		drop			x _(),y
list list \		cut			x _ y

1=#x .			infra
x .			index/monad/dyad	. x</pre>
</blockquote>

<h3>Iterators</h3>

<p>The False combinators <em>if</em> and <em>while</em> have been
eliminated, and <em>cond</em>, <em>if</em>, and <em>while</em>
have been defined as words in the prelude. The truth-values of F
are more general than those of K: 0 is <em>false</em>, any other
value is <em>true</em>.</p>

<h3>Assignment</h3>

<p>Assignment has the form <em>value unassigned_name</em>. An
assigned name may not be re-assigned.</p>

<p>Reserved names cannot be assigned:</p>

<blockquote>
    <pre>F&gt;12 inf
12 inf</pre>
</blockquote>

<p>Use of an assigned name (a variable) places the value assigned
to it on the stack:</p>

<blockquote>
    <pre>F&gt;10 a

F&gt;a
10
F&gt;12 a
10 12 10
F&gt;a
10 12 10 10</pre>
</blockquote>

<p>A symbol can be produced indirectly:</p>

<blockquote>
    <pre>F&gt;10 foo

F&gt;foo
10
F&gt;[foo] first!
foo
F&gt;!
10</pre>
</blockquote>

<h3>Quotation</h3>

<p>The <em>quote</em> primitive ' takes the next item on the
queue and quotes it:</p>

<blockquote>
    <pre>F&gt;'+
[+]
F&gt;
F&gt;'[1 2 3]
[[1 2 3]]
F&gt;
F&gt;''
[']</pre>
</blockquote>

<p>The <em>unquote</em> combinator ! is Joy's <em>i</em>. ! takes
the top item <em>x</em> on the stack and prepends the elements of
<em>x</em> to the queue:</p>

<blockquote>
    <pre>F&gt;2 3 '+ !
5</pre>
</blockquote>

<p>The <em>dip</em> combinator is defined as it is in Joy. `
takes the top two items <em>x</em> <em>y</em> on the stack and</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nsl.com/k/f/f.htm">http://www.nsl.com/k/f/f.htm</a></em></p>]]>
            </description>
            <link>http://www.nsl.com/k/f/f.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238846</guid>
            <pubDate>Fri, 21 Aug 2020 21:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Technology]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24238641">thread link</a>) | @jacobedawson
<br/>
August 21, 2020 | https://balajis.com/the-purpose-of-technology/ | <a href="https://web.archive.org/web/*/https://balajis.com/the-purpose-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/the-purpose-of-technology--1-.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/the-purpose-of-technology--1-.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/the-purpose-of-technology--1-.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png" alt="The Purpose of Technology">
                </figure>
                <section>
                    <div>
                        <p>If the proximate purpose of technology is to reduce scarcity, the ultimate purpose of technology is to eliminate mortality.</p><p>At first that sounds crazy. But let's start with the premise: is the proximate purpose of technology to reduce scarcity? Think about how a breakthrough is described: faster, smaller, cheaper, better. All of these words mean that with this new technology, one can do <em>more with less</em>. In the digital world, Google made information on any topic free to anyone with an Internet connection, and WhatsApp made it free to communicate with the same. In the physical world, innovations like the <a href="https://en.wikipedia.org/wiki/Haber_process">Haber Process</a> or the <a href="https://en.wikipedia.org/wiki/Norman_Borlaug#Expansion_to_South_Asia:_the_Green_Revolution">Green Revolution</a> allowed us to produce more with less. In a real sense, these technologies <em>reduced scarcity</em>.</p><p>Now for second half of the sentence, the logical implication. Is the ultimate purpose of technology to eliminate mortality? Well, mortality is the main source of scarcity. If we had infinite time, we would be less concerned with whether something was faster. The reason speed has value is because time has value; the reason time has value is because human life has value, and lifespans are finite. If you made lifespans much longer, you'd reduce the effective cost of <em>everything</em>. Thus insofar as reducing scarcity is acknowledged to be the proximate purpose of technology, eliminating the main source of scarcity ‚Äì namely mortality ‚Äì is the ultimate purpose of technology. <strong>Life extension is the most important thing we can invent.</strong></p><p>And it's actually feasible today. It's been shown that we can extend healthy lifespans in mammals ‚Äì and even <em>reverse</em> aging to bring people back to youth. Here's <a href="https://twitter.com/davidasinclair/status/1259084270854905856">link</a> after <a href="https://www.longevity.vc/">link</a> after <a href="https://www.nature.com/articles/s41467-020-15174-3">link</a> after <a href="https://news.harvard.edu/gazette/story/2019/11/researchers-able-to-improve-reverse-age-related-diseases-in-mice/">link</a> on the topic.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Six years ago, a lifetime in the aging field, the mere suggestion that aging could be reversed was enough to have your colleagues &amp; donors screw up their noses. Tom Rando <a href="https://twitter.com/StanfordMed?ref_src=twsrc%5Etfw">@StanfordMed</a> deserves a shout out for being brave enough back then to use the word "reversal" openly 6/n</p>‚Äî David Sinclair, PhD (@davidasinclair) <a href="https://twitter.com/davidasinclair/status/1259912936602177536?ref_src=twsrc%5Etfw">May 11, 2020</a></blockquote>

</figure><p>You probably weren't aware of this, though. You probably also weren't aware of how far we've come on <a href="https://www.nature.com/articles/d41586-020-00339-3">gene therapy</a>, how much has been done in <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">regenerative medicine</a>, how advanced the latest <a href="https://www.nature.com/articles/s41586-020-2285-x">bionic eyes</a> are ‚Äì or how <a href="https://twitter.com/balajis/status/1228447944287932416">deadly</a> COVID-19 was as a threat until March of 2020.</p><h2 id="a-duty-to-evangelize-technological-progress">A duty to evangelize technological progress</h2><p>That is because people with scientific and technical backgrounds have not taken it upon ourselves to write about technological progress <em>as a duty</em>. We need to take time out of our busy days to make the case, repeatedly and with high production values, that technological progress is the <em>most </em>important thing we can do for broad-based prosperity and economic growth, and for life itself.</p><p>That starts with testing, drugs, treatments, and vaccines for COVID-19. But it goes far beyond that. Put another way: we may not get life extension or the whole suite of transhumanist technologies (brain-machine interfaces, stem cells, CRISPR gene therapy, and more) unless you, personally, evangelize them online. Not just tweets, but articles. Not just articles, but videos. Not just videos, but feature films. And not just a few films, but an <a href="https://www.whats-on-netflix.com/news/how-long-would-it-take-to-watch-all-of-netflix/">entire Netflix original library's worth</a>, a parallel tech media ecosystem full of inspirational content for technological progressives. A lifetime's worth of content that makes the case for immutable money, infinite frontier, artificial intelligence, and eternal life.</p><p>This may mean less focus on the businesses and personalities of technology. After all, do we care whether the technology for reversing aging is developed by a startup, an academic lab, a scientific consortium, or a solitary biohacker in their garage? No. What we care about is the goal of transcendence. If the technology ends up being <a href="https://www.amazon.com/Patenting-Sun-Polio-Salk-Vacine/dp/0688094945">completely free</a> and open source, so much the better. A corporate vehicle is just one means to an end, not an end in itself. We may need to understand every detail of operating a business, but we can't get lost in those details.</p><p>The point of doing a startup after all is to build something you can't buy. Money can't yet buy you a trip to <a href="https://www.spacex.com/human-spaceflight/mars/">Mars</a>. Or a <a href="https://www.neuralink.com/">neural implant</a>. Or a <a href="https://tricorder.xprize.org/prizes/tricorder">medical tricorder</a>. And at one point in the not-too-distant past it could not buy you a web browser, a search engine, or a smartphone. When the iPhone did not exist, people had to invent it. And they needed to be inspired to invent it.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>for iphone 1:</p><p>the original mac,<br>blade runner,<br>2001: a space odyssey,<br>sony walkman TPS-L2, <br>braun ET66, <br>the concorde, <br>massimo vignale, <br>henry dreyfuss, <br>apollo 11, <br>the beatles,<br>warp records,<br>NASA,<br>polaroid,<br>arthur c. clarke,<br>eero saarinen</p><p>among others‚Ä¶ <a href="https://t.co/F3ayC03T3y">https://t.co/F3ayC03T3y</a></p></div>‚Äî Imran Chaudhri (@imranchaudhri) <a href="https://twitter.com/imranchaudhri/status/1092194839540584449?ref_src=twsrc%5Etfw">February 3, 2019</a></blockquote>

</figure><h2 id="a-sense-of-purpose">A sense of purpose</h2><p>Why doesn't inspirational content for technological progressives exist in abundance? Part of the reason is adverse selection. While science fiction ‚Äì even dystopian science fiction ‚Äì can inspire, the scientists, engineers, founders, and funders thus inspired are often more occupied with building technology than evangelizing it. But this in turn means that we aren't directly educating the next generation, or the public at large.</p><p>We need to change that. Specifically, people who know math and science, who have experience in managing and investing, who are <em>technological progressives</em> rather than technological conservatives ‚Äì these people need to learn to write, report, publish, and direct. We need to consciously build a parallel tech-driven decentralized media ecosystem, and we need it to become the first point of call for anyone seeking to learn about technology.</p><p>In this we will have allies around the world. Only the very richest people can afford to be cynical about the merits of technological progress. The <a href="https://www.ben-evans.com/benedictevans/2019/5/28/the-end-of-mobile">billions</a> of people who just got their first smartphone have had their lives dramatically improved as a consequence, and are too pragmatic to romanticize the past. If you haven't already internalized this point, take two minutes to watch <a href="https://www.youtube.com/watch?v=QpvEWVVnICE">this</a>.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/QpvEWVVnICE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Back? OK. So, building a media ecosystem for technological progressives clearly starts with technical education. At the K-12 level, we've already got plenty of learning apps, and the next step is remote schools. And at the level of collegiate education and continuous learning, Lambda School, Fast.ai, Coursera, Udacity, Udemy, Binance Academy, and the countless GitHub tutorials are an amazing start. But our duty extends beyond education to media of all kinds, particularly visual media.</p><p>The tech ecosystem has natural advantages here. We have the domain knowledge. And the experts at hand. We're already doing content marketing, podcasts, conferences, and a tweetstorm or two. We understand search engines, social networks, and distribution. And yes, we have learned to code.</p><p>What we haven't done yet is <em>full stack narrative</em>. That is, with a <a href="https://wistia.com/series/one-ten-one-hundred">few exceptions</a>, like Elon Musk, we haven't really told story arcs with technological progress at the center. We haven't taken the pitch we use to recruit engineers and externalized it for the public. We haven't infused <a href="https://twitter.com/balajis/status/1276010131990261761">emotion</a> and meaning into our public communications. We haven't made every one of our companies a media company. We haven't set out to tell our story ourselves.</p><p>We need to correct that immediately, and start evangelizing technological progress with every word and action. To recognize that the purpose of technology is to transcend our limits, and to motivate everything we're doing with a sense of that purpose. To take the winnings from our web apps and <a href="https://www.quora.com/How-did-Elon-Musk-fund-his-businesses-from-PayPal-to-SpaceX-and-Tesla">put them towards Mars</a>, to feel no hesitation towards starting small and no shame in dreaming big, to tell the world that it actually is possible to <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">cure the deaf</a>, <a href="https://www.nature.com/articles/s41586-020-2285-x">restore sight</a>, and <a href="http://med.stanford.edu/news/all-news/2020/03/old-human-cells-rejuvenated-with-stem-cell-technology.html">end</a> <a href="https://www.youtube.com/watch?v=9nXop2lLDa4">death</a> <a href="https://www.ldeming.com/longevityfaq">itself</a>.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/the-purpose-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238641</guid>
            <pubDate>Fri, 21 Aug 2020 20:38:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai releases new deep learning course]]>
            </title>
            <description>
<![CDATA[
Score 609 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24237207">thread link</a>) | @amardeep
<br/>
August 21, 2020 | https://www.fast.ai/2020/08/21/fastai2-launch/ | <a href="https://web.archive.org/web/*/https://www.fast.ai/2020/08/21/fastai2-launch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>Written: 21 Aug 2020 by <i>Jeremy Howard</i></span></p><p>fast.ai is a self-funded research, software development, and teaching lab, focused on making deep learning more accessible. We make all of our software, research papers, and courses freely available with no ads. We pay all of our costs out of our own pockets, and take no grants or donations, so you can be sure we‚Äôre truly independent.</p>

<p>Today is fast.ai‚Äôs biggest day in our four year history. We are releasing:</p>

<ul>
  <li><a href="https://docs.fast.ai/">fastai v2</a>: A complete rewrite of fastai which is faster, easier, and more flexible, implementing new approaches to deep learning framework design, as discussed in the peer reviewed fastai <a href="https://www.mdpi.com/2078-2489/11/2/108/htm">academic paper</a></li>
  <li><a href="https://fastcore.fast.ai/">fastcore</a>, <a href="https://fastscript.fast.ai/">fastscript</a>, and <a href="https://fastgpu.fast.ai/">fastgpu</a>: Foundational libraries used in fastai v2, and useful for many programmers and data scientists</li>
  <li><a href="https://course.fast.ai/">Practical Deep Learning for Coders</a> (2020 course, part 1): Incorporating both an introduction to machine learning, and deep learning, and production and deployment of data products</li>
  <li><a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD</a>: A book from O‚ÄôReilly, which covers the same material as the course (including the content planned for part 2 of the course)</li>
</ul>

<p>Also, in case you missed it, earlier this week we released the <a href="https://ethics.fast.ai/">Practical Data Ethics</a> course, which focuses on topics that are both urgent and practical.</p>

<h3 id="contents">Contents</h3>

<ul id="markdown-toc">
  <li><a href="#fastai-v2" id="markdown-toc-fastai-v2">fastai v2</a></li>
  <li><a href="#practical-deep-learning-for-coders-the-course" id="markdown-toc-practical-deep-learning-for-coders-the-course">Practical Deep Learning for Coders, the course</a></li>
  <li><a href="#deep-learning-for-coders-with-fastai-and-pytorch-the-book" id="markdown-toc-deep-learning-for-coders-with-fastai-and-pytorch-the-book">Deep Learning for Coders with fastai and PyTorch, the book</a></li>
  <li><a href="#fastcore-fastscript-and-fastgpu" id="markdown-toc-fastcore-fastscript-and-fastgpu">fastcore, fastscript, and fastgpu</a>    <ul>
      <li><a href="#fastcore" id="markdown-toc-fastcore">fastcore</a></li>
      <li><a href="#fastscript" id="markdown-toc-fastscript">fastscript</a></li>
      <li><a href="#fastgpu" id="markdown-toc-fastgpu">fastgpu</a></li>
    </ul>
  </li>
  <li><a href="#acknowledgements" id="markdown-toc-acknowledgements">Acknowledgements</a></li>
</ul>

<h2 id="fastai-v2">fastai v2</h2>

<p>fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes:</p>

<ul>
  <li>A new type dispatch system for Python along with a semantic type hierarchy for tensors</li>
  <li>A GPU-optimized computer vision library which can be extended in pure Python</li>
  <li>An optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 45 lines of code</li>
  <li>A novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training</li>
  <li>A new data block API</li>
  <li>And much more‚Ä¶</li>
</ul>

<figure>
  <img srcset="https://www.fast.ai/images/layered.png 2w" sizes="1px" src="https://www.fast.ai/images/layered.png">
  
  <figcaption>fastai's layered architecture</figcaption>
  
</figure>

<p>fastai is organized around two main design goals: to be approachable and rapidly productive, while also being deeply hackable and configurable. It is built on top of a hierarchy of lower-level APIs which provide composable building blocks. This way, a user wanting to rewrite part of the high-level API or add particular behavior to suit their needs does not have to learn how to use the lowest level.</p>

<p>To see what‚Äôs possible with fastai, take a look at the <a href="https://docs.fast.ai/quick_start.html">Quick Start</a>, which shows how to use around 5 lines of code to build an image classifier, an image segmentation model, a text sentiment model, a recommendation system, and a tabular model. For each of the applications, the code is much the same.</p>

<figure>
  <img srcset="https://www.fast.ai/images/segmentation-fastai.png 2w" sizes="1px" src="https://www.fast.ai/images/segmentation-fastai.png">
  
  <figcaption>Example of using fastai for image segmentation</figcaption>
  
</figure>

<p>Read through the <a href="https://docs.fast.ai/tutorial">Tutorials</a> to learn how to train your own models on your own datasets. Use the navigation sidebar to look through the fastai documentation. Every class, function, and method is documented here. To learn about the design and motivation of the library, read the <a href="https://www.mdpi.com/2078-2489/11/2/108/htm">peer reviewed paper</a>, or watch <a href="https://youtu.be/bHVqO5YyNbU">this presentation</a> summarizing some of the key design points.</p>

<p>All fast.ai projects, including fastai, are built with <a href="https://nbdev.fast.ai/">nbdev</a>, which is a full <a href="https://www.fast.ai/2019/12/02/nbdev/">literate programming environment</a> built on Jupyter Notebooks. That means that every piece of documentation can be accessed as interactive Jupyter notebooks, and every documentation page includes a link to open it directly on Google Colab to allow for experimentation and customization.</p>

<p>It‚Äôs very easy to migrate from plain PyTorch, Ignite, or any other PyTorch-based library, or even to use fastai in conjunction with other libraries. Generally, you‚Äôll be able to use all your existing data processing code, but will be able to reduce the amount of code you require for training, and more easily take advantage of modern best practices. Here are migration guides from some popular libraries to help you on your way: <a href="https://docs.fast.ai/migrating_pytorch">Plain PyTorch</a>; <a href="https://docs.fast.ai/migrating_ignite">Ignite</a>; <a href="https://docs.fast.ai/migrating_lightning">Lightning</a>; <a href="https://docs.fast.ai/migrating_catalyst">Catalyst</a>. And because it‚Äôs easy to combine and part of the fastai framework with your existing code and libraries, you can just pick the bits you want. For instance, you could use fastai‚Äôs GPU-accelerated computer vision library, along with your own training loop.</p>

<p>fastai includes many modules that add functionality, generally through callbacks. Thanks to the flexible infrastructure, these all work together, so you can pick and choose what you need (and add your own), including: <a href="https://arxiv.org/abs/1710.09412">mixup</a> and <a href="https://arxiv.org/abs/1708.04552">cutout</a> augmentation, a uniquely flexible <a href="https://docs.fast.ai/vision.gan.html">GAN training</a> framework, a range of schedulers (many of which aren‚Äôt available in any other framework) including support for fine tuning following the approach described in <a href="https://arxiv.org/abs/1801.06146">ULMFiT</a>, mixed precision, gradient accumulation, support for a range of logging frameworks like Tensorboard (with particularly strong support for Weights and Biases, as <a href="https://app.wandb.ai/borisd13/demo_config/reports/Visualize-track-compare-Fastai-models--Vmlldzo4MzAyNA">demonstrated here</a>), <a href="http://docs.fast.ai/medical.imaging">medical imaging</a>, and much more. Other functionality is added through the <a href="https://github.com/nestordemeure/fastai-extensions-repository">fastai ecosystem</a>, such as support for <a href="https://ohmeow.github.io/blurr/">HuggingFace Transformers</a> (which can also be done manually, as shown in <a href="http://docs.fast.ai/tutorial.transformers">this tutorial</a>), <a href="https://github.com/rbracco/fastai2_audio">audio</a>, <a href="https://muellerzr.github.io/fastinference/inference/">accelerated inference</a>, and so forth.</p>

<figure>
  <img srcset="https://www.fast.ai/images/medical-fastai.png 2w" sizes="1px" src="https://www.fast.ai/images/medical-fastai.png">
  
  <figcaption>Medical imaging in fastai</figcaption>
  
</figure>

<p>There‚Äôs already some great learning material made available for fastai v2 by the community, such as the ‚ÄúZero to Hero‚Äù series by Zach Mueller: <a href="https://muellerzr.github.io/fastblog/2020/08/20/_08_21-beginner.html">part 1</a>; <a href="https://muellerzr.github.io/fastblog/2020/08/20/_08_21-intermediate.html">part 2</a>.</p>

<h2 id="practical-deep-learning-for-coders-the-course">Practical Deep Learning for Coders, the course</h2>

<p>Previous fast.ai courses have been studied by hundreds of thousands of students, from all walks of life, from all parts of the world. Many students have told us about how they‚Äôve become <a href="https://forums.fast.ai/t/my-first-gold-medal/54237">multiple gold medal winners</a> of <a href="https://towardsdatascience.com/my-3-year-journey-from-zero-python-to-deep-learning-competition-master-6605c188eec7">international machine learning competitions</a>, <a href="https://forums.fast.ai/t/how-has-your-journey-been-so-far-learners/6480/2">received offers</a> from top companies, and <a href="https://icml-compbio.github.io/2020/papers/WCBICML2020_paper_67.pdf">having</a> <a href="https://ui.adsabs.harvard.edu/abs/2020EGUGA..2221465A/abstract">research</a> <a href="https://arxiv.org/pdf/2004.14356.pdf">papers</a> <a href="https://pubs.rsna.org/doi/abs/10.1148/ryai.2019190113?journalCode=ai">published</a>. For instance, Isaac Dimitrovsky <a href="https://forums.fast.ai/t/thanks-ra2-dream-challenge-win/76875">told us</a> that he had ‚Äú<em>been playing around with ML for a couple of years without really grokking it‚Ä¶ [then] went through the fast.ai part 1 course late last year, and it clicked for me</em>‚Äù. He went on to achieve first place in the prestigious international <a href="https://www.synapse.org/#!Synapse:syn20545111/wiki/594083">RA2-DREAM Challenge</a> competition! He developed a <a href="https://www.synapse.org/#!Synapse:syn21478998/wiki/604432">multistage deep learning method</a> for scoring radiographic hand and foot joint damage in rheumatoid arthritis, taking advantage of the fastai library.</p>

<p><a href="https://course.fast.ai/">This year‚Äôs course</a> takes things even further. It incorporates both machine learning and deep learning in a single course, covering topics like random forests, gradient boosting, test and validation sets, and p values, which previously were in a separate machine learning course. In addition, production and deployment are also covered, including material on developing a web-based GUI for our own deep learning powered apps. The only prerequisite is high-school math, and a year of coding experience (preferably in Python). The course was recorded live, in conjunction with the <a href="https://www.usfca.edu/data-institute">Data Institute</a> at the University of San Francisco.</p>

<p>After finishing this course you will know:</p>

<ul>
  <li>How to train models that achieve state-of-the-art results in:
    <ul>
      <li>Computer vision, including image classification (e.g.,classifying pet photos by breed), and image localization and detection (e.g.,finding where the animals in an image are)</li>
      <li>Natural language processing (NLP), including document classification (e.g.,movie review sentiment analysis) and language modeling</li>
      <li>Tabular data (e.g.,sales prediction) with categorical data, continuous data, and mixed data, including time series</li>
      <li>Collaborative filtering (e.g.,movie recommendation)</li>
    </ul>
  </li>
  <li>How to turn your models into web applications, and deploy them</li>
  <li>Why and how deep learning models work, and how to use that knowledge to improve the accuracy, speed, and reliability of your models</li>
  <li>The latest deep learning techniques that really matter in practice</li>
  <li>How to implement stochastic gradient descent and a complete training loop from scratch</li>
  <li>How to think about the ethical implications of your work, to help ensure that you‚Äôre making the world a better place and that your work isn‚Äôt misused for harm</li>
</ul>

<p>We care a lot about teaching, using a <a href="https://www.fast.ai/2016/10/08/teaching-philosophy/">whole game</a> approach. In this course, we start by showing how to use a complete, working, very usable, state-of-the-art deep learning network to solve real-world problems, using simple, expressive tools. And then we gradually dig deeper and deeper into understanding how those tools are made, and how the tools that make those tools are made, and so on. We always teach through examples. We ensure that there is a context and a purpose that you can understand intuitively, rather than starting with algebraic symbol manipulation. We also dive right into the details, showing you how to build all the components of a deep learning model from scratch, including discussing performance and optimization details.</p>

<p>The whole course can be completed for free without any installation, by taking advantage of the guides for the Colab and Gradient platforms, which provide free, GPU-powered Notebooks.</p>

<h2 id="deep-learning-for-coders-with-fastai-and-pytorch-the-book">Deep Learning for Coders with fastai and PyTorch, the book</h2>

<p>To understand what the new book is about, and who it‚Äôs for, let‚Äôs see what others have said about it‚Ä¶ Soumith Chintala, the co-creator of PyTorch, said in <a href="https://www.fast.ai/2020/08/20/soumith-forward/">the foreword</a> to  <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch</a>:</p>

<blockquote>
  <p>But unlike me, Jeremy and ‚Ä¶</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fast.ai/2020/08/21/fastai2-launch/">https://www.fast.ai/2020/08/21/fastai2-launch/</a></em></p>]]>
            </description>
            <link>https://www.fast.ai/2020/08/21/fastai2-launch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24237207</guid>
            <pubDate>Fri, 21 Aug 2020 17:51:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficiency is dangerous and slowing down makes life better]]>
            </title>
            <description>
<![CDATA[
Score 606 | Comments 268 (<a href="https://news.ycombinator.com/item?id=24236489">thread link</a>) | @joubert
<br/>
August 21, 2020 | https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>√¢‚Ç¨ÀúSlow down, you move too fast <em>√¢‚Ç¨¬¶</em>√¢‚Ç¨‚Ñ¢ <br>√¢‚Ç¨‚Äú √¢‚Ç¨ÀúThe 59th Street Bridge Song (Feelin√¢‚Ç¨‚Ñ¢ Groovy)√¢‚Ç¨‚Ñ¢ (1966) by Paul Simon</blockquote>
<p><strong>We worship efficiency</strong>. Use less to get more. Same-day delivery. Multitask; text on one device while emailing on a second, and perhaps conversing on a third. Efficiency is seen as good. Inefficiency as wasteful.</p>
<p>There√¢‚Ç¨‚Ñ¢s a sound rationale for thinking this way. Economists teach us that increased efficiency is the major way to improve our standard of living. If your company gives you a pay rise without becoming more efficient, it will also have to raise its prices to make up the shortfall. If all companies do the same, everyone ends up running in place √¢‚Ç¨‚Äú you√¢‚Ç¨‚Ñ¢ll need your higher wages to match the higher prices of the things you buy. So, if we want to make material progress, we must become more efficient. Streamlined supply chains, just-in-time deliveries and no slack in the workforce all serve to raise efficiency. Achieve this, and all our lives will get better and better, or so we√¢‚Ç¨‚Ñ¢re promised.</p>
<p>For automobile manufacturers, who wish to squeeze as many miles per gallon as possible out of their car designs, air resistance and the grab of the road are the enemies of efficiency. In the world of finance, it is at the point of exchange that most friction arises. Before money, the potato farmer had to use sacks of potatoes to trade for eggs and milk. As the British historian Niall Ferguson reminds us in his <a href="https://www.penguin.co.uk/books/178/178638/the-ascent-of-money/9780141990262.html">book</a> <em>The Ascent of Money</em> (2008), the invention of money went a long way toward reducing this inefficiency, and much that has happened in the financial world over the past 200 years can be seen as a continuation of that revolution.</p>
<p>Credit, for example, meant that you could go shopping for eggs and milk even without having the money right now. Financial markets have since taken this efficiency to another level. The creation of √¢‚Ç¨Àúoption markets√¢‚Ç¨‚Ñ¢ means that you don√¢‚Ç¨‚Ñ¢t have to go to the trouble of buying a stock that you√¢‚Ç¨‚Ñ¢re going to be selling soon anyway. You can just promise to buy it, and then sell it at a price and date specified by the option contract. And then you can trade the option rather than the underlying stock.</p>
<p>Each of these developments and many others have made it easier to do one√¢‚Ç¨‚Ñ¢s business without wasted time and energy √¢‚Ç¨‚Äú without friction. Each has made economic transactions quicker and more efficient. That√¢‚Ç¨‚Ñ¢s obviously good in some ways. But the financial crisis of 2008 suggested that maybe there could be too much of a good thing. If mortgages and other loans hadn√¢‚Ç¨‚Ñ¢t been transformed into tradable assets (√¢‚Ç¨Àúsecurities√¢‚Ç¨‚Ñ¢), then bankers might have taken the time to assess the credit-worthiness of each applicant. If people had to visit a bank to withdraw cash, they might spend less and save more. This is not mere speculation √¢‚Ç¨‚Äú for instance, <a href="https://doi.org/10.1002/(SICI)1099-0771(199909)12:3%3c183::AID-BDM318%3e3.0.CO;2-F">research</a> <a href="https://doi.org/10.1016/0167-2681(80)90051-7">reviewed</a> by the Nobel Prize-winning economist Richard Thaler shows that people will pay more for an item with a credit card than with cash. Arguably, a little friction to slow us down would have enabled both institutions and individuals to make better financial decisions.</p>
<p>A decade ago, the American psychologist Adam Grant and I argued in a journal <a href="https://journals.sagepub.com/doi/full/10.1177/1745691610393523?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub%20%200pubmed">paper</a> that this √¢‚Ç¨Àútoo much of a good thing√¢‚Ç¨‚Ñ¢ phenomenon might be a general rule. Some motivation produces excellent performance; too much motivation produces choking. Some group collaboration produces cohesion and enhances productivity; too much of it leads to staleness. Some empathy enables you to understand what another person is going through; too much could prevent you from saying and doing hard things. Similarly, in my <a href="https://www.harpercollins.com/products/the-paradox-of-choice-barry-schwartz?variant=32207920234530">book</a> <em>The Paradox of Choice</em> (2004), I argued that, whereas a life with no freedom to choose is not worth living, a life with too much choice leads to paralysis, bad decisions and dissatisfaction. Finding the right amount √¢‚Ç¨‚Äú what Aristotle called the √¢‚Ç¨Àúmean√¢‚Ç¨‚Ñ¢ √¢‚Ç¨‚Äú of motivation, collaboration, empathy, choice and many other aspects of life, including efficiency, is a key challenge we face, both as individuals and as a society.</p>
<p>To be better prepared next time, we need to learn to live less efficiently in the here and now</p>
<p>But finding the mean isn√¢‚Ç¨‚Ñ¢t easy. As the English poet William Blake observed in <em>The Marriage of Heaven and Hell</em> (1790-93): √¢‚Ç¨ÀúYou never know what is enough unless you know what is more than enough.√¢‚Ç¨‚Ñ¢</p>
<p><strong>If the financial crisis</strong> taught us that we had become too efficient with our transactions, what of the COVID-19 pandemic? Why hadn√¢‚Ç¨‚Ñ¢t we stockpiled key supplies and machines, built up hospital capacity, or ensured the robustness of our supply chains? The reason, of course, is that it would have been seen as inefficient and profit-robbing. Money spent on masks and gowns gathering dust in a warehouse could always be put to more √¢‚Ç¨Àúproductive√¢‚Ç¨‚Ñ¢ use in the marketplace. Likewise, employing more people than needed under √¢‚Ç¨Àúordinary√¢‚Ç¨‚Ñ¢ circumstances, or making products yourself rather than relying on international supply chains, would have been seen as inefficient. One lesson, then, is that to be better prepared next time, we need to learn to live less √¢‚Ç¨Àúefficiently√¢‚Ç¨‚Ñ¢ in the here and now.</p>
<p>Seen in this light, at least some inefficiency is like an insurance policy. Think about your own situation. Every year that you don√¢‚Ç¨‚Ñ¢t get into a car accident and your house doesn√¢‚Ç¨‚Ñ¢t burn down and you stay healthy, you could think to yourself that you have √¢‚Ç¨Àúwasted√¢‚Ç¨‚Ñ¢ your money on various pointless insurance products, and that you√¢‚Ç¨‚Ñ¢d be financially better off without all those insurance premiums to pay.</p>
<p>Most of us don√¢‚Ç¨‚Ñ¢t like the sense that we√¢‚Ç¨‚Ñ¢re wasting money on insurance. We would rather be wearing that money, or eating it, or driving it. Some years ago, with a struggle, I convinced my ageing mother to supplement her basic health insurance policy with a more comprehensive insurance product. Her resources were modest and the policy wasn√¢‚Ç¨‚Ñ¢t cheap. The year went by and, happily, she had no serious medical conditions that required the use of the extra cover. When the time came to renew, my mother resisted, because, indeed, the money she spent the year before had been √¢‚Ç¨Àúwasted√¢‚Ç¨‚Ñ¢. My reply, perhaps unduly snarky, was to suggest to her that maybe the next year she would get lucky, have a really serious illness, and get her money√¢‚Ç¨‚Ñ¢s worth out of her insurance.</p>
<p>Thankfully, in many domains, government regulations protect us from our desire for ever-greater personal financial efficiency by forcing us to have insurance. Laws require that our cars be insured, and mortgagers require the same for our homes. In the United States, √¢‚Ç¨ÀúObamacare√¢‚Ç¨‚Ñ¢ (the Affordable Care Act enacted in 2010, designed to increase the number of US citizens covered by health insurance) essentially compelled people to have health insurance, until the Supreme Court challenged this aspect of the Act as unconstitutional. I suspect that many of us are underinsured in general, but the problem would be much worse without these various, state-imposed insurance requirements.</p>
<p>One way to think about insurance, however inefficient it might feel, is that it enables us to be resilient against shocks that could befall us from a world that is radically uncertain. And the world <em>is</em> radically uncertain. As the British economists John Kay and Mervyn King point out in their <a href="https://wwnorton.com/books/9781324004776">book</a> <em>Radical Uncertainty</em> (2020), efforts to quantify risk by attaching probabilities to various unlikely future states of the world are mostly science fiction. The world is much messier than a roulette wheel or a pair of dice.</p>
<p>A little bit of friction can forestall disaster when you encounter an icy road</p>
<p><strong>What should we do</strong> in the face of this radical uncertainty? When making decisions, instead of asking ourselves which option will give us the best results, we should be asking which option will give us good-enough results under the widest range of future states of the world. Instead of trying to maximise return on investment in our retirement account, we should be setting a financial goal and then choosing investments that will allow us to achieve that goal under the widest set of future financial circumstances. Instead of looking for the √¢‚Ç¨Àúbest√¢‚Ç¨‚Ñ¢ job, we should be looking for a job that will be good enough √¢‚Ç¨‚Äú satisfying enough √¢‚Ç¨‚Äú as co-workers and managers come and go, and the future economy gyrates. Instead of choosing the best college to go to, we should be choosing a college that will be good enough, even with an obnoxious roommate and a boring Bio 1 teacher.</p>
<p>The term used to describe this approach to decision-making is <em>satisficing</em>. And satisficing with an eye toward a radically uncertain future might be called <em>robust satisficing</em>. Satisficing is a form of insurance √¢‚Ç¨‚Äú insurance against financial meltdowns, global pandemics, nasty bosses, boring teachers and crappy roommates. Insurance can seem stodgy √¢‚Ç¨‚Äú like the guy who wears a belt <em>and</em> suspenders. Perhaps we don√¢‚Ç¨‚Ñ¢t need both, but what happens if we have neither?</p>
<p>I think the real flaw in capitalism revealed by the 2008 financial crisis was its unbridled, single-minded pursuit of profit and efficiency. And perhaps the real flaw revealed in our lack of readiness for the 2019-20 pandemic was a manifestation of the same thing. Capitalism needn√¢‚Ç¨‚Ñ¢t be either unbridled or single-minded. It isn√¢‚Ç¨‚Ñ¢t in other societies with high standards of living, and it hasn√¢‚Ç¨‚Ñ¢t been at all points in history in the US. So perhaps it√¢‚Ç¨‚Ñ¢s time to rekindle certain social norms that serve to slow us down. For example, if people thought about their homes less as financial investments and more as places to live, full of the friction of kids, dogs, friends, neighbours and community, there might be less property speculation with an eye toward buying and selling houses merely for profit. If companies felt the friction of being caretakers of their communities, they might look differently at streamlining their operations by eliminating jobs.</p>
<p>We√¢‚Ç¨‚Ñ¢d all like a car that gets 100 miles to a gallon. The forces of ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better">https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236489</guid>
            <pubDate>Fri, 21 Aug 2020 16:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ammonia as a fuel for compression ignition engines]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24236204">thread link</a>) | @airstrike
<br/>
August 21, 2020 | https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/ | <a href="https://web.archive.org/web/*/https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>The diesel engine, also known as the compression ignition (CI) engine, has been a workhorse of the modern energy economy for more than a hundred years.&nbsp;Its role in the coming sustainable energy economy will be determined by its ability to co-evolve with climate-friendly fuels.&nbsp;Two researchers from the National Institute of Advanced Industrial Science and Technology in Japan have now examined the fit between ammonia and the CI engine.&nbsp;</p><p>Pavlos Dimitriou and Rahat Javaid arrive at a two-part conclusion in their paper, ‚Äú<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.sciencedirect.com/science/article/abs/pii/S0360319920300124" target="_blank">A review of ammonia as a compression ignition engine fuel</a>,‚Äù published in January in the <em>International Journal of Hydrogen Energy</em>. Part one is good news: ‚ÄúAmmonia as a compression ignition fuel can be currently seen as a feasible solution.‚Äù&nbsp;Part two is a dose of qualifying reality: to manage emissions of N2O, NOx, and unburnt NH3, ‚Äúaftertreatment systems are mandatory for the adaptation of this technology,‚Äù which means that ammonia-fueled CI engines are likely to be feasible ‚Äúonly for marine, power generation and possibly heavy-duty applications where no significant space constraints exist.‚Äù</p><p>The paper provides a detailed and readable account of efforts over the last eight decades to develop a viable version of an ammonia-fueled CI engine.&nbsp;The authors state that, ‚Äúto the best of [their] knowledge, this is the first review approach focusing entirely on ammonia utilisation for compression ignition.‚Äù&nbsp;A major challenge confronted by the development efforts derives from ammonia‚Äôs ‚Äúpoor combustion characteristics ‚Ä¶ such as high autoignition temperature, low flame speed, narrow flammability limits and high heat of vaporization.‚Äù They continue, ‚Äúsuccessful ammonia compression ignition operation could only be observed for engine designs that featured extremely high compression ratios from 35:1 to 100:1.‚Äù</p><p>To address this challenge, most researchers resorted to the expedient of co-combustion.&nbsp;With the addition of fuels like diesel, biodiesel, and dimethyl ether, ‚Äúthe combustion of ammonia ‚Ä¶ is a realistic conception, as the secondary fuel, with lower Autoignition temperature, can be used to trigger the combustion of the mixture.‚Äù&nbsp;Different researchers have used a variety of fuel ratios under a variety of conditions.&nbsp;Ammonia ratios as high as 95% have been achieved, but numbers in the range of 40 to 80% are more prevalent in the literature. Hydrogen has been used successfully as the complementary fuel.&nbsp;This includes hydrogen derived from on-board ammonia cracking, but the authors of one study determined that ‚Äúthe introduction of pure hydrogen [from an off-board source] seems to be the most promising in terms of emissions reduction and engine performance enhancement.‚Äù</p><p>The dual-fuel approach opens the door to CI for ammonia, but another challenge soon arises: when ammonia is burned as a CI fuel, it tends to produce problematic levels of nitrogen oxides and unburned ammonia. To compound the issue, NOx tends to be a product of high combustion temperatures and unburned ammonia of low temperatures ‚Äì and there is no ‚Äúsweet spot‚Äù temperature where neither species is a problem.&nbsp;</p><p>Contemporary researchers are attacking this problem with two methods.&nbsp;The first is with advanced fuel injection techniques.&nbsp;By injecting fuel at several points during the engine‚Äôs compression stroke, with fine control of the fuel increments, it is possible to achieve ‚Äúsimultaneous reduction of N2O and NH3 emissions in ammonia dual-fuel engines.‚Äù&nbsp;The second method is exhaust after-treatment.&nbsp;Selective catalytic reduction (SCR) technologies have been found that can reduce both NOx and unburned ammonia to acceptable levels, a result furthered by ‚Äúthe effect of ammonia in NOx reduction as observed in the modern after-treatment systems.‚Äù</p><p>The authors‚Äô conclusion that ammonia is unlikely to become a major fuel for passenger cars will not come as a surprise to most members of the ammonia energy community.&nbsp;Ships, of course, are a different story.</p><p>Engine manufacturer MAN Energy Solutions expects to bring its dual-fueled maritime engine to market in 2024. (An <em>Ammonia Energy</em> <a href="https://www.ammoniaenergy.org/articles/man-ammonia-engine-update/">update on the MAN ammonia engine</a> appeared in January.)&nbsp;Success in the maritime realm will certainly encourage development of engines scaled for off-grid and back-up power generation.&nbsp;For other transportation applications, long the near-exclusive province of internal combustion, CI might have its hands full fighting off electrification via battery and fuel cell.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236204</guid>
            <pubDate>Fri, 21 Aug 2020 16:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Nat Traversal Works]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24236010">thread link</a>) | @psanford
<br/>
August 21, 2020 | https://tailscale.com/blog/how-nat-traversal-works/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/how-nat-traversal-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>We covered a lot of ground in our post about <a href="https://tailscale.com/blog/how-tailscale-works/"><em>How Tailscale
Works</em></a>.  However, we glossed over how we can get through NATs
(Network Address Translators) and connect your devices directly to
each other, no matter what‚Äôs standing between them. Let‚Äôs talk about
that now!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-intro.png">
    
    
</figure>

<p>Let‚Äôs start with a simple problem: establishing a peer-to-peer
connection between two machines. In Tailscale‚Äôs case, we want to set
up a WireGuard¬Æ tunnel, but that doesn‚Äôt really matter. The
techniques we use are widely applicable and the work of many people
over decades. For example, <a href="https://webrtc.org/">WebRTC</a> uses this bag of tricks to
send peer-to-peer audio, video and data between web browsers. VoIP
phones and some video games use similar techniques, though not always
successfully.</p>
<p>We‚Äôll be discussing these techniques generically, using Tailscale and
others for examples where appropriate. Let‚Äôs say you‚Äôre making your
own protocol and that you want NAT traversal. You need two things.</p>
<p>First, the protocol should be based on UDP. You <em>can</em> do NAT traversal
with TCP, but it adds another layer of complexity to an already quite
complex problem, and may even require kernel customizations depending
on how deep you want to go. We‚Äôre going to focus on UDP for the rest
of this article.</p>
<p>If you‚Äôre reaching for TCP because you want a stream-oriented
connection when the NAT traversal is done, consider using QUIC
instead. It builds on top of UDP, so we can focus on UDP for NAT
traversal and still have a nice stream protocol at the end.</p>
<p>Second, you need direct control over the network socket that‚Äôs sending
and receiving network packets. As a rule, you can‚Äôt take an existing
network library and make it traverse NATs, because you have to send
and receive extra packets that aren‚Äôt part of the ‚Äúmain‚Äù protocol
you‚Äôre trying to speak. Some protocols tightly integrate the NAT
traversal with the rest (e.g. WebRTC). But if you‚Äôre building your
own, it‚Äôs helpful to think of NAT traversal as a separate entity that
shares a socket with your main protocol. Both run in parallel, one
enabling the other.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-deep-integration.png">
    
    
</figure>

<p>Direct socket access may be tough depending on your situation. One
workaround is to run a local proxy. Your protocol speaks to this
proxy, and the proxy does both NAT traversal and relaying of your
packets to the peer. This layer of indirection lets you benefit from
NAT traversal without altering your original program.</p>
<p>With prerequisites out of the way, let‚Äôs go through NAT traversal from
first principles. Our goal is to get UDP packets flowing
bidirectionally between two devices, so that our other protocol
(WireGuard, QUIC, WebRTC, ‚Ä¶) can do something cool. There are two
obstacles to having this Just Work: stateful firewalls and NAT
devices.</p>
<h3 id="figuring-out-firewalls">Figuring out firewalls</h3>
<p>Stateful firewalls are the simpler of our two problems. In fact, most
NAT devices include a stateful firewall, so we need to solve this
subset before we can tackle NATs.</p>
<p>There are many incarnations to consider. Some you might recognize are
the Windows Defender firewall, Ubuntu‚Äôs ufw (using iptables/nftables),
BSD‚Äôs pf (also used by macOS) and AWS‚Äôs Security Groups. They‚Äôre all
very configurable, but the most common configuration allows all
‚Äúoutbound‚Äù connections and blocks all ‚Äúinbound‚Äù connections. There
might be a few handpicked exceptions, such as allowing inbound SSH.</p>
<p>But connections and ‚Äúdirection‚Äù are a figment of the protocol
designer‚Äôs imagination. On the wire, every connection ends up being
bidirectional; it‚Äôs all individual packets flying back and forth. How
does the firewall know what‚Äôs inbound and what‚Äôs outbound?</p>
<p>That‚Äôs where the stateful part comes in. Stateful firewalls remember
what packets they‚Äôve seen in the past and can use that knowledge when
deciding what to do with new packets that show up.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-1a.png">
    
    
</figure>

<p>For UDP, the rule is very simple: the firewall allows an inbound UDP
packet if it previously saw a matching outbound packet. For example,
if our laptop firewall sees a UDP packet leaving the laptop from
<code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, it‚Äôll make a note that incoming
packets from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code> are also fine. The
trusted side of the world clearly intended to communicate with
<code>7.7.7.7:5678</code>, so we should let them talk back.</p>
<p>(As an aside, some <em>very</em> relaxed firewalls might allow traffic from
anywhere back to <code>2.2.2.2:1234</code> once <code>2.2.2.2:1234</code> has communicated
with anyone. Such firewalls make our traversal job easier, but are
increasingly rare.)</p>
<h4 id="firewall-face-off">Firewall face-off</h4>
<p>This rule for UDP traffic is only a minor problem for us, as long as
all the firewalls on the path are ‚Äúfacing‚Äù the same way. That‚Äôs
usually the case when you‚Äôre communicating with a server on the
internet. Our only constraint is that the machine that‚Äôs <em>behind</em> the
firewall(s) must be the one initiating all connections. Nothing can
talk to it, unless it talks first.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-2.png">
    
    
</figure>

<p>This is fine, but not very interesting: we‚Äôve reinvented client/server
communication, where the server makes itself easily reachable to
clients. In the VPN world, this leads to a hub-and-spoke topology: the
hub has no firewalls blocking access to it and the firewalled spokes
connect to the hub.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-3.png">
    
    
</figure>

<p>The problems start when two of our ‚Äúclients‚Äù want to talk
directly. Now the firewalls are facing each other. According to the
rule we established above, this means both sides must go first, but
also that neither can go first, because the other side has to go
first!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-4.png">
    
    
</figure>

<p>How do we get around this? One way would be to require users to
reconfigure one or both of the firewalls to ‚Äúopen a port‚Äù and allow
the other machine‚Äôs traffic. This is not very user friendly. It also
doesn‚Äôt scale to mesh networks like Tailscale, in which we expect the
peers to be moving around the internet with some regularity. And, of
course, in many cases you don‚Äôt have control over the firewalls: you
can‚Äôt reconfigure the router in your favorite coffee shop, or at the
airport. (At least, hopefully not!)</p>
<p>We need another option. One that doesn‚Äôt involve reconfiguring
firewalls.</p>
<h4 id="finessing-finicky-firewalls">Finessing finicky firewalls</h4>
<p>The trick is to carefully read the rule we established for our
stateful firewalls. For UDP, the rule is: <strong>packets must flow out
before packets can flow back in.</strong></p>
<p>However, nothing says the packets must be <em>related</em> to each other
beyond the IPs and ports lining up correctly. As long as <em>some</em> packet
flowed outwards with the right source and destination, any packet that
<em>looks like</em> a response will be allowed back in, even if the other
side never received your packet!</p>
<p>So, to traverse these multiple stateful firewalls, we need to share
some information to get underway: the peers have to know in advance
the <code>ip:port</code> their counterpart is using. One approach is to
statically configure each peer by hand, but this approach doesn‚Äôt
scale very far. To move beyond that, we built a <a href="https://tailscale.com/blog/how-tailscale-works/#the-control-plane-key-exchange-and-coordination">coordination
server</a> to keep the <code>ip:port</code> information synchronized in a
flexible, secure manner.</p>
<p>Then, the peers start sending UDP packets to each other. They must
expect some of these packets to get lost, so they can‚Äôt carry any
precious information unless you‚Äôre prepared to retransmit them. This
is generally true of UDP, but especially true here. We‚Äôre <em>going</em> to
lose some packets in this process.</p>
<p>Our laptop and workstation are now listening on fixed ports, so that
they both know exactly what <code>ip:port</code> to talk to. Let‚Äôs take a look at
what happens.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5a.png">
    
    
</figure>

<p>The laptop‚Äôs first packet, from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, goes
through the Windows Defender firewall and out to the internet. The
corporate firewall on the other end blocks the packet, since it has no
record of <code>7.7.7.7:5678</code> ever talking to <code>2.2.2.2:1234</code>. However,
Windows Defender now remembers that it should expect and allow
responses from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code>.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5b.png">
    
    
</figure>

<p>Next, the workstation‚Äôs first packet from <code>7.7.7.7:5678</code> to
<code>2.2.2.2:1234</code> goes through the corporate firewall and across the
internet. When it arrives at the laptop, Windows Defender thinks ‚Äúah,
a response to that outbound request I saw‚Äù, and lets the packet
through! Additionally, the corporate firewall now remembers that it
should expect responses from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, and
that those packets are also okay.</p>
<p>Encouraged by the receipt of a packet from the workstation, the laptop
sends another packet back. It goes through the Windows Defender
firewall, through the corporate firewall (because it‚Äôs a ‚Äúresponse‚Äù to
a previously sent packet), and arrives at the workstation.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5c.png">
    
    
</figure>

<p>Success! We‚Äôve established two-way communication through a pair of
firewalls that, at first glance, would have prevented it.</p>
<h4 id="creative-connectivity-caveats">Creative connectivity caveats</h4>
<p>It‚Äôs not always so easy. We‚Äôre relying on some indirect influence over
third-party systems, which requires careful handling. What do we need
to keep in mind when managing firewall-traversing connections?</p>
<p>Both endpoints must attempt communication at roughly the same time, so
that all the intermediate firewalls open up while both peers are still
around. One approach is to have the peers retry continuously, but this
is wasteful. Wouldn‚Äôt it be better if both peers knew to start
establishing a connection at the same time?</p>
<p>This may sound a little recursive: to communicate, first you need to
be able to communicate. However, this preexisting ‚Äúside channel‚Äù
doesn‚Äôt need to be very fancy: it can have a few seconds of latency,
and only needs to deliver a few thousand bytes in total, so a tiny VM
can easily be a matchmaker for thousands of machines.</p>
<p>In the distant past, I used XMPP chat messages as the side channel,
with great results. As another example, WebRTC requires you to come up
with your own ‚Äúsignalling channel‚Äù (a name that reveals WebRTC‚Äôs IP
telephony ancestry), and plug it into the WebRTC APIs. In Tailscale,
our coordination server and fleet of DERP (Detour Encrypted Routing
Protocol) servers act as ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/how-nat-traversal-works/">https://tailscale.com/blog/how-nat-traversal-works/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236010</guid>
            <pubDate>Fri, 21 Aug 2020 16:04:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[But I was helping the compiler]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24235783">thread link</a>) | @aw1621107
<br/>
August 21, 2020 | https://pankajraghav.com/2020/08/16/RVO.html | <a href="https://web.archive.org/web/*/https://pankajraghav.com/2020/08/16/RVO.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Compilers are getting better with each release. Sometimes a noticeable difference can be observed in the assembly output for the same piece code in a different version of the same compiler (can be easily done via <a href="https://godbolt.org/">compiler explore</a>).</p>

<p>I have gotten into the practice of checking the assembly output lately to analyze the overhead of various implementations. Beware, sometimes it can get addictive. But I think it is a nice way of learning to read assembly and also be amazed at how clever the compilers are these days.</p>

<p>In this article, I am going to cover one such incident that happened when I was looking at the assembly output of a function during my <a href="https://github.com/Panky-codes/CHIP8">CHIP8</a> implementation.</p>

<p>But the context of the problem first!</p>

<h2 id="the-magic-of-move-semantics">The magic of move semantics</h2>
<p>Move semantics was introduced in C++11. We can think of move semantics as a way of transferring ownership of an object. If you are really new to move semantics, consider the following example:</p>

<p>So your colleague has a document that you also want. We have two options here. The first option, you take that document to a copier, take a copy of the document for yourself, and return the original document to your colleague. The second option, assuming your colleague doesn‚Äôt need the document anymore, instead of throwing it away, your colleague can give it to you, thereby, saving paper.</p>

<p>Replace the document with a memory resource in a program, then the first option is doing a copy, and the second option is doing a move, where you transfer the ownership instead of wasting the resource.</p>
<h2 id="putting-what-i-learned-in-action">Putting what I learned in action</h2>
<p>While implementing my <a href="https://github.com/Panky-codes/CHIP8">CHIP8</a> emulator, I saw an opportunity to replace an expensive copy operation into a cheap move operation (at least that is what I thought).</p>

<p>To give a bit of context: In each frame cycle, I had to return an array containing 2048 integers that will be used to draw the graphics on the screen. The pseudo-C++ code is shown below:</p>

<div><div><pre><code><span>// chip8.cpp</span>
<span>static</span> <span>constexpr</span> <span>display_size</span> <span>=</span> <span>2048</span><span>;</span>
<span>class</span> <span>Chip8</span> <span>{</span>
    <span>...</span> 
    <span>public</span> <span>:</span> 
        <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>uint8_t</span><span>,</span> <span>display_size</span><span>&gt;</span> <span>get_display_pixels</span><span>()</span> <span>{</span>
              <span>// Do some computation</span>
              <span>return</span> <span>gfx</span><span>;</span>
          <span>}</span>
    <span>...</span> 
    <span>private</span> <span>:</span> 
        <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>uint8_t</span><span>,</span> <span>display_size</span><span>&gt;</span> <span>gfx</span><span>{};</span>
<span>};</span>

<span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>

<p>This is what I assumed was going on when I did the call to <code>get_display_pixels()</code> member function:</p>
<ol>
  <li>The compiler <code>copies</code> the <code>gfx</code> private variable of the <code>Chip8</code> class to the return value of the <code>get_display_pixels()</code> member function.</li>
  <li>The compiler calls the <code>copy constructor</code> to copy the return value of the function call to the <code>disp_pixels</code> variable.</li>
</ol>

<p>So, I concluded that I could use a <code>move constructor</code> to transfer the contents to my local variable <code>disp_pixels</code> to avoid a copy in the second step as described above.</p>

<p>So I changed my code in the <code>main</code> function as follows:</p>
<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>emulator</span><span>.</span><span>get_display_pixels</span><span>());</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>

<p>Before you get furious and stop reading the article further because what I assumed was completely wrong, I realized that too, and the rest of the article is about that.</p>

<p>As soon as I used a <code>std::move</code> as shown in my previous code snippet, I observed the compiler was generating more assembly code than my initial code without a <code>std::move</code>(with std::move: <a href="https://godbolt.org/z/WulpDX">link</a>, without std::move: <a href="https://godbolt.org/z/oU8Tq4">link</a>).</p>

<p>What went wrong? Hmm‚Ä¶.</p>
<h2 id="nrvo-to-the-rescue">NRVO to the rescue</h2>
<p>NRVO stands for Named Return Value Optimization. It is a nice trick that the compiler uses to omit unnecessary copy or move if certain conditions are met. Compilers have been using this trick for a long time. If <code>NRVO</code> takes place in our function call, then effectively we just do one copy instead of two. Let‚Äôs see how it works.</p>

<p>Even though the function signature of <code>get_display_pixels</code> indicates that it does not take any parameters, the compiler will pass one extra parameter behind the scenes from the caller (initialization call of <code>disp_pixels</code> from <code>main.cpp</code>) to the callee (<code>get_display_pixels</code> function in <code>chip8.cpp</code>). The caller will allocate the memory for the return value and pass the address of that memory to the callee. The callee will use that memory to construct the object and copy the value of the private variable <code>gfx</code> (in this case). As the memory of the caller (<code>disp_pixels</code>) was used by the callee, there is no need to copy the return value again, thereby, saving one unnecessary copy/move operation.</p>

<p>We should see the assembly output to really understand how <code>NRVO</code> is happening under the hood. The assembly code from the caller side is as follows:</p>
<div><div><pre><code><span>1</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>2</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>3</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>4</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>5</span>   <span>call</span> <span>Chip8</span><span>::</span><span>get_display_pixels</span><span>()</span>
</code></pre></div></div>
<p>Before the function call, <code>rsi</code> and <code>rdi</code> registers are loaded with upper and lower bound of the memory address of the <code>disp_pixels</code> variable. And, the trimmed assembly output from the callee side is as follows:</p>

<div><div><pre><code><span>1</span>   <span>Chip8</span><span>::</span><span>get_display_pixels</span><span>()</span><span>:</span>
<span>2</span>   <span>push</span> <span>rbp</span>
<span>3</span>   <span>mov</span>  <span>rbp</span><span>,</span> <span>rsp</span>
<span>4</span>   <span>mov</span>  <span>QWORD</span> <span>PTR</span> <span>[</span><span>rbp</span><span>-</span><span>8</span><span>],</span> <span>rdi</span>
<span>5</span>   <span>mov</span>  <span>QWORD</span> <span>PTR</span> <span>[</span><span>rbp</span><span>-</span><span>16</span><span>],</span> <span>rsi</span>
<span>...</span>
</code></pre></div></div>
<p>As seen from the callee side, the <code>rdi</code> and <code>rsi</code> values are moved to the stack, and further operations are performed with that memory address. Pretty neat!</p>

<p>A <code>simple analogy</code> for <code>NRVO</code> I like to think of is when you are asking a friend to fill in water inside a water bottle, you would give your bottle to fill water from the tap directly. It would be inefficient to first fill the water in a temporary bottle and transfer the contents again to your bottle. In the C++ context, <code>bottle</code> is the <code>memory space</code> and the <code>water</code> it holds is the <code>return value</code>.</p>

<p>If we assume that the  <code>NRVO</code> will take place, then the most efficient way of writing my function call is:</p>
<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>
<p>GCC and Clang even have an extra warning flag <code>-Wpessimizing-move</code> which detects when we are trying to use a <code>move</code> where compiler-generated NRVO is much more efficient.</p>

<p>Even though we can assume in many situations that a <code>NRVO</code> will take place, especially if optimizations are turned on, C++ standard does not guarantee <code>NRVO</code> in all situations<sup>1</sup>. But what if compiler does not perform a <code>NRVO</code>?</p>
<h2 id="lvalues-and-rvalues-and-all-other-value-categories-in-between">Lvalues and Rvalues (and all other value categories in between)</h2>
<p>Even though there are some <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2025r0.html">proposals</a> to guarantee <code>NRVO</code>, it is not yet guaranteed by the standard. As it is not guaranteed, should we explicitly indicate a move operation to save a copy just in case the compiler doesn‚Äôt do a <code>NRVO</code>? To answer that, I added the flag <code>-fno-elide-constructors</code> that disables copy elision (the super-set of NRVO) in our code, thereby, allowing to see what the compiler does otherwise.</p>

<p>I was surprised to see that compiler was still performing a <code>NRVO</code> for <code>C++17</code> standard with <code>-fno-elide-constructors</code> enabled. But this was not the case for <code>C++14</code>, the compiler generated different assembly with <code>-fno-elide-constructors</code> enabled. If someone knows the reason why this difference occurs between <code>C++17</code> and <code>C++14</code> even though <code>NRVO</code> is not guaranteed, please email me about it. Godbolt <a href="https://godbolt.org/z/hPW3rh">link</a>.</p>

<p>Let‚Äôs use <code>C++14</code> with <code>-fno-elide-constructors</code> flag to simulate the scenario where the compiler fails to apply <code>NRVO</code> so that we can check whether we needed to do something extra to avoid superfluous copies.</p>

<p>So I added <code>-fno-elide-constructors</code> to disable any <code>NRVO</code> to the final code of the previous section. The caller generated the following assembly code:</p>

<div><div><pre><code><span>1</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>2</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>3</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>4</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>5</span>   <span>call</span> <span>Chip8</span><span>::</span><span>get_display</span><span>()</span>
<span>6</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>7</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>8</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>9</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>10</span>  <span>call</span> <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>unsigned</span> <span>char</span><span>,</span> <span>32ul</span><span>&gt;::</span><span>array</span><span>(</span><span>std</span><span>::</span><span>array</span><span>&lt;</span><span>unsigned</span> <span>char</span><span>,</span> <span>32ul</span><span>&gt;&amp;&amp;</span><span>)</span>
</code></pre></div></div>

<p>As we can notice, the first 5 assembly instructions are the same as the version with NRVO enabled, and there are 5 more assembly instructions in this version as we disabled NRVO. The most important instruction we need to focus on is line number 10 where a <code>move constructor</code>(notice <code>&amp;&amp;</code> in the function signature). Wait, a <code>move constructor</code> is invoked? I did not use a <code>std::move</code> but the compiler decided to do it anyway. To really comprehend the reason, we need to understand <code>value categories</code> in C++.</p>

<p>In these two articles: <a href="https://eli.thegreenplace.net/2011/12/15/understanding-lvalues-and-rvalues-in-c-and-c">Understanding lvalues and rvalues in C and C++ </a> and <a href="http://eel.is/c++draft/basic.lval#1">basic.lval#1</a>, value categories are explained in detail<sup>2</sup>. In brief, quoting from the first article: ‚ÄúAn lvalue (locator value) represents an object that occupies some identifiable location in memory. Rvalue is an expression that does not represent an object occupying some identifiable location in memory.‚Äù. Of course, there are more categories than just a <code>lvalue</code> and a <code>rvalue</code>. I would highly recommend reading both articles. Though you don‚Äôt need a perfect grasp of them to understand what comes later in this article. Let‚Äôs get back to our original example and analyze why the move constructor was called.</p>

<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>
<p>In the above code snippet, the function call to <code>get_display_pixels</code> belongs to the <code>rvalue</code> (more precisely a <code>prvalue</code>) category and it generates a temporary. The compiler can now safely <code>move</code> that temporary into the <code>disp_pixels</code> variable because that temporary will be destroyed anyway after this statement. If the type that is being returned does not have a move constructor (in our case <code>std::array</code> has a move constructor), then the compiler will call the <code>copy constructor</code>.</p>

<p>In principle, if any of the <code>moveable</code> types (standard or user-defined) is returned from a function by <code>value</code>, we can safely assume either <code>NRVO</code> or <code>move operation</code> will take place resulting in no superfluous copies for standard compilers that support <code>C++11</code> and above.</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pankajraghav.com/2020/08/16/RVO.html">https://pankajraghav.com/2020/08/16/RVO.html</a></em></p>]]>
            </description>
            <link>https://pankajraghav.com/2020/08/16/RVO.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24235783</guid>
            <pubDate>Fri, 21 Aug 2020 15:41:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Splitgraph Data Delivery Network ‚Äì query over 40k public datasets]]>
            </title>
            <description>
<![CDATA[
Score 281 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24233948">thread link</a>) | @mildbyte
<br/>
August 21, 2020 | https://www.splitgraph.com/blog/data-delivery-network-launch | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#usage" as="#usage">Usage</a><ol><li><a href="#connecting" as="#connecting">Connecting</a></li><li><a href="#workspaces" as="#workspaces">Workspaces</a></li><li><a href="#running-queries" as="#running-queries">Running queries</a></li></ol></li><li><a href="#behind-the-scenes" as="#behind-the-scenes">Behind the scenes</a></li><li><a href="#future-and-roadmap" as="#future-and-roadmap">Future and roadmap</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Today, we are announcing the next step for Splitgraph: the <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect"><strong>Splitgraph Data Delivery Network</strong></a>.</p><p>The Splitgraph DDN is a single SQL endpoint that lets you query over 40,000 public datasets hosted on or proxied by Splitgraph.</p><p>You can connect to it from most PostgreSQL clients and BI tools <strong>without having to install anything else</strong>. It supports all read-only SQL constructs, including filters and aggregations. It even lets you run joins across distinct datasets.</p><p>In this post, we will give you a quick introduction to the DDN as well as discuss how it works behind the scenes and our plan for its future.</p><section><h3 id="usage">Usage</h3><section><h4 id="connecting">Connecting</h4><p>The endpoint is at <code>postgresql://data.splitgraph.com:5432/ddn</code>. You will need a Splitgraph API key and secret to access it.</p><p>You don't need to install anything to use the endpoint. If you go to your Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">account settings</a>, you can generate a pair of credentials. You can then plug them into your SQL client.</p><p>If you're already using the <a href="https://www.splitgraph.com/docs/architecture/sgr-client"><code>sgr</code> client</a> and had registered for Splitgraph before, you can check your <code>.sgconfig</code> file for the API keys. You can also upgrade your client to version 0.2.0 with <code>sgr upgrade</code> and run <code>sgr cloud sql</code> to get a libpq-compatible connection string.</p><p><a href="https://www.splitgraph.com/docs/getting-started/installation">Installing Splitgraph locally</a> will let you snapshot these datasets and use them in <a href="https://www.splitgraph.com/docs/concepts/splitfiles">Splitfiles</a>.</p><p>There are more setup methods available in <a href="https://www.splitgraph.com/docs/splitgraph-cloud/data-delivery-network">our documentation</a>. This includes connecting to Splitgraph with clients like DBeaver, BI tools like Metabase or Google Data Studio or even other databases through ODBC.</p></section><section><h4 id="workspaces">Workspaces</h4><p>When you connect to Splitgraph, your SQL client will show you some schemas. These are data repositories featured on our <a href="https://www.splitgraph.com/explore">explore page</a> as well as datasets that you upload to Splitgraph.</p><p>We call this feature "workspaces". It works by implementing the <a href="https://en.wikipedia.org/wiki/Information_schema" as="https://en.wikipedia.org/wiki/Information_schema">ANSI information schema</a> standard. We'll expand on workspaces more in the future. For example, we'll let you:</p><ul><li>bookmark repositories that you want to show up in your workspace</li><li>allow you to have multiple workspaces and manage access to them</li><li>search for Splitgraph repositories directly from your SQL client.</li></ul></section><section><h4 id="running-queries">Running queries</h4><p>You can run queries on Splitgraph images by referencing them as PostgreSQL schemata: <code>namespace/repository[:hash_or_tag]</code>. By default, we query the <code>latest</code> tag.</p><p>For example, if you want to query the <a href="https://www.splitgraph.com/cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc" as="https://www.splitgraph.com/cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"><code>cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc</code> repository</a>, proxied by Splitgraph to <a href="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-and-Deaths/naz8-j4nc" as="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-and-Deaths/naz8-j4nc">Socrata</a>, you can run:</p><pre><code metastring=""><span>SELECT</span> <span>*</span> <span>FROM</span>
    <span>"cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"</span><span>.</span>covid19_daily_cases_deaths_and_hospitalizations
</code></pre><p>We let you use SQL <code>SELECT</code> and <code>EXPLAIN</code> statements. You can use any SQL clauses, including group-bys, aggregations, filters and joins. Splitgraph pushes filters down to the origin data source.</p><p>This sample query that we used in our <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals" as="/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals">Metabase demo</a> runs a JOIN between two datasets:</p><pre><code metastring=""><span>SELECT</span>
    cambridge_cases<span>.</span><span>date</span> <span>AS</span> <span>date</span><span>,</span>
    chicago_cases<span>.</span>cases_total <span>AS</span> chicago_daily_cases<span>,</span>
    cambridge_cases<span>.</span>new_positive_cases <span>AS</span> cambridge_daily_cases
<span>FROM</span>
    <span>"cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"</span><span>.</span>covid19_daily_cases_deaths_and_hospitalizations chicago_cases
<span>FULL</span> <span>OUTER</span> <span>JOIN</span>
    <span>"cambridgema-gov/covid19-cumulative-cases-by-date-tdt9-vq5y"</span><span>.</span>covid19_cumulative_cases_by_date cambridge_cases
<span>ON</span>
    date_trunc<span>(</span><span>'day'</span><span>,</span> chicago_cases<span>.</span>lab_report_date<span>)</span> <span>=</span> cambridge_cases<span>.</span><span>date</span>
<span>ORDER</span> <span>BY</span> <span>date</span> <span>ASC</span><span>;</span>
</code></pre><p>This will join the data between two distinct Socrata data portals (<a href="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-Deaths-and-Hospitalizations/naz8-j4nc" as="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-Deaths-and-Hospitalizations/naz8-j4nc">Chicago, IL</a> and <a href="https://data.cambridgema.gov/Public-Safety/COVID-19-Cumulative-Cases-by-Date/tdt9-vq5y" as="https://data.cambridgema.gov/Public-Safety/COVID-19-Cumulative-Cases-by-Date/tdt9-vq5y">Cambridge, MA</a>).</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0900_splitgraph-cloud/images/sql-endpoint/2-dbeaver-join.png" alt="Splitgraph SQL endpoint JOIN query example"></p><p>We also support <a href="https://postgis.net/" as="https://postgis.net/">PostGIS</a>, letting you query and visualize geospatial data. For example, you can query the <a href="https://www.splitgraph.com/splitgraph/london_wards/" as="https://www.splitgraph.com/splitgraph/london_wards/">London ward boundary data</a> image as follows:</p><pre><code metastring=""><span>SELECT</span>
    name<span>,</span>
    gss_code<span>,</span>
    
    ST_Transform<span>(</span>ST_SetSRID<span>(</span>geom<span>,</span> <span>27700</span><span>)</span><span>,</span> <span>4326</span><span>)</span><span>,</span>
    
    ST_Area<span>(</span>ST_Transform<span>(</span>ST_SetSRID<span>(</span>geom<span>,</span> <span>27700</span><span>)</span><span>,</span> <span>3035</span><span>)</span><span>)</span> <span>/</span> <span>1000000</span> <span>AS</span> area_sqkm
<span>FROM</span>
    <span>"splitgraph/london_wards"</span><span>.</span>city_merged_2018
<span>ORDER</span> <span>BY</span> gss_code <span>ASC</span><span>;</span>
</code></pre><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0900_splitgraph-cloud/images/sql-endpoint/3-dbeaver-geodata.png" alt="PostGIS data on Splitgraph DDN"></p><p>There are more sample queries on our <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Connect page</a>.</p></section></section><section><h3 id="behind-the-scenes">Behind the scenes</h3><p>The Splitgraph Data Delivery Network is the result of all the work we've put into the <a href="https://www.splitgraph.com/docs/architecture/sgr-client"><code>sgr</code> client</a> and the <a href="https://github.com/splitgraph/splitgraph" as="https://github.com/splitgraph/splitgraph">Splitgraph Core</a> code over the past two years.</p><p>It would also have not been possible without some other open source technologies.</p><p>We use PostgreSQL foreign data wrappers. They let us perform query execution and planning across federated data sources. We wrote about <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">foreign data wrappers</a> before: they're powerful and underused!</p><p>We manage connections using a fork of <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org">pgBouncer</a>, a PostgreSQL connection pooler. Our fork lets us perform authentication outside of PostgreSQL. We can issue and revoke API keys without having to manipulate database roles. Several inbound Splitgraph users can run queries as a single PostgreSQL user.</p><p>We also use pgBouncer to transform queries on the fly. We rewrite clients' introspection queries and let them reference Splitgraph images as PostgreSQL schemata.</p><p>Each client essentially operates within its own isolated virtual database. The obvious implementation of this would be spinning up one database per client. But our query transformations let us do this at a <strong>much lower infrastructure cost</strong>. We also use this feature to inspect and drop unwanted queries on the fly.</p><p>Finally, we use our own <code>sgr</code> client to orchestrate this. Splitgraph engines power the data delivery network. They manage foreign data wrapper instantiation and querying Splitgraph images via <a href="https://www.splitgraph.com/docs/large-datasets/layered-querying">layered querying</a>. In the future, we will use Splitgraph's <a href="https://www.splitgraph.com/docs/concepts/objects">storage format</a> to snapshot remote datasets or cache frequent queries.</p></section><section><h3 id="future-and-roadmap">Future and roadmap</h3><p>There are a lot of directions we would like to pursue with Splitgraph.</p><p>You will be able to use Splitgraph to <strong>replace some of your data lake or ETL pipelines</strong> and query the data at source. This is similar to the idea of "data virtualization". But, unlike other software in this space, Splitgraph uses an open PostgreSQL procotol. This makes it immediately compatible with most of your BI tools and dashboards. It won't lock you into a proprietary query language.</p><p>We will soon have the ability to add <a href="https://www.splitgraph.com/docs/splitgraph-cloud/external-repositories">external repositories</a> to public or on-premises Splitgraph data catalogs. You will be able to query any dataset indexed in this catalog over the single SQL endpoint or our <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">REST API</a>. You will be able to even use these datasets in <a href="https://www.splitgraph.com/concepts/splitfiles">Splitfiles</a>. This will let you define reproducible transformations on your data, enrich it with public datasets and track lineage.</p><p>You will be able to use Splitgraph as an <strong>SQL firewall and a rewrite layer</strong>. You won't need to use views to set up access policies for your data warehouse. Data consumers won't need to manage credentials to disjoint data silos. Splitgraph can inspect proxied queries and enforce granular access policies on individual columns. It will even be able to do PII masking and access auditing.</p><p>The single SQL endpoint is well suited for a <strong>data marketplace</strong>. Data vendors currently ship data in CSV files or other ad-hoc formats. They have to maintain pages of instructions on ingesting this data. With Splitgraph, data consumers will be able to acquire and interact with data directly from their applications and clients.</p></section><section><h3 id="conclusion">Conclusion</h3><p>Today, we launched the Splitgraph Data Delivery Network. It's a seamless experience of a single database with thousands of datasets at your fingertips, compatible with most existing clients and BI tools.</p><p>If you wish to try it out, you can get credentials to access it in less than a minute: just head on to the <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">landing page</a>.</p><p>We're also building towards a <a href="https://www.splitgraph.com/about/company/private-cloud-beta">"Splitgraph Private Cloud" product</a> that will let setup your own private Splitgraph cluster, managed by us and deployed to the cloud region of your choice. <a href="mailto:support@splitgraph.com" as="mailto:support@splitgraph.com">Contact us</a> if you're interested!</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24233948</guid>
            <pubDate>Fri, 21 Aug 2020 11:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product-led Growth]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24233859">thread link</a>) | @yakkomajuri
<br/>
August 21, 2020 | https://posthog.com/blog/product-led-growth | <a href="https://web.archive.org/web/*/https://posthog.com/blog/product-led-growth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!-- ![PLG Banner](../images/plg-header.png) -->
<p>You will need sales, but do you need a sales team to achieve revenue?</p>
<p>Let's say you are the founder of a new tech startup.&nbsp;</p>
<p>A few months back, you and a couple of friends (all developers) built an amazing tool and have now received Seed funding.&nbsp;</p>
<p>As a result, you're under some pressure to grow. You took a few million from some VCs here and there, and they want to see some results.</p>
<p>Since the realization of needing to grow hit you, you've started to lose some sleep.&nbsp;</p>
<p>Before, you were just a group of friends working your ass off to build an amazing product, with some revenue coming in from your immediate network. Now you actually have to focus on ramping up your sales.</p>
<p>You call in a founders meeting to discuss next steps, and a conclusion is reached: you can't spend all your budget on engineers, which is what you wanted to do.&nbsp;</p>
<p>Instead, you need to hire some Sales people. Or some Marketing people. Or both. Whoever can get you some users that pay for your product. Or do you? Could you invest in engineering instead to drive more revenue, and perhaps building a better company along the way?</p>
<h2 id="getting-people-to-pay-you"><a href="#getting-people-to-pay-you" aria-label="getting people to pay you permalink"></a>Getting People to Pay&nbsp;You</h2>
<p>VC funding or not, all startups will eventually need to get paid for what they do.&nbsp;</p>
<p>Irrespective of how cool your idea is, or how helpful it may be, if you're not getting money in, you can't push it forward.&nbsp;
You need customers.</p>
<p>Traditionally, there are two ways to do this: sales and marketing. They are not mutually exclusive, but one strategy or the other generally takes the lead in generating growth.  To understand them, it's helpful to refer to a funnel:</p>
<p><span>
      <a href="https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/c211c/hogflix-funnel.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HogFlix Example Funnel" title="HogFlix Example Funnel" src="https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/fcda8/hogflix-funnel.png" srcset="https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/12f09/hogflix-funnel.png 148w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/e4a3f/hogflix-funnel.png 295w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/fcda8/hogflix-funnel.png 590w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/efc66/hogflix-funnel.png 885w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/c83ae/hogflix-funnel.png 1180w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/c211c/hogflix-funnel.png 1502w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3 id="marketing-led-growth-"><a href="#marketing-led-growth-" aria-label="marketing led growth  permalink"></a>Marketing-led Growth&nbsp;üìà</h3>
<p>The goal of marketing is to increase the number of people going through the funnel. </p>
<p>The idea is to make your business be seen. But not just that‚Ää-‚Ääit's also about being seen by the right people and seen in a positive light.</p>
<p>This involves a wide variety of aspects, from branding, to social media, and, of course, ads. If this is done well, the customer should come to you, so you won't need to go after them.</p>
<h3 id="sales-led-growth-ü§ù"><a href="#sales-led-growth-%F0%9F%A4%9D" aria-label="sales led growth ü§ù permalink"></a>Sales-led Growth&nbsp;ü§ù</h3>
<p>Sales, on the other hand, is about improving the conversion between steps of the funnel. </p>
<p>In some ways, it is the opposite of Marketing, as you will often go after the customer, rather than try to make them come to you. This can be done in a variety of ways, from cold calls to leveraging leads.&nbsp;</p>
<p>Essentially, the assumption is that there are people out there who are willing to pay for your product, so you need to do your best to find them and get them to pay you.</p>
<h2 id="the-underrated-alternative"><a href="#the-underrated-alternative" aria-label="the underrated alternative permalink"></a>The Underrated Alternative</h2>
<p>There are various benefits to Sales-led and Marketing-led growth strategies, and they are still widely used today.&nbsp;</p>
<p>However, a new approach has been gaining traction in the past few years, called Product-led Growth (PLG).</p>
<h3 id="let-your-product-do-the-talking"><a href="#let-your-product-do-the-talking" aria-label="let your product do the talking permalink"></a>Let your product do the&nbsp;talking</h3>
<p>With Product-led Growth, the idea is that rather than bringing users through an active sales team or aggressive marketing campaigns, you just focus on building your product‚Ää-‚Ääand ensure you make it great.</p>
<p>The concept is based on the assumption that if you build something that is useful and works well, the users will eventually come to you as result... with a little push, of course.</p>
<p>As such, your primary objective should be to make something truly amazing, rather than portray your product as amazing (which is what great Sales and Marketing people can do).</p>
<p>Now, following a PLG approach does not substitute having a Sales or Marketing team. It just means growth is <em>led</em> by the product, and the other teams in the organization operate in alignment with this methodology. </p>
<p>Additionally, operating a B2B company without a Sales team does become impractical at a large scale. We would know, since our founders used to close software sales deals in the seven figures.</p>
<h2 id="the-key-is-in-the-dna"><a href="#the-key-is-in-the-dna" aria-label="the key is in the dna permalink"></a>The Key is in the&nbsp;DNA</h2>
<p>While this "strategy" sounds more like common sense than a methodical approach, there's more to Product-led growth than meets the eye.</p>
<p>To truly succeed as a business that drives growth primarily through its product, this concept needs to be built into the company culture.</p>
<p>While Sales and Marketing can often work well as segregated teams that draw from the product but operate independently in practice, focusing on building a product is an organization-wide effort.</p>
<p>As <a href="https://www.productled.org/foundations/what-is-product-led-growth">PLGC</a> put it, different teams often operate in different wavelengths, but with Product-Led Growth, you need everyone to converge into one single wavelength: user experience.&nbsp;</p>
<p>At PostHog, we follow a Product-led Growth approach. And we'll tell you, this has implications for all areas of the company:</p>
<h3 id="sales"><a href="#sales" aria-label="sales permalink"></a>Sales</h3>
<p>Don't make a sale if your product is not a good fit for the customer.&nbsp;</p>
<p>From the first paragraph of <a href="https://posthog.com/handbook/growth/sales">PostHog's Handbook Sales page</a>:</p>
<blockquote>
<p>Always focus on delivering what the customer needs. Sometimes that will mean sending them to a competitor or turning them&nbsp;down.</p>
</blockquote>
<p>Yes, this is literally an official guideline for doing Sales at PostHog.</p>
<h3 id="team"><a href="#team" aria-label="team permalink"></a>Team</h3>
<p>If you're a software company, PLG might mean opting for more Engineers than Sales people, for instance. In our case, we still don't have a single person doing Sales or Marketing exclusively. Almost our entire team is made up of Engineers, including people not working day-to-day on our codebase.&nbsp;</p>
<p>More than with other approaches, you also need to make sure your hires are individuals who understand and are passionate about the product, as well as are proactive in making it better.&nbsp;</p>
<p>Your Sales people shouldn't cut corners to close a deal, and the Marketing team should focus on highlighting the product you built.</p>
<h3 id="communication"><a href="#communication" aria-label="communication permalink"></a>Communication</h3>
<p>Listen to your users on everything.</p>
<p>Built something? Get feedback. New idea? Get feedback. Launched a release? Get feedback.</p>
<p>As one of our <a href="https://twitter.com/mariusandra">core devs</a> put it following interviews with users about a new feature he built: "Your assumptions are mostly wrong. Talk to people to correct them".</p>
<p>When generating growth primarily through Sales or Marketing, the segregation between the people who are building the product and those selling it can lead to diversion between what users want and what is being offered to them.</p>
<p>When focusing on the product, you should always be touching base with your users, and be willing to drop features you love if they don't feel the same way.</p>
<h3 id="priorities"><a href="#priorities" aria-label="priorities permalink"></a>Priorities</h3>
<p>At PostHog, our methodology is:</p>
<blockquote>
<p>If we keep our team first and users second, then our investors will take care of themselves!</p>
</blockquote>
<p>Users are key and should be a top priority.</p>
<p>However, you must remember that your team consists of the first users of your product, its main advocates, and its builders!&nbsp;</p>
<p>Hence, since users are a priority, and the team takes care of the users, you need to take care of your team!</p>
<h3 id="growth"><a href="#growth" aria-label="growth permalink"></a>Growth</h3>
<p>Since you're not aggressively seeking out users with Product-Led Growth, you are likely to experience slower growth at first.&nbsp;
Later on, however, if you did truly build something great, you may benefit from a network effect that skyrockets your userbase.&nbsp;</p>
<p>Facebook and Slack are great examples of this.&nbsp;</p>
<table>
<thead>
<tr>
<th><span>
      <a href="https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/d56b5/facebook-stock.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Facebook Stock Price" title="Facebook Stock Price" src="https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/fcda8/facebook-stock.png" srcset="https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/12f09/facebook-stock.png 148w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/e4a3f/facebook-stock.png 295w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/fcda8/facebook-stock.png 590w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/efc66/facebook-stock.png 885w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/c83ae/facebook-stock.png 1180w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/d56b5/facebook-stock.png 1215w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></th>
</tr>
</thead>
<tbody>
<tr>
<td><center> Facebook (FB) Stock Price - Source: <a href="https://finance.yahoo.com/chart/FB">Yahoo Finance</a></center></td>
</tr>
</tbody>
</table>
<p>Facebook, in fact, actually grew fast early on, while following a primarily PLG approach. This goes on to show that it is possible
to grow fast despite following a Product-led Growth approach, or, perhaps even because of it. When you're an industry disruptor, your product speaks for itself, since it is something new, rather than an improvement on something that already exists. As such, your product can potentially drive your growth even if you don't explicitly follow a PLG strategy.</p>
<p>Tesla is another example of a company that lets its disruptive product do the talking. They reportedly spend a <a href="https://www.forbes.com/sites/johnkoetsier/2019/05/06/tesla-spends-zero-on-ads-heres-where-bmw-toyota-ford-and-porsche-spend-digital-ad-dollars/#4a574ec911d4">whopping 0$ on advertising</a>, yet have a brand that is known worldwide, and a <a href="https://finance.yahoo.com/quote/TSLA/">stock price that seems to just keep on rising</a>. </p>
<h3 id="revenue"><a href="#revenue" aria-label="revenue permalink"></a>Revenue&nbsp;</h3>
<p>Since the initial focus is on building a product rather than selling it, you will likely make less money in the short-run.</p>
<p>With the goal not being to hit a Sales metric, you might be turning down opportunities to generate revenue if they are not perfectly aligned with what you're building.</p>
<p>As such, you need to make sure your team and investors are aligned with this. It should be understood that <a href="https://posthog.com/blog/raising-3m-for-os">it's okay to not be making money in the early stages</a>.</p>
<h2 id="one-size-doesnt-fit-all"><a href="#one-size-doesnt-fit-all" aria-label="one size doesnt fit all permalink"></a>One Size Doesn't Fit&nbsp;All</h2>
<p>Product-Led Growth is not a magic pill. It does have its shortcomings.</p>
<p>Primarily, how can you let your product speak for itself if you can't get anyone to look at it in the first place?</p>
<p>But rather than tell you when Product-led Growth might not work, let's explore some aspects that may be beneficial to it.</p>
<h3 id="funding"><a href="#funding" aria-label="funding permalink"></a>Funding</h3>
<p>It's much easier to focus almost exclusively on building a product when you're already well-funded. This is our case at PostHog.</p>
<p>To build a great product, you need a great team. And to build a great team, you need money.&nbsp;</p>
<p>Thus, if you're a company without a lot of money in the bank, you might just need to get some Sales done now, simply to fund your operations.</p>
<p>Not having funding shouldn't discourage you from trying a PLG approach, however. It can still work, just look at GitLab. They first raised money after already having 100,000 users and Sid (their CEO) <a href="https://posthog.com/blog/a-chat-with-sid">told us</a> they didn't even have a significant marketing budget until then. Wow.</p>
<h3 id="open-source-software"><a href="#open-source-software" aria-label="open source software permalink"></a>Open Source&nbsp;Software</h3>
<p>Being open source is a great characteristic for companies looking to follow a PLG approach.&nbsp;</p>
<p>This is because you can get users excited not only about the usability of your product, but also how it's built.</p>
<p>Additionally, open source software projects by default encourage community participation, since anyone is able to suggest a change, raise an issue, or even contribute code.&nbsp;</p>
<p>As such, you are more involved with your users and can gain better insight into how people feel about your product.</p>
<h3 id="breadth-of-experience"><a href="#breadth-of-experience" aria-label="breadth of experience permalink"></a>Breadth of Experience</h3>
<p>With regards to professional experience, depth refers to extensive experience in a specific field, whereas breadth can be seen as experience across fields.</p>
<p>Depth of experience is an essential characteristic of a world-class team. However, having some focus on breadth can also be beneficial. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://posthog.com/blog/product-led-growth">https://posthog.com/blog/product-led-growth</a></em></p>]]>
            </description>
            <link>https://posthog.com/blog/product-led-growth</link>
            <guid isPermaLink="false">hacker-news-small-sites-24233859</guid>
            <pubDate>Fri, 21 Aug 2020 11:07:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Memory Fragmentation in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24232809">thread link</a>) | @tirumaraiselvan
<br/>
August 21, 2020 | https://www.well-typed.com/blog/2020/08/memory-fragmentation/ | <a href="https://web.archive.org/web/*/https://www.well-typed.com/blog/2020/08/memory-fragmentation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <p>Recently I‚Äôve done a bit of work for <a href="https://hasura.io/">Hasura</a>, investigating some strange memory behavior in <a href="https://github.com/hasura/graphql-engine">graphql-engine</a>. When measuring memory usage, we can ask the operating system (OS) how much memory our process is using, but we can also use the GHC runtime system‚Äôs (RTS) heap profiler. After running a <code>graphql-engine</code> benchmark, the server‚Äôs memory usage reported by the OS was much higher than the ‚Äúheap residency‚Äù reported by GHC‚Äôs heap profiler. This led us down a bit of a rabbit hole of understanding memory allocation and memory fragmentation in programs compiled with GHC.</p>
<p>In this blog post, we look at memory fragmentation in the Haskell heap and how it arises. We look at how fragmentation affects the discrepancy between heap residency reported by the RTS and memory usage reported by the OS. In particular, we focus on a pathological case of a program that makes use of pinned data and transitions from high heap residency to relatively low heap residency.</p>
<!-- more -->
<h3 id="memory-metrics">Memory Metrics</h3>
<p>On Linux there are multiple ways to measure memory usage of a process, but the one we‚Äôll focus on is <em>virtual memory resident set size</em>, <code>VmRSS</code>. This can be sampled from <code>/proc/&lt;PID&gt;/status</code> where <code>&lt;PID&gt;</code> is a process ID. We won‚Äôt get into the details of this, but suffice it to say that we consider <code>VmRSS</code> the ‚Äútrue‚Äù memory usage of our Haskell program.</p>
<p><em>Heap residency</em> is a measurement taken by the runtime system‚Äôs heap profiler. It measures the size of all <em>live</em> data on the Haskell heap. <code>VmRSS</code> is always higher than heap residency. The reason is that heap residency is only a measure of <em>live</em> data on the Haskell heap while <code>VmRSS</code> is ‚Äúall inclusive‚Äù. <a href="https://downloads.haskell.org/~ghc/8.10.2/docs/html/users_guide/profiling.html#actual-memory-residency">The GHC user‚Äôs guide</a> gives the following reasons for a higher <code>VmRSS</code>:</p>
<ol type="1">
<li>Overhead due to a profiled build. Each heap object uses an extra 2 words that are usually not counted in the heap profile.</li>
<li>Garbage collection. The copying collector (i.e.&nbsp;the default collector) makes a copy of all live unpinned data causing a peak in memory usage.</li>
<li>Thread stacks are not counted in the heap profile by default. Profiling with the <code>-xt</code> runtime system option includes stacks in the profile.</li>
<li>The program text itself, the C stack, any ‚Äúnon-heap‚Äù data (e.g.&nbsp;data allocated by foreign libraries and data allocated by the RTS itself), and <code>mmap()</code>‚Äòd memory are not counted in the heap profile.</li>
</ol>
<p>In the following section is an example program which we focus on for this blog post. We‚Äôll dive into the details shortly, but this program exhibits much higher <code>VmRss</code> than heap residency, so let‚Äôs consider why this might be:</p>
<ul>
<li><p>We‚Äôre not using a profiled build, so point 1 does not apply.</p></li>
<li><p>In general, stack usage can be significant and you should profile with <code>-xt</code> to diagnose this. The example program has negligible stack size, so point 3 also doesn‚Äôt apply.</p></li>
<li><p>The runtime system (RTS) is written in C and has it‚Äôs own stack and non-heap data, but this is negligible compared to the large amount of data we‚Äôre allocating on the Haskell heap. The program text is small and we‚Äôre also not calling any foreign code nor <code>mmap()</code>‚Äôing any memory, so point 4 doesn‚Äôt apply.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p></li>
</ul>
<p>That leaves point 2 which is certainly applicable, but there is another reason that the above list does not mention: fragmentation.</p>
<p>Another metric from the RTS is the <em>heap size</em>. Heap size is an all inclusive metric of the Haskell heap. It includes fragmentation. <code>VmRSS</code> and heap size are about equal in our example program.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> Comparing <code>VmRSS</code> and heap size is a good way to check if the memory usage is truly in the Haskell heap or if there are other issues as listed in point 4.</p>
<h4 id="kilobyte-vs-kibibyte">Kilobyte vs Kibibyte</h4>
<p>As we‚Äôre closely counting bytes, we should make clear the awkward situation that memory is sometimes reported in base 10 units (e.g.&nbsp;kilobyte (kB) = 1000 bytes) and sometimes in base 2 units (e.g.&nbsp;kibibyte (KiB) = 1024 bytes). To make it worse, the ‚Äúi‚Äù used in the symbols for base 2 units (e.g.&nbsp;‚ÄúKiB‚Äù) is often omitted so they look just like the base 10 counterpart (e.g.&nbsp;‚ÄúKB‚Äù). Confusingly, <code>/proc/&lt;PID&gt;/status</code> says ‚ÄúkB‚Äù but means ‚ÄúKiB‚Äù. The <code>eventlog2html</code> output says ‚ÄúG‚Äù, ‚ÄúM‚Äù, and ‚ÄúK‚Äù but means ‚ÄúGB‚Äù, ‚ÄúMB‚Äù, ‚ÄúkB‚Äù. The debugging output from the <code>-Dg</code> RTS option prints ‚ÄúMB‚Äù but means ‚ÄúMiB.‚Äù<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>With the exception of the heap profile graphs (generated with <code>eventlog2html</code>), all numbers in the blog post will be in base 2: gibibyte (GiB) = 1024 MiB, mebibyte (MiB) = 1024 KiB, and kibibyte (KiB) = 1024 bytes.</p>
<h3 id="example">Example</h3>
<p>Let‚Äôs consider the following application that allocates a list of <code>ByteString</code>s and then retains a smaller 1/10th subset of them:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span>-- Main.hs</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span>{-# LANGUAGE BangPatterns #-}</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span>{-# OPTIONS_GHC -Wall #-}</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span>import</span> <span>Control.Concurrent</span> (threadDelay)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span>import</span> <span>Control.DeepSeq</span> (force)</span>
<span id="cb1-7"><a href="#cb1-7"></a><span>import</span> <span>Control.Monad</span> (forM_)</span>
<span id="cb1-8"><a href="#cb1-8"></a><span>import</span> <span>qualified</span> <span>Data.ByteString</span> <span>as</span> <span>BS</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span>import</span> <span>System.Mem</span> (performGC)</span>
<span id="cb1-10"><a href="#cb1-10"></a><span>import</span> <span>System.Environment</span> (getArgs)</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span>main ::</span> <span>IO</span> ()</span>
<span id="cb1-13"><a href="#cb1-13"></a>main <span>=</span> <span>do</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>  n <span>&lt;-</span> <span>read</span> <span>.</span> <span>head</span> <span>&lt;$&gt;</span> getArgs</span>
<span id="cb1-15"><a href="#cb1-15"></a></span>
<span id="cb1-16"><a href="#cb1-16"></a>  <span>-- Allocate lots of ByteStrings (ByteStrings are backed with pinned data)</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>  <span>let</span> <span>!</span>superset <span>=</span> force <span>$</span> <span>take</span> n [BS.singleton x <span>|</span> x <span>&lt;-</span> <span>cycle</span> [<span>minBound</span><span>..</span><span>maxBound</span>]]</span>
<span id="cb1-18"><a href="#cb1-18"></a>  <span>putStrLn</span> <span>"1st Plateau start"</span></span>
<span id="cb1-19"><a href="#cb1-19"></a>  spin <span>3</span></span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a>  <span>-- Extract only a small subset of the superset and allow superset to be</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>  <span>-- garbage collected. Specifically retain every 10th element.</span></span>
<span id="cb1-23"><a href="#cb1-23"></a>  <span>let</span> subsetFactor <span>=</span> <span>10</span><span> ::</span> <span>Int</span></span>
<span id="cb1-24"><a href="#cb1-24"></a>  <span>let</span> <span>!</span>subset <span>=</span> force <span>$</span> [x <span>|</span> (x, <span>1</span>) <span>&lt;-</span> <span>zip</span> superset (<span>cycle</span> [<span>1</span><span>..</span>subsetFactor])]</span>
<span id="cb1-25"><a href="#cb1-25"></a>  <span>putStrLn</span> <span>"2nd Plateau start"</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>  spin (<span>3</span> <span>*</span> subsetFactor)</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a>  <span>-- Stop `subset` from being garbage collected by using it here.</span></span>
<span id="cb1-29"><a href="#cb1-29"></a>  <span>print</span> (<span>length</span> subset)</span>
<span id="cb1-30"><a href="#cb1-30"></a></span>
<span id="cb1-31"><a href="#cb1-31"></a><span>-- Spin and allow heap profiler to collect samples.</span></span>
<span id="cb1-32"><a href="#cb1-32"></a><span>spin ::</span> <span>Int</span> <span>-&gt;</span> <span>IO</span> ()</span>
<span id="cb1-33"><a href="#cb1-33"></a>spin i <span>=</span> forM_ [<span>1</span><span>..</span>i] (\_ <span>-&gt;</span> threadDelay <span>1</span> <span>&gt;&gt;</span> performGC)</span></code></pre></div>
<p>Compile with <code>ghc -rtsopts -eventlog -debug Main.hs</code> and run with <code>./Main 10000000 +RTS -s -Dg -hT -l --disable-delayed-os-memory-return -RTS</code>. The <code>-hT -l</code> options produce an eventlog with a memory profile that we can be visualized with <code>eventlog2html</code>. The <code>-Dg</code> option prints garbage collector statistics to standard error. The <code>--disable-delayed-os-memory-return</code> option is explained later.</p>
<p>Consider what we expect when running a heap profile. The program should allocate some memory then spin a bit. Next, <code>superset</code> is garbage collected and we‚Äôre left with <code>subset</code>. We expect heap residency to drop to 1/10 of the size. After spinning for some more time the program will exit. That‚Äôs what we expect. Here is what the heap profile shows:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/prof-heap-strip.svg"></p>
<p>The majority of memory is <code>PS</code>, <code>ARR_WORDS</code>, <code>:</code>, and <code>PlainPtr</code>. These are the type constructors found in a list of <code>ByteString</code>. <code>PS</code> is the <code>ByteString</code> constructor and <code>PlainPtr</code> and <code>ARR_WORDS</code> are internal to <code>ByteString</code>. We see that allocating <code>superset</code> results in about 1.04GiB (1.12GB) of heap residency corresponding to the first plateau in the heap profile between 27 and 39 seconds. After this, we take 1/10 of that data, <code>subset</code>, and allow the rest of <code>superset</code> to be garbage collected. Hence, we expect the heap residency to drop to about 1/10 of the size, 0.10GiB (0.11GB), but this is not what the profile shows! Heap residency decreases only to about 0.37GiB (0.4GB) and all of <code>ARR_WORDS</code> is unexpectedly retained.</p>
<p>This is not some subtle mistake in the code causing <code>ARR_WORDS</code> to be retained. This is in fact due to how the RTS handles pinned memory. Let‚Äôs look at the memory residency reported by the operating system. I sampled the <code>VmRSS</code> reported in <code>/proc/&lt;pid&gt;/status</code> every 0.01 seconds:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/prof-vmrss-strip.svg"></p>
<p>The <code>VmRSS</code> has some discrepancies with the heap profile. The OS is reporting about 1.84GiB of memory at the first plateau. That‚Äôs almost 1.8 times more than the heap profile. In synch with the heap profile, between 40 and 61 seconds, there is a second plateau where <code>VmRSS</code> is about 1.5GiB. That‚Äôs about 4 times more than the heap profile. So not only is the <code>VmRSS</code> significantly higher than heap residency on the first plateau, but the discrepancy is much worse on the second plateau.</p>
<h3 id="the-heap">The Heap</h3>
<p>In order to make sense of the memory profile we need to understand the structure of GHC‚Äôs Haskell heap, how allocation works, and a bit about garbage collection. I‚Äôll give a simplified overview of this. In particular I‚Äôm ignoring megablock/block groups, block descriptors, and am only considering the oldest garbage collector generation. I‚Äôm also assuming that the default copying garbage collector is in use.</p>
<h4 id="megablocks-blocks-and-objects">Megablocks, Blocks, and Objects</h4>
<p>The Haskell heap is made up of 1MiB ‚Äúmegablocks‚Äù. Within those are 4KiB ‚Äúblocks‚Äù. Within those blocks are the actual data objects. Blocks are designated as exclusively containing either pinned or unpinned data. Here is an example of what the heap might look like in virtual memory space:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/heap-legend.png"> <img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/heap-example.png"></p>
<p>This is not to scale. In reality a megablock contains many more blocks, a block typically contains many more objects, and objects can vary in size. Notice that megablocks are not necessarily contiguous within virtual memory space. We call the unused gaps between megablocks ‚Äúmegablock level fragmentation‚Äù:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/megablock-level-frag.png"></p>
<p>Likewise the unused gaps between blocks within megablocks is called ‚Äúblock level fragmentation‚Äù:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/block-level-frag.png"></p>
<p>Dead objects within blocks are called ‚Äúobject level fragmentation‚Äù:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/object-level-frag.png"></p>
<p>Note that some blocks have some unused space at the end because we have yet to add objects there or there was not enough space to add an object so the RTS allocated a new block instead. That extra space is called ‚Äúslop‚Äù and we don‚Äôt count this as object level fragmentation. We mostly ignore slop for this post.</p>
<h4 id="pinned-data">Pinned Data</h4>
<p>What is pinned data? Thanks to referential transparency, the memory address of an object in Haskell is usually not important. This permits the RTS‚Äôs default copying garbage collector to move objects around in memory i.e.&nbsp;changing their memory location. In practice, we may want a chunk of memory that won‚Äôt be moved by the RTS. The most obvious example is when passing data to foreign code. The foreign code won‚Äôt be very happy if the RTS suddenly moves that data. As such, GHC supports the notion of ‚Äúpinned‚Äù data which can be allocated via <code>GHC.Exts.newPinnedByteArray#</code> and similar variants. Pinned data is guaranteed not to be moved by the RTS. We refer to all other data as ‚Äúunpinned‚Äù. ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.well-typed.com/blog/2020/08/memory-fragmentation/">https://www.well-typed.com/blog/2020/08/memory-fragmentation/</a></em></p>]]>
            </description>
            <link>https://www.well-typed.com/blog/2020/08/memory-fragmentation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232809</guid>
            <pubDate>Fri, 21 Aug 2020 07:21:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ReMarkable MicroSD (2019)]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 120 (<a href="https://news.ycombinator.com/item?id=24232801">thread link</a>) | @devnonymous
<br/>
August 21, 2020 | http://www.davisr.me/projects/remarkable-microsd/ | <a href="https://web.archive.org/web/*/http://www.davisr.me/projects/remarkable-microsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>This page discusses how I added a microSD card to my <a href="https://arstechnica.com/gadgets/2017/12/remarkable-tablet-review-the-high-price-of-getting-that-paper-feeling/">reMarkable tablet</a>. I did this because I want to develop software for my rM without wearing out the internal eMMC. I chose an external card because I want to be able to swap them easily; it also makes backups faster.<br>
</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/34.jpg" alt="Opened reMarkable tablet">




<h2><a name="opening">Opening the Case</a></h2>
<p>
The aluminum back panel is held to the plastic case with glue. I have 
not yet determined what melts this glue, or how to ‚Äúproperly‚Äù take the 
back off. I was able to lift it off, by starting slowly in a corner. 
Thereafter, I used a putty knife to slowly peel it away. The panel bent,
 but I was able to bend it mostly-flat again.
</p><p>
Next, there is a magnesium chassis screwed to the plastic case. 
Underneath the rubber feet are six silver screws. There are also XX 
black screws, that must be removed.
</p><p>
The epaper display is glued to the magnesium chassis; don‚Äôt try to pull 
it apart. There is also a white silicone-like substance around the edge 
of the epaper panel, which seems to disintegrate and flake off. I think 
it fills the gap, and perhaps offers a little waterproofing. This is 
non-replaceable. The screen can be pushed apart from the plastic 
chassis. It is held on the perimeter with plastic latches, so split it 
with a spudger and go slowly.
</p><p>
With the case off, the guts can be removed. There are five connectors to
 the logic board. In clockwise order starting at top-left: power button,
 touch panel, antenna, epaper display, USB daughterboard and buttons, 
and Wacom digitizer.
</p><p>
Finally, the logic board can be removed. It is held with six small 
screws and washers. Underneath the logic board is a plastic tape, a 
section of which must be removed around the SD pads.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/mmc-pads.jpg" alt="MMC solder pads">

<h2>
<a name="positioning">Positioning the Card</a>
</h2>
<p>
The bottom-right seemed like an appropriate placement for the card 
socket, because the area is already spacious. The right side was easier 
to route the cables to, because of the channels cut in the white plastic
 case. I reassembled the reMarkable 
prior to soldering, to ensure no bulges or deformities appered.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/placement.JPG" alt="Placing the microSD slot in the lower right corner">

<h2>
<a name="soldering">Soldering the Wires</a>
</h2>
<p>
Using ten 30 AWG wires and plenty of flux, I connected the board to the 
socket. The board indicates which pin is first. The board has a ninth 
pin, which is used for card-detect. This gets pulled low when a card is 
inserted.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/flatcable.JPG" alt="Wires underneath logic board">
<p>
To keep things as flat as possible, I used cellophane tape to mate the 
wires to the board. They feed out beneath the digitizer‚Äôs FFC cable in 
one beautiful ribbon. This also prevents elecrical contact to the grounded chassis.<br>
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/wires.JPG" alt="Wires on back">

<h2>
<a name="cutting">Cutting the Case</a>
</h2>
<p>
I drilled the SD slot by-hand with a rotary tool. Starting with a carving bit
 on the inside, I first hollowed out the area to give me a thin veneer, 
measured with a flashlight. Once I felt it was thin enough, I drilled 
from the front with a pointy sanding bit, and cut longitudinally.</p><p>
The magnesium chassis had a small section removed, which was easy with a
 tiny wire cutter. While it sacrifices a little
 bit of strength, it makes up for it in storage capacity.
</p><p>
After testing the fit once again, I fillited epoxy around the edge 
of the socket, gluing it down. I was careful not to get any inside the 
socket.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/externalshot.JPG" alt="microSD slot from the outside">

<h2>
<a name="loading">Loading the Kernel</a>
</h2>
<p>The stock rM kernel doesn't enable the SDHC1 slot, which is how these
 pins are designated in the device tree file. I recommend first being 
comforable with <a href="https://github.com/torwag/remarkableflash">this remarkable-flash guide</a>, the <a href="http://www.davisr.me/projects/remarkable-microsd/i.MX_BSP_Porting_Guide_Linux.pdf">NXP porting guide for the i.MX6 processor</a>, and the <a href="http://www.davisr.me/projects/remarkable-microsd/i.MX_Yocto_Project_User%27s_Guide_Linux.pdf">i.MX Yocto user guide</a>.<br>

</p>
  <p>The rM is a mostly-vanilla i.MX6 board (many share similaries, including the <a href="http://www.davisr.me/projects/remarkable-microsd/pico-imx6ul-emmc-hobbit-reva1-hardware-manual-20160328.pdf">Hobbitboard</a>).
 As such, it shares the same SDHC interface. What the microSD slot 
connects to, and what the stock kernel does not activate, is the SDHC1 
interface. This can be enabled in the device tree, and the kernel may be
 recompiled to include support for an SD card.<br>
  </p>
<p>
By default, the sdhc1 interface is disabled in the device tree. Enabling
 this is the first step. Copy the 
<code>arch/arm/boot/dts/zero-gravitas-factory.dts</code> over 
<code>arch/arm/boot/dts/zero-gravitas.dts</code>. Then, edit it to enable the sdhc1 
interface like shown in the diff below.
</p>
<pre> &amp;usdhc1 {<br>        pinctrl-names = "default", "state_100mhz", "state_200mhz";<br>        pinctrl-0 = &lt;&amp;pinctrl_usdhc1&gt;;<br>        pinctrl-1 = &lt;&amp;pinctrl_usdhc1_100mhz&gt;;<br>        pinctrl-2 = &lt;&amp;pinctrl_usdhc1_200mhz&gt;;<br>        bus-width = &lt;4&gt;;<br>        cd-gpios = &lt;&amp;gpio4 7 GPIO_ACTIVE_LOW&gt;;<br>        disable-wp;<br>        wp-controller;<br>        keep-power-in-suspend;<br>        enable-sdio-wakeup;<br>        no-1-8-v;<br>        /*disable-wp;*/<br>-       status = "disabled";<br>+       status = "okay";<br> };
</pre>


<p>Next, <code>make zero-gravitas_defconfig</code> and edit the <code>.config</code> file produced to include the following drivers.</p><pre>CONFIG_CFG80211=y
CONFIG_MAC80211=y
CONFIG_BRCMUTIL=y
CONFIG_BRCMFMAC=y
CONFIG_RTL_CARDS=y
CONFIG_BATTERY_BQ27XXX=y
CONFIG_BATTERY_BQ27XXX_I2C=y
CONFIG_USB_ACM=y
CONFIG_USB_F_ACM=y
CONFIG_USB_U_SERIAL=y
CONFIG_USB_CDC_COMPOSITE=y
CONFIG_CRYPTO_AEAD=y
CONFIG_CRYPTO_GF128MUL=y
CONFIG_CRYPTO_NULL=y
CONFIG_CRYPTO_CCM=y
CONFIG_CRYPTO_GCM=y
CONFIG_CRYPTO_SEQIV=y
CONFIG_CRYPTO_CTR=y
CONFIG_CRYPTO_GHASH=y
CONFIG_CRYPTO_ARC4=y
</pre>
<p>
Once done, rebuild the Linux kernel with <code>make</code>. Copy the artifacts to the rM's <code>/boot</code> directory: <code>arch/arm/boot/dts/zero-gravitas.dtb</code> and <code>arch/arm/boot/zImage</code>. I have included my artifacts <a href="http://www.davisr.me/projects/remarkable-microsd/boot.tar">here</a> for posterity, but it is foolish to install a kernel that someone else compiled.<br>
</p><p>
Reboot the rM, to make sure xochitl still runs. Then, check <code>dmesg | grep
 ‚Äòmmc0‚Äô</code> to ensure the card was detected, and double-check it with <code>fdisk 
-l</code>. Partition your card as you like, then change the /etc/fstab option 
to mount that partition at /home.
</p>
<pre>root@reMarkable:~# dmesg | grep mmc0
[    2.091218] mmc0: SDHCI controller on 2190000.usdhc [2190000.usdhc] using DMA
[    2.377570] mmc0: new high speed SDXC card at address aaaa
[    2.391939] mmcblk0: mmc0:aaaa SC200 183 GiB 
</pre>
<pre>#/dev/mmcblk1p7 /home auto defaults,nofail 1 2
/dev/mmcblk0p7 /home auto defaults,nofail 1 2
</pre>
<p>
Reboot, and bask in the increased storage capacity.
</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/storage-screen.png" alt="Storage screen showing 179 GB free">

<h2>
<a name="notes">Ending Notes</a>
</h2>
<ul>
<li>Now, the aluminum back is held on with gaffer tape. I am afraid to glue it shut, in case I want to access the guts again.
</li><li>Maybe the white stuff that came out around the bezel can be replaced with calk</li><li>I wish I had used multicolor wires, because it was difficult following them with my eyes.
</li><li>I didn‚Äôt cut close enough to the top of the plastic case, and 
so my SD slot is taller than it needs to be, but it isn't very 
noticable. I shimmed the extra vertical space with a folded up business 
card for a tighter fit.
</li><li>Before using solid-core wirewrap wire, I tried making my own 
ribbon cable with magenet wire and masking tape. This didn‚Äôt work well, 
because the enamel was hard to remove from just the ends, and the 
masking tape was too thick. The wirewrap wire turned out much nicer.
</li><li>Technically, I think the IMX needs to be changed too (and 
re-wrote over /dev/mmcblk1boot0) but I didn‚Äôt do this, and it seems to 
work alright. I'm fine using it just for the data partition so my OS updates work.
</li>
<li>I am glad this article has created encouragement from other people. I
 would like to extend an offer: if you would like a microSD card in your
 rM, and are willing to let me install one with the possibility of it 
not coming out exactly perfect (i.e. someone who finds ultimate use of 
rM in its utility, not pristine beauty) I would like to refine this 
process. One thing could be to install an internal card using quality 
flash media. I would like to know how many people could go for something
 like that, and if there could be a market doing that kind of thing. I 
will soon have installed my own CNC machine, and can practice doing this
 modification better, eventually charging for the service.<br>
</li>
</ul>

<h2><a name="images">More Images</a></h2>
<img src="http://www.davisr.me/projects/remarkable-microsd/backpanel.jpg" alt="Back panel">
<img src="http://www.davisr.me/projects/remarkable-microsd/connectors.jpg" alt="Connectors">
<img src="http://www.davisr.me/projects/remarkable-microsd/cracking-open.jpg" alt="Splitting the case open">
<img src="http://www.davisr.me/projects/remarkable-microsd/dontpullscreen.jpg" alt="Don't pull the screen like this">
<p>Don't peel the screen off!</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/openback.jpg" alt="Open back">
<img src="http://www.davisr.me/projects/remarkable-microsd/split-chassis.jpg" alt="Split chassis">

</article></div>]]>
            </description>
            <link>http://www.davisr.me/projects/remarkable-microsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232801</guid>
            <pubDate>Fri, 21 Aug 2020 07:20:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I got the French Tech Visa to start my company in France]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 190 (<a href="https://news.ycombinator.com/item?id=24232025">thread link</a>) | @christpetron
<br/>
August 20, 2020 | https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/ | <a href="https://web.archive.org/web/*/https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Three years ago, things were different. I didn‚Äôt know any French, I didn‚Äôt have a business, and I didn‚Äôt have a job.</p>



<p>I had just quit a great job in Singapore to start my own company. My partner was starting her master‚Äôs in Paris and told me to come stay. So I packed up everything, shipped some of it to my mom in New York, and hopped on a flight to CDG.</p>



<figure><img src="http://christianpetroske.com/wp-content/uploads/2020/08/paris.png" alt="" srcset="https://christianpetroske.com/wp-content/uploads/2020/08/paris.png 878w, https://christianpetroske.com/wp-content/uploads/2020/08/paris-300x74.png 300w, https://christianpetroske.com/wp-content/uploads/2020/08/paris-768x191.png 768w" sizes="(max-width: 878px) 100vw, 878px"></figure>



<p>Around this time, French President Macron released an iconic video as part of the <a rel="noreferrer noopener" href="https://makeourplanetgreatagain.fr/en/business" target="_blank">Make Our Planet Great Again campaign</a>. He told scientists, researchers, and innovators from around the world to come to France. I was supposed to be an innovator now. My ears perked up.</p>



<p>‚ÄúYour new homeland‚Äù it said. It continued: ‚ÄúEntrepreneurs and skilled employees from all over the world, France is made for you!‚Äù</p>



<p>Made for me, huh? Okay, I‚Äôll bite.</p>



<p>I bit.</p>



<p>A few clicks later I found myself reading about <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/" target="_blank">the French Tech Visa</a>, a visa scheme that awards founders of tech companies a visa for four years to live and start their business in France.</p>



<p>This seemed like the ultimate three-birds-one-stone: I would get to start my company, be with my partner, and live in effing Paris‚Äîlearning French, discussing philosophy, eating croissants, whatever else people do in Paris. Life sorted for the next few years! Right?</p>



<p>In retrospect, I was right about the big stuff: starting the company, living with my partner, learning French, and the croissants (oh oui). </p>



<p>But it did not come easy. I learned a ton. I am incredibly grateful that it worked out. There were many moments when it almost didn‚Äôt. Through a combination of luck, hustle, privilege, and the kindness of others, I am where I am today: running my own business, living in France with my partner, speaking French, eating croissants, and looking back on it all muttering <em>putain</em> in happy disbelief.</p>



<p>Looking back too, I‚Äôm struck by how little information there was out there for people in my situation. I kept finding out critical information through chance conversations‚Äîand I‚Äôd done my research. I started thinking that he whole process should be a lot more transparent.</p>



<p>I‚Äôve since had conversations with several people who were considering this path. So I decided to write down some of it to help others who are thinking about coming to France to start their company.</p>



<p>If that‚Äôs you, here are the basics of what you need to know. The challenge generally breaks down into 1) the visa, 2) the business, and 3) the language and culture.</p>



<p>(If you‚Äôre really serious about this, I‚Äôm writing a complete guide to the French Tech Visa which <a href="https://gum.co/SRUhE" target="_blank" rel="noreferrer noopener">you can preorder here</a>.)</p>



<h2>First: the visa</h2>



<p>There are three different French Tech visas: for <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-founders/" target="_blank">founders</a>, <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-employees/" target="_blank">employees</a>, and <a rel="noreferrer noopener" href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-les-investors/" target="_blank">investors</a>. I have the one for founders. That‚Äôs the one I know the most about, so it‚Äôs the one I focus on here.</p>



<p>The first step to getting the French Tech Visa for founders is to look at this list of incubators.</p>



<figure><a href="https://lafrenchtech.com/en/how-france-helps-startups/french-tech-visa/visa-for-founders/" target="_blank" rel="noopener noreferrer"><img src="http://christianpetroske.com/wp-content/uploads/2020/08/image-1024x707.png" alt="" srcset="https://christianpetroske.com/wp-content/uploads/2020/08/image-1024x707.png 1024w, https://christianpetroske.com/wp-content/uploads/2020/08/image-300x207.png 300w, https://christianpetroske.com/wp-content/uploads/2020/08/image-768x530.png 768w, https://christianpetroske.com/wp-content/uploads/2020/08/image-1536x1061.png 1536w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2048x1414.png 2048w, https://christianpetroske.com/wp-content/uploads/2020/08/image-1200x829.png 1200w, https://christianpetroske.com/wp-content/uploads/2020/08/image-1980x1367.png 1980w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>These incubators are all partnered with the French government to support foreign founders. The kind of support varies, but your goal is to find one that can offer you the visa.</p>



<p>One week, I decided I would do this. So I came up with a startup idea, made a pitch deck, website, and email address, and started sending emails. I reached out to probably 30 of these and had conversations with about 10 until it got down to 2-3 that seemed promising. </p>



<p>I just found the deck I made in Canva. It was an employee engagement app called Purpose, Go! (I know right?).</p>



<figure><img src="http://christianpetroske.com/wp-content/uploads/2020/08/image-2-1024x768.png" alt="" srcset="https://christianpetroske.com/wp-content/uploads/2020/08/image-2-1024x768.png 1024w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-300x225.png 300w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-768x576.png 768w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-1536x1152.png 1536w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2-1200x900.png 1200w, https://christianpetroske.com/wp-content/uploads/2020/08/image-2.png 1754w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Lol ok, not bad. How an app was supposed to accomplish that, lord knows.</figcaption></figure>



<p>I ended up on the phone with <a rel="noreferrer noopener" href="https://theschoolab.com/en/" target="_blank">Schoolab</a> in Paris, who said they liked my idea and told me to come in to meet the team. I met them, did a tour, and got offered a spot. It cost me ‚Ç¨650 a month for their 6 month program, including the visa, access to the community of startups and mentors, and office space. I took the deal.</p>



<p>Fees vary by incubator, but overall you‚Äôll need around ‚Ç¨5,000 in the bank to pay for the incubator program plus taxes and fees in the application process.</p>



<p>Then, you‚Äôll need to prove that you have money equal to the French minimum wage (‚Ç¨18,254.60 in 2019). I didn‚Äôt have this. Instead, you can find someone who does have this kind of money to be your ‚Äúguarantor‚Äù. The visa office will accept it as long as that person signs a letter saying they will support you if needed while you‚Äôre in France.</p>



<p>Once you get into the incubator, they will help you apply to get your three-page business proposal approved by the relevant government agency. They even helped me translate mine into French. It takes a couple of months, but once you have that approval letter, you are on the fast track for a four year visa.</p>



<p>There are differences by country, but being a US citizen, I had to go back to my home consulate in New York to complete the visa process.</p>



<p>I arrived in France in August, started the incubator in September, and didn‚Äôt get my provisional visa until February‚Ä¶ So that gives you an idea. </p>



<h2>Second: the business</h2>



<p>Once I was in the incubator, the next challenge arose: What the hell was I going to do with this business?</p>



<p>For about two solid months I worked on Purpose, Go! alongside various client projects to keep some money coming in. I networked hard in the HR tech world in Paris and got to know some interesting people. But it became clear that these relationships were not going anywhere‚Äîand without relationships, I had no hope of selling into businesses.</p>



<p>So I started spending more time with a friend I‚Äôd made in the program, <a rel="noreferrer noopener" href="https://plentyworks.io/outer-space-mindset/" target="_blank">Buddhika</a>, who was working on a VR fitness company. When it became clear my thing wasn‚Äôt going to work (and they were struggling a bit too), we started talking in earnest about partnering up. Becoming co-founders.</p>



<p>So I started to work with them on the VR fitness idea. It was clear it was going to take a while to mature into something that could make money, so we looked around for income sources. One of our friends in the program needed an app built, so we decided to go into software development. That‚Äôs what led to our real French company.</p>



<p>We started out as individual micro-entrepreneurs, since it‚Äôs super easy to get started and get paid legally through that status. Eventually, we opened up a SAS entity in what seemed like an extremely painful and expensive process. It didn‚Äôt need to be.</p>



<p>The perfect time to start a SAS (the equivalent of a US Corporation) is when you‚Äôre building something you want to raise money for at some point. We wanted to keep our options open, so we did that. </p>



<p>Many small businesses start as SARL entities (rough equivalent of a US LLC) instead, since taxes are lower but fundraising ability is null.</p>



<p>Whatever you choose, the most important (and most difficult) thing is to find a way to actually get paid in the first place. French business is highly networked, even more so than the US, which means that people like to only do business with people they have a relationship with. So investing in building relationships is the number one most important thing you can do for the success of your French business.</p>



<p>Speaking of which‚Ä¶</p>



<h2>Third: the language</h2>



<p>To build relationships with people, you will need some level of French. It‚Äôs certainly possible to only run in circles where you can speak English, don‚Äôt get me wrong. But you will miss opportunities if you‚Äôre constrained by language.</p>



<p>One of the first places you may run into this problem is when looking for an incubator. Schoolab, for instance, has since shrunk or canceled their English-language programming since I was there because it was too difficult to maintain programs in two languages (and they couldn‚Äôt get everyone to switch over to English). </p>



<p>So how do you learn French quickly, cheaply, and effectively?</p>



<p>This is exactly what I tried to do, being hyper-conscious that my runway was dwindling with each passing month. Here was my rough language-learning regimen that got me conversational in about 6 months:</p>



<ul><li>Start out with cheap private lessons through iTalki. You can spend $10-15 an hour for a junior teacher to talk with you and teach you core grammar principles and vocab.</li><li>Listen to French podcasts constantly. This is key to improving comprehension. Read the transcript along if you can. My favorites at the beginning were <a rel="noreferrer noopener" href="https://savoirs.rfi.fr/fr/apprendre-enseigner/langue-fran%C3%A7aise/journal-en-fran%C3%A7ais-facile" target="_blank">Le Journal en Fran√ßais Facile from RFI</a>, <a rel="noreferrer noopener" href="https://podcasts.apple.com/gb/podcast/learn-french-by-podcast/id160256534" target="_blank">Learn French by Podcast</a>, and <a rel="noreferrer noopener" href="https://podcasts.apple.com/gb/podcast/coffee-break-french/id263170419" target="_blank">Coffee Break French</a>. Now I love <a rel="noreferrer noopener" href="https://www.lesechos.fr/podcasts/la-story" target="_blank">La Story by Les Echos</a>, <a rel="noreferrer noopener" href="https://www.binge.audio/podcast/a-bientot-de-te-revoir/" target="_blank">A bient√¥t de te revoir</a>, and many more.</li><li>Read French news and blogs. Focus on what you‚Äôre interested in. I‚Äôm interested in technology and startups so I would read <a rel="noreferrer noopener" href="https://www.maddyness.com/" target="_blank">Maddyness</a>.</li><li>Get grammar lessons from YouTube. My hands-down favorite here is <a rel="noreferrer noopener" href="https://learnfrenchwithalexa.com/" target="_blank">Learn French with Alexa</a>. She explains even the advanced concepts so clearly.</li><li>And of course, take every opportunity to talk to real people! Having friends who are willing to suffer through your awful French (and laugh at you a bit, yes) is one of the things that will accelerate your learning the most. Go to events you find on Facebook. Take a dance class. Get out there. The more uncomfortable you are with your language ability, the more motivated you will be to learn faster.</li></ul>



<p>There‚Äôs also the culture to get used to, but maybe we‚Äôll save that one for another post. </p>



<p>It‚Äôs wild that I‚Äôm coming up on three years in France. It has been an adventure. Hopefully some of this will help others navigating this for the first time. </p>



<p>If you liked this story and you want to stay in touch, follow me on <a href="https://twitter.com/christpetron" target="_blank" rel="noreferrer noopener">Twitter</a>.</p>



<hr>



<p>I‚Äôm compiling all this info and more into <a rel="noreferrer noopener" href="https://gum.co/SRUhE" target="_blank">the Complete Guide to the French Tech Visa</a>, which <a rel="noreferrer noopener" href="https://gum.co/SRUhE" target="_blank">you can pre-order right here</a>. It includes:</p>



<ul><li>Step-by-step instructions on how to obtain your French Tech Visa</li><li>The full list of documents you‚Äôll need</li><li>The full timeline of how long you can expect it to take</li><li>The full set of visa-related costs you‚Äôll face</li><li>Step-by-step guidance on creating your French business entity (Micro-entrepreneur, SAS and SARL)</li><li>Important information on taxes, insurance, employment, and liability</li><li>Opening a personal ‚Ä¶</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/">https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/</a></em></p>]]>
            </description>
            <link>https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232025</guid>
            <pubDate>Fri, 21 Aug 2020 04:38:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Braess' Paradox and the Price of Anarchy (2019)]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24231860">thread link</a>) | @luu
<br/>
August 20, 2020 | http://cadlag.org/posts/braess-paradox-and-the-price-of-anarchy.html | <a href="https://web.archive.org/web/*/http://cadlag.org/posts/braess-paradox-and-the-price-of-anarchy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on August 10, 2019
    
        by Erik Davis
    
</p>




<p>Consider the following scenario. A large number of independent agents wish to traverse a network, from some start vertex to some end vertex. Each edge they travel will take some time, which could in general depend on the number of agents traveling along the edge. For the sake of simplicity, we‚Äôll normalize things so that <span>\(x\)</span> denotes a proportion of agents (i.e. <span>\(x\)</span> ranges from 0 to 1). In what follows, we will let <span>\(\mathcal{E}\)</span> denote the set of edges, and <span>\(c_e :
[0,1] \to \mathbb{R}\)</span> the <em>cost</em> function associated with edge <span>\(e\)</span>. A very simple example is something like the following, where <span>\(s\)</span> is the start and <span>\(d\)</span> is the destination, and edges have been labeled with their cost.</p>
<div>
<p><img src="http://cadlag.org/ancillary/braess/initial.png" alt="A simple routing network, with variable edge cost."></p><p>A simple routing network, with variable edge cost.</p>
</div>
<p>One way to summarize the entire set of paths chosen is via a <em>flow</em> <span>\(f\)</span>, which assigns to each edge the normalized proportion of agents who have chosen to travel along it. For example, if all agents chose the top route in the above network, then we would have <span>\(f_{su} = 1, f_{ud} = 1\)</span> and <span>\(f_{sv} = 0, f_{vd} =
0\)</span>. There are of course other possible flows; one could consider the flow that puts all agents along the bottom path, or another which mixes the top and bottom paths somehow. <a href="#fn1" id="fnref1"><sup>1</sup></a></p>
<p>For a general flow <span>\(f\)</span>, the <em>total cost</em> borne by the agents in navigating the network is</p>
<p><span>\[
C(f) = \sum_{e \in E} f_e c_e(f_e).
\]</span></p>
<p>In the above example, routing all traffic along the top path (or equivalently, the bottom path) has a total cost of <span>\(2\)</span>. However, if one split the traffic so that half travels along the top path and half along the bottom path, then the total cost is only <span>\(0.5 c_{su}(0.5) + 0.5 \cdot c_{ud} + 0.5 \cdot c_{sv}(0.5) +
0.5 \cdot_{vd}(0.5) = 1.5\)</span>. In this example, this turns out that this is the minimum cost flow. One could imagine that if we were benevolent dictators controlling the choices of the agents, we might opt for this as an outcome.</p>

<p>Another way of looking at this routing problem is from the agent‚Äôs point of view. Suppose that, for each path <span>\(P\)</span>, some proportion of agents choose <span>\(P\)</span> for their traversal. In other words, we may imagine that we have a distribution <span>\(g\)</span> with <span>\(g_P \geq 0\)</span> and <span>\(\sum_{P \in \mathcal{P}} g_P = 1\)</span>, where <span>\(\mathcal{P}\)</span> denotes the set of <span>\(s-d\)</span> paths through the network. Thus <span>\(g_P\)</span> is the proportion of agents choosing path <span>\(P\)</span>. We‚Äôll call such a <span>\(g\)</span> a <em>path distribution</em>, for lack of a better name.</p>
<p>There‚Äôs nothing lost by thinking about path distributions rather than flows. Indeed, given a path distribution <span>\(g\)</span> we can recover a flow by letting <span>\(f_e =
\sum_{P : e \in P} g_P\)</span>, where the sum is over all paths containing the edge <span>\(e\)</span>. It‚Äôs not hard to show that this is an honest flow.<a href="#fn2" id="fnref2"><sup>2</sup></a></p>
<p>So, from this vantage point: which path would an agent like to pick? In general, the cost of an edge depends on hhow much traffic it gets, so the answer is really contingent on the paths chosen by the other agents.</p>
<p>To give some clarity around this, let‚Äôs introduce an assumption about behavior: an agent will choose a path only if there are no cheaper alternatives. This is both a weak assumption, in the sense that it‚Äôs hard to argue with the rationale, and a strong one, in the sense that we‚Äôre granting each agent quite a lot of information about the problem at hand (e.g. the network topology, the behavior of the other agents, and so on).</p>
<p>With this in mind, note that relative to a fixed flow <span>\(f\)</span>, the cost of a path <span>\(P\)</span> is</p>
<p><span>\[ C(P; f) = \sum_{e \in P} c_e(f_e). \]</span></p>
<p>Formally, a path distribution <span>\(g\)</span> is said to be a (pure Nash) <em>equilibrium</em> distribution if</p>
<p><span>\[ g_P &gt; 0 \text{ only if } P \text{ minimizes } C(P; f), \]</span></p>
<p>where <span>\(f\)</span> is the flow associated with <span>\(g\)</span>.</p>
<p>In other words, in an equilibrium distribution every agent takes a path that is minimal <em>with respect to the flow induced by the others</em>.</p>
<p>It‚Äôs worth mulling this over a bit. With an equilibrium distribution, there‚Äôs no incentive for any particular agent to switch paths. Each agent sees the social world around it as essentially fixed; the others have induced some flow <span>\(f\)</span>, and the best one can do is pick the path that‚Äôs cheapest relative to this.</p>
<p>In our simple network, there is only one equilibrium distribution: half of the agents take the top path, and half take the bottom. The cost of this equilibrium distribution is <span>\(1.5\)</span>, just as before.</p>

<p>To briefly recap, we‚Äôve singled out two sorts of flows as being special.</p>
<ul>
<li>Cost-minimizing flows are the ones that we‚Äôd pick if were playing the part of a benevolent dictator.</li>
<li>Equilibrium flows (i.e. those induced by an equilibrium path distribution) are the ones that we can imagine a bunch of independent agents settling for.</li>
</ul>
<p>It was something of a coincidence that in our toy network these two ended up being the same. But they don‚Äôt have to be.</p>
<p>So what happens if we start adding edges to the network? Naively, it seems like it can only make things better. Certainly, adding an edge doesn‚Äôt increase the cost of any previous flows (since they simply do not use the new edge), and in fact it‚Äôs possible that it makes available a new, cheaper flow. So as benevolent dictators, there‚Äôs not much to lose.</p>
<p>But what happens when we think from the agent‚Äôs perspective? Surprisingly enough, adding an edge can shift the equilibrium flow to something even costlier! For an extreme example, consider adding a free edge to our previous network.</p>
<div>
<p><img src="http://cadlag.org/ancillary/braess/augmented.png" alt="A network augmented with a zero cost edge."></p><p>A network augmented with a zero cost edge.</p>
</div>
<p>With this addition, the equilibrium distribution <a href="#fn3" id="fnref3"><sup>3</sup></a> puts all of the agents on the path <span>\(suvd\)</span>, for a total cost of 2! This is <a href="https://en.wikipedia.org/wiki/Braess%27s_paradox">Braess‚Äô paradox</a>: adding capacity to a network can actually increase the cost of an equilibrium flow.</p>
<div>
<p><img src="http://cadlag.org/ancillary/braess/equilibrium.png" alt="The new equilibrium flow."></p><p>The new equilibrium flow.</p>
</div>
<p>I‚Äôm not going to prove that this flow is equilibrium, but let me give a glimpse of the incentives: the previous distribution, which put half of the agents on the top half and half of the agents on the bottom, is now unappealing from a traveller‚Äôs vantage point: relative to that flow, the effect of an agent on <span>\(sud\)</span> switching to <span>\(suvd\)</span> is to reduce their path cost by <span>\(0.5\)</span>. And so on.</p>

<p>By definition, an equilibrium flow is at least as costly as a cost-minimizing flow. The ratio</p>
<p><span>\[ \frac{\text{maximum cost of an equilibrium flow}}{\text{cost of min cost flow}} \]</span></p>
<p>is sometimes referred to as the <a href="https://en.wikipedia.org/wiki/Price_of_anarchy">Price of Anarchy</a>. For our original network, it was <span>\(1\)</span>. After adding the edge, it was <span>\(4/3\)</span>.</p>







        </div></div>]]>
            </description>
            <link>http://cadlag.org/posts/braess-paradox-and-the-price-of-anarchy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24231860</guid>
            <pubDate>Fri, 21 Aug 2020 04:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Did Mozilla Remove XUL Add-Ons?]]>
            </title>
            <description>
<![CDATA[
Score 378 | Comments 302 (<a href="https://news.ycombinator.com/item?id=24231017">thread link</a>) | @est31
<br/>
August 20, 2020 | https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/ | <a href="https://web.archive.org/web/*/https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>TL;DR: Firefox used to have a great extension mechanism based on the XUL and XPCOM. This mechanism served us well for a long time. However, it came at an ever-growing cost in terms of maintenance for both Firefox developers and add-on developers. On one side, this growing cost progressively killed any effort to make Firefox secure, fast or to try new things. On the other side, this growing cost progressively killed the community of add-on developers. Eventually, after spending years trying to protect this old add-on mechanism, Mozilla made the hard choice of removing this extension mechanism and replacing this with the less powerful but much more maintainable WebExtensions API. Thanks to this choice, Firefox developers can once again make the necessary changes to improve security, stability or speed.</p>

<p>During the past few days, I‚Äôve been chatting with Firefox users, trying to separate fact from rumor regarding the consequences of the August 2020 Mozilla layoffs. One of the topics that came back a few times was the removal of XUL-based add-ons during the move to Firefox Quantum. I was very surprised to see that, years after it happened, some community members still felt hurt by this choice.</p>

<p>And then, as someone pointed out on reddit, I realized that we still haven‚Äôt taken the time to explain in-depth why we <em>had no choice</em> but to remove XUL-based add-ons.</p>

<p>So, if you‚Äôre ready for a dive into some of the internals of add-ons and Gecko, I‚Äôd like to take this opportunity to try and give you a bit more detail.</p>



<p>For a very long time, Firefox was composed of a very small core on top of which everything was implemented as extensions. Many of these extensions were written in C++, others in JavaScript and many involved the XUL interface language and the XBL binding language. C++ and JavaScript code were connected thanks to a technology called XPCOM. Whenever an extension developer wished to customize Firefox, it was simple and extremely powerful, as the exact same building blocks used to power Firefox could be used to customize it.</p>

<p>This is how Session Restore (the technology that lets you resume Firefox where you left it the last time, even in case of crash) or the Find Bar were first implemented in Firefox, among other features. This is the technology that powers Firefox and <a href="https://www.thunderbird.net/">Thunderbird</a>. This is how tools such as <a href="https://en.wikipedia.org/wiki/Songbird_(software)">Songbird</a> (an open-source iTunes competitor) or <a href="https://en.wikipedia.org/wiki/Instantbird">Instantbird</a> (a chat client) were developed. This is also how I customized Firefox to become an eBook reader a long time ago. And this is how thousands of Firefox add-ons were developed.</p>

<p>Many people call this extension mechanism ‚ÄúXUL-based Add-Ons‚Äù, or sometimes ‚ÄúXPCOM-based Add-Ons‚Äù, and I‚Äôll use both terms in this blog entry, but I often think of this as the ‚ÄúPromiscuous Extension Mechanism‚Äù, for several reasons:</p>

<ul>
<li>very quickly, add-on developers realized that anything they did could break anything else in the system, including other add-ons and Firefox itself, and they often had no way to prevent this;</li>
<li>similarly, anything Firefox developers did could break add-ons, and they often had no way to prevent this;</li>
<li>also, some of the changes that Firefox needed to be as fast, as stable and as secure as possible were going to break most add-ons immediately, possibly all add-ons in the longer term;</li>
<li>oh, and by the way, since add-ons could do everything, they could very easily do anything to the operating system, from stealing passwords to pretending to be your bank.</li>
</ul>

<p>Note: Having read in comments that some users apparently do not care about security, let me add that being secure is a really, really important point for Mozilla and has been since the first day. Regardless of add-ons, <em>not</em> having security means that an exploit is eventually going to show up that will steal user‚Äôs passwords and use them to steal their bank accounts ‚Äì and that exploit will get sold around and will soon show up everywhere. Firefox developers fight this threat daily by all sorts of means, including code reviews, defensive programming, crash scene investigations, several types of sandboxing, static analysis, memory-safe languages, ‚Ä¶ Consequently, for Mozilla, if a feature prevents us from achieving great security, we <em>always</em> pick security over features.</p>

<p>I‚Äôll return to these points in more details later. For the moment, suffices to say that it had been clear to Firefox developers for a long time (at least since 2010) that this situation was untenable. So Mozilla came up with a backup plan called the <em>Firefox Jetpack</em>.</p>

<p>Firefox Jetpack was a very different manner of extending Firefox. It was much cleaner. It finally had a permissions mechanism (something that had been suggested even before Firefox was called Firefox and that was generally considered too hard to implement). Out of the box, add-ons could not break each other or Firefox (I seem to remember that it was still sometimes possible by exploiting the observer service, but you had to work hard at it), it made extensive use of async programming (which was great to achieve a feeling of high-performance) and thanks to the fact that it had a finite API, it could be tested, which meant that when Firefox developers broke add-ons, they knew about it immediately and could fix the breakages! That was several enormous steps forward. This came at the cost of a more limited API but in most cases, the tradeoff seemed worth it.</p>

<p>Unfortunately, it turned out that there was an unexpected incompatibility between the design of Jetpack and some of the major changes that were needed in Firefox. I‚Äôm not entirely clear about what this incompatibility was but this meant that we had to abandon Jetpack.
Instead, we introduced WebExtensions. Overall, WebExtensions had a similar objective as Jetpack-based add-ons, with a similarly restricted API and the added bonus that they could be made to work on both Chromium-based browsers and Firefox.</p>

<p>If you needed very advanced APIs, switching from the promiscuous extension mechanism to Jetpack or WebExtensions was not always possible, but for most extensions, the transition was simple ‚Äì in my personal experience, it was even pleasant.</p>

<p>Firefox introduced WebExtensions in time for Firefox Quantum because this is when the promiscuous add-on model was scheduled to break.</p>

<p>At this stage, we‚Äôre done with the historical overview. I hope you‚Äôre ready for a more technical dive because that‚Äôs how I‚Äôm going to explain to you exactly which problems were solved as we switched from the promiscuous extension model to WebExtensions.</p>



<h2 id="how-it-started">How it started</h2>

<p>XPCOM, the Xross-Platform Component Object Model, is perhaps the feature of Firefox that can best be described as <em>the core</em> (for people who know Gecko in-depth, I‚Äôm counting XPConnect and the Cycle Collector as part of XPCOM), alongside SpiderMonkey, our JavaScript Virtual Machine.</p>

<p>XPCOM is a technology that lets you write code in two languages and have each other call the other. The code of Firefox is full of C++ calling JavaScript, JavaScript calling C++ and a long time ago, we had projects that added Python and .Net in the mix. This piece of machinery is extremely complicated because languages do not share the same definitions (what‚Äôs a 64-bit integer in JavaScript? what‚Äôs a JavaScript exception in C++?) or the same memory model (how do you handle a JavaScript object holding a reference to a C++ object that C++ might wish to <code>delete</code> from memory?) or the same concurrency model (JavaScript workers share nothing while C++ threads share everything).</p>

<p>Gecko itself was originally designed as thousands of XPCOM components that could each be implemented in C++ or in JavaScript, tested individually, plugged, unplugged or replaced dynamically and <em>it worked</em>. In addition, the XPCOM architecture made for much cleaner C++ programming than was available at the time, worked on dozens of platforms, and let us combine the convenience of writing code in JavaScript and the raw speed permitted by C++.</p>

<p>To write a XPCOM component, you typically define <a href="https://searchfox.org/mozilla-central/rev/6cc48251bb97600fdf11a5b4c5f621bfc8606d55/dom/interfaces/base/nsIFocusManager.idl">an interface</a>, then write the implementation in either C++ or JavaScript (or Rust, nowadays, and maybe soon Wasm). Some boilerplate is needed, but hey, it works.</p>

<p>When early Firefox developers decided to open the platform to extensions, XPCOM was immediately picked as the base technology for add-ons. Firefox just had to let add-on authors plug anywhere within the code and they would have tremendous power at their disposal.</p>

<p>And add-on developers (including myself) certainly did and had lots of fun with it!</p>

<h2 id="the-era-of-immutable-xpcom">‚Ä¶the era of immutable XPCOM</h2>

<p>Unfortunately, problems progressively started to creep up.</p>

<p>When you‚Äôre developing a large application, you need to change things, either to fix bugs or to add new features, or to improve performance. In the XPCOM world, this meant changing XPCOM components. Sometimes to add new features to a component. Sometimes to entirely remove one because this design has been replaced with a better design.</p>

<p>In the first era of the XPCOM-based extension mechanism, this was often forbiddden. If there was an XPCOM component used by add-ons, it simply <strong>could not</strong> be changed in incompatible ways. This was great for add-on developers but it quickly became a nightmare for Firefox developers. Because every single change had to be made in backwards-compatible way both externally (for web developers) and internally (for add-on developers). This meant that each XPCOM component <code>nsISomething</code> was quickly accompanied by a <code>nsISomething2</code>, which was the better component ‚Äì and both needed to be made to work alongside each other - One case was even more complicated to handle by Firefox developers: XPCOM-based add-ons could replace <em>any existing XPCOM component</em>. Needless to say, this was a very good way to break Firefox in ways that puzzled Firefox crash investigators.</p>

<p>This meant that development became slower and slower as we needed to check each new feature or each improvement against not only current features, but also past/deprecated features or simply old ways to work ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</a></em></p>]]>
            </description>
            <link>https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24231017</guid>
            <pubDate>Fri, 21 Aug 2020 01:30:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promised Land: Religious Ideology and Solarpunk Science Fiction]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24230502">thread link</a>) | @apsec112
<br/>
August 20, 2020 | http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/ | <a href="https://web.archive.org/web/*/http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<div>
  <p><span>Octavia Butler, the Black science fiction author to whom all others were compared until the coming of N.K. Jemisin, published the novel </span><i><span>Parable of the Sower</span></i><span> in 1993,</span> <span>first of a trilogy. In her fictional near-future, Southern California will become but one of the newly red-lined regions earmarked for a corner pocket of Hell, because the end is nigh. I‚Äôm talking, dolphins Snapchatting us, ‚ÄúWE OUT! NO-THANKS-FOR-THE-MERCURY-MARINATED-FISH!‚Äù-type of climatic environmental and societal collapse. No kaiju necessary. We will die of consumption after a fifty-plus year bender, drunk on neoliberal, late-stage capitalist moonshine.</span></p>
<p><em><span>[[This article appears in <a href="http://thenewmodality.com/letter-from-the-editor-newmo-issue-one/">Issue One</a> of </span></em><span>The New Modality.</span><em><span><a href="https://thenewmodality.backerkit.com/hosted_preorders"> Buy your copy or subscribe here</a>.]]</span></em></p>
<p><span>Fast forward to our present non-fiction. My day job is teaching elementary school. Yet despite the allure of two months of do-whatever-I-want-time, more and more I dread the coming of summer, because glaciers the size of islands are falling into the ocean. Is this the season when my <em>Westworld</em> kingdom is invaded by drought and famine? When Russia‚Äôs permafrost melts, releasing primeval microscopic disease-titans (</span><a href="http://www.bbc.com/earth/story/20170504-there-are-diseases-hidden-in-ice-and-they-are-waking-up"><span>they are real, 2017</span></a><span>) to gobble me up in a surprise Greek tragedy? When the floodgates of my Amazon-fueled desires are permanently clogged by natural man-made disaster? Of course, Prime will continue to deliver, but the markup would be understandably obscene.</span></p>
<p><span>Will this be the season my melanin hard-fails me?</span></p>
<p><span>I joke because I‚Äôm afraid. Not only is this specific dystopia possible, Butler seems to have predicted it twenty-seven years ago. </span><i><span>Parable of the Sower</span></i><span> is set somewhere in the 2020s during a presidential election in which the candidate‚Äôs campaign slogan is ‚ÄúMake America Great Again</span><i><span>.‚Äù </span></i><span>Oh yes, and California actually </span><i><span>is</span></i> <span>burning right now. This is a horrible present. I ordered the exact opposite of this nightmare. I asked for solarpunk.</span></p>
<p><b>Solarpunk: The Genre of Solutions</b></p>
<p><span>Solarpunk is the environmentally conscious speculative arts movement that best navigates the terrors ahead. Detractors label it a kind of Pollyanna utopianism full of empty calories. It‚Äôs true that the Google replicator machine will serve up a visual feast</span><span> of enforested skyscrapers and lush solar energy mushroom cities (possibly under the sea, possibly shared with amiable, buck-toothed invertebrates with ageless comedic timing). The solarpunk aesthetic will sometimes wear utopian clothing, but it‚Äôs nobody‚Äôs fault, really. Ursula K. Le Guin helped plant solarpunk seeds decades ago, in stories such as the 1972 novel </span><i><span>The Dispossessed,</span></i> <span>her 1982 essay ‚Äú</span><a href="https://www.fifthestate.org/archive/382-spring-2010/non-euclidean-view-california-cold-place-1982/"><span>A Non-Euclidean View of California as a Cold Place to Be</span></a><span>,‚Äù</span> <span>and many othe</span><span>r Daoist-inspired works</span><i><span>.</span></i><span> Thus, the movement was growing long before the term was coined in 2008. So after decades of imagineering and community building, there are bound to be layers and crumbly edges. And to be fair, it is impossible to dream of Hell and not pine for its opposite.</span></p>
<p><span>In truth, solarpunk is functional AF. The primary colors of its aura are red, orange, and yellow: Courageously compassionate, creatively scientific, and awakened interdependence. In many ways, it can be more rigorous than so-called ‚Äúhard science fiction.‚Äù Don‚Äôt @ the messenger; I‚Äôm quoting Kim Stanley Robinson, author of </span><i><span>New York 2140</span></i><span> among many other groundbreaking stories of eco-fiction. He takes issue with the viral over-affixation of ‚Äú-punk‚Äù (Google punk genres and see how many you get). However, at Boskone 57, one of the largest science fiction conventions in the country, where he was guest of honor, Robinson described a genre full of futures to defy the Anthropocene. Stories where sacrifices are made, but in the end, we find ways to survive and become wise. I told him afterwards that it sounded like solarpunk, and he stage-whispered, ‚ÄúThat‚Äôs because it is.‚Äù&nbsp;</span></p>
<p><span>If we focus primarily on the genre‚Äôs textual artifacts ‚Äî including the discourses on the various social media platforms, but especially the genre fiction it produces ‚Äî solarpunk‚Äôs better qualities become unimpeachable. I have read all the major solarpunk anthologies that have come out in the last five years. To quote Sarena Ulibarri, editor of </span><i><span>Glass and Gardens: Solarpunk Summers</span></i><span> and newly out </span><i><span>Solarpunk Winters,</span></i><span> because she‚Äôs so damn quotable, ‚Äú[Solarpunk] stories depict adaptation and compromise rather than destruction and conquest‚Ä¶ empathy over greed.‚Äù They are an antidote for the toxin, yin to counteract the damage done by the big yang motorcycle trip, and I am a believer.</span></p>
<p><span>Yet after reading and enjoying these stories, I noticed a pattern. The viewpoint characters of solarpunk stories roughly fall into categories with similar confluences; Jo√™nia from Thomas Badlan‚Äôs ‚ÄúOrchidae‚Äù (in </span><i><span>Glass and Gardens: Solarpunk Winters,</span></i> <span>2020) is one among many intrepid scientists you will find in the genre, racing the clock to preserve life or help us adapt. Young makers, like Del the biotech tinkerer in D.K. Mok‚Äôs ‚ÄúThe Spider and the Stars,‚Äù and the community that comes together to ceremonially re-create the vanished Arctic in Andrew Dana Hudson‚Äôs ‚ÄúBlack Ice City‚Äù (both in </span><i><span>Solarpunk Summers,</span></i><span> 2018), are also well represented in solarpunk.&nbsp;&nbsp;</span></p>
<p><span>There‚Äôs some spillover from the makers into the anarchists. In T.X. Waston‚Äôs ‚ÄúThe Boston Hearth Project‚Äù (in </span><i><span>Sunvault</span></i><i><span>,</span></i><span> a 2017 anthology edited by Wagner and Wieland), these are people who thrive on the leftmost bleeding edge of society, breaking rules that should never have been in order to shelter the homeless. But many solarpunk characters ‚Äî and most salient to this conversation ‚Äî are young people, often women of color, adjusting to the dangers of the new normal brought on by severe environmental changes and doing so in ways their elders did not have the foresight or perspective to do themselves. Daesha in ‚ÄúFyrewall‚Äù by Stefani Cox </span><i><span>(Solarpunk Summers)</span></i><span> is one like this, gifted with responsibilities beyond her years when she must fix the wall protecting future Californians from raging wildfires. All these stories showcase new or repurposed material resources and technologies for increased sustainability.&nbsp;&nbsp;</span></p>
<p><span>Clearly these voices are necessary. But there‚Äôs something missing. The intersection with communities of faith is roped off.</span></p>
<p><b>Spirit in the Machine: The Missing Piece</b></p>
<p><span>The heroine of Butler‚Äôs </span><i><span>Parable of the Sower</span></i> <span>is</span> <span>Lauren Oya Olamina. She will be little more than a child before inevitable mayhem and metastasized, commodified suffering rolls up on her family, murders everyone, and destroys what is left of her community. She will escape with her life, but orphaned and traumatized. What is she to do?</span></p>
<p><span>Step one: Become a self-made messiah.</span></p>
<p><span>Step two: Reengineer God.</span></p>
<p><span>Step three: Save humanity.</span></p>
<p><span><span>Step four: Bong hits.</span></span></p>
<p><span>Hers is an incredibly powerful story. She very much fits the mold of solarpunk heroines with one exception: She‚Äôs a faith leader. Why aren‚Äôt there more characters like her? Where are the griots and santeras? Where are the bodhisattvas and the saints? Those who speak the languages of heaven‚Äôs heart? Where are the Lauren Oya Olaminas?</span></p>
<p><span>Her absence, given what she might represent, is understandable. Ideology (the dogmatic kind) has often been the death of free thinkers and first adopters. It has produced conservative paradigms that sustained brutal hierarchies, birthed unforgettable monsters, and poured bleach on other people‚Äôs history. But too often to ignore, the opposite has also been the case. Tibetan Buddhism and the Dalai Lama comes to mind. The Southern Christian Leadership Conference, the nonviolent Civil Rights Era organizing group whose goal was to redeem ‚Äúthe soul of America,‚Äù was not an aberration of history. Martin Luther King may have been a GOAT (Greatest Of All Time, for those without access to Urban Dictionary), but if time‚Äôs memory was more robust, his would not be the only spirit we commune with on special occasions.&nbsp;</span></p>
<p><span>So, whether it has been a purposeful or subconscious omission, this issue must be addressed for solarpunk to move beyond artists, and progressive secularists. We need to mainstream the radical.</span></p>
<p><b>The Intersection is Under Construction</b></p>
<p><span>There are three tenets of solarpunk orthodoxy that are relevant here. The first is that solarpunk is an overtly inclusive space. If it could be a real boy, anti-racism would be in its DNA. Keep that in mind when I tell you that the US Census <a href="https://www.brookings.edu/blog/the-avenue/2018/03/14/the-us-will-become-minority-white-in-2045-census-projects/%20">projects</a> that by the year 2045, the majority of US population will be people of color (already the case for residents under age eighteen) and the majority of us profess some kind of faith (itinerant Seon Buddhist right here).<br></span></p>
<p><span>In 2008, when last Pew Research asked the question, 95% of those surveyed reported belief in a higher power of some kind. Even among scientists, the believers were in the majority. Both numbers go up if you include the rest of the world, particularly the black and brown parts. So, for solarpunk to be properly inclusive of us in possible futures, it would be a mistake to blackbox significant guiding tenets because of an aversion to the dominant ideologies and the much-discussed potential for evil in organized religion. Evil is everywhere. Search for kittens on your favorite browser and scroll down for about thirty seconds. There be evil.&nbsp;</span></p>
</div>
</div><div>
    
<div>
    
<p><span>
  <img alt="Image" src="http://imaketheater.com/newmodality_x/wp-content/uploads/2019/09/mini_gradient_divider.png" width="69" height="6">
</span></p><blockquote>
    <div>
    <p><span>There is no greater or more fundamental technology than culture. It, and the ark of ideologies that arise from it, are more than just peer pressure from dead people. Culture is </span><i><span>software. </span></i><span>And more often than not, that includes a spiritual platform.</span></p>      </div>
  </blockquote>

<p><span>
  <img alt="Image" src="http://imaketheater.com/newmodality_x/wp-content/uploads/2019/09/mini_gradient_divider.png" width="69" height="6">
</span></p><div>
  <p><span>Claudie Arseneault, author of <i>Wings of Revival: A Solarpunk Dragon Anthology</i>, gives us the second tenet: ‚Äú[Solarpunk should work] from existing technologies, from things we already know are possible.‚Äù This is key. There is no greater or more fundamental technology than culture. It, and the ark of ideologies that arise from it, are more than just peer pressure from dead people. Culture is <i>software.</i> And more often than not, that includes a spiritual platform.</span></p>
<p><span>Now, a deep dive into the Pok√©mon competitions ‚Ä¶</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/">http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/</a></em></p>]]>
            </description>
            <link>http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24230502</guid>
            <pubDate>Fri, 21 Aug 2020 00:13:15 GMT</pubDate>
        </item>
    </channel>
</rss>
