<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 10]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 10. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 24 Dec 2020 12:50:42 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-10.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 24 Dec 2020 12:50:42 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[This Community is Available in the App]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25502828">thread link</a>) | @rukshn
<br/>
December 21, 2020 | https://ruky.me/2020/12/22/this-community-is-available-in-the-app/ | <a href="https://web.archive.org/web/*/https://ruky.me/2020/12/22/this-community-is-available-in-the-app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Yesterday’s <a href="https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/">post</a> was an awesome one, I learned a lot in JavaScript and and I was happy to see people doing what I thought impossible. Writing a simple todo app within 280 chars, in plain js.</p>
<p>After I finished writing the post, I wanted to share it on Reddit JavaScript community, r/javascript at the same time I shared it on HackerNews.</p>
<p>I have seen lot of comments on HackerNews criticizing the new Reddit design, using JavaScript and breaking in their mobile website, and constant nags pushing the users to their mobile app.</p>
<p>I was one of those few who liked their new design on desktop, no page loads between posting something, lot of white spaces, I feel most of the average users would be feeling the same, except for the tech community. But as a service Reddit should be looking at the common denominator, not the outliers.</p>
<p>I’m annoyed with the mobile app nag, when I visit the mobile website, Reddit is always asking me to download the mobile app. But I just cancel it and move along in the mobile browser.</p>
<p>But what happened yesterday just took me off the ledge. When I visited the r/javascript community on my iPad, I was greeted with this screen.</p>
<figure><img data-attachment-id="73" data-permalink="https://ruky.me/2020/12/22/this-community-is-available-in-the-app/img_0041/" data-orig-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=1536%2C2048&amp;ssl=1" data-orig-size="1536,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="img_0041" data-image-description="" data-medium-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?fit=768%2C1024&amp;ssl=1" loading="lazy" width="768" height="1024" src="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?w=1536&amp;ssl=1 1536w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?w=1536&amp;ssl=1 1536w" data-lazy-src="https://i0.wp.com/ruky.me/wp-content/uploads/2020/12/img_0041.png?resize=768%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>This community is only available in the app.</figcaption></figure>
<p>Why do you block me from from visiting the community from my mobile device?</p>
<p>Will the whole mobile website is scrapped and you end up with a landing page to download the mobile app?</p>
<p><strong>If you want to visit a popular subreddit</strong>, <strong>install our up and use it, or else login. </strong></p>
<p>I’ve managed to see the subreddit by requesting the desktop website, but I’m sure they will figure out a way, by checking the screen size to block this as well.</p>
<p>I understand that, as a company, you need to push to gain as much users as possible on their mobile devices, that’s the best way to track, to send notifications and keep you hooked and keep coming back. If I had a company like Reddit I might have done the same.</p>
<p>But for blocking users from their mobile devices, a service they once offered is a very dark pattern, instead what they should do is introduce some awesome features that will make the users download the app by themselves so they can enjoy those features. Not forcing the app though their throats.</p>
<p>Anyone else experienced a similar experience on Reddit mobile?</p>
<p><em>Only after writing the and checking the screenshot again made me see that they allow you to see the subreddit by logging in. But that is obscured and they intend to push users to download the app.</em></p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2020/12/22/this-community-is-available-in-the-app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502828</guid>
            <pubDate>Tue, 22 Dec 2020 04:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Blind Passwords a.k.a. Horcruxing]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25502703">thread link</a>) | @phantom_rehan
<br/>
December 21, 2020 | https://kaizoku.dev/double-blind-passwords-aka-horcruxing | <a href="https://web.archive.org/web/*/https://kaizoku.dev/double-blind-passwords-aka-horcruxing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1607775961422/elXIChWIZ.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Before we get into Horcruxing, here's a quick prologue on online security hygiene. You can skip to the  <a href="#double-blind-passwords-aka-horcruxing">Horcruxing section</a>  if it seems redundant.</p>
<h3 id="rules-for-strong-online-security">Rules for Strong Online Security</h3>
<p>1.
<strong>Longer passwords (atleast 16 characters) are better than shorter ones</strong></p>
<pre><code>=&gt; cutesamantha15101995 &gt; cutesamantha
</code></pre><p>2.
<strong>Randomized passwords are better than personally identifiable passwords</strong></p>
<pre><code>=&gt; process-cancel-stingy-garnet &gt; cutesamantha15101995
</code></pre><p><strong>NOTE: </strong> <code>process-cancel-stingy-garnet</code> is technically a passphrase - basically an easy-to-remember password in comparison to randomized strings like <code>B6fSpxMj&amp;f6DU@5^k</code></p>
<p>3.
<strong>Have a <em>significantly</em> different password for each account</strong></p>
<p>Having the same password for different accounts is like using the same key for different locks. It beats the whole point of having multiple locks! Also, having different passwords but with only one easily guessable word different (like the ones below) still poses the same risk. The passwords should be <strong><em>significantly</em></strong> different.</p>
<pre><code>bounce-unfold-stunning-chute        process-cancel-stingy-facebook
symptom-untouched-unpaid-arena  &gt;   process-cancel-stingy-twitter
sediment-tweak-annually-koala       process-cancel-stingy-gmail
</code></pre><p>4.
<strong>Use 2FA/MFA wherever possible</strong></p>
<p>Both Google and Facebook offer a 2FA feature where you need the second factor only when you login from a new device or a new location, instead of needing 2FA every time. That's a rare combination of convenience &amp; security right there! 
Most other sites also offer some variation of 2FA.</p>
<p><strong>NOTE</strong>: Use the  <a target="_blank" href="https://play.google.com/store/apps/details?id=org.shadowice.flocke.andotp">andOTP</a>  (or any other) app's TOTP as the second factor since it cannot be spoofed or spied on lock-screen like the SMS OTP and does not require a mobile network or internet connection. You can also use Biometrics (finger print or face recognition)</p>
<blockquote>
<p>Woah! How do I create a long password for each of the bazillion websites out there, <em>and</em> have them significantly different <em>and</em> remember them? Security seems like such a pain in the ass!</p>
</blockquote>
<h3 id="enter-password-manager">[enter] <strong>PASSWORD MANAGER</strong></h3>
<p>A password manager helps you manage all your passwords in one place, either in the form of a browser extension, mobile app, or website. Good password managers will offer a browser extension and a mobile app with one-click auto-fill-login-page feature by removing the hassle of copy pasting or typing your login details. A few smart ones even detect phishing pages and warn you indirectly, by not showing the login details for such web pages.</p>
<p>They enable all the above measures for strong online security with ease. While I agree it takes some effort to set it up for the very first time. But, after that, it just flows like butter. </p>
<p><br>
For example, password generator in <a target="_blank" href="https://bitwarden.com/">BitWarden</a> lets you custom design your random password in different flavours.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1607770748804/m93T3kqUH.png?auto=compress" alt="BitWarden's password generator"></p>
<h3 id="yay-im-secure">YAY! I'm Secure!</h3>
<p>You meticulously move all your passwords and secrets to a trusted password manager. Finally, you can rest easy knowing that your digital life is truly secure. Or, is it?  <br></p>
<p><strong>What if </strong></p><ul>
<li>your master password (the password to your password manager) is compromised due to a security breach or you left it in plaintext on a post-it/ email/ notes app</li>
<li>someone gained temporary access to your unlocked system (computer or phone) when you stepped away to get that last coffee for the day and your password manager is still logged in for everyone to see</li>
</ul>
<p>The answer: you're <strong><em>screwed</em></strong>. The cost of putting all your eggs in one basket is that it could all go into oblivion in one fell swoop. How do you overcome this challenge now? </p>
<h3 id="double-blind-passwords-aka-horcruxing">Double Blind Passwords (aka Horcruxing)</h3>
<p>For all his faults, Voldemort did one good thing for us muggles. He gave us the concept of a horcrux. For the uninitiated, a horcrux is any object in which you store a piece of your soul, putting the proverbial eggs of your soul into different baskets, to gain quasi-immortality. </p>
<p><strong>The basic idea</strong>: You split your password into 2 parts - one which is stored in the password manager, and the other which is stored in your head (aka horcrux).</p>
<p>Basically, at any given point in time, you and your password manager know only a piece of the password. It's double-blind. In effect, just like You-Know-Who, you're splitting your password (soul) into pieces and storing them in different places.</p>
<h4 id="before">BEFORE</h4>
<pre><code>
<span>username: rick</span>
<span>password: rollthepeople1732</span>


<span>username: rick</span>
<span>password: rollthepeople1732</span>
</code></pre><h4 id="after">AFTER</h4>
<pre><code>
<span>username: rick</span>
<span>password: roll-the-people-venus</span>


<span>horcrux: papel</span>


<span>username: rick</span>
<span>password: roll-the-people-venuspapel</span>
</code></pre><p>The horcrux adds an additional layer of security that only you can unlock. It's a kind of 2FA. Again, the longer the horcrux the better. But, a simple word should also be fine as long as only you know the horcrux.</p>
<p>If it feels like too much effort, use a horcrux only for the most important logins - your social media, bank accounts etc. </p>
<h3 id="one-last-thing">One Last Thing</h3>
<p>Security is never absolute. One can try to secure a system as tightly as possible, but never really say that it is fully secure (if you see someone claiming otherwise, it's mostly marketing bullshit). If we cannot make systems completely secure, the next best thing to do is to make them as secure as possible and a good way to do it is <a target="_blank" href="https://en.wikipedia.org/wiki/Defense_in_depth_(computing">Defense In Depth</a> - basically make sure that even if one layer of security is breached, there exist other layers to mitigate further damage - which is what we've tried to achieve all along.</p>
<h3 id="summary">Summary</h3>
<p>1.
Use a good password manager </p>
<blockquote>
<p>I use BitWarden (since it is open source and costs just $10 a year for the PRO features)</p>
</blockquote>
<p>2.
Use TOTP/ biometrics instead of SMS-based OTP</p>
<blockquote>
<p>I use andOTP (since it is open source)</p>
</blockquote>
<p>3.
Use a horcrux (a double-blind password) for the most important logins</p>

<p>P.S. Keep in mind that horcruxing only works fine until you connect your brain to NeuraLink and accidentally upload your thoughts online for everyone to see. :P</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://kaizoku.dev/double-blind-passwords-aka-horcruxing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502703</guid>
            <pubDate>Tue, 22 Dec 2020 03:58:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconventional Warfare in Mexico: The US Trained Some of Its Most Brutal Cartels]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25502435">thread link</a>) | @AndrewBissell
<br/>
December 21, 2020 | https://narco.news/unconventional-warfare-in-mexico | <a href="https://web.archive.org/web/*/https://narco.news/unconventional-warfare-in-mexico">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-120a3898=""><div data-v-120a3898=""><p><a href="https://fas.org/irp/doddir/dod/jp1_02.pdf">Unconventional Warfare</a> (UW): Activities conducted to enable a resistance movement or insurgency to coerce, disrupt, or overthrow a government or occupying power by operating through or with an underground, auxiliary, and guerrilla force in a denied area.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-20-at-5.49.19-PM.png" width="1000" height="888"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-20-at-5.49.29-PM.png" width="1000" height="888"></p></div></div><figcaption>Unconventional Warfare associated terminology <a href="https://www.soc.mil/ARIS/books/pdf/Unconventional%20Warfare%20Pocket%20Guide_v1%200_Final_6%20April%202016.pdf">Special Operations Command</a></figcaption></figure><hr><p><em>Los Zetas</em> were the highly-trained enforcers of the Gulf cartel made up of supposed deserters from the Mexican special forces known as the <em>Grupo AeromÃ³vil de Fuerzas Especiales </em>(GAFE). The GAFES<em> </em>were formed in 1986 as an elite quick reaction force specializing in counterinsurgency and unconventional warfare. When the North American Free Trade Agreement went into effect in 1994, the GAFES received combat experience in the brutal fight with the leftist <em>EjÃ©rcito Zapatista de LiberaciÃ³n Nacional</em> (EZLN) in Chiapas. According to <a href="http://historic.edualter.org/material/ddhh/proc1.htm">reporting by Carlos Marin</a>, the army sent the GAFES to Chiapas to <strong>create paramilitaries and displace the population</strong> in order to break the support of the people for the EZLN, an approach which would be used against organized crime years later. In Ioan Grillo's book <em>El Narco</em>, he describes how the mutilated bodies of rebels captured by the GAFES were dumped along a riverbank in the Las Margaritas municipality with their ears and noses sliced off, the sort of spectacular violence that <em>Los Zetas</em> would later standardize in the Drug War.</p><figure><img src="https://publish.narco.news/content/images/2020/10/Screen-Shot-2020-10-26-at-5.09.07-PM-1.png"><figcaption>2005 FBI memo about <em>Los Zetas</em></figcaption></figure><p>Some of the original members of <em>Los Zetas</em> are said to have been <a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB499/DOCUMENT01-20050422.PDF">trained by the U.S.</a> at the notorious School of the Americas, although accounts vary about exactly who, where and when. Some say it was at <a href="https://www.kold.com/story/3394374/los-zetas-draw-concern-of-us-government/">Ft. Benning</a> in Georgia, others at <a href="https://www.aljazeera.com/features/2010/11/03/us-trained-cartel-terrorises-mexico/">Ft. Bragg</a> in North Carolina, while other rumors suggest it was at <a href="https://www.army.mil/article/63245/army_north_hosts_mexican_army_leaders_to_strengthen_relationships">Ft. Hood</a> in Texas. According to Lt. Col. Craig Deare (retired), the former Academic Dean at the intellectual center of gravity of U.S. defense policy in Latin America since 1997, the Center for Hemispheric Defense Studies (CHDS), it was likely that more than 500 Mexican GAFES received training from U.S. special operations forces (SOF).</p><p>According to <a href="https://www.aljazeera.com/features/2010/11/03/us-trained-cartel-terrorises-mexico/">reporting</a> in Al Jazeera:</p><p><em>Some of the cartelâ€™s initial members were elite Mexican troops, trained in the early 1990s by Americaâ€™s 7th Special Forces Group or â€œsnake eatersâ€� at Ft. Bragg, North Carolina, a former US special operations commander has told Al Jazeera.</em></p><p><em>â€œThey were given map reading courses, communications, standard special forces training, light to heavy weapons, machine guns and automatic weapons,â€� says Craig Deare, the former special forces commander who is now a professor at the US National Defence University.</em></p><p><em>â€œI had some visibility on what was happening, because this [issue] was related to things I was doing in the Pentagon in the 1990s,â€� Deare, who also served as [Mexico] director in the office of the US Secretary of Defence, says.</em></p><p>The <a href="https://en.wikipedia.org/wiki/7th_Special_Forces_Group_(United_States)">7th Special Forces Group</a> (SFG) specializes in the approach the U.S. has taken with Latin America since the end of the second world war: unconventional warfare, counterinsurgency and, more recently, counterterrorism. During the Reagan administration in the 1980s, the 7th SFG trained, supported and fought with some of the most brutal and repressive special operations and unconventional forces in El Salvador, Guatemala, Honduras, Panama, Colombia, Peru, Bolivia and Venezuela.</p><figure><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.45.27-PM.png"><figcaption>A U.S. special forces Soldier assigned to 7th SF Group, oversees a group of Guatemalan Special Forces "Kaibils" conduct pistol marksmanship training Jan. 28 in Poptun, Guatemala (<a href="https://www.dvidshub.net/image/1749645/kaibil-us-special-forces-promote-security-through-partnership">DVIDS</a>)</figcaption></figure><p>Between 1996 and 1999, <a href="https://www.jornada.com.mx/1998/08/16/mexico.html">3,200 soldiers</a>, including at least 500 GAFES, were reportedly trained by the 7th SFG in the U.S. to create elite "counternarcotics" forces for fighting on behalf of the post-Cold War U.S. national security agenda.</p><p>Conveniently framed as an ironic consequence of the corrupting influence of the cartels, the training from the U.S. special forces diffused into the service of one of Mexico's oldest drug trafficking organizations. In 1997, the same year that the Center for Hemispheric Defense Studies was founded, Arturo GuzmÃ¡n Decena, a GAFE later known by the alias "<a href="https://en.wikipedia.org/wiki/Arturo_Guzm%C3%A1n_Decena">El Zeta-uno</a>", supposedly defected along with other elite Mexican soldiers to work for the Gulf cartel in Tamaulipas. The GAFES trained by the U.S. in counterinsurgency and unconventional warfare to fight drug-trafficking would become one of the most infamous drug-trafficking organizations in Mexico: Los Zetas.</p><p>The School of the Americas changed the way that organized crime operates in Mexico. <em>Los Zetas</em> application of advanced training in insurgency and terror justified President Felipe CalderÃ³n's (2006-2012) decision to <a href="https://www.chicagotribune.com/hoy/ct-hoy-8766718-la-guerra-contra-el-narco-en-mexico-costosa-cara-y-mortal-story.html">deploy the military</a> to prosecute the War against Drug-trafficking in his first month in office. The consequences of that decision have been devastating for Mexico.</p><figure><img src="https://publish.narco.news/content/images/2020/10/Screen-Shot-2020-10-19-at-2.08.25-PM-5.png"><figcaption>INEGI</figcaption></figure><p>According to a <a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB445/docs/20090700ca.PDF">2009 DEA memo</a>, Los Zetas also recruited other U.S.-trained SOF in Latin America, like the Kaibiles. The Kaibiles and other Guatemalan security forces were trained by the U.S. in counterinsurgency and unconventional warfare before, during and after Guatemala's 36-year <a href="https://www.nytimes.com/1999/02/26/world/guatemalan-army-waged-genocide-new-report-finds.html">genocide</a>. After a 1999 report commissioned by the United Nations determined that the 200,000+ people killed and disappeared by the Guatemalan Army was, <a href="https://www.nytimes.com/1999/02/26/world/guatemalan-army-waged-genocide-new-report-finds.html">in fact, genocide</a>, the School of the Americas briefly closed before opening a year later as the Western Hemisphere Institute for Security Cooperation (WHINSEC). According to <a href="https://www.sfgate.com/default/article/Bay-Area-protesters-sentenced-in-Georgia-Jail-2796779.php">testimony</a> from Major Joseph Blair, a former instructor at the school, the changes were only superficial and an identical curriculum was taught from the exact same instruction manuals. Between 1999 and 2010, <a href="http://www.ghrc-usa.org/Publications/factsheet_kaibiles.pdf">3,555 Guatemalan soldiers</a>, many of them Kaibiles, were trained by the U.S. through WHINSEC and other programs.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.58.27-PM.png" width="1256" height="712"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-10.11.53-AM.png" width="1462" height="944"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-10.11.36-AM.png" width="1462" height="944"></p></div></div><figcaption><a href="https://www.nytimes.com/1999/02/26/world/guatemalan-army-waged-genocide-new-report-finds.html">New York Times</a>; <a href="https://www.aaas.org/sites/default/files/s3fs-public/mos_en.pdf">CEH</a>;</figcaption></figure><p>The Kaibiles are taught to kill without mercy or thought. In training, recruits are given a puppy to look after and bond with for several weeks before being ordered to kill the animal with their bare hands, drink the blood and eat the raw flesh, a method which <a href="https://www.voltairenet.org/Los-Kaibiles-mexicanos">reportedly</a> has since diffused to the Mexican GAFES and other forces that train with the Kaibiles. Like the "snake eaters" of the U.S. 7th SFG, the Kaibiles kill to eat and live to kill. Their motto is: "<em>Si avanzo, sÃ­gueme. Si me detengo, aprÃ©miame. Si retrocedo, mÃ¡tame!</em> / <em>If I advance, follow me. If I stop, urge me on. If I retreat, kill me!"</em></p><figure><div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-23-at-2.12.06-PM-1.png" width="1256" height="946"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-23-at-2.23.00-PM.png" width="1222" height="776"></p></div></div><figcaption>Participant in the Dos Erres massacre and former School of the Americas Instructor Pedro Pimental Rios (<a href="https://www.ocweekly.com/pedro-pimentel-rios-accused-in-guatemalan-massacre-to-be-deported-6479330/">OC Weekly</a>; <a href="https://www.ice.gov/news/releases/ice-removes-former-member-guatemalan-army-linked-1980s-massacre">ICE</a>)</figcaption></figure><p>In 1982, the Kaibiles massacred 226 people in the Dos Erres village in Guatemala. According to the <a href="https://www.aaas.org/sites/default/files/s3fs-public/mos_en.pdf">United Nations Truth Commission Clarification</a> and reporting by <a href="https://www.propublica.org/article/finding-oscar-massacre-memory-and-justice-in-guatemala">ProPublica</a>, they arrived in the middle of the night and accused the residents of being guerrilla sympathizers. The smallest children were killed by smashing their heads against trees and the sides of buildings, while older children were killed with a hammer. Adults were interrogated and tortured, one by one, and the women were raped by the Kaibiles. The Kaibiles also cut fetuses out of pregnant women. After the interrogation, the adults were also killed with a hammer and the corpses were dumped in a well. A few years after the massacre, one of the Kaibil officers who had supervised the atrocity, Pedro Pimental Rios, became an instructor at the School of the Americas. He was extradited from the U.S. in 2012 and sentenced to more than 6,000 years in prison for his involvement.</p><p>According to a declassified <a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB32/docs/doc42.pdf">Defense Intelligence Agency (DIA) memo</a> from 1994, intelligence sources described clandestine graves outside of a Guatemalan military facility. The memo described Guatemalan soldiers flying captives over the ocean before pushing them out of helicopters to their deaths, a technique also used in <a href="https://www.nytimes.com/1995/03/13/world/argentine-tells-of-dumping-dirty-war-captives-into-sea.html">Argentina</a>. In 2015, former Chilean military officer Jaime Garcia Covarrubias was <a href="https://www.mcclatchydc.com/news/nation-world/national/national-security/article24781345.html">arrested</a> for torturing and executing seven people in 1973. He had been a faculty member at the Center for Hemispheric Defense Studies for 13 years.</p><figure><div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.09.33-PM.png" width="1100" height="1436"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.10.15-PM-1.png" width="1100" height="1436"></p></div><div><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-2.10.38-PM.png" width="1100" height="1436"></p><p><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-23-at-2.29.05-PM.png" width="1238" height="740"></p></div></div><figcaption><a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB32/docs/doc42.pdf">National Security Archive</a>; <a href="https://www.nytimes.com/1995/03/13/world/argentine-tells-of-dumping-dirty-war-captives-into-sea.html">New York Times</a></figcaption></figure><p>After the end of the Cold War, the Kaibiles were <a href="https://www.aljazeera.com/features/2011/8/15/guatemalas-feared-special-forces">repurposed</a> to fight the United States' new greatest threat to national security: drugs. From 2007 to 2014, U.S. SOF training <a href="https://www.wola.org/analysis/u-s-special-operations-latin-america-parallel-diplomacy/">tripled</a> in Latin America, mostly in the area of responsibility (AOR) of U.S. Department of Defense's Southern Command (SOUTHCOM) in the Caribbean, Central and South America. The U.S. military continues training the Kaibiles to this day. </p><figure><img src="https://publish.narco.news/content/images/2020/12/Screen-Shot-2020-12-21-at-1.03.23-PM.png"><figcaption>U.S. soldiers training with the Kaibiles in Information Operations, July 2019 (<a href="https://www.dvidshub.net/image/5602004/us-soldiers-trek-through-jungles-with-guatemalan-special-forces">DVIDS</a>)</figcaption></figure><hr><p>While the Mexican military was fighting a war nominally against violent drug-trafficking organizations like <em>Los Zetas</em>, the U.S. military was developing and spreading a new doctrine for waging a new regional war on terror in Latin America. A <a href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a475840.pdf">2007 academic paper</a> outlined a new <strong>distributed operational model</strong> for command and control (C2) for Special Operations Command in the U.S. SOUTHCOM AOR based on the approach of the U.S. Marine Corps (USMC). The authors recognized the USMC approach as, "better suited for counterinsurgency and non-combat environments, where the objectives are more ambivalent." According to the authors:</p><p><em>In standard military maneuver operations where missions such as â€œattack that position,â€� are clearly defined, the [conventional] definition of C2 is sufficient. However, in an ambiguous environment where SOF often operates, the mission (e.g., plan and execute UW [Unconventional Warfare]) is not as clearly defined. As a result, a special operator in the field must be able to operate with maximum authority, flexibility, and agility to respond to immediate changes emerging from dynamic situations. The USMC definition reflects precisely how SOCSOUTHâ€™s staff currently approaches C2 in its theater of operations.</em></p><p>Officers from the Colombian military studying at the <strong>United State Marine Corps Command and Staff College</strong> at the Marine Corps University quickly recognized the advantages of the U.S. approach. According to a <a href="https://apps.dtic.mil/dtic/tr/fulltext/u2/a491149.pdf">2008 academic paper</a>…</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://narco.news/unconventional-warfare-in-mexico">https://narco.news/unconventional-warfare-in-mexico</a></em></p>]]>
            </description>
            <link>https://narco.news/unconventional-warfare-in-mexico</link>
            <guid isPermaLink="false">hacker-news-small-sites-25502435</guid>
            <pubDate>Tue, 22 Dec 2020 03:11:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Engineering Axioms]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25500815">thread link</a>) | @mnouquet
<br/>
December 21, 2020 | https://martinrue.com/my-engineering-axioms/ | <a href="https://web.archive.org/web/*/https://martinrue.com/my-engineering-axioms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <h3>My Engineering Axioms</h3>

            <p>A few months back I gave a talk in which I shared a list of my personal engineering axioms – things that, over the years, I've come to think of as generally true and useful to have in mind when writing code, building things, and working with others.</p>

            <p>Axiom is a fancy word, but popping a few layers off the etymology stack we arrive neatly at the ancient Greek word <a href="https://en.wiktionary.org/wiki/%E1%BC%80%CE%BE%CE%AF%CF%89%CE%BC%CE%B1">ἀξίωμα</a>, or "that which is thought fit or worthy". I like that, and consider each item on the list at least worthy of consideration.</p>

            <p>Of course they're <b>my</b> engineering axioms – things I believe to be useful based on my own experience. Your experience may well differ. Maybe you already knew about <a href="https://martinrue.com/zzuy-a-lesson-in-perseverance/">zero termination</a>, or have better tools than <a href="https://martinrue.com/give-yourself-more-playtime/">scissors to remove bugs</a> from your programs.</p>

            <p>In any case, I thought it would be fun to share the list here, with a few brief clarifications. Some things are pretty unsurprising, but hopefully others will generate some provocative thoughts and/or interesting disagreements.</p>

            <h4>1. Change is constant.</h4>

            <p>This one shouldn't be too controversial. Almost everything is always changing, including the rate of change itself. We need to acknowledge not only that our ability to respond to change is crucial, but that how well we do it (time, cost, quality, reliability) is often a dimension of our competitiveness.</p>

            <h4>2. Your product is an asset, but code is a liability.</h4>

            <p>Your product solves your customer's problem(s), and therefore is your asset. The code itself is the cost of creating the asset. The more code you have, the more it needs to be read, tested, changed, and understood. This is especially relevant when you consider axiom 1. Accept new code (and dependency on external code) conservatively. The best code is code you don't have to write.</p>

            <h4>3. Duplication is less costly than premature abstraction.</h4>

            <p>Until you have a high degree of confidence that your abstraction is going to pay for itself because it solves a real, abstract problem you really do have, don't do it. Wait and learn more. Until then, repeating code can help avoid dependency, which itself makes the code easier to change independently or delete. A premature abstraction creates complexity through dependency and indirection, and can become a bottleneck to your ability to respond to change.</p>

            <h4>4. Code should be easy to delete.</h4>

            <p>Write code to be removable, which in large part is the same as saying "decoupled". For sure not all code needs to be similarly removable, but minimising dependencies, having clear boundaries via well-defined interfaces, and having a thoughtful overall system design allows parts to be removed/changed more easily. I once heard someone use the expression "code spent", as an alternative to "code written" and I love that. I like the implication that removing code is reducing future cost.</p>

            <h4>5. Existing code exerts a powerful influence.</h4>

            <p>The very fact it's there suggests it's correct and necessary. Hopefully it is, but not always. We need to maintain both the confidence to change it, and the ability to reason about whether we should. Don't let the existence of code itself create doubt that it can't be removed. As per axiom 4, it should be easy to remove, and the system design should be good enough to enable us to understand whether we still need it.</p>

            <h4>6. Accidental complexity is one of the biggest risks.</h4>

            <p>Accidental complexity is complexity that can be avoided, and occurs due to things like poor design, bad decisions, and not prioritising an appropriate level of simplicity within a system. If simplicity is not a goal, accidental complexity is more likely to occur as a system grows, and will gradually negatively affect almost everything from changing the system to even being able to understand it. The 2006 paper <a href="http://curtclifton.net/papers/MoseleyMarks06a.pdf">Out of the Tar Pit</a> is a worthwhile read on this subject.</p>

            <h4>7. Technical excellence can be shadowed by bad personal skills.</h4>

            <p>Unless you're working completely alone, it's not just your ability to solve technical problems, to write good code, etc, that matters. To the contrary, they matter even less if you make the people around you unhappy and less productive. Just like learning to write good code, you have to learn "to people" good as well. Empathy is a big part of this, as is recognising that people are different – be caring, be understanding, help others and ask for help yourself, be nice. Be an engineer others want to work with.</p>

            <h4>8. You are not your code. Be kind to the coder, not to the code.</h4>

            <p>Code is merely a moment in time that captured what we thought we knew about something. It's not you. You may have wrote it, but since that moment (even if it was 3 minutes ago) you've grown, but the code has not. A conversation about code, good or bad, should never be personal. Keep it professional. Talk about the code, or about the problem, but don't make it about the person who wrote it. Use "we" instead of "you". Sometimes I try to pretend I wrote the code someone else wrote, which helps me avoid accidentally sounding personal.</p>

            <h4>9. Treat people who know less than you with respect and patience.</h4>

            <p>We all start somewhere, and the journey is a lot more joyful when you're surrounded by patient people who want you to succeed, rather than those who make you feel like you don't belong. If you struggle with this, it may be helpful to remember that the newbie programmer almost certainly does something better than you do – perhaps they're fluent in another language, or cook amazingly, or play a sport. Just imagine yourself in the reverse role. How would you like them to treat you, the total newbie? Again: be an engineer others want to work with.</p>

            <h4>10. The only true authority stems from knowledge, not from position.</h4>

            <p>Knowledge and understanding of the problem, the domain, the customer, are all far more important than whatever the first 3 letters on your business card are. <a href="https://youtu.be/cISYzA36-ZY?t=85">Even if it does have a watermark</a>. Understand how something works from first principles, build a solid understanding, and authority will follow.</p>

            <h4>11. Teaching is a form of learning in disguise.</h4>

            <p>If you think you know something, try teaching it. Often the very act of trying to explain what you know to someone else forces you to formalise your own thoughts much more clearly. Writing things down seems to have a similar effect. I've lost count of the number of times I've begun explaining something only to find I don't quite understand it as well as I thought.</p>

            <h4>12. Lift the skills of people around you, not just yourself.</h4>

            <p>A great team is never a great because of one amazing person. It's a great team because everyone challenges each other and everybody grows together. When you learn something cool, share it – help the people around you get better. As they do the same, everybody benefits and nobody gets left behind. It's also far more fun. Secondary benefit: axiom 11.</p>

            <h4>13. The longer you wait the more you'll know.</h4>

            <p>I'm still learning this and trying hard to avoid my almost default desire to decide quickly. The truth is, the longer you delay non-essential decisions the more information you'll have to lean on when the time comes to make it. Of course you can't always procrastinate a decision, but often you can, and as a minimum you should at least consider whether not knowing the answer right now is actually OK.</p>

            <h4>14. A good type system is worth its weight plus some.</h4>

            <p>Having gone backwards and forwards through various static and dynamic languages over my career, I'm currently of the opinion that a good type system is worth its overhead. A good type system shouldn't carry all that much overhead. If the type system is designed well, it can almost feel like a dynamic language (via features like inference and flow analysis) while removing a whole class of issues that the compiler can handle far better and quicker than you can. Developments like ownership in Rust are a nice example of how this has gone even further than people would have imagined years back.</p>

            <h4>15. The right team of people trumps everything else.</h4>

            <p>Having a team of people who just want to work together and build great things makes a lot of other problems easier to deal with. The word "right" here is highly subjective and contextual, but at least anecdotally, empathy, respect, and friendship have been recurring elements of great teams I've been part of.</p>

            <h4>16. Stick to boring technology, unless there's a good reason not to.</h4>

            <p>Boring tech is often older and better understood. There's battle-hardened experience of how to use it effectively, better understanding of its failure modes, and it's easier to find people and resources on how to best apply it. I really like Dan McKinley's idea of <a href="https://mcfunley.com/choose-boring-technology">innovation tokens</a>. You only get 3. Use them to adopt or build brand new stuff – ideally stuff that will make you better at your core competency – but any more than 3 and the risk of never reaching stability/maturity starts to grow.</p>

            <h4>17. Have the smallest team possible, but no smaller. Grow it carefully.</h4>

            <p>A play on a well-known quote, and your mileage may vary on this one. In my career so far, I've reliably seen smaller teams be more effective than larger ones. There's a balance to be found, for sure, which depends on the magnitude and complexity of the problem you're solving. That said, smaller teams benefit from less communication overhead, less room for miscommunication, and more space for everyone's voice to be heard. In a smaller team, it also feels more personal, and I feel more responsible, and I like that.</p>

            <h4>18. Rest.</h4>

            <p>I'm happy to see the gradual de-sexification of …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://martinrue.com/my-engineering-axioms/">https://martinrue.com/my-engineering-axioms/</a></em></p>]]>
            </description>
            <link>https://martinrue.com/my-engineering-axioms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500815</guid>
            <pubDate>Mon, 21 Dec 2020 23:08:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write code. Not too much. Mostly functions.]]>
            </title>
            <description>
<![CDATA[
Score 619 | Comments 260 (<a href="https://news.ycombinator.com/item?id=25500671">thread link</a>) | @brundolf
<br/>
December 21, 2020 | https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>There's a well-known quote by author <a href="https://en.wikipedia.org/wiki/Michael_Pollan">Michael Pollan</a>:
        "Eat food. Not too much. Mostly plants." I like it because it doesn't
        attempt to be dogmatic: it encapsulates some basic guiding principles that get
        you 90% of the way there 90% of the time. Wikipedia describes the book the quote
        is from (emphasis mine):</p>
      <blockquote>
        <p>He explains...the notion that nutritionism and, therefore, the whole Western
          framework through which we intellectualize the value of food <strong>is more a religious
and faddish devotion to the mythology of simple solutions than a convincing and
reliable conclusion of incontrovertible scientific research</strong>.</p>
      </blockquote>
      <p>That...sounds familiar.</p>
      <h2 id="write-code">Write code </h2>
      <p>Code, like food, has value. I think those of us who write it can (hopefully)
        agree on that. Some, though, are so afraid of writing/eating
        <em>too much</em> that they avoid writing/eating what they should.</p>
      <p>In the context of programming, I think this translates to an unhealthy fear
        (again, for some) of duplication. A little bit of duplication - writing
        something in a way that doesn't completely maximize conciseness - isn't the end
        of the world. Sometimes it's the best path forward. Sometimes it's okay to
        copy-and-modify here and there, especially when you're still figuring out what
        your application will end up being.</p>
      <h2 id="not-too-much">Not too much </h2>
      <p>Of course too much code, like too much food, can also be a bad thing. This is
        a well-trodden topic so I don't feel the need to go too far into it here.</p>
      <p>Just be aware of your project's "appetite": write what needs to be written,
        and then try not to over-indulge.</p>
      <h2 id="mostly-functions">Mostly functions </h2>
      <p>By "functions" here I mean "pure functions". You could make a case that pure
        functions aren't the "plants" of code, though I feel
        that they are. In my experience most codebases have a pure functional
        subset, and I believe writing that subset in a pure-functional style is nearly
        always a win for the long-term health of the project.</p>
      <p>Of course the qualifier is "mostly": this isn't a dogma. Writing a 100%
        functional system ("going vegan", if you will) often requires you to jump
        through a bunch of extra hoops to get all the functionality you need. Looking
        at it solely from the perspective of health, those extra complications may not
        be worth it.</p>
      <p>And then different projects have different needs: just as an athlete may need
        a larger percentage of protein, or individuals may have certain nutrient
        deficiencies, a project may only have a very small functional subset, or may not
        be able to afford to return new values each time due to data size or
        performance-sensitivity. There's nothing wrong with that.</p>
      <h2 id="%22real-code%22">"Real code" </h2>
      <p>Pollan later qualifies his snappy statement a bit further:</p>
      <blockquote>
        <p>He contends that most of what Americans now buy in supermarkets, fast food
          stores, and restaurants is not in fact food, and that a practical tip is to eat
          only those things that people of his grandmother's generation would have
          recognized as food.</p>
      </blockquote>
      <p>At the risk of stretching the analogy, maybe the equivalent is
        "code only those things that people at a junior level would recognize for what
        they do". Code in simple, straightforward terms. Don't get too clever,
        "manufacturing artificial ingredients". Use the primitives that are there, when
        possible. Write what is simple, and natural, and human.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500671</guid>
            <pubDate>Mon, 21 Dec 2020 22:53:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuck Amazon Vine]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25500255">thread link</a>) | @fivedogit
<br/>
December 21, 2020 | https://thingamagig.com/vine/WhyAmazonVineSucks.html?x=3 | <a href="https://web.archive.org/web/*/https://thingamagig.com/vine/WhyAmazonVineSucks.html?x=3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thingamagig.com/vine/WhyAmazonVineSucks.html?x=3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25500255</guid>
            <pubDate>Mon, 21 Dec 2020 22:13:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Be a 10x Developer]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25498696">thread link</a>) | @mooreds
<br/>
December 21, 2020 | https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/ | <a href="https://web.archive.org/web/*/https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><span><span>Reading Time: </span> <span>13</span> <span>minutes</span></span></p><p>It’s not a clickbait title, but I understand why it looks that way.</p>



<p>I’ve made my thoughts about the 10x developer trope <a href="https://chelseatroy.com/2019/12/06/listening-7-deliberate-appreciation/">extremely clear</a>. I think that someone who produces 10x as much code as someone else has left a wake of destruction that will slow down other developers. I don’t think 10x counts if you achieve it by slowing down everyone else. I think 10x has to take into account how you impact other people.</p>



<p>And <em>that,</em> paradoxically, suggests a path for how to become a 10x developer: empower and enable other people such that nine additional developers’ worth of work gets done. You can do that by making nine other developers’ workflows 2x smoother. You can also do that by making 18 other developers’ workflows 50% smoother, or 90 other developers’ workflows 10% smoother.</p>



<div><figure><a href="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?ssl=1"><img data-attachment-id="8295" data-permalink="https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/screen-shot-2020-12-18-at-12-53-49-am/" data-orig-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?fit=1200%2C1202&amp;ssl=1" data-orig-size="1200,1202" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2020-12-18 at 12.53.49 AM" data-image-description="" data-medium-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?fit=723%2C724&amp;ssl=1" loading="lazy" src="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=310%2C310&amp;ssl=1" alt="owl holding a red leaf in its beak" width="310" height="310" srcset="https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?w=1200&amp;ssl=1 1200w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=1022%2C1024&amp;ssl=1 1022w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=768%2C769&amp;ssl=1 768w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=450%2C450&amp;ssl=1 450w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=60%2C60&amp;ssl=1 60w, https://i0.wp.com/chelseatroy.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-18-at-12.53.49-AM.png?resize=550%2C550&amp;ssl=1 550w" sizes="(max-width: 310px) 100vw, 310px" data-recalc-dims="1"></a><figcaption>PC @templephotobetsy on Instagram</figcaption></figure></div>



<p>At some point, your biggest gains in your X are gonna be in improving the ecosystem for other developers. On occasions when I have succeeded at that, from <a href="https://chelseatroy.com/2018/02/25/how-to-socialize-big-changes-at-work-part-1-start-at-the-grassroots-level/">driving workplace changes</a> to <a href="https://chelseatroy.com/category/teaching/">teaching computer science classes</a>, I have noticed that I’m using one or more of three techniques. So I thought I’d list them here.</p>



<h3>First, establish the motivation.</h3>



<p>Learning is work. Sometimes, it’s boring or difficult work. Folks don’t undertake that kind of work unless they understand why they should. That’s not as simple as <em>telling</em> them why. Understanding comes from engaging with the material.</p>



<p>Suppose you want to make a major code change that affects your team’s workflow. If you blaze forward and do that without buy-in, the team will resent it (<a href="https://chelseatroy.com/2018/02/25/how-to-socialize-big-changes-at-work-part-1-start-at-the-grassroots-level/">as we’ve discussed in more detail here</a>). So I recommend starting with individual conversations about the reasons for the change:</p>



<blockquote><p><span>What is bothering you about your team’s current workflow that motivates you to push your solution? Are you annoyed at having to write the same code over and over in different places? Are you tired of trying to poke your way around an opaque tool? Are you losing track of things that cost you time and money? Before you&nbsp;</span><em>push</em><span>&nbsp;your solution,&nbsp;</span><em>pull</em><span>&nbsp;your coworkers to it by making sure they feel the pain that you feel.</span></p><p>Before I do a major refactor, I’ll deliberately pair program with key people on my team on the kind of problems that my refactor would solve. I want them to experience the pain firsthand; I want to hear them say ‘oh my&nbsp;<em>god&nbsp;</em>this is annoying.’ After I have that admission of pain from a critical mass of people on my team, I’ll propose my solution, and I’ll offer to spearhead the refactor. I will craft a concise explanation of how our workflow changes after the refactor, and I’ll point out why I think the new way is nicer for us than the way we’re doing it now.&nbsp;&nbsp;I have ‘negative testimonials’ about the old way, which I can whip out to capture the attention and agreement of others on my team. This approach allows me to muster support for my refactor and then, in spearheading the refactor, look like I’m taking one for the team.</p><p>Imagine the same scenario, same refactor, but instead of socializing my solution, I go off on my own, do the refactor, and push. My team didn’t understand the pain that the refactor solved, so all they’re seeing is the pain of learning the&nbsp;<em>new</em>&nbsp;way to do things. To them, it looks like I made a unilateral decision that screwed them over—the&nbsp;<em>opposite</em>&nbsp;of what a team player would do. Keep in mind, in both circumstances, I wrote the&nbsp;<em>same code</em>. The only difference is how I introduced it.</p></blockquote>



<p>In effect, even the right code changes need to be <em>sold</em>. </p>



<p>How do we know what the right code changes are? This one is tricky, but one guiding principle has helped me out a lot:</p>



<h3>Look for bonehead solutions to convoluted technical issues.</h3>



<p>Michael Feathers talks a great deal about technical simplification options in his various discussions on edge-free programming (<a href="https://chelseatroy.com/2020/05/28/lessons-from-space-edge-free-programming/">here’s a more detailed look at some of those principles)</a>. But for exemplary purposes, here are a few simple solutions to complex problems that I’m especially proud of:</p>



<ul><li>I solved a thorny issue with a sometimes camouflaged, sometimes unreliable delete button by ripping it out (<a href="https://github.com/zooniverse/mobile/pull/345">Here’s the PR if you want more details</a>)</li><li>I resolved the issue of a laggy metronome in React-Native, where computationally expensive operations can result in delays for scheduled tasks. The app happened to also need to play back tracks at various multiples of their original speed. So I recorded a sound file of a metronome at 120 BPM, calculated what speed to play it by dividing the BPM the musician requested by 120, and wrote one method that shelled out to <code>expo-av</code> to play accurate-to-tempo sound files for both the metronome and the backtracks.</li><li>I resolved an issue of regulating how often a person should be allowed to log their mood by realizing the issue was fake (assumed foil to “let’s make sure they log it at least this often”) and letting them log as often as they want (<a href="https://chelseatroy.com/2020/05/28/lessons-from-space-edge-free-programming/">more details here</a>).</li></ul>



<p>Each of these solutions made the code cleaner and eliminated<em> </em>multiple problems with the product. But they were not genius solutions. In fact, they were easy to miss precisely because complex problems don’t scream “I have a bonehead solution.”</p>


	
	


<p><strong>One drawback: </strong>the tech industry generally rewards churning out tons of code <em>over</em> elegant solutions. Chen Lin recently <a href="https://twitter.com/votecapgood/status/1337920511095918592">tweeted about</a> his experience with this at Uber. Chen is responding to <a href="https://twitter.com/mountain_ghosts/status/1337552024821510144">this commentary</a>, which starts out salty but goes on to articulate a rarely-discussed element of how the tech industry functions: tech executives <em>have</em> to make their work appear innovative in order to secure VC funding. So they’re forced to artificially “make it innovative” by filing patents or hopping on the latest trends. In the case of Uber and iOS development, that imperative <a href="https://twitter.com/StanTwinB/status/1336890442768547845">burned them badly</a>.</p>



<p>Academia is similar: <a href="https://www.mccormick.northwestern.edu/research-faculty/directory/affiliated/watt-jeremy.html">Dr. Jeremy Watt</a>, author of <em><a href="https://github.com/jermwatt/machine_learning_refined">Machine Learning Refined</a></em>, articulates how academics <em>have</em> to make their work appear novel in order to get published, and they have to get published to keep their jobs, so they’re forced to artificially differentiate similar concepts—to convolute rather than simplify.</p>



<p>There’s a great <a href="https://twitter.com/mekkaokereke/status/1027552576454021120">explanation from Mekka Okereke</a> about how to counteract some of this as an engineer. It shares a lot with our “first establish the motivation” approach—namely, by starting from the <em>problem</em>, not the solution.</p>



<p><strong>Also, a giant caveat: </strong>This solution is not always there. Sometimes the solution just has to be clever, or complicated, or messy. Sadly I can’t give you an ironclad heuristic for how to find them or how to confirm their existence. I can tell you this: in most cases where I have found them, I have found them by popping <em>up</em> a level from the implementation level to the design level. </p>



<p>Also, this recommendation applies specifically to technical solutions: it does not apply, for example, to racism or fascism. The problems we’re talking about here are de facto circumscribed by the scope of an application. When we’re talking about a generational cultural, political, and structural phenomenon, “just rip out X” doesn’t work.</p>


	<div>
		<figure>
							
										<figcaption>Nor does one simply solve [insert insidious social issue here].</figcaption>
					</figure>
	</div>
	


<p>White supremacy culture in tech alone is so insidious and multifaceted that I’ve got <a href="https://chelseatroy.com/2020/02/07/the-price-of-whiteness-in-tech/">an ongoing series</a> about reimagining different parts of tech through a not-white-supremacist lens. But also, listen to <a href="https://twitter.com/polotek/status/1249908489826099201">Marco Rogers about this caveat</a>. He knows more things than I do.</p>



<p>ANYWAY, anyway, anyway. </p>



<p>So we’ve talked about selling our changes, and we’ve talked about making changes that reduce the scope of complexity. Naturally, the third thing I find myself doing, is selling new knowledge <em>by</em> reducing the scope of complexity. Here we go:</p>



<h3>Try to spread intuition with as few prerequisites as possible.</h3>



<p>One of my Mobile Software Development students asked me what frameworks he should consider for testing a Python app he’s working on. Here’s what I said:</p>



<blockquote><div><p>In Python there are two leading options: unittest and pytest. Both work fine. When I’m working on teams, I tend to go with pytest because the output is a little nicer.&nbsp;</p><p>But…when I’m&nbsp;<em>teaching</em>&nbsp;Python, I don’t use a testing framework at all. I write methods that call the method I’m testing, and then I use Python’s&nbsp;<a rel="noreferrer noopener" href="https://www.w3schools.com/python/ref_keyword_assert.asp" target="_blank">built in assert keyword</a>&nbsp;to check the state of the modified objects or return values. Reason being, I don’t want to jump into the complexity of all the different stuff you can use to test until students understand&nbsp;<em>why</em>&nbsp;we test. I try to use the minimum toolset that gets the point across.</p></div></blockquote>



<p><br>One of the big things that educational approaches manage to screw up, in my view, is to introduce prerequisites that make the topic in question <em>harder</em> instead of <em>easier</em>. Fluent Forever founder Gabriel Wyner <a href="https://youtu.be/bPVeIHcgfTs?t=74">articulates how language learning often depends on translation</a>—which is a whole, separate, <em>difficult</em> skill. So when I’m trying to help someone build intuition, I’ll try to eliminate as many dependencies as possible. </p>



<p>I’ll show you an example for teaching testing in Python. I pulled this example out of a notebook that I share with my <a href="https://www.emergentworks.org/">Emergent Works</a> and <a href="https://centerforjustice.columbia.edu/justicethroughcode">Justice Through Code</a> mentee. She was working on writing a Sudoku solver. Of course, to solve a Sudoku, it helps to know when a Sudoku is solved. </p>



<p>Suppose we start with a similar but simpler puzzle; each row and each column must each possess one copy of each number, like this:</p>



<pre><code>puzzle = [
    [1, 2, 3, 4],
    [2, 1, 4, 3],
    [3, 4, 1, 2],
    [4, 3, 2, 1],
]</code></pre>



<p>This is a valid puzzle, albeit smaller than your typical 9 x 9. </p>



<p>It shows a way of <em>representing</em> our problem space—a list of lists. We could make a <code>Puzzle </code>class for this, with all kinds of methods on it. I’m not doing that yet. I’m doing the <em>minimum thing</em> that gets the point across: we need a way to represent our data. Here is a way to represent our data with minimal dependencies and indirection. </p>



<p>We’re gonna do the same thing for the test, no test framework involved (yet!):</p>



<pre><code>def valid_puzzle(puzzle):
    try: 
        # Python is duck-typed, so …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/">https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/</a></em></p>]]>
            </description>
            <link>https://chelseatroy.com/2020/12/18/how-to-be-a-10x-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25498696</guid>
            <pubDate>Mon, 21 Dec 2020 19:49:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing JSON at the CLI: A Practical Introduction to jq and more]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25498364">thread link</a>) | @sequoia
<br/>
December 21, 2020 | https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/ | <a href="https://web.archive.org/web/*/https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><p><code>jq</code> is a command line tool for parsing and modifying JSON. It is useful for extracting relevant bits of information from tools that output JSON, or REST APIs that return JSON. Mac users can install <code>jq</code> using homebrew (<code>brew install jq</code>); see <a href="https://stedolan.github.io/jq/download/">here</a> for more install options.</p>
<p>In this post we'll examine a couple "real world" examples of using <code>jq</code>, but let's start with...</p>
<h2 id="-code-jq-code-basics">
    <a href="#-code-jq-code-basics">
      
    </a>
    <code>jq</code> Basics</h2><p>The most basic use is just tidying &amp; pretty-printing your JSON:</p>
<pre><code>$ USERX=<span>'{"name":"duchess","city":"Toronto","orders":[{"id":"x","qty":10},{"id":"y","qty":15}]}'</span>
$ <span>echo</span> <span>$USERX</span> | jq <span>'.'</span>
</code></pre>
<p>outputs</p>
<pre><code>{
  <span>"name"</span>: <span>"duchess"</span>,
  <span>"city"</span>: <span>"Toronto"</span>,
  <span>"orders"</span>: [
    {
      <span>"id"</span>: <span>"x"</span>,
      <span>"qty"</span>: <span>10</span>
    },
    {
      <span>"id"</span>: <span>"y"</span>,
      <span>"qty"</span>: <span>15</span>
    }
  ]
}
</code></pre>
<p>I like this pretty-printing/formatting capability so much, I have an alias that formats JSON I've copied (in my OS "clipboard") &amp; puts it back in my clipboard:</p>
<pre><code><span>alias</span> jsontidy=<span>"pbpaste | jq '.' | pbcopy"</span>
</code></pre>
<p>The <code>'.'</code> in the <code>jq '.'</code> command above is the simplest jq "filter." The dot takes the input JSON and outputs it as is. You can read more about filters <a href="https://stedolan.github.io/jq/manual/#Basicfilters">here</a>, but the bare minimum to know is that <code>.keyname</code> will filter the result to a property matching that key, and <code>[index]</code> will match an array value at that index:</p>
<pre><code>$ <span>echo</span> <span>$USERX</span> | jq <span>'.name'</span>
<span>"duchess"</span>
$ <span>echo</span> <span>$USERX</span> | jq <span>'.orders[0]'</span>
{
  <span>"id"</span>: <span>"x"</span>,
  <span>"qty"</span>: 10
}
</code></pre>
<p>And <code>[]</code> will match <em>each</em> item in an array:</p>
<pre><code><span>echo</span> <span>$USERX</span> | jq <span>'.orders[].id'</span>
<span>"x"</span>
<span>"y"</span>
</code></pre>
<p>Filtering output by value is also handy! Here we use <code>|</code> to output the result of one filter into the input of another filter and <code>select(.qty&gt;10)</code> to select only orders with <code>qty</code> value greater than 10:</p>
<pre><code><span>echo</span> <span>$USERX</span> | jq <span>'.orders[]|select(.qty&gt;10)'</span>
{
  <span>"id"</span>: <span>"y"</span>,
  <span>"qty"</span>: 15
}
</code></pre>
<p>One more trick: filtering by <strong>key</strong> name rather than value:</p>
<pre><code>$ ORDER=<span>'{"user_id":123,"user_name":"duchess","order_id":456,"order_status":"sent","vendor_id":789,"vendor_name":"Abe Books"}'</span>
$ <span>echo</span> <span>$ORDER</span> | jq <span>'.'</span>
{
  <span>"user_id"</span>: 123,
  <span>"user_name"</span>: <span>"duchess"</span>,
  <span>"order_id"</span>: 456,
  <span>"order_status"</span>: <span>"sent"</span>,
  <span>"vendor_id"</span>: 789,
  <span>"vendor_name"</span>: <span>"Abe Books"</span>
}
$ <span>echo</span> <span>$ORDER</span> | jq <span>'with_entries(select(.key|match("order_")))'</span>
{
  <span>"order_id"</span>: 456,
  <span>"order_status"</span>: <span>"sent"</span>
}
</code></pre>
<p>(cheat sheet version: <code>with_entries(select(.key|match("KEY FILTER VALUE")))</code>)</p>
<p>Check out <a href="#more-resources">more resources</a> below to learn about other stuff jq can do!</p>
<h2 id="a-usecase-debugging-some-prometheus-metrics">
    <a href="#a-usecase-debugging-some-prometheus-metrics">
      
    </a>
    A Usecase: Debugging Some Prometheus Metrics</h2><p>I have a prometheus metric showing up locally that doesn't look quite right:</p>
<pre><code>async_task_total{task_name="/Users/duchess/charmoffensive/toodle-app/pkg/web/page/globals.go(189):(*GlobalsPopulator).Populate"} 6
</code></pre>
<p>The fact that the <code>task_name</code> value is a <em>filename</em> is a red flag–<a href="https://prometheus.io/docs/practices/naming/#labels">it's bad to have labels with high cardinality</a> and I'm not sure how many of these there are. I want to find out:</p>
<ol>
<li>What do these <code>task_name</code> labels look like in production?</li>
<li>How many unique values are there for these labels?</li>
</ol>
<h3 id="1-getting-the-label-values-in-production">
    <a href="#1-getting-the-label-values-in-production">
      
    </a>
    1. Getting the label values in production</h3><p>At my company there is a <abbr title="Command Line Interface">CLI</abbr> tool we'll call <code>pquery</code> that allows prometheus metrics to be queried from the command line, and it outputs JSON–how conventient! I use this tool in the following examples. You don't have this tool, but fear not: <a href="https://learndevops.substack.com/p/hitting-prometheus-api-with-curl">this wonderful post</a> explains how to query prometheus using <a href="https://curl.se/">curl</a> which is essentially what <code>pquery</code> does.</p>
<p>Using <code>pquery</code> we can view prometheus metrics from our various clusters. But even if we filter for this exact metric name, it's more data than we can easily look at. We'll use <code>wc -l</code> (wordcount: count lines) to get a rough idea of how much data we're working with:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | wc <span>-l</span>
316117
</code></pre>
<p>316,117 lines of JSON! Oof! We want to iterate over the metrics. But what jq filter do we need to access the array of metrics? I find <code>head</code> useful for figuring out what the top level keys are for a large json structure:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | head -n 20
{
    <span>"data"</span>: {
        <span>"result"</span>: [
            {
                <span>"metric"</span>: {
                    <span>"__name__"</span>: <span>"async_task_total"</span>,
                    <span>"app"</span>: <span>"toodle-app-alpha"</span>,
                    <span>"instance"</span>: <span>"10.55.55.55:9393"</span>,
                    <span>"job"</span>: <span>"toodle-app-alpha"</span>,
                    <span>"kubernetes_pod_name"</span>: <span>"toodle-app-b446b7ccd-6mls6"</span>,
                    <span>"namespace"</span>: <span>"noweb"</span>,
                    <span>"netpol"</span>: <span>"toodle-app"</span>,
                    <span>"node_name"</span>: <span>"gke-production-04-3455c6df-j526"</span>,
                    <span>"release"</span>: <span>"toodle-app"</span>,
                    <span>"task_name"</span>: <span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
                },
                <span>"value"</span>: [
                    1600981630.344,
                    <span>"2"</span>
</code></pre>
<p>You can also use <code>jq 'keys'</code> if you just want the key names:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | jq <span>'keys'</span>
[
  <span>"data"</span>,
  <span>"status"</span>
]
</code></pre>
<p>Anyway we can see from above that <code>.data.result</code> is the "filter" path for the metrics themselves. Let's get the <strong>first result</strong> (<code>[0]</code>) of this array so we can see what one metric looks like:</p>
<pre><code>$ pquery <span>'async_task_total'</span> | jq <span>'.data.result[0]'</span>
{
  <span>"metric"</span>: {
    <span>"__name__"</span>: <span>"async_task_total"</span>,
    <span>"app"</span>: <span>"toodle-app-alpha"</span>,
    <span>"instance"</span>: <span>"10.55.55.55:9393"</span>,
    <span>"job"</span>: <span>"toodle-app-alpha"</span>,
    <span>"kubernetes_pod_name"</span>: <span>"toodle-app-b446b7ccd-6mls6"</span>,
    <span>"namespace"</span>: <span>"noweb"</span>,
    <span>"netpol"</span>: <span>"toodle-app"</span>,
    <span>"node_name"</span>: <span>"gke-production-04-3455c6df-j526"</span>,
    <span>"release"</span>: <span>"toodle-app"</span>,
    <span>"task_name"</span>: <span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
  },
  <span>"value"</span>: [
    1600981906.069,
    <span>"2"</span>
  ]
}
</code></pre>
<p>Oops! That <code>app</code> value (<code>toodle-app-alpha</code>) indicates a mistake: I'm only interested in results from the <code>toodle-app</code> app, <em>not</em> from other apps that may also emit this metric (such as the <code>alpha</code> deployment we see here). We could <code>select</code> for this using jq, but <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/"><code>promql</code> already lets us filter by metric names</a> so we'll do that instead: <code>pquery 'async_task_total{app="toodle-app"}'</code>.</p>
<p>We're interested in the <code>task_name</code> value in the <code>metric</code> object, so let's pluck that from <strong>each</strong> item in the array above:</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(122):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(132):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(73):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(160):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(166):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(172):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(140):(*areaCategoryView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(146):(*areaCategoryView).fetchData"</span>
{... + 18009 more lines}
</code></pre>
<blockquote>
<p>📝 Update: It was pointed out to me that as this is a post about <code>jq</code>, not about <code>promql</code>, a <code>jq</code> solution is more appropriate here. I'd originally used promql because it's more efficient to filter on the server when possible. Here's the <code>jq</code> version which uses the <a href="https://stedolan.github.io/jq/manual/#select(boolean_expression)"><code>select</code> filter</a>:</p>
<pre><code>$ pquery <span>'async_task_total'</span> \
| jq <span>'.data.result[].metric | select(.app == "toodle-app").task_name'</span>
</code></pre>
<p>Back to the post...</p>
</blockquote>
<p>Eighteen thousand values for that label!? That's bad!! But wait a tic–if other labels are varying, some of these may actually be duplicates. Let's sort them and see:</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | head -n10
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
</code></pre>
<p>Yep: most of these are actually not unique names. <code>uniq</code> to the rescue!</p>
<pre><code>$  pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | uniq
<span>"/charmoffensive/toodle-app/pkg/core/collection/resolvers/query.go(221):(*queryResolver).Verticals"</span>
<span>"/charmoffensive/toodle-app/pkg/core/guides/guides.go(411):generateGuideFromDefinition"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(122):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/place/place.go(132):FetchPlaceDetailForCollection"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(67):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/core/user/user.go(73):GetAccountDetails"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(160):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(166):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area.go(172):(*areaView).fetchData"</span>
<span>"/charmoffensive/toodle-app/pkg/web/page/area_category.go(140):(*areaCategoryView).fetchData"</span>
{... more}
</code></pre>
<p>Now I've got a full list of all the <em>distinct</em> values for this label, which answers my first question.</p>
<h3 id="how-many-unique-values-are-there-for-these-labels-">
    <a href="#how-many-unique-values-are-there-for-these-labels-">
      
    </a>
    How many unique values are there for these labels?</h3><p>Well that's pretty easy at this point...</p>
<pre><code>$ pquery <span>'async_task_total{app="toodle-app"}'</span> \
| jq <span>'.data.result[].metric.task_name'</span> | sort | uniq | wc <span>-l</span>
92
</code></pre>
<p>Ninety-two! Not so bad. Mystery solved, and I can say with reasonable confidence "the cardinality of these labels isn't terribly high, I'm …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/">https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/</a></em></p>]]>
            </description>
            <link>https://sequoia.makes.software/parsing-json-at-the-cli-a-practical-introduction-to-jq-and-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25498364</guid>
            <pubDate>Mon, 21 Dec 2020 19:22:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I rewrote a Clojure tool in Rust]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25497050">thread link</a>) | @praveenperera
<br/>
December 21, 2020 | https://timofreiberg.github.io/clojure-vs-rust/ | <a href="https://web.archive.org/web/*/https://timofreiberg.github.io/clojure-vs-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <div>
            
<p>2020-12-20</p>


<p>About two years ago, I wrote a quite complicated diff tool in Clojure.<br>
It was complicated enough that I struggled to fit the algorithm in my head and the inputs were large enough that I had to make some efforts to improve performance.</p>
<p>About half a year later, I started learning Rust, ported the current state of the Clojure program into Rust, was very happy with the change<sup><a href="#hooked-on-rust">1</a></sup> and continued exclusively with Rust.<br>
While working on that project, I've developed some opinions about the two languages, especially about error handling and performance:</p>
<p>I think that these are areas where Rust excels, while they are among the weaker spots of Clojure<sup><a href="#not-hating-on-clojure">2</a></sup>.</p>
<p>To put my experience in context:
I had a bit more than one year of experience in Clojure when I moved to Rust.
The diff tool was by far the largest Clojure program I've ever written, and it was only about 3000 lines.<br>
When I started writing Rust, reimplementing the existing Clojure code was among my first Rust code.
I've continued learning Rust since then and have mostly stopped writing Clojure.<br>
If things have changed in Clojure recently, please let me know and I'll update the article.</p>
<h2 id="error-handling"><a href="#error-handling" aria-label="Anchor link for: error-handling">🔗</a>Error Handling</h2>
<p>The error handling requirements in this project were not very complicated.
All errors just needed to be logged and returned to the user.<br>
The only slightly unusual requirement was that parsing and validation logic should show all errors for each row in both uploaded excel files
(instead of just the first error) so I had to accumulate errors.</p>
<h3 id="error-handling-in-clojure"><a href="#error-handling-in-clojure" aria-label="Anchor link for: error-handling-in-clojure">🔗</a>Error Handling in Clojure</h3>
<p>Error handling in Clojure is not opinionated.<br>
<a href="https://lispcast.com/clojure-error-messages-accidental/">Similar to error messages</a>
, what error handling idioms exist in Clojure seem to me to be largely accidental or inherited from Java.</p>
<p>The standard library mostly supports <a href="https://clojuredocs.org/clojure.core/ex-info">exceptions</a>.<br>
There are some libraries that support returning error values instead of throwing exceptions like the error handling library <a href="https://github.com/adambard/failjure"><code>failjure</code></a>.<br>
Others, like the parsing library <a href="https://github.com/Engelberg/instaparse"><code>instaparse</code></a>, return their own custom error values<sup><a href="#insta-result">3</a></sup>.</p>
<p>I used failjure to help accumulate errors in a nicer way (and because it appealed to my Haskell-influenced taste).</p>
<p>Let's look at a Clojure function from my diff tool that uses <a href="https://github.com/adambard/failjure#attempt-all">attempt-all</a> to parse and validate the input data.
If any errors occur, all errors are aggregated into a string:</p>
<pre><code><span>(</span><span>defn </span><span>parse
  </span><span>[country-mapping data]
  #_"</span><span>   👇 the attempt-all function exits early 
           if any binding returned a failure</span><span>"
  (</span><span>fail/attempt-all
   </span><span>[headers (</span><span>header-row</span><span> data)
    parsed (</span><span>map
             </span><span>#(</span><span>parse-rule</span><span> headers country-mapping %)
             (</span><span>content-rows</span><span> data))
    #_"</span><span>           👇 list of failures is aggregated here</span><span>"
    failed-parses (</span><span>-&gt;&gt;</span><span> parsed
                    (</span><span>filter</span><span> fail/failed?)
                    (</span><span>map</span><span> fail/message))
    #_"</span><span>          👇 this can return a failure,
                    triggering an early exit</span><span>"
    parse-result (</span><span>if </span><span>(</span><span>empty?</span><span> failed-parses)
                   parsed
                   #_"</span><span>👇 a single failure value containing the
                         list of failures concatenated into a string</span><span>"
                   (</span><span>fail/fail
                    </span><span>(</span><span>let </span><span>[msg (</span><span>str
                               </span><span>"</span><span>Failed to parse </span><span>"
                               (</span><span>count</span><span> failed-parses)
                               "</span><span> rules:</span><span>")]
                      (</span><span>str</span><span> msg "</span><span>\n</span><span>" failed-parses))))
    #_"</span><span>          👇 This can also return a failure</span><span>"
    spec-result (</span><span>util/check-specs </span><span>"</span><span>Rules</span><span>"
                                  </span><span>:rule/id
                                  ::spec/rule</span><span>
                                  parse-result)]
   #_"</span><span>👇 if everything was successful, this is returned</span><span>"
   spec-result
   #_"</span><span>👇 if any failure occurred, this is returned</span><span>"
   (</span><span>fail/when-failed </span><span>[failure]
                       (</span><span>do
                         </span><span>(</span><span>log/warn
                           </span><span>(</span><span>str </span><span>"</span><span>Failed to parse data </span><span>"
                             data "</span><span>:</span><span>\n</span><span>" (</span><span>fail/message</span><span> failure)))
                         failure))))
</span></code></pre>
<p>Nice things about this:</p>
<ul>
<li>The identifier-expression pairs in the square brackets use the same syntax as Clojure's <a href="https://clojuredocs.org/clojure.core/let"><code>let</code>-form</a>
which makes it look familiar.</li>
<li>I can optionally add an error handling function to the very end, which is helpful to, e.g., log the argument of the function, as I did here.</li>
</ul>
<p>Not so nice things about this:</p>
<ul>
<li>I can't see which functions can actually fail. I have to read them to find out.</li>
<li>Since the Clojure ecosystem doesn't have a uniform error handling style, I have to manually convert exceptions or other errors like <code>instaparse</code> error values to <code>failjure</code> errors.</li>
</ul>
<p>My verdict is:<br>
Since Clojure is a Lisp, it's possible to use most kinds of error handling and make it look fine, if you really want to.
The most pragmatic solution in most cases will be to use exceptions.</p>
<p>I found that readability could suffer when using less explicit error handling, especially in a dynamic language.</p>
<p>Due to the freedom of choice in error handling approacher, I was tempted to experiment more than with a more opinionated language.</p>
<h3 id="error-handling-in-rust"><a href="#error-handling-in-rust" aria-label="Anchor link for: error-handling-in-rust">🔗</a>Error handling in Rust</h3>
<p>Rust is quite opinionated about error handling.
The Rust community has worked on developing and improving common idioms, some of which were incorporated into the standard library, thereby improving the baseline error handling.</p>
<p>There's no improvement without change though, and the frequent changes have been a source of complaints.
While backwards compatibility was never broken, people that wanted their code to be idiomatic had to update it anyway.
Old tutorials and guides have therefore also become outdated.</p>
<p>There are lots of good, up-to-date articles about error handling in Rust<sup><a href="#rust-error-handling-links">4</a></sup>, which help learn the current idioms.</p>
<p>In Rust, functions that can error return the <a href="https://doc.rust-lang.org/std/result/index.html"><code>Result</code></a> type<sup><a href="#panic-ref">5</a></sup>.<br>
There are several libraries that make creating your own errors or handling errors from libraries easier, but they (mostly) just use the types from the standard library instead of introducing new stuff that's incompatible with the rest of the ecosystem.</p>
<p>Let's look at the same function as before, but this time in Rust:</p>
<pre><code><span>pub fn </span><span>parse</span><span>(
    </span><span>workbook</span><span>: &amp;</span><span>mut</span><span> Workbook,
    </span><span>country_mapping</span><span>: CountryMapping,
) -&gt; Result&lt;Vec&lt;Rule&gt;&gt; {
    </span><span>let</span><span> range = workbook
        .</span><span>worksheet_range</span><span>("</span><span>Rules</span><span>")
        </span><span>// this question mark triggers an early exit
        // there are two because we have an Option
        // containing a Result                    👇
        </span><span>.</span><span>ok_or</span><span>(format_err!("</span><span>Missing Rules sheet</span><span>"))??;
        </span><span>//                               👇
    </span><span>let</span><span> range = </span><span>skip_to_header_row</span><span>(range)?;
    </span><span>let</span><span> parsed = RangeDeserializerBuilder::new()
        .</span><span>has_headers</span><span>(</span><span>true</span><span>)
        .</span><span>from_range</span><span>(&amp;range)
        </span><span>//                                    👇
        </span><span>.</span><span>context</span><span>("</span><span>Failed to read Rules sheet</span><span>")?;
    </span><span>let</span><span> rules = </span><span>collect_errs</span><span>(parsed.</span><span>map</span><span>(|</span><span>parse_result</span><span>| {
        parse_result
            </span><span>// 👇 mapping a lambda over the error value
            </span><span>.</span><span>map_err</span><span>(|</span><span>e</span><span>| e.</span><span>into</span><span>())
            </span><span>// 👇 this would be called flatMap in some other languages
            </span><span>.</span><span>and_then</span><span>(|</span><span>row</span><span>| row.</span><span>parse</span><span>(&amp;country_mapping))
    }))
    </span><span>// 👇 this converts a list of errors into a single error
    //    containing a string
    </span><span>.</span><span>map_err</span><span>(|</span><span>es</span><span>| {
        format_err!(
            "</span><span>Failed to parse {} rules:</span><span>\n</span><span>{}</span><span>",
            es.</span><span>len</span><span>(),
            </span><span>// 👇 very elegant...
            //    this would just be one .joinToString call in Kotlin
</span><span>            es.</span><span>into_iter</span><span>()
                .</span><span>map</span><span>(|</span><span>e</span><span>| e.</span><span>to_string</span><span>())
                .collect::&lt;Vec&lt;_&gt;&gt;()
                .</span><span>join</span><span>("</span><span>\n</span><span>")
        )
   </span><span>// 👇
    </span><span>})?;
    Ok(rules)
}
</span></code></pre>
<p>Nice things about this:</p>
<ul>
<li>The standard library, every Rust library I've ever seen and my own application code is always using the same <a href="https://doc.rust-lang.org/std/result/enum.Result.html"><code>Result</code></a> type, which keeps things pretty compatible.</li>
<li><a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">The <code>?</code> operator</a> makes fallible functions visible but keeps it succinct.<br>
It also automatically converts error types where possible, which reduces the need for manual type conversion.</li>
<li>The error type I'm using here from the library <a href="https://docs.rs/anyhow/*/anyhow/index.html"><code>anyhow</code></a> supports a <a href="https://docs.rs/anyhow/*/anyhow/trait.Context.html"><code>.context</code></a> method, which gives otherwise unhelpful low-level errors the necessary context.<br>
This is usually done in exception-based languages by catching, wrapping and rethrowing, but this looks a lot more pleasant.</li>
</ul>
<p>Not so nice things about this:</p>
<ul>
<li>I have to keep the error types compatible, which I accomplish in this case by not distinguishing between different error types at all<sup><a href="#anyhow-usecase">6</a></sup>.<br>
I still have to return a single error value, which means I have to manually and verbosely convert the list of errors into a single one - in this case a newline-delimited string.</li>
<li>If I want to log something when this entire function returns an error or add some <code>.context</code> to it, I would like to have the equivalent of a <code>try/catch</code>-block around the entire function body.<br>
This doesn't exist yet<sup><a href="#try-blocks">7</a></sup>, the current best practice seems to be do move the entire body into an inner function or lambda.</li>
</ul>
<p>My verdict is:<br>
In Rust, you will use the <code>Result</code> type and you will like it<sup><a href="#and-you'll-like-it">8</a></sup>.<br>
The main design decisions are whether you use some of the helper libraries and how you design your error types.</p>
<p>Designing the error types can be a challenge though, especially because it's a bit different than designing e.g. Java exception hierarchies.<br>
I was lucky that keeping up to date with the evolving error handling idioms wasn't too hard for me as I was not under time pressure and often worked in my spare time with learning as my primary objective.
It might have been painful for teams maintaining bigger production systems.<br>
The large number of error handling tutorials and articles should hopefully make it easier to learn now than it was a few years ago.</p>
<p>The learning curve aside:
To me, Rust's error handling feels like part of the secret sauce that makes it the most promising language for correctness that I know of.</p>
<h2 id="performance"><a href="#performance" aria-label="Anchor link for: performance">🔗</a>Performance</h2>
<p>The part of the program that caused performance issues was the diff algorithm and, to a slightly lesser extent, a data normalization step before that.<br>
The type of performance problems I had were mostly being CPU bound, having to generate and compare a lot of temporary data.
The large amount of data also often caused memory issues in both languages.</p>
<h3 id="clojure-performance"><a href="#clojure-performance" aria-label="Anchor link for: clojure-performance">🔗</a>Clojure Performance</h3>
<p>In …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://timofreiberg.github.io/clojure-vs-rust/">https://timofreiberg.github.io/clojure-vs-rust/</a></em></p>]]>
            </description>
            <link>https://timofreiberg.github.io/clojure-vs-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25497050</guid>
            <pubDate>Mon, 21 Dec 2020 17:23:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix's Metaflow: Reproducible machine learning pipelines]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 97 (<a href="https://news.ycombinator.com/item?id=25497008">thread link</a>) | @ChefboyOG
<br/>
December 21, 2020 | https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex | <a href="https://web.archive.org/web/*/https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><h4>From training to deployment with Metaflow and Cortex</h4></p><div content-type="article"><p>If we were to design an optimal machine learning pipeline, it would be:</p><ul role="list"><li><strong>Scalable</strong>. As workloads increased, it would scale up without issue.</li><li><strong>Reproducible</strong>. We would be able to draw a line from any model to its data.</li><li><strong>Configurable</strong>. It wouldn’t lock us into particular frameworks or tools.</li></ul><p>Typically, pipelines will tradeoff in at least one of these areas. A pipeline might be scalable, but will rely on a platform that puts limits on data scientists. Or, a pipeline will be completely configurable, but will also be glued together by a mess of ad hoc code and will be impossible to reproduce.</p><p>In this piece, I want to introduce a way to build this kind of ideal pipeline without any tradeoffs. To do this, we’ll be using <a href="https://metaflow.org/" target="_blank">Metaflow, the open source data science framework from Netflix</a>, and <a href="https://github.com/cortexlabs/cortex" target="_blank">Cortex, our open source deployment platform for machine learning</a>. </p><p>Let’s start by defining our pipeline.</p><h3>Defining a pipeline in Metaflow</h3><p>Metaflow is a data science framework that provides a single API for managing different pieces of the infrastructure stack. It places an emphasis on scalability, reproducibility, and usability.</p><div><p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/XV5VGddmP24" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></div><p>At a high level, Metaflow allows us to define pipelines as DAGs, called “flows,” in which data undergoes a sequence of transformations called ”steps.” These steps persist transformed data as “data artifacts,” which are accessible by subsequent steps throughout the flow. </p><p>For example, say we had a training flow that loaded data (probably produced by another flow), trained multiple models with different strategies, evaluated the different models, and saved the top performer:</p><p>This is just a snapshot of our full pipeline, which I’ll be adding to in the next section, but even with just this snippet we have a repeatable training pipeline that can scale to run on many machines. We also have, thanks to Metaflow’s Client API, a way to version, audit, and reproduce these training runs.</p><p>For example, to instantiate a given step from a previous flow, we can simply pass in the flow name, run id, and step name to the Metaflow Client:</p><p>To access an artifact from a particular run, the logic is very similar:</p><p>This means that every time a flow is executed, Metaflow automatically versions and records it using a standard taxonomy. As a result, we can trace any given model’s lineage from raw data to final export. </p><p>There is much more to Metaflow, and I’d encourage you to check out their <a href="https://docs.metaflow.org/" target="_blank">documentation</a> to learn more, but as an introduction, this should serve to get us started. </p><p>Now, let’s talk a bit about triggering deployments in Metaflow.</p><h3>Deploying models with Cortex</h3><p>In this section, I’m going to take our training flow from before and add a step for deploying our model as a production API on AWS. To do this, we’re going to use Cortex.</p><p>Cortex is a deployment platform for machine learning. On the surface, it provides simple interfaces for building prediction services, deploying them to production, and managing an inference cluster. </p><p>Under the hood, Cortex automates all of the cloud infrastructure needed for inference—autoscaling, GPU/ASIC support, load balancing, prediction tracking, etc—and implements a automated deployment process in which model serving code is packaged, versioned, and deployed to the cluster.</p><p>We can trigger a deployment using Cortex’s Python client within our training flow like this:</p><p>You’ll notice the client includes a deploy() method, which takes a configuration object for defining our API. This configuration works with the Metaflow client to extract the location of the model, and the metadata of the flow for logging purposes. Now, when we audit our deployments, we can connect it all the way back to the run that produced it, extending our lineage from data to deployment.</p><p>The configuration object also references a predict.py script, which is where the actual prediction service is defined. A Cortex predictor looks like this:</p><p>The structure is very simple. We initialize our model in the init() function, which runs on initial deployment, and we generate predictions in the predict() function. Similar to steps in Metaflow, these Python methods can contain whatever logic you want to implement.</p><p>Now, when we run the flow, the model will be trained, evaluated, and deployed to production with zero downtime or extra configuration needed. </p><p>Because Cortex provides native support for A/B testing and traffic splitting, we can even run complex deployment strategies without breaking Metaflow’s lineage.</p><p>For example, if after selecting a best model, we wanted to test how the model performed in different formats—say ONNX vs TensorFlow—we could export two versions of the model, deploy them both in an A/B test, and log their performance. Because our training flow is connected to our deployment, we can then pass this information back and forth between Cortex and Metaflow without issue.</p><h3>An easier path to production machine learning</h3><p>Over the years, a number of end-to-end data science platforms have been released, and most of them fall into the same traps:</p><ul role="list"><li>Providing a smooth interface, with zero transparency into what’s happening under the hood, killing reproducibility and auditing.</li><li>Solving one part of the stack well, like training, but “bolting on” under-developed solutions for other parts, like deployment.</li><li>Locking data scientists and machine learning engineers into a narrow stack by only supporting specific frameworks and integrations.</li></ul><p>The result is a platform that makes production machine learning easy—if you stay strictly within the confines of the system. When you have a diverse set of problems to solve, however, this is difficult to do.</p><p>Metaflow and Cortex represent a fundamentally different, human-centric approach. The emphasis is not on providing a magic solution to a narrow set of problems, but on providing an easy interface for building solutions to any problem.</p><p>If you’re interested in digging into either platform, check out the links below:</p><ul role="list"><li><strong>Metaflow documentation: </strong> <a href="https://docs.metaflow.org/" target="_blank">https://docs.metaflow.org/</a></li><li><strong>Metaflow GitHub: </strong><a href="https://github.com/Netflix/metaflow" target="_blank">https://github.com/Netflix/metaflow</a></li><li><strong>Cortex documentation: </strong><a href="https://docs.cortex.dev/" target="_blank">https://docs.cortex.dev/</a></li><li><strong>Cortex GitHub: </strong><a href="https://github.com/cortexlabs/cortex" target="_blank">https://github.com/cortexlabs/cortex</a></li></ul><p>‍</p></div></div>]]>
            </description>
            <link>https://www.cortex.dev/post/reproducible-machine-learning-pipelines-with-metaflow-and-cortex</link>
            <guid isPermaLink="false">hacker-news-small-sites-25497008</guid>
            <pubDate>Mon, 21 Dec 2020 17:20:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[eBPF Updates 2nd issue. Collection of news and links about eBPF]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25496621">thread link</a>) | @genbit
<br/>
December 21, 2020 | https://ebpf.io/news/ebpf-updates-2020-12 | <a href="https://web.archive.org/web/*/https://ebpf.io/news/ebpf-updates-2020-12">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div>
<h2 id="foreword"><a href="#foreword" aria-label="foreword permalink"></a>Foreword</h2>
<p>Welcome to the second issue of the <em>eBPF Updates</em>! This time we have
interesting resources about how to write eBPF programs with Zig, or with Rust,
or on how to manage them with libbpf. On the kernel side, modules now support
BTF, and improvements to memory accounting for eBPF should help to solve the
limitations of rlimit. Did this just sound incomprehensible to you? Do not
fear, we also have some gentle introductions to eBPF in the list. This issue
also introduces a “Did You Know” section, and this time the focus is on CO-RE.
Read, learn, trace, and filter!</p>
<h2 id="important-news"><a href="#important-news" aria-label="important news permalink"></a>Important News</h2>
<p>The calls for participation (CFPs) for the devrooms for
<a href="https://fosdem.org/2021/">FOSDEM 2021</a> (online event) are open. Some of the
devrooms have hosted multiple talks about eBPF over the last year. In
particular:</p>
<ul>
<li>The SDN devroom (<a href="https://mdr78.github.io/2020/12/01/fosdem-cfp.html">CFP</a>)
accepts submissions until the 20th of December 2020.</li>
<li>The Containers devroom
(<a href="https://discuss.linuxcontainers.org/t/fosdem-2021-containers-devroom-call-for-papers/9625">CFP</a>)
accepts submissions until the 22th of December 2020.</li>
</ul>
<p>Recent start-up acquisitions highlight the growing adoption and the maturity of
eBPF:</p>
<ul>
<li><a href="https://www.flowmill.com/">Flowmill</a>, offering a solution for network
observability relying on eBPF,
<a href="https://techcrunch.com/2020/11/24/splunk-acquires-network-observability-service-flowmill/">has been acquired</a>
by <a href="https://www.splunk.com/en_us/newsroom/press-releases/2020/splunk-to-acquire-network-performance-monitoring-leader-flowmill.html">Splunk</a>.</li>
<li><a href="https://pixielabs.ai/">Pixie Labs</a>, which uses eBPF for visibility in
Kubernetes,
<a href="https://techcrunch.com/2020/12/10/new-relic-acquires-kubernetes-observability-platform-pixie-labs/">has been acquired</a>
by <a href="https://blog.newrelic.com/product-news/pixie-developer-first-observability/">New Relic</a>.</li>
</ul>
<p>Readers from Brazil may be interested in the <a href="https://ebpfbr.org/">eBPF Brasil</a>
website, which aims at gathering, translating, and sharing knowledge about
eBPF.</p>

<p>eBPF was named as one of the 5 technologies to watch in 2021 by CNCF TOC chair
<a href="https://twitter.com/lizrice">Liz Rice</a>, and the eBPF community just keeps on
growing every day.</p>
<p><span>
      <a href="https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/91608/community.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="community" title="community" src="https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/8c557/community.png" srcset="https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/4edbd/community.png 175w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/13ae7/community.png 350w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/8c557/community.png 700w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/e996b/community.png 1050w,
https://ebpf.io/static/46c6d0cb6279e137c838606098a3a67b/91608/community.png 1251w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span></p>
<h2 id="new-resources"><a href="#new-resources" aria-label="new resources permalink"></a>New Resources</h2>
<h3 id="blog-posts-presentations"><a href="#blog-posts-presentations" aria-label="blog posts presentations permalink"></a>Blog Posts, Presentations</h3>
<ul>
<li><a href="https://blog.container-solutions.com/the-top-reasons-why-you-should-give-ebpf-a-chance"><em>The Top Reasons Why You Should Give eBPF a Chance</em></a>,
from Lucas Severo Alves.<br>
Several factors are responsible for eBPF's success and should make readers
consider learning about, or using, this technology. This post cites its
powerful tracing capabilities, with the ability to attach to nearly any
function in the kernel with little impact on performance. Another reason is
that more and more companies, including large ones, are adopting eBPF; a
detailed list follows. At last, eBPF makes it possible to quickly develop
tools to instrument new parts of the kernel, without the need to go through a
longer process to upstream new attach points.</li>
<li><a href="https://cmd.com/blog/making-bpf-easy-with-libbpf-and-zig/"><em>Making BPF easy with libbpf and Zig</em></a>,
from Matt Knight.<br>
The <a href="https://ziglang.org/">Zig</a> programming language is used to create and
handle a simple eBPF program in this tutorial, both for the user space loader
and the eBPF program itself. The objective is mostly to understand how libbpf
manipulates the ELF object containing a program in order to load it, but
compiling from Zig, which aims at competing with C while offering some newer
features, may open new perspectives. The code is available
<a href="https://github.com/mattnite/zig-bpf-intro">on GitHub</a>.</li>
<li><a href="https://github.com/cilium/cilium/pull/13943">Weight support for Cilium's eBPF-based Maglev load balancer implementation</a>,
from Fankaixi Li.<br>
A new pull request by a software engineer at ByteDance (TikTok) popped up,
adding weight support to the eBPF-based
<a href="https://cilium.io/blog/2020/11/10/cilium-19#maglev">Maglev implementation in Cilium</a>.
Maglev provides consistent hashing for high-availability scenarios, and
balance packets to the same backends even if they arrive at different load
balancing nodes. The feature adds the possibility to assign weights to favor
some backends. It is still being discussed, but should land soon.</li>
<li><a href="https://kccncna20.sched.com/event/ekDR/beyond-the-buzzword-bpfs-unexpected-role-in-kubernetes-andrew-randall-alban-crequy-kinvolk"><em>Beyond the Buzzword: BPF’s Unexpected Role in Kubernetes</em></a>,
from Andrew Randall and Alban Crequy.<br>
After a high-level overview of eBPF, this presentation depicts the landscape
of the projects gravitating around this technology. The authors explain that
there are many powerful tools based on eBPF, although none of them would
cover Kubernetes clusters. As an answer to fill the gap, they introduce
Inspektor Gadget, which reuses some elements from the bcc tools to provide a
new set of monitoring gadgets for examining Pods. Note that the wording in
the slides might be misleading: If there was no equivalent to bcc for tracing
containers before Inspektor Gadget, there <em>are</em> other tools targeting the
platform, such as Cilium/Hubble for network and observability or BPFd for
running bcc scripts in containers.</li>
<li><a href="https://filipnikolovski.com/posts/ebpf/"><em>TIL: eBPF is awesome</em></a>,
from Filip Nikolovski.<br>
We all agree on this! This post is a gentle introduction to eBPF. A bit of
history, some details on the core infrastructure and its components, and a
simple “Hello, World!” example extracted from
<a href="https://github.com/iovisor/bcc/blob/34cada17f798b8e00268d1ba4a4a8d765b948532/examples/tracing/hello_fields.py">the bcc tools</a>.
A nice read if you just got started with eBPF.</li>
<li><a href="https://suchakra.wordpress.com/2020/11/20/building-an-esoteric-filesystem-tracing-tool-with-ebpf/"><em>Building an Esoteric Filesystem Tracing Tool with eBPF</em></a>,
from Suchakra Sharma.<br>
This post has a focus on the read-ahead mechanism in the Linux kernel. After
providing a refresher on how read-ahead works, Suchakra explains in details
how eBPF can monitor the hit rate and efficiency of this mechanism. It turns
out that the program used to do that already exists in two versions, one with
a mix of C and Python proper to the bcc tools, and another one based on
libbpf and the newer features brought by the library, like CO-RE (Compile
Once, Run Everywhere). The last section details the benefits of the latter
version and the motivations to port tools to libbpf.</li>
<li><a href="https://lac2020.sciencesconf.org/data/proceedings.pdf#section*.12"><em>eXpress Data Path Kernel Objects for Real-Time Audio Streaming Optimization</em></a> (PDF),
from Christoph Kuhr and Alexander Carôt.<br>
Focusing on audio packet processing, this work aims at facilitating the set
up of a rehearsal environment for conducted orchestras via the Internet with
up to sixty musicians. The system may be susceptible to latency issues when
the different UDP streams must be processed and combined. The authors
investigated the use of XDP for processing these UDP streams, aggregating
them in the kernel and reporting only the final audio sample to the user
application. The authors found that XDP was not ideal, because of its lack of
floating-point operations and because it does not permit to retrieve hardware
timestamps. They were also limited by the incompatibility between LLVM, used
to compile the eBPF programs, and their build system, and could not
experiment on one part of their frontend. And although XDP increased the
performance, they realized that they could obtain similar speeds for their
use case with an optimized handling of a generic raw socket. Still, the use
case and experiment remain an interesting read.<br>
Video of the presentation may be available in the future from
<a href="https://lac2020.sciencesconf.org/">the page of the conference</a>, if it gets
uploaded.</li>
<li><a href="https://thenewstack.io/primer-how-xdp-and-ebpf-speed-network-traffic-via-the-linux-kernel/"><em>Primer: How XDP and eBPF Speed Network Traffic via the Linux Kernel</em></a>,
from Jack Wallen.<br>
There is a resolute focus on XDP in this article which describes how this
eBPF hook can speed up network traffic on Linux. This is followed by a simple
tutorial, where bcc is used to attach a XDP program and to track UDP packets
sent to a given port.</li>
<li><a href="https://nakryiko.com/posts/libbpf-bootstrap/"><em>Building BPF applications with libbpf-boostrap</em></a>,
from Andrii Nakryiko.<br>
You want to start developing an eBPF application, but you feel intimidated by
libbpf's complexity or lack of documentation? You <em>must</em> have a look at
libbpf-bootstrap. This project builds simple application templates, on which
you can directly build your software. Of the two available templates, the
simplest one (<code>minimal</code>) manipulates an eBPF program that simply logs the PID
of the process that calls it. The more advanced template (<code>bootstrap</code>) sets
up an application with more advanced features like eBPF maps, read-only
configuration variables, eBPF ring buffer, or CO-RE which needs a BTF (BPF
Type Format) description of the kernel's internals. This means that using
these features gets simple and immediate, all is set up for you in the
template. This article goes into a thorough description of the mechanisms
involved. This is a long read, but well worth it if you want to program
applications working with eBPF.</li>
<li><a href="https://pluginized-protocols.org/xbgp/2020/11/29/xbgp-hello.html"><em>A first xBGP plugin</em></a>,
from Thomas Wirtgen.<br>
As a follow-up from the link to the paper for xBGP in the previous issue of
these <em>eBPF Updates</em>, this is the introduction of a first eBPF-based xBGP
plugin. The idea is that, quoting the post, “<em>a network operator would like
to ignore the BGP UPDATE messages that contain an unknown attribute. A
practical example of this usage is when problems with the processing of BGP
Path attribute 128 caused the failure of BGP sessions</em>”. All steps required
for running this example are provided. The code is hosted on
<a href="https://github.com/pluginized-protocols/xbgp_plugins.git">GitHub</a>, but there
is also a
<a href="https://github.com/pluginized-protocols/libxbgp/blob/master/misc/Dockerfile_xbgp">Dockerfile</a>
packaging all the required elements.</li>
<li><a href="https://docs.google.com/presentation/d/1cB4rJcdxTolIIUy5IEcb9iiUJHlMNmyT7c5eYY9D5LU/edit?usp=sharing"><em>Cilium &amp; eBPF - From Device to Service-Centric Networking</em></a>,
from Thomas Graf.<br>
In this presentation at the NAG (Network Architecture Geeks) Cafe in
December, Thomas outlines how eBPF allows to build powerful service-centric
networking models and how to evolve away from the old device-centric
networking architecture to meet requirements of containers and cloud-native
environments.</li>
<li><a href="https://medium.com/simplestaking/integrating-an-ebpf-based-firewall-into-the-tezedge-node-with-multipass-validations-769d4c6ccd93"><em>Integrating an eBPF-based firewall into the TezEdge node with multipass validations</em></a>,
from Juraj Selep.<br>
TezEdge peer-to-peer nodes validate blocks for the decentralized
<a href="https://en.wikipedia.org/wiki/Tezos">Tezos</a> blockchain, providing smart
contracts. Blockchain networks are subject to DDoS (Distributed Denial of
Service) attacks, generally mitigated with a firewall. In the current case,
XDP is used to implement it. The eBPF program checks that each connection
starts with a valid and unique proof of work, making it expensive for an
adversary to start many connections. This is further integrated with the
“multipass validation” scheme that aims at detecting erroneous blocks as soon
as possible. Note that the eBPF programs are written in Rust.</li>
<li><a href="https://en.pingcap.com/blog/why-we-switched-from-bcc-tools-to-libbpf-tools-for-bpf-performance-analysis"><em>Why We Switched from bcc-tools to libbpf-tools for BPF Performance Analysis</em></a>,
from Wenbo Zhang.<br>
Another article on the benefits brought by CO-RE, for which libbpf provides
good support. After comparing bcc-based and libbpf-based tracing tools in
terms of features and memory footprint, the author provide a list of tools
and invocation patterns they use to analyze I/O performance.</li>
<li><a href="https://cilium.io/blog/2020/12/11/kube-proxy-free-cve-mitigation"><em>How to mitigate Kubernetes CVE-2020-8554 with eBPF</em></a>
from Jed Salazar.<br>
<a href="https://github.com/kubernetes/kubernetes/issues/97076">CVE-2020-8554</a>
represents a MITM (Man-in-the-middle) attack in Kubernetes where the
ExternalIP service feature can be used to attack a workload and redirect
egress network traffic from a unsuspecting Pod to another destination. In
this blog, Jed describes how Cilium is able to …</li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ebpf.io/news/ebpf-updates-2020-12">https://ebpf.io/news/ebpf-updates-2020-12</a></em></p>]]>
            </description>
            <link>https://ebpf.io/news/ebpf-updates-2020-12</link>
            <guid isPermaLink="false">hacker-news-small-sites-25496621</guid>
            <pubDate>Mon, 21 Dec 2020 16:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chef cofounder on CentOS: It’s time to open source everything]]>
            </title>
            <description>
<![CDATA[
Score 187 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25493606">thread link</a>) | @ashitlerferad
<br/>
December 21, 2020 | https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/ | <a href="https://web.archive.org/web/*/https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Commentary: Red Hat has been in hot water about changing the way CentOS operates, but that model looks like the exact right way for open source entrepreneurs to operate.</p><div data-component="lazyloadImages">
<figure><span></span><figcaption></figcaption></figure>
<p>Red Hat switched up CentOS to make it less of a Red Hat Enterprise Linux (RHEL) clone and more of a feeder project into RHEL (as Fedora was always supposed to be, yet wasn’t). Some people are mad, as <a href="https://www.zdnet.com/article/red-hat-resets-centos-linux-and-users-are-angry/" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Steven J. Vaughan-Nichols has written</a> on sister site ZDNet. Some people, like former Disney employee Justin Garrison, <a href="https://twitter.com/rothgar/status/1337818039799070722" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">think</a> it sounds perfect (the hipper, slightly edgier version of RHEL). If you’re a billion-dollar company upset that Red Hat appears to be trying to charge for something you value, the <a href="https://www.zdnet.com/article/goodbye-centos-hello-rocky-linux/" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">founder of CentOS has a new way for you to get something for nothing</a>: Rocky Linux.</p>

<p>But if you’re an open source entrepreneur wondering what this means for you, well, Chef cofounder and System Initiative CEO <a href="https://twitter.com/adamhjk/status/1337062314357514251" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Adam Jacob has you covered</a>. In a series of tweets, he walks through how Red Hat’s CentOS strategy can play out for you. (He should know, as the company he co-founded, Chef, <a href="https://www.techrepublic.com/article/why-chefs-100-open-source-move-is-smart-business/" data-absolute="true">last year open sourced everything</a>.)</p>
<p>Let’s observe.</p>
<h2>Open source all the things</h2>
<p><a href="https://twitter.com/adamhjk/status/1337062314357514251" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Jacob’s first rule</a>? Open it up. Completely. “If I do an open source strategy for a company ever again, I will own the upstream, it will be fully open source, and I’ll happily collaborate with anyone downstream.” But not just an open upstream–it’s also important to, “Produce a commercial distribution [and c]ollaborate on downstream non-commercial ones, in the open,” he <a href="https://twitter.com/adamhjk/status/1337062321982758912" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">argued</a>.</p>
<p>What does he mean by “upstream” and “downstream”? In open source, think of the <a href="https://opensource.stackexchange.com/questions/993/what-does-upstream-mean" target="_blank" rel="noopener noreferrer nofollow" data-absolute="true" data-component="externalLink">upstream</a> as the parent, the head, the initial open source project. Downstream might be forks or distributions (packaging up of a particular build of the upstream code) of the upstream.</p>
<p>What Red Hat announced was basically that CentOS would move from being downstream to upstream. It becomes a place, as <a href="https://twitter.com/adamhjk/status/1337062318451068929" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">Jacob noted</a>, that others <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux" target="_blank" rel="noopener noreferrer nofollow" data-absolute="true" data-component="externalLink">like Facebook</a> can collaborate with Red Hat in a way they simply couldn’t before (as Fedora wasn’t closely enough aligned with RHEL). CentOS as a downstream RHEL community was mostly one of users, of consumers, not of collaborators. It was somewhere to get RHEL, but rebranded CentOS, for free.</p>
<p>As such, Jacob pointed out, “They weren’t invested in it beyond using it.” And when someone removes the downstream they get mad “because it’s like someone threatened the water supply,” <a href="https://twitter.com/adamhjk/status/1337062319558434822" target="_blank" rel="noopener noreferrer" data-absolute="true" data-component="externalLink">he argued</a>. It’s therefore far better to condition people to participate as collaborators with an open source project, and through the commercial distribution to also condition users to become customers, if they want the certified distribution.</p>
<h2>Open source + cloud</h2>
<p>One way that open source companies are doing this model to fantastic effect is by open sourcing their upstream and creating a cloud distribution (read: managed service). A variety of companies have embraced this model to greater or lesser extents.</p>
<p>Yugabyte, for example, ditched its Open Core model a year ago and open sourced 100% of its database code. A year later, CTO Karthik Ranganathan told me in an interview, “It increased our adoption like crazy,” growing the number of Yugabyte clusters 10x, but it also has dramatically accelerated their business without them losing any known pipeline. Could someone take that upstream and create a competitive downstream competitor? Of course. But no one should be able to out-Yugabyte on their home turf.</p>
<p>Or take Redis Labs. The company has fiddled with licensing over the last few years, but has kept core Redis completely open while encouraging a growing community (which includes downstream competitors) to lend a hand to improving the code. While Redis Labs doesn’t publish results, its business is booming, even as 10 or so other companies have created competitive downstream managed service offerings.</p>
<p>Which brings us back to Jacob: “Run an open upstream from the jump. Produce a commercial distribution. Collaborate on downstream non-commercial ones, in the open.”</p>
<p>That’s the strategy. That’s the magic. You don’t need to go Open Core or any other permutation of kind-of, sort-of open source. You can open source everything and just ensure you have a rock-solid managed cloud service. This reliance on cloud is what’s driving MongoDB, Confluent, DataStax, Redis Labs, and others to great success. It can be your model, too.</p>
</div></div>]]>
            </description>
            <link>https://planetstoryline.com/chef-cofounder-on-centos-its-time-to-open-source-everything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493606</guid>
            <pubDate>Mon, 21 Dec 2020 10:22:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pijul: Commutation and Scalability]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25493577">thread link</a>) | @Ygg2
<br/>
December 21, 2020 | https://pijul.org/posts/2020-12-19-partials/ | <a href="https://web.archive.org/web/*/https://pijul.org/posts/2020-12-19-partials/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Sunday, December 20, 2020</p>
<p>I just finished the implementation of an important feature of Pijul: clones, pushes and pulls on partial repositories. In this post, I explain why this matters.</p>
<h2 id="change-commutation">Change commutation</h2>
<p>Pijul is based on <em>changes</em>, also called <em>patches</em> or <em>diffs</em>.
This doesn’t mean that its only internal datastructure is patches, quite to the contrary: it was only by departing from a patch-only internal representation that we were able to solve the algorithmic challenges inherent to patch-based systems.</p>
<p>However, being change-based does mean that the core operations of Pijul are defined on changes, and that Pijul is designed in such a way that changes satisfy basic intuitive properties, similar to algebraic operations. One basic thing is that applying a change is an <em>associative</em> operation, like matrix multiplication: applying $A$ and $B$ at once, and then later $C$, is the same as applying $A$, and then $B$ and $C$ at once. In matrix multiplication, $(AB)C = A(BC)$. Moreover, in Pijul, all changes are invertible (whereas only some matrices are): for any change $A$, there is an “inverse change” $A^{-1}$ such that applying $A^{-1}$ after $A$ is the same as applying neither. Of course, both $A$ and $A^{-1}$ will appear in the log, but the contents of the repository will be the same as applying neither $A$ nor $A^{-1}$.</p>
<p>There is another property that users want from version control systems, and that is <strong>commutation</strong>.
Matrix multiplication rarely commutes<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
In Git, commutation is usually <em>simulated</em> using branches and rebase: indeed, rebasing a branch A on top of another branch B really means commuting the commits of A since the divergence between A and B, and the commits of B since the divergence. However, that commutation isn’t perfect, since the commits must change their hash when rebased.</p>
<p>Things are simpler in Pijul, because any two changes that <em>could have been written independently</em> always commute, meaning that if the two changes could be written without knowledge of each other, they can be applied in any order.</p>
<p>This of course raises a potential concern:</p>
<blockquote>
<p>If I can apply $A$ and $B$ in any order, how do I know which order is the <strong>right</strong> one?</p>
</blockquote>
<p>In Pijul, this question <strong>does not matter</strong>: both orders will yield <strong>the exact same result</strong>, the only difference is that the log will list the changes in the order in which they were applied. And I’m not saying that it doesn’t matter because I’m careless, but because it truly is the same thing.</p>
<blockquote>
<p>I disagree: it does matter, I still prefer to have a “<em>linear</em>” order for my changes/commits.</p>
</blockquote>
<p>Indeed, everybody wants to see the order of operations in a repository, for many reasons. For example:</p>
<ul>
<li>We want to keep a record of the operations performed on our repository.</li>
<li>We want to go back in time.</li>
</ul>
<p>And in fact, Pijul allows you to do exactly that, but in a more rigorous way than Git. Indeed, take the scenario where Alice and Bob work together, Alice makes a change $A$ while Bob makes $B$. When they put their work together, Alice applies Bob’s change, resulting in the log $AB$, while Bob applies Alice’s change, resulting in the log $BA$. In this case, there is no “true” linear history, since they worked on different things, and took different steps at different times. However, both of them want to be able to go back in time, step-by-step, and not just “<em>step-by-step-according-to-Bob’s-order</em>”.</p>
<h2 id="commutation-and-massive-repositories">Commutation and massive repositories</h2>
<p>One of the biggest challenge for Pijul up to the recent releases was scalability: even modestly-sized repositories like Pijul’s source code would use a lot of disk space. This was even more disappointing since, as I’m about to explain, commutation was suposed to allow it to scale to gigantic repository sizes… in theory. The same problem also made massive tests impossible, meaning that getting past the “0.x releases” seemed more and more impossible as time passed.</p>
<p>Now that this phase is mostly behind us, the cool bits of the theory finally become practical.</p>
<p>In particular, in Pijul, each change contains a reference to the files it modifies. Note that, because we want operations on repositories (such as renaming files) to commute with edits inside files, we don’t identify files and directories by name, but by a unique identifier made from the hash of the change that introduced that file or directory.</p>
<p>For repositories with multiple projects, this makes it possible to clone and pull just parts of a repository, and work on that part as if we had the entire thing. Indeed, imagine we have a repository with the following log:</p>
<ol>
<li>A, adding file <em>x</em></li>
<li>B, editing <em>x</em></li>
<li>C, adding file <em>y</em></li>
<li>D, adding file <em>z</em></li>
<li>E, renaming <em>x</em> to <em>w</em></li>
<li>F, editing <em>y</em> and <em>z</em></li>
</ol>
<p>All these changes do not necessarily commute; however, since B and C touch completely different files (namely, <em>x</em> and <em>y</em>), they could be produced in parallel, and hence they commute. This means that we can pull only the changes related to a specific file, say <em>x</em>, and make the following history: A, B, E<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p>Moreover, any change made on top of that sequence will commute with C, D and F: indeed, if we edit file <em>x</em> again, producing a change G, then since G can be made in parallel to C, D and F, we can push G after any patch that comes after B in that history, for example getting history “ABCDEFG”.</p>
<p>Note that this is done without changing the changes nor their hash.</p>
<h2 id="another-trick-for-large-files">Another trick for large files</h2>
<p>As explained in previous posts on this blog, Pijul changes have a bit more information than diffs, and operate on graphs rather than files. This means that changes can be split into two parts, a short-ish one with a binary specification of the graph operations, and then the new content inserted by the change.</p>
<p>The change format is designed to be downloadable in two stages: one can download the operations without downloading the contents. One issue with this is security: if we don’t download the contents, how can we make sure that the hash is right? This is done by including a hash of the change in the “operations” section of the change, and letting the hash of a change be the hash of the “operations” section.</p>
<p>This makes it possible for someone to make five versions of a large binary file in a day, where each change deletes the entire file, and adds it again, the operation sections only contain the length of the different versions, not the actual bytes. In order to get the latest version of the file, a client will therefore only have to download the latest change completely, and only the operations section of the previous ones.</p>
<p>Note that this makes the following “attack” possible: a server might trick a client into believing that the server has a change with hash $A$, which inserts $n$ bytes into a file, and then another change with hash $B$, deleting all these bytes. When the client downloads $A$ and $B$, it doesn’t need to download the contents. However, if the client later decides to unrecord $B$, the contents of $A$ will have to be downloaded, and the client will be able to tell that the hash of $A$ was incorrect. This should make it impossible to unrecord $B$ without also unrecording $A$. However, if $A$ made other edits, and other changes depend on $A$, this could be problematic.</p>
<h2 id="what-is-next">What is next?</h2>
<p>There is one remaining painpoint for very large repositories, and this is the fact that in order to clone a repository with a very large history, one must download and apply all the changes, one by one. Even though our apply function is quite fast<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, this can still be problematic for dozens or hundreds of thousands of changes.</p>
<p>In my next post, I will talk about a solution to this problem, which I have started to implement.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Matrices that are simultaneously diagonalizable do, for example, but for two arbitrary matrices $A$ and $B$, $AB$ is often different from $BA$. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Note that in this case, we could also pull A, E, B, since renaming a file commutes with editing it. However, we must start with A, since adding a file could not be possibly done in parallel to editing or renaming it. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>The complexity of apply is in $O(|p| |c| \log |H|)$, where $|p|$ is the size of the change, $|c|$ is the size of the largest conflict in which $p$ is involved, and $|H|$ is the number of edits made since the start of the repository. <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>
</div></div>]]>
            </description>
            <link>https://pijul.org/posts/2020-12-19-partials/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493577</guid>
            <pubDate>Mon, 21 Dec 2020 10:14:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for on Call Engineers During the Holidays]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25493498">thread link</a>) | @kiyanwang
<br/>
December 21, 2020 | https://www.transposit.com/blog/2019.12.23-tips-for-on-call-engineers-during-the-holidays/ | <a href="https://web.archive.org/web/*/https://www.transposit.com/blog/2019.12.23-tips-for-on-call-engineers-during-the-holidays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://transposit.imgix.net/img/2019.12.23a.jpg?auto=format&amp;ch=Width,DPR&amp;q=95&amp;w=800" alt="Picture of fire burning in a fireplace"></p><p>Are you sitting by the fire sipping cocoa, worrying secretly about whether you’ll have to put out an engineering fire any minute?</p><p>If only everyone could enjoy a well-earned break from on call life, the week would be more relaxing, but there is no rest for the technology that keeps our world running. This week certain industries are reaching a holiday high, and DevOps, SREs, and on call engineers everywhere will have to don their invisible superhero capes and keep us humans and our devices connected, just like they always do.</p><p>At Transposit, we know the pain of on call ourselves, and so we’ve banded together to come up with some of our top tips for making holiday on call shifts as painless as possible.</p><h2 id="on-call-tip-number-one%3A">On Call Tip Number One: <a href="#on-call-tip-number-one%3A">#</a></h2><p>Whether on-callers are planning on having a Rockwellian Christmas, lighting the menorah with Bubbe, visiting family abroad, or taking a tropical trip with the two federal holidays padding their vacation request, there is one consistent truth about the holiday week between Christmas and New Years: Mass exodus from the office. So, before we even get into the challenges of answering a page when no one is around to help you, how can you avoid that conundrum in the first place?</p><p>On call engineering managers should be careful to adjust on call schedules so that the same people are not on call during multiple peak times. Which times are most painful are up to the individual, so giving each person the opportunity to sign up for what works for them first is always a best practice. Perhaps someone doesn’t mind being on call Christmas morning, but absolutely can’t do it on New Years Eve. Start by letting people pick what is ideal for them, and then fill in the remaining gaps, being sure not to unduly burden any one member of the team.</p><p>When making the on call schedule, make sure that there are primaries and secondaries who are committed to each shift, since they will likely be working together without quick access to the rest of the team when something goes wrong.</p><p>To reduce the pain further, consider upping on call bonuses for the entire week as an incentive for taking on undesirable shifts, and once everyone is back in the office in January, be sure to acknowledge the on-callers who responded quickly to keep the business running while everyone else was enjoying their time away from work.</p><h2 id="on-call-tip-number-two%3A">On Call Tip Number Two: <a href="#on-call-tip-number-two%3A">#</a></h2><h3 id="communicate-early-and-often%2C-with-and-without-runbooks.">Communicate early and often, with and without runbooks. <a href="#communicate-early-and-often%2C-with-and-without-runbooks.">#</a></h3><p>Without easy access to the rest of the team, good playbook/runbook documentation during this period is even more important than it is the rest of the year. If your typical on call process involves opening up a collaborative team Slack thread or Jira ticket and then letting various experts or senior SREs weigh in, you might face a rude awakening when your reliable experts are MIA during the holiday week.</p><p>Make sure your runbooks are updated and everyone has easy access to the DevOps systems they need before everyone leaves on vacation, because if on-callers are left to search half-empty wikis by themselves, the speed to resolution is going to be stressful for everyone - engineers, managers, and executives alike.</p><p>Additionally, make sure that primary and secondary on-callers know exactly who they are paired with for a particular shift. Make sure that both are committed to being fully available and sober during their shifts, so that in the absence of the whole team, they are secure in having at least one problem-solving partner.</p><h2 id="on-call-tip-number-three%3A">On Call Tip Number Three: <a href="#on-call-tip-number-three%3A">#</a></h2><h3 id="plan-around-potential-travel-problems">Plan around potential travel problems <a href="#plan-around-potential-travel-problems">#</a></h3><p>While it may seem obvious to plan your travel around your on call shifts so that you aren’t in the air while you’re supposed to be available, these days, we sometimes have too much faith in our connectivity during travel. Airports and even some planes have wifi, many airplane seats have built-in electricity and jacks, what could possibly go wrong?</p><p>Remember, this week is one of the busiest travel weeks of the year in the US, so our already strained infrastructure will be at the edge of capacity in the best of circumstances. You won’t be very effective at troubleshooting an outage if you are standing in a 2-hour long airport security line or sitting in a traffic jam on the way up to the mountains. Add unpredictable winter weather to the mix, and we have on call disasters in the making. So, what should on-callers do?</p><p>First, you should plan wider time-frames for travel around your on call shifts to avoid accidentally being unavailable. You also shouldn’t count on access to wifi on your flights (only some planes are equipped, and airlines often shift which plane is flying a certain route based on weather and mechanical issues). Don’t expect access to electricity in the airport to charge your computer or phone, as the high number of travelers may easily keep the charging stations fully occupied, and make sure you have your computer and charger easily accessible, so that if you are forced to gate-check a bag on your crowded flight, you will be sure to keep these precious items on your person.</p><p>Traveling on-callers should also remember that time zones are a thing - your on call planning will need to be adjusted accordingly. If you are the secondary, your primary may be in a different time zone (or vice versa), and you should discuss your plans with them beforehand so that you are prepared for them to be asleep at different hours.</p><p>Finally, if you are traveling anywhere that has inclement weather or otherwise unreliable access to internet, you should have a back-up plan, such as tethering your computer to your phone’s data service to get around unreliable wifi. If you arrive at your destination and realize that you have bad data service, finicky wifi, or (gasp) the possibility of power outages, you should admit your defeat early and find an understanding colleague to take your shift, rather than hoping for the best and leaving any alerts to your back-ups.</p><h2 id="on-call-tip-number-four%3A">On Call Tip Number Four: <a href="#on-call-tip-number-four%3A">#</a></h2><p>We’ve already talked about the importance of secondaries as problem-solving partners, but what about the other, more social challenges of being on call during this time? Let’s say you’re sitting down to a nice family dinner, and, just like you were dreading, there goes your phone dinging with an urgent alert. How are you going to explain this situation to your relatives, who in many cases, don’t really understand what you do?</p><p>This is where a friendly ally can help serve as your secondary within your social situation. If you arm a sibling or supportive partner with talking points to explain why you have to get up from the festive table to crouch frantically over your laptop in the back room, you will be able to focus on troubleshooting without worrying about the familial fallout.</p><h2 id="on-call-tip-number-five%3A">On Call Tip Number Five: <a href="#on-call-tip-number-five%3A">#</a></h2><h3 id="pat-yourself-and-your-team-on-the-back">Pat yourself and your team on the back <a href="#pat-yourself-and-your-team-on-the-back">#</a></h3><p>It should go without saying, and so often it does, that there is a reason the world functions so smoothly during this week, despite its unique circumstances. While a lot of the credit is due to excellent engineering and team planning throughout the rest of the year, there are always unanticipated incidents that simply can’t be avoided. That’s why on call shifts, DevOps, and SREs exist in the first place! And so, as we look back on the year, and the incidents resolved during this special last week of 2019, let’s remember to give a shout out to all the engineering heroes who stepped forward to make it happen. Cheers to you!</p></div></div>]]>
            </description>
            <link>https://www.transposit.com/blog/2019.12.23-tips-for-on-call-engineers-during-the-holidays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493498</guid>
            <pubDate>Mon, 21 Dec 2020 09:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Lisp (2019)]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25493495">thread link</a>) | @wheresvic4
<br/>
December 21, 2020 | https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019 | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  It's 2019 and Lisp stories are on fire at HackerNews. While there exist multiple Lisp dialects, Common Lisp is the
  oldest and most mentioned. Thus, if you're looking to get started with programming in Common Lisp, then there are 2
  options:
</p>

<ul>
  <li>Use <a href="https://portacle.github.io/">portacle</a> to get up and running with SBCL + Emacs.</li>
  <li>
    Use
    <a href="https://github.com/roswell/roswell">roswell</a> to install multiple Lisp implementations + build and bundle
    lisp applications. Roswell installs SBCL by default.
  </li>
</ul>

<p>
  As for me, I did not feel like learning a brand new text editor just to get started with Lisp so I went with Roswell.
  Follow the instructions on installing Roswell for your platform. In my case, I decided to install it under
  <code>$HOME/bin</code> on my linux machine via:
</p>

<pre>$ sudo apt install rlwrap
$ mkdir $HOME/bin
$ git clone -b release https://github.com/roswell/roswell.git
$ cd roswell/
$ sh bootstrap
$ ./configure --prefix=$HOME/bin
$ make
$ make install</pre>

<p>
  Make sure to add the roswell path to your <code>~/.bashrc</code> (note that roswell installed itself under
  <code>~/bin/bin</code> and if this looks odd to you, install it under <code>$HOME/apps</code> or something of the
  sort):
</p>

<pre>if [ -d "$HOME/bin/bin" ] ; then
  PATH="$HOME/bin/bin:$PATH"
fi</pre>

<p>
  Open a new terminal and setup roswell:
</p>

<pre>$ which ros
/home/xxx/bin/bin/ros
$ ros --version
roswell 19.06.10.100
$ ros setup </pre>

<p>
  We will now setup VSCode to run lisp. First install the
  <a href="https://marketplace.visualstudio.com/items?itemName=mattn.Lisp">vscode-lisp</a> extension. Open a new file
  and type the following in:
</p>

<pre>(defun main ()
  (format t "Hello world"))
</pre>

<p>
  Then <a href="https://code.visualstudio.com/docs/editor/integrated-terminal">launch a terminal</a> inside VSCode. In
  the terminal run <code>rlwrap ros run</code> to start the REPL (Read/Eval/Print Loop). Select the above defined
  function and use the "Run Selected Text in Active Terminal" from the Command Palette (F1) to run your code!
  Note that you can exit the REPL via: <code>(SB-EXT:EXIT)</code>. The <code>rlwrap</code> utility remembers previously
  typed commands which makes for a much nicer REPL experience.
</p>

<p>
  What is amazing about Roswell is that is comes with a scripting / build ability that allows you to easily distribute
  your application. To see this in action first create a roswell script via <code>ros init hello-world</code>. Then add
  in the following code so that your script looks like the following:
</p>

<pre>#!/bin/sh
#|-*- mode:lisp -*-|#
#|
exec ros -Q -- $0 "$@"
|#
(progn ;;init forms
  (ros:ensure-asdf)
  ;;#+quicklisp(ql:quickload '() :silent t)
  )

(defpackage :ros.script.hello-world.3774807541
  (:use :cl))
(in-package :ros.script.hello-world.3774807541)

(defun helloWorld
  ()
  (format t "Hello world")
)

(defun main (&amp;rest argv)
  (declare (ignorable argv))
  (helloWorld))
;;; vim: set ft=lisp lisp:
</pre>

<p>
  We can now simply run this script via <code>ros hello-world.ros</code> but more interestingly, we can actually compile
  a binary via <code>ros build hello-world.ros &amp;&amp; ./hello-world</code>.
</p>

<p>
  Interestingly enough, I am not a complete noob to Common Lisp, I actually programmed it 15 years ago during my
  undergrad years. A colleague and I
  <a href="https://smalldata.tech/api/to/847c726edff337b818ba86914d9e71b6">compared an experimental genetic algorithm against an ant colony optimization algoritm on a path-finding problem</a>. Once I had lisp running I opened up the project and basically executed <code>ants.lisp</code> in the REPL, ran
  <code>(INITIALIZE-ANT-WORLD)</code> followed by <code>(DISPATCH-ANTS)</code> and voila, my ants were able to find
  their food!
</p>

<p>
  No guide to getting started with Lisp would be complete without a list of further reading that will keep you busy for
  the next 100 years so here we go:
</p>

<ul>
  <li>
    A very basic Lisp <a href="https://lisp-lang.org/learn/first-steps">tutorial</a> which also features an excellent
    <a href="https://lisp-lang.org/books/">list</a> of Lisp books
  </li>
  <li>
    <a href="https://smalldata.tech/api/to/3c02f249908494a961ac4b28e33f1ec5">A road to common lisp</a> - Steve Losh's excellent guide to
    getting into Lisp programming. The following is a small snippet of useful information from the post:
    <ul>
      <li>
        Files are files on your hard drive.
      </li>
      <li>Packages are containers of symbols. They are orthogonal to files.</li>
      <li>
        Systems are collections of code, instructions on how to load that code, dependency lists, and metadata. They are
        orthogonal to packages.
      </li>
      <li>
        Projects are high-level collections of "stuff" such as code, documentation, maybe some image assets,
        etc. They are (mostly) orthogonal to systems.
      </li>
      <li>Common Lisp itself knows about files and packages.</li>
      <li>ASDF adds systems.</li>
      <li>Quicklisp adds the internet.</li>
    </ul>

    This guide also provides a very nice review of libraries and is definitey worth a read.
  </li>
  <li>
    Another <a href="https://smalldata.tech/api/to/cb5d30e9026cba3d1d0b838611d1624c">article</a> that recommends roswell and provides
    instructions for Atom integration along with project and library management.
  </li>
</ul>

<p>
  Well, that's about it - Lisp is beautiful and I'm off to wrap my head around some 15 year old code that doesn't look
  too bad, go functional programming!
</p>
<p><a href="https://news.ycombinator.com/submitlink?u=https%3A%2F%2Fsmalldata.tech%2Fblog%2F2019%2F08%2F16%2Fgetting-started-with-lisp-in-2019&amp;t=Getting%20started%20with%20Lisp%20in%202019">HackerNews submission / discussion</a></p></div></div>]]>
            </description>
            <link>https://smalldata.tech/blog/2019/08/16/getting-started-with-lisp-in-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25493495</guid>
            <pubDate>Mon, 21 Dec 2020 09:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “Office Hours” Meetup (2014)]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25492576">thread link</a>) | @luu
<br/>
December 20, 2020 | https://ideolalia.com/essays/the-office-hours-meetup.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/the-office-hours-meetup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>Consider the meetup speaker.  She’s had a topic in mind for while, and so when the request went out for speakers, she volunteered.  But that was three months ago, and now the meetup’s only a few weeks away, and she hasn’t even begun.  She starts to outline the talk, but can’t quite figure out where to start.  She can explain all the details easily, but the order in which they should be introduced, the organizing structure of the talk, remains elusive.  Giving a talk about a subject, it turns out, is not the same as having a conversation about it.</p>

<p>Consider the first-time meetup attendee.  He’s been interested in the technology for a few months, but there doesn’t seem to be any guides that help him progress from the ubiquitous “hello world” or “distributed word count” examples to actual, effective production usage.  Maybe, he thinks, there will be some people at the meetup who can guide him through this awkward adolescence.  So after a long day at work, he wanders over to the meetup space, where everyone’s hanging around the open pizza boxes.  A few are eyeing the kegerator in the corner, wondering if it’s off-limits.  He stands next to them and eats his pizza, listening to their conversation, wondering if he should introduce himself or just wait for the talk to begin.</p>

<p>Consider the long-time meetup attendee.  He’s been using the technology for a few years, and wants its adoption to grow, so every month he comes to the meetup, eats the pizza, makes small talk with the other regular attendees, and dutifully listens to the talk.  The talk, unfortunately, is usually either too remedial or focused on something not very relevant to his day-to-day usage.  Also, the talks tend to be scattered, introducing concepts out of order, with lots of mental throat-clearing as the speaker tries to remember what was going through their head when they made the slide.  Usually within ten minutes half the audience is looking at their laptops, with only the occasional glance up to confirm that the talk is, in fact, still going on.  He attends almost every month, and often leaves wondering why he bothers.</p>

<p>In this based-on-a-true-story scenario, everyone’s motivations are good: they want to educate and to learn, to nurture and grow the community, to meet people who share their enthusiasm.  And yet, a typical meetup is at best weakly successful in all of these dimensions.  This is for a variety of reasons:</p>

<ul>
  <li><strong>Any growing community is at least half-filled with novices.</strong>  Very few assumptions can be made about what vocabulary and concepts are universally understood.  The speaker needs to make a conscious choice to either build up from first principles, greatly delaying the time it takes to get to the actual topic at hand, or leave a significant part of the audience behind.</li>
  <li><strong>Understanding something well enough to use it doesn’t mean you can explain it well.</strong>  We should all aspire to a clarity of understanding that lets us easily explain an idea to people from a variety of backgrounds, but that doesn’t come for free.  Details need to be synthesized into broader concepts, without losing sight of the practical knowledge necessary to apply those concepts.  Unsurprisingly, speakers are often still ascending that learning curve.</li>
  <li><strong>The standard lecture format expects and enforces passive participation.</strong> Ostensibly the attendees are making an active choice to learn and grow by attending a meetup, but upon arriving all that’s expected of them is to eat and listen.  Each attendee likely has interests and projects of their own, but unless the talk directly addresses them, any discussion must be crammed into the margins of the meetup - either before, when people are eating and the speaker is fussing with the projector, or after, when the hosts are tidying up and giving not-so-subtle looks to everyone who’s lingering.</li>
</ul>

<p>The lecture format still has value, of course, but much less so than its widespread usage would suggest.</p>

<p>In <a href="http://en.wikipedia.org/wiki/Seeing_Like_a_State">Seeing Like a State</a>, James Scott contrasts two Ancient Greek words for knowledge, <em>techne</em> and <em>metis</em>.  <em>Techne</em> is universal and timeless: the Pythagorean theorem and the <a href="http://en.wikipedia.org/wiki/Musica_universalis">harmony of the spheres</a>.  <em>Metis</em> is local and contextual: Odysseus infiltrating Troy and escaping the Cyclops.  Our educations are anchored in <em>techne</em> - data structures, algorithms, and exams with objectively correct answers - but upon entering the real world, we find the <em>techne</em> only takes us so far.  The problems we solve are not universal, they’re bounded by the context of our particular domains.  This is fortunate, because needing to solve the general form of every problem we come across would slow our work to a standstill.  However, this means our <em>metis</em> is unavoidably tangled up in the context in which we developed it.</p>

<p>Looking back, leaving the <em>techne</em> of school for the <em>metis</em> of our jobs can feel like a fall from grace.  What was once clear is now hopelessly muddled, littered with a thousand half-remembered details.  The promise of the lecture format is a return to that higher plane, an escape from the endless minutiae that awaits below.  And yet, most of what we’ve learned in our careers is within that minutiae.  There is enormous practical knowledge available at every meetup, and the lecture format uses almost none of it.</p>

<p>And so, at Factual we’ve been experimenting with <a href="http://www.meetup.com/The-Bay-Area-Clojure-User-Group/events/181057342/">a Clojure meetup</a> modeled on a different academic tradition: office hours.  At a university, students who have questions about the lecture content or coursework can visit the professor, and have a one-on-one conversation.  This can be enormously freeing for both parties: the student can ask questions without fear of looking stupid or holding up the rest of the class, and the professor can focus on giving an explanation that makes sense to this particular student, rather than the entire class.</p>

<p>At the beginning of every meetup, we give everyone a name tag, and provide a whiteboard with two columns, “teachers” and “students”.  Attendees are encouraged to put their name and interests in both columns.  From there, everyone can eat their food and read the whiteboard, and go in search of someone from the opposite column who shares their interests.  Typically they form groups of two or three, sometimes with a few more people listening in.</p>

<p>We’ve only had three meetups so far, each time with around twenty attendees, but the results have been promising.  It has been especially encouraging seeing novice Clojure users bring in their first project to get a critique of their approaches, and discuss how they can better use Clojure’s core abstractions.  These are precisely the sorts of conversations that create a healthy, growing community.</p>

<p>It’s unclear what the maximum practical size for this sort of meetup is.  Given the small size of each group it may scale fairly well, but at some point it becomes impossible for people to find each other.  Some sort of pre-event registration where people list their interests, and popular topics are assigned a physical location, may offset this.  However, for the vast majority of tech meetups, where the attendees number in the dozens rather than hundreds, this can be an enormously useful and engaging alternative to the lecture format.  We encourage everyone to give it a try.  And if you find yourself in San Francisco and have even a passing interest in Clojure, <a href="http://www.meetup.com/The-Bay-Area-Clojure-User-Group/events/181057342/">give us a visit</a>.</p>

<hr>

<p>This post was originally on the Factual blog, which has since been taken down post-acquisition.</p>


		</article>
	</div>

</div></div>]]>
            </description>
            <link>https://ideolalia.com/essays/the-office-hours-meetup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492576</guid>
            <pubDate>Mon, 21 Dec 2020 06:24:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Herald – Bluetooth contact tracing protocol]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25492423">thread link</a>) | @npad
<br/>
December 20, 2020 | https://vmware.github.io/herald/ | <a href="https://web.archive.org/web/*/https://vmware.github.io/herald/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div>
  <div>
    <div>
      <div>
        
        <p>Herald provides reliable Bluetooth communication and range finding across a wide range of mobile devices, allowing Contact Tracing and other applications to have regular and accurate information to make them highly effective.</p>        
      </div>
      
    </div>
  </div>
</div> <!-- /home-hero -->



<!--
<div class="section pb-0">
    <div class="section-content">
      <div class="row">
        <div class="col">
          <h2 class="text-center"></h2>
          <p></p>
  
          <ul>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
--> 

<div>
  <div>
    <div>
      <p>
        <h2>Herald solves risk estimation problems</h2>
      </p>          
    </div>
    <p><img src="https://vmware.github.io/herald/images/EstimationBenefits.png" alt="Herald estimation benefits">
  </p></div>
</div>

<div>
  <div>
    
    
    
<div>
  
    <div>
      
      <div>
        <div>
          
          <h5>Detect nearby phones</h5>
          
          
<p>100% detection of phones in the foreground and background across iOS and Android devices. <a href="https://vmware.github.io/herald/efficacy/herald">Herald supports</a>) 100% of the phones in the UK that support advertising, as well as the 35% of Android phones (<a href="https://vmware.github.io/herald/efficacy/statistics">~14% of all phones overall</a>) that cannot act as ‘advertisers’ and so remain unseen by advertising-only based protocols.</p>

          
        </div>
      </div>
    </div>
    
  
    <div>
      
      <div>
        <div>
          
          <h5>Provide regular distance readings</h5>
          
          
<p>Herald performs distance estimations every few seconds, with higher frequency on modern phones. This allows for a more accurate data and risk picture over time. Maximum frequency can be configured to optimise battery use. At <a href="https://vmware.github.io/herald/efficacy/herald">~4s per reading battery use is 6-11% over 8 hours</a>), depending on the age of the phone and its battery capacity.</p>

          
        </div>
      </div>
    </div>
    
  
    <div>
      
      <div>
        <div>
          
          <h5>Interoperate internationally</h5>
          
          
<p>By providing a common packet header we allow for <a href="https://vmware.github.io/herald/payload/interop">international interoperability</a> amongst all contact tracing applications, whether designed for centralised or decentralised contact matching and risk scoring.</p>

          
        </div>
      </div>
    </div>
    
        
</div>

  </div>
</div>

<div>
  <div>
    
    
    <div>

    
        
        


    <div>
    <div>
        <div>
            <p><img src="https://vmware.github.io/herald/img/herald.png" alt="New guides added to website">
                
            </p>
            <article>
                <h5>
                    <a href="https://vmware.github.io/herald/blog/guides">New guides added to website</a>
                </h5>
                <p>
                    We’ve been busy getting ready for the upcoming V1.1 release. For this release we’ve dramatically changed
our documentation on this website.


                </p>
            </article>
        </div>
    </div>
</div>
        
        


    <div>
    <div>
        <div>
            <p><img src="https://vmware.github.io/herald/img/herald.png" alt="New logo and website">
                
            </p>
            <article>
                <h5>
                    <a href="https://vmware.github.io/herald/blog/website">New logo and website</a>
                </h5>
                <p>
                    Quite a few things have happened in the first month since Herald was published as Open Source Software
under the MIT license. [29 Nov 2020 NOTE: Code now under the Apache-2.0 license]


                </p>
            </article>
        </div>
    </div>
</div>
        
         
</div>
    
  </div>
</div>


<div>
  <div>
    
<p>
A lot of work has gone in to mobile app based contact tracing protocol 
research, design, testing and collaboration worldwide. We'd like to thank 
all of those in VMware Pivotal Labs and elsewhere worldwide that have 
assisted with various national and state governments to use mobile contact 
tracing to help save lives. ❤️
</p>
  </div>
</div>

<div>
  <div>
    
<p>

All Herald works are Copyright 2020 Herald Authors.
</p>
<p>
The code for Herald (Android, iOS, Analysis Scripts, Calibration tool) are Apache-2.0 licensed. The documentation for Herald, including this website, are under the Creative Commons Attribution 4.0 International Public License.
</p>
<p>
See LICENSE.txt and NOTICE.txt for details.
</p>
  </div>
</div>


<div>
  <div>
    
<div>
  <div>
    <p>Herald Project is released as open source software and provides community support through our GitHub project page.
        If you encounter an issue or have a question, feel free to reach out on the <strong><a href="https://vmware.github.io/herald/issues">GitHub issues page for Herald Project</a></strong>.</p>
    <p>The Herald project team welcomes contributions from the community — please see our <strong><a href="https://github.com/vmware/herald/blob/master/contributing.md">contributing documentation</a></strong>.</p>
  </div>
</div>



  </div>
</div>
      <div>
    <div>
        <div>
            <div>
                <h5>Getting Started</h5>
                <p>To help you get started, see the documentation.</p>
            </div>
            
        </div>
    </div>
</div>




<!-- JS -->







    </div>
  </div></div>]]>
            </description>
            <link>https://vmware.github.io/herald/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492423</guid>
            <pubDate>Mon, 21 Dec 2020 05:44:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A TO-DO app that fits inside a single tweet]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25492302">thread link</a>) | @rukshn
<br/>
December 20, 2020 | https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/ | <a href="https://web.archive.org/web/*/https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Sunday morning while I was scrolling through my Twitter feed one tweet caught my eye,</p>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p><a href="https://twitter.com/hashtag/JavaScript?src=hash&amp;ref_src=twsrc%5Etfw">#JavaScript</a> Challenge:</p><p>Can you make a TO-DO app within a single Tweet? (280 chars)</p><p>The app should be able to add tasks, strike-through finished tasks &amp; clear all tasks.</p><p>Any general-purpose library is allowed.<br>Starting HTML body should be empty except the &lt;script&gt;.<a href="https://twitter.com/hashtag/JS?src=hash&amp;ref_src=twsrc%5Etfw">#JS</a> <a href="https://twitter.com/hashtag/code?src=hash&amp;ref_src=twsrc%5Etfw">#code</a></p></div>— Dumi (@dumindaxsb) <a href="https://twitter.com/dumindaxsb/status/1340539549890404354?ref_src=twsrc%5Etfw">December 20, 2020</a></blockquote>
<p>The challenge was to make a todo app that fits in a single tweet, just like any other todo app, you should be able to add or remove tasks and clear the task list. I thought how hard this can get, I thought to myself this is doable just by using plain JavaScript.</p>
<p>So since I don’t have a laptop, what resulted was a whole day of torture having to code though my iPad on codepen.</p>
<h2><strong>Plain JavaScript</strong> </h2>
<p>Soon after I started using plain JavaScript it became obvious that I was not able to make it within one tweet, the DOM manipulation was taking too much characters<em>, document.createElements, document.getElements. </em></p>
<p>It was obvious that was not the right approach.</p>
<h2>Using vue</h2>
<p>Vue framework won’t require any build tools, so I don’t have to go through setting up Webpack,</p>
<p>Also I can easily create the DOM within the script tag using simple HTML. So that will save some characters for me in DOM manipulation.</p>
<p>The first version I made use the <em>method</em> option in Vue app to handle button clicks, the button click event will call the function in methods to add new tasks and clear the task list.</p>
<p>However, I was unable to reduce it to one tweet. Then I went back to in-line functions, the same methods were added to button click events inline and not within the <em>methods</em> section.</p>
<p>Also I had to change buttons to anchor tags, in order to save some characters, and I had to use emojis instead of button text to save some more characters.</p>
<p>I also had to drop few buttons like a button to add a task, and instead I had to go with pressing enter key to add a task instead.</p>
<p>So I made the final version, the JavaScript code looked like this, </p>
<p data-height="300" data-theme-id="dark" data-default-tab="js" data-user="rukshn" data-slug-hash="qBaXmpE" data-pen-title="qBaXmpE">
<span>See the Pen <a href="https://codepen.io/rukshn/pen/qBaXmpE">
qBaXmpE</a> by Rukshan Ranatunge (<a href="https://codepen.io/rukshn">@rukshn</a>)
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>Then I ran the code through an online JavaScript minifier and then the whole HTML though an HTML minifier, and ended up with this piece of code,</p>
<pre><code>&lt;body&gt;&lt;script src=https://unpkg.com/<a href="https://ruky.me/cdn-cgi/l/email-protection" data-cfemail="d8aeadbd98b6bda0ac">[email&nbsp;protected]</a>&gt;&lt;/script&gt;&lt;script&gt;var x={data:()=&gt;({t:[],k:""}),template:'&lt;input @keyup.enter="t.push(k)" v-model="k"&gt;&lt;a @click="t=[]"&gt;❎&lt;/a&gt;&lt;p v-for="(v,i) in t"&gt;&lt;a @click="t.splice(i,1)"&gt;🅾️&lt;/a&gt;{{v}}&lt;/p&gt;'};Vue.createApp(x).mount("body")&lt;/script&gt;</code></pre>
<p>With my fingers crossed, I copied the code on to Twitter, and guess what it fits perfectly inside a single Tweet.</p>
<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">&lt;body&gt;&lt;script src=<a href="https://t.co/FY9eWOxLgZ">https://t.co/FY9eWOxLgZ</a>&gt;&lt;/script&gt;&lt;script&gt;var x={data:()=&gt;({t:[],k:""}),template:'&lt;input <a href="https://twitter.com/keyup?ref_src=twsrc%5Etfw">@keyup</a>.enter="t.push(k)" v-model="k"&gt;&lt;a <a href="https://twitter.com/Click?ref_src=twsrc%5Etfw">@click</a>="t=[]"&gt;❎&lt;/a&gt;&lt;p v-for="(v,i) in t"&gt;&lt;a <a href="https://twitter.com/Click?ref_src=twsrc%5Etfw">@click</a>="t.splice(i,1)"&gt;🅾️&lt;/a&gt;{{v}}&lt;/p&gt;'};Vue.createApp(x).mount("body")&lt;/script&gt;</p>— Rukshan (@JustRuky) <a href="https://twitter.com/JustRuky/status/1340862545322762240?ref_src=twsrc%5Etfw">December 21, 2020</a></blockquote>
<p>And here is the code in action, <a href="https://jsbin.com/venihiliha/1/edit?html,output">link</a> </p>
<p data-height="265" data-theme-id="dark" data-default-tab="result" data-user="rukshn" data-slug-hash="qBaXmpE" data-pen-title="qBaXmpE">
<span>See the Pen <a href="https://codepen.io/rukshn/pen/qBaXmpE">
qBaXmpE</a> by Rukshan Ranatunge (<a href="https://codepen.io/rukshn">@rukshn</a>)
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<h2>What I failed to achieve </h2>
<p>The original Tweet says, that the completed tasks should have a strike through.</p>
<p>But because css was costing me too much characters I had to fall back to remove completed tasks instead, but I’m sure someone will figure a solution for that as well.</p>
<p>At the same time, I think you can save even more characters by using <a href="https://mithril.js.org/">mithril</a>, because you have short-codes for DOM elements as well, but I haven’t tried mithril in awhile.</p>
<h4>One last thing</h4>
<p>No I didn’t waste my whole Sunday on this problem, but I had to spend few hours, thinking and trying different versions. </p>
<p>I would have cut back some more time if I had a laptop. Somerimes I feel like buying an old laptop and refurbishing it and installing Ubuntu on it.</p>
<p>Sunday well spent? Absolutely yes.</p>
<h2>Best answer?</h2>
<p>One thing I love about HN is the fact that there are lot of bright minds out there. Since I posted this on HN I knew it was just a matter of time since someone figures this out.</p>
<p>I guess this is the best answer and also ticks all the boxes, well done.</p>
<pre><code> &lt;script&gt;document.write(`&lt;style&gt;:checked+*{text-decoration:line-through}#t{display:none}&lt;/style&gt;&lt;p id="t"&gt;&lt;input type="checkbox"&gt;&lt;input&gt;&lt;div id="f"&gt;&lt;/div&gt;&lt;p&gt;&lt;button onclick="f.appendChild(t.cloneNode(true)).id=''"&gt;+&lt;/button&gt;&lt;button onclick="f.innerHTML=''"&gt;×&lt;/button&gt;`)&lt;/script&gt;</code></pre>
<p><strong>HN link to this answer</strong>: https://news.ycombinator.com/item?id=25493533</p>
<p><strong>Original thread on HN</strong>: https://news.ycombinator.com/item?id=25492302</p>
</div></div>]]>
            </description>
            <link>https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492302</guid>
            <pubDate>Mon, 21 Dec 2020 05:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modeling TLA+ in Z3Py (2020)]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25492150">thread link</a>) | @philzook
<br/>
December 20, 2020 | https://www.philipzucker.com/Modelling_TLA_in_z3py/ | <a href="https://web.archive.org/web/*/https://www.philipzucker.com/Modelling_TLA_in_z3py/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It’s that time of year again where I’m fiddling around with Z3Py. I’m booting it back up because I’m scheduled to do a <a href="https://fmie2021.github.io/agenda.html">tutorial on Z3</a> on Feb 3. It’s kind of silly because I probably already have too much content, and the tutorial is aimed at newbies, but there are some fun new things that I’ve learned in the last year I can do in Z3. As one example, it’s not so hard to build a pretty reasonable simulacrum of TLA+ in Z3.</p>

<p><a href="https://lamport.azurewebsites.net/tla/tla.html">TLA+</a> is a modelling/specification language for computational processes. It is particularly useful for modeling concurrency, where our intuitions fail us <a href="http://deadlockempire.github.io/">http://deadlockempire.github.io/</a>. It’s the mind child of Leslie Lamport, the same guy behind <a href="https://en.wikipedia.org/wiki/LaTeX">LaTex</a> and <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a>. The language doesn’t aim for deep verification of your actual code as is sometimes the goal with tools like Coq, but because of that it is significantly more lightweight and easy to use. 
The <a href="https://lamport.azurewebsites.net/tla/toolbox.html">TLA+ Toolbox</a> is a freely available IDE and checker to TLA+, but I think it is kind of a neat idea to replicate something in the flavor of TLA+ in all too familiar python. By leveraging Z3, we can get a lot of logical mileage and solver power for free.</p>

<p><a href="https://rise4fun.com/z3/tutorial">Z3</a> is an SMT solver. Its input language <a href="http://smtlib.cs.uiowa.edu/examples.shtml">smtlib2</a> is a kind of typed first order logic with special support for things like booleans, integers, reals, bitvectors, and algebraic datatypes. You can ask Z3 if propositions are valid, or if not it can provide a counterexample. It works pretty crazy good, especially if you work around its weaknesses (mostly quantifiers and nasty nonlinear stuff). Z3 has top class performance and its <a href="https://z3prover.github.io/api/html/namespacez3py.html">python bindings</a> are widely regarded as very good.</p>

<p>The main unusual things TLA brings into play compared to bog standard logics is the primed variables \(x'\), representing the values of variables at the next time step, and some temporal operators like always \(\Box\) and eventually \(\Diamond\).</p>

<p>We could mark primes by creating variables in pairs</p>
<div><div><pre><code><span>from</span> <span>z3</span> <span>import</span> <span>*</span>
<span>x</span><span>,</span> <span>xnxt</span> <span>=</span> <span>Ints</span><span>(</span><span>"x x'"</span><span>)</span>
</code></pre></div></div>

<p>But I’ve chosen to mark the prime variables using a special uninterpreted function, which we strip out later.</p>

<div><div><pre><code><span>def</span> <span>nxt</span><span>(</span><span>x</span><span>):</span> <span># next is a special function for generators in python, so we shouldn't use that name
</span>    <span>assert</span> <span>is_const</span><span>(</span><span>x</span><span>)</span>
    <span>assert</span> <span>f</span><span>.</span><span>decl</span><span>().</span><span>kind</span><span>()</span> <span>==</span> <span>Z3_OP_UNINTERPRETED</span><span>:</span>
    <span>s</span> <span>=</span> <span>x</span><span>.</span><span>sort</span><span>()</span>
    <span>return</span> <span>Function</span><span>(</span><span>"nxt"</span><span>,</span> <span>s</span><span>,</span> <span>s</span><span>)(</span><span>x</span><span>)</span>
</code></pre></div></div>

<p>One breakage here as compared to with TLA+ is the use of types. TLA+ curiously insists on a lack of intrinsic types and argues against them as a foundational feature. Types are instead propositions that are proved in the system. This just is really not convenient for using with Z3, so from the get-go I’m going to take liberties.</p>

<p>We can implement an <code>always</code> operator via a fairly simple procedure, we just roll out the execution of any formula for <code>n</code> time steps. This is the trick of bounded model checking. This rollout can be achieved by using the Z3 <code>substitute</code> function, a surprisingly useful little fellow.</p>

<div><div><pre><code><span># collects up all the variable from a formula
# https://stackoverflow.com/questions/14080398/z3py-how-to-get-the-list-of-variables-from-a-formula
</span><span>def</span> <span>get_vars</span><span>(</span><span>f</span><span>):</span>
    <span>r</span> <span>=</span> <span>set</span><span>()</span>
    <span>def</span> <span>collect</span><span>(</span><span>f</span><span>):</span>
      <span>if</span> <span>is_const</span><span>(</span><span>f</span><span>):</span> 
          <span>if</span> <span>f</span><span>.</span><span>decl</span><span>().</span><span>kind</span><span>()</span> <span>==</span> <span>Z3_OP_UNINTERPRETED</span><span>:</span>
              <span>r</span><span>.</span><span>add</span><span>(</span><span>f</span><span>)</span>
      <span>else</span><span>:</span>
          <span>for</span> <span>c</span> <span>in</span> <span>f</span><span>.</span><span>children</span><span>():</span>
              <span>collect</span><span>(</span><span>c</span><span>)</span>
    <span>collect</span><span>(</span><span>f</span><span>)</span>
    <span>return</span> <span>r</span>


<span>#https://theory.stanford.edu/~nikolaj/programmingz3.html#sec-bounded-model-checking
# rolls out the transition relation for n steps
# it replaces x with x_i and prime(x) with x_(i+1)
</span><span>def</span> <span>always</span><span>(</span><span>p</span><span>,</span><span>n</span><span>=</span><span>20</span><span>):</span>
    <span>orig_vs</span> <span>=</span> <span>get_vars</span><span>(</span><span>p</span><span>)</span>
    <span>nextvs</span> <span>=</span> <span>orig_vs</span>
    <span>t</span> <span>=</span> <span>True</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span><span>n</span><span>):</span>
        <span>vs</span> <span>=</span> <span>nextvs</span>
        <span>nextvs</span> <span>=</span>  <span>[</span> <span>Const</span><span>(</span> <span>f"</span><span>{</span><span>str</span><span>(</span><span>v</span><span>)</span><span>}</span><span>_</span><span>{</span><span>i</span><span>}</span><span>"</span><span>,</span> <span>v</span><span>.</span><span>sort</span><span>())</span> <span>for</span> <span>v</span> <span>in</span> <span>orig_vs</span>  <span>]</span>
        <span>p1</span> <span>=</span> <span>substitute</span><span>(</span><span>p</span><span>,</span> <span>[</span> <span>(</span><span>nxt</span><span>(</span><span>v</span><span>),</span> <span>nextv</span><span>)</span> <span>for</span> <span>v</span><span>,</span> <span>nextv</span> <span>in</span> <span>zip</span><span>(</span><span>orig_vs</span><span>,</span><span>nextvs</span><span>)</span>  <span>])</span> 
        <span>p2</span> <span>=</span> <span>substitute</span><span>(</span><span>p1</span><span>,</span> <span>[</span> <span>(</span><span>orig_v</span><span>,</span> <span>v</span><span>)</span> <span>for</span> <span>orig_v</span><span>,</span> <span>v</span> <span>in</span> <span>zip</span><span>(</span><span>orig_vs</span><span>,</span><span>vs</span><span>)</span>  <span>])</span>
        <span>t</span> <span>=</span> <span>And</span><span>(</span><span>t</span><span>,</span><span>p2</span><span>)</span>
    <span>return</span> <span>t</span>
</code></pre></div></div>

<p>Here for example is the specification of a clock from the <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/05/book-02-08-08.pdf">Specifying Systems</a> book. The clock starts with an hour between 0 and 12, and at each time step increases unless it’s wrapped around 12.</p>

<div><div><pre><code><span>hr</span> <span>=</span> <span>Int</span><span>(</span><span>"hr"</span><span>)</span>
<span>HCini</span> <span>=</span> <span>And</span><span>(</span><span>1</span> <span>&lt;=</span> <span>hr</span><span>,</span> <span>hr</span> <span>&lt;=</span> <span>12</span><span>)</span>
<span>HCnxt</span> <span>=</span> <span>nxt</span><span>(</span><span>hr</span><span>)</span> <span>==</span> <span>If</span><span>(</span><span>hr</span> <span>!=</span> <span>12</span><span>,</span> <span>hr</span> <span>+</span> <span>1</span><span>,</span> <span>1</span><span>)</span>
<span>HC</span> <span>=</span> <span>And</span><span>(</span><span>HCini</span><span>,</span> <span>always</span><span>(</span><span>HCnxt</span><span>))</span> 
<span>prove</span><span>(</span><span>Implies</span><span>(</span><span>HC</span><span>,</span>  <span>always</span><span>(</span><span>HCini</span><span>)))</span> <span># prove clock always stays between 0 and 12 (for 20 times steps)
</span></code></pre></div></div>

<p>You do have to be careful with using always. Arbitrarily nesting it’s usage may give unexpected results. Lamport makes an argument that specs very rarely do or should make sophisticated use of the temporal operators. Maybe this is good enough or maybe there is a way to patch this up.</p>

<p>Here are some other useful TLA+ like features and functions transcoded.</p>

<div><div><pre><code><span>def</span> <span>elem</span><span>(</span><span>x</span><span>,</span><span>S</span><span>):</span>
    <span>return</span> <span>Or</span><span>([</span><span>x</span> <span>==</span> <span>s</span> <span>for</span> <span>s</span> <span>in</span> <span>S</span><span>])</span>

<span>def</span> <span>unchanged</span><span>(</span><span>*</span><span>args</span><span>):</span>
    <span>return</span> <span>And</span><span>([</span><span>prime</span><span>(</span><span>x</span><span>)</span> <span>==</span> <span>x</span> <span>for</span> <span>x</span> <span>in</span> <span>args</span><span>])</span>

<span>def</span> <span>eventually</span><span>(</span><span>p</span><span>,</span> <span>n</span><span>=</span><span>20</span><span>):</span>
    <span>return</span> <span>Not</span><span>(</span><span>always</span><span>(</span><span>Not</span><span>(</span><span>p</span><span>),</span><span>n</span><span>=</span><span>n</span><span>))</span>

<span>def</span> <span>stutter</span><span>(</span><span>p</span><span>,</span> <span>vars</span><span>=</span><span>None</span><span>):</span>
    <span>if</span> <span>vars</span> <span>==</span> <span>None</span><span>:</span>
        <span>vars</span> <span>=</span> <span>get_vars</span><span>(</span><span>p</span><span>)</span>
    <span>return</span> <span>Or</span><span>(</span><span>p</span><span>,</span> <span>unchanged</span><span>(</span><span>*</span><span>vars</span><span>))</span>

<span>def</span> <span>enabled</span><span>(</span><span>A</span><span>):</span>
    <span>vs</span> <span>=</span> <span>get_vars</span><span>(</span><span>A</span><span>)</span>
    <span>nxtvs</span> <span>=</span>  <span>[</span> <span>FreshConst</span><span>(</span>  <span>v</span><span>.</span><span>sort</span><span>(),</span> <span>prefix</span><span>=</span><span>str</span><span>(</span><span>v</span><span>)</span> <span>)</span> <span>for</span> <span>v</span> <span>in</span> <span>vs</span><span>]</span>
    <span>p1</span> <span>=</span> <span>substitute</span><span>(</span><span>A</span><span>,</span> <span>[</span> <span>(</span><span>nxt</span><span>(</span><span>v</span><span>),</span> <span>nextv</span><span>)</span> <span>for</span> <span>v</span><span>,</span> <span>nextv</span> <span>in</span> <span>zip</span><span>(</span><span>vs</span><span>,</span><span>nxtvs</span><span>)</span>  <span>])</span> 
    <span>return</span> <span>Exists</span><span>(</span><span>nxtvs</span><span>,</span> <span>p1</span><span>)</span>

<span># backports useful logical operator notation for z3 that it does not have by default
</span><span>BoolRef</span><span>.</span><span>__and__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>And</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__or__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>Or</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__xor__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>Xor</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__invert__</span> <span>=</span> <span>lambda</span> <span>self</span><span>:</span> <span>Not</span><span>(</span><span>self</span><span>)</span>
<span>BoolRef</span><span>.</span><span>__rshift__</span> <span>=</span> <span>lambda</span> <span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>Implies</span><span>(</span><span>self</span><span>,</span><span>rhs</span><span>)</span>
</code></pre></div></div>

<p>Here as another example is the <a href="http://lamport.azurewebsites.net/video/video4.html">Die Hard puzzle</a></p>

<div><div><pre><code><span>small</span><span>,</span> <span>big</span> <span>=</span> <span>Ints</span><span>(</span><span>"small big"</span><span>)</span>

<span>TypeOk</span> <span>=</span> <span>And</span><span>(</span>
   <span>elem</span><span>(</span><span>small</span><span>,</span> <span>range</span><span>(</span><span>4</span><span>)),</span>
   <span>elem</span><span>(</span><span>big</span><span>,</span> <span>range</span><span>(</span><span>6</span><span>))</span>
<span>)</span>
<span>Init</span> <span>=</span> <span>And</span><span>(</span>
   <span>big</span> <span>==</span> <span>0</span><span>,</span>
   <span>small</span> <span>==</span> <span>0</span>
<span>)</span>

<span>FillSmall</span> <span>=</span> <span>And</span><span>(</span><span>prime</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>3</span><span>,</span> <span>unchanged</span><span>(</span><span>big</span><span>))</span>
<span>FillBig</span> <span>=</span> <span>And</span><span>(</span><span>prime</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>5</span><span>,</span> <span>unchanged</span><span>(</span><span>small</span><span>))</span>
<span>Goal</span> <span>=</span> <span>big</span> <span>!=</span> <span>4</span>
<span>SmallToBig</span> <span>=</span> <span>If</span><span>(</span><span>big</span> <span>+</span> <span>small</span> <span>&lt;=</span> <span>5</span><span>,</span>   
                 <span>And</span><span>(</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>big</span> <span>+</span> <span>small</span><span>,</span> <span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>0</span> <span>)</span> <span>,</span> 
                 <span>And</span><span>(</span><span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>small</span> <span>-</span> <span>(</span><span>5</span> <span>-</span> <span>big</span><span>),</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>5</span><span>)</span>
               <span>)</span>

<span>BigToSmall</span> <span>=</span> <span>If</span><span>(</span> <span>big</span> <span>+</span> <span>small</span> <span>&lt;=</span> <span>3</span><span>,</span>
                 <span>And</span><span>(</span> <span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>big</span> <span>+</span> <span>small</span><span>,</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>0</span><span>),</span>
                 <span>And</span><span>(</span> <span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>3</span><span>,</span> <span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>big</span> <span>-</span> <span>(</span><span>3</span> <span>-</span> <span>small</span><span>)</span> <span>)</span>
                <span>)</span>

<span>EmptyBig</span> <span>=</span> <span>And</span><span>(</span><span>nxt</span><span>(</span><span>big</span><span>)</span> <span>==</span> <span>0</span><span>,</span>  <span>unchanged</span><span>(</span><span>small</span><span>))</span> 
<span>EmptySmall</span> <span>=</span> <span>And</span><span>(</span><span>nxt</span><span>(</span><span>small</span><span>)</span> <span>==</span> <span>0</span><span>,</span>  <span>unchanged</span><span>(</span><span>big</span><span>))</span> 
<span>Next</span> <span>=</span> <span>Or</span><span>(</span><span>FillSmall</span><span>,</span> <span>FillBig</span><span>,</span> <span>EmptySmall</span><span>,</span> <span>EmptyBig</span><span>,</span> <span>SmallToBig</span><span>,</span> <span>BigToSmall</span><span>)</span>

<span>Spec</span> <span>=</span> <span>Init</span> <span>&amp;</span> <span>always</span><span>(</span><span>Next</span><span>,</span> <span>n</span><span>=</span><span>8</span><span>)</span>
<span>prove</span><span>(</span> <span>Implies</span><span>(</span><span>Spec</span>  <span>,</span> <span>always</span><span>(</span><span>Goal</span><span>,</span> <span>n</span> <span>=</span> <span>8</span><span>)))</span>
</code></pre></div></div>

<p>Z3 does in fact return a counter model that fills the buckets up as desired.</p>

<p>TLA+ has a tendency to use functions/records which are not so obvious how to encode. There are different ways of going about this. One aspect of playing around with Z3py is that it makes extremely clear the existence of the logic language and a metalanguage. The logic is Z3 expressions, but the metalanguage is python and they are obviously very different. But there is often a choice of whether to encode things in the logic vs the metalanguage. It is usually better I think to encode as much in python as possible if you can get away with it. Z3 likes piles of simple constraints more than it likes complicated quantifiers and things.</p>

<p>For example, we can want to encode an Enum type in python or in Z3.</p>

<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span><span>,</span> <span>auto</span>
<span>#python enum
</span><span>class</span> <span>RMState</span><span>(</span><span>Enum</span><span>):</span>
     <span>WORKING</span> <span>=</span> <span>auto</span><span>()</span>
     <span>PREPARED</span> <span>=</span> <span>auto</span><span>()</span>
     <span>COMMITTED</span> <span>=</span> <span>auto</span><span>()</span>
     <span>ABORTED</span> <span>=</span> <span>auto</span><span>()</span>

<span># z3 enum
</span><span>RMState</span> <span>=</span> <span>Datatype</span><span>(</span><span>"RMState"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"working"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"prepared"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"committed"</span><span>)</span>
<span>RMState</span><span>.</span><span>declare</span><span>(</span><span>"aborted"</span><span>)</span>
<span>RMState</span> <span>=</span> <span>RMState</span><span>.</span><span>create</span><span>()</span>
</code></pre></div></div>

<p>Or we can choose to encode records in Z3 vs python.</p>

<div><div><pre><code><span>#python record of z3 values
</span><span>val</span> <span>=</span> <span>Int</span><span>(</span><span>"val"</span><span>)</span>
<span>rdy</span><span>,</span> <span>ack</span> <span>=</span> <span>Bools</span><span>(</span><span>"rdy ack"</span><span>)</span>
<span>chan</span> <span>=</span> <span>{</span><span>val</span> <span>:</span> <span>val</span><span>,</span> <span>rdy</span> <span>:</span> <span>rdy</span><span>,</span> <span>ack</span> <span>:</span> <span>ack</span><span>}</span>

<span># Z3 record of Z3 values
</span><span>Chan</span> <span>=</span> <span>Datatype</span><span>(</span><span>"Chan"</span><span>)</span>
<span>ChanCon</span> <span>=</span> <span>Chan</span><span>.</span><span>declare</span><span>(</span><span>"constr"</span><span>,</span> <span>(</span><span>"val"</span><span>,</span> <span>IntSort</span><span>())</span> <span>,</span> <span>(</span><span>"rdy"</span><span>,</span> <span>BoolSort</span><span>()),</span>  <span>(</span><span>"ack"</span><span>,</span> <span>BoolSort</span><span>())</span> <span>)</span>
<span>Chan</span> <span>=</span> <span>Chan</span><span>.</span><span>create</span><span>()</span>
<span>record</span> <span>=</span> <span>Chan</span><span>.</span><span>constr</span><span>(</span><span>val</span><span>,</span><span>rdy</span><span>,</span><span>ack</span><span>)</span>
<span>chan</span> <span>=</span> <span>Const</span><span>(</span><span>"chan"</span><span>,</span> <span>Chan</span><span>)</span>
</code></pre></div></div>

<p>Or we can choose to encode functions in z3 or python</p>

<div><div><pre><code><span># python square. Works of Z3 values too
</span><span>def</span> <span>square</span><span>(</span><span>x</span><span>):</span>
    <span>return</span> <span>x</span><span>*</span><span>x</span>

<span># Internalized Z3 square function
</span><span>square</span> <span>=</span> <span>Function</span><span>(</span><span>"square"</span><span>,</span> <span>IntSort</span><span>(),</span><span>IntSort</span><span>())</span>
<span>x</span> <span>=</span> <span>Int</span><span>(</span><span>"x"</span><span>)</span>
<span>square_axiom</span> <span>=</span> <span>ForAll</span><span>([</span><span>x</span><span>],</span> <span>square</span><span>(</span><span>x</span><span>)</span> <span>==</span> <span>x</span> <span>*</span> <span>x</span><span>)</span>
</code></pre></div></div>

<h3 id="bits-and-bobbles">Bits and Bobbles</h3>

<p>Downsides:</p>

<ul>
  <li>Very ad hoc. The use of special autogenerated names is a great way to inadvertently smash things together</li>
  <li>TLA syntax is designed to be readable. The python adds a lot of noise</li>
  <li>TLA toolbox can format specs nicely using latex.</li>
  <li>TLA has a lot of thought gone into it. Making changes to it in an afternoon of thought is probably not to be trusted</li>
</ul>

<p>Upsides:</p>
<ul>
  <li>Better fits Z3, so we get good automation from the get go</li>
  <li>python is lingua franca of computing. It is comforting compared to TLA+, even if Z3py might be discomfiting.</li>
  <li>Having to download the toolbox and figure out how to use it is always going to be a slight speedbump. There is a TLA+ vscode extension now though. That might help</li>
</ul>

<p>Using Python ast parsing <a href="https://greentreesnakes.readthedocs.io/en/latest/index.html">https://greentreesnakes.readthedocs.io/en/latest/index.html</a>, we could probably use regular simple python syntax as a PlusCal like DSL and compile it into the above Z3-TLA+ hybrid.</p>

<p>I’m not sure if the CHOOSE operator of TLA+ will be easy to implement. It kind of seems like it requires nested solves? Can it be encoded using</p>

<p>I don’t particularly understand the TLA+ module system yet and I’m not so sure how to emulate it. Python modules might be one way, or perhaps classes.</p>

<p>Although I tried to copy exactly, perhaps one shouldn’t spec in precisely the style of standard TLA+.</p>

<h3 id="links">Links</h3>

<ul>
  <li><a href="https://www.learntla.com/introduction/">https://www.learntla.com/introduction/</a> Hillel Wayne’s tutorial</li>
  <li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/05/book-02-08-08.pdf">https://www.microsoft.com/en-us/research/uploads/prod/2018/05/book-02-08-08.pdf</a> Specifying Systems</li>
  <li><a href="https://pron.github.io/tlaplus">https://pron.github.io/tlaplus</a>  Very impressive essays by Ron Pressler</li>
  <li><a href="https://github.com/cobusve/TLAPLUS_DeadlockEmpire">https://github.com/cobusve/TLAPLUS_DeadlockEmpire</a> Very neat way to learn TLA+</li>
  <li><a href="https://github.com/tlaplus/Examples">https://github.com/tlaplus/Examples</a></li>
  <li>Apalache is a Z3 backed model checker for TLA+ <a href="https://github.com/informalsystems/apalache">https://github.com/informalsy…</a></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.philipzucker.com/Modelling_TLA_in_z3py/">https://www.philipzucker.com/Modelling_TLA_in_z3py/</a></em></p>]]>
            </description>
            <link>https://www.philipzucker.com/Modelling_TLA_in_z3py/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492150</guid>
            <pubDate>Mon, 21 Dec 2020 04:31:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix Recovery Legend (1986)]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25491790">thread link</a>) | @signa11
<br/>
December 20, 2020 | https://www.ee.ryerson.ca/~elf/hack/recovery.html | <a href="https://web.archive.org/web/*/https://www.ee.ryerson.ca/~elf/hack/recovery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h4>This classic article from Mario Wolczko first
appeared on Usenet in 1986.  </h4>

Have you ever left your terminal logged in, only to find when you
came back to it that a (supposed) friend had typed "<kbd>rm -rf
~/*</kbd>" and was hovering over the keyboard with threats along the
lines of "<em>lend me a fiver 'til Thursday, or I hit return</em>"?
Undoubtedly the person in question would not have had the nerve to
inflict such a trauma upon you, and was doing it in jest.  So you've
probably never experienced the worst of such disasters....<p>


It was a quiet Wednesday afternoon.  Wednesday, 1st October, 15:15
BST, to be precise, when Peter, an office-mate of mine, leaned away
from his terminal and said to me, "<em>Mario, I'm having a little
trouble sending mail.</em>" Knowing that msg was capable of confusing
even the most capable of people, I sauntered over to his terminal to
see what was wrong.  A strange error message of the form (I forget
the exact details) "<kbd>cannot access /foo/bar for userid 147</kbd>"
had been issued by msg.  My first thought was "<em>Who's userid 147?;
the sender of the message, the destination, or what?</em>" So I leant
over to another terminal, already logged in, and typed</p><blockquote>        <kbd>grep 147 /etc/passwd</kbd></blockquote>

<p>only to receive the response</p><blockquote>        <kbd>/etc/passwd: No such file or directory.</kbd></blockquote>

Instantly, I guessed that something was amiss.  This was confirmed
when in response to<blockquote>        <kbd>ls /etc</kbd></blockquote>

<p>I got</p><blockquote>        <kbd>ls: not found.</kbd></blockquote>

I suggested to Peter that it would be a good idea not to try anything
for a while, and went off to find our system manager.<p>

When I arrived at his office, his door was ajar, and within ten
seconds I realised what the problem was.  James, our manager, was
sat down, head in hands, hands between knees, as one whose world has
just come to an end.  Our newly-appointed system programmer, Neil, was
beside him, gazing listlessly at the screen of his terminal.  And at
the top of the screen I spied the following lines:</p><blockquote>
        <kbd># cd <br>
        # rm -rf *</kbd>
</blockquote>

<p>Oh, shit, I thought.  That would just about explain it.</p><p>


I can't remember what happened in the succeeding minutes; my memory
is just a blur.  I do remember trying <kbd>ls</kbd> (again),
<kbd>ps</kbd>, <kbd>who</kbd> and maybe a few other commands beside,
all to no avail.  The next thing I remember was being at my terminal
again (a multi-window graphics terminal), and typing</p><blockquote>
        <kbd>cd /<br>
        echo *</kbd>
</blockquote>
<p>I owe a debt of thanks to David Korn for making <kbd>echo</kbd> a
built-in of his shell; needless to say, <kbd>/bin</kbd>, together
with <kbd>/bin/echo</kbd>, had been deleted.  What transpired in the
next few minutes was that <kbd>/dev</kbd>, <kbd>/etc</kbd> and
<kbd>/lib</kbd> had also gone in their entirety; fortunately Neil had
interrupted <kbd>rm</kbd> while it was somewhere down below
<kbd>/news</kbd>, and <kbd>/tmp</kbd>, <kbd>/usr</kbd> and
<kbd>/users</kbd> were all untouched.</p><p>


Meanwhile James had made for our tape cupboard and had retrieved what
claimed to be a dump tape of the root filesystem, taken four weeks
earlier.  The pressing question was, "<em>How do we recover the
contents of the tape?</em>".  Not only had we lost
<kbd>/etc/restore</kbd>, but all of the device entries for the tape
deck had vanished.  And where does <kbd>mknod</kbd> live?  You
guessed it, <kbd>/etc</kbd>.  How about recovery across Ethernet of
any of this from another VAX?  Well, <kbd>/bin/tar</kbd> had gone,
and thoughtfully the Berkeley people had put <kbd>rcp</kbd> in
<kbd>/bin</kbd> in the 4.3 distribution.  What's more, none of the
Ether stuff wanted to know without <kbd>/etc/hosts</kbd> at least.
We found a version of <kbd>cpio</kbd> in <kbd>/usr/local</kbd>, but
that was unlikely to do us any good without a tape deck.</p><p>


Alternatively, we could get the boot tape out and rebuild the root
filesystem, but neither James nor Neil had done that before, and we
weren't sure that the first thing to happen would be that the whole
disk would be re-formatted, losing all our user files.  (We take dumps
of the user files every Thursday; by Murphy's Law this had to happen
on a Wednesday).  Another solution might be to borrow a disk from
another VAX, boot off that, and tidy up later, but that would have
entailed calling the DEC engineer out, at the very least.  We had a
number of users in the final throes of writing up PhD theses and the
loss of a maybe a weeks' work (not to mention the machine down time)
was unthinkable.</p><p>


So, what to do?  The next idea was to write a program to make a
device descriptor for the tape deck, but we all know where
<kbd>cc</kbd>, <kbd>as</kbd> and <kbd>ld</kbd> live.  Or maybe make
skeletal entries for <kbd>/etc/passwd</kbd>, <kbd>/etc/hosts</kbd>
and so on, so that <kbd>/usr/bin/ftp</kbd> would work.  By sheer
luck, I had a <kbd>gnuemacs</kbd> still running in one of my windows,
which we could use to create <kbd>passwd</kbd>, etc., but the first
step was to create a directory to put them in.  Of course
<kbd>/bin/mkdir</kbd> had gone, and so had <kbd>/bin/mv</kbd>, so we
couldn't rename <kbd>/tmp</kbd> to <kbd>/etc</kbd>.  However, this
looked like a reasonable line of attack.</p><p>


By now we had been joined by Alasdair, our resident UNIX guru, and as
luck would have it, someone who knows VAX assembler.  So our plan
became this: write a program in assembler which would either rename
<kbd>/tmp</kbd> to <kbd>/etc</kbd>, or make <kbd>/etc</kbd>, assemble
it on another VAX, <kbd>uuencode</kbd> it, type in the uuencoded file
using my gnu, <kbd>uudecode</kbd> it (some bright spark had thought
to put <kbd>uudecode</kbd> in <kbd>/usr/bin</kbd>), run it, and hey
presto, it would all be plain sailing from there.  By yet another
miracle of good fortune, the terminal from which the damage had been
done was still <kbd>su</kbd>'d to root (<kbd>su</kbd> is in
<kbd>/bin</kbd>, remember?), so at least we stood a chance of all
this working.</p><p>


Off we set on our merry way, and within only an hour we had managed
to concoct the dozen or so lines of assembler to create
<kbd>/etc</kbd>.  The stripped binary was only 76 bytes long, so we
converted it to hex (slightly more readable than the output of
<kbd>uuencode</kbd>), and typed it in using my editor.  If any of you
ever have the same problem, here's the hex for future reference:</p><blockquote>
   <kbd>070100002c000000000000000000000000000000000000000000000000000000<br>
        0000dd8fff010000dd8f27000000fb02ef07000000fb01ef070000000000bc8f<br>
		8800040000bc012f65746300</kbd>
</blockquote>

<p>

I had a handy program around (doesn't everybody?) for converting
ASCII hex to binary, and the output of <kbd>/usr/bin/sum</kbd>
tallied with our original binary.  But hang on---how do you set
execute permission without <kbd>/bin/chmod</kbd>?  A few seconds
thought (which as usual, lasted a couple of minutes) suggested that
we write the binary on top of an already existing binary, owned by
me...problem solved.

So along we trotted to the terminal with the root login, carefully
remembered to set the umask to 0 (so that I could create files in it
using my gnu), and ran the binary.  So now we had a <kbd>/etc</kbd>,
writable by all.  From there it was but a few easy steps to creating
<kbd>passwd</kbd>, <kbd>hosts</kbd>, <kbd>services</kbd>,
<kbd>protocols</kbd>, (etc), and then <kbd>ftp</kbd> was willing to
play ball.  Then we recovered the contents of <kbd>/bin</kbd> across
the ether (it's amazing how much you come to miss <kbd>ls</kbd> after
just a few, short hours), and selected files from <kbd>/etc</kbd>.
The key file was <kbd>/etc/rrestore</kbd>, with which we recovered
<kbd>/dev</kbd> from the dump tape, and the rest is history.</p><p>


Now, you're asking yourself (as I am), what's the moral of this
story?  Well, for one thing, you must always remember the immortal
words, <strong>DON'T PANIC</strong>.  Our initial reaction was to
reboot the machine and try everything as single user, but it's
unlikely it would have come up without <kbd>/etc/init</kbd> and
<kbd>/bin/sh</kbd>.  Rational thought saved us from this one.</p><p>


The next thing to remember is that UNIX tools really can be put to
unusual purposes.  Even without my <kbd>gnuemacs</kbd>, we could have
survived by using, say, <kbd>/usr/bin/grep</kbd> as a substitute for
<kbd>/bin/cat</kbd>.</p><p>


And the final thing is, it's amazing how much of the system you can
delete without it falling apart completely.  Apart from the fact that
nobody could login (<kbd>/bin/login</kbd>?), and most of the useful
commands had gone, everything else seemed normal.  Of course, some
things can't stand life without say <kbd>/etc/termcap</kbd>, or
<kbd>/dev/kmem</kbd>, or <kbd>/etc/utmp</kbd>, but by and large it
all hangs together.</p><p>


I shall leave you with this question: if you were placed in the same
situation, and had the presence of mind that always comes with
hindsight, could you have got out of it in a simpler or easier way?
Answers on a postage stamp to:</p><pre>Mario Wolczko
------------------------------------------------------------------------
Dept. of Computer Science       ARPA:   miw%uk.ac.man.cs.ux@cs.ucl.ac.uk
The University                  USENET: mcvax!ukc!man.cs.ux!miw
Manchester M13 9PL              JANET:  miw@uk.ac.man.cs.ux
U.K.                            061-273 7121 x 5699
------------------------------------------------------------------------
</pre>

<hr>

<address><a href="https://www.ee.ryerson.ca/~elf/hack/index.html">Hacker's Wisdom</a>: Unix Recovery
Legend</address>

<!-- hhmts start -->
Last modified: Thu Mar  7 13:47:40 EST 1996
<!-- hhmts end --></div>]]>
            </description>
            <link>https://www.ee.ryerson.ca/~elf/hack/recovery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491790</guid>
            <pubDate>Mon, 21 Dec 2020 03:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Covid vaccine scientist dead w stab wounds after falling from 14th floor]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25491576">thread link</a>) | @bookofjoe
<br/>
December 20, 2020 | https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/ | <a href="https://web.archive.org/web/*/https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491576</guid>
            <pubDate>Mon, 21 Dec 2020 02:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cakelisp: A Programming Language for Games]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25491568">thread link</a>) | @makuto
<br/>
December 20, 2020 | https://macoy.me/blog/programming/CakelispIntro | <a href="https://web.archive.org/web/*/https://macoy.me/blog/programming/CakelispIntro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><em>Update:</em> See the <a href="https://news.ycombinator.com/item?id=25491568">Hacker News thread</a>, <a href="https://www.reddit.com/r/programming/comments/kh6ox0/cakelisp_a_programming_language_for_games/">/r/programming</a>, <a href="https://www.reddit.com/r/ProgrammingLanguages/comments/kh6gh2/cakelisp_a_programming_language_for_games/">/r/ProgrammingLanguages</a>, and <a href="https://www.reddit.com/r/gamedev/comments/kh1p0a/cakelisp_a_programming_language_for_games/">/r/gamedev</a> posts for discussions on this article and Cakelisp.</p>
<p>I have been working on a new programming language since the end of August 2020. It is hosted on <a href="https://github.com/makuto/cakelisp/">Github</a>, and mirrored on <a href="https://macoy.me/code/macoy/cakelisp/">my site</a>.</p>
<p>If you want to see a working example first, <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame.cake</a> is a simple audio looper with Ogre 3D graphics and SDL for windowing, input, and audio. This demo supports code hot-reloading and doesn't require an external build system, only Cakelisp. You can also check <a href="https://macoy.me/code/macoy/cakelisp/src/branch/master/runtime/Macros.cake">Macros.cake</a>, which demonstrates some use-cases for compile-time code.</p>
<p>I figured showing non-trivial examples would be much more interesting. It also proves that Cakelisp is working.</p>

<p>Cakelisp is built for me first, but it should appeal to fellow programmers who know what they're doing and want to try a more powerful language.</p>
<p>Cakelisp might be for you if you want…</p>
<ul>
<li><strong>Uncompromised performance</strong></li>
<li><strong>Trust in you, the programmer</strong></li>
<li><strong>Powerful code generation</strong></li>
</ul>
<p>If any of the things in that list don't make sense to you, or you think you're already getting them in language <em>X</em>, then Cakelisp isn't for you, and that's okay! We have different domains and different problems, so it makes some sense to use different languages and methodologies.</p>
<p>While many languages have these features, few have the combination of all three. Lisp has extremely powerful code generation, but makes serious performance compromises. C is great for performance but can require extremely repetitive code writing to accomplish tasks a simple code generator could handle. Rust is fast (well, apart from compilation, which is very important for iterative development to be productive), but doesn't trust the programmer.</p>

<p>My goal is to "have my cake and eat it too", meaning all three of these features in one coherent package. Importantly, there isn't one dominating principle in Cakelisp (no <a href="https://www.youtube.com/watch?v=TH9VCN6UkyQ">Big Idea</a>). I've found that the small things like removing the need for header files, no longer dealing with external build systems, or being able to run Cakelisp files like scripts, end up making a big difference when combined in one package.</p>
<p>It is useful to go over the goals in detail so you can understand my decisions.</p>
<h2 id="uncompromised-performance">Uncompromised performance</h2>
<p>This means no garbage collection, no type boxing/unboxing, etc. Fewer abstractions (besides the ones you create) between you and what the computer is actually doing. Idiomatic usage of the language should result in performance comparable with C (in most cases, it should be identical, because it's only a thin layer on C).</p>
<h2 id="trust-in-you-the-programmer">Trust in you, the programmer</h2>
<p>While languages like Rust offer benefits in terms of security and stability, they cost programmers in terms of productivity. It makes sense to value safety so highly if your code is safety-critical (operating systems, aerospace, automotive, etc.), but it's much less valuable when safety isn't as important (e.g. in games).</p>
<p>In a perfect world all programs would be as robust as space flight software, but in reality, that level of robustness is unnecessary for most programs. It's important to realize that the safety focus is just one way of doing things, not the <em>One True Way</em> or anything.</p>
<h2 id="powerful-code-generation">Powerful code generation</h2>
<p>In my opinion, most languages offer far too little opportunity for the programmer to automate the actual writing of code. This power also relates to trusting in the programmer, because gone wild, the code can become incomprehensible.</p>
<p>The company I work for has what I consider to be a state-of-the-art code generator built for the company's use-case: multi-platform MMOs. It's used very effectively on serialization, RPC, automatic commands, monitoring, automatic documentation, and more.</p>
<p>To give more credence to the use of code generation in games, <a href="https://docs.unrealengine.com/en-US/ProgrammingAndScripting/GameplayArchitecture/index.html">Unreal</a> and <a href="https://www.youtube.com/watch?v=wiJqUWfR90I">Naughty Dog</a> also rely on code generation.</p>
<h2 id="simplify-project-setup-and-management">Simplify project setup and management</h2>
<p>I want to dramatically reduce time wasted on C++ project set-up and "code logistics". This includes setting up build systems, creating header files, adding and managing new C/C++ 3rd party libraries, and other things of that ilk.</p>
<h2 id="gain-more-power">Gain more power!</h2>
<p>Every language has limitations. The lack of straightforward, all-powerful code generation was my primary gripe with C++.</p>
<p>For example, automatically creating function and structure bindings using C++ template metaprogramming is very complex. These are two very useful tools in game development: function bindings for commands, scripting languages, and RPC; structure bindings for serialization or game monitors.</p>
<p>I also wanted features like hot-reloading (being able to load new versions of the code without restarting the program/losing runtime state). Cakelisp made it possible to implement hot-reloading entirely in "user-space", thanks to code modification.</p>
<h2 id="have-my-cake-and-eat-it-too.">"Have my cake and eat it too."</h2>
<p>By this I mean lose little-to-nothing on metrics I care about, which include build time, runtime performance, overall complexity, and various other things. I looked into several languages in my <a href="https://macoy.me/code/macoy/LanguageTests">LanguageTests</a> experiment and found they all had major drawbacks I couldn't accept.</p>
<h2 id="unexpected-freedom">Unexpected freedom</h2>
<p>I did not realize when I started Cakelisp how freeing it felt. All of the sudden, I got to decide what made sense to <em>me</em>, not what made sense to previous language designers.</p>
<h3 id="freedom-in-syntax">Freedom in syntax</h3>
<p>A simple example is type declarations. In C:</p>

<p>The same variable, in Cakelisp:</p>

<p>In my opinion C type declarations are much harder to parse than my explicit type declarations. You need to work backwards from the name to properly interpret the type. The parentheses do add more typing, but they're more clear, machine-parseable, and can be read naturally (e.g. read left to right "pointer to constant character" vs. C's "constant character pointer", which seems worse in my mind).</p>
<p>My form also handles arrays as part of the type: <code>(var my-array ([] 5 int))</code> rather than <code>int myArray[5];</code>, another way it is more consistent, readable, and parsable.</p>
<p>I chose to swap the order of name and type because it places more emphasis on the name. A well-written program will convey more useful information in the name than in the type, so it makes sense to me to have it come first for the reader.</p>
<h3 id="freedom-in-process">Freedom in process</h3>
<p>I also found that having an executable which preprocesses my code exactly how I want it opens the door to a huge amount of awesome features:</p>
<ul>
<li>Compile-time code execution. "Macros" and "Generators" are defined in-line with the rest of your code, making them feel like a natural part of your code. Defining them in-line makes it acceptable to add one-off macros, whereas adding such a thing to an external code generator would quickly become unmaintainable</li>
<li>Build optimization. A recent idea I discovered is automatically creating precompiled headers for large batches of 3rd-party headers. This would be a complex task that would need to be integrated in whatever build system you use, whereas Cakelisp can have it built-in</li>
<li>Other data processing. Compile-time code execution means you can do things like prepare assets, download 3rd-party code, run tests, etc. without having to set up all these additional tools</li>
</ul>

<p>I was inspired by Naughty Dog's use of <a href="https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp">Game Oriented Assembly Lisp</a>, GOOL, and <a href="https://www.youtube.com/watch?v=oSmqbnhHp1c">Racket/Scheme</a> (on their modern titles). I've also taken several ideas from Jonathan Blow's <a href="https://www.youtube.com/user/jblow888">talks on Jai</a>.</p>
<p>I'm a software engineer in the game industry. I've been working since July 2015 at a studio that makes cross-platform MMOs. The company has a custom engine written in C (with some C++).</p>
<p>I <a href="https://macoy.me/code/macoy/LanguageTests">experimented</a> with other languages before deciding I needed to write my own.</p>

<p>Now that my goals are clear, I will show you how I approached achieving them.</p>
<h2 id="notation">Notation</h2>
<p>Cakelisp uses an <a href="https://en.wikipedia.org/wiki/S-expression">S-expression</a>-style notation. Here is some Cakelisp code from <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame</a>:</p>

<p>There are a few things you can notice from reading this code:</p>
<ul>
<li>Types. Cakelisp is strongly- and explicitly-typed. I prefer reading code with explicit types because I can better imagine what the computer is actually doing, and what possibilities I have with each variable</li>
<li>Name-type order. I talked about this in a previous section. I wanted to emphasize the name of a variable for conveying meaning, especially when you may have many variables of the same type</li>
<li>Explicit <code>return</code>. I find I prefer code where return points are made explicit. Lisp will implicitly return the result of the last evaluation</li>
<li>Lisp-y style. The parentheses, plus keywords like <code>unless</code>, <code>defun</code>, <code>var</code>, <code>at</code>, and <code>incr</code>. I matched Lisp only when I didn't have strong opinions for a better notation. I am not trying to create something which is compatible with existing Lisps</li>
<li>C types and function calls. Cakelisp has seamless C interop, which means Cakelisp's "standard library" <em>is</em> C's standard library. No bindings had to be written to use the C types or make the function calls</li>
</ul>
<p>You can read more Cakelisp code in <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/src">Gamelib</a>.</p>
<p>You should think of Cakelisp more as "C in S-expressions" rather than "Lisp with C performance". If you know C, you'll have a relatively smooth transition to Cakelisp. If you only know Lisp, you're going to have a rougher time.</p>
<h3 id="why-s-expressions">Why S-expressions?</h3>
<p>When I set out to make Cakelisp, I decided on S-expressions syntax for several reasons:</p>
<ul>
<li>Parsability. S-expressions shift the burden of creating a syntax tree onto the programmer. This does result on more work for the human, but I value its extremely explicit nature. It also facilitates simpler tokenization, domain-specific-language implementation, and external tool support</li>
<li>Consistency. There are only four types of tokens in Cakelisp: open and close parenthesis, symbol, and string. The consistency is admittedly limiting, so things like paths (<code>myThing-&gt;member.member</code>) become much more verbose to type, unfortunately. However, this limitation keeps Cakelisp code parsable, and has an elegant feel that I appreciate</li>
</ul>
<p>I don't believe there is one notation to rule them all, especially after I've encountered the disadvantages of using S-exprs. I'm still happy with the decision though, and it does give Cakelisp a novel and distinguishing characteristic from the many …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macoy.me/blog/programming/CakelispIntro">https://macoy.me/blog/programming/CakelispIntro</a></em></p>]]>
            </description>
            <link>https://macoy.me/blog/programming/CakelispIntro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491568</guid>
            <pubDate>Mon, 21 Dec 2020 02:28:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PicoLisp Chess]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25491356">thread link</a>) | @simonpure
<br/>
December 20, 2020 | https://software-lab.de/chess/README | <a href="https://web.archive.org/web/*/https://software-lab.de/chess/README">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>|<n>|<b>|<q>|<k>|<b>|<n>|<r>|
      +---+---+---+---+---+---+---+---+
    7 |<p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|</p><p>|
      +---+---+---+---+---+---+---+---+
    6 |   | - |   | - |   | - |   | - |
      +---+---+---+---+---+---+---+---+
    5 | - |   | - |   | - |   | - |   |
      +---+---+---+---+---+---+---+---+
    4 |   | - |   | - |   | - |   | - |
      +---+---+---+---+---+---+---+---+
    3 | - |   | - |   | - |   | - |   |
      +---+---+---+---+---+---+---+---+
    2 | P | P | P | P | P | P | P | P |
      +---+---+---+---+---+---+---+---+
    1 | R | N | B | Q | K | B | N | R |
      +---+---+---+---+---+---+---+---+
        a   b   c   d   e   f   g   h

For a local installation, supply instead of "pil" the actual path like "./pil"
or "../pil21/pil".

The pieces are indicated by the letters 'K'ing, 'Q'ueen, 'R'ook, 'B'ishop,
k'N'ight and 'P'awn, with black pieces in angular brackets.

You can enter your moves with the field names (in lower case) for the "from" and
"to" positions:

: (go e2 e4)

Castling may be entered by just specifying the king's move:

: (go e1 g1)

To promote a pawn to some piece other than a queen, you can specify a class:

: (go h7 h8 +Knight)

To undo one or several moves, enter

: (go -)

and to redo them

: (go +)

To switch sides (and have the computer play against itself), call 'go' without
arguments:

: (go)

The initial board position can be restored with

: (main)

The global variable '*Depth' holds the maximal depth of the alpha-beta tree
search. It defaults to 5. You may change it to some smaller value for a faster
response, or to a larger value for a deeper search:

: (setq *Depth 7)

The same effect can be achieved by passing the desired depth as the first
argument to 'main':

: (main 7)

The second (optional) argument to 'main' is your color ('NIL' for white and 'T'
for black).

To setup some given board position, call 'main' with a list of triples, with
each describing:

   1. The field
   2. The piece's classes
   3. An optional flag to indicate that the piece did not move yet

: (main 5 NIL
   (quote
      (a2 (+White +Pawn) T)
      (b1 (+White +King))
      (d4 (+Black +King)) ) )
   +---+---+---+---+---+---+---+---+
 8 |   | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 7 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 6 |   | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 5 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 4 |   | - |   |<k>|   | - |   | - |
   +---+---+---+---+---+---+---+---+
 3 | - |   | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
 2 | P | - |   | - |   | - |   | - |
   +---+---+---+---+---+---+---+---+
 1 | - | K | - |   | - |   | - |   |
   +---+---+---+---+---+---+---+---+
     a   b   c   d   e   f   g   h

At any time, you can print the current board position in the above format to a
file with

: (ppos "file")

which later can be restored with

: (load "file")


   === PilBox and Web App ===

If you have the PilBox App installed on your Android device, just type "chess"
in the settings and press the "Download" button.

To start the Web application, use

   $ pil chess/main.l -chess~main -go +

Alternatively, you can start it with German localization as

   $ pil chess/main.l -'chess~main "DE" "de"' -go +

then point your browser to http://localhost:8080

In both cases you can interact with the chess board in this way:

   â€” To enter a move, drag a piece to the new field.
   â€” A click on the board does an auto-move and then switches sides.
   â€” The search depth can be changed with a drop-down menu.
   â€” The "New" button starts a new game, and the "Undo" and "Redo" buttons
     navigate in the history.
   â€” The text "White" or "Black" indicate who is to move next. It changes to
     "White ..." or "Black ..." while the computer is thinking.
   â€” After a move, the moved piece and the old and new positions are indicated
     above that text.

The "Setup" button switches to edit mode and allows you to change the position
manually:

   â€” A click on a piece removes it from the board.
   â€” Dragging a piece moves it to another field.
   â€” A new piece can be placed on the board by dragging it from the setup area.
   â€” The "Clear" button removes all pieces from the board.
   â€” The "New" button sets up all pieces for a new game.
   â€” The "Game" button switches back to play mode.

As in any PilBox app, you can go to the settings (wheel icon on top right) and

   â€” switch to another language in the "Language" tab or
   â€” view the App's source code by clicking on the app name "chess" in the
     "PILs" tab.


   === Credits and Copying ===

The pieces and board colors are from https://chessboardjs.com

The icon is from
   https://commons.m.wikimedia.org/wiki/File:Chess logo.PNG

(MIT/X11 License)
</k></p></r></n></b></k></q></b></n></div></div>]]>
            </description>
            <link>https://software-lab.de/chess/README</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491356</guid>
            <pubDate>Mon, 21 Dec 2020 01:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First release of quantum operating system, Deltaflow]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 42 (<a href="https://news.ycombinator.com/item?id=25490816">thread link</a>) | @kristianpaul
<br/>
December 20, 2020 | https://www.riverlane.com/news/2020/12/riverlane-release-first-version-of-quantum-operating-system-deltaflow-os/ | <a href="https://web.archive.org/web/*/https://www.riverlane.com/news/2020/12/riverlane-release-first-version-of-quantum-operating-system-deltaflow-os/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <div>
                <article>
                    

                    <div>
                        
                        <div>
                            <p>In May 2020, Riverlane revealed that they will lead a consortium which has been <a href="https://www.riverlane.com/news/2020/05/uk-companies-to-build-radically-new-operating-system-for-quantum-computers/">awarded a £7.6m grant to build a radically new operating system</a> for quantum computers. We marked a ‘hello world’ moment in September, with the first <a href="https://www.riverlane.com/news/2020/09/commercial-breakthrough-following-success-of-deltaflow-os-trials/">successful trials of Deltaflow.OS</a>, using quantum hardware belonging to leading trapped-ion company, <a href="https://www.oxionics.com/">Oxford Ionics</a>.</p>
<p>The latest milestone is the public release of the first version of Deltaflow.OS; ‘Deltaflow-on-ARTIQ’. The product has been built to enable quantum hardware companies as well as algorithm and app developers to accelerate their research by making collaboration easier and reduce down-time in labs. This version uses simulated hardware and <a href="http://m-labs.hk/experiment-control/artiq/">ARTIQ</a> as a backend. ARTIQ is a control system which is widely used in the trapped-ion community.</p>
<p>Deltaflow-on-ARTIQ consists of the Deltaflow language (Deltalanguage), and various hardware models on which the language can be run, including an emulator of the ARTIQ control system. The Deltalanguage lets users define a graph of different hardware nodes corresponding to the type of hardware elements found in labs. After defining a programme, users can test it on increasingly realistic hardware models.</p>
<p>Robert Jördens of M-Labs commented, “My hands are twitching because I really want to see and try that&nbsp;emulator and Deltaflow. There are so many valuable pieces in there.”</p>
<p>A first <a href="https://vimeo.com/480247763/d8fd4a0708">public demonstration of Deltaflow.OS</a> took place at the virtual National Quantum Technologies Showcase on 6 November 2020, where the team demonstrated how a Rabi-Oscillation would be performed.</p>
<p>The release of Deltaflow-on-ARTIQ marks a significant step towards Riverlane’s mission to build a quantum operating system that is high performance, portable across all qubit technologies and scalable to millions of qubits.</p>
<p>Access <a href="https://www.riverlane.com/products/">Deltaflow-on-ARTIQ</a></p>





                        </div>
                    </div>

                </article>
            </div>
        </section></div>]]>
            </description>
            <link>https://www.riverlane.com/news/2020/12/riverlane-release-first-version-of-quantum-operating-system-deltaflow-os/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25490816</guid>
            <pubDate>Mon, 21 Dec 2020 00:06:10 GMT</pubDate>
        </item>
    </channel>
</rss>
