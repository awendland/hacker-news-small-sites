<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 05 Oct 2020 01:07:05 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 05 Oct 2020 01:07:05 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Reverse Engineering a North Korean Sim City Game]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24670827">thread link</a>) | @pcr910303
<br/>
October 3, 2020 | https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/ | <a href="https://web.archive.org/web/*/https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-371">
	<!-- .entry-header -->

	<div>
		<p><em>Reverse engineering the North Korean version of a popular Sim City-like game using Ghidra and ndSpy to understand video game monetization strategies in the DPRK and the marketization of the country’s economy. </em></p><p><em>Key takeaways:</em></p><p><em>
<li>Android devices and applications are increasingly common in North Korea. Physical “app stores” can be found on every street corner in Pyongyang.</li>
<li>The game considered in this post is based on a Chinese version of a popular Android game developed in the Netherlands</li>
<li>The game’s monetization strategy was adapted to the country’s infrastructure (low internet/intranet availability, physical app stores)</li>
<li>The North Korean version eschews the original freemium + online microtransaction model for a one-time licence purchase + offline microtransaction model</li>
<li>File integrity checks added by North Korean developers shows that piracy is a concern and suggests the existence a warez/cracking scene in the DPRK</li>
<li>The cryptographic algorithms used for the licence are MD5, SHA1, RSA and AES. The library used by the game included the domestically developed private key algorithms Pilsung and Jipsam, but they were not used as part of the licencing system</li></em></p><p><a href="#intro">0. Introduction</a><br>
<a href="#licence">1. Licensing system</a><br>
<a href="#check">2. File integrity checks</a><br>
<a href="#money">3. In-game monetization strategy and key generation</a><br>
<a href="#end">4. Conclusion</a></p>
<h4 id="intro">0. Introduction </h4><p>During a recent trip to North Korea, I noticed the recent and ubiquitous presence of <em>Information Technology Exchange Rooms</em> (정보기술교류실), physical stores where one can purchase a variety of electronic devices – from laptops and tablets to USB sticks and chargers – as well as software and video games for PC, mobile and tablets (for an in-depth look at what goes on inside those stores as well as what the app selection looks like, <a href="https://www.nknews.org/2019/02/what-to-buy-inside-a-north-korean-app-store/">this article</a> by Alek Sigley provides a an excellent description. There are also a few <a href="https://www.youtube.com/watch?v=1ujblnigJmM">videos</a> on YouTube). After looking through the catalogue of available games at different stores, I eventually decided to try and buy a Sim City-like game called <em>City Management</em> (도시경경).</p>
<figure id="attachment_426"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png" alt="" width="845" height="760"></a><figcaption>Billboards for various app stores in Pyongyang</figcaption></figure><p>The game only cost 5000 wons (less than 1 USD) which I paid to have the app installed on the phone I had, a Samsung Galaxy A5 running Android 8. The vendor connected the phone to his PC, transferred the APK and tried to install it, but to no avail. After multiple attempts, he eventually informed me that North Korean apps most likely could not run on phones from other countries. </p>
<figure id="attachment_428"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png" alt="" width="551" height="827"></a><figcaption>Advertisement for a car racing game inside a North Korean app store</figcaption></figure><p>Fortunately, I was later able to purchase one of the different tablets sold in North Korea. I got the <em>Morning</em> (아침) brand, which is geared towards students and quite affordable. The tablet ran Android 4 (Kit Kat) on an ARM cpu and came loaded with a few educational apps: language learning courses, dictionaries and several e-book libraries containing the complete works of Kim Il Sung, school textbooks and a collection of literary works. No games, but that could now be fixed quite easily.</p>
<figure id="attachment_431"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png" alt="" width="800" height="490"></a><figcaption>A North Korean Ach’im (Morning) tablet</figcaption></figure><p>I retrieved the <em>City Management</em> APK from my phone and installed it on the tablet, where it ran perfectly. Unfortunately, after the game’s initial splash screen, I landed on this:</p>
<figure id="attachment_434"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png" alt="" width="1024" height="600"></a><figcaption>Licence key needed</figcaption></figure><p>The screen tells us that there is no “key file” (열쇠화일) and that we should purchase one at a store. There is a “request number” (요청번호) likely used to generate the licence key and make sure it can’t be shared with other devices. Unfortunately, since the APK never installed, the vendor did not put a licence file on my phone when I bought the app. My stay in North Korea was coming to an end too and I did not have time to go back to an app store to buy a new key. So I figured I would take a look inside the app and see if I could get it running nonetheless. </p>
<hr id="licence">
<h4>1. Licensing system </h4><p>To start looking into the APK’s code, I’ll use the standard suite of tools to decompress, decompile and rebuild android apps: <a href="https://sourceforge.net/projects/dex2jar/">dex2jar</a>, <a href="http://java-decompiler.github.io/">jd-gui</a>, <a href="https://ibotpeaches.github.io/Apktool/install/">apktool</a> and <a href="https://github.com/appium/sign">apksign</a>. I’ll also use <a href="https://developer.android.com/studio">Android Studio</a> to run and debug the app. The fact that I couldn’t run the app on my phone may have just come from an Android version compatibility issue: I had no problem running it on an emulated Android 4.4 device with Android Studio. The decompilation of the <code>classes.dex</code> file gives us some interesting information right away:</p>
<figure id="attachment_438"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png" alt="" width="211" height="326"></a><figcaption>Packages and classes from the decompiled <code>classes.dex</code> file</figcaption></figure><p>The name of the <code>com.bz.cityisland2</code> package actually refers to the original game that <em>City Management</em> is based on: <a href="https://www.sparklingsociety.net/sparkling-games/city-building-games/city-island-2/">City Island 2</a> by the Dutch game studio Sparkling Society. The name of the package <code>com.smartions.appprotected</code> refers to <a href="https://www.crunchbase.com/organization/smartions-ag#section-overview">Smartions</a>, a company that offers solutions to “monetize your mobile game or app in China” and are apparently also City Island’s <a href="https://en.wikipedia.org/wiki/Sparkling_Society">distributor in China</a>. There are no mentions of those companies in the game itself however. The game’s loading splash screen only tells us that the game was made by the Ryusong (meteor) Technology Exchange Center (류성기술교류소) and that it is protected by the law for the protection of software (<a href="https://www.kisdi.re.kr/kisdi/common/premium?file=1%7C10360">콤퓨터쏘프트웨어보호법</a>). The law has been in place since 2003 to regulate the sales and distribution of software in the country and guarantees software developers the private ownership of their creation.</p>
<figure id="attachment_502"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png" alt="" width="1000" height="640"></a><figcaption>Loading screen for the game</figcaption></figure><p>It’s hard to tell whether the North Korean version is based on the source code of the original game or if it’s entirely reverse engineered. In any case, the North Korean version does not use Smartions’s monetization system nor Sparkling Society’s but relies on a different system, which is the main difference from the original game. Save for the translation and some minor renames, the game is otherwise similar to the original (from a cursory examination) in its design, gameplay, features… to the original. </p>
<figure id="attachment_442"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png" alt="" width="339" height="221"></a><figcaption>Structure a Unity APK. From Shim et al., <a href="https://www.hindawi.com/journals/scn/2018/6280768/"><em>Static and Dynamic Analysis of Android Malware and Goodware Written with Unity Framework</em></a> (2018).<br></figcaption></figure><p>There’s not much more we can glean from the Java code for now since, as the classes in <code>unity3dplayer</code> and <code>AndroidManifest.xml</code> file make clear, it is used to run code that was written with <a href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity</a>, a popular cross-plaform video game framework which uses C# as its main programming language. The Unity code is stored in various library with the developer’s C# code being compiled to <code>Assembly-CSharp.dll</code>. C# compiled code is easily decompilable using tools such as <a href="https://github.com/0xd4d/dnSpy">dnSpy</a>. Once the dll is decompiled, we can look for the message we got earlier “열쇠화일이 존재하지 않습니다” (“The key file does not exist”) to find the bits of code we are interested in. The string search takes us to the <code>CIGLoadingScreen</code> class where we find the string among other variables:</p>
<pre title="">
	// Token: 0x0400056A RID: 1386
	private string userKey;

	// Token: 0x0400056B RID: 1387
	private string tapjoyCurrencyIdentifier;

	// Token: 0x0400056C RID: 1388
	private bool bannerVisible;

	// Token: 0x0400056D RID: 1389
	private int _loadingScreenShownCount;

	// Token: 0x0400056E RID: 1390
	private Dictionary&lt;int, bool&gt; m_gameObjectStatus = new Dictionary&lt;int, bool&gt;();

	// Token: 0x0400056F RID: 1391
	private bool m_isVerify;

	// Token: 0x04000570 RID: 1392
	private Font kfont;

	// Token: 0x04000571 RID: 1393
	private string reqMsg = "열쇠화일이 존재하지 않습니다.\r\n열쇠화일을 판매소에서 구입하십시오.";

	// Token: 0x04000572 RID: 1394
	private string reqNumLabel = "요청번호 : ";

	// Token: 0x04000573 RID: 1395
	private string reqNum;

	// Token: 0x04000574 RID: 1396
	private string finishLabel = "끝내기";
</pre><p>Looking for the name of the string variable <code>reqMsg</code> takes us here:</p>
<pre title="">	// Token: 0x06000928 RID: 2344 RVA: 0x00026E60 File Offset: 0x00025060
	private void OnGUI()
	{
		if (!this.m_isVerify &amp;&amp; this.loadingDone)
		{
			GUI.skin.font = this.kfont;
			GUI.DrawTexture(new Rect(0f, 0f, (float)Screen.width, (float)Screen.height), this.blackBg, ScaleMode.StretchToFill);
			GUI.Label(this.GetTextLabelRect(this.reqMsg, 0.5f, 0.3f), this.reqMsg);
			GUI.Label(this.GetTextLabelRect(this.reqNumLabel, 0.3f, 0.5f), this.reqNumLabel);
			GUI.Label(this.GetTextLabelRect(this.reqNum, 0.6f, 0.5f), this.reqNum);
			RectOffset padding = GUI.skin.button.padding;
			GUI.skin.button.padding = new RectOffset(20, 20, 10, 10);
			if (GUI.Button(this.GetButtonRect(this.finishLabel, 0.5f, 0.8f), this.finishLabel))
			{
				Application.Quit();
			}
		}
	}
</pre><p>This is the code used to display the splashscreen we encountered earlier. If the boolean property <code>this.m_isVerify</code>, presumably the result of a call to a function checking the existence and validity of a licence key, is <code>False</code> then, the screen is displayed with the message we saw earlier and the “request number”. The verification function and the generation of the request number are handled in another class <code>GameCus</code>:</p>
<pre title="">using System;
using System.IO;
using System.Runtime.InteropServices;

// Token: 0x02000147 RID: 327
public class GameCus
{
	// Token: 0x06000AA7 RID: 2727
	[DllImport("Game")]
	private static extern int vProcess(byte[] key, int keyLen, byte[] certData, int certDataLen);

	// Token: 0x06000AA9 RID: 2729 RVA: 0x0002E910 File Offset: 0x0002CB10
	public string GetReqNumber()
	{
		string deviceIdString = this.GetDeviceIdString();
		return string.Format("{0:d4} {1:d4} {2:d4} {3:d4}", new object[]
		{
			deviceIdString.Substring(0, 4),
			deviceIdString.Substring(4, 4),
			deviceIdString.Substring(8, 4),
			deviceIdString.Substring(12, 4)
		});
	}

	// Token: 0x06000AAA RID: 2730 RVA: 0x0002E968 File Offset: 0x0002CB68
	public string GetDeviceIdString()
	{
		string text = Utils.GetDeviceModel();
		text = string.Format("{0:d10}", (uint)text.GetHashCode());
		string str = text.Substring(2, 8);
		string text2 = Utils.GetDeviceUid();
		text2 = string.Format("{0:d10}", (uint)text2.GetHashCode());
		string str2 = text2.Substring(2, 8);
		return str + str2;
	}

	// Token: 0x06000AAB RID: 2731 RVA: 0x0002E9CC File Offset: 0x0002CBCC
	public bool checkCertData(byte[] certData)
	{
		if (certData == null || certData.Length == 0)
		{
			return false;
		}
		string text = this.GetDeviceIdString() + …</pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</a></em></p>]]>
            </description>
            <link>https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670827</guid>
            <pubDate>Sat, 03 Oct 2020 09:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is the market share of Firefox in Germany so much higher?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24670605">thread link</a>) | @jlelse
<br/>
October 3, 2020 | https://jlelse.blog/posts/firefox-market-share/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/posts/firefox-market-share/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently took a closer look at Cloudflare’s new project <a href="https://radar.cloudflare.com/" target="_blank" rel="noopener">Radar</a>. Besides statistics about internet usage, attacks and popular domains, the site also shows statistics about the market shares of browsers.</p><p>Here is an overview of the global statistics:</p><p><a href="https://media.jlelse.blog/eb2cc6b3a4f116777f08594989bc16b4376a10b159e2c9d9ccc93080fb077631.png"><img src="https://media.jlelse.blog/eb2cc6b3a4f116777f08594989bc16b4376a10b159e2c9d9ccc93080fb077631.png" loading="lazy" alt="Global top browsers" title="Global top browsers"></a></p><p>Here the distribution in the USA:</p><p><a href="https://media.jlelse.blog/172293b33c412050c263e9a5eff0062158c509b58e40c3da31447199e304a871.png"><img src="https://media.jlelse.blog/172293b33c412050c263e9a5eff0062158c509b58e40c3da31447199e304a871.png" loading="lazy" alt="Top browsers in the USA" title="Top browsers in the USA"></a></p><p>And here in Germany:</p><p><a href="https://media.jlelse.blog/fb2e26d1aafda14d14b0affe91b35c6e531669632b3aa7cad1de3276130dd795.png"><img src="https://media.jlelse.blog/fb2e26d1aafda14d14b0affe91b35c6e531669632b3aa7cad1de3276130dd795.png" loading="lazy" alt="Top browsers in Germany" title="Top browsers in Germany"></a></p><p>When comparing the statistics, I notice a few interesting things:</p><ul><li>In the USA as well as in Germany the usage of Firefox is higher than the world average. In Germany, however, it is much higher, instead of only about 7%, the share of Firefox in Germany is almost 21%.</li><li>The use of Safari (iOS and desktop) in the USA is significantly higher than the world average and in Germany.</li><li>However, Chrome (mobile) and Samsung Internet have higher shares in Germany than in the USA. But Chrome (mobile) in Germany still has less than worldwide.</li></ul><p>The higher share of Safari in the USA can probably be explained relatively by the higher market share of Apple in the USA. While many people in Germany tend to rely more on Android smartphones (and Windows PCs), the iPhone (and Mac) share is significantly higher in the USA. Here are <a href="https://www.statista.com/statistics/461900/android-vs-ios-market-share-in-smartphone-sales-germany/" target="_blank" rel="noopener">some</a> <a href="https://www.statista.com/statistics/1150677/us-market-share-held-by-leading-smartphone-vendors/" target="_blank" rel="noopener">statistics</a> on this.</p><p>This different distribution naturally also affects the other mobile browsers. In Germany many people seem to use Samsung smartphones and the pre-installed browser Samsung Internet.</p><p>What I can’t quite explain is the high percentage of Firefox in Germany. Are people in Germany more critical of Google? I somehow don’t believe that…</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/posts/firefox-market-share/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670605</guid>
            <pubDate>Sat, 03 Oct 2020 08:53:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Honest Review of Gatsby]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24670252">thread link</a>) | @ehfeng
<br/>
October 3, 2020 | https://cra.mr/an-honest-review-of-gatsby/ | <a href="https://web.archive.org/web/*/https://cra.mr/an-honest-review-of-gatsby/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We decided to adopt Gatsby for <a href="https://docs.sentry.io/">Sentry’s customer-facing documentation</a> - well, I should say that <em>I</em> decided. We were already using it successfully for a variety of static marketing content, and I knew it had a lot of hype, so after a brief proof-of-concept it seemed like a safe choice.</p>
<p>To help contextualize everything I’m about to say, it’s important to understand the scope of our usage. Sentry’s documentation is not as straightforward as you might think - in fact, there are over 3,000 pages as of writing. We have a large amount of templated content designed to render language-specific examples, as well as a variety of different types of documentation (user guides, help desk-y articles, code-rich technical docs). Originally we had extended Jekyll to support a lot of this, but Ruby isn’t widely used at Sentry (approximately 0% of the engineering team knows Ruby), and it had become a big mess of spaghetti code with slow build times.</p>
<p>I also want to note that while this blog post is primarily focusing on the flaws of Gatsby as a framework, I’m not here to tell you that it’s not good for your use case. That said, I was not able to discover many of these short comings easily when evaluating Gatsby, and many things you read on the internet don’t stem out of real-world usage. My hope here is that Gatsby continues to improve over time, and that, as a user, you can be more informed about if it’s the right choice for you.</p>
<h2>Adopting Gatsby</h2>
<p>So, enter Gatsby. It seemed fast, was built on React (we’re experts on that here, with our gigabyte-sized Sentry frontend app), and had a huge adoption (assumed future existence and stability). While we didn’t have the desire to use MDX, it also seemed like a positive outcome given we could more easily deal with some of the rich aspects of our docs site, without having to resort to 2010-era JavaScript. We assumed a bunch of the other features of Gatsby had value-add, but we didn’t have an immediate need. These were things like dynamic source data - thus the need for a GraphQL engine at all - as well as the large plug-in ecosystem.</p>
<p>We started by iteratively converting sections of the Jekyll site into Gatsby - running them side by side for a time. At one point we eventually bulk converted pages, and ripped off the band aid. At this point though it was becoming clear build times were a problem. You’d spend at least 5 minutes on image optimization alone, with no way to even disable that. Slowly but surely we were depleting the ozone later on re-optimizing images which had already been pre-optimized. Oh yeah, and we were crippling our iteration speed as well, since the build cache would invalidate under a variety of situations in early development.</p>
<p>Making this worse was how we deployed Gatsby. We started off leveraging what we had already done: deploying Jekyll with Docker onto our own infrastructure - effectively just proxied via a CDN. We continued that for a period of time, but deploy times were far too long - upwards of 30-40 minutes for everything to build. Eventually we moved over to <a href="https://vercel.com/">Vercel</a> which dropped it down closer to 10 minutes, but ultimately it can’t fix what it doesn’t control.</p>
<p>The build and deploy times were the first of many woes, and they represent what would become a continued frustration: a problem without a clear solution.</p>
<h2>Enter MDX</h2>
<p>Rewind time a little bit - this actually wasn’t our first project converting documentation to Gatsby. The proof-of-concept I mentioned earlier was actually our <a href="https://develop.sentry.dev/">developer documentation</a>, which I had migrated out of Notion to make public. While doing that we had gotten our hands dirty with some initial MDX usability and extensions - like our code samples which support toggling between different languages. This was one of the many things we needed to solve for, but MDX made it look like it’d be seemingly easy. No more jQuery DOM manipulation, just clean, encapsulated React components. Or so we thought.</p>
<p>Almost immediately we hit rough spots with MDX. We were coming from Jekyll - which was Liquid-rendered (a template engine) markdown - to MDX - a strange offspring of Markdown and JSX, attempting all of the benefits of both, but missing by a fairly large margin. Let’s illustrate the crux of the issue with what has got to be one of the most common needs in a documentation system: an alert (or callout) component:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>info<span>"</span></span><span>&gt;</span></span>You should know something important about this!<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>At face value this looks great. <code>Alert</code> is just a React component, and JSX is close enough to HTML that non-technical folks are able to pick it up fairly easily. Now the problem comes into play when you actually want to do something in the real world. Here’s an example from our API docs:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span>
    <span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.
<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>How would you expect this to render? Both as an engineer and a non-engineer, I would expect - given this is markdown - that the “PUT/DELETE” text would be bold. It’s not. Because the MDX interpreter decides that once you enter a component block, it’s no longer markdown. So instead, we’re forced with this monstrosity <em>everywhere</em> in our documentation:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;</span>markdown</span><span>&gt;</span></span>

<span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.

<span><span><span>&lt;/</span>markdown</span><span>&gt;</span></span><span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>There’s two things you should note here: 1) we have to use this <code>&lt;markdown&gt;</code> tag, 2) we have to put empty new-lines to ensure paragraph tags render.</p>
<p>“But David”, you might say, “why don’t you just tell the <code>Alert</code> component to render the text as markdown?“. If only you could, or at least, if only I could have possibly found a way to achieve that as a user with minimal Gatsby or MDX internals knowledge.</p>
<p>To Gatsby, or at least to the MDX team’s credit, they recognize some of these problems and <a href="https://github.com/mdx-js/mdx/issues/1041">there is work underway</a> on a 2.0 of the MDX dialect. While I’m confident they will improve things, I’m not confident MDX can ultimately succeed. It’s likely going to tradeoff one problem for another due to what it’s trying to achieve in the first place. It may get to a good place, but frankly, we need to step back and look at what we’re trying to solve, instead of creating a solution to a problem we don’t have. I don’t need JSX syntax in my markdown, I need a way to include JSX components. That might sound similar, but its quite a different thing.</p>
<p>As an example, there’s no reason I couldn’t simply use markdown syntax, and provide a way to achieve something akin to:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>a-valid-html-tag-because-markdown-allows-that</span> <span>a-valid-property</span><span><span>=</span><span>"</span>a-value<span>"</span></span><span>&gt;</span></span></code></pre></div>
<p>This wouldn’t force us to work around quirks in a new language (or interpreter even), and could be solved in a much more sustainable way. There are other alternatives as well. A generic way to render extensions in markdown could simply call into a React component, and avoid even trying to hijack HTML in the first place. While I don’t know what this might look like in Markdown, in <a href="https://www.sphinx-doc.org/en/master/usage/restructuredtext/index.html">Sphinx’s use of reStructuredText</a> this was solved early on with Directives:</p>
<div data-language="text"><pre><code>.. my-directive:: some data
   :property-name: property-value</code></pre></div>
<p>I will hold out for MDX 2.0 and hope that finds a nice minimal-compromise place, but if not, we’ll be looking for a way to extend native markdown.</p>
<h2>A Broken DOM</h2>
<p>While we were able to work around the kinks of MDX, there’s been some things not yet solved. One of those is the layer which Gatsby uses to apply diffs to the DOM. I’m going to caveat this section with <em>I don’t know what the technical implementation is</em>, but I can make some assumptions given what I know of the domain. The system itself is intended to apply deltas to the DOM. This is naively also how React works, and I imagine under the hood it’s relying on React at least for part of it. We’ve had issues with this identified in two places already:</p>
<ul>
<li>progressive image loading</li>
<li>dynamic JSX components</li>
</ul>
<p>While they might not be linked to the same issue, they smell like they are, so we’re going to roll with it. The problem exhibits itself when you have a bunch of DOM that to a naive robot might look the same:</p>
<div data-language="text"><pre><code>&lt;div&gt;foo&lt;/div&gt;
&lt;div&gt;bar&lt;/div&gt;
&lt;div&gt;baz&lt;/div&gt;
&lt;div&gt;foobizbar&lt;/div&gt;</code></pre></div>
<p>In React it uses the graph to identify which node is which - effectively creating a unique entity ID based on its location. In cases where that’s difficult, React will warn you to explicitly bind a <code>key</code> attribute on each element to ensure it can more accurately deal with updates. While I would assume Gatsby is at least partially using React’s DOM engine, what we see in production effectively takes the above example, and replaces some of the content with other subsets of content - meaning it’s unable to accurately identify which nodes need updated.</p>
<p>We’ve seen this where a progressive image is replaced with an entirely different image that’s present near it on the page. We’ve also seen this happen for a dynamically loaded section of content (our language-selector include tags). While we’ve yet to identify a fix for the image tags, our other issue was resolved by literally changing a <code>div</code> tag to a different tag, one which is less commonly used (in our case, <code>section</code>).</p>
<p>All of the cases happen after Gatsby’s initial static render and exist only when applying some form of delta.</p>
<h2>Let’s Talk GraphQL</h2>
<p>It’s a static website generator. It literally does not need GraphQL all over the place. While there are few instances in the real world where that is valuable, it shouldn’t require a GraphQL API to read objects that are already in memory.</p>
<p>I don’t want to spend the energy to hammer this in, but take a look at Jared Palmer’s <a href="https://jaredpalmer.com/gatsby-vs-nextjs">Gatsby vs. Next.js</a> as it echoes my thoughts.</p>
<p>So, let’s actually not talk about GraphQL, but all its done is create complexity for us.</p>
<h2>Minor Gripes</h2>
<p>There’s a number of other things we’ve found fairly frustrating at this point, but this post is already getting long, so I’m choosing to summarize them.</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cra.mr/an-honest-review-of-gatsby/">https://cra.mr/an-honest-review-of-gatsby/</a></em></p>]]>
            </description>
            <link>https://cra.mr/an-honest-review-of-gatsby/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670252</guid>
            <pubDate>Sat, 03 Oct 2020 07:18:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Starter Kit 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24669220">thread link</a>) | @todsacerdoti
<br/>
October 2, 2020 | https://wiki.alopex.li/RustStarterKit2020 | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/RustStarterKit2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>People were arguing about Rust’s std lib recently, so I went through the <code>Cargo.toml</code> of all the Rust projects I’ve written since 2015 and picked out the choice tools that get used over and over again. Up to date as of October 2020.</p>
<p>Also see <a href="https://wiki.alopex.li/RustCrates" title="Go to wiki page">RustCrates</a>, though that’s old. There’s also <a href="https://christine.website/blog/rust-crates-go-stdlib-2020-09-27">this</a>, which is narrower but deeper, and <a href="https://github.com/rust-unofficial/awesome-rust">awesome-rust</a>, which is shallower and broader, and the various <a href="https://www.arewewebyet.org/">more</a> <a href="https://arewegameyet.rs/">specific</a> <a href="https://areweasyncyet.rs/">websites</a> <a href="https://www.areweguiyet.com/">for various</a> <a href="https://areweideyet.com/">topics</a>.</p>

<p>I need to set up a new Rust dev environment, what do I install?</p>
<h2 id="linting-clippy">Linting – <code>clippy</code></h2>
<p>The one, the only, the great Rust style and correctness linter. Want to learn how to write “idiomatic” Rust, or just learn more about handy little corners of the language and library? Run <code>clippy</code> regularly. It’s distributed with the compiler via <code>rustup</code> now, so you have no excuse not to.</p>
<h2 id="build-cache-sccache">Build cache – <code>sccache</code></h2>
<p>Or, “how to make a full rebuild 70% faster”. <code>sccache</code> is a build artifact cache similar to <code>icecream</code> or <code>ccache</code>, except it’s actually trivial to just use. <code>cargo install sccache</code>, add a single line in a home dir config file, and you’re ready to go. Pretty much handles most crate and compiler versioning issues for you, so it Just Works if you update crates or install a new version of <code>rustc</code> or something. I think I’ve had to force-clear the cache due to some build weirdness a grand total of once. Looks like it has enough features to use in a professional context as well, at least on a small-to-medium scale.</p>
<h2 id="dependency-viewer-cargo-tree">Dependency viewer – <code>cargo-tree</code></h2>
<p>The best way to view what dependencies you are using, and what dependencies they are using, and so on. Best way to start cracking down on flabby dependencies.</p>
<h2 id="benchmarking-criterion">Benchmarking – <code>criterion</code></h2>
<p>Basically the best benchmark system out there. Incredibly simple to use, informative, and statistically sound. Doesn’t really do profiling, but it’s a good start for understanding your program’s performance, and better for proving that your implementation of X is faster than someone else’s.</p>
<h2 id="other-things">Other things</h2>
<p>Stuff that is less general purpose but occasionally very useful for the meta-programming process of choosing libraries, evaluating them, etc.</p>
<ul>
<li><code>cargo-geiger</code> – Measures how much unsafe code is in a codebase, and its dependencies</li>
<li><code>cargo-crev</code> – A <a href="https://wiki.alopex.li/ActuallyUsingCrev">very neat tool</a> for authoring and verifying distributed code reviews.</li>
<li>Various tools maintained by <a href="https://github.com/EmbarkStudios/rust-ecosystem">Embark Studios</a>, useful for production/company purposes like checking licenses, pinning specific versions of crates, etc.</li>
</ul>

<p>The cool stuff Real Computer Scientists write about.</p>
<h2 id="hashing">Hashing</h2>
<p>No specific crates here. There’s no single crate that provides All The Hash Algorithms, just lots of little ones that generally provide a single algorithm each. Just type the name of the algorithm you want into <code>crates.io</code> and you’ll get at least a couple options, choose the one with 8 million downloads or whatever. <code>sha2</code>, <code>md5</code>, <code>crc</code>, etc. Lots of them are written by the Rust core team.</p>
<h2 id="compression">Compression</h2>
<p>Same as the hashing category. Type <code>zip</code> or <code>bzip2</code> or whatever into crates.io and you’ll get what you need. <code>flate2</code> might be the one crate that’s not quite trivial to find. Again, many of them are written by the Rust core team.</p>
<h2 id="encryption">Encryption</h2>
<p>I have little actual experience or authority on this topic, so I’m going to punt on this one.</p>
<h2 id="pseudorandom-number-generator">Pseudorandom number generator</h2>
<p>Use <code>oorandom</code>. (Disclaimer, I wrote <code>oorandom</code>, but people besides me seem to like it.) More usually you’ll see the <code>rand</code> crate in use. If you’re doing Real Science and need to generate <a href="https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html">fancy probabilities</a>, then <code>rand</code> is the right tool, but most people aren’t doing that. Otherwise <code>rand</code> is complicated and has lots of features, while <code>oorandom</code> is very simple and has about two features, and I expect 80% of code to use at least one of them. <code>rand</code> has had several major breaking changes in its history that the rest of the ecosystem still hasn’t caught up with, while I intend <code>oorandom</code>’s API to change maybe twice in my lifetime. (Its version number, while obeying semver, is mostly a joke.)</p>
<p>There’s other lightweight PRNG crates that are just fine; see <code>oorandom</code>’s readme for a list of some others and choose one you like. Whatever you choose, use the <code>getrandom</code> crate to produce Real Random Seeds for it.</p>

<p>“I just need to solve this ooooooone common problem, but it needs to be solved WELL…”</p>
<h2 id="logging-log">Logging – <code>log</code></h2>
<p>Need to output log messages in your code? Why, use the <code>log</code> crate. Where do the log messages go? <code>log</code> provides only an interface, and that interface compiles to nothing if it isn’t used. You can write your own system for it to actually output the logs to, which is pretty easy, or use one of the small plethora of crates for it. My preferred one is <code>pretty_env_logger</code>, but <code>fern</code>, <code>slog</code> and others are all good too.</p>
<h2 id="parallel-data-crunching-rayon">Parallel data crunching – <code>rayon</code></h2>
<p>Ever have some computation where you have a big list of STUFF and want to process it in parallel, farming out jobs to as many threads as you have CPU’s? That’s what <code>rayon</code> does, and it does it really, really well. You still <a href="https://aspenuwu.me/posts/rust-optimization.html">have to know what you’re doing</a>, but changing a single <code>.iter()</code> into <code>.par_iter()</code> and watching your CPU-bound data-crunching run 8x faster is pretty magical. Now your CPU can help keep you warm this winter!</p>
<p>Please never use it in a library. It’s rude to spawn threads in library code, unless that’s specifically what the library is for.</p>
<h2 id="regexes-regex">Regexes – <code>regex</code></h2>
<p>To quote the inestimable <a href="https://www.jwz.org/blog/">jwz</a>:</p>
<blockquote>
<p>Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.</p>
</blockquote>
<p>On the other hand, <a href="https://xkcd.com/208/">somebody’s gotta save the day</a>. So, use the <code>regex</code> crate. Also use <a href="https://crates.io/crates/ripgrep">anything else</a> <a href="https://crates.io/crates/xsv">written by BurntSushi</a>. BurntSushi is a paragon of Rust program design, and also just a great <del>human being</del> charred cuisine in general.</p>
<h2 id="threadsafe-globals-lazy_static">Threadsafe globals – <code>lazy_static</code></h2>
<p>“I know globals are evil,” you say, “but I just need one. I’ll only use it for good, I promise.” <code>lazy_static</code> has your back.</p>
<p>May eventually be superseded by <code>once_cell</code>, which looks like its <a href="https://github.com/rust-lang/rfcs/pull/2788">headed for inclusion into <code>std</code></a>.</p>
<h2 id="serializationdeserialization-serde">Serialization/deserialization – <code>serde</code></h2>
<p>Ever have a struct and just wanted to turn it into JSON, CBOR, XML, or some other engine of woe and devastation designed to be written to an I/O stream? Or had a blob of random JSON and wanted to just stuff it into a struct matching it? Sure you have. <code>serde</code> lets you do this with a single <code>#[derive]</code>. <code>serde</code> is without a doubt one of Rust’s killer libraries. It is better than any other serialization system I have ever used.</p>
<p>What data formats does it support? Anything; the actual reading and writing is done via plugin library. There’s a <a href="https://serde.rs/#data-formats">wide selection of them</a>, of varying quality, and writing your own is a little tedious but not terribly difficult.</p>
<h2 id="error-handling">Error handling</h2>
<p>This spot deliberately left blank.</p>
<p>Rust’s <code>Result&lt;T,E&gt;</code> type is one of the best setups for lightweight, transparent error handling I’ve seen, but it doesn’t do everything. How do you easily write your own error type without a bunch of boilerplate? What if you have multiple different error types from different libraries you want to coalesce together? How do you collect a backtrace of every function an <code>Err</code> is returned through, so you can find the root cause of where it came from? Can we do all this without allocating anything unnecessarily? And so on.</p>
<p>There have been various crates to try to solve these problems. First in 2015 there was <code>error_chain</code>, which was complicated and not very convenient. Then in 2017 there was <code>failure</code>, which was simpler but not very flexible, and which took an irritatingly long time to compile. Then in 2019 there was <code>anyhow</code>, which was about the time I stopped paying attention. Now apparently the new kid on the block is <code>eyre</code>, and I’m sure that in another year or two there will be something else.</p>
<p>So, I just write the boilerplate and make my errors descriptive enough I don’t need a backtrace. When I want to get fancy I implement the built-in <a href="https://doc.rust-lang.org/std/error/trait.Error.html"><code>Error</code></a> trait, which used to be kinda useless but is now more helpful. And in another five years it’ll still work just fine.</p>
<h2 id="byte-mucking-bytemuck">Byte mucking – <code>bytemuck</code></h2>
<p>For the rare occasions you need to turn a structure into arbitrary <code>&amp;[u8]</code> or back. Doing this using unsafe pointers is quite easy, and also makes it very easy to screw up horribly with Undefined Behavior galore. (Did you know that changing the value of padding bytes in a struct in UB? You do now.) <code>bytemuck</code> lets you muck around with bytes a little more responsibly.</p>
<h2 id="human-dates-and-times-chrono">Human dates and times – <code>chrono</code></h2>
<p>Rust’s <code>std::time</code> doesn’t really handle calendar or wall-clock times, just arbitrary, monotonic <code>Instant</code>’s and measurable <code>Duration</code>’s between them. Nice, pure, computationally-robust time measurement. For all the nasty human calendar and timezone stuff, you use <code>chrono</code>. (And maybe <code>humantime</code>, but I personally reach for <code>chrono</code> first, just out of habit.)</p>
<h2 id="bit-flags-bitflags">Bit flags – <code>bitflags</code></h2>
<p>Defining type-safe bit-masks in a reasonably convenient way. Not always worth the trouble, but sometimes pretty convenient.</p>

<p>“I have to create or read a…”</p>
<h2 id="pngjpeggifetc-image">PNG/JPEG/GIF/etc – <code>image</code></h2>
<p>General-purpose loading and saving and images, which can handle a lot of formats. Can do some amount of image manipulation as well, such as cropping, smoothing, etc. but that will hopefully be pulled out into its own library at some point soon.</p>
<h2 id="small-data-things-uuid-base64-csv-semver">Small data THINGS – <code>uuid</code>, <code>base64</code>, <code>csv</code>, <code>semver</code>…</h2>
<p>Exactly what it says on the tin.</p>

<p>Not aware of any great encoders, but there’s plenty of <em>decoders</em> for common audio formats. <code>lewton</code> for Ogg Vorbis, <code>hound</code> for .wav, <code>minimp3</code> for MP3, <code>claxon</code> for FLAC. Video, I haven’t used enough to have an opinion on.</p>
<h2 id="config-files-toml">Config files – <code>toml</code></h2>
<p>For all your config file format needs. Works with <code>serde</code>, naturally.</p>
<h2 id="markdown-pulldown-cmark">Markdown – <code>pulldown-cmark</code></h2>
<p>There’s several good Markdown readers and writers, <code>pulldown-cmark</code> is my favorite. It supports CommonMark, it’s simple to use, and it’s pure Rust.</p>
<h2 id="templating-askama">Templating – <code>askama</code></h2>
<p>There’s several quite good text templating engines, but <code>askama</code> IMO rises above them all by compiling your templates into Rust code and type-checking your templates at compile time. Sometimes this isn’t what you want, but it is a great feature surprisingly often. This also makes it super fast, for when you really need to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/RustStarterKit2020">https://wiki.alopex.li/RustStarterKit2020</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/RustStarterKit2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24669220</guid>
            <pubDate>Sat, 03 Oct 2020 03:17:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ Guidelines]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24668455">thread link</a>) | @zerofrancisco
<br/>
October 2, 2020 | https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors | <a href="https://web.archive.org/web/*/https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>August 3, 2020</p>

<p>Editors:</p>

<ul>
  <li><a href="http://www.stroustrup.com/">Bjarne Stroustrup</a></li>
  <li><a href="http://herbsutter.com/">Herb Sutter</a></li>
</ul>

<p>This is a living document under continuous improvement.
Had it been an open-source (code) project, this would have been release 0.8.
Copying, use, modification, and creation of derivative works from this project is licensed under an MIT-style license.
Contributing to this project requires agreeing to a Contributor License. See the accompanying <a href="https://isocpp.github.io/CppCoreGuidelines/LICENSE">LICENSE</a> file for details.
We make this project available to “friendly users” to use, copy, modify, and derive from, hoping for constructive input.</p>

<p>Comments and suggestions for improvements are most welcome.
We plan to modify and extend this document as our understanding improves and the language and the set of available libraries improve.
When commenting, please note <a href="#S-introduction">the introduction</a> that outlines our aims and general approach.
The list of contributors is <a href="#SS-ack">here</a>.</p>

<p>Problems:</p>

<ul>
  <li>The sets of rules have not been completely checked for completeness, consistency, or enforceability.</li>
  <li>Triple question marks (???) mark known missing information</li>
  <li>Update reference sections; many pre-C++11 sources are too old.</li>
  <li>For a more-or-less up-to-date to-do list see: <a href="#S-unclassified">To-do: Unclassified proto-rules</a></li>
</ul>

<p>You can <a href="#S-abstract">read an explanation of the scope and structure of this Guide</a> or just jump straight in:</p>

<ul>
  <li><a href="#S-introduction">In: Introduction</a></li>
  <li><a href="#S-philosophy">P: Philosophy</a></li>
  <li><a href="#S-interfaces">I: Interfaces</a></li>
  <li><a href="#S-functions">F: Functions</a></li>
  <li><a href="#S-class">C: Classes and class hierarchies</a></li>
  <li><a href="#S-enum">Enum: Enumerations</a></li>
  <li><a href="#S-resource">R: Resource management</a></li>
  <li><a href="#S-expr">ES: Expressions and statements</a></li>
  <li><a href="#S-performance">Per: Performance</a></li>
  <li><a href="#S-concurrency">CP: Concurrency and parallelism</a></li>
  <li><a href="#S-errors">E: Error handling</a></li>
  <li><a href="#S-const">Con: Constants and immutability</a></li>
  <li><a href="#S-templates">T: Templates and generic programming</a></li>
  <li><a href="#S-cpl">CPL: C-style programming</a></li>
  <li><a href="#S-source">SF: Source files</a></li>
  <li><a href="#S-stdlib">SL: The Standard Library</a></li>
</ul>

<p>Supporting sections:</p>

<ul>
  <li><a href="#S-A">A: Architectural ideas</a></li>
  <li><a href="#S-not">NR: Non-Rules and myths</a></li>
  <li><a href="#S-references">RF: References</a></li>
  <li><a href="#S-profile">Pro: Profiles</a></li>
  <li><a href="#S-gsl">GSL: Guidelines support library</a></li>
  <li><a href="#S-naming">NL: Naming and layout rules</a></li>
  <li><a href="#S-faq">FAQ: Answers to frequently asked questions</a></li>
  <li><a href="#S-libraries">Appendix A: Libraries</a></li>
  <li><a href="#S-modernizing">Appendix B: Modernizing code</a></li>
  <li><a href="#S-discussion">Appendix C: Discussion</a></li>
  <li><a href="#S-tools">Appendix D: Supporting tools</a></li>
  <li><a href="#S-glossary">Glossary</a></li>
  <li><a href="#S-unclassified">To-do: Unclassified proto-rules</a></li>
</ul>

<p>You can sample rules for specific language features:</p>

<ul>
  <li>assignment:
<a href="#Rc-regular">regular types</a> –
<a href="#Rc-initialize">prefer initialization</a> –
<a href="#Rc-copy-semantic">copy</a> –
<a href="#Rc-move-semantic">move</a> –
<a href="#Rc-matched">other operations</a> –
<a href="#Rc-eqdefault">default</a></li>
  <li><code>class</code>:
<a href="#Rc-org">data</a> –
<a href="#Rc-struct">invariant</a> –
<a href="#Rc-member">members</a> –
<a href="#Rc-helper">helpers</a> –
<a href="#SS-concrete">concrete types</a> –
<a href="#S-ctor">ctors, =, and dtors</a> –
<a href="#SS-hier">hierarchy</a> –
<a href="#SS-overload">operators</a></li>
  <li><code>concept</code>:
<a href="#SS-concepts">rules</a> –
<a href="#Rt-raise">in generic programming</a> –
<a href="#Rt-concepts">template arguments</a> –
<a href="#Rt-low">semantics</a></li>
  <li>constructor:
<a href="#Rc-struct">invariant</a> –
<a href="#Rc-ctor">establish invariant</a> –
<a href="#Rc-throw"><code>throw</code></a> –
<a href="#Rc-default0">default</a> –
<a href="#Rc-default">not needed</a> –
<a href="#Rc-explicit"><code>explicit</code></a> –
<a href="#Rc-delegating">delegating</a> –
<a href="#Rc-ctor-virtual"><code>virtual</code></a></li>
  <li>derived <code>class</code>:
<a href="#Rh-domain">when to use</a> –
<a href="#Rh-abstract">as interface</a> –
<a href="#Rh-dtor">destructors</a> –
<a href="#Rh-copy">copy</a> –
<a href="#Rh-get">getters and setters</a> –
<a href="#Rh-mi-interface">multiple inheritance</a> –
<a href="#Rh-using">overloading</a> –
<a href="#Rc-copy-virtual">slicing</a> –
<a href="#Rh-dynamic_cast"><code>dynamic_cast</code></a></li>
  <li>destructor:
<a href="#Rc-matched">and constructors</a> –
<a href="#Rc-dtor">when needed?</a> –
<a href="#Rc-dtor-fail">may not fail</a></li>
  <li>exception:
<a href="#S-errors">errors</a> –
<a href="#Re-throw"><code>throw</code></a> –
<a href="#Re-errors">for errors only</a> –
<a href="#Re-noexcept"><code>noexcept</code></a> –
<a href="#Re-catch">minimize <code>try</code></a> –
<a href="#Re-no-throw-codes">what if no exceptions?</a></li>
  <li><code>for</code>:
<a href="#Res-for-range">range-for and for</a> –
<a href="#Res-for-while">for and while</a> –
<a href="#Res-for-init">for-initializer</a> –
<a href="#Res-empty">empty body</a> –
<a href="#Res-loop-counter">loop variable</a> –
<a href="#Res-???">loop variable type ???</a></li>
  <li>function:
<a href="#Rf-package">naming</a> –
<a href="#Rf-logical">single operation</a> –
<a href="#Rf-noexcept">no throw</a> –
<a href="#Rf-smart">arguments</a> –
<a href="#Rf-conventional">argument passing</a> –
<a href="#Rf-out-multi">multiple return values</a> –
<a href="#Rf-return-ptr">pointers</a> –
<a href="#Rf-capture-vs-overload">lambdas</a></li>
  <li><code>inline</code>:
<a href="#Rf-inline">small functions</a> –
<a href="#Rs-inline">in headers</a></li>
  <li>initialization:
<a href="#Res-always">always</a> –
<a href="#Res-list">prefer <code>{}</code></a> –
<a href="#Res-lambda-init">lambdas</a> –
<a href="#Rc-in-class-initializer">in-class initializers</a> –
<a href="#Rc-initialize">class members</a> –
<a href="#Rc-factory">factory functions</a></li>
  <li>lambda expression:
<a href="#SS-lambdas">when to use</a></li>
  <li>operator:
<a href="#Ro-conventional">conventional</a> –
<a href="#Ro-conversion">avoid conversion operators</a> –
<a href="#Ro-lambda">and lambdas</a></li>
  <li><code>public</code>, <code>private</code>, and <code>protected</code>:
<a href="#Rc-private">information hiding</a> –
<a href="#Rh-public">consistency</a> –
<a href="#Rh-protected"><code>protected</code></a></li>
  <li><code>static_assert</code>:
<a href="#Rp-compile-time">compile-time checking</a> –
<a href="#Rt-check-class">and concepts</a></li>
  <li><code>struct</code>:
<a href="#Rc-org">for organizing data</a> –
<a href="#Rc-struct">use if no invariant</a> –
<a href="#Rc-class">no private members</a></li>
  <li><code>template</code>:
<a href="#Rt-raise">abstraction</a> –
<a href="#Rt-cont">containers</a> –
<a href="#Rt-concepts">concepts</a></li>
  <li><code>unsigned</code>:
<a href="#Res-mix">and signed</a> –
<a href="#Res-unsigned">bit manipulation</a></li>
  <li><code>virtual</code>:
<a href="#Ri-abstract">interfaces</a> –
<a href="#Rc-concrete">not <code>virtual</code></a> –
<a href="#Rc-dtor-virtual">destructor</a> –
<a href="#Rc-dtor-fail">never fail</a></li>
</ul>

<p>You can look at design concepts used to express the rules:</p>

<ul>
  <li>assertion: ???</li>
  <li>error: ???</li>
  <li>exception: exception guarantee (???)</li>
  <li>failure: ???</li>
  <li>invariant: ???</li>
  <li>leak: ???</li>
  <li>library: ???</li>
  <li>precondition: ???</li>
  <li>postcondition: ???</li>
  <li>resource: ???</li>
</ul>



<p>This document is a set of guidelines for using C++ well.
The aim of this document is to help people to use modern C++ effectively.
By “modern C++” we mean effective use of the ISO C++ standard (currently C++17, but almost all of our recommendations also apply to C++14 and C++11).
In other words, what would you like your code to look like in 5 years’ time, given that you can start now? In 10 years’ time?</p>

<p>The guidelines are focused on relatively high-level issues, such as interfaces, resource management, memory management, and concurrency.
Such rules affect application architecture and library design.
Following the rules will lead to code that is statically type safe, has no resource leaks, and catches many more programming logic errors than is common in code today.
And it will run fast – you can afford to do things right.</p>

<p>We are less concerned with low-level issues, such as naming conventions and indentation style.
However, no topic that can help a programmer is out of bounds.</p>

<p>Our initial set of rules emphasizes safety (of various forms) and simplicity.
They may very well be too strict.
We expect to have to introduce more exceptions to better accommodate real-world needs.
We also need more rules.</p>

<p>You will find some of the rules contrary to your expectations or even contrary to your experience.
If we haven’t suggested you change your coding style in any way, we have failed!
Please try to verify or disprove rules!
In particular, we’d really like to have some of our rules backed up with measurements or better examples.</p>

<p>You will find some of the rules obvious or even trivial.
Please remember that one purpose of a guideline is to help someone who is less experienced or coming from a different background or language to get up to speed.</p>

<p>Many of the rules are designed to be supported by an analysis tool.
Violations of rules will be flagged with references (or links) to the relevant rule.
We do not expect you to memorize all the rules before trying to write code.
One way of thinking about these guidelines is as a specification for tools that happens to be readable by humans.</p>

<p>The rules are meant for gradual introduction into a code base.
We plan to build tools for that and hope others will too.</p>

<p>Comments and suggestions for improvements are most welcome.
We plan to modify and extend this document as our understanding improves and the language and the set of available libraries improve.</p>



<p>This is a set of core guidelines for modern C++ (currently C++17) taking likely future enhancements and ISO Technical Specifications (TSs) into account.
The aim is to help C++ programmers to write simpler, more efficient, more maintainable code.</p>

<p>Introduction summary:</p>

<ul>
  <li><a href="#SS-readers">In.target: Target readership</a></li>
  <li><a href="#SS-aims">In.aims: Aims</a></li>
  <li><a href="#SS-non">In.not: Non-aims</a></li>
  <li><a href="#SS-force">In.force: Enforcement</a></li>
  <li><a href="#SS-struct">In.struct: The structure of this document</a></li>
  <li><a href="#SS-sec">In.sec: Major sections</a></li>
</ul>

<h2 id="intarget-target-readership"><a name="SS-readers"></a>In.target: Target readership</h2>

<p>All C++ programmers. This includes <a href="#S-cpl">programmers who might consider C</a>.</p>

<h2 id="inaims-aims"><a name="SS-aims"></a>In.aims: Aims</h2>

<p>The purpose of this document is to help developers to adopt modern C++ (currently C++17) and to achieve a more uniform style across code bases.</p>

<p>We do not suffer the delusion that every one of these rules can be effectively applied to every code base. Upgrading old systems is hard. However, we do believe that a program that uses a rule is less error-prone and more maintainable than one that does not. Often, rules also lead to faster/easier initial development.
As far as we can tell, these rules lead to code that performs as well or better than older, more conventional techniques; they are meant to follow the zero-overhead principle (“what you don’t use, you don’t pay for” or “when you use an abstraction mechanism appropriately, you get at least as good performance as if you had handcoded using lower-level language constructs”).
Consider these rules ideals for new code, opportunities to exploit when working on older code, and try to approximate these ideals as closely as feasible.
Remember:</p>

<h3 id="in0-dont-panic"><a name="R0"></a>In.0: Don’t panic!</h3>

<p>Take the time to understand the implications of a guideline rule on your program.</p>

<p>These guidelines are designed according to the “subset of superset” principle (<a href="#Stroustrup05">Stroustrup05</a>).
They do not simply define a subset of C++ to be used (for reliability, safety, performance, or whatever).
Instead, they strongly recommend the use of a few simple “extensions” (<a href="#S-gsl">library components</a>)
that make the use of the most error-prone features of C++ redundant, so that they can be banned (in our set of rules).</p>

<p>The rules emphasize static type safety and resource safety.
For that reason, they emphasize possibilities for range checking, for avoiding dereferencing <code>nullptr</code>, for avoiding dangling pointers, and the systematic use of exceptions (via RAII).
Partly to achieve that and partly to minimize obscure code as a source of errors, the rules also emphasize simplicity and the hiding of necessary complexity behind well-specified interfaces.</p>

<p>Many of the rules are prescriptive.
We are uncomfortable with rules that simply state “don’t do that!” without offering an alternative.
One consequence of that is that some rules can be supported only by heuristics, rather than precise and mechanically verifiable checks.
Other rules articulate general principles. For these more general rules, more detailed and specific rules provide partial checking.</p>

<p>These guidelines address the core of C++ and its use.
We expect that most large organizations, specific application areas, and even large projects will need further rules, possibly further restrictions, and further library support.
For example, hard-real-time programmers typically can’t use free store (dynamic memory) freely and will be restricted in their choice of libraries.
We encourage the development of such more specific rules as addenda to these core guidelines.
Build your ideal small foundation library and use that, rather than lowering your level of programming to glorified assembly code.</p>

<p>The rules are designed to allow <a href="#S-modernizing">gradual adoption</a>.</p>

<p>Some rules aim to increase various forms of safety while others aim to reduce the likelihood of accidents, many do both.
The guidelines aimed at preventing accidents often ban perfectly legal C++.
However, when there are two ways of expressing an idea and one has shown itself a common source …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors">https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors</a></em></p>]]>
            </description>
            <link>https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668455</guid>
            <pubDate>Sat, 03 Oct 2020 00:36:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doctoberfest – Beanies for Open Source Documentation Contributions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24668194">thread link</a>) | @barlo
<br/>
October 2, 2020 | https://try.wagon.dev/doctoberfest/ | <a href="https://web.archive.org/web/*/https://try.wagon.dev/doctoberfest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lp-pom-text-10"><p><span><span><a data-fr-linked="true" href="https://try.wagon.dev/doctoberfest/clkn/https/wagon.dev/"></a></span></span><span><span>The open source world needs more documentation.&nbsp;</span></span></p><p><span><span>For the month of October, we will will be offering a beanie to developers and technical writers that make &nbsp;documentation improvements to open source projects that support IPv6, privacy, and advancements in networking technology.</span></span></p></div><div id="lp-pom-text-333"><p><span><span>Participants</span></span><span><span>&nbsp;must make three (3) substantial documentation improvements.&nbsp;</span></span></p><p><span><span>Improvements can be to a single project or more than one. The offer is limited to the first one hundred participants.&nbsp;</span></span></p></div><div id="lp-pom-text-336"><p><span>After verifying your pull requests, we will email you a link to submit your address for shipping.</span></p><p><a data-action="url" data-params="false" href="mailto://doctoberfest@wagon.dev" target="_self"><span>doctoberfest@wagon.dev</span></a></p></div></div>]]>
            </description>
            <link>https://try.wagon.dev/doctoberfest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668194</guid>
            <pubDate>Fri, 02 Oct 2020 23:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It, Part III: Hammer-Time]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24668125">thread link</a>) | @dddddaviddddd
<br/>
October 2, 2020 | https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, we continue our four-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">II</a>, III, IV) look at pre-modern iron and steel production.  Last week we took our ore and smelted it into a rough, spongy mass of iron called a bloom; this week we’re going to go through the processes to reshape that bloom first into a consolidated billet, then into a bar that is useful for forging and finally into some useful final object.</p>



<p>I want to stress at the outset that we are not going to cover anything close to the whole of blacksmithing practice in this post.  Blacksmithing is fairly complex and any given object, shape or tool is going to have its own set of processes and techniques to produce the required shape at the required hardness and malleability characteristics.  If you <em>are</em> interested in that sort of information, I recommend A.W. Bealer’s <em>The Art of Blacksmithing</em> (1969) as a fairly good starting point, though there is no substitute to speaking with a practicing blacksmith.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<h2>Heat, Hammers and Hardness</h2>



<p>There are a few basic behaviors of iron that fundamentally control what blacksmiths are going to do with it in this stage.  To begin with, we need to introduce some terminology to avoid this coming confusing: a given piece of metal can be <em>hard</em> (resistant to deformation) or <em>soft</em>; they can also be <em>ductile </em>(able to deform significantly before breaking) or <em>brittle</em> (likely to break without deformation).  This is easiest to understand at the extremes: a soft, brittle material (like a thin wooden dowel) takes very little energy and breaks immediately without behind, while a hard, ductile material (the same dowel, made of spring-steel) bends more easily under stress but resists breaking.  But it is also possible to hard hard brittle materials (pottery being a classic example) which fiercely resist deforming but break catastrophically the moment they exceed their tolerances or a soft, ductile material (think wet-noodle) which bends very easily.</p>



<p>(I should note that all of these factors are, in fact, very complex – far more complex than we are going to discuss.  In particular, as I understand it, some of what I am using ‘hardness’ to describe also falls under the related category of yield strength.  Hopefully you will all pardon the necessary simplification; if it makes you feel any better, ancient blacksmiths didn’t understand how any of this worked either, only that it worked.)</p>



<p>Of course these treats are not binaries but a spectrum.  Materials have a degree of hardness or ductility; as we’ll see, these are not quite <em>opposed</em>, but changing one does change the other – increasing hardness often reduces ductility.</p>



<p>The sort of things that pre-modern people are going to want to be made in iron are going to have fairly tight tolerances for these sorts of things.  Objects that had wide tolerances (that is, things which could be weak or a little bendy or didn’t have to take much force) got made out of other cheaper, easier materials like ceramics, stone or wood; metals were really only used for things that had to be both strong and relatively light for precisely the reasons we’ve seen: they were too expensive for anything else.  <strong>That means that a blacksmith doesn’t merely need to bring the metal to the right shape but also to the right <em>characteristics</em></strong><em><strong>.</strong>  </em>Some tools would need to finish up being quite hard (like the tip of a pick, or the edge of a blade), while others needed to be able to bend to absorb strain (like the core of a blade or the back of a saw).</p>



<p>Keep all of that in mind as we discuss:</p>



<h2>Forge Techniques</h2>



<p>I realize this is a long aside to leave our bloom waiting, but as we’ll see, the remaining steps share a basic set of techniques, making it easier to discuss those techniques together.</p>



<p>Fundamentally, each stage of forging iron revolves around a basic cycle: <strong>by heating the metal, the smith makes it soft enough to <em>work</em> </strong>(that is, hammer into shape).  Technically, it is possible to shape relatively thin masses of iron by hammering when cold (this is called cold-working) but in contrast to other metals (tin, copper and bronze all come to mind) nearly all serious iron-working was done ‘hot.’  In smithing terminology, each of these cycles is referred to as a ‘heat’ – the more heats a given project requires, the more fuel it is going to consume, the longer and more expensive it is going to be (but a skilled smith can often finish the work in fewer heats than an unskilled smith).</p>



<figure><img data-attachment-id="4712" data-permalink="https://acoup.blog/202833001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg" data-orig-size="2500,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="202833001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/P_1836-0811-78">Via the British Museum</a>, A Dutch drawing (c. 1624-1640) of blacksmiths at work, with the blacksmith himself in the center and a striker (with the two-handed hammer) to the left.  An assistant mans the bellows on the forge to maintain the temperature.</figcaption></figure>



<p>A modern blacksmith can gauge the temperature of a metal using sophisticated modern thermometers, but pre-modern smiths had no recourse to such things (and most traditional smiths I’ve met don’t use them anyway).  Instead, the temperature of the metal is gauged by looking at its <em>color</em>: as things get hotter, they glow from brown to dark red through to a light red into yellow and then finally white.  For iron heated in a forge, a blacksmith can control the temperature of the forge’s fire by controlling the air-input through the bellows (pushing in more air means more combustion, which means more heat, but also more fuel consumed).  As we’ve seen, charcoal (and we will need to use charcoal, not wood, to hit the necessary heat required), while not cripplingly expensive, was not trivial to produce either.  A skilled smith is thus going to try to do the work in as few heats as possible and not excessively hot either (there are, in fact, other reasons to avoid excessive heats, this is just one).</p>



<p>One hot the metal can be shaped by hammering.  The thickness of a bar of metal could be thickened by <em>upsetting</em> (heating the center of the bar and them hammering down on it like a nail to compress the center, causing it to thicken) or thinned by <em>drawing</em> (hammering out the metal to create a longer, thinner shape).  If the required shape needed the metal to be bent it could be heated and bent either over the side of the anvil or against a tool; many anvils had (and still have) a notch in the back where such a tool could be fitted.  A good example of this kind of thing would be hammering out a sheet of iron over a dome-shape to create the bowl of a helmet (a task known as ‘raising’ or ‘sinking’ depending on precisely how it is done).  A mass of iron can also be divided by heating it at the intended cutting point and then using a hammer and chisel to cut through the hot, soft metal.</p>



<p>But for understanding the entire process, the most important of these operations is the<strong> <em>fire weld</em></strong>.  Much like bloomery furnaces, the forges available to pre-modern blacksmiths could not reach the temperatures necessary to melt or cast iron, but it was necessary to be able to join smaller bits of iron into larger ones which was done through a fire weld (sometimes called a forge weld).  In this process, the iron is heated very hot, typically to a ‘yellow’ or ‘white’ heat (around 1100 °C).  The temperature range for the operation is quite precise: too cold and the iron will not weld, too hot and it will ‘burn’ making the weld brittle.  Once at the right temperature, the two pieces of iron are put next to each other and hammered into each other with heavy blows.  If done properly, the two pieces of metal join completely, leaving a weld that is as strong as every other part of the bar.</p>



<figure><img data-attachment-id="4703" data-permalink="https://acoup.blog/fire-welds/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png" data-orig-size="1057,282" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fire-welds" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png 1057w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://youtu.be/cc_n8H-2-I0">From this demonstration</a>, a series of hammer blows in the process of making a fire or forge weld.  The sparks you see are flux and hammer scale (and possibly some amount of slag and excess iron material) being ejected out of the weld.</figcaption></figure>



<p>That’s not all there is to say about these processes (we’ll come back to them in a moment) but we now have enough of the basics to begin processing our bloom.</p>



<h2>From Bloom to Billet to Bar</h2>



<p>As you may recall, when we finished our process last time, we ended with a ‘bloom’ of iron: a spongy mass of pure, metallic iron interspersed with inclusions of waste materials called slag:</p>



<figure><img data-attachment-id="4630" data-permalink="https://acoup.blog/1024px-iron_bloom/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg" data-orig-size="1024,853" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-iron_bloom" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The iron of the bloom itself is also likely to be quite brittle because of these slag inclusions.  This isn’t a product that can be sent directly to a blacksmith.  It needs to be consolidated first into a billet and most of that slag needs to be forced out, both of which can be achieved via liberal application of <strong>fire welding</strong>.</p>



<p>This step is sometimes called <strong>bloomsmithing</strong>.  The bloom is heated to roughly 1100 °C (gauged, as above, by the color of the iron) – it seems plausible that it may have been broken up into smaller chunks to make this more useful – and then hammered into a single mass through a series of fire welds.  We’re not very well informed how this was done in the ancient world (save ‘with hammers’) because bloomsmithing doesn’t tend to leave a lot of evidence for us to observe.  The end shape of the process was generally a very thick rectangular bar called a <strong>billet</strong>, ready for relatively easy transport.</p>



<p>This process has some advantages and disadvantages, beyond merely shaping the metal into a more usable and transportable form.  Remember that our bloom contains a lot of material which isn’t iron (the slag); fire welding, especially when repeated, tends to expel this slag – as the iron is compressed in the weld, the slag is forced out.  There is some debate (note Sim &amp; Kaminski, <em>op. cit.</em>) if this process is sufficient to explain the <em>very</em> low slag counts seen in high quality weapons and armor, but it is certainly true that fire welding reduces the overall slag count.  That …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668125</guid>
            <pubDate>Fri, 02 Oct 2020 23:35:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plasma and the Systemd Startup]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24668038">thread link</a>) | @zirak
<br/>
October 2, 2020 | http://blog.davidedmundson.co.uk/blog/plasma-and-the-systemd-startup/ | <a href="https://web.archive.org/web/*/http://blog.davidedmundson.co.uk/blog/plasma-and-the-systemd-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-339">
	
	<!-- .entry-header -->

	<div>
		
<p>Landing in master, plasma has an optional new startup method to launch and manage all our KDE/Plasma services via a systemd user instance rather than the current boot scripts. This will be available in Plasma 5.21.</p>
<p>It is currently opt-in, off by default.  I hope to make it the default where available after more testing and feedback, but it is important to stress that the current boot-up method will exist and be supported into the future. A lot of work was put into splitting and tidying so the actual amount of duplication in the end result is quite small and managable.</p>
<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/10/bitmap.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/10/bitmap.png" alt="Our logos are weirldy similar...conspiracy?"></a></p>

<h2>Overlapping requirements</h2>
<p>We have to start a lot of things in a given order. Systemd naturally is designed for handling doing this.</p>
<p>Whilst we already have a somewhat working system, it has issues. One classic problem is services that talk to other services needing to be both spawned but also fully initialised before the other can send a message. DBus activation solves a lot; but not quite enough.</p>
<p>For example, we have the real world case of scripts run long before plasmashell trying to send notifications; we want DBus daemon to know our notification server it's activatable so that it will pause the dispatch of the message, but making it DBus activatable can't guarantee the dependencies are run in the correct order. This is currently solved with a <del>genius</del> horrific hack.</p>
<p>But starting things up is only half the battle. We currently have a big issue with shutting things down. Whose responsibility is it to stop running services? A lot of things only exit because their wayland connection is swept away. When dealing with services that potentially restart during the session lifespan, this solution is far from trivial and the current situation is fundamentally broken.</p>
<h2>Customisation / Sysadmin Familiarity</h2>
<p>Most users and especially sysadmins already have to learn how to use their init system. Whether it's simply enabling a service on boot, or something much more complex users are exposed to it already. If not, there is good existing documentation and countless Stackoverflow posts to answer any question.</p>
<p>We had a meeting akademy 2 years ago about use of systemd and it was the sysadmins from Limux who clearly knew far more than any programmer as to how it should all work. There is a lot more merit in using existing things than just sharing code.</p>
<hr>
<p>Another big motivating factor was the ability for customisation. The root of Plasma's startup is very hardcoded. What if you want to run krunner with a different environment variable set? or have a script run every time plasmashell restarts, or show a UI after kwin is loaded but before plasma shell to perform some user setup? You can edit the code, but that's not easy and you're very much on your own.</p>
<p>Systemd provides that level of customisation; both at a distro or a user level out of the box. From our POV for free.</p>
<h2>CGroups and resource limits</h2>
<p>I've talked about use of <a href="http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/">cgroups for applications</a> for better control of resources. Especially as more things become multi-process. </p>
<p>CGroups and slices provide several benefits over what we can do currently. Because resources are always relative to within the parent slice, we are able to boost resources as well as limit things. This will allow us to bump kwin and such ever so slightly without needing elevated cap privileges.</p>
<p>This also works the other way; cgroups have some extra scheduler features not otherwise available. We can not just set weigh to a process, but also absolute limits. This could be useful for file indexers and alike to minimise battery drainage or capture runaway processes. CGroups are where all the new kernel features are.</p>
<p>Memory management is another factor, when we run out the kernel comes in and kills some processes.<br>
We can tag some services as being safer to OOM kill than others with a lot more granularity than a single oomscore adjustment. We can provide expected memory usages for a service, we can put defaults levels on entire slices at once, and it's all easily customisable by the user if their opinions don't match our upstream defaults.</p>
<h2>Logging</h2>
<p>The current state of logging is a mess. One of two things happen:<br>
Either stderr from a service is lost, or logs go into one giant "xsession-errors" file. This file exists on a real file system slowly expanding and expanding. It doesn't rotate, if it gets too big your home folder becomes full and things explode. Each time you log in, we override that log, so we lose any history. </p>
<p>The alternative is that logs are simply lost.</p>
<p>Systemd provides queryable logging with each unit, and each invocation of each unit being separate. It's already making my life a lot easier for the last bugs I've been working on. When people on bugzilla have this too, it'll make everything easier.</p>

<h2>Previous implementations</h2>
<p>A plasma systemd boot has been <a href="https://github.com/eliasp/plasma-workspace-units">tried before</a> by Elias Probst. It worked well as a demo, and was used as inspiration for some parts. The key difference now is instead of trying to design around plasma, we're changing plasma to fit what we need and really put the focus on every last detail.</p>
<h2>Refactor, Split, Refactor, Split, ...</h2>
<p>Unintuitively the first start of a port to systemd was a complete rewrite of the legacy path.</p>
<p>Plasma used to be managed by a tree of processes that would spawn, set up some environment variables, spawn the next part of the boot and continue running. We eventually get to ksmserver, which was a monolith that did many many things. It started several hardcoded processes like kwin, then all the autostart .desktop files, and then session restore. There were many reasons to break this up that I outlined when I started in <a href="https://blog.davidedmundson.co.uk/blog/changes-to-ksmserver/">2018</a>.</p>
<p>Since then we've been chopping a tiny part out every release. Each release would split out a tiny part at a time so we could always be on top of any regressions that happened. </p>
<p>Once we'd refactored and rewrote some parts we could have a very clear and readable understanding of  <a href="http://blog.davidedmundson.co.uk/blog/plasma-startup/"> what actually happens in a plasma boot</a> and what is really dependent on what.</p>
<p>The biggest problem that we have is many things rely on environment variables or even xrdb databases to be correct at the time of launching; several early parts of the boot (kcminit, kded phase0) will adjust these and the next parts may rely on these for correct theming. </p>
<p>Another massive rewrite that landed (by Kai Uwe Broulik) was the detaching of kwin from ksmserver. kwin needs to know which session we're restoring so that restored windows can be placed at the right place; this previously came from an environment variable that means we needed ksmserver up and running to spawn kwin. We rewrote how that all works and gets communicated so the order can be agnostic but still without any features getting lost.</p>
<h2>Final patchset</h2>
<p>Eventually we got to a point where ksmserver is <em>only</em> dealing with X11 session management. We have another quite tiny binary (<code>plasma_session</code>) that <em>only</em> deals with starting services in a specific order. And everything else is completely separate standalone independent components. This has been released for a while. Even without the systemd boot, everything is in a much much cleaner better off state.</p>
<p>The final patch to use systemd is then really quite boring and small. We just don't call the <code>plasma_session binary</code>, and instead try to start a systemd target; <code>plasma-workspace.target</code>.</p>
<p>All our core services ship their own .service files which plasma-workpace requires for a full Plasma session.</p>
<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200923_114125.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/09/Screenshot_20200923_114125-1024x249.png" alt="This picture shows random circles and lines. I felt it helped break up the wall of text."></a></p>
<h2>Autostart files</h2>
<p>One of the key aspects of startup is handling autostart .desktop files in /etc/xdg/autostart or ~/.config/autostart. We need this to work as before.</p>
<p>Benjamin Berg (of Red Hat and Gnome) came up with a very elegant solution using a <a href="https://www.freedesktop.org/software/systemd/man/systemd.generator.html">systemd generator</a>. It goes through all the .desktop files parsing them and generates an appropriate systemd service automagically.</p>
<p>For application developers everything keeps working the same, but to an end user we can interact with them like native services. We get the best of both worlds.</p>
<p>Despite being a shared implementation even KDE-specific things like X-KDE-AutostartCondition just work. Implementation wise the generator converts this into an ExecCondition= line which then calls into a plasma-shipped binary to check if it's allowed.</p>

<h2>Is it faster?</h2>
<p>A lot of the prep work over the past few years to get to this state has made absolutely massive differences. The splitting found bugs dead code and potential optimisations that add up to magnitudes of difference.</p>
<p>As for switching over to the systemd itself, it should be roughly the same. Ultimately we're triggering the exact same set of things in the exact same order with the exact same blocks if we've done our job properly. Sorry to disappoint!</p>
<h2>Is it finished?</h2>
<p>The fundamentals are definitely at a point that I think are stable and working; but we haven't enabled all of the potential extra features we have available. I would welcome people who are experiences to give feedback and help out.</p>

<p>You must have latest master of Plasma, it is not in the 5.20 beta. </p>
<p>Enable with:</p>
<pre><code>kwriteconfig5 --file startkderc --group General --key systemdBoot true</code></pre>
<p>As mentioned above there are checks that you have the systemd 246 or newer for the generator of existing autostart services to work.</p>
<p>To confirm the boot worked correctly you can run</p>
<pre><code>systemctl --user status plasma-plasmashell.service</code></pre>
<p>It should show as active.</p>
<p>This safety check of 246 can be skipped. You will lose auto-activation of apps using the classic .desktop file approach, but everything else still works. I won't mention how publicly to avoid false bug reports, but as a dev you can probably find out.</p>
<h3>Dev setups - a caveat</h3>
<p>If you build your own KDE and install into a non standard prefix, instead of getting Plasma from your distribution, there is one new hurdle. Systemd user sessions starts earlier than most people set their custom prefixes so naturally it can't find things in your new paths.</p>
<p>There are multiple solutions, simplest is to re-run  <code>./install-sessions</code> script in plasma-workspace …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.davidedmundson.co.uk/blog/plasma-and-the-systemd-startup/">http://blog.davidedmundson.co.uk/blog/plasma-and-the-systemd-startup/</a></em></p>]]>
            </description>
            <link>http://blog.davidedmundson.co.uk/blog/plasma-and-the-systemd-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668038</guid>
            <pubDate>Fri, 02 Oct 2020 23:21:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Gates and Jeffrey Epstein met with Nobel Committee chair in 2013]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24667843">thread link</a>) | @AndrewBissell
<br/>
October 2, 2020 | https://www.dn.no/magasinet/dokumentar/jeffrey-epstein/thorbjorn-jagland/terje-rod-larsen/bill-gates-and-jeffrey-epstein-met-with-nobel-committee-chair/2-1-885834 | <a href="https://web.archive.org/web/*/https://www.dn.no/magasinet/dokumentar/jeffrey-epstein/thorbjorn-jagland/terje-rod-larsen/bill-gates-and-jeffrey-epstein-met-with-nobel-committee-chair/2-1-885834">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dn.no/magasinet/dokumentar/jeffrey-epstein/thorbjorn-jagland/terje-rod-larsen/bill-gates-and-jeffrey-epstein-met-with-nobel-committee-chair/2-1-885834</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667843</guid>
            <pubDate>Fri, 02 Oct 2020 22:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archillect – an AI created to discover and share stimulating visual content]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24667732">thread link</a>) | @dewey
<br/>
October 2, 2020 | https://archillect.com/about | <a href="https://web.archive.org/web/*/https://archillect.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://archillect.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667732</guid>
            <pubDate>Fri, 02 Oct 2020 22:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ZGlue Teams Up with Antmicro and Google in Open Chiplet Initiative]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24667641">thread link</a>) | @rbanffy
<br/>
October 2, 2020 | https://antmicro.com/blog/2020/10/open-chiplet-initiative/ | <a href="https://web.archive.org/web/*/https://antmicro.com/blog/2020/10/open-chiplet-initiative/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://antmicro.com/blog/2020/10/open-chiplet-initiative/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667641</guid>
            <pubDate>Fri, 02 Oct 2020 22:22:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why most Hacktoberfest PRs are from India]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24667488">thread link</a>) | @pulkitsh1234
<br/>
October 2, 2020 | https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/ | <a href="https://web.archive.org/web/*/https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Before reading the post</em></p>

<p>Now that I have mentioned the name of a country in the title, please read the following points:</p>
<ul>
  <li>I am an Indian and have been living in the country since my birth.</li>
  <li>I do not claim to be right on all of this and there are many anecdotal generalisations here. Somethings are more like human problems instead of Indian problems <strong>but</strong> just the sheer number of people here puts India on everyone’s radar.</li>
  <li>This post is NOT to denigrate India. It is definitely critical of some of its social and psychological aspects. As a proof for that I want to mention that I am writing a series on the wisdom of ancient Indian philosophical ideas here: <a href="https://pulkitsharma07.github.io/2020/06/25/source-0/">Source [0]</a>, just so you know that I am not writing all my posts with the sole intention to show what is “wrong” with India. We should be brave enough to face the good and bad of it.</li>
  <li>It is a shame that I need to write this header in the first place. But the reality is with or without this, people will still get offended.</li>
</ul>

<hr>

<h2 id="index">Index</h2>

<ul>
<li><a href="#what">What</a></li>

<li><a href="#how">How</a></li>

<li><a href="#why">Why</a>
<ul>
  <li><a href="#the-signalling-problem">The Signalling Problem</a></li>
  <li><a href="#the-jugaad-mentality">The Jugaad Mentality</a></li>
  <li><a href="#computer-science-education-in-india">Computer Science Education in India</a></li>
  <li><a href="#but-why-for-hacktoberfest">But why for Hacktoberfest?</a></li>
  <li><a href="#the-problem-with-high-population-density">The problem with high population density</a></li>
  <li><a href="#hierarchy-of-needs">Hierarchy of Needs</a></li>
</ul></li>
<li><a href="#closing-thoughts">Closing Thoughts</a>
<ul>
  <li><a href="#probable-future">Probable Future</a></li>
  <li><a href="#improbable-future">Improbable Future</a></li>
</ul>
</li>
</ul>
<hr>

<h2 id="what">What</h2>

<p>As most of you may know, <a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> started on 1st October 2020. And as it with most things in human life, people came with <a href="https://mobile.twitter.com/shitoberfest">different</a> ways to hack hacktoberfest to get the free t-shirt.</p>

<p>Now apart from the sheer number of spam PRs which were opened, copious amount of time is being spent by the comparatively small number of open source maintainers who have comment, close and label each individual PR.</p>

<p>I became aware of this happening from this <a href="https://news.ycombinator.com/item?id=24643894">post</a>, and in a days time several more <a href="https://joel.net/how-one-guy-ruined-hacktoberfest2020-drama">posts</a> popped up. 
I got motivated (triggered?) to write this post when I saw the following on HN:</p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/hn_comment.png" alt="hn-comment"></p>

<p>After some investigation, I found the original claim to be true, <code>more than 60% of the spam PRs are coming from one country: India</code> and that is just 1 day after hacktoberfest started, I am sure the percentage will increase as days go by (unless DigitalOcean does something).</p>
<hr>

<h2 id="how">How</h2>

<p><a href="https://joel.net/how-one-guy-ruined-hacktoberfest2020-drama">This</a> post talks about one Indian YouTube channel which apparently told people to open spammy PRs. After I looked around some people were claiming he was falsely accused, anyways the video is deleted now, so I can’t comment on that.</p>

<p>Anyways, it didn’t take long and I was able to find few more Indian YouTubers who were pretty directly promoting ways to open PRs to get those sweet T-Shirts. One created his own <a href="https://github.com/seeditsolution/cprogram/pulls">repo</a> and encouraged people to google different programs and copy-paste them into a new PR against the empty repo.</p>

<p>I do not want to focus on the <em>How</em>, you will find find plenty videos/blogs on it, I am sure some Indian YouTuber has started working on creating a video on it.</p>
<hr>

<h2 id="why">Why</h2>
<p>One of the simplest explanation is that, DigitalOcean should have been very well anticipated that this is going to happen, after all they must have all the stats from the previous HacktoberFests.</p>

<p>We need to understand that Hacktoberfest is an marketing event. And all these spam and blogs posts around it is definitely serving their main purpose, there is no such thing as bad publicity indeed. Of course I could be totally wrong, all of this could be completely unintentional.</p>

<hr>

<p>Now, coming to the Indian side of the ongoing issue. Out of all the countries why does India have the most spammy PRs ? As a seasoned armchair philosopher, the following are my thoughts on the “Why” of all this.</p>
<hr>

<h3 id="the-signalling-problem">The Signalling Problem</h3>
<p>Whenever an online article/documentary/report claim to give a view into the “real” India, most of us (Indians) get offended.</p>

<p>I <em>was</em> in the bubble which was in the “offended” bucket for long time. The reason was simple: I, the people around me and the societal structures around me were all part of the same bubble. We do not have to worry about paying school fees or rent, we do not have worry about sending part of salary back home just so that our parents can buy groceries to survive..</p>

<p>I can go on and on, the overall gist is that I got offended in seeing what other people claim as “real” India, because that India was not part of my reality. Sure, I saw that when travelling from one place to another, saw that on news, read about that in the newspaper; but I was at a very safe distance from all of that.</p>

<p>These days, I try to not get offended when people say India has problem X or problem Y, because I realise I am living inside a cocoon where all of my needs are met, and one of the most serious issues my country is facing right now is <strike>witch-hunting </strike> nabbing the “drug mafia” amongst the Bollywood celebrities who allegedly murdered an actor by giving CBD oil (The absurdity of all this is unfathomable)</p>

<p>I mention all of this, because whenever I read posts which show India in some <a href="https://news.ycombinator.com/item?id=24552047">bad light</a>, there is always someone somewhere who gives anecdotes of how that is not true.</p>

<p>Here are some facts: we have a culture of <strong>extreme signalling</strong>. Signalling is the core building block of our society, most people don’t even realise that how big we are into signalling until they study about “signalling” as a phenomena and start becoming conscious of it. You notice that in the way your parents view you, how you make choices, how people around you make choices.</p>

<p>Of course, people will say “that is not an Indian problem, signalling is just a social construct and literally everyone does that on some level”. I am not denying not that, the very fact that I am writing this post is a kind of signalling I am doing.</p>

<p>It is well known fact that India is one of the densest countries on our <a href="https://ourworldindata.org/grapher/population-density?time=2017">planet</a>, extreme siginalling is just one of the consequences of the myriad social problems created by high population density. Signalling in an high density environment is now ever more important as the people you interact or the people who notice your activities/accomplishments are multiples higher than in any other place on the planet.</p>

<p>We people like the wear the “tightly knit society” as badge of honour, let me tell you this “tightly knit society” has done more harm than good. We Indian people have no India of the amount of mental harassment we all go through, because that is just normalized as being just phases of “life”.</p>

<p>The prevalence of extreme signalling brews the classic and infamous <em>herd mentality</em> in our minds. In middle school children have dreams to become a Pilot in the airforce, or maybe a Police officer, or maybe a Opera Singer ! But by the time of high school, everyone is just either on road to become an Engineer, a Doctor, a Lawyer, a Chartered Accountant …. or a <strong>failure</strong>. This may seem harsh but that’s how most of the society operates here in India.</p>

<p>Now once your track is chosen for you (or fortunately, if you get to choose the track), you have some set goals you “must” achieve because they guarantee monetary success with an extremely high probability. If you are Engineer, you need to get into IIT. If you are a Doctor, you need to get into AIIMS. If you are doing management, you need to get into IIM.</p>

<p>Now, if you are an Engineer then your success criteria is not just any IIT, it should be one of the top ones (Bombay, Delhi, Kharagpur, Roorkee) and not just any branch in IIT, it should be <em>Computer Science</em>. Because that’s how you get <a href="https://www.newindianexpress.com/nation/2019/dec/04/five-iitians-bag-pay-packages-of-over-rs-15-crore-2071120.html">Rs 1.5 crore “packages” (equivalent to 200K USD)</a>.</p>

<p>You can give me examples of how not all IIT toppers choose “Computer Science”, but that’s not the point, for the vast majority of people (more than a million), the success criteria is: getting Computer Science at IIT Bombay.</p>

<p>As might know (or have guessed) getting a seat in IIT Bombay is next to impossible for more than 99% people giving IIT, so they “lower” their goal by aiming for other IITs, but “Computer Science” remains the top priority.</p>

<h3 id="the-jugaad-mentality">The Jugaad mentality</h3>
<p>Hacking systems is so ingrained in our society that we have a word for it: <a href="https://en.wikipedia.org/wiki/Jugaad">Jugaad</a>. The whole scene with Hacktoberfest is just a demo of our Jugaad skills. Wait till you find out that <a href="https://indianexpress.com/article/india/inside-indias-fake-research-paper-shops-pay-publish-profit-5265402">most of the research papers</a> published in India are <a href="https://scroll.in/article/908230/indian-academics-lead-the-world-in-publishing-in-fake-journals-tarring-the-whole-education-sector">fake</a>. Even the orthodontist I was visiting for my checkup turned out to be fake and had forged her certificates (as told by by one other dentist).</p>

<p>The coaching industry actively promotes “cracking” these exams, and I am so tired writing on that topic that I do not want to write more about it here. Refer to my post on this <a href="https://www.linkedin.com/pulse/coding-interviewing-coaching-industry-prologue-pulkit-sharma?articleId=6662006663559684097">here</a>. Some children start joining these coaching classes from as low as 5th grade! (apart from doing regular school), just to be able to “crack” the IITs after 7-8 years !</p>

<p>Now how is coaching industry a Jugaad ? Simply because from the point of view of IITs, attending regular school should be enough to prep you for the exams (I think). These coaching industries have made the process significantly harder as you can’t even hope of getting a low tier IIT without attending the coaching classes.</p>

<p>The IIT coaching industry is minting fat cheques out of this entire situation, look at these ads on the front page of the news paper. These ads create a vicious cycle by reinforcing the core “signalling” construct of our society.</p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_1.png" alt="hn-comment"></p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_2.png" alt="hn-comment"></p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_3.png" alt="hn-comment"></p>

<p>Do not quote me on this, but I think the IIT coaching industries make more <a href="https://www.businessinsider.in/education/news/iits-iisc-say-that-patchy-funding-is-delaying-institute-of-eminence-plans/articleshow/72103538.cms">money than the IITs</a> themselves. I understand the purpose of IITs is not to directly generate money, but if it would have more resources they can probably improve the infrastructure, employ better professors and improve the overall level of education.</p>

<h3 id="computer-science-education-in-india">Computer Science Education in India</h3>
<p>For vast majority of engineers in India, Computer Science is  one of the subjects you study in order to succeed in life. Just like you study Chemistry, you “study” Computer Science and once you learn all the “concepts”, you get a good job. (Apologies for so many quoted words, I can’t help putting them in quotes because they carry so much weight for me).</p>

<p>When people are in an average Indian college and if they are are lucky, information about some permutation/combination of the following is spread amongst the …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/">https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/</a></em></p>]]>
            </description>
            <link>https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667488</guid>
            <pubDate>Fri, 02 Oct 2020 22:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Play Spaceport Volumetric Live Video in Unity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24667094">thread link</a>) | @kerrarbone
<br/>
October 2, 2020 | https://antmedia.io/spaceport-volumetric-live-video-in-unity/ | <a href="https://web.archive.org/web/*/https://antmedia.io/spaceport-volumetric-live-video-in-unity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2>Volumetric Live Video</h2>
<p>This is the second part of the series <a href="https://antmedia.io/volumetric-video-container-2/" target="_blank" rel="noopener noreferrer">Spaceport Volumetric Video Container</a>. We pick up the containers back from the place where we created and read. In this tutorial, we’re going to walk you how to play <strong>Spaceport Volumetric Live Video</strong> using Unity. Don’t worry, it’s surprisingly easy to get the containers from the server and decode <strong>volumetric video</strong>, especially when controlling the <strong>container</strong> structure as we want.</p>
<h2>Modifying The Volumetric Video Container</h2>
<p>Let’s start by dividing the large <strong>volumetric container</strong> as many smaller containers that are broken up into ~10 frame increments(you can specify this size as you wish). We only need to buffer frames seconds in advance on the <strong>Unity App</strong> side as we divided the container up in this way. Normally, our CreateContainer() function is programmed to generate a single <strong>.space</strong> file. We will add one condition like the following figure.<br>
<img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-18-1024x340.png" alt="spaceport volumetric video" width="1024" height="340" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-18-1024x340.png 1024w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-18-300x100.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-18-768x255.png 768w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-18-1536x510.png 1536w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-18-600x199.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-18.png 1964w" sizes="(max-width: 1024px) 100vw, 1024px" title="How To Play Spaceport Volumetric Live Video In Unity 1"><br>
In the old version, a single container was containing one metadata, now each small container can hold its own metadata. The metadata is served first and it tells the client where to find each frame start positions. <span>Navigate to the directory of the Spaceport Container file and run the following command:</span></p>
<pre> g++ -I ~/local/include -L ~/local/lib -o output ObjContainer.cpp 10 -ldracoenc -lboost_serialization</pre>
<p>Each new container looks like the following:</p>
<p><img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/output1-1024x519.png" alt="Inside of New Volumetric Video Container" width="750" height="380" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/output1-1024x519.png 1024w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/output1-300x152.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/output1-768x389.png 768w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/output1-600x304.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/output1.png 1524w" sizes="(max-width: 750px) 100vw, 750px" title="How To Play Spaceport Volumetric Live Video In Unity 2"></p>
<p>Congratulations! You are done with the hard part, now you have simple containers that can be served over HTTP to watch Volumetric Live Video. Let’s set up a simple HTTP server to test it. I used NodeJs / <a href="https://www.npmjs.com/package/http-server" target="_blank" rel="noopener noreferrer nofollow">http-server</a> but you can create it however you want.</p>
<h2>Getting Containers From HTTP Server</h2>
<p>We only require a simpler request/response pair. Nowadays, the most common way to solve this problem is to utilize the “Networking” library in Unity.<span>&nbsp;We only need to call the function “<code>SendWebRequest()</code>”&nbsp; to get a volumetric container one by one, until we get a request error.</span> Note that web requests are typically done asynchronously, so Unity’s web request system returns a “yield” instruction.&nbsp;You have to wait until the request is completed. Now you’re done with making requests over <strong>http-server</strong>.</p>
<p><img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/unity-get-frame-1024x759.png" alt="ant media server spaceport" width="1024" height="759" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/unity-get-frame-1024x759.png 1024w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/unity-get-frame-300x222.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/unity-get-frame-768x570.png 768w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/unity-get-frame-1536x1139.png 1536w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/unity-get-frame-600x445.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/unity-get-frame.png 1796w" sizes="(max-width: 1024px) 100vw, 1024px" title="How To Play Spaceport Volumetric Live Video In Unity 3"></p>
<p>Do you remember how we read Volumetric Containers in the previous article? There are only a few fundamental differences between the two structures. We’ll do the same thing but this time, all the files will have the own <strong>metadata</strong>.</p>
<p><img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1024x720.png" alt="Volumetric Video ant media server" width="1024" height="720" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1024x720.png 1024w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-300x211.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-768x540.png 768w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1536x1080.png 1536w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-600x422.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16.png 1610w" sizes="(max-width: 1024px) 100vw, 1024px" title="How To Play Spaceport Volumetric Live Video In Unity 4"></p>
<p><span>Now let’s turn our eyes to the decoder.</span> We reconstruct the objects for each frame. As above, we will use <strong>MemoryStream</strong> class instead of <strong>BinaryReader.</strong></p>
<p><img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1-1024x777.png" alt="Volumetric Live Video spaceport" width="1024" height="777" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1-1024x777.png 1024w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1-300x228.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1-768x583.png 768w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1-1536x1166.png 1536w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1-600x455.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/carbon-16-1.png 1544w" sizes="(max-width: 1024px) 100vw, 1024px" title="How To Play Spaceport Volumetric Live Video In Unity 5"></p>

<h2>Conclusion</h2>
<p>This article provides an overview of how to divide and handle volumetric video containers. That’s all folks, as we can see, we can change the container structure as we want and then reconstruct it for our purpose. We hope this article gave you some ideas for watching the live volumetric video. <span>If you have any questions or feedback don’t hesitate to write your thoughts.</span></p>
<p><img src="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/Annotation-2020-08-13-004735-1024x536.png" alt="Volumetric Live Video ant media" width="1024" height="536" srcset="https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/Annotation-2020-08-13-004735-1024x536.png 1024w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/Annotation-2020-08-13-004735-300x157.png 300w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/Annotation-2020-08-13-004735-768x402.png 768w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/Annotation-2020-08-13-004735-600x314.png 600w, https://i0.wp.com/antmedia.io/wp-content/uploads/2020/08/Annotation-2020-08-13-004735.png 1440w" sizes="(max-width: 1024px) 100vw, 1024px" title="How To Play Spaceport Volumetric Live Video In Unity 6"></p>
</div></div>]]>
            </description>
            <link>https://antmedia.io/spaceport-volumetric-live-video-in-unity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667094</guid>
            <pubDate>Fri, 02 Oct 2020 21:15:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the best dumb TV?]]>
            </title>
            <description>
<![CDATA[
Score 413 | Comments 412 (<a href="https://news.ycombinator.com/item?id=24666968">thread link</a>) | @evo_9
<br/>
October 2, 2020 | https://pointerclicker.com/best-dumb-tv/ | <a href="https://web.archive.org/web/*/https://pointerclicker.com/best-dumb-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>There are a few things you need to consider when you’re looking to buy a good dumb TV. Let’s take a closer look at each of them.</p><h3>Screen size</h3><p>The biggest challenge you will face when you’re looking for a good dumb TV is getting a good screen size. You will soon realize that there are not a lot of dumb TVs that come in the latest size standards for home entertainment.</p><p>A lot of dumb TVs only have 30-40-inch screens. If this size works for you, then you are in luck. However, in today’s standards, 30-40 inches is not enough screen real estate.</p><p>You may want to find something with at least a 50-inch screen. The good news is that they do exist and, according to our research, you can even go up to 65 inches.</p><p><strong>If you’re in hurry, here’s our recommendations</strong></p><table><thead><tr><th>Image</th><th>Product</th><th>Features</th><th>Price</th></tr></thead><tbody><tr id="product-723"><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer"><img src="https://m.media-amazon.com/images/I/419R0211LBL.jpg" data-src="https://m.media-amazon.com/images/I/419R0211LBL.jpg" alt="Sceptre 65 Inches 4K UHD LED TV"></a></td><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer">Sceptre 65 Inches 4K UHD LED TV</a></td><td><div><ul><li>Bright LED display and sharp contrast</li><li>65-inch 4K UHD, HDR and MEMC120</li><li>HDMI ports, component ports, optical and line audio outputs</li></ul></div></td><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer" data-style="">Check Price On Amazon</a></td></tr><tr id="product-724"><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer"><img src="https://m.media-amazon.com/images/I/51S-2IYjHFL.jpg" data-src="https://m.media-amazon.com/images/I/51S-2IYjHFL.jpg" alt="Sceptre 50"></a></td><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer">Sceptre 50″ 4K UHD Ultra Slim LED TV</a></td><td><div><ul><li>50-inch screen that supports 4K UHD</li><li>Mobile High-Definition Link (MHL) to stream videos from a smartphone</li><li>Stunning colors and image contrast</li></ul></div></td><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer" data-style="">Check Price On Amazon</a></td></tr></tbody></table><h3>Input ports</h3><p>Another thing that turns a regular dumb TV into a good dumb TV is the number of input ports it has. Since your dumb TV relies on external devices for display content, you will want several ports to ensure that you can plug in all your devices.</p><p>Having several input ports will allow you to switch between devices without having to physically unplug and plug them. Reaching behind your TV to do this can be very inconvenient.</p><p>HDMI ports are what most external devices today use. You will want at least 3 HDMI ports on your dumb TV. Having more HDMI ports will be better, especially if you’re thinking about getting a few more external devices.</p><h3>Monitors</h3><p>When looking for a good dumb TV, people often make the mistake of looking in the monitor category. A monitor may work for you, but there are a couple of reasons why they may not work as well as a TV.</p><p><a href="https://pointerclicker.com/how-to-clean-a-matte-monitor/" target="_blank" rel="noopener noreferrer">Monitor displays</a> are relatively darker than TV displays. This is because monitors are designed for people who sit up close.</p><p>It may not be a problem when you’re watching a movie in a dark room. If you watch with the windows open during the day, however, your monitor won’t be able to produce enough brightness to give you pleasant viewing experience.</p><p>Monitors also do not come with a TV tuner. This will be a problem if you’re thinking about watching local channels.</p><h2><span id="Does_a_great_dumb_TV_exist_in_2020">Does a great dumb TV exist in 2020?</span></h2><p>The short answer is yes. Although smart TVs are more popular, there are still a few great dumb TVs being manufactured.</p><p>You can visit your local electronic shop or search for one online. Below are some of our dumb TV recommendations.</p><h2><span id="Editors_recommendations">Editor’s recommendations</span></h2><p>We’ve put together a shortlist of our top dumb TV picks. Take a moment to review each one so you can make a better decision when you plan to make a purchase.</p><h3>1. Sceptre 50” 4K UHD (U518CV-UM)</h3> <p>Sceptre sells quite a number of dumb TVs as well as smart TVs. This particular one has a large 50-inch screen that supports 4K UHD.</p><p>It also comes with Mobile High-Definition Link (MHL) that allows you to stream videos from your smartphone. Sceptre also boasts about its stunning colors and image contrast.</p><h3 id="title"><span id="productTitle">2. Sceptre 65 inches 4K LED TV (U658CV-UMC)</span></h3><div><div data-aawp-product-id="B0198XNF6U" data-aawp-product-title="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC 2018" data-aawp-click-tracking="true"> <p><span>Sale</span></p><p><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC, 2018" rel="nofollow noopener" target="_blank"> <img src="https://m.media-amazon.com/images/I/41Q8eA+4zwL.jpg" data-src="https://m.media-amazon.com/images/I/41Q8eA+4zwL.jpg" alt="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC, 2018"> </a></p></div></div><p>If you want to step it up, you can opt for the 65-inch 4K UHD TV from Sceptre. It is going to cost you more, but it also comes with additional features.</p><p>It has a bright <a href="https://pointerclicker.com/can-you-use-a-laser-pointer-on-a-tv-screen/" target="_blank" rel="noopener noreferrer">LED display</a> and a sharp contrast. Its UHD upscaling will enhance your SD or HD videos so they display excellently in 4K. It also comes with HDR and MEMC120 to give you the best viewing experience.</p><p>This particular TV also has great connectivity options. HDMI ports, component ports, optical and line audio outputs. You won’t be needing additional ports with this TV.</p><h2><span id="What_is_the_dumb_TV">What is the dumb TV?</span></h2><p>When you walk through the video section in an electronic shop, you’re going to find an array of different TVs. Most of the newer ones you will have large high definition screens. And almost all of them are going to be smart TVs.</p><p>Smart TVs have taken over the home entertainment industry by storm. To the point where it has become more difficult to find one that does not have smart features. TVs lacking smart features are also called dumb TVs.</p><p>Dumb TVs are display screens with a built-in TV tuner. They also come with different input ports where you can input video information from an HDTV antenna, Blu-ray player, etc. The most common input ports are HDMI and AV.</p><p>What makes a dumb TV “dumb”? The difference between a dumb TV and a smart TV is that the former does not come with an operating system. It relies on external devices to convert data into video information that it can display.</p><p>All televisions that were manufactured before the invention of smart TVs are dumb TVs. Dumb TVs are still being manufactured today for various reasons, although they are less popular.</p><p>Smart TVs, on the other hand, are more like smartphones or computers. They come with an operating system and a handful of pre-installed apps. You can connect them directly to the internet and stream videos on YouTube, Netflix, and other popular platforms.</p><h2><span id="Why_do_people_need_a_dumb_TV_without_smart_features">Why do people need a dumb TV without smart features?</span></h2><p>As you learn more about what smart TVs offer, you may start to wonder why anyone would want to settle for a dumb TV. Smart TVs are more convenient, and they offer so many useful features.</p><p>While the popularity of smart TV increases, there are quite a few people who still prefer dumb TVs. There are a few reasons why you might opt to get a dumb TV. Let’s take a closer look at each of those reasons in more detail.</p><h3>Security and privacy</h3><p>When it comes to the internet, security and privacy are huge topics. There have been countless horror stories that resulted from having personal devices connected to the internet. If you’re connected, there is always going to be some sort of risk.</p><p>Smart TVs are said to be one of the most vulnerable to hacking and data theft. The FBI has even issued a warning of the risks.</p><p>One of the reasons for this is that smart TVs use automatic content recognition or ACR. ACR gathers information about what you watch and sends it back to the manufacturer. With this information, more relative ads can be shown when you’re browsing for something to watch.</p><p>Unfortunately, there are times when a third party receives the information captured by ACR. These third parties can do whatever they want with that information.</p><p>Many newer smart TVs also come with webcams and microphones. These can be used by hackers to spy on you while you’re watching your favorite show.</p><p>Many people are aware of the dangers of this. This is one of the main reasons there are still quite a few people who opt to get dumb TVs instead of TVs with smart features.</p><h3>Better set-top and stick options</h3><p>Another reason why people purchase dumb TVs is that they prefer to use other TV stick and set-top devices. These devices don’t cost a lot of money and they often work better than smart TVs.</p><p>A few of the more popular ones are the <span><a href="https://www.amazon.com/dp/B075XLWML4?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Roku Streaming Stick+" target="_blank" rel="nofollow noopener" data-aawp-product-id="B075XLWML4" data-aawp-product-title="Roku Streaming Stick+ | HD/4K/HDR Streaming Device with Long-range Wireless and Voice Remote with TV Controls  updated for 2019" data-aawp-click-tracking="true">Roku Streaming Stick+</a>&nbsp;<a href="https://www.amazon.com/dp/B075XLWML4?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Roku Streaming Stick+" target="_blank" rel="nofollow noopener" data-aawp-product-id="B075XLWML4" data-aawp-product-title="Roku Streaming Stick+ | HD/4K/HDR Streaming Device with Long-range Wireless and Voice Remote with TV Controls  updated for 2019" data-aawp-click-tracking="true"><span></span></a></span>, <span><span>No products found.</span></span>, <span><a href="https://www.amazon.com/dp/B0791TX5P5?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Amazon Fire TV Stick" target="_blank" rel="nofollow noopener" data-aawp-product-id="B0791TX5P5" data-aawp-product-title="Fire TV Stick streaming media player with Alexa built in includes Alexa Voice Remote HD easy set-up released 2019" data-aawp-click-tracking="true">Amazon Fire TV Stick</a>&nbsp;<a href="https://www.amazon.com/dp/B0791TX5P5?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Amazon Fire TV Stick" target="_blank" rel="nofollow noopener" data-aawp-product-id="B0791TX5P5" data-aawp-product-title="Fire TV Stick streaming media player with Alexa built in includes Alexa Voice Remote HD easy set-up released 2019" data-aawp-click-tracking="true"><span></span></a></span>, and <span><span>No products found.</span></span>. There are many more options in the market to choose from.</p><p>These devices connect to your WI-FI and allow you to stream content on popular platforms such as Netflix and YouTube.</p><p>All these devices have seamless UI’s and tons of different apps and features. They also come with <a href="https://pointerclicker.com/presentation-pointers-lcd-tv-screens/" target="_blank" rel="noopener noreferrer">remote controls</a> that support voice commands.</p><p>One feature many people find very useful in these devices is the casting feature. It allows you to use your TV as a larger display for your smartphone. You can play videos, view images, and browse the web on your smartphone and have it cast onto your TV.</p><p>You should also remember that technology is advancing a lot quicker than ever before. Your brand-new smart TV will be outdated in just a couple of years. The only way you’re going to be able to keep up with new features and security fixes is to buy a new TV.</p><p>You won’t need to replace your dumb TV to stay updated. All you need to do is purchase the latest stick or set-top device. You can get brand-new ones that already come with voice control for an affordable price.</p><p>Check out this video to learn more about stick and set-top devices.</p><div title="4K Streaming Device Round Up 2019: Apple TV vs Chromecast vs Roku vs Fire TV, Which is best for you?"><div id="WYL_H2Bq9X3a41A"><div id="lyte_H2Bq9X3a41A" data-src="https://pointerclicker.com/wp-content/plugins/wp-youtube-lyte/lyteCache.php?origThumbUrl=https%3A%2F%2Fi.ytimg.com%2Fvi%2FH2Bq9X3a41A%2Fhqdefault.jpg"><div><p>4K Streaming Device Round Up 2019: Apple TV vs Chromecast vs Roku vs Fire TV, Which is best for you?</p></div></div></div></div><h3>Interface issues on smart TVs</h3><p>When you use your smartphone or computer, you have two main input sources: pointing and typing. You don’t have either of those in a smart TV interface.</p><p>For the most part, you will use your TV’s remote to click through menus and an onscreen keyboard for typing. It will take you quite a number of button presses to type something into your TV’s search service.</p><p>Some smart TVs also come with poorly designed interfaces. It will take a lot of time trying to navigate around the interface.</p><p>On the other hand, the interfaces that come with newer sticks and set-box devices are more seamless. They also include voice commands and many support keyboard input from your smartphone.</p><h3>Unreliable apps on smart TVs</h3><p>App developers today need to work harder when it comes to compatibility. They need to make sure apps work well with smartphones, browsers, stick and set-top devices, smart TVs and more. Unfortunately, smart TVs are often the last priority.</p><p>This leaves smart TVs with unreliable apps that may crash or freeze. Older smart TVs may also not be compatible with app updates.</p><h2><span id="Conclusion">Conclusion</span></h2><p>Although smart TVs are the most popular choice, there are still a few reasons why you might opt to get a dumb TV. The good news is that there are still quite a few of them being manufactured.</p><p>It may be more challenging to find a good dumb TV, but there’s a good chance a few of them are being sold at your nearest electronics shop. If you want more options, finding them online will be your best bet.</p><p>You can check out online shops such as Amazon, BestBuy, Walmart, and Costco. You may also visit manufacturer websites and look through their …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pointerclicker.com/best-dumb-tv/">https://pointerclicker.com/best-dumb-tv/</a></em></p>]]>
            </description>
            <link>https://pointerclicker.com/best-dumb-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666968</guid>
            <pubDate>Fri, 02 Oct 2020 20:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Hiring 101: A Founder's Guide]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24666580">thread link</a>) | @ivankirigin
<br/>
October 2, 2020 | https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f | <a href="https://web.archive.org/web/*/https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666580</guid>
            <pubDate>Fri, 02 Oct 2020 20:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Fungi Can Teach Us a New Way of Looking at the World”]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24666521">thread link</a>) | @jseliger
<br/>
October 2, 2020 | https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;14a48b6b-06ab-4edb-83c8-8a827e78971b&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;cb1fb386-110c-428a-8794-8acaa2a62941&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w948_r1.77_fpx39.41_fpy49.97.jpg" srcset="https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w520_r1.77_fpx39.41_fpy49.97.jpg 520w, https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w948_r1.77_fpx39.41_fpy49.97.jpg 948w" width="948" height="536" sizes="948px" title="Merlin Sheldrake: &quot;When food becomes scarce, they some fungi can switch to a hunting mode.&quot;" alt="Merlin Sheldrake: &quot;When food becomes scarce, they some fungi can switch to a hunting mode.&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Merlin Sheldrake:</strong> "When food becomes scarce, they some fungi can switch to a hunting mode."</p>
<span>
Foto: Andrea Artz / DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p><em>Merlin Sheldrake, 32, earned his Ph.D. in tropical ecology at the University of Cambridge for his research into underground fungal networks in the tropical forests of Panama. Since then, he has not lost his fascination for them. He is the author of "Entangled Life: How Fungi Make Our Worlds, Change Our Minds and Shape Our Futures," which was published in early September.</em></p>


<div>
<p><strong>DER SPIEGEL:</strong> Dr. Sheldrake, we are here in London's Hampstead Heath. This place, you write in your book, means more to you than any other. Why is that?</p><p><strong>Sheldrake:</strong>&nbsp;I grew up here. This is where I learned to walk. Later, I climbed trees here, and still later, I had parties with friends. And my interest in nature has been incubated by this place.</p><p><strong>DER SPIEGEL:&nbsp;</strong>Your interest in nature in general, or fungi in particular?</p><p><strong>Sheldrake:&nbsp;</strong>Both. I've always been particularly interested in how things transform, how they grow and decompose. I was amazed how piles of leaves disappear over time. How did this transformation come about without me being able to see anything? Composting, I understood, is largely the work of fungi.</p>
</div>

<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>For most people, nature is primarily made up of plants and animals. What role do fungi play in between those two realms?</p><p><strong>Sheldrake:&nbsp;</strong>Fungi are of enormous importance. The basic principle of ecology is the relationships between organisms - and fungi form connections between organisms and so embody this idea.</p><p><strong>DER SPIEGEL:&nbsp;</strong>If fungi are so important, why don’t we see them all over the place?</p><p><strong>Sheldrake:</strong>&nbsp;Oh, fungi are everywhere. Just take this leaf: Between tens and hundreds of species of fungi live on and in it. No plant has ever been found in nature which does not have fungi in its leaves and in its shoots. Or take the roots of the grass we are walking on, the rotting twigs, the soil under our feet: There are fungi everywhere. You have yeast all over your body, in the lining of your ears, in your nostrils. Even in the air: At this moment, you are breathing fungi. Fifty million tons of fungal spores are floating in the atmosphere, the largest source of living particles in the air. And they change the weather by causing water droplets to form.</p>
</div>


<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>If fungi are so ubiquitous, why we know so little about them?</p><p><strong>Sheldrake:</strong>&nbsp;There are many reasons. The most obvious one is access. The fungus we see is nothing more than the fruit of the organism itself. The mycelium network that belongs to it is buried in the ground. It is as if we only saw acorns for one moment every year, but we couldn't see the magnificent oak trees.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Do even scientists underestimate the importance of fungi?</p><p><strong>Sheldrake:</strong>&nbsp;They did so for a long time, at least. Until the 1960s, fungi were thought to be plants. Only then did they gain taxonomical independence. The new sequencing techniques have changed that. Today, we can read the DNA in every teaspoon of soil and find out who is there.</p>
</div>


<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 39/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;6898059e-48ed-4593-8f39-f3151744b819&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>And? What does one find?</p><p><strong>Sheldrake:</strong>&nbsp;The kingdom of fungi is vast. There are six times more species of fungi than of plants, and only 6 to 8 percent of them have even been described. We still know so little! ! Just one thing is clear: There are many ways to be a fungus.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is perhaps the lack of appreciation for fungi because of the fact that they are not very nutritious and often even poisonous?</p><p><strong>Sheldrake:</strong>&nbsp;Many people think like that. But in fact, many mushrooms contain important minerals and they have a high content of antioxidants. They produce an amazing variety of substances that affect cancer, viruses or our immune system. And mushrooms are high in protein. Truffles are a good example of an edible fungus. After all, they want to be eaten. Truffles sit deep in the ground where no wind can spread their spores. They attract animals with a very subtle mixture of odors, so that these animals then eat them and spread their spores.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Some mushrooms lure us with substances that have a direct effect on our consciousness ...</p><p><strong>Sheldrake:</strong>&nbsp;Yes, about 200 fungal species contain psilocybin, a substance that people have been interested in because of its strong psychedelic effects.</p>
</div>

<div>
<p><strong>DER SPIEGEL:</strong>&nbsp;Such mushrooms cause hallucination and change the way we think. How do mushrooms benefit from making psychedelic drugs for humans?</p><p><strong>Sheldrake:</strong>&nbsp;We don’t know. The first mushrooms to make psilocybin lived 75 million years ago, long before humans arose. But the receptors that this substance binds to can also be found in many animals. Does psilocybin change the behavior of certain insects in a way that induces them to spread fungal spores? Or do they change the behavior of insects in a way that deters them from eating the mushrooms?</p><p><strong>DER SPIEGEL:</strong>&nbsp;Have you personally tried the effects of psychedelic mushrooms?</p><p><strong>Sheldrake:</strong>&nbsp;Yes, under their influence I realized that most of my consciousness was unknown to me. It was as if I had spent my life in a garden until then, and now I suddenly discovered that this garden has a gate through which I can enter a strange and wonderful forest, that was largely unknown to me.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Does the gate disappear once the effects of psilocybin fade away?</p><p><strong>Sheldrake:</strong>&nbsp;Not necessarily. Once you know that this forest exists, it is much easier to find your way into it.</p><p><strong>DER SPIEGEL:</strong>&nbsp;You even took part in a scientific study.</p><p><strong>Sheldrake:</strong>&nbsp;Yes, though it was LSD tested in that study. But both substances have similar effects. Among other things, it was to be examined whether LSD promotes creativity. Each participant had to name a problem they were currently working on and, under the influence of LSD, &nbsp;we were to try to solve that problem.</p><p><strong>DER SPIEGEL:</strong>&nbsp;And?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp; I found the effects of LSD very helpful in allowing me to approach questions from new angles and imagine the relationships between plant and fungus from different points of view.</p><p><strong>DER SPIEGEL:</strong>&nbsp;You attribute cognitive abilities to fungi. What makes you think so?</p><p><strong>Sheldrake:</strong>&nbsp;I've been thinking about this for a while. I'm interested in the way fungi perceive their environment and how they react to it. Information is continuously flowing through their decentralized bodies.</p><p><strong>DER SPIEGEL:</strong>&nbsp;What do fungi perceive?</p><p><strong>Sheldrake:</strong>&nbsp;Most importantly, they have extremely diverse chemical sensors. A fungus can be seen as a large, chemically sensitive membrane, so to speak, as one big olfactory epithelium. But many mushrooms can also perceive light and they are sensitive to gravity, to changes in temperature and to changes in pressure.</p><p><strong>DER SPIEGEL:</strong>&nbsp;So the fungi under our feet can sense that we are here?</p><p><strong>Sheldrake:</strong> Some fungi would detect the pressure of our steps, yes. And now the question is, how do they process all this information without a brain and how do they translate it into behavior, into action?</p><p><strong>DER SPIEGEL:</strong>&nbsp;Action? Behavior? What do fungi do?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp;Fungi are quite active. Take hunting, for example.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Excuse me? Mushrooms can hunt?</p><p><strong>Sheldrake:</strong>&nbsp;Yes. When food becomes scarce, some fungi can switch to a hunting mode. They build traps consisting of sticky loops or poisonous droplets. And with special substances, they lure nematodes into these traps.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is this really "behavior" of the kind we see in animals?</p><p><strong>Sheldrake:</strong>&nbsp;Well, we can run away from danger, fungi have to face it. Therefore, they defend themselves with the help of chemicals, or they regenerate. But that doesn't change the fact that fungi do make decisions, just as we do.</p><p><strong>DER SPIEGEL:</strong>&nbsp;What kind of decisions?</p><p><strong>Sheldrake:</strong>&nbsp;Fungi have many options: where to grow, what to eat, what nutrients to transport, whether to withdraw and when to hunt nematodes. Each fungus forms thousands of so-called hyphae - tiny tubes that can either grow, divide or fuse.</p><p><strong>DER SPIEGEL:</strong>&nbsp;If fungi make decisions, are they also capable of solving problems?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp;Absolutely. For example, their growth follows very efficient navigation algorithms. There are various experiments in which fungi very rapidly found the shortest route through a maze.</p><p><strong>DER SPIEGEL:</strong>&nbsp;If fungi are, as you claim, complex information processing networks, are they essentially a kind of brain?</p><p><strong>Sheldrake:</strong>&nbsp;No, I wouldn’t say that. But you are right: Neurons are tip-growing, electrically excitable, network-forming cells. And so are fungal cells.</p><p><strong>DER SPIEGEL:</strong>&nbsp;So mushrooms have a form of intelligence?</p><p><strong>Sheldrake:</strong>&nbsp;It depends on your definition of "intelligence." In a broad sense, all organisms show intelligence, albeit to different degrees. The study of cognition and intelligence arose from the study of the human mind. This resulted in a very human- and brain-centered view. I find it refreshing to extend these considerations to organisms that do not have brains. We shouldn't use ourselves as the yardstick to judge everything else in this world.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is there still a lot to discover in the field of fungi cognition?</p><p><strong>Sheldrake:&nbsp;</strong>Absolutely. Little is known about how fungi coordinate their behavior. We don't know the mechanisms by which they pass signals around. We've not fully understood the basic biology of mycelial growth.</p>
</div>

<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>But we do know a lot about the symbiotic relationship between mushrooms and plants …</p><p><strong>Sheldrake:&nbsp;</strong>… exactly, via the mycorrhiza, through which the fungus supplies the plant with minerals such as nitrogen and phosphorus, and the plant in turn provides the fungus with energy-rich sugars.</p><p><strong>DER SPIEGEL:</strong>&nbsp;How important is this symbiosis? If all fungi were wiped out in this forest floor, could the trees survive?</p><p><strong>Sheldrake:</strong>&nbsp;No. They would be prone to disease, just as we would be if it weren't for the bacteria in our intestines. This microbiome keeps us healthy. In this sense, soil is sort of the gut of our planet.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Many ecologists are enthusiastic about the "Wood Wide Web," by which trees are mysteriously connected via the fungi in the soil and allegedly even communicate via this …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f">https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666521</guid>
            <pubDate>Fri, 02 Oct 2020 20:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where our economy is, for the young response II]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24666338">thread link</a>) | @danap
<br/>
October 2, 2020 | http://dandymadeproductions.com/history.html | <a href="https://web.archive.org/web/*/http://dandymadeproductions.com/history.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://dandymadeproductions.com/history.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666338</guid>
            <pubDate>Fri, 02 Oct 2020 19:42:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The little things Apple misses from Steve Jobs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665999">thread link</a>) | @doersino
<br/>
October 2, 2020 | https://techreflect.net/2020/10/01/the-little-things-apple-misses-from-steve-jobs/ | <a href="https://web.archive.org/web/*/https://techreflect.net/2020/10/01/the-little-things-apple-misses-from-steve-jobs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

							
<article id="post-1193">

	
	
	<!-- .entry-header -->

	<div>
	
<p>There probably have been millions of articles written about the Apple of Tim Cook and how it differs from the Apple of Steve Jobs. I’ve always been hesitant to add to that.</p>



<p>Having worked at Apple for 12 years under Steve and 8 years under Tim, that gives me plenty of exposure to both eras. I’ll start with a quick review of the <strong>big things</strong> that people generally agree Apple misses from the loss of Steve before getting to the <strong>little things</strong>.</p>



<h3>The big things Apple misses</h3>



<p>After Steve died, the majority of pundits seemed to predict some level of doom for Apple, as if Steve were personally responsible for the entirety of every Apple product. It was as if he were the sole person making every decision at Apple. The second most common thing mentioned is the loss of Steve’s relentless curation of Apple products. It was argued that Steve had once-in a lifetime skills in these two categories.</p>



<p>This may be true, but it must be recognized than Apple has enjoyed great financial success under Tim Cook and also product success with Apple Watch and AirPods specifically. To balance it out, there were also duds like HomePod, neglect of the Mac, and a decline in software quality. But you could pluck similar things from the era when Steve was in charge.</p>



<figure><img src="https://techreflect.net/wp-content/uploads/2020/10/screen-shot-2012-01-28-at-6-28-23-pm.png" alt="" srcset="https://techreflect.net/wp-content/uploads/2020/10/screen-shot-2012-01-28-at-6-28-23-pm.png 669w, https://techreflect.net/wp-content/uploads/2020/10/screen-shot-2012-01-28-at-6-28-23-pm-295x300.png 295w, https://techreflect.net/wp-content/uploads/2020/10/screen-shot-2012-01-28-at-6-28-23-pm-266x270.png 266w" sizes="(max-width: 669px) 100vw, 669px"></figure>



<h3>The little things Apple misses</h3>



<p>What interests me the most is the little things Apple misses. Just like Apple used to be famous for the clever little touches they added to their products, Steve had many little facets to his personality. Each one may not be significant on its own, but together, I think they add up to a huge loss.</p>



<h4>Giddy excitement</h4>



<p>Steve had an infectious excitement that we felt working at Apple and that people couldn’t help but notice at product introduction events. </p>



<p>Seeing him around campus, he was either deep in thought—possibly talking with Jony Ive or another confidant—or often with a grin on his face. But he always had a spring in his step, even close to the end. He felt like a little kid in an adult body. If you were having a down day, it was hard not to be uplifted by the sight of your CEO practically skipping down the halls.</p>



<figure><img src="https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316-1024x576.jpg" alt="" srcset="https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316-1024x576.jpg 1024w, https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316-300x169.jpg 300w, https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316-768x432.jpg 768w, https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316-1536x864.jpg 1536w, https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316-480x270.jpg 480w, https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316-850x478.jpg 850w, https://techreflect.net/wp-content/uploads/2020/10/getty_128349414_2000133320009280124_274316.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Although I don’t question that Tim is excited about Apple, you just don’t feel it. He comes across far too rehearsed. Steve’s combination of being very articulate, possessing great presentation skills, and this giddy excitement made you want to feel the same excitement he did about the products. </p>



<h4>Technical prowess</h4>



<p>Steve was never considered to be much of an engineer, but he could speak engineer language and understood the smallest of technical details. Even though he would motivate and push engineers to do the impossible, he also understood what was currently possible. How else would you know what’s impossible to demand? 🙂</p>



<p>Steve spent his life around engineers and artists at both Pixar and Apple. Tim simply does not have that background so you can’t criticize him for lacking in it. Nonetheless, having a CEO of a tech company be very highly technically savvy is a huge win.</p>



<h4>Two peas in a pod</h4>



<p>It’s cliché to say, but Steve and Jony Ive were definitely greater than the sum of their parts. By losing Steve, we also lost a great deal of Jony as well. I don’t know Jony or much about him, but I feel like he never fully recovered from Steve’s death.</p>



<p>I would go to lunch fairly late every day and would inevitably see Jony and Steve having lunch and immersed in conversation. I’d often see them walking and talking together. They were joined at the hip. I typically would see him alone—on his way somewhere—or with Jony.</p>



<figure><img src="https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203-1024x576.jpg" alt="" srcset="https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203-1024x576.jpg 1024w, https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203-300x169.jpg 300w, https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203-768x432.jpg 768w, https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203-1536x864.jpg 1536w, https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203-480x270.jpg 480w, https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203-850x478.jpg 850w, https://techreflect.net/wp-content/uploads/2020/10/steve-jobs-jony-ive_41203.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I hate to criticize such a close friend of Steve’s but the decline in Apple software quality is pretty closely aligned with Jony taking ownership of it in addition to his usual hardware duties. Without Steve to balance him out, he was just out of his league.</p>



<p>iOS 7 was one of Jony’s first software projects, widely regarded as a train wreck which took several years to fix. You’ll often hear the phrase “this would never have happened under Steve” and in this case, I think it’s true. Steve was good at reeling things in and stripping them down and that’s a huge loss.</p>



<h4>Belief and respect</h4>



<p>Before working at Apple, I was used to working for relatively uninspiring and often clueless CEOs. One thing that I found refreshing at Apple was that—even though people had their differences—people respected Steve and believed in the direction he was taking the company.</p>



<p>This had a profound affect inside Apple. If Steve was pushing the company in a specific direction combined with that respect, it was much easier to do your day-to-day job. Most jobs involve a lot of smaller decisions that would never rise to Steve’s level. But because we knew the path we were on, it was easy to make these smaller decisions ourselves.</p>



<p>In a sentence, we understood the mission we were on and we respected the messenger.</p>



<h4>Visibility</h4>



<p>I’ve worked at companies with 200 employees where we’d see the CEO twice a year at company meetings. He was holed up in his office or meeting with his directs all the time—or maybe playing golf—and never interacted with anyone else.</p>



<p>I worked at Infinite Loop for 19 years, with 12 of those under Steve. For such a large company, Steve was a routine presence around the company. He was often walking in the inner quad area of the campus, in the hallways, and would drop in frequently on projects important to him. He ate in the café every day as far as I can tell.</p>



<p>It’s easy to feel like there’s no one steering the ship if you never see the captain, so his frequent presence was very comforting. Even saying hi to him felt like an acknowledgment that you were a part of what everyone was working towards.</p>



<h4>Culling</h4>



<p>You’ll sometimes hear stories about how Steve is this awful tyrant and how he cruelly disassembled a project someone was working on during a presentation. All these stories have one thing in common: they come from <em>former</em> Apple employees.</p>



<p>Now, you could argue that a current employee would never talk, but I think a disgruntled one would talk anonymously at least. There are many cases of this.</p>



<div><figure><img src="https://techreflect.net/wp-content/uploads/2020/10/ll-1.jpg" alt="" srcset="https://techreflect.net/wp-content/uploads/2020/10/ll-1.jpg 417w, https://techreflect.net/wp-content/uploads/2020/10/ll-1-300x195.jpg 300w, https://techreflect.net/wp-content/uploads/2020/10/ll-1-415x270.jpg 415w" sizes="(max-width: 417px) 100vw, 417px"></figure></div>



<p>I’m calling this trait “culling” because Steve was not only very direct, he was seeing how you handled the pressure. If what you were demoing to him was crappy, he would tell you it’s shit. Now, some people would take great offense at that, typically those with larger egos, while others see it as just part of the making great products.</p>



<p>Over time, I think this led to management and lead engineers being thick-skinned and willing to change when the CEO told them they were way off track. If you’ve worked in software, I think you can see the benefit of being able to take criticism.</p>



<p>Overall, I think it led to a stronger workforce that was less prone to petty politics or bad-mouthing others. Instead, people would criticize products, not people and that led to great people making great products.</p>



<h4>Hiring</h4>



<p>With a huge notable exception over his entire career— John Sculley—Steve really knew how to hire exceptional people. The talent pool that was inherited by the NeXT acquisition was phenomenal as well as hiring amazing people like Tim Cook.</p>



<p>I imagine a form of culling took place in a Steve interview as well. If you crumbled under difficult questions that might be highly critical of your current job, how could you survive at Apple?</p>



<h4>Public Presentations</h4>



<p>There’s general agreement that Steve was a great presenter, possibly one of the best ever. What is interesting to me is how that affected Apple employees. Certainly, having something you worked on or cared about demonstrated on a big stage with media present was a great feeling. But to have <em>Steve</em> be the presenter was an amazing feeling.</p>



<figure><img src="https://techreflect.net/wp-content/uploads/2020/10/ap080115083034-1.jpg" alt="" srcset="https://techreflect.net/wp-content/uploads/2020/10/ap080115083034-1.jpg 800w, https://techreflect.net/wp-content/uploads/2020/10/ap080115083034-1-300x205.jpg 300w, https://techreflect.net/wp-content/uploads/2020/10/ap080115083034-1-768x524.jpg 768w, https://techreflect.net/wp-content/uploads/2020/10/ap080115083034-1-396x270.jpg 396w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>FILE – In this Jan. 15, 2008, file photo, Apple CEO Steve Jobs holds up the new MacBook Air after giving the keynote address at the Apple MacWorld Conference in San Francisco. Apple on Wednesday, Oct. 5, 2011 said Jobs has died. He was 56. (AP Photo/Jeff Chiu, File)</figcaption></figure>



<p>When I worked on Mail in the very early days, we were generally in every keynote, primarily because there weren’t many apps on Mac OS X! But still, to have your work presented with the giddy excitement I mentioned previously was a great motivational factor.</p>



<h4>Internal presentations </h4>



<p>Only Apple employees saw these except for a few that leaked over the years. Employees would wait in line to see a his multi-hour communications meetings! How many can say that for their companies?</p>



<p>Even though Steve was a great marketer, these meetings were generally very straightforward and often very blunt. Not a lot of spin. Often a response would be “No. Next question!” rather than a drawn out politically savvy response.</p>



<p>Here’s one example of this. One employee got up to complain about his salary, feeling that Apple’s rising success—this was around 2005—was not reflected in his paycheck. Steve asked him “Do you have stock?” and he answered “Yes” and Steve answered with “Next Question!” </p>



<p>I’m sure he wasn’t the only one that felt like their salary could be higher but Steve’s response cut to the chase and people left thinking they had less to complain about. If we all work towards the success of the company and it’s reflected in the market, we had nothing to complain about.</p>



<p>And he was right.</p>



<h2>Conclusion</h2>



<p>There are some big gaping holes left behind by Steve, but also quite a few smaller ones that add up to something significant. He is sorely missed.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
			</div></div>]]>
            </description>
            <link>https://techreflect.net/2020/10/01/the-little-things-apple-misses-from-steve-jobs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665999</guid>
            <pubDate>Fri, 02 Oct 2020 19:10:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data from 70 Offer Negotiations Using a Career Agent]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665710">thread link</a>) | @brianliou91
<br/>
October 2, 2020 | https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary | <a href="https://web.archive.org/web/*/https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>Consider two graduating PhDs who are transitioning into industry. Both are incredibly busy finishing their research, writing their dissertation, and teaching. Both spend the same amount of time recruiting for industry roles - and both join the same company in a similar role. PhD #1, let’s call her Jane,  soon discovers she is being paid less than her peers for the same work and has a boss that won’t promote her. She’s forced to work doubly hard just to achieve parity with her co-workers, or else leave and start over somewhere new, wasting a year. PhD #2, let’s call her Joanne, in contrast, is happy with her job. She is paid similarly to her peers and has a clear path for growth at the company. What did Joanne do better?</p><p>We have now advised 71 PhDs to follow this second, better track and we understand what defines these trajectories. We hope this salary negotiation report educates similar individuals how to negotiate salary. The difference between these two individuals is not merit, nor is it about who interviewed better or does better work. The difference is in how they think and negotiate. Joanne understands that she is joining a business. Compensation and promotions are respectfully taken by her self-advocacy, not given by the company. Jane assumes that the company will take care of her once she proves herself and so does not ask for much at the beginning. Joanne sets expectations and gives feedback to her manager for a productive working relationship. This is a <em>virtuous</em> cycle: you ask and your manager sets the higher expectations that enable you to work upwards. Jane is reticent and does not want to damage relationships. This is a <em>vicious</em> cycle: you don’t ask and your manager doesn’t expect more, so you stagnate and it becomes even harder to advance. </p><p>This power of setting expectations is evident at the very beginning of your relationship with your employer, in the offer negotiation. You haven’t started work yet, but simply setting higher expectations from the outset enables you to get paid more and begins the positive, virtuous cycle. Here we quantify the impact of negotiating using Ralph by looking at the data from our first 71 PhD clients. Most of them came from computation-heavy PhDs and were transitioning into their first industry role in engineering or data science, or a research role in technology or quantitative finance. Our results reveal just how beneficial it can be to advocate for yourself, and how beneficial a Career Agent can be to advise you through this process of multiple offers and changes. Because while most people know they <em>should</em> negotiate, they don’t know how <em>far</em> to negotiate. Our data gives you insight into just how much you’re worth and how much room there is for offer changes. </p><p><img src="https://landen.imgix.net/blog_VkwwMuKsXVDkwaYZ/assets/KnTGkpeVnsGRSckK.jpg" alt="Tables.jpg"></p><p><img src="https://landen.imgix.net/blog_VkwwMuKsXVDkwaYZ/assets/uOGQqqzabfskEZzm.jpg" alt="Visualizations.jpg"></p><p><strong>High Level Results</strong></p><p>On average, our clients have increased their initial offer by 30% through negotiation using our insight and advising. This increase is calculated from changes in base salary, equity, and any annual, signing, or relocation bonus changes. This increase represents an average $75K more in the offer. As expected, having offers from multiple companies resulted in a larger increase from the baseline offer; however, even if clients only had an offer from a single company, they were still able to secure an average 20% increase from their initial offer. Having four offers resulted in a dramatic increase (56%) in the negotiated accepted offer.&nbsp;</p><p><strong>Negotiating You Are Likely Not Doing</strong></p><p>The majority of our clients (52%) changed their offer twice. This means they negotiated an increase once and then negotiated <strong>another</strong> increase. Usually this second change would occur after the company said no to any further changes. We were able to advise our clients to keep advocating for themselves and set initial expectations high, resulting in an average total increase of 39%.  When the offer changed once, it increased on average 18%. While the majority of this data comes from before COVID-19, we have advised 9 clients during COVID-19 with similar results. Our largest negotiated offer ever was achieved in March 2020 (<a href="https://www.withralph.com/blog/negotiated-a-143-offer-increase">the story here</a>). Our data from working with 70+ clients is clear: you can negotiate significant (and often multiple) increases in your offer if you know your true, competitive worth.&nbsp;</p><p>These results we hope debunk three common misconceptions that hinder a candidates' ability to negotiate a strong starting offer and set the stage for your upward growth.&nbsp;</p><p><strong>Misconception #1: Companies pay equally for the same role, level, and location in a new grad offer.</strong></p><p>We have seen two candidates with the same role, level, company, and location have a $35,000 base salary difference. We have seen equity range by more than $900,000 in a 4-year package in public company offers. We have data for new grad Google offers that start as low as ~$180K/year and end as high as ~$550K/year.</p><p>Even independent of a company's intent, if you don't negotiate you will be paid unequally because the highest paid individuals are always negotiating. The squeaky wheel gets the oil. </p><p><strong>Misconception #2: Interviewing with one company at a time is ok.</strong></p><p>The factor that affects your compensation the most is having multiple offers at the same time. Companies are a business. They will pay what they have to, not what they can. Our data shows having two offers increases your compensation by 5% and 4 offers increases your compensation by 56%.&nbsp;Companies interview candidates they have no intention of hiring just to see the market. So should you.</p><p><strong>Misconception #3: The company increased my offer so I’ve successfully negotiated.</strong></p><p>The majority of companies start with a low offer that leaves room for the candidate to negotiate. You should define successfully negotiating as getting a change <strong>after</strong> the company has said no. This is when the negotiation has actually begun. Otherwise, you have just asked and they conceded. There has been no negotiation. Our data shows that it is rare for an offer <strong>not</strong> to change after it is initially given: 90% of offers change from the initial offer after negotiating.</p><p>Almost all of the negotiation challenges PhDs face come from a lack of information and experience in industry. They don’t know what to expect, don’t have time to research, and assume whatever the company says is correct. As our data shows, there is room for negotiating multiple times to achieve a 30% or greater increase in your initial offer. We hope that by sharing our findings, we can help you educate and advocate for yourself and feel more confident to set high expectations even before you begin working at your company. Ask yourself the question: <strong>how do I know I am getting the best offer possible?</strong> You might be surprised to know that you are likely worth a lot more than the initial offer you receive. </p><p>--</p><p>To read more content: <a href="https://www.withralph.com/blog/where-to-start">start here</a></p><p><a href="https://www.withralph.com/blog/where-to-start"></a>To get updated with insights and learnings: <a href="https://www.linkedin.com/company/ralph-inc">Follow us on LinkedIn</a></p><p>Questions? Email hi@withralph.com</p></div></div></div></div>]]>
            </description>
            <link>https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665710</guid>
            <pubDate>Fri, 02 Oct 2020 18:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Think About Chess]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665598">thread link</a>) | @FailMore
<br/>
October 2, 2020 | https://taaalk.co/t/how-to-think-about-chess#ld16z | <a href="https://web.archive.org/web/*/https://taaalk.co/t/how-to-think-about-chess#ld16z">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a keen, but not very accomplished, chess player. I'm looking to understand the basics of good chess strategy.</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I started playing chess when I was 6, and played seriously until the age of 18. My career highlights include 30th in the European U18s, captaining/vice-captaining England at most age groups, playing for Oxford in 3 Varsity matches and achieving rankings of 195 ECF and 2200 FIDE. I'm a software engineer at <a href="https://stripe.com/">Stripe</a> and blog at <a href="https://robertheaton.com/">robertheaton.com</a>.</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Admin</p>
          <p>13:27, 06 May 20 (edit: 13:28, 13 May 20)</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>This Taaalk was written on the first version of Taaalk in 2016.</p></div><div><p>The archive.org version is available <a href="https://web.archive.org/web/20160427012637/http://taaalk.co/taaalk/chess/robert-heaton-josh-summers">here</a>.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>A lot of people write about chess as having an opening game, a middle game and an endgame. When you're playing is that what's going through your head?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Everyone has an opening repertoire. Many people just have one answer for each question they might reasonably expect their opponents to ask, which means they get very good at playing those answers, but equally become very predictable. There are some openings that are razor sharp and precise, and require knowing many 15-20 move variations in order to not get destroyed without the game even starting. I personally prefer openings that are more conceptual, which tend to be slightly more flexible, require much less knowledge, but arguably lead to somewhat more boring positions because of this.</p></div><div><p>So when the middlegame comes around, it's probably the kind of position I've played many times before. My strategy is usually to throw lots of pieces at their king and hope they die or I can win some material. Since I'm hoping to win at this point, I probably don't start thinking explicitly about the endgame until little suggestions of things that might become relevant start cropping up. So if pawns become isolated or doubled, or we end up with opposite colored bishops, or with a bishop on the same color square as most of our pawns, etc. If I can take one of these small positional advantages then I will, and then effectively "bank" it until the endgame actually comes around. Having one or more of these might make me more likely to head towards an endgame too.</p></div><div><p>Endgames are really hard and require a lot of technique that I don't really have. Fortunately most other people don't either, because you just don't get to play that many of them.</p></div><div><p>It probably is fair to say that I'm pretty aware of the opening/middlegame/endgame distinction. The opening is where I'm playing pretty much from memory, the middlegame is where I try and win, and the endgame is what I might head towards if I think I have a tangible advantage but try and avoid otherwise.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So when you say that the endgame is what you might head towards - is the endgame not just the 'end of the game'? In which case won't most games have one? I know in the extremely amateur world of chess that I play in that most games come to a end where one side is actively checkmated. Is the endgame more unusual the higher up you go because a party will often resign when one side is in a dominant position?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>I guess this is a question for statistics to answer properly, but my gut says that there possibly are fewer endgames in higher level play. If you lose a bishop or a knight without any obvious compensation, you will almost definitely resign on the spot. That said, it's probably also true that fewer boneheaded mistakes mean that neither side may have had much of a chance to win before the endgame. Overall I'm not sure!</p></div><div><p>But when I say "might head towards the endgame", I mean that I might deliberately choose to swap off pieces and accelerate progress towards the end of the game. If I'm a pawn up then trading off pieces is likely a huge win for me, because whilst a queen + 2 rooks + 1 bishop + 2 knights + 7 pawns v the same but 6 pawns is not a huge advantage, a bishop + 5 pawns v a bishop + 4 pawns probably is. Small material advantages are a much bigger deal in the endgame and leave less room for your opponent to generate compensation, so if you are slightly ahead then deliberately swapping off pieces is very important. Games can naturally meander towards an endgame where neither side is too psyched about their chances, or they can be forced.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="6">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK - that makes a lot of sense. You mentioned that you like to keep your openings of a 'conceptual' nature. What kind of concepts are you basing your openings on?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="7">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Honestly I like openings that allow you to put your pieces on nice squares without thinking too hard, and then throw them all at your opponent's king. This is not a very sophisticated strategy, but it can be very hard to deal with if you aren't prepared (this is a good example). If you can get off the beaten track without doing anything too insane then you become much more familiar with the kinds of positions that result than your opponents, and develop a big box of patterns that have worked in the past.</p></div><div><p>This becomes somewhat less effective the higher level and more famous you get, as you start to become notorious for particular openings, and opponents can start preparing counters to them. This is where a degree of flexibility and unpredictability becomes invaluable, so that your opponents can't just put all their time into preparing for your Stonewall Dutch or Trompowsky, and also have to keep in mind that you might throw in a Benko Gambit or English Opening. It can be worthwhile playing these alternatives in high profile tournaments that will get their games into databases that your future opponents will see and get confused and upset by.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="8">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>The part on variation makes a lot of sense. So what are nice squares and what makes them nice?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="9">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>"Nice" squares is obviously a super-vague concept, but in this situation I mostly just mean:</p></div><div><p>Knights in the middle of the board</p></div><div><p>Bishops pointing towards the king</p></div><div><p>Rooks on open files or behind pawns that are marching towards their king</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="10">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK - now we're warming up!! A few things to deal with:</p></div><div><p>1) Why is it good to have knights in the middle of the board?</p></div><div><p>2) Why is it good to have bishops pointing at the king?</p></div><div><p>3) And i) what is an open file? and ii) why do I want my rook on it?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="11">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:12, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>1) Knights on the edge of the board don't attack many squares, knights in the centre of the board do. Because of their uniquely short range, they are the one piece that really benefits from being in the centre. A rook or bishop in the corner can still rake across the entire board, but a knight in the same spot looks pretty dumb.</p></div><div><p>2) If you want to attack the king (I do), you need to have your pieces attacking him and the squares around him! Even if you aren't planning on immediately checkmating anytime soon, you may be able to use threats against him to force smaller concessions or weaknesses.</p></div><div><p>3) An open file is one that isn't blocked by any of your pawns or pieces, and so if you put a rook at one end of it you'll be probing into some part of their position (hopefully a weak part!). This is the most direct way for your rooks to influence the game. As mentioned above, you don't necessarily need to be destroying or capturing anything in order for your pieces to be making your opponents' life awkward, so principles like "rooks on open files" will almost always be good things to at least look out for.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="12">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:14, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right. Would you say you're setting yourself up in the strongest position possible to deal with the largest number of variations down your opponents end (defensive) or setting yourself up to maximise your attacking options? Or a balance of the two?</p></div><div><p>When I'm playing with friends sometimes it feels like there is an unspoken agreement to let the other player 'set up' so to speak. To get their pieces into the strongest structural position before the WAR takes place. When you're playing is this something that happens? Or are you looking to start WAR while you set up your …</p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://taaalk.co/t/how-to-think-about-chess#ld16z">https://taaalk.co/t/how-to-think-about-chess#ld16z</a></em></p>]]>
            </description>
            <link>https://taaalk.co/t/how-to-think-about-chess#ld16z</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665598</guid>
            <pubDate>Fri, 02 Oct 2020 18:35:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Check your LAN network speeds with iperf3]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665579">thread link</a>) | @phiilu
<br/>
October 2, 2020 | https://phiilu.com/check-your-lan-network-speeds-with-iperf3 | <a href="https://web.archive.org/web/*/https://phiilu.com/check-your-lan-network-speeds-with-iperf3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Connecting to host 192.168.1.13, port 5201</span></p><p><span>[  5] local 192.168.1.179 port 63847 connected to 192.168.1.13 port 5201</span></p><p><span>[  7] local 192.168.1.179 port 63848 connected to 192.168.1.13 port 5201</span></p><p><span>[  9] local 192.168.1.179 port 63849 connected to 192.168.1.13 port 5201</span></p><p><span>[ ID] Interval           Transfer     Bitrate</span></p><p><span>[  5]   0.00-1.00   sec  15.0 MBytes   126 Mbits/sec</span></p><p><span>[  7]   0.00-1.00   sec  42.8 MBytes   359 Mbits/sec</span></p><p><span>[  9]   0.00-1.00   sec  56.7 MBytes   476 Mbits/sec</span></p><p><span>[SUM]   0.00-1.00   sec   115 MBytes   961 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   1.00-2.00   sec  10.8 MBytes  90.8 Mbits/sec</span></p><p><span>[  7]   1.00-2.00   sec  49.5 MBytes   416 Mbits/sec</span></p><p><span>[  9]   1.00-2.00   sec  52.1 MBytes   437 Mbits/sec</span></p><p><span>[SUM]   1.00-2.00   sec   112 MBytes   943 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   2.00-3.00   sec  17.7 MBytes   149 Mbits/sec</span></p><p><span>[  7]   2.00-3.00   sec  47.5 MBytes   398 Mbits/sec</span></p><p><span>[  9]   2.00-3.00   sec  47.3 MBytes   397 Mbits/sec</span></p><p><span>[SUM]   2.00-3.00   sec   113 MBytes   944 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   3.00-4.00   sec  24.8 MBytes   208 Mbits/sec</span></p><p><span>[  7]   3.00-4.00   sec  46.6 MBytes   391 Mbits/sec</span></p><p><span>[  9]   3.00-4.00   sec  41.0 MBytes   344 Mbits/sec</span></p><p><span>[SUM]   3.00-4.00   sec   112 MBytes   943 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   4.00-5.00   sec  26.0 MBytes   218 Mbits/sec</span></p><p><span>[  7]   4.00-5.00   sec  43.2 MBytes   362 Mbits/sec</span></p><p><span>[  9]   4.00-5.00   sec  42.9 MBytes   360 Mbits/sec</span></p><p><span>[SUM]   4.00-5.00   sec   112 MBytes   940 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   5.00-6.00   sec  32.2 MBytes   270 Mbits/sec</span></p><p><span>[  7]   5.00-6.00   sec  43.2 MBytes   363 Mbits/sec</span></p><p><span>[  9]   5.00-6.00   sec  36.6 MBytes   307 Mbits/sec</span></p><p><span>[SUM]   5.00-6.00   sec   112 MBytes   940 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   6.00-7.00   sec  33.4 MBytes   280 Mbits/sec</span></p><p><span>[  7]   6.00-7.00   sec  39.6 MBytes   332 Mbits/sec</span></p><p><span>[  9]   6.00-7.00   sec  39.3 MBytes   330 Mbits/sec</span></p><p><span>[SUM]   6.00-7.00   sec   112 MBytes   943 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   7.00-8.00   sec  27.5 MBytes   231 Mbits/sec</span></p><p><span>[  7]   7.00-8.00   sec  41.5 MBytes   348 Mbits/sec</span></p><p><span>[  9]   7.00-8.00   sec  43.0 MBytes   361 Mbits/sec</span></p><p><span>[SUM]   7.00-8.00   sec   112 MBytes   940 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   8.00-9.00   sec  23.2 MBytes   195 Mbits/sec</span></p><p><span>[  7]   8.00-9.00   sec  45.3 MBytes   380 Mbits/sec</span></p><p><span>[  9]   8.00-9.00   sec  42.6 MBytes   358 Mbits/sec</span></p><p><span>[SUM]   8.00-9.00   sec   111 MBytes   932 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[  5]   9.00-10.00  sec  26.2 MBytes   219 Mbits/sec</span></p><p><span>[  7]   9.00-10.00  sec  43.9 MBytes   368 Mbits/sec</span></p><p><span>[  9]   9.00-10.00  sec  43.4 MBytes   364 Mbits/sec</span></p><p><span>[SUM]   9.00-10.00  sec   113 MBytes   952 Mbits/sec</span></p><p><span>- - - - - - - - - - - - - - - - - - - - - - - - -</span></p><p><span>[ ID] Interval           Transfer     Bitrate</span></p><p><span>[  5]   0.00-10.00  sec   237 MBytes   199 Mbits/sec                  sender</span></p><p><span>[  5]   0.00-10.01  sec   236 MBytes   198 Mbits/sec                  receiver</span></p><p><span>[  7]   0.00-10.00  sec   443 MBytes   372 Mbits/sec                  sender</span></p><p><span>[  7]   0.00-10.01  sec   442 MBytes   370 Mbits/sec                  receiver</span></p><p><span>[  9]   0.00-10.00  sec   445 MBytes   373 Mbits/sec                  sender</span></p><p><span>[  9]   0.00-10.01  sec   444 MBytes   372 Mbits/sec                  receiver</span></p><p><span>[SUM]   0.00-10.00  sec  1.10 GBytes   944 Mbits/sec                  sender</span></p><p><span>[SUM]   0.00-10.01  sec  1.10 GBytes   940 Mbits/sec                  receiver</span></p><p><span>iperf Done.</span></p></div></div>]]>
            </description>
            <link>https://phiilu.com/check-your-lan-network-speeds-with-iperf3</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665579</guid>
            <pubDate>Fri, 02 Oct 2020 18:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Warns about Root.cern]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665503">thread link</a>) | @cozzyd
<br/>
October 2, 2020 | https://root.cern.ch/blog/false-positives/ | <a href="https://web.archive.org/web/*/https://root.cern.ch/blog/false-positives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      



<div id="main" role="main">
  
  



  <div>
    
      
    
     <p><span size="1">(2 October 2020)</span></p><p>Thank you for your reports of Google warning about some pages on https://root.cern. Let me give you some background:</p>

<p>We have investigated virus scanner reports on some of ROOT’s binaries. The ROOT team has invested about 2.5 work days into this investigation: we took this seriously. On top of that, CERN IT’s security team has investigated this independently, and also invested a notable amount of working hours. We were able to create binaries that were diagnosed as infected, by building <code>hadd.exe</code> “from scratch”. We are convinced that these reports are false positives. We found out that upgrading the compiler works around the issue.</p>

<p>We could report this as false positive to the vendors whose virus scanner was reporting some of ROOT’s binaries. This has a high latency, especially when adding the latency between the virus scanner engines tweaking their patterns and Google removing root.cern from the list of flagged sites.</p>

<p>We could argue with Google. This does not seem like a fast track option either.</p>

<p>Instead, we have removed the file in question. We are upgrading the compiler on our build machines, which means that we cannot create Windows binaries for new patch releases of ROOT 6.20 and before: only newer ROOT versions can be built with the newest Visual Studio version.</p>

<p>Given the removal of the file reported by Google, we have asked Google for a review of root.cern. As <a href="https://support.google.com/webmasters/answer/9044101#harmful_downloads">Google puts it</a>, “A review can take from a few days to a few weeks to complete.”</p>

<p>If you have ideas how to further improve the situation, please let us know by adding a comment below.</p>

<p>Please rest assured that we build our binaries on always up-to-date Windows installations running updated virus scanners, and that we do whatever we can to keep our binaries clean. This is the second time in 20+ years that ROOT files have been misdiagnosed as infected. To address this, we will scan binaries proactively on <a href="https://www.virustotal.com/">VirusTotal</a> from here on, before offering them for download, to avoid false positives affecting us again.</p>

<p>Axel, for the ROOT team.</p>

  </div>
</div>






    </div></div>]]>
            </description>
            <link>https://root.cern.ch/blog/false-positives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665503</guid>
            <pubDate>Fri, 02 Oct 2020 18:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Explaining a one-liner code with regular expression]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24665451">thread link</a>) | @ethink
<br/>
October 2, 2020 | https://medium.com./analytics-vidhya/thousand-separator-by-regular-expressions-with-python-and-javascript-7edf8ed7e331 | <a href="https://web.archive.org/web/*/https://medium.com./analytics-vidhya/thousand-separator-by-regular-expressions-with-python-and-javascript-7edf8ed7e331">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="3596">Using regular expression with Python and Javascript solutions: Solve Thousand Separator, an easy leetcode problem</h2><div><div><div><div><a rel="noopener" href="https://medium.com./@ezzeddinabdullah?source=post_page-----7edf8ed7e331--------------------------------"><div><p><img alt="Ezz El Din Abdullah" src="https://miro.medium.com/fit/c/96/96/1*1Hrm4GLucwFIp4hPW0ifww.jpeg" width="48" height="48"></p></div></a></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/5536/1*aTwZq7ceSHClNuAconBNig.jpeg" width="2768" height="1848" srcset="https://miro.medium.com/max/552/1*aTwZq7ceSHClNuAconBNig.jpeg 276w, https://miro.medium.com/max/1104/1*aTwZq7ceSHClNuAconBNig.jpeg 552w, https://miro.medium.com/max/1280/1*aTwZq7ceSHClNuAconBNig.jpeg 640w, https://miro.medium.com/max/1400/1*aTwZq7ceSHClNuAconBNig.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*aTwZq7ceSHClNuAconBNig.jpeg?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@mbaumi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener nofollow">Mika Baumeister</a> on <a href="https://unsplash.com/s/photos/numbers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener nofollow">Unsplash</a></figcaption></figure><p id="e478"><a href="https://leetcode.com/problems/thousand-separator/" rel="noopener nofollow">Thousand Separator</a> is an easy problem at leetcode, I hope you have read the problem carefully and have tried solving it. This problem requires to put a thousand separator in its right position of the number. The question is how you can iterate on such a number to write a dot (.) in every possible position.</p><p id="049d">You’re given an integer and the output should be a string with the thousand separators. Dealing with strings can be cumbersome and a problem like this can take multiple lines of code while you can do it literally in one-liner code if you really compacted the variables. While regular expression (shortened regex) can be seen complicated, this is due to the unclear readability of it, I will try to explain solving this problem in a more readable approach and a more expressing way to be able to understand and solve such problem in just one line of code and if you need to get deeper, I’ve put some references at the bottom.</p><p id="685e">Regular expression is dealing with patterns so that you can manipulate strings. In this problem, it seems we want to find a pattern that exists across the string with multiple positions and then put dots in every possible position.</p><p id="ed4d">To know how it works, we need to know two things:</p><ul><li id="3e2f"><em>pattern </em>— the pattern we want to match</li><li id="87b7"><em>repl — </em>what should be replaced with</li></ul><h2 id="dbc9">Example 1</h2><p id="2f28">Say we have this simple example 1234. The separator here should exist between 1 and 2 like this 1.234</p><p id="92fb">Using regex can make us search for a pattern and when we match this pattern correctly we can use it to substitute/replace the number(s) we captured. Grouping is a basic concept of regex, you can use parenthesis to group specific characters.</p><p id="9450">The pattern here can be <strong>one digit followed by 3 digits</strong>. This can be converted to a regular expression pattern like this <code>(\d)(?=(\d{3}))</code></p><pre><span id="f806"><strong>(\d) </strong>one digit…</span><span id="d2b4"><strong>(?= </strong>followed by…</span><span id="909a"><strong>   (\d{3}) </strong>3 digits</span><span id="737e"><strong>)</strong></span></pre><p id="9312">The pattern here should match 1 in <strong>1</strong>234</p><p id="1f88">So now we have the pattern, what else should we do with that?</p><p id="244b">It seems we have captured two groups here, one digit and 3 digits .. we’re just interested in the first group so we should replace that digit (<strong>1 </strong>here) with itself followed by a dot so that we can see <strong>1.</strong>234. That’s why <em>repl </em>here equals <strong>\1. </strong>or <strong>\$1. </strong>depending on the language you use</p><p id="3abe">Let’s say we want the separator here to be a comma, not a dot, <em>repl </em>here should equal <strong>\1, </strong>and <strong>\$1,</strong></p><h2 id="3cb1">Example 2</h2><p id="338b">Let’s see a more complicated example: 123456789 so the expected output should be 123.456.789</p><p id="fe22">The pattern here is different from the previous example because if it’s the same, the grouping will be to these bold numbers <strong>123456</strong>789 because in each number is followed by 3 digits until you reach 789 (the last 3 digits). So how can we approach this solution to only group the numbers that we should replace each and add dots?</p><p id="ae4b">Here we should group the 3 digits in a right way; we want to <strong>capture one digit which is followed by one or more groups of 3 digits which are not followed by any more digits</strong>. Let’s convert that into a regular expression pattern: <code>(\d)(?=(\d{3})+(?!\d))</code></p><pre><span id="fc30"><strong>(\d) </strong>capture one digit…</span><span id="d2e6"><strong>(?= </strong>which is followed by…</span><span id="1252"><strong>   (\d{3})+ </strong>one or more groups of 3 digits…</span><span id="3675"><strong>   (?!\d) </strong>which are not followed by any more digits</span><span id="99dc"><strong>)</strong></span></pre><p id="e594">With this pattern, the numbers highlighted will be matched 12<strong>3</strong>45<strong>6</strong>789. There you should replace both by each one plus a dot like this: 12<strong>3.</strong>45<strong>6.</strong>789</p></div></div></section></div>]]>
            </description>
            <link>https://medium.com./analytics-vidhya/thousand-separator-by-regular-expressions-with-python-and-javascript-7edf8ed7e331</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665451</guid>
            <pubDate>Fri, 02 Oct 2020 18:22:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 Habits That Help Me as a Manager]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665244">thread link</a>) | @martymatheny
<br/>
October 2, 2020 | http://www.martymatheny.com/blog/2020/10/2/10-habits-that-help-me-as-a-manager | <a href="https://web.archive.org/web/*/http://www.martymatheny.com/blog/2020/10/2/10-habits-that-help-me-as-a-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1601658998244" id="item-5f775f9b7e36cf63ac5e9f98"><div><div><div data-block-type="2" id="block-d26faa974e7c46179664"><div><p>Many years ago I was interviewing for a management job at a growing tech company. After a long day of meeting with engineers and product managers, I made it to the final boss, the VP of Engineering. He introduced himself, put his hands together at the fingertips, and said, "Tell me your top accomplishments for the last three and six months."</p><p>I froze up. It had been a very busy year. I’d worked on a wide variety of things. I stalled. "Hmm... Let me think about that." He quickly cut me off. “No. That's not a good answer. You should be able to answer that without hesitation. Communicating the value you bring to the organization is an important part of being a leader. My advice for you is to set a calendar reminder. Every three months write down the top achievements for your team and your personal ones."</p><p>I was not offered that job. But I appreciated the great advice! After the interview, I set a calendar reminder, and every quarter since that day I have written down my top accomplishments. It's a very helpful habit for reasons I describe below. Many things that help me succeed in my role as an engineering leader are simple habits, like that one. I developed a set of daily, weekly, quarterly and annual routines that I'll share in this post. Many were tips given to me by coworkers, some I read about in blogs and books.</p><p>These habits are all personal actions I would practice regardless of the type of project or team I’m working with. This is definitely not a comprehensive list of everything managers need to do to be effective. They’re just a few things I find helpful. Here are my habits:</p><p><strong>Identify Your Top Six Priorities</strong></p><p>I use a to-do list in<a href="https://evernote.com/"> <span>Evernote</span></a> to record all my pending tasks. During the day I’ll agree to do some work and add a task to the bottom of my to-do list. The list gets long during busy periods, so I prioritize it daily using the<a href="https://jamesclear.com/ivy-lee"> <span>Ivy Lee Method</span></a>. Productivity consultant Ivy Lee recommended this method to Charles Schwab in 1918 as a way to help his company’s executives be more efficient. It’s very simple. At the end of work each day you rank your top six priorities in order of importance. When you start the next day, work on the tasks in priority order. That’s it! I typically set out to tackle three-to-six tasks per day, so the Ivy Lee number seems appropriate.</p><p><strong>Write and Share Daily Intentions</strong></p><p>Most software engineering teams start each day with a “standup” meeting where each member summarizes what they plan to focus on that day. The team I currently work on is distributed across US and EU time zones, so we do this asynchronously by writing that info into a Slack channel used for daily standup posts. I find it helpful to record my daily intentions as it motivates me to complete what I publicly said I’d do. Having those entries written down also helps me remember what I accomplished when I write my weekly status update.</p><p><strong>Keep an Emotional Journal</strong>&nbsp;</p><p>Since the COVID-19 pandemic started I’ve been trying to keep closer tabs on my emotions. After experiencing strong feelings like stress, irritation, fear, anger, or excitement, I jot down a brief note about the emotion and situation in a notebook I keep on my desk. Recognizing and naming your feelings is an important part of building emotional intelligence. My daily entries are useful to reflect on when I write my weekly impact journal entry. They often describe the emotional roller coaster I experience while encountering setbacks, pitfalls, and small wins.</p><p><strong>Update My Calendar</strong></p><p>It’s important to start your week with a good plan. As a manager in a medium-sized company, I usually have 2 to 4 hours of meetings per day. Many of those are recurring like 1-on-1’s and weekly staff meetings. Others are ad-hoc project meetings that I need to prepare for in advance. I take a few minutes each Monday morning to look at the week ahead, canceling or declining meetings I don’t need to attend, and adding blocks of personal time for accomplishing the tasks on my “top six priorities” list. This helps me spend my time intentionally.</p><p><strong>Exercise</strong></p><p>Exercise is an important tool I use to manage stress. I’ve been going to the gym twice a week for years and doing the same simple workout. It’s such a regular habit that, after years of repetition, it requires no will power or deliberate effort on my part. It has been tricky adapting my exercise habits during the pandemic, but I’ve made do with jogging, YouTube yoga, and buying a bench and a few free weights for my basement. Whatever routine I follow must be so easy that I have no excuse not to do it. I also listen to things I enjoy while exercising like music, podcasts, and audiobooks as a rewarding motivator.</p><p><strong>Review Indicator Metrics</strong></p><p>In the seminal management book “<a href="https://www.amazon.com/High-Output-Management-Andrew-Grove/dp/0679762884"><span>High Output Management</span></a>”, Andy Grove recommends establishing indicators to help you understand how you’re progressing towards your goals. Pursuing metrics blindly can cause unintended problems, so Grove recommends using “paired metrics” that show both the positive effects of your teams’ focus as well as the negative consequences. An example is pairing Jira velocity (quantity) with the bug rate (quality). I’ve managed infrastructure owning teams over the last few years, so I’ve tracked metrics like:</p><ul data-rte-list="default"><li><p>new platform adoption %</p></li><li><p>weekly production incidents</p></li><li><p>off-hours paged while on-call</p></li><li><p>security tasks open past due date</p></li></ul><p>Every Friday morning I add a new column in my “indicator metrics” spreadsheet then record 10 metrics for the week. This process helps me model how work flows through the system, and allows me to see if the team made progress or was interrupted by reactive tasks. It also produces data I use to create charts showing trends like the percentage of customers migrated to the new platform over the last six months.</p><p><strong>Write in an Impact Journal</strong>&nbsp;</p><p>During an all-hands meeting, a VP at my company mentioned they keep a work journal where they wrote down the impact they made each week and how they felt about it. I started doing this and found it’s a very useful way to reflect. After starting his habit, you can scan the weekly wins you recorded every three months to remember the highlights from the quarter. Writing down your impact is doubly useful because you can immediately copy-paste it into your weekly status report. I’ve also found it interesting to read through my emotions from the last three and six months. When I read about my greatest worries and fears months after a stressful situation has been resolved, it reminds me of the powerful emotions we experience during challenges, and that every crisis is eventually resolved one way or another.</p><p><strong>Share a Weekly Update</strong></p><p>Information flow within your organization is critical and it helps to have a planned, consistent approach. This often looks like a weekly email, shared doc, or internal blog post shared with your manager and ideally with your stakeholders. There’s great advice on how to do these including<a href="https://twitter.com/lara_hogan"> <span>Laura Hogan</span></a>'s “<a href="https://larahogan.me/blog/week-in-review/"><span>Week in Review Leadership Comms</span></a>” and my colleague<a href="https://twitter.com/JadeRubick"> <span>Jade Rubick</span></a>’s “<a href="https://www.rubick.com/infobits-for-information-flow/"><span>How to be an information flow superhero</span></a>”. Currently, my process is writing a “reflection” on Friday mornings in<a href="https://www.koan.co/"> <span>Koan</span></a>, an OKR tracking tool. It's visible to leaders in my org and I also share it with the team I manage. The format of the update is: things the team accomplished, things I got done, after-hours on-call support issues, priorities for next week, and concerns I’d like to raise. I write this after reviewing indicator metrics and writing my impact journal entry, so it’s mainly a copy-and-paste exercise. As we’re all remote workers during the pandemic, this habit is even more valuable. Your manager and stakeholders need to know where your team is focused, what’s holding you back, what's finished, and what you’re working on next.</p><p><strong>Record My Quarterly Accomplishments</strong></p><p>Every three months I write down my top achievements under these categories:&nbsp;</p><ul data-rte-list="default"><li><p>Team accomplishments</p></li><li><p>Communications (internal blog posts)&nbsp;</p></li><li><p>Process work</p></li><li><p>Helping other managers</p></li><li><p>Hiring</p></li></ul><p>I scan through my impact journal entries from the last 12 weeks and copy-paste the most impressive items into the quarterly accomplishment list. When it comes time for my performance review, which happens every six months at my company, I simply combine the lists from the last two quarters then share with my manager. Nice and easy.</p><p>It's great having a record from each quarter going back for years of the things I've helped my team do and other things I've done personally. If anyone asks what I've done over the last year, I know where to look to help jog my memory. Sometimes I go back through the lists during times of doubt and uncertainty to help me remember what is possible. Reflecting on how you overcame past struggles can provide insight into your current challenge.</p><p><strong>Create Personal OKRs</strong></p><p>Each year on January 1st, I open a Google doc and create a list of personal OKRs (objectives and key results) for the year. I usually have three or four top objectives with about five measurable results under each one. After writing my list of new year’s resolutions, I set a biweekly calendar reminder to revisit and update my progress.<a href="https://twitter.com/cwodtke"> <span>Christina Wodtke</span></a>, author of the book<a href="https://www.amazon.com/gp/product/0996006028/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=0996006028&amp;linkCode=as2&amp;tag=eleganthack&amp;linkId=S5TUIOCJ66ZD4NMG"> <span>Radical Focus</span></a> on OKRs, has some<a href="http://eleganthack.com/personal-okrs-three-years-later/"> <span>great tips about using personal OKRs here</span></a>.&nbsp;</p><p>Personal OKRs help me focus on my health, family, friendships, and things I aspire to do outside my 8-to-5 job. Life is not all about work. It can be easy to continue thinking about work challenges on nights and weekends. This habit helps remind me there are other important things in my life.</p><p>Have you formed a productivity habit you find particularly useful? Is one missing from my list? I’m curious about what works for you. Feel free to share your favorite habit in the comments below. Thanks!</p></div></div></div></div></div>
      
    </div></div>]]>
            </description>
            <link>http://www.martymatheny.com/blog/2020/10/2/10-habits-that-help-me-as-a-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665244</guid>
            <pubDate>Fri, 02 Oct 2020 18:03:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Promoted: A Counterargument]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665130">thread link</a>) | @lacker
<br/>
October 2, 2020 | https://lacker.io/tech/2020/10/02/how-to-get-promoted.html | <a href="https://web.archive.org/web/*/https://lacker.io/tech/2020/10/02/how-to-get-promoted.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Recently I read Slava’s post on <a href="https://defmacro.substack.com/p/how-to-get-promoted">How to get promoted</a>.
I have a lot of respect for Slava, but I don’t agree with this post. So I thought I would share how I
think about it.</p>



<p>Slava is right about one important thing, that many people in Silicon Valley misunderstand what it
takes to get promoted. Many people assume that promotions just come naturally to people who deserve
them, and this is incorrect. The mentality here is like</p>

<ol>
  <li>Do good work</li>
  <li>???</li>
  <li>Promotion!</li>
</ol>

<p>To get promoted, you need to figure out Step 2. But how?</p>



<p>I mean this in a linguistic sense! If you think about it as “getting
promoted”, you are using the passive voice. You’re omitting
information. The laws of nature aren’t promoting you. Some specific
person at your company is the most important decisionmaker for your
promotion. To get promoted, you need to understand who that
decisionmaker is, and what sort of performance they want from you to
get a promotion. The mentality here is like</p>

<ol>
  <li>Do good work</li>
  <li>Convince the key decisionmaker that your work deserves a promotion</li>
  <li>Promotion!</li>
</ol>

<p>Who is the key decisionmaker? It depends on what your role is. If
you’re a software engineer, the key decisionmaker is probably just
your manager. Maybe it’s your manager’s manager. If your company is
smaller, maybe it’s just the CEO. But if you’re trying to get
promoted, you need to figure out who this person is, and what they
want.</p>



<p>If you have a good manager, you can simply ask them. Ask your manager
how promotion decisions are made, who the key decisionmakers are, and
more specifically ask them what you need to achieve in order to get
promoted.</p>

<p>If you have an inexperienced manager, maybe they aren’t able to
explain this to you. Or, maybe you just
won’t accept what your manager telling you, that you aren’t ready for a
promotion because you need to do better work.</p>

<p>Sometimes, it sounds like your manager is asking the impossible of
you, in order to get promoted. Sorry! That may or may not be your
manager’s fault, or your fault. I don’t know. At least you’re having
the conversation.</p>

<p>Sometimes it is impossible for you to get promoted on your current
team. You’re a senior engineer, and you want to make staff engineer,
but what you’re working on just isn’t important enough to merit a
promotion. This isn’t necessarily your manager’s fault, although often
a good manager can help you figure out how to navigate this.</p>



<p>So what’s the right strategy for someone who only cares about
promotion? Slava’s thoughts:</p>

<p><em>The winning strategy is to ignore company metrics completely and move
between projects every eighteen months so that nobody notices.</em></p>

<p><em>Wouldn’t people notice anyway? Rank and file employees will, but not
the management. In a fast growing company things change very quickly.</em></p>

<p>To me, this just sounds like a case of bad management. It’s hard to
manage a fast-growing startup, and bad management happens. But you
won’t find bad management everywhere. And often, what seems like bad
management from afar, is actually decent management grappling with a
seemingly impossible problem, once you dig into the details.</p>

<p>Instead, I think the best strategy for someone who only cares about
promotion is to do the unsexy work that management thinks is
important, but is having a hard time recruiting people for. Everybody
wants to work on the VR project. Nobody wants to fix the billing
system. Everybody wants to add a new feature to the consumer
app. Nobody wants to be responsible for fixing the database service that
recently caused a big outage. Work on the important stuff that nobody
wants to do.</p>

<p>People who do this are incredibly valuable to an organization, and
usually end up rewarded. Part of being a good manager is to figure out
who is willing to do the unsexy but critical work, and to reward these
people when they succeed at it.</p>



<p>In summary, my career advice for opportunists is to ask your manager
what it will take to get promoted, and then do it. If that isn’t
working, try working on a project that nobody wants to work on, but
management thinks it’s really important. The rituals and management
fashions, don’t worry about it. Spend your mental energy on getting
stuff done.</p>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://lacker.io/tech/2020/10/02/how-to-get-promoted.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665130</guid>
            <pubDate>Fri, 02 Oct 2020 17:53:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mp3 to Text]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24664763">thread link</a>) | @sabbakeynejad
<br/>
October 2, 2020 | https://www.veed.io/tools/mp3-to-text#hn-new | <a href="https://web.archive.org/web/*/https://www.veed.io/tools/mp3-to-text#hn-new">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="Intro"><div><div id="w-node-be84c295ef36-ccc0cf0b"><h2><strong>Turn your MP3 into text files, online</strong></h2><p>Do you want to transcribe the speech from your MP3 into a text file? Well, now you can, with VEED! VEED’s online auto transcription tool is fast, free, and easy to use. Compatible not just with MP3s, but with WAVs, AACs, OGGs, M4As, and even video files - you can convert to text with the click of a button</p></div><p><img alt="" loading="lazy" src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png" sizes="(max-width: 479px) 100vw, (max-width: 767px) 87vw, (max-width: 991px) 728px, 65vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png 1280w"></p></div><div><div id="w-node-be84c295ef39-ccc0cf0b"><h3><strong>MP3 to Text, Online</strong></h3><p>With VEED you can upload your MP3 files in your browser, no software required, and have a text transcription ready in no time</p></div><div id="w-node-be84c295ef3a-ccc0cf0b"><h3><strong>Automatic</strong></h3><p>No longer do you have to sit and listen, typing along to your MP3 files. Now VEED transcribes your MP3s automatically</p></div><div id="w-node-be84c295ef3b-ccc0cf0b"><h3><strong>Fast</strong></h3><p>Our super-fast, cloud-based servers will have your audio files uploaded, transcribed, and converted into text files in a matter of seconds. It’s so easy!</p></div><div id="w-node-be84c295ef3c-ccc0cf0b"><h3><strong>Edit</strong></h3><p>If you want to change anything, or add a note or comment, just click on a line of transcription and start typing!</p></div><div id="w-node-be84c295ef3d-ccc0cf0b"><h3><strong>Different Languages</strong></h3><p>VEED is able to recognise and transcribe languages from all over the world - English, Spanish, French, Chinese, and many more</p></div><div id="w-node-be84c295ef3e-ccc0cf0b"><h3><strong>Video Transcription</strong></h3><p>You can also upload video files (in multiple formats) and create transcriptions, add subtitles, or download subtitle (.srt) files</p></div></div></div><div id="How-to"><div><h2>How to transcribe MP3 to text:</h2><p>Transcribe your MP3 in 3 easy steps</p></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7b5d102969e0f443e9_cloud.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>1. Upload</strong></h3><p>Upload your MP3 files to VEED. VEED is all online, no software required</p><p>‍</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7a7679911e1f802d1d_scissors.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>2. Convert to text</strong></h3><p>Under ‘Subtitles’, click ‘Auto Subtitles’, choose your language, and that’s it! Your MP3 transcript is generated</p><p>‍</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7afbaf558411481ae3_Share.png" loading="lazy" width="32" alt=""></p></div><div><h3><strong>3. Download</strong></h3><p>You can now download in multiple formats - .txt, .vtt, .srt - whatever you need</p></div></div></div><div><div><p><h4>How to use VEED - Make social media video content online</h4><h5>591 views</h5></p></div></div></div><div id="use-cases"><div><h2>Why use our MP3 to Text tool?</h2><p>Turn your MP3s into text files, automatically</p></div><div><div><h3><strong>Quick</strong></h3><p>No need to download any software, you don't even need an account. Get started right away, with our super-fast MP3 to Text tool</p></div><div><h3><strong>Easy</strong></h3><p>You can create transcriptions of your MP3 with a single click, and make line-by-line edits with ease</p></div><div><h3><strong>Versatile</strong></h3><p>You can export your MP3 transcription as a text file, subtitle file, whatever you need</p></div></div></div><div id="testimonials"><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3fcd9f6ea642218575ff6d_quote.png" loading="lazy" width="28" alt=""></p><h2>What they say about <span>VEED</span></h2></div><div><div data-animation="slide" data-duration="500" data-infinite="1"><div><div><div><div><p>Veed is a great piece of browser software with the best team I've ever seen.</p><p>‍</p><p>Veed allows for subtitling, editing, effect/text encoding, and many more advanced features that other editors just can't compete with. The free version is wonderful, but the Pro version is beyond perfect. Keep in mind that this a browser editor we're talking about and the level of quality that Veed allows is stunning and a complete game changer at worst.</p></div><p><strong>Chris Y.</strong></p></div></div><div><div><div><p>I love using VEED&nbsp;as the speech to subtitles transcription is the most accurate I've seen on the market.</p><p>‍</p><p>It has enabled me to edit my videos in just a few minutes and bring my video content to the next level</p></div><p><strong>Laura Haleydt</strong> - Brand Marketing Manager, Carlsberg Importers</p></div></div><div><div><div><p>The Best &amp; Most Easy to Use Simple Video Editing Software!</p><p>‍</p><p>I had tried tons of other online editors on the market and been disappointed. With VEED I haven't experienced any issues with the videos I create on there.</p><p>‍</p><p>It has everything I need in one place such as the progress bar for my 1-minute clips, auto transcriptions for all my video content, and custom fonts for consistency in my visual branding.</p></div><p><strong>Diana B - </strong>Social Media Strategist, Self Employed</p></div></div></div></div></div></div><div id="more-things"><div><div><h2><strong>More than just an MP3 to Text tool</strong></h2><p>VEED is so much more than just an MP3 to Text converter - you can edit and create all kinds of video and audio. Create YouTube video intros, auto-generate subtitles, create Instagram Stories with links and stickers, add sound effects to your audio, join MP3 files together, and so much more!</p></div><p><img src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png" alt="" sizes="(max-width: 479px) 100vw, (max-width: 767px) 96vw, (max-width: 991px) 728px, 65vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png 1600w"></p></div></div></div></div>]]>
            </description>
            <link>https://www.veed.io/tools/mp3-to-text#hn-new</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664763</guid>
            <pubDate>Fri, 02 Oct 2020 17:15:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists develop 'super enzyme' that breaks down plastic faster than ever]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24664510">thread link</a>) | @soperj
<br/>
October 2, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A team of international scientists have developed what they call a "super enzyme" that can break down plastic into is original building blocks so it can be recycled infinitely.&nbsp;</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5746639.1601578207!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1190912666.jpg"></p></div><figcaption>Plastic waste litters the shoreline in Koattey wetlands on Dec. 14, 2019, in Hithadhoo, Maldives.<!-- --> <!-- -->(Carl Court/Getty Images)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Scientists develop 'super enzyme' that breaks down plastic faster than ever"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/91/606/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:33</span><span>Scientists develop 'super enzyme' that breaks down plastic faster than ever</span></p></div></div></div></span></p><p><span><p><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/october-1-2020-episode-transcript-1.5748666">Read Story Transcript</a></p>  <p>A team of international scientists have developed what they call a "super enzyme" that can break down plastic into its original building blocks so it can be recycled infinitely.&nbsp;</p>  <p>The team, <a href="https://www.cbc.ca/news/technology/plastic-eating-enzyme-pollution-1.4622923">which made waves in 2018 for engineering&nbsp;a plastic-eating enzyme</a>,&nbsp;has&nbsp;now combined it with a second enzyme to create&nbsp;a "<a href="https://www.eurekalert.org/pub_releases/2020-09/uop-pe092520.php">cocktail</a>" that can break down plastic six times faster.</p>  <p>"The enzymes are really specific to certain types of bonds in the molecular structure of the plastic. This means that it breaks it down into the same starting materials that were used to make the product to begin with," Erika Erickson, a bioengineering researcher at the U.S. Department of Energy's&nbsp;National Renewable Energy Laboratory (NERL), told <em>As It Happens </em>host Carol Off.&nbsp;</p>  <p>"So instead of having an inferior product in the end, you could start with the same starting materials and come back to an equal value plastic water bottle or food package, etc., on&nbsp;the other side, without needing to use petroleum products to get there."</p>  <p>The findings were <a href="https://www.eurekalert.org/pub_releases/2020-09/uop-pe092520.php">published this week in the journal Proceedings of the National Academy of Sciences.</a></p>  <h2>Nature finds a way — and scientists speed it up&nbsp;</h2>  <p>The whole thing began when scientists at NERL and Britain's University of Portsmouth discovered a naturally occurring enzyme in a waste recycling centre in Japan that was helping bacteria break down&nbsp;polyethylene terephthalate&nbsp;(PET), a common plastic developed in the '40s that's used to make&nbsp;water bottles, food packaging, film and more.&nbsp;</p>  <p>"There are natural enzymes that have been evolved to break down plastic," Erickson said. "And if you think about that, it's quite extraordinary that an organism has been able to do this in such a short amount of time."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/plastic-eating-enzymes.jpeg 300w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/plastic-eating-enzymes.jpeg 460w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/plastic-eating-enzymes.jpeg 620w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/plastic-eating-enzymes.jpeg 780w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/plastic-eating-enzymes.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/plastic-eating-enzymes.jpeg"></p></div><figcaption>Researchers from Britain's University of Portsmouth and the U.S. Department of Energy's National Renewable Energy Laboratory have combined two plastic-eating enzymes to create what they call a 'super enzyme.'<!-- --> <!-- -->(University of Portsmouth)</figcaption></figure></span></p>  <p>However, the natural process is a slow one. So the scientists tweaked the enzyme by adding amino acids to speed things up.</p>  <p>The resulting&nbsp;engineered enzyme, called&nbsp;PETase, could break down&nbsp;one water bottle in a couple months, Erickson estimated — a big step up from the hundreds of years it takes to break down in nature.</p>    <p>Now the team has combined&nbsp;PETase&nbsp;with a second enzyme from the same garbage eating bacteria, called MHETase, making the process even faster. The new super enzyme, Erickson&nbsp;said, could potentially break down one bottle in as little as six weeks.&nbsp;</p>  <p>She admits that's still "a little bit too slow for a real recycling process," but says it's a major step forward to creating a commercially viable system.&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/erika-erickson.JPG 300w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/erika-erickson.JPG 460w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/erika-erickson.JPG 620w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/erika-erickson.JPG 780w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/erika-erickson.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/erika-erickson.JPG"></p></div><figcaption>Erika Erickson is postdoctoral researcher in bioengineering a the U.S. Department of Energy's National Renewable Energy Laboratory.<!-- --> <!-- -->(Werner Slocum/NREL)</figcaption></figure></span></p>  <p>The way plastic is recycled now is not very efficient or cost-effective, says Erickson.</p>  <p>"In&nbsp;mechanical recycling, the plastic gets ground down into small pieces and then melted and then reformed into a new product," she said.</p>  <p>"But in the process of doing that, all of the contaminated dirt or food products or other types of plastic get mixed into that. So the quality of the recycled good is usually quite low compared to the original."</p>  <p>With an enzymatic approach, however, the plastic is recycled in its entirety&nbsp;— turning a bottle, for example, back into the same material used to make the bottle, and potentially creating an infinite loop of recycling.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/996523044.jpg 300w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/996523044.jpg 460w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/996523044.jpg 620w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/996523044.jpg 780w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/996523044.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/996523044.jpg"></p></div><figcaption>Workers sort recycling material at the Waste Management Material Recovery Facility in Elkridge, Md.<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Another big problem with modern recycling is the amount of energy used to collect materials and deliver them to a central location for sorting.&nbsp;</p>  <p>"That won't necessarily be a problem that disappears with a new strategy for recycling," Erickson said.</p>  <p>"The difference, however, would be that the embedded use of fossil fuels for the extraction of petroleum from the Earth, you would lose a lot of that, which is also quite costly.... If we could separate some of the products that we use from that cycle, then the greenhouse gas emissions and fossil fuel utilization would be lower."</p>  <h2>Technology helps — but people have to step up&nbsp;</h2>  <p>The team has touted the potential of this method to one day revolutionize recycling, should it be developed on a commercial scale.&nbsp;</p>  <p>But Erickson notes that technology alone won't fix the problem of plastic pollution.</p>    <p>"It's difficult to convey the ability to sort of shirk off responsibility for our daily choices toward this kind of technology in general&nbsp;…&nbsp;each of us&nbsp;can make a difference in our daily choices," she said.</p>  <p>"And so I hope that people both understand that [with this]&nbsp;technology, we're hoping we can we can make some big impacts and in good directions, but it still comes down to individual choices."</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Menaka Raman-Wilms and Kate Cornick.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664510</guid>
            <pubDate>Fri, 02 Oct 2020 16:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Security Hardening and Other Tweaks]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24664507">thread link</a>) | @aytekat
<br/>
October 2, 2020 | https://vez.mrsk.me/linux-hardening.html#hn | <a href="https://web.archive.org/web/*/https://vez.mrsk.me/linux-hardening.html#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<strong>Linux Security Hardening and Other Tweaks</strong>
<hr>

<p>
Last updated: 08/18/2020,
by <a href="https://twitter.com/blakkheim">@blakkheim</a>

</p><p>
This page lists the changes I make to a vanilla install of Arch Linux
for security hardening, as well as some other changes I find useful.
While Arch is my target platform, most of the changes will work on
any Linux system that's reasonably up to date.

</p><p>
I typically favor security over performance. You may also see suggestions
merely to make something more useful or shave precious seconds off
a wait time. It's not a one-size-fits-all setup, but hopefully certain
pieces of it will be useful.

</p><p>
Arch is worth considering for a few reasons:

</p><ul>
<li><strong>The install size:</strong> The base install is relatively minimal
    compared to a "prebuilt" distro like Fedora or Mint. This lets me focus
    on adding just what I want, rather than constantly trying to strip out
    things I don't need.
</li><li><strong>The kernel:</strong> A common misconception about the Linux
    kernel is that it's secure, or that one can go a long time without
    worrying about kernel security updates. Neither of these are even
    remotely true. New versions of Linux are released almost every week,
    often containing security fixes buried among the many other changes.
    These releases typically
    <a href="https://youtu.be/5PmHRSeA2c8?t=4075">don't</a> make explicit
    mention of the changes having security implications. As a result, many
    "stable" or "LTS" distributions don't know
    <a href="https://web.archive.org/web/20200623161340/https://www.openwall.com/lists/oss-security/2020/06/23/2">which commits</a> should be
    backported to their old kernels, or even that something needs backporting
    at all. If the problem has a public CVE assigned to it, maybe your distro
    will pick it up. Maybe not. Even if a CVE exists, at least in the case
    of Ubuntu and Debian especially, users are often left with kernels full
    of <a href="https://security-tracker.debian.org/tracker/source-package/linux">known holes</a>
    for months at a time. Arch doesn't play the backporting game, instead
    opting to provide the newest stable releases shortly after they come out.
</li><li><strong>The <a href="https://wiki.archlinux.org/index.php/Arch_Build_System">Arch Build System</a></strong>:
    Having enjoyed the
    <a href="https://en.wikipedia.org/wiki/Ports_collection">ports</a>
    system of <a href="https://vez.mrsk.me/freebsd-defaults.html">FreeBSD</a>
    and <a href="https://www.openbsd.org/">OpenBSD</a> for a long time, the ABS
    has been a pleasure to use. It makes building/rebuilding packages easy.
    It makes updating packages easy. It shows how things are actually built
    and with what options. This BSD-borrowed concept makes interacting with
    the package system simple and intuitive.
</li></ul>

Now on to how I set things up.

<hr>
<p>

<strong>Security Hardening</strong>
</p><ul>
  <li><a href="#disks">Disk Layout</a>
  </li><li><a href="#pacman">Pacman</a>
  </li><li><a href="#kern">Kernel Options</a>
  </li><li><a href="#fw">Firewall</a>
  </li><li><a href="#sudo">Sudo</a>
  </li><li><a href="#firejail">Application Sandboxing</a>
  </li><li><a href="#rfk">RFKill (Disable WiFi / Bluetooth)</a>
</li></ul>

<strong>Other Tweaks</strong>
<ul>
  <li><a href="#ntp">NTP (Network Time Protocol)</a>
  </li><li><a href="#mkinit">mkinitcpio</a>
  <!--
  <li><a href="#login"    >Automatic Login</a>
  -->
  </li><li><a href="#pulse">PulseAudio</a>
  </li><li><a href="#misc">Miscellaneous</a>
  </li><li><a href="#closing">Closing</a>
</li></ul>

<hr>

<h2 id="disks">Disk Layout</h2>

This section contains a few tips to consider during your initial disk layout
creation. The concepts should apply to any distrbution.

<p>
To start, consider using
<a href="https://wiki.archlinux.org/index.php/Dm-crypt/Encrypting_an_entire_system">full disk encryption</a>
along with a
<a href="https://wiki.archlinux.org/index.php/LVM">Logical Volume Manager</a>
setup. Disk encryption protects data at rest, while LVM allows for some
flexibility that can be quite useful. A simple disk layout might look like
this:

</p><ul>
<li><code>/dev/sda1</code> (a small, unencrypted
<a href="https://wiki.archlinux.org/index.php/EFI_system_partition">EFI System Partition</a>,
FAT32)
mounted at <code>/efi</code> (assuming this is
a PC with UEFI, otherwise not needed)
</li><li><code>/dev/sda2</code> (a small, unencrypted ext4 partition)
mounted at <code>/boot</code>.
</li><li><code>/dev/sda3</code> (using the rest of the drive space)
as the encrypted
<a href="https://wiki.archlinux.org/index.php/Dm-crypt">LUKS</a> container
for LVM
</li></ul>

Splitting up the logical volumes for different mount points provides some
benefits, including the ability to set mount flags on specific directories.
Consider creating separate logical volumes for <code>/</code>,
<code>/var</code>, and <code>/home</code> in the install. For a typical
desktop, you probably want to give <code>/home</code> most of the disk space.
The other two don't need much unless there's a specific use case in mind.
25GB and 8GB are used in this example. If you need to have a huge database
in <code>/var</code> or something, make adjustments accordingly.

<p>
There are a lot of user-writable directories in Linux, each one providing
an opportunity for attackers to execute their own binaries.
Once the <a href="https://wiki.archlinux.org/index.php/Fstab">fstab</a>
file is created, add the <code>noexec</code> and <code>nodev</code> flags
to <code>/var</code> and <code>/home</code>. Doing so will disallow execution
of binaries on these mount points, as well as prevent interpreting character
or block special devices on them. Two temporary filesystems (<code>/tmp</code>
and <code>/dev/shm</code>) can also be locked down with the same flags by
adding the following:

</p><pre># /etc/fstab
[...]
tmpfs /tmp     tmpfs rw,noexec,nodev,size=1G,mode=1777 0 0
tmpfs /dev/shm tmpfs rw,noexec,nodev,size=1G 0 0
</pre>

Adjust the <code>1G</code> size limit value as desired.

<p>
Once booted into the finished installation, it should look something like this:

</p><pre># <strong>lvs</strong>
  LV   VG   Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  home lvm  -wi-ao---- 189.12g                                                    
  root lvm  -wi-ao----  25.00g                                                    
  var  lvm  -wi-ao----   8.00g                                                    
# <strong>mount | egrep '(lvm|/tmp|shm)' | sort</strong>
/dev/mapper/lvm-home on /home type ext4 (rw,nodev,noexec,relatime)
/dev/mapper/lvm-root on / type ext4 (rw,relatime)
/dev/mapper/lvm-var on /var type ext4 (rw,nodev,noexec,relatime)
tmpfs on /dev/shm type tmpfs (rw,nodev,noexec,size=1048576k)
tmpfs on /tmp type tmpfs (rw,nodev,noexec,relatime,size=1048576k)
</pre>

Another user-writable directory to consider is <code>/run</code>, specifically
the <code>/run/user/$UID</code> directories that systemd spawns when someone
logs in, but their transience is
<a href="https://lists.freedesktop.org/archives/systemd-devel/2015-February/028429.html">annoying</a>
and <a href="https://lwn.net/Articles/436012/">complicated</a>.
I have yet to find the perfect solution there that won't break other things.
<a href="https://wiki.archlinux.org/index.php/FUSE">FUSE</a> is another way
for non-root users to create new mount points and execute binaries. If FUSE
functionality isn't needed, the kernel module can be
<a href="https://wiki.archlinux.org/index.php/Kernel_module#Blacklisting">blacklisted</a>.

<hr>

<h2 id="pacman">Pacman</h2>

Package managers usually don't need much additional configuration.
<a href="https://wiki.archlinux.org/index.php/Pacman">Pacman</a>, the one
Arch uses, is no different. My recommendation for any package manager is
simply to make sure that
<a href="https://web.archive.org/web/20200528161634/https://blog.packagecloud.io/eng/2018/02/21/attacks-against-secure-apt-repositories/">only HTTPS mirrors</a>
are used.

<pre># /etc/pacman.d/mirrorlist

Server = <strong>https</strong>://example.com/[...]/$repo/os/$arch
</pre>

Check the
<a href="https://www.archlinux.org/mirrorlist/all/https/">mirrorlist
generator</a> to see a list of TLS-capable servers near you.

<p>
Using an HTTPS mirror with Pacman is especially important because it
<a href="https://security.archlinux.org/package/pacman">doesn't validate</a>
the package database files and it
<a href="https://en.wikipedia.org/wiki/Privilege_separation">runs everything as root</a>.
HTTPS doesn't mitigate either of these problems, but it is one line of defense
against a MITM attack. I hope the developers will make fixing these two
security issues a priority for the project soon. Other package managers
have been doing it the right way for a long time.

</p><hr>

<h2 id="kern">Kernel Options</h2>

The
<a href="https://www.archlinux.org/packages/extra/x86_64/linux-hardened/">linux-hardened</a>
kernel package in Arch includes some compile-time security improvements
that can't be set at runtime.
If your distribution doesn't have a package for it, applying the
<a href="https://github.com/anthraxx/linux-hardened/releases">patchset</a>
to upstream sources and building your own kernel is pretty easy. If you go
that route, have a look at the
<a href="https://github.com/a13xp0p0v/kconfig-hardened-check">kconfig-hardened-check</a>
script for more compile-time settings to consider.

<!--
<p>
The main issue I've found with linux-hardened is that it's often outdated.
Upstream Linux development moves quickly, so out-of-tree patches will always
require extra work to maintain. Why the (relatively small) patches aren't
upstreamed is unknown to me. There are times when linux-hardened is lagging
multiple versions behind the latest kernel, thus missing out on many
important security fixes. In such a situation, the user must choose between
a more secure kernel with known vulnerabilities and a less secure kernel
with fewer known vulnerabilities. Not a great situation.
-->

<p>
Runtime configuration of the kernel can be done in a number of ways.
Desired flags may be passed on startup in the form of
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters">kernel parameters</a>,
of which there is an
<a href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt">extensive list</a>.
Parameters are usually passed by the
<a href="https://wiki.archlinux.org/index.php/Bootloader#Boot_loader">bootloader</a>, so
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters#Configuration">configuration details</a>
vary depending whether the system uses
<a href="https://wiki.archlinux.org/index.php/GRUB">GRUB</a>,
<a href="https://wiki.archlinux.org/index.php/Systemd-boot">systemd-boot</a>,
or something else.

</p><p>
The following options, split up into categories, are worth considering for
security improvements:

</p><pre>l1tf=full,force
spec_store_bypass_disable=on
spectre_v2=on
</pre>

These are addtional mitigations for certain CPU security flaws.
While the <code>mitigations=auto</code> option is used by default in upstream
Linux, some of the mitigations it enables have been "toned down" for
performance reasons.
Examples of this include the
<a href="https://en.wikipedia.org/wiki/Foreshadow_(security_vulnerability)">L1TF</a>
and
<a href="https://en.wikipedia.org/wiki/Microarchitectural_Data_Sampling">Microarchitectural Data Sampling</a>
vulnerabilities, which can't be fully mitigated unless HyperThreading
is disabled.
The
<a href="https://en.wikipedia.org/wiki/Speculative_Store_Bypass">Speculative Store Bypass</a>
vulnerability is only partially mitigated by default, with applications being
allowed to opt-in for protections via prctl or seccomp.
Finally, we enable all mitigations (including those against userspace) for
<a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre V2</a>.

<pre>apparmor=1
lsm=lockdown,yama,apparmor
lockdown=<span color="#ff0000"><strong>XXX</strong></span>
</pre>

These enable the
<a href="https://wiki.archlinux.org/index.php/AppArmor">AppArmor</a>, 
<a href="https://www.kernel.org/doc/Documentation/security/Yama.txt">Yama</a>,
and
<a href="https://web.archive.org/web/20200525014035/https://mjg59.dreamwidth.org/55105.html">Lockdown</a>
features, with the lockdown mode left for the reader to choose.
Valid options are <code>integrity</code> and <code>confidentiality</code>,
both described briefly
<a href="https://wiki.archlinux.org/index.php/Security#Kernel_lockdown_mode">here</a>.
Replace <code><strong><span color="#ff0000">XXX</span></strong></code> with
whichever you see fit, or omit this option entirely if the feature isn't
wanted.

<p>
For what it's worth, running in <code>confidentiality</code> mode on my
desktop hasn't caused any problems. Your mileage and use case may vary.
Lockdown will break suspend-to-disk and any out-of-tree kernel modules
like ZFS, as well as
<a href="https://wiki.archlinux.org/index.php/Dynamic_Kernel_Module_Support">DKMS</a> modules.

</p><pre>init_on_alloc=1
init_on_free=1
page_alloc.shuffle=1
slab_nomerge
vsyscall=none
</pre>

This group will instruct the kernel to fill newly allocated pages and heap
objects with zeroes, fill freed pages and heap objects with zeroes, tell the
page allocator to randomize its free lists, disable merging of
<a href="https://en.wikipedia.org/wiki/Slab_allocation">slabs</a>
with similar size, and disable
<a href="https://web.archive.org/web/20200526182112/https://lwn.net/Articles/446528/">vsyscalls</a>
due to their history of making exploits easier.
All five options are all set by default when using the linux-hardened kernel.

<pre>slub_debug=F
</pre>

This enables sanity checks in the
<a href="https://www.kernel.org/doc/Documentation/vm/slub.txt">SLUB allocator</a>.
Two other flags to consider for non-hardened kernels are <code>Z</code>
(redzoning, to detect when a slab is overwritten past its real size) and
<code>P</code> (to enable poisoning on slab cache allocations).

<p>
The full list of kernel parameters to be used must be specified on a single
line, separated by spaces, in the bootloader's config file. An example for
GRUB might look like this:

</p><pre># /etc/default/grub

[...]
GRUB_CMDLINE_LINUX_DEFAULT="apparmor=1 init_on_alloc=1 init_on_free=1 l1tf=full,force lockdown=confidentiality lsm=lockdown,yama,apparmor page_alloc.shuffle=1 slab_nomerge slub_debug=F spec_store_bypass_disable=on spectre_v2=on vsyscall=none"
[...]
</pre>

Depending on the bootloader in use, the file may need to be regenerated after
any edits are made.

<p>
Changes to the kernel parameters won't take effect until after a reboot.
To verify they were applied, run:

</p><pre>$ <strong>cat /proc/cmdline</strong>
</pre>

<p>
Yet more runtime options of the kernel can be configured through the
<a href="https://wiki.archlinux.org/index.php/Sysctl">sysctl</a> utility.
The values specified by …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vez.mrsk.me/linux-hardening.html#hn">https://vez.mrsk.me/linux-hardening.html#hn</a></em></p>]]>
            </description>
            <link>https://vez.mrsk.me/linux-hardening.html#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664507</guid>
            <pubDate>Fri, 02 Oct 2020 16:51:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploiting GitHub Actions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24664233">thread link</a>) | @blakbelt78
<br/>
October 2, 2020 | https://bullish.email/blog/exploiting-github-actions/ | <a href="https://web.archive.org/web/*/https://bullish.email/blog/exploiting-github-actions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p><a href="https://bullish.email/"><img src="https://bullish.email/blog/logo.png"></a>
      </p>
      
      <hr>
      <p>
        At the beginning of this year, I launched a stock market newsletter
        called <a href="https://bullish.email/">Bullish</a>. I’ve been building
        this project to be fully autonomous, trying to squeeze as much I can get
        from free tiers available everywhere, keeping costs close to zero,
        trying to build a completely automated micro SaaS product.
      </p>

      <p>
        Bullish is a Ruby app that fetches data from multiple finance API’s and
        synthesizes that into an email template generated twice a day that gets
        triggered to MailerLite for delivery.
      </p>

      <p>
        There are many ways to accomplish this task and the way I initially
        solved it was to re-purpose a Raspberry Pi that was collecting dust to
        run the project and set up CRON jobs to trigger emails and other tasks.
      </p>

      <p>
        Although unusual, this configuration worked great, and the workflow was
        seamless; all I had to do was ssh into Pi and pull from master to get
        the latest updates.
      </p>

      <p>
        Over time a couple of issues started to bother me. First, using
        Raspberry Pi introduced a single point of failure in the process if
        power was out, for example, or I was away from home, and something went
        wrong, there was no way to fix it.
      </p>

      <p>
        Another problem is that I would forget to run bundle to install or
        update gems breaking the CRON jobs more often than not.
      </p>

      <p>
        But the most concerning one was security-related. Bullish stores all of
        its API keys in an env file, and although not in source control, these
        keys had to be available in the Raspberry Pi for the service to run and
        that alone was a big enough reason to look for a better, more scalable
        and FREE solution.
      </p>

      <p>
        There are many ways I could have solved this. The most elegant probably
        being a Lambda function run on a schedule with API keys managed by a
        service like AWS Secrets Manager, which I still might do at some point,
        but this time around, I was looking for a quick win.
      </p>

      <p>
        I’ve been using Github Actions to run tests on every push to master
        branch, and one day it occurred to me, why not use this to have a
        workflow to trigger emails and other tasks as well?
      </p>

      <p>
        Doing some research, I found that Github Actions supports jobs triggered
        by a scheduled event and has a generous free tier that would work
        perfectly for my use case.
      </p>

      <p>
        Github Actions is still pretty new and has some annoying limitations
        like not sharing common data between jobs, leading to many duplicated
        steps, but it does allow sharing environment variables across jobs.
      </p>

      <p>
        Another neat feature is that Github offers managed secrets that get
        injected in the container when the job executes, so no more API keys are
        in the open.
      </p>

      
      <p>
        Overall I am satisfied with this solution, maybe not definitive, but it
        addresses most of my concerns like:
      </p>

      <ul>
        <li>Single point of failure using Raspberry Pi</li>
        <li>Forgetting to update Pi manually with the latest code after a git push</li>
        <li>Secrets exposed in environment variables</li>
      </ul>

      <p>
        And as a bonus, you get notified via email if your job ever fails,
        giving free visibility that you would otherwise have to put together
        yourself in services like CRON to figure out if a job ran successfully
        or not.
      </p>

      <p>
        Bullish is an open source project on
        <a href="https://github.com/eduardosasso/bullish">GitHub</a>.
      </p>

      <p>Cheers.</p>
    </section></div>]]>
            </description>
            <link>https://bullish.email/blog/exploiting-github-actions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664233</guid>
            <pubDate>Fri, 02 Oct 2020 16:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Largest German book retail chain is making common cause with China]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24664224">thread link</a>) | @_Microft
<br/>
October 2, 2020 | https://translate.google.de/translate?sl=de&tl=en&u=https%3A%2F%2Fwww.merkur.de%2Fverbraucher%2Fthalia-china-buchhandel-kette-buecher-propaganda-werke-heftige-kritik-zr-90047427.html | <a href="https://web.archive.org/web/*/https://translate.google.de/translate?sl=de&tl=en&u=https%3A%2F%2Fwww.merkur.de%2Fverbraucher%2Fthalia-china-buchhandel-kette-buecher-propaganda-werke-heftige-kritik-zr-90047427.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://translate.google.de/translate?sl=de&amp;tl=en&amp;u=https%3A%2F%2Fwww.merkur.de%2Fverbraucher%2Fthalia-china-buchhandel-kette-buecher-propaganda-werke-heftige-kritik-zr-90047427.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664224</guid>
            <pubDate>Fri, 02 Oct 2020 16:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Neural Nets and Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24664223">thread link</a>) | @andreyk
<br/>
October 2, 2020 | https://www.skynettoday.com/overviews/neural-net-history | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/overviews/neural-net-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</h2>

<blockquote>
  <p>“Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.” -<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239">Dr. Christopher D. Manning, Dec 2015</a> <sup id="fnref:part1_1" role="doc-noteref"><a href="#fn:part1_1">1</a></sup></p>
</blockquote>

<p>This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‘tsunami’. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‘Deep Learning’ was anything fancy or just a scaled up version of the ‘artificial neural nets’ that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‘big neural nets’  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.</p>


<blockquote><p id="sources">
I am certainly not a foremost expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf">"Learning Deep Architectures for AI"</a>, Jürgen Schmidhuber's <a href="http://arxiv.org/pdf/1404.7828v4.pdf">"Deep Learning in Neural Networks: An Overview"</a> and LeCun et al.s' <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">"Deep learning"</a>. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is Jürgen Schmidhuber's <a href="http://people.idsia.ch/~juergen/deep-learning-overview.html">"Deep Learning in Neural Networks: An Overview"</a>. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's <a href="http://chronicle.com/article/The-Believers/190147">"The Believers"</a>, John Markoff's <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">"Scientists See Promise in Deep-Learning Programs"</a> and Gary Marcus's <a href="http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence">"Is “Deep Learning” a Revolution in Artificial Intelligence?"</a>. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
<br>
Any corrections would be appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling. 
<br>
This piece is an updated and expanded version of blog posts originally released in 2015 on www.andreykurenkov.com. 
</p></blockquote>

<ul id="markdown-toc">
  <li><a href="#prologue-the-deep-learning-tsunami" id="markdown-toc-prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</a></li>
  <li><a href="#part-1-the-beginnings-1950s-1980s" id="markdown-toc-part-1-the-beginnings-1950s-1980s">Part 1: The Beginnings (1950s-1980s)</a>    <ul>
      <li><a href="#the-centuries-old-machine-learning-algorithm" id="markdown-toc-the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</a></li>
      <li><a href="#the-folly-of-false-promises" id="markdown-toc-the-folly-of-false-promises">The Folly of False Promises</a></li>
      <li><a href="#the-thaw-of-the-ai-winter" id="markdown-toc-the-thaw-of-the-ai-winter">The Thaw of the AI Winter</a></li>
    </ul>
  </li>
  <li><a href="#part-2-neural-nets-blossom-1980s-2000s" id="markdown-toc-part-2-neural-nets-blossom-1980s-2000s">Part 2: Neural Nets Blossom (1980s-2000s)</a>    <ul>
      <li><a href="#neural-nets-gain-vision" id="markdown-toc-neural-nets-gain-vision">Neural Nets Gain Vision</a></li>
      <li><a href="#neural-nets-go-unsupervised" id="markdown-toc-neural-nets-go-unsupervised">Neural Nets Go Unsupervised</a></li>
      <li><a href="#neural-nets-gain-beliefs" id="markdown-toc-neural-nets-gain-beliefs">Neural Nets Gain Beliefs</a></li>
      <li><a href="#neural-nets-make-decisions" id="markdown-toc-neural-nets-make-decisions">Neural Nets Make Decisions</a></li>
      <li><a href="#neural-nets-get-loopy" id="markdown-toc-neural-nets-get-loopy">Neural Nets Get Loopy</a></li>
      <li><a href="#neural-nets-start-to-speak" id="markdown-toc-neural-nets-start-to-speak">Neural Nets Start to Speak</a></li>
      <li><a href="#a-new-winter-dawns" id="markdown-toc-a-new-winter-dawns">A New Winter Dawns</a></li>
    </ul>
  </li>
  <li><a href="#part-3-deep-learning-2000s-2010s" id="markdown-toc-part-3-deep-learning-2000s-2010s">Part 3: Deep Learning (2000s-2010s)</a>    <ul>
      <li><a href="#the-funding-of-more-layers" id="markdown-toc-the-funding-of-more-layers">The Funding of More Layers</a></li>
      <li><a href="#the-development-of-big-data" id="markdown-toc-the-development-of-big-data">The Development of Big Data</a></li>
      <li><a href="#the-importance-of-brute-force" id="markdown-toc-the-importance-of-brute-force">The Importance of Brute Force</a></li>
      <li><a href="#the-deep-learning-equation" id="markdown-toc-the-deep-learning-equation">The Deep Learning Equation</a></li>
    </ul>
  </li>
  <li><a href="#epilogue-the-decade-of-deep-learning" id="markdown-toc-epilogue-the-decade-of-deep-learning">Epilogue: The Decade of Deep Learning</a></li>
</ul>


<p>The beginning of a story spanning half a century, about how we learned to make computers learn. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets’ return to popularity with backpropagation in 1986.</p>

<h2 id="the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</h2>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/Linear_regression.svg" alt="Linear Regression">     
    <figcaption>Linear regression <a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg">(Source)</a></figcaption>
</figure>

<p>Let’s start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little <a href="https://en.wikipedia.org/wiki/Linear_regression#cite_note-4">200 year old</a> technique for extrapolating a general function from some set of input-output pairs. And here’s why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.</p>

<p>Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what <strong>supervised Machine Learning</strong> is all about: ‘learning’ a function given a <strong>training set</strong> of <strong>examples</strong>, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google’s current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.</p>

<p>This generalization principle is so important that there is almost always a <strong>test set</strong> of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is <strong>overfitting</strong> - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard <strong>datasets</strong> of training and testing sets that could be used to evaluate machine learning algorithms.</p>

<p>Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don’t match any of the points we started with. Don’t worry, the rest of this history will not be nearly so dry as all this. Here we go.</p>

<h2 id="the-folly-of-false-promises">The Folly of False Promises</h2>

<p>Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=1959-09865-001">Frank Rosenblatt’s <strong>Perceptron</strong></a><sup id="fnref:part1_2" role="doc-noteref"><a href="#fn:part1_2">2</a></sup>.</p>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34998.jpg" alt="Perceptron">
    <figcaption>A diagram showing how the Perceptron works. <a href="http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg">(Source)</a></figcaption>    
</figure>

<p>A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‘bias’ input, which just has a value of 1 and basically ensures that more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts <a href="http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf">Mcculoch-Pitts</a><sup id="fnref:part1_3" role="doc-noteref"><a href="#fn:part1_3">3</a></sup>, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to perform formal logical reasoning would essentially solve AI.</p>

<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34832.jpg" alt="Perceptron 2"> 
    <figcaption>Another diagram, showing the biological inspiration. The <b>activation function</b> is what people now call the non-linear function applied to the weighted input sum to produce the output of the artificial neuron - in the case of Rosenblatt's Perceptron, the function just a thresholding operation.  <a href="http://cs231n.github.io/neural-networks-1/">(Source)</a> </figcaption>    
</figure>

<p>However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the <a href="http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract">foundational work</a><sup id="fnref:part1_4" role="doc-noteref"><a href="#fn:part1_4">4</a></sup> of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb’s Rule:</p>

<blockquote>
  <p>“When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A’s efficiency, as one of the cells firing B, is increased.”</p>
</blockquote>

<p>The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a <strong>training set</strong> of input-output examples the Perceptron should ‘learn’ a function from, for each example increase the weights if the Perceptron output for that example’s input is too low compared to the example, and otherwise decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:</p>

<ol>
  <li>Start off with a Perceptron having random weights and a training set</li>
  <li>For the inputs of an example in the …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/overviews/neural-net-history">https://www.skynettoday.com/overviews/neural-net-history</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/overviews/neural-net-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664223</guid>
            <pubDate>Fri, 02 Oct 2020 16:25:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Social Dilemma: We’re Victims of Stockholm Syndrome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24664159">thread link</a>) | @Soundaryab12
<br/>
October 2, 2020 | https://www.bsoundarya.com/the-social-dilemma-were-victims-of-stockolm-syndrome/ | <a href="https://web.archive.org/web/*/https://www.bsoundarya.com/the-social-dilemma-were-victims-of-stockolm-syndrome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				
<p>I learned that the term <a href="https://en.wikipedia.org/wiki/Stockholm_syndrome#Stockholm_bank_robbery">Stockholm Syndrome</a> came from an incident that happened in 1972 in a bank in Stockholm, Sweden. Four employees of a bank were held hostage by two captors for six days. In the end, after the police caught the captors, none of the hostages were willing to testify against them in court. Rather, they began raising money to aid them with their defense.</p>
<p>When I watched <em>The Social Dilemma</em> recently, I kept thinking about this syndrome. Although it is still widely contested among psychologists and psychiatrists in its medical merit, I kept thinking about the analogy to social media. We have come to love something that has a captor-like spell on us, that we <em>know</em> can be detrimental. What do we do?</p>
<p>For starters, I urge you to watch the documentary. Second, spend some time thinking about what you saw (and maybe write about it?). Finally, <em>do something about it.</em></p>
<p>As a corollary to the second step above, I wanted to write down the top ten takeaways I had from the unnerving documentary followed by sharing my thoughts and short-term best practices on how I have been tackling this problem.</p>

<p><img src="https://i2.wp.com/www.indiewire.com/wp-content/uploads/2020/01/200787-1-1100.jpg?w=1080&amp;ssl=1" alt="The Social Dilemma Review: A Film About How Facebook Will Kill Us All | IndieWire" data-recalc-dims="1"></p>

<h2><strong>Top Ten Takeaways: <em>The Social Dilemma</em>&nbsp;</strong></h2>
<div>
<p><strong>One:</strong> In a 1980 interview for a documentary film, Steve Jobs said that the computer is like a <a href="https://www.youtube.com/watch?v=ob_GX50Za6c">bicycle for your mind</a>. The same cannot be said about social media. Whereas a bicycle is a passive <em>tool</em> that has the option to be used or not used based on an individual’s choice, social media is not just a passive tool. It is an active tool that <em>expects</em> you to use it, by giving instant gratification and feeding your dopamine levels in return.</p>
<p><strong>Two:</strong> The entire business model of companies like Facebook and Twitter are built on grabbing our attention <em>and</em> changing the way we think and behave. Jeff Orlowski, the director of the documentary, says, “Our social media platforms are powered by a surveillance-based business model designed to mine, manipulate, and extract our human experiences at any cost, causing a breakdown of our information ecosystem and shared sense of truth worldwide.”</p>
<p><strong>Three:</strong> As a result of the algorithms and preferences, our individual social media feeds can become echo chambers – basically reaffirming our worldview over and over, most worryingly perhaps even at the expense of the objective truth. We become more limited in our lens as we start to see only what we <em>want</em> to see.</p>
<p><strong>Four:</strong> Magicians are some of the earliest neuroscientists and psychologists who understood human behavior and exploited it by making us believe things that are not real (personally, I’m obsessed with decoding the magicians’ code). The effects are benign. On the other hand, social media does something similar: it collates fact and fiction by presenting the same information differently. Imagine having a customized Wikipedia page on every topic. What to believe anymore?</p>
<p><strong>Five:</strong> No one feels the existential threat while scrolling down to see one more image or video, but the consequences are seen when, as a society, we are more divided, lonely, and depressed. Left unchecked, the algorithms will feed us more and more divisive content in an effort to gain our attention and increase time on the platform.</p>
<div>
<blockquote><p><em>“In 2014,&nbsp;<a href="https://www.pewresearch.org/politics/2014/06/12/political-polarization-in-the-american-public/">Pew Research Center</a>&nbsp;found that partisan antipathy and division in America is “deeper and more extensive than at any point in the last two decades”. Over the past six years, social media has only exacerbated these sentiments. In 2019, 77% of Republicans and 72% of Democrats&nbsp;<a href="https://www.pewresearch.org/politics/2019/10/10/partisan-antipathy-more-intense-more-personal/">said</a> voters in both parties “not only disagree over plans and policies, but also cannot agree on the basic facts”.”</em></p></blockquote>
</div>
<p><strong>Six:</strong> We are all worried about a time when artificial intelligence will surpass our human strengths, i.e., achieve general intelligence and consciousness. What we don’t realize is that artificial intelligence has <em>already</em> surpassed our human weaknesses, i.e. our need for social validation, instant gratification, and limited focused attention.</p>

<div>
<p><img loading="lazy" title="How We Bring Humanity Back to Tech | by Tom Littler | Medium" src="https://i1.wp.com/miro.medium.com/max/3848/1*Z5vb1QsPiycUKi5BZ5BRPw.png?resize=986%2C540&amp;ssl=1" width="986" height="540" data-recalc-dims="1"></p>

<blockquote><p><em>“Dystopian technology will not strong-arm us. Instead, we’ll unwittingly submit ourselves to a devil’s bargain: freely trade our subconscious preferences for memes, our social cohesion for instant connection, and the truth for what we want to hear.”</em></p></blockquote>
<p><strong>Seven:</strong> We can try to fight it, but it will always be a losing battle. Why? Because it is our brain vs their algorithms. It is our brain that was developed over millions of years and is still primitive in its needs vs their algorithms that is getting smarter, efficient, and more targeted by the second. We cannot blame ourselves; nor can we expect <em>will-power</em>, which is limited, to help us.</p>
</div>
<p><strong>Eight:</strong> It is so hard to accept that technology is evil, <em>because it is not</em>. The degree of benefits we enjoy as a species today is unprecedented. We get access to everything ever known to humankind at the touch of a button (and soon by having a mere <a href="https://www.nanalyze.com/2020/09/kernel-brain-computer-interface/">thought</a>), we get to work with people from all corners of the world and learn from each other, we can get almost anything delivered in a day (or sometimes a few hours), we can travel anywhere we want to… I can keep going. How can this be considered dystopia? It’s not. Except, the same technology has also made us more disconnected, lonely, depressed, and divisive in real life. It is so hard to feel the threat because of the cruel juxtaposition of utopia next to dystopia.</p>
<p><strong>Nine:</strong> Any solution that can tackle this problem needs to be aligned with the financial incentive of a company. At the end of the day, all this technology is powered by shareholders who have vested interests. The first step to tackling this is through regulation. Unlike phone companies that have restrictions on how our data is used (and have had for decades), social media companies have just begun facing the consequences with anti-trust laws. There needs to be more, and fast.</p>
<p><strong>Ten:</strong> The people who created this are not evil. They did so with a good intention, of connecting the world, spreading positivity, and giving voice to everyone. But, we don’t see it anymore because of what happened along the way. Until the business model changes from ground up and the companies start valuing us for more than our attention, we can’t make progress. <em>We</em> created this, and so we <em>can</em> — and have a responsibility to — change it for the sake of our future generation.</p>

</div>
<h2><strong>What can we do?</strong></h2>
<div>
<p>I completely disagree with someone who says <em>we can choose to run away and try to live a completely social media-free life. </em>We cannot. Not if our profession or career goal requires us to disseminate our work to the mass public. If you’re a creator or an artist, of <em>any</em> kind, and you want your work to reach people, you, unfortunately, need to go where people are. And where people are is on social media. Besides, if all the good people quit social media, we are left with those who will only exacerbate the problem of spreading fake news. The solution is to rather use the knowledge we have against the system and build good habits in the short-term while demanding robust action from our leaders for the long-term.</p>
<p>I realize that I have been implementing some best practices to lessen my usage and consumption of content I don’t want since I <a href="https://www.bsoundarya.com/why-deep-work-is-valuable-busy-work-is-not-2/">read</a> <em>Deep Work</em> by Cal Newport in January 2019. I hope these help you as a starting point:</p>
<div>
<ul>
<li><strong>Disable notifications from <em>all</em> non-essential apps:</strong> And I mean all. Except for messages from my family on WhatsApp, high-priority emails, reminders, and notifications related to finances, nothing else grabs my attention on my phone. I’ve never looked back. This can be itchy for a few days, as you’ll have the urge to constantly keep checking your phone. Like any good habit, it will be difficult to follow and easy to break. Give it two weeks, and you’ll see the result.</li>
<li><strong>Use plugins to block out irrelevant content:</strong> YouTube is rightly called a rabbit-hole. The algorithms are so good that they begin showing you videos that you never knew you needed <em>and</em> videos you never needed. <a href="https://chrome.google.com/webstore/detail/remove-youtube-recommende/khncfooichmfjbepaaaebmommgaepoid?hl=en">Use a plugin</a> that hides all <em>recommended</em> videos so you can open the app only to watch what <em>you</em> wanted. While we’re on the topic of plugins, other good ones include: <a href="https://resumeworded.com/sendy/l/rLscJ9sX8BWC7yGUzQ81cA/OaW2vNZ0dV7NObkSSu8920iA/mdjjl892Dl5pWFKT0eV08B2A">Pomodoro clock</a>, <a href="https://chrome.google.com/webstore/detail/email-extractor/jdianbbpnakhcmfkcckaboohfgnngfcc?hl=en">email extractor</a>, and <a href="https://chrome.google.com/webstore/detail/weava-highlighter-pdf-web/cbnaodkpfinfiipjblikofhlhlcickei?hl=en">Weava</a> highlighter.</li>
<li><strong>Don’t let just anyone enter your email home:</strong> Your email is sacred. It’s where you receive the most important alerts, it’s where you interact with your friends, and maybe close deals. Don’t let just anyone enter. I use a <a href="https://www.proofpoint.com/us/products/email-protection">Proofpoint</a> filter that automatically detects spam-my emails. I also religiously unsubscribe from information that isn’t directly relevant or interesting to me (yet I still get unwanted emails. Sigh.).</li>
<li><strong>Delete social media apps unless you need them for something critical:</strong> I know this seems drastic, but truth be told, you can still access these through your computer (or even your phone through the website). By deleting them from your phone, you will at least add one layer of friction. <strong>Side Note:</strong> Instead of using the better-looking version of Facebook, use the <a href="https://mbasic.facebook.com/">basic version</a> on your phone. With its limited functionality and sub-par UI, it’s the perfect panacea to stop getting addicted.</li>
</ul>
</div>

<p>Honestly, despite the above, sometimes I still feel overwhelmed with information. Below are a few more measures I plan to experiment with:</p>
<ol>
<li>Monitor my screen time. Although my phone screen time might be low, I’m afraid my laptop screen time is too high.</li>
<li>Read news articles only from paid subscriptions: <em>The New York Times, The Guardina, Medium.&nbsp;</em></li>
<li>Find a way to disable likes/comments on my posts on Instagram and LinkedIn so I’m not tempted to check them once I make a post.</li>
</ol>

<p>Most of you reading this will continue using social media, which is warranted. I plan to continue using it too. But, if you don’t pause for a few minutes to build some good habits now, you will wake up from the spell after a few years wondering where all the time went. Take control of your time now.</p>
</div>

<p><em>Images Courtesy: Google Images</em></p>

			</div> <!-- .et_pb_post_content -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div></div>]]>
            </description>
            <link>https://www.bsoundarya.com/the-social-dilemma-were-victims-of-stockolm-syndrome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664159</guid>
            <pubDate>Fri, 02 Oct 2020 16:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pressing YubiKeys]]>
            </title>
            <description>
<![CDATA[
Score 390 | Comments 188 (<a href="https://news.ycombinator.com/item?id=24663989">thread link</a>) | @bertrandom
<br/>
October 2, 2020 | https://bert.org/2020/10/01/pressing-yubikeys/ | <a href="https://web.archive.org/web/*/https://bert.org/2020/10/01/pressing-yubikeys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>If you work in tech, you probably have a YubiKey. I have this one, the <a href="https://www.yubico.com/product/yubikey-5c-nano/">YubiKey 5C Nano</a>:</p>

<p><img src="https://bert.org/assets/posts/yubikey/nano.jpg" alt="YubiKey 5C Nano"></p>

<p>If you don’t work in tech but primarily work on your laptop, you probably <em>should</em> have a YubiKey. And if you work on a political campaign or as a journalist, you should definitely have one (or something similar). Talk to your IT Security department about that. This post will mostly be about something your IT Security department doesn’t want to hear about, though, so maybe don’t mention it to them.</p>

<p>YubiKeys act as two-factor authentication. This means that after you log-in to a system with your username and password, the system requires you to authorize in a second way as well. This way if your login credentials are compromised, the attacker would also have to compromise the second form of authentication, which is harder.</p>

<p>There are different forms of two-factor authentication - a common one is that a website will ask you to scan a QR code with the Google Authenticator app (or similar) on your phone which will generate 6 digit codes. The way this works is that the server and the app both have a shared secret. The phone generates codes based on that secret and the current timestamp and the server generates the same codes and sees if they match.</p>

<p><img src="https://bert.org/assets/posts/yubikey/qr-code.png" alt="QR Code"></p>

<p><img src="https://bert.org/assets/posts/yubikey/authenticator.png" alt="Google Authenticator"></p>

<p>Another one is SMS-based 2FA, which is pretty widely regarded as insecure. In this case, the server generates a code and sends it to your phone via SMS. The reason it’s considered insecure is that an attack exists called <a href="https://en.wikipedia.org/wiki/SIM_swap_scam">SIM-jacking</a> where someone convinces a cell phone carrier to port a number to a new SIM card, effectively directing all SMS traffic to their phone instead of yours.</p>

<p><img src="https://bert.org/assets/posts/yubikey/wells.jpg" alt="Wells Fargo"></p>

<p>YubiKeys are small devices that plug in to the USB port of your computer and emulate a keyboard. When tapped, they emit a one-time password (OTP) which can be then verified by a validation server. A private key exists on the device which is used to sign information, but it can never leave the device because it is stored in a tamper-resistant environment.</p>

<p>The YubiKey that I use is designed to always sit in a USB port of my laptop, so whenever I would take my laptop from my desk to a conference room or to another office, it was always available. But like many new remote workers, my laptop never leaves my desk anymore. I have it hooked up to an external monitor and to save some desk space, I have it in clamshell mode sitting vertically on a stand.</p>

<p>This makes tapping the YubiKey difficult, especially when I store my laptop far away from my keyboard and mouse. I solved this by buying a <a href="https://smile.amazon.com/gp/product/B071DMMW4J/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">USB-C extension cable</a>, which brought the YubiKey closer to my keyboard.</p>

<p>One thing I haven’t mentioned about the YubiKey 5C Nano is that it’s kind of difficult to tap, even without the distance issues. The target area that you need to touch is extremely small:</p>

<p><img src="https://bert.org/assets/posts/yubikey/nano-big.png" alt="YubiKey 5C Nano"></p>

<p>One of the features of the YubiKey is that the little metal strip determines that it is being tapped by a human - this prevents it from being accidentally triggered by bumping your laptop into something, but if you’ve ever seen a one-time password in a Slack channel or Google Doc like <code>tlerefhcvijlngibueiiuhkeibbcbecehvjiklltnbbl</code>, you know it isn’t a perfect system. I would estimate that 1 in 5 times that I attempt to trigger it, it doesn’t register.</p>

<p>A lot of thought has gone into ensuring that the YubiKey can’t be triggered from software on the computer itself.</p>

<p>Before we go any further, I’d like to acknowledge the reasons for this. If a remote attacker were to compromise your laptop, being able to trigger the YubiKey from software on the computer defeats the whole point of using the YubiKey. But I think we always make tradeoffs between security and convenience - for example, you often don’t have to enter your YubiKey every time you access a system, some systems will only ask you once and not ask you again on subsequent logins for a certain amount of time. When you use a 2FA system and it gives you “backup codes”, do you always print those out and store them in a safe location? Everyone should figure out what level of security and convenience they are okay with.</p>

<p>With that being said, let’s talk about how you could trigger a YubiKey with software.</p>



<p>I’ve been calling this mechanism <strong>The Finger</strong>.</p>

<h2 id="hardware">Hardware</h2>

<p>First, we need some way for the computer to talk to <strong>The Finger</strong>. I had a bunch of these <a href="https://smile.amazon.com/gp/product/B076F53B6S/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">IZOKEE D1 Mini</a> development boards lying around, they are smaller versions of boards that use the infamous <a href="https://en.wikipedia.org/wiki/ESP8266">ESP8266</a> chip found in a lot of IoT devices.</p>

<p><img src="https://bert.org/assets/posts/yubikey/d1-mini.jpg" alt="IZOKEE D1 Mini"></p>

<p>We can connect this to the laptop and talk to it over USB serial, but since it has WiFi, we can also just run a webserver on it and send it HTTP requests.</p>

<p>Next, we need some way to push <strong>The Finger</strong> towards the Yubikey. After a little googling, I found that the <a href="https://smile.amazon.com/gp/product/B01CP18J4A/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">28BYJ-48 stepper motor</a> interfaces well with the D1 Mini board.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor.jpg" alt="stepper motor"></p>

<p>Stepper motors convert electrical pulses into mechanical rotation and the D1 Mini has pins for sending electrical pulses.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor.gif" alt="stepper motor"></p>

<p>But stepper motors rotate and we mostly just need to poke in a straight direction. So I searched on Thingiverse for “28BYJ-48” and found this: <a href="https://www.thingiverse.com/thing:3593641">28BYJ-48 Motor Halter</a>.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor-case.jpg" alt="28BYJ-48 Motor Halter"></p>

<p>This attaches a gear to the motor which can guide a long rack forward and backward. But if we’re going to push a long plastic thing toward the YubiKey, it might as well look like a finger. Back to Thingiverse, this time searching for “finger” and I found this model someone made for Halloween:</p>

<p><img src="https://bert.org/assets/posts/yubikey/finger_model.jpg" alt="finger"></p>

<p>I opened up these two models in Fusion 360 and used an advanced CAD technique called “smooshing”, resulting in this:</p>

<p><img src="https://bert.org/assets/posts/yubikey/finger_smoosh.png" alt="finger"></p>

<p>Next, I exported the smooshed STL and 3D printed it in <a href="https://shop.prusa3d.com/en/prusament/715-prusament-pla-lipstick-red-1kg.html">Prusament PLA Lipstick Red</a> because that’s what I happened to have in my printer at the time. Then I took the plastic finger and touched the YubiKey which.. didn’t do anything. I picked up a metal screw on my desk and touched the YubiKey, which immediately spit out a OTP. So then I took the finger and secured it to my desk with a vise and drilled a small hole in it, then screwed the metal screw into it and touched it to the YubiKey, which again did nothing.</p>

<p><img src="https://bert.org/assets/posts/yubikey/vise.jpg" alt="vise"></p>

<p>That’s when I realized that I’m an idiot and that when I had touched the metal screw to the Yubikey, it was just transmitting the electrical charge from my body to the metal screw, which then transmitted it to the capacitive touch sensor on the YubiKey. So how could I trick the capacitive touch sensor into thinking it was a real finger?</p>

<p>I guessed that the way that capacitive touch sensors work is that they’re measuring your body’s capacitance to ground, so if we just hook up the sensor directly towards ground, it’ll think that its really conductive or at least conductive enough for a human finger to be between the two. So I took an insulated wire, unscrewed the metal screw slightly, wrapped it around the screw and tightened it again. Then I took the other end and connected it the GND port on the D1 Mini board, touched it to the YubiKey, and it worked!</p>

<p>Now the driver board for the stepper motor already connects to the 5V and GND on the D1 Mini, so I thought I might have to strip the GND wire and run it to both the driver board and the screw, but on a whim I decided to just wedge the end of the wire from the metal screw between the stepper motor metal body (figuring the metal body case was grounded) and the plastic housing. This also worked!</p>

<p><img src="https://bert.org/assets/posts/yubikey/ground.jpg" alt="grounding"></p>

<p>Once I confirmed that the finger would trigger the YubiKey, I needed a way to mount the YubiKey close to the finger, so I used my digital calipers to measure the size of the USB-C extension cable and designed a holder in Fusion 360.</p>

<p><img src="https://bert.org/assets/posts/yubikey/holder.png" alt="holder"></p>

<p>The USB-C extension cable would go into the hole on the left and the motor would mount on the right.</p>

<p>At this point, we have to wire the stepper motor driver board to the D1 Mini. This can be done by soldering some headers onto the D1 Mini and then connecting some Dupont jumper wires between them.</p>

<p><img src="https://bert.org/assets/posts/yubikey/pins.jpg" alt="pins"></p>

<table>
  <thead>
    <tr>
      <th>D1 Mini</th>
      <th>28BYJ-48 Driver Board</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5V</td>
      <td>5V</td>
    </tr>
    <tr>
      <td>GND</td>
      <td>GND</td>
    </tr>
    <tr>
      <td>D1</td>
      <td>IN1</td>
    </tr>
    <tr>
      <td>D2</td>
      <td>IN2</td>
    </tr>
    <tr>
      <td>D3</td>
      <td>IN3</td>
    </tr>
    <tr>
      <td>D4</td>
      <td>IN4</td>
    </tr>
  </tbody>
</table>

<p>Once we put the stepper motor into the housing and screw everything together, it should look like this:</p>

<p><img src="https://bert.org/assets/posts/yubikey/setup.jpg" alt="setup"></p>

<h2 id="software">Software</h2>

<p>The software is much more straightforward. The D1 Mini can be programmed using the Arduino IDE. First, we go into Preferences and add <code>https://arduino.esp8266.com/stable/package_esp8266com_index.json</code> under <em>Additional Board Manager URLs</em>. Then when you go into the <em>Boards Managers</em>, you can install the <code>esp8266</code> package which includes the board <strong>LOLIN(WEMOS) D1 R2 &amp; mini</strong>, which should be selected under <em>Tools</em>.</p>

<p>At this point I’ll run a sketch for blinking the LED just to verify that it’s working:</p>

<div><div><pre><code>#define LED 2 //Define blinking LED pin

void setup() {
  pinMode(LED, OUTPUT); // Initialize the LED pin as an output
}
// the loop function runs over and over again forever
void loop() {
  digitalWrite(LED, LOW); // Turn the LED on (Note that LOW is the voltage level)
  delay(1000); // Wait for a second
  digitalWrite(LED, HIGH); // Turn the LED off by making the voltage HIGH
  delay(1000); // Wait for two seconds
}
</code></pre></div></div>

<p>I found this <a href="https://robojax.com/learn/arduino/?vid=robojax_ESP8266_28BYJ-48_Stepper_ESP8STP-1">sketch</a> that shows how to control the 28BYJ-48 Stepper Motor using WiFi.</p>

<p>Here are the parts that have to do with the motor:</p>

<div><div><pre><code>int Pin1 = D1; //IN1 is connected 
int Pin2 = D2; //IN2 is connected   
int Pin3 = D3; //IN3 is connected 
int Pin4 = D4; //IN4 is connected 
 
int pole1[] ={0,0,0,0, 0,1,1,1, 0}; //pole1, 8 step values
int pole2[] ={0,0,0,1, 1,1,0,0, 0}; //pole2, 8 step values
int pole3[] ={0,1,1,1, 0,0,0,0, 0}; //pole3, 8 step values
int pole4[] ={1,1,0,0, 0,0,0,1, 0}; //pole4, 8 step values

int poleStep = 0; 
int dirStatus = 3; // stores direction status 3= stop (do not change)
String argId[] ={"ccw", "cw"};

...

void loop(void) {
    server.handleClient();
    MDNS.update();

    if (dirStatus == 1) {
        poleStep++;
        driveStepper(poleStep);
    } else if (dirStatus == 2) {
        poleStep--;
        driveStepper(poleStep);
    } else {
        driveStepper(8);
    }
    
    if (poleStep&gt;7) { 
        poleStep=0; 
    }

    if (poleStep&lt;0) {
        …</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bert.org/2020/10/01/pressing-yubikeys/">https://bert.org/2020/10/01/pressing-yubikeys/</a></em></p>]]>
            </description>
            <link>https://bert.org/2020/10/01/pressing-yubikeys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663989</guid>
            <pubDate>Fri, 02 Oct 2020 16:03:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cuda.jl 2.0]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663940">thread link</a>) | @ChrisRackauckas
<br/>
October 2, 2020 | https://juliagpu.org/2020-10-02-cuda_2.0/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-10-02-cuda_2.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        





<i data-feather="calendar"></i> <time datetime="2020-10-02">Oct 2, 2020</time>




  <br>
  <i data-feather="edit-2"></i> Tim Besard


<p>Today we’re releasing CUDA.jl 2.0, a breaking release with several new features. Highlights
include initial support for Float16, a switch to CUDA’s new stream model, a much-needed
rework of the sparse array support and support for CUDA 11.1.</p>
<p>The release now requires <strong>Julia 1.5</strong>, and assumes a GPU with <strong>compute capability 5.0</strong> or
higher (although most of the package will still work with an older GPU).</p>
<h2 id="low--and-mixed-precision-operations">Low- and mixed-precision operations</h2>
<p>With NVIDIA’s latest GPUs featuring more and more low-precision operations,
CUDA.jl <a href="https://github.com/JuliaGPU/CUDA.jl/pull/417">now</a> starts to support
these data types. For example, the CUBLAS wrappers can be used with (B)Float16
inputs (running under <code>JULIA_DEBUG=CUBLAS</code> to illustrate the called methods)
thanks to the <code>cublasGemmEx</code> API call:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> mul!(CUDA<span>.</span>zeros(<span>Float32</span>,<span>2</span>,<span>2</span>), cu(rand(<span>Float16</span>,<span>2</span>,<span>2</span>)), cu(rand(<span>Float16</span>,<span>2</span>,<span>2</span>)))

I<span>!</span> cuBLAS (v11<span>.</span><span>0</span>) <span>function</span> cublasStatus_t cublasGemmEx(<span>...</span>) called<span>:</span>
i!  Atype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16F(<span>2</span>)
i!  Btype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16F(<span>2</span>)
i!  Ctype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  computeType<span>:</span> type<span>=</span>cublasComputeType_t; val<span>=</span>CUBLAS_COMPUTE_32F(<span>68</span>)

<span>2</span>×2 CuArray{<span>Float32</span>,<span>2</span>}<span>:</span>
 <span>0.481284</span>  <span>0.561241</span>
 <span>1.12923</span>   <span>1.04541</span>
</code></pre></div><div><pre><code data-lang="julia">julia<span>&gt;</span> <span>using</span> BFloat16s

julia<span>&gt;</span> mul!(CUDA<span>.</span>zeros(BFloat16,<span>2</span>,<span>2</span>), cu(BFloat16<span>.</span>(rand(<span>2</span>,<span>2</span>))), cu(BFloat16<span>.</span>(rand(<span>2</span>,<span>2</span>))))

I<span>!</span> cuBLAS (v11<span>.</span><span>0</span>) <span>function</span> cublasStatus_t cublasGemmEx(<span>...</span>) called<span>:</span>
i!  Atype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16BF(<span>14</span>)
i!  Btype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16BF(<span>14</span>)
i!  Ctype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16BF(<span>14</span>)
i!  computeType<span>:</span> type<span>=</span>cublasComputeType_t; val<span>=</span>CUBLAS_COMPUTE_32F(<span>68</span>)

<span>2</span>×2 CuArray{BFloat16,<span>2</span>}<span>:</span>
 <span>0.300781</span>   <span>0.71875</span>
 <span>0.0163574</span>  <span>0.0241699</span>
</code></pre></div><p>Alternatively, CUBLAS can be configured to automatically down-cast 32-bit inputs to Float16.
This is <a href="https://github.com/JuliaGPU/CUDA.jl/pull/424">now</a> exposed through a task-local
CUDA.jl math mode:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> CUDA<span>.</span>math_mode!(CUDA<span>.</span>FAST_MATH; precision<span>=:</span><span>Float16</span>)

julia<span>&gt;</span> mul!(CuArray(zeros(<span>Float32</span>,<span>2</span>,<span>2</span>)), CuArray(rand(<span>Float32</span>,<span>2</span>,<span>2</span>)), CuArray(rand(<span>Float32</span>,<span>2</span>,<span>2</span>)))

I<span>!</span> cuBLAS (v11<span>.</span><span>0</span>) <span>function</span> cublasStatus_t cublasGemmEx(<span>...</span>) called<span>:</span>
i!  Atype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  Btype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  Ctype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  computeType<span>:</span> type<span>=</span>cublasComputeType_t; val<span>=</span>CUBLAS_COMPUTE_32F_FAST_16F(<span>74</span>)

<span>2</span>×2 CuArray{<span>Float32</span>,<span>2</span>}<span>:</span>
 <span>0.175258</span>  <span>0.226159</span>
 <span>0.511893</span>  <span>0.331351</span>
</code></pre></div><p>As part of these changes, CUDA.jl now defaults to using tensor cores. This may affect
accuracy; use math mode <code>PEDANTIC</code> if you want the old behavior.</p>
<p>Work is <a href="https://github.com/JuliaGPU/CUDA.jl/issues/391">under way</a> to extend these
capabilities to the rest of CUDA.jl, e.g., the CUDNN wrappers, or the native kernel
programming capabilities.</p>
<h2 id="new-default-stream-semantics">New default stream semantics</h2>
<p>In CUDA.jl 2.0 we’re <a href="https://github.com/JuliaGPU/CUDA.jl/pull/395">switching</a> to CUDA’s
<a href="https://developer.nvidia.com/blog/gpu-pro-tip-cuda-7-streams-simplify-concurrency/">simplified stream programming
model</a>.
This simplifies working with multiple streams, and opens up more possibilities for
concurrent execution of GPU operations.</p>
<h3 id="multi-stream-programming">Multi-stream programming</h3>
<p>In the old model, the default stream (used by all GPU operations unless specified otherwise)
was a special stream whose commands could not be executed concurrently with commands on
regular, explicitly-created streams. For example, if we interleave kernels executed on a
dedicated stream with ones on the default one, execution was serialized:</p>
<div><pre><code data-lang="julia"><span>using</span> CUDA

N <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>20</span>

<span>function</span> kernel(x, n)
    tid <span>=</span> threadIdx()<span>.</span>x <span>+</span> (blockIdx()<span>.</span>x<span>-</span><span>1</span>) <span>*</span> blockDim()<span>.</span>x
    <span>for</span> i <span>=</span> tid<span>:</span>blockDim()<span>.</span>x<span>*</span>gridDim()<span>.</span>x<span>:</span>n
        x[i] <span>=</span> CUDA<span>.</span>sqrt(CUDA<span>.</span>pow(<span>3.14159f0</span>, i))
    <span>end</span>
    <span>return</span>
<span>end</span>

num_streams <span>=</span> <span>8</span>

<span>for</span> i <span>in</span> <span>1</span><span>:</span>num_streams
    stream <span>=</span> CuStream()

    data <span>=</span> CuArray{<span>Float32</span>}(undef, N)

    <span>@cuda</span> blocks<span>=</span><span>1</span> threads<span>=</span><span>64</span> stream<span>=</span>stream kernel(data, N)

    <span>@cuda</span> kernel(data, <span>0</span>)
<span>end</span>
</code></pre></div>

<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multistream_before.png" alt="Multi-stream programming (old)">
</figure>

<p>In the new model, default streams are regular streams and commands issued on them can
execute concurrently with those on other streams:</p>


<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multistream_after.png" alt="Multi-stream programming (new)">
</figure>

<h3 id="multi-threading">Multi-threading</h3>
<p>Another consequence of the new stream model is that each thread gets its own default stream
(accessible as <code>CuStreamPerThread()</code>). Together with Julia’s threading capabilities, this
makes it trivial to group independent work in tasks, benefiting from concurrent execution on
the GPU where possible:</p>
<div><pre><code data-lang="julia"><span>using</span> CUDA

N <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>20</span>

<span>function</span> kernel(x, n)
    tid <span>=</span> threadIdx()<span>.</span>x <span>+</span> (blockIdx()<span>.</span>x<span>-</span><span>1</span>) <span>*</span> blockDim()<span>.</span>x
    <span>for</span> i <span>=</span> tid<span>:</span>blockDim()<span>.</span>x<span>*</span>gridDim()<span>.</span>x<span>:</span>n
        x[i] <span>=</span> CUDA<span>.</span>sqrt(CUDA<span>.</span>pow(<span>3.14159f0</span>, i))
    <span>end</span>
    <span>return</span>
<span>end</span>

Threads<span>.</span><span>@threads</span> <span>for</span> i <span>in</span> <span>1</span><span>:</span>Threads<span>.</span>nthreads()
    data <span>=</span> CuArray{<span>Float32</span>}(undef, N)
    <span>@cuda</span> blocks<span>=</span><span>1</span> threads<span>=</span><span>64</span> kernel(data, N)
    synchronize(CuDefaultStream())
<span>end</span>
</code></pre></div>

<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multithread_after.png" alt="Multi-threading (new)">
</figure>

<p>With the old model, execution would have been serialized because the default stream was the
same across threads:</p>


<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multithread_before.png" alt="Multi-threading (old)">
</figure>

<p>Future improvements will make this behavior configurable, such that users can use a
different default stream per task.</p>
<h2 id="sparse-array-clean-up">Sparse array clean-up</h2>
<p>As part of CUDA.jl 2.0, the sparse array support <a href="https://github.com/JuliaGPU/CUDA.jl/pull/409">has been
refactored</a>, bringing them in line with other
array types and their expected behavior. For example, the custom <code>switch2</code> methods have been
removed in favor of calls to <code>convert</code> and array constructors:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> <span>using</span> SparseArrays
julia<span>&gt;</span> <span>using</span> CUDA, CUDA<span>.</span>CUSPARSE

julia<span>&gt;</span> CuSparseMatrixCSC(CUDA<span>.</span>rand(<span>2</span>,<span>2</span>))
<span>2</span>×2 CuSparseMatrixCSC{<span>Float32</span>} with <span>4</span> stored entries<span>:</span>
  [<span>1</span>, <span>1</span>]  <span>=</span>  <span>0.124012</span>
  [<span>2</span>, <span>1</span>]  <span>=</span>  <span>0.791714</span>
  [<span>1</span>, <span>2</span>]  <span>=</span>  <span>0.487905</span>
  [<span>2</span>, <span>2</span>]  <span>=</span>  <span>0.752466</span>

julia<span>&gt;</span> CuSparseMatrixCOO(sprand(<span>2</span>,<span>2</span>, <span>0.5</span>))
<span>2</span>×2 CuSparseMatrixCOO{<span>Float64</span>} with <span>3</span> stored entries<span>:</span>
  [<span>1</span>, <span>1</span>]  <span>=</span>  <span>0.183183</span>
  [<span>2</span>, <span>1</span>]  <span>=</span>  <span>0.966466</span>
  [<span>2</span>, <span>2</span>]  <span>=</span>  <span>0.064101</span>

julia<span>&gt;</span> CuSparseMatrixCSR(ans)
<span>2</span>×2 CuSparseMatrixCSR{<span>Float64</span>} with <span>3</span> stored entries<span>:</span>
  [<span>1</span>, <span>1</span>]  <span>=</span>  <span>0.183183</span>
  [<span>2</span>, <span>1</span>]  <span>=</span>  <span>0.966466</span>
  [<span>2</span>, <span>2</span>]  <span>=</span>  <span>0.064101</span>
</code></pre></div><p><a href="https://github.com/JuliaGPU/CUDA.jl/pull/421">Initial support for the COO sparse matrix type
</a> has also been added, along with more <a href="https://github.com/JuliaGPU/CUDA.jl/pull/351">better
support for sparse matrix-vector
multiplication</a>.</p>
<h2 id="support-for-cuda-111">Support for CUDA 11.1</h2>
<p>This release also features support for the brand-new CUDA 11.1. As there is no compatible
release of CUDNN or CUTENSOR yet, CUDA.jl won’t automatically select this version, but you
can force it to by setting the <code>JULIA_CUDA_VERSION</code> environment variable to <code>11.1</code>:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> ENV[<span>"JULIA_CUDA_VERSION"</span>] <span>=</span> <span>"11.1"</span>

julia<span>&gt;</span> <span>using</span> CUDA

julia<span>&gt;</span> CUDA<span>.</span>versioninfo()
CUDA toolkit <span>11.1</span><span>.</span><span>0</span>, artifact installation

Libraries<span>:</span>
<span>-</span> CUDNN<span>:</span> missing
<span>-</span> CUTENSOR<span>:</span> missing
</code></pre></div><h2 id="minor-changes">Minor changes</h2>
<p>Many other changes are part of this release:</p>
<ul>
<li>Views, reshapes and array reinterpretations <a href="https://github.com/JuliaGPU/CUDA.jl/pull/437">are now
represented</a> by the Base array wrappers,
simplifying the CuArray type definition.</li>
<li>Various optimizations to <a href="https://github.com/JuliaGPU/CUDA.jl/pull/428">CUFFT</a> and
<a href="https://github.com/JuliaGPU/CUDA.jl/pull/321">CUDNN</a> library wrappers.</li>
<li><a href="https://github.com/JuliaGPU/CUDA.jl/pull/427">Support</a> for <code>LinearAlgebra.reflect!</code> and
<code>rotate!</code></li>
<li><a href="https://github.com/JuliaGPU/CUDA.jl/pull/435">Initial support</a> for calling CUDA libraries
with strided inputs</li>
</ul>



      </main>
    </div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-10-02-cuda_2.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663940</guid>
            <pubDate>Fri, 02 Oct 2020 15:58:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kurt Gödel: A Contradiction in the U.S. Constitution?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663885">thread link</a>) | @dfischer
<br/>
October 2, 2020 | https://jeffreykegler.github.io/personal/morgenstern.html | <a href="https://web.archive.org/web/*/https://jeffreykegler.github.io/personal/morgenstern.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>by Jeffrey Kegler</p>
    <p>The story of Gödel's citizenship hearing had been much repeated over the years.
      What was known was that on 5 December 1947, Kurt Gödel went to his citizenship hearing in Trenton, New Jersey.
      The examiner was Judge Philip Forman.
      As his witnesses, Gödel brought his two closest friends, Oskar Morgenstern and Albert Einstein.
      Gödel was granted citizenship, and took his oath on 2 April 1948.
      Those were the reliably established facts.
    </p>
    <p>Afterwards, Morgenstern told many people that he and Einstein had had their hands full preventing the brilliant, but politically naive, Gödel from derailing his citizenship chances.
      No account directly from Morgenstern or anyone else at the hearing had survived, but hearsay versions circulated widely.
      The hearsay versions show considerable variation, but their burden is something like the following:
    </p>
    <p>Gödel, in his usual manner, had read extensively in preparing for the hearing.
      In the course of his studies, Gödel decided that he had discovered a flaw in the U.S. Constitution --
      a contradiction which would allow the U.S. to be turned into a dictatorship.
      Gödel, usually quite reticent, seemed to feel a need to make this known.
      Morgenstern and Einstein warned Gödel that it would be a disaster to confront his citizenship examiner with visions of a Constitutional flaw leading to an American dictatorship.
    </p>
    <p>Arriving in Princeton, the trio had no idea who the examiner would be.
      They happened to run into Judge Forman.
      Forman was a friend of Einstein's --
      when Einstein became a citizen, Forman had administered the oath.
      How lucky this was became apparent almost immediately during the questioning.
      Forman happened to remark how fortunate it was that the US was not a dictatorship, which Gödel took as a cue to explain his discovery.
      A surprised Forman exchanged glances with Einstein and Morgenstern, cut Gödel off, and forced-marched the hearing through to a successful conclusion.
    </p>
    <h2>The History, and the Legend</h2>
    <p>Nobody seems to know what Gödel's proof was.
      Many versions of the hearing that circulated featured invented dialog.
      In faculty room yarns this would be unfortunate, but not surprising.
      More startling is the presence of such dialog in the version given
      in the extremely scholarly and very carefully edited Gödel's
      <cite>Collected Works</cite>, Vol. I, p. 12.
      A footnote in
      <cite>Collected Works</cite>
      admits that its version is pure hearsay.
    </p>
    <p>I've learned to distrust such sources.
      When I was in graduate school, studying Theory of Computation, Kurt Gödel was still alive.
      I heard many tales of Gödel's eccentric behavior from mathematicians.
      Gödel certainly was eccentric, and first-hand tales of this abound,
      but I later discovered that every single anecdote I'd gotten second- or third-hand was almost certainly false.
    </p>
    <p>1997 marked a turning point in Gödel biography,
      with the publication of John Dawson's careful and reliable biography of Gödel:
      <cite>Logical Dilemmas</cite>.
      When Dawson wrote, all four participants in the hearing were dead.
      Morgenstern refers, briefly and cryptically, to the hearing in his diary, but does not say enough to fully support the story.
      Dawson in general, and quite correctly, rejected the use of hearsay.
      But this story was the most well-known story about Gödel, and nobody doubted that it had a basis in truth.
    </p>
    <p>Dawson apparently decided that some reference to this story must be made, regardless of sourcing difficulty.
      Given no alternative to using hearsay, Dawson was careful to seek out what could reasonably be thought of as the
      source of the best hearsay -- Morgenstern's widow.
      She certainly would have heard the story many times, and directly from Morgenstern.
      Dawson interviewed her on 17 October 1983.
      Dawson's account in
      <cite>Logical Dilemmas</cite>
      (pp. 179-180) is based on that interview and Morgenstern's diary entry.
    </p>
    <h2>The Lost Document</h2>
    <p>According to Dawson (p. 300), Morgenstern had written up an account of this matter for publication, but Dawson was unable to locate it.
      Dorothy Morgenstern was sure that she'd once had her husband's write-up,
      and that she'd sent it to someone.
      But she could not remember who.
      This wasn't exactly promising for the accuracy of her retelling.
      But best evidence is best evidence -- you take it how it comes.
    </p>
    <p>In dealing with the matter as a Wikipedia editor,
      I took the position that Dawson's account of this hearing was the final word.
      The other versions were either retellings of the Dawson account,
      hearsay from less reliable sources or pure speculation.
      Regardless of which of the three they were, they were to be rejected as sources for the Wikipedia article.
    </p>
    <p>When dealing with the matter as a novelist, the God Proof,
      I took the position that this story had become a legend as much as any tale of an 11th century saint.
      Since it was a legend, I was free as a writer of fiction to add any incident or dialog I thought to be in the spirit of the thing.
    </p>
    <p>But now the "lost" Morgenstern document has reappeared.
      Apparently the IAS has had it all these years.
    </p>
    <h2>Links</h2>
    <ul>
      <li>
        <a href="https://drive.google.com/file/d/0B9_mR_M2zOc4Y2VhNzZkMDQtMDdlNC00YWQ0LWJlYzQtMzAxZjAxMGYxNzM5/view?usp=sharing">
          PDF of original Morgenstern document on the Gödel citizenship hearing</a>:
        Morgenstern says that he did not check dates, and that corrected ones would be needed.
        The dates are, indeed, wrong.
        The ones above are from Dawson and presumably correct.
        The "Examinor" (sic) referred to is Judge Forman.
        Morgenstern was not a native English speaker, and this often shows in his wording and spelling.
      </li>
      <li>
        <a href="http://www.ias.edu/people/godel/institute">
          The Institute for Advanced Studies Web page</a>
        on which I first saw an edited version the Lost Morgenstern Document.
      </li>
      <li><a href="http://www.ias.edu/files/pdfs/publications/letter-2006-spring.pdf">The IAS "Letter" for Spring 2006,
          in which the Lost Morgenstern Document first reappeared</a>.
      </li>
      <li>
        <a href="http://jeffreykegler.blogspot.com/2008/11/kurt-gdel-contradiction-in-us.html">
          The first article in my blog series on the finding of the Lost Morgenstern Document</a>,
        and what I think it reveals.
      </li>
      <li><a href="http://jeffreykegler.github.io/personal/">My personal website</a>
        has more about me (Jeffrey Kegler) and my other interests.
      </li>
      <li>I wrote a novel about Gödel's "ontological proof" of the existence of God.
        The God Proof is available as
        <a href="https://drive.google.com/open?id=0B9_mR_M2zOc4WVJFNWJXNkJfSHc">
          as a free download</a>.
        You can also order
        <a href="http://www.amazon.com/God-Proof-Jeffrey-Kegler/dp/1434807355">
          print copies from Amazon.com</a>.
      </li>
    </ul>
    
    <p>These pages are licensed under a
      <a href="https://creativecommons.org/licenses/by-nd/4.0/">Creative
        Commons Attribution-NoDerivatives 4.0 International
        License</a>
    </p>
    
    
    
    

</div>]]>
            </description>
            <link>https://jeffreykegler.github.io/personal/morgenstern.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663885</guid>
            <pubDate>Fri, 02 Oct 2020 15:54:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Does My Computer Not Boot with a USB Hub Attached?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24663858">thread link</a>) | @kn100
<br/>
October 2, 2020 | https://kn100.me/usb-hub-bs/ | <a href="https://web.archive.org/web/*/https://kn100.me/usb-hub-bs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>My trusty old USB 3 hub has failed. It was only around a year old, but it was cheap and it worked. It wasn’t powered, but most of the time it didn’t need to be. One day I began having very strange issues with USB on my computer. Devices randomly disconnecting, devices never connecting until the computer was rebooted and so on. I eventually narrowed it down to the hub. I tossed it out after a quick internal inspection had revealed nothing obviously wrong, and went shopping for a new hub.</p>
<p>My requirements for a hub were very simple:</p>
<ul>
<li>it must be externally powered,</li>
<li>it must be relatively aesthetically neutral - no gamer aesthetics or hideous glossy plastic,</li>
<li>it must be USB 3,</li>
<li>it must offer between 3 and 7 extra ports - any less and what’s the point, and more and the hub is unnecessarily big, and I treat my desk like Tokyo. Space is a at a premium,</li>
<li>the cost must not exceed 35 GBP (45 US Dollars at the time of writing),</li>
<li>and it must have a detachable cord that connects it to the computer, or offer a cord long enough to reach my computer under my desk.</li>
</ul>
<p>While shopping, almost every single hub I came across had some stupid design that either prioritised it looking space age with blue LEDS galore, and a lot of them even had individual power switches for each USB port. Why anyone would want that is beyond me. Other hubs had tiny 15cm cables, since they’re designed to be used right beside a laptop.</p>
<p>I ended up settling on a very cleverly designed Orico 4 port Aluminium hub. I particularly liked this one because aesthetically speaking it was pretty neutral, and it even handles the problem of the USB hub floating off in the breeze by integrating a clamp so that you can clamp it to your desk or your monitor.</p>
<figure>
<img src="https://kn100.me/hub-product.jpg"> <figcaption>
<h4>The hub I chose. A novel design!</h4>
</figcaption>
</figure>
<p>It arrived, and seemed to work perfectly. USB transfer speeds were as expected, the external power source being MicroUSB meant I could attach any fairly dumb USB power supply to it to supply extra power, the cable leading to the PC itself was detachable and relatively standard (USB A to USB A) and all was good with the world.</p>
<p>That was until I put my computer to sleep. The next morning, I pressed a key on my keyboard to trigger the system to wake up, and nothing happened. The keyboard is not attached to the hub, nor is it attached to a port on the motherboard that is on the same controller, so this was perplexing. I pressed the power button on the tower, but still nothing! Very strange. I detached the USB hub, and immediately my computer came to life and worked as normal.</p>
<p>Through further experimentation I determined this strange phenomenon only happened when an external power source was connected. I toyed with the idea of returning what was obviously a faulty product, but reasoned that I didn’t actually need it to be powered, and pretty much all the other hubs in the same price range were either aesthetically disgusting or lacked other features I liked about this one - so I kept it.</p>
<p>That is until today, when through some research, I found this isn’t just a problem with <em>my</em> USB hub, it’s a problem many have with powered hubs. Articles like <a href="https://www.pro-tools-expert.com/production-expert-1/2019/9/18/warning-your-usb-hub-may-be-harming-your-drives-and-you-may-lose-valuable-studio-work-heres-how-to-fix-it">this</a>, or forum posts like <a href="https://forums.tomshardware.com/threads/computer-wont-start-with-usb-hub-connected.2753255/">this</a> show that totally unrelated hubs cause similar issues for their owners. This got me thinking to past experiences of USB hubs I’ve had. In the past, a less financially stable me used to buy the cheapest possible thing every time. At one time, I was experimenting with a Raspberry Pi along with external hard drives. I discovered that a powered hub was necessary for these experiments because the Pi itself was incapable of providing much USB power. I bought the cheapest USB 2 powered hub I could at the time from eBay, and it mostly worked fine. To describe the setup a little, I had the hub itself connected to its power supply, and the ‘in’ usb port connected to one of the Pis USB ports. Imagine my surprise when the Pi switched on and booted up, without any power supply attached! I thought this was cool at the time, and chalked it up to ‘It’s not a bug, it’s a feature’, and forgot about it. Fast forward to today me, when I realised my experience back then was possibly related to the problems I was having with this new Orico USB hub today. After a little bit of thought, I realised that the hub was most likely ‘backfeeding’ power to the connected computer.</p>

<p>To keep things simple, let’s stick to USB 2 for now. USB 2 consists of 4 conductors, known as VCC (this is the ‘positive’ 5 volt connection), GND (this is the ‘negative’ power connection), D+, and D- (the data transmission pins, no true power flows over these pins). This means that a connected USB device can both draw power and transfer data. When you see 5 volts on a power adaptor or something, this is usually an approximation. For various reasons which revolve mostly around cost saving, most USB power adaptors will actually output slightly more than 5 volts, and then when a load is applied (say, a charging phone), the voltage drops down a bit. The better the quality of the power supply, closer to 5 volts it’ll start at generally and the smaller the drop when a load is applied.</p>
<figure>
<img src="https://kn100.me/usb-pinout.png"> <figcaption>
<h4>The USB pinout</h4>
</figcaption>
</figure>
<p>This applies to your computer’s USB ports too - except for one big difference: the power supply inside your computer is probably significantly better designed than the USB plug sockets that are mass produced. In fact, if I measure the voltage coming from my USB ports on my computer, I get a value of around 5.03v. If I measure the voltage coming from my phone charger, I get 5.21v. This is a pretty big difference!</p>
<p>The next thing to know is how a powered hub actually works. Essentially, a powered hub takes an external power source, and passes that power source through to the USB devices connected to the hub in place of your computer. One problem that these hubs face however is what if the user wishes to use the hub in its ‘unpowered’ state - where they’ve connected the hub to their computer with no power supply. In order to implement this properly, the hub would probably need some mechanism to switch between the computer power and the external PSU if it is connected. This would however add cost to the manufacture of the hub, so instead of doing this, they just connect the 5v of your computer through to the 5v of the external power supply. This is ridiculously bad because if there is even the smallest difference between the voltage being supplied by your computer and the voltage being supplied by the external power source, power will flow towards the device with the lower voltage! This is ‘backfeeding’. As a simple analogy, imagine you took two rechargeable batteries and connected them together. What you’d find happens is that the batteries will eventually end up at exactly the same voltage, which will be slightly lower than what you’d expect if you did the maths, as a small amount of power would be lost as heat. If the power source is ‘infinite’ however - like our wall connected computer or our wall connected external hub, this power will just continue to flow. Where it goes or what happens with it is completely undefined. In the case of our Raspberry Pi earlier, the circuit was simple enough that it just led to the Pi being powered up. In the case of my computer, it screwed with the system so badly that hardware buttons like the power button literally stopped functioning altogether.</p>

<p>This design seems stupid right? The problem is, it is the cheapest way of achieving the design goal of having a USB hub work with or without power. If we didn’t care about this particular feature, we could either just not have an external power source and have a purely unpowered hub, or we could not connect the 5v pin from the computer and therefore only supply power from the external PSU. Both of these solutions in effect are more expensive than just living with the backfeeding ‘feature’ since it’d mean the company offering the hub would need to deal with support requests from people wondering why their hub doesn’t work ‘unpowered’ when their other one does, or vice versa. Instead, we get backfeeding. I’m sure that some computers would not exhibit any real problems with this design, seeing as it’s been around since as long as powered USB hubs have been around as far as I can tell, and it’s likely some USB chipsets are designed with this in mind, but mine was not. Others computers, especially Macs, deal with this particular issue far more destructively, causing damage to the computer’s USB chipset when a backfeeding USB hub is connected.</p>

<p>Before we continue, you should know I am not an electrical engineer, if that wasn’t clear from how vaguely I described things above. I am a software engineer who likes to dabble with electronics. This means my advice below does not come from someone who is qualified to give it. You should follow this advice at your own risk. I take no responsibility for damage you do to yourself, your USB hub, or your computer, or to anything else for that matter.</p>

<ol>
<li>Firstly, I validated this was the problem. I engaged in a clever little trick where I took an old USB cable - USB 2 or 3 is fine, cut it in half, exposed the either 2 (cable is power only) or 4 wires, and looked up USB wire colouring to realise that the red wire is usually the VCC wire, and Black/White is usually GND. I then connected the cut up USB lead to the input port on my hub (where my computer connects), and connected the external power supply. I measured 5 volts across these two wires using the multimeter, meaning this hub does backfeed.</li>
</ol>
<figure>
<img src="https://kn100.me/hub-screw.jpg"> <figcaption>
<h4>The hubs screws</h4>
</figcaption>
</figure>
<ol start="2">
<li>My hub comes apart very easily. Disconnect all wires. Four screws removed and we immediately get access to the circuit board. USB 3 is a little more complicated than USB 2 - featuring 9 conductors rather than USB 2s 4.</li>
</ol>
<figure>
<img src="https://kn100.me/hub-circuit.jpg"> <figcaption>
<h4>The hubs circuit board. Surprisingly nice, given this stupid issue!</h4>
</figcaption>
</figure>
<ol start="3">
<li>I have no idea what the pinout of USB 3 is, nor how this specific connector orders things. I connected the cut up USB lead to the input port on my hub (where my computer …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kn100.me/usb-hub-bs/">https://kn100.me/usb-hub-bs/</a></em></p>]]>
            </description>
            <link>https://kn100.me/usb-hub-bs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663858</guid>
            <pubDate>Fri, 02 Oct 2020 15:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write 5x more but write 5x less]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663390">thread link</a>) | @mcrittenden
<br/>
October 2, 2020 | https://critter.blog/2020/10/02/write-5x-more-but-write-5x-less/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/10/02/write-5x-more-but-write-5x-less/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1744">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>There are 2 things I have come to believe about writing:</p>



<ol><li><strong>The average person should write 5x more things than they do.</strong></li><li><strong>The average written thing should be 5x shorter than it is.</strong></li></ol>



<p>That’s what I mean by “write 5x more but write 5x less.” Write more often, but make each thing you write shorter. </p>



<p>I don’t care what it is. Blog posts. Novels. Google docs. Articles. Wiki pages. Write more of them, but make them shorter. </p>



<p>Why write more often? </p>



<ul><li>Because writing helps thinking. </li><li>Because practice will make you better. </li><li>Because writing is more shareable than speaking.</li><li>Because humans are worse than computers at storing knowledge.</li><li>Because writing your old thoughts frees your brain to think of new thoughts.</li></ul>



<p>Why make them shorter?</p>



<ul><li>Because the shorter it is, the more people will read it.</li><li>Because of the <a href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto principle</a>: 80% of the value is in 20% of the length (hence “5x shorter”).</li></ul>



<p>So write more, but write less.</p>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/10/02/write-5x-more-but-write-5x-less/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663390</guid>
            <pubDate>Fri, 02 Oct 2020 15:06:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What We Learned by Closing a $4M Investment from Accel]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663314">thread link</a>) | @hodgesrm
<br/>
October 2, 2020 | https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel | <a href="https://web.archive.org/web/*/https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>I’m pleased to share the news that Altinity has raised a $4M seed investment from Accel. Dan Levine led the round. We are honored by Accel’s trust and delighted to work with Dan. We plan to use the investment to roll out our new <a href="https://altinity.com/cloud/">Altinity.Cloud platform</a> and to strengthen <a href="https://clickhouse.tech/">ClickHouse </a>into the best analytic database on the planet.&nbsp;</p><p>Dan was the first venture capitalist to contact us, as he tells in his <a href="http://www.accel.com/noteworthy/our-seed-in-altinity" target="_blank" rel="noreferrer noopener">blog article about the seed investment</a>. He was enthusiastic but also very patient.That was fortunate, because we then talked to 43 other VCs at greater or lesser length over the next year and a half. The count omits those who greeted our overtures with stony silence. In the end we were absolutely confident Dan and Accel were the right choice. At the same time, we learned from many others.</p><p>Looking back, it is apparent we did more than just collect a check from a great investment team. We also learned a number of valuable lessons about early stage venture investment.&nbsp; Many of these were not obvious, at least to me. In this article I will share what we learned, along with a spreadsheet we developed to help with investment math. I hope our account will be useful — or at least entertaining!</p><p><h2 id="h-what-do-vcs-really-want">What do VCs really want?</h2>
</p><p>VC websites often sport brave slogans like “we are looking for bold entrepreneurs who will change the world.” What they are actually looking for, of course, is far more concrete: a big return on a speculative bet about a new business. The first thing we learned was how venture capital actually works and how we fit in.&nbsp;</p><p>Let’s start with where the money comes from and how it is managed. Venture capital firms operate one or more funds, which they use to make investments. Each venture capital firm has general partners who work for the company, decide where to invest, and take care of serving on boards and other duties required to supervise each investment.&nbsp; There is also another type of partner, known as a limited partner or LP. LPs can be wealthy individuals, pension funds, sovereign investment funds, you name it. They supply cash but have no role in making investment decisions. Here is a picture.&nbsp;</p><div><figure><img loading="lazy" width="954" height="368" src="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png" alt="" srcset="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png 954w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-300x116.png 300w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-768x296.png 768w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-600x231.png 600w" sizes="(max-width: 954px) 100vw, 954px" data-lazy-srcset="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png 954w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-300x116.png 300w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-768x296.png 768w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-600x231.png 600w" data-lazy-src="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>In the first meeting with a new VC you typically hear about the current funds, how big they are, and other details like reserves for follow-on investments in promising companies. When you ask what payback they are seeking the most frequent answer is “return the fund.” This is so common that I stopped writing it down unless the answer was something different. It means the investment in your company needs to pay out at the value of the entire fund, not just what the VC put into your company. The reason has to do with the mechanics of the funds.</p><p>Most startups fail or return money that does not come close to covering the investment. To provide a decent return to limited partners and VC general partners plus pay overhead, at least a couple of investments need to hit home runs and to pay off at full value of the fund. It’s basic math, but the numbers are big. Say a $400M fund invests $40M total for a 25% share of your startup, a typical target percentage. To return the fund means that the startup will have to exit for $1.6B ($400M = $1.6B * 25%). Grand slams like <a href="https://news.crunchbase.com/news/these-were-the-biggest-winners-in-snowflakes-record-busting-ipo" target="_blank" rel="noreferrer noopener">Snowflake</a> return far more and make the fund very successful.&nbsp;</p><p>At first it was disconcerting when A-list VC prospects baldly asked how we would get them an exit in the $1B+ range. Over time I developed empathy for this attitude. VC general partners have to make the math work or find another job. Meanwhile entrepreneurs need to have a problem that fits the pattern of investment or venture funding does not make a lot of sense. That’s the economic reality and has little to do with how individual VCs feel about you personally, or even about your business.&nbsp;</p><p>We needed to articulate to ourselves how we would win in a large market–SQL data warehouses–filled with a lot of savvy competitors like Amazon and Snowflake. The classic strategy is to create a <em><span>new</span> </em>market that did not previously exist, then become the leader. Anurag Gupta and his colleagues at Amazon put it brilliantly <a href="https://dl.acm.org/doi/10.1145/2723372.2742795" target="_blank" rel="noreferrer noopener">in a paper on Amazon Redshift</a>:&nbsp;</p><p><em>Our goal with Amazon Redshift was not to compete with other data warehousing engines, but to compete with non-consumption.&nbsp;</em></p><p>The unique differentiation of ClickHouse is that it is open source and runs anywhere: from public clouds down to Android phones. Any developer on the planet can download it and add high performance analytics to any application without sacrificing portability or scaling. That’s an enormous expansion of the market that will fuel innovation not just at the database level but will extend to new applications of big data as well as the tools and platforms to run them.&nbsp;</p><p>Here’s another key insight: it took months to be able to state that value proposition in three sentences. It’s like learning a new language — anyone can learn to say hello but achieving fluency requires real work.&nbsp;</p><p>We did a lot of modeling to understand the growth trajectory needed to achieve the kind of revenue our predecessors are making. One of the conclusions was that we needed to build a great cloud platform for ClickHouse. It’s a tried-and-true way to build a successful business, especially for companies that manage data, and one that our customers have confirmed as a fruitful path to growth. We believe in the plan and it matches venture capital economics.&nbsp;</p><p><h2 id="h-vcs-work-off-a-thesis">VCs Work Off a Thesis</h2>
</p><p>I didn’t know a lot of early stage VCs when we began fund-raising, though like everyone I heard they were fine human beings worthy of acquaintance. The initial conversations were illuminating in one particular respect. Venture capitalists don’t necessarily know that much about specific technology or markets.&nbsp;</p><p>Here’s an example. My favorite demo for ClickHouse is the <a href="https://youtu.be/zDIK3Ej86GU" target="_blank" rel="noreferrer noopener">ClickHouse-fast demo</a> where I first run a query on data generated purely in memory followed by a similar query that accesses 1.3 billion rows of taxi data in slowish network-attached storage. I usually pause dramatically after the in-memory query to ask which query is going to be faster. Everybody knows access to memory is faster than storage, right?</p><p>Actually, in this demo it’s not. You have to be very careful to make an apples-to-apples comparison when comparing memory and storage access speeds. ClickHouse compresses stored data and parallelizes I/O extremely well. Reading from storage is therefore very fast. With ClickHouse it is not hard to choose in-memory queries that look similar but run far slower because they have a different execution path with less parallelization or other inefficiencies. It’s a subtle point that experienced database people understand, whereas VCs I talked to often got it wrong. (And then argued about it, too.)&nbsp;</p><p>This experience illustrates that deep dives on technology are not always the best way to evaluate early stage businesses. Good VCs tend to look for proxies that indicate signs of traction. In our case Dan Levine knew about ClickHouse because his other start-up investments used it. Dan pays really close attention to things they like. Dan picked up on ClickHouse earlier and more clearly than anyone we spoke to. The fact that we were an experienced team already selling services profitably was perhaps another useful signal. But Dan was also looking for more than just specific signals–he was looking for a pattern related to data, backed by a solid team.&nbsp;</p><p>Over time, we found that the VCs who really picked up on our story had a thesis about the value of combining two things:&nbsp;</p><div><ul>
<li>Data – Faster and more cost effective ways of analyzing large datasets are inherently valuable to enterprises.&nbsp;&nbsp;</li>
<li>Open source – There are standard models for marketing and monetizing open source projects to build very large businesses</li>
</ul>
</div><p>VCs with these convictions tended to like what we were doing overall, though they often found specific things they didn’t like: open source community too small, too much competition, not the right team, already made a competing investment, etc. That said, we didn’t argue about the size of the market or whether open source was the right overall strategy to reach it.&nbsp;It helped that the original developers of <a href="https://en.wikipedia.org/wiki/ClickHouse">ClickHouse at Yandex</a> did an amazing job of open sourcing the code and starting a great community around it. </p><p>Not surprisingly, we learned that those same investors were precisely the people we wanted backing the company. Not only did we share key assumptions about the business, but they had funded such businesses before with successful outcomes. Because of that they could offer useful advice on big topics like strategy to build open source communities or workable business models.&nbsp; They could also connect us with outstanding people like Mike Olson of Cloudera (and many others) who had worked through similar problems and could help us see around corners.&nbsp;</p><p>Here’s a final insight that relates back to the technology point I made above. VCs can identify promising companies, but they can’t tell you how to run yours. As an entrepreneur you understand the technology, your customers, and what is feasible to achieve. We had a number of debates with potential investors about details of the business plan.</p><p>For example, many VCs favor pure cloud services, because the best ones experience explosive growth and high margins. However, a push-button service is not a complete solution, especially for complex enterprise products like databases. Altinity has been in business since 2017 and we have articulate users who say they want us to take care of running ClickHouse in the cloud. They also want application tools, new server features, training, support, and implementation help. Their problem is not just to deploy a database but to create applications that add value to their own business. If you help them do that you have a much more competitive business.&nbsp;</p><p>Our mission is to help any enterprise that uses ClickHouse. We provide everything customers need to be successful with ClickHouse, <em>including</em> a great cloud service. We also support the ClickHouse …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel">https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel</a></em></p>]]>
            </description>
            <link>https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663314</guid>
            <pubDate>Fri, 02 Oct 2020 14:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I've learned about isometric rendering]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663156">thread link</a>) | @endlessvoid94
<br/>
October 2, 2020 | https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/ | <a href="https://web.archive.org/web/*/https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>As part of my work on <a rel="noreferrer noopener" href="https://agave.com/" target="_blank">Agave</a>, I needed to find a way to render a virtual office in a web application. I also needed the ability to maintain a high engineering velocity and get high leverage out of the libraries we chose.</p>



<p>So far, the biggest learning experience for me has been isometric rendering. You know isometric rendering. It’s that sort of 2.5-dimension look that some video games have, where you’re sort of looking down from the top right on the map. Some examples:</p>



<figure><img data-attachment-id="1434" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/simcity-2000-free-download-7/" data-orig-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?fit=1280%2C867&amp;ssl=1" data-orig-size="1280,867" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="SimCity-2000-Free-Download-7" data-image-description="" data-medium-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?fit=300%2C203&amp;ssl=1" data-large-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?fit=660%2C447&amp;ssl=1" loading="lazy" width="660" height="447" src="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?resize=660%2C447&amp;ssl=1" alt="" srcset="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?resize=1024%2C694&amp;ssl=1 1024w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?resize=300%2C203&amp;ssl=1 300w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?resize=768%2C520&amp;ssl=1 768w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?resize=402%2C272&amp;ssl=1 402w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/SimCity-2000-Free-Download-7.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>Isometric map: SimCity 2000</figcaption></figure>



<figure><img data-attachment-id="1435" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/red-alert-2-free-download-1/" data-orig-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?fit=1024%2C768&amp;ssl=1" data-orig-size="1024,768" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Red-Alert-2-Free-Download-1" data-image-description="" data-medium-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?fit=660%2C495&amp;ssl=1" loading="lazy" width="660" height="495" src="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?resize=660%2C495&amp;ssl=1" alt="" srcset="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/Red-Alert-2-Free-Download-1.jpg?resize=363%2C272&amp;ssl=1 363w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>Isometric map: C&amp;C Red Alert 2</figcaption></figure>



<p>Perhaps the most appropriate modern example is the intro scene to HBO’s Silicon Valley:</p>



<figure><p><span><iframe width="660" height="372" src="https://www.youtube.com/embed/7m2j_0ivw2I?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<p>From the start, we had a vision of a virtual office in this style. It would be significantly more immersive than a flat (two-dimensional) map, and afforded the opportunity for some seriously cool experiences. (Plus, Jared and I both loved playing these games when we were kids.)</p>



<p>This was a daunting task, as I had no experience in video game design or programming. I ended up watching a ton of different YouTube videos on the topic in an effort to find my way. I didn’t really even know what I was looking for – it was sort of an immersive, random process.</p>



<p>I have been a longtime fan of Id software, Doom in particular, and have followed John Carmack for a long time. So, naturally I ordered a copy of <a rel="noreferrer noopener" href="https://www.amazon.com/gp/product/1099819776/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1" target="_blank">The Game Engine Black Book: Doom</a> and read it cover to cover in three days. I learned a lot!</p>



<p>I was most interested in how the engine worked and, in particular, rendering:</p>



<figure><img data-attachment-id="1438" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/img_2791-2/" data-orig-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG_2791" data-image-description="" data-medium-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?fit=660%2C495&amp;ssl=1" loading="lazy" width="660" height="495" src="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=660%2C495&amp;ssl=1" alt="" srcset="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=363%2C272&amp;ssl=1 363w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?resize=1320%2C990&amp;ssl=1 1320w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_2791.png?w=1980&amp;ssl=1 1980w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>Buy this book, it’s amazing</figcaption></figure>



<p>I finally figured out that what we were looking for was called <strong>isometric</strong> rendering. Here’s what I learned.</p>



<h2>Cartesian vs. Isometric</h2>



<p>On a 2d game, there is simply a cartesian map. It has x and y coordinates. If you were to lay out the old-school board game <strong>Risk</strong> onto its cartesian map, it would look something like this:</p>



<figure><img data-attachment-id="1439" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/plate_carree_projection/" data-orig-file="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?fit=1179%2C599&amp;ssl=1" data-orig-size="1179,599" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="plate_carree_projection" data-image-description="" data-medium-file="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?fit=300%2C152&amp;ssl=1" data-large-file="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?fit=660%2C335&amp;ssl=1" loading="lazy" width="660" height="335" src="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?resize=660%2C335&amp;ssl=1" alt="" srcset="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?resize=1024%2C520&amp;ssl=1 1024w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?resize=300%2C152&amp;ssl=1 300w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?resize=768%2C390&amp;ssl=1 768w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?resize=535%2C272&amp;ssl=1 535w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/plate_carree_projection.png?w=1179&amp;ssl=1 1179w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>The world map projected onto a cartesian grid</figcaption></figure>



<p>Conventionally the top left cell is 0,0 (the origin). So, where I live in South Lake Tahoe would be somewhere inside 5,5, or maybe 6,5. </p>



<p>Cartesian grids are trivial to store in memory as two dimensional arrays. And, even in games like Sim City, all of the units, characters, items, really anything on the map has a coordinate in the Cartesian plane. So to store the data for our virtual office, we’d need a simple two dimensional array that indicates where each avatar, furniture, etc all exist in the office.</p>



<p>Next, we needed artwork for everything. We started with floor tiles. Here’s an example of the sprite we used:</p>



<div><figure><img data-attachment-id="1441" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/floor-tile2/" data-orig-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/floor-tile2.png?fit=50%2C30&amp;ssl=1" data-orig-size="50,30" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="floor-tile2" data-image-description="" data-medium-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/floor-tile2.png?fit=50%2C30&amp;ssl=1" data-large-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/floor-tile2.png?fit=50%2C30&amp;ssl=1" loading="lazy" width="50" height="30" src="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/floor-tile2.png?resize=50%2C30&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>







<p>As you can see, this is not a square. It’s a square tile as seen from the top-right. It’s also not technically a <strong>perspective</strong> sprite because the lines do not converge to the horizon – they remain parallel. It’s an <strong>isometric</strong> sprite. To make things more confusing, the image file itself is a rectangular, transparent PNG. Here’s a closer look:</p>



<div><figure><img data-attachment-id="1444" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/screen-shot-2020-10-01-at-1-00-27-pm/" data-orig-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?fit=1129%2C696&amp;ssl=1" data-orig-size="1129,696" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen-Shot-2020-10-01-at-1.00.27-PM" data-image-description="" data-medium-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?fit=300%2C185&amp;ssl=1" data-large-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?fit=660%2C407&amp;ssl=1" loading="lazy" width="660" height="407" src="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?resize=660%2C407&amp;ssl=1" alt="" srcset="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?resize=1024%2C631&amp;ssl=1 1024w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?resize=300%2C185&amp;ssl=1 300w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?resize=768%2C473&amp;ssl=1 768w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?resize=441%2C272&amp;ssl=1 441w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.00.27-PM.png?w=1129&amp;ssl=1 1129w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>As you can see, this is a 50×30 PNG file with a transparent background.</figcaption></figure></div>



<p>And, it turns out, the tile itself has a height of 5 pixels, meaning the “top” of the tile is 50×25. It’s half as tall as it is wide.</p>



<p>After some fiddling I had produced the following map by rendering each tile individually (in a loop) in order from “top left” to “bottom right”:</p>



<div><figure><img data-attachment-id="1445" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/screenshot-2020-08-05-18-12-49/" data-orig-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?fit=836%2C409&amp;ssl=1" data-orig-size="836,409" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-2020-08-05-18.12.49" data-image-description="" data-medium-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?fit=300%2C147&amp;ssl=1" data-large-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?fit=660%2C323&amp;ssl=1" loading="lazy" width="660" height="323" src="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?resize=660%2C323&amp;ssl=1" alt="" srcset="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?w=836&amp;ssl=1 836w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?resize=300%2C147&amp;ssl=1 300w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?resize=768%2C376&amp;ssl=1 768w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/Screenshot-2020-08-05-18.12.49.png?resize=556%2C272&amp;ssl=1 556w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"></figure></div>



<p>It got confusing quickly. The “top left” when looked at isometrically is actually in the top of the screen, slightly to the right of center!</p>



<p>So I needed to figure out how to place avatars and other items onto the map from my cartesian grid. The brown-haired avatar on the left is “at” location 5,12. I had to figure out how to convert from cartesian to isometric so that I could tell the game engine precisely where to render the avatar.</p>



<p>If we were just rendering on a Cartesian plane, I could simply tell the engine to render an item at 2,2 by multiplying by the width of one tile in the grid:</p>



<pre><code>screen_x_coord = cartesian_x * tile_width
screen_y_coord = cartesian_y * tile_height</code></pre>



<p>However, this only works with a square grid. Our isometric grid is not exactly a square. This illustrates the problem better than I can explain:</p>



<div><figure><img data-attachment-id="1447" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/img_875327dd02e8-1/" data-orig-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?fit=1288%2C1229&amp;ssl=1" data-orig-size="1288,1229" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_875327DD02E8-1" data-image-description="" data-medium-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?fit=300%2C286&amp;ssl=1" data-large-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?fit=660%2C630&amp;ssl=1" loading="lazy" width="660" height="630" src="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?resize=660%2C630&amp;ssl=1" alt="" srcset="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?resize=1024%2C977&amp;ssl=1 1024w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?resize=300%2C286&amp;ssl=1 300w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?resize=768%2C733&amp;ssl=1 768w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?resize=285%2C272&amp;ssl=1 285w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_875327DD02E8-1.jpeg?w=1288&amp;ssl=1 1288w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"></figure></div>







<p>Thinking this through: for every 1 cell “right” we want to go, we’re actually going “right” by 1/2 a tile <em>width</em> and “down” by 1/2 a tile <em>height</em>. Like this:</p>



<div><figure><img data-attachment-id="1449" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/img_572c53bca2e5-1/" data-orig-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?fit=1229%2C605&amp;ssl=1" data-orig-size="1229,605" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_572C53BCA2E5-1" data-image-description="" data-medium-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?fit=300%2C148&amp;ssl=1" data-large-file="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?fit=660%2C325&amp;ssl=1" loading="lazy" width="660" height="325" src="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?resize=660%2C325&amp;ssl=1" alt="" srcset="https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?resize=1024%2C504&amp;ssl=1 1024w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?resize=300%2C148&amp;ssl=1 300w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?resize=768%2C378&amp;ssl=1 768w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?resize=553%2C272&amp;ssl=1 553w, https://i0.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_572C53BCA2E5-1.jpeg?w=1229&amp;ssl=1 1229w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"></figure></div>







<p>So, we have a new formula:</p>



<pre><code>screen_x_coord = cartesian_x * (tile_width / 2) - cartesian_y * (tile_width / 2)
screen_y_coord = cartesian_y * (tile_height / 2) + cartesian_x * (tile_height / 2)</code></pre>



<p>Plugging these values in gives the right map location and everything looked great.</p>



<figure><img data-attachment-id="1455" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/image/" data-orig-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?fit=1624%2C1136&amp;ssl=1" data-orig-size="1624,1136" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-medium-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?fit=660%2C461&amp;ssl=1" loading="lazy" width="660" height="461" src="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?resize=660%2C461&amp;ssl=1" alt="" srcset="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?resize=1024%2C716&amp;ssl=1 1024w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?resize=300%2C210&amp;ssl=1 300w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?resize=768%2C537&amp;ssl=1 768w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?resize=1536%2C1074&amp;ssl=1 1536w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?resize=389%2C272&amp;ssl=1 389w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?resize=1320%2C923&amp;ssl=1 1320w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/image.png?w=1624&amp;ssl=1 1624w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>An early prototype of our isometric virtual office</figcaption></figure>



<p>The other thing I wanted was the ability to click somewhere on the map and move your avatar to that location. This meant I had to detect the x,y coordinates on the screen that the mouse clicked, reverse the above conversion from isometric to cartesian, move the avatar in the 2d arrays and then re-render them isometrically. </p>



<p>Whew! Lots of steps to simply render an item at a specific set of coordinates. </p>



<p>Another wrinkle that I ran into was that rendering a sprite “at” a location is not very well defined. If I’m trying to render a square image at a particular cell, by default many game engines place the top left of the image at the defined location. That won’t work for us since we need our characters to be “standing” in a particular cell. So much of our rendering code actually does even more arithmetic by adjusting the coordinates according to the width and height of the sprite such that the bottom-center of the image (where the character’s feet are) become the “anchor” point and we render the item “at” a coordinate by place it’s bottom-center in the defined coordinates:</p>



<figure><img data-attachment-id="1457" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/img_e973daae6f2e-1/" data-orig-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?fit=930%2C1213&amp;ssl=1" data-orig-size="930,1213" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_E973DAAE6F2E-1" data-image-description="" data-medium-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?fit=230%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?fit=660%2C861&amp;ssl=1" loading="lazy" width="660" height="861" src="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?resize=660%2C861&amp;ssl=1" alt="" srcset="https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?resize=785%2C1024&amp;ssl=1 785w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?resize=230%2C300&amp;ssl=1 230w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?resize=768%2C1002&amp;ssl=1 768w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?resize=209%2C272&amp;ssl=1 209w, https://i2.wp.com/davepaola.com/wp-content/uploads/2020/10/IMG_E973DAAE6F2E-1.jpeg?w=930&amp;ssl=1 930w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>How anchor placement affects the location of a sprite</figcaption></figure>







<p>There were lots of other challenges along the way, including representing the whole thing as a grid, determining which sections of the map are “walkable” so that we can use a pathfinding algorithm, finding the right “pace” a character walks across the map, and more. And I’m just scratching the surface on the types of challenges – I haven’t even mentioned our proximity video conversations that enable magical serendipitous moments, the interactive relic system we’ve devised, native operating system components and much more.</p>



<figure><img data-attachment-id="1450" data-permalink="https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/screen-shot-2020-10-01-at-1-32-02-pm/" data-orig-file="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?fit=1312%2C962&amp;ssl=1" data-orig-size="1312,962" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen-Shot-2020-10-01-at-1.32.02-PM" data-image-description="" data-medium-file="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?fit=300%2C220&amp;ssl=1" data-large-file="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?fit=660%2C484&amp;ssl=1" loading="lazy" width="660" height="484" src="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?resize=660%2C484&amp;ssl=1" alt="" srcset="https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?resize=1024%2C751&amp;ssl=1 1024w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?resize=300%2C220&amp;ssl=1 300w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?resize=768%2C563&amp;ssl=1 768w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?resize=371%2C272&amp;ssl=1 371w, https://i1.wp.com/davepaola.com/wp-content/uploads/2020/10/Screen-Shot-2020-10-01-at-1.32.02-PM.png?w=1312&amp;ssl=1 1312w" sizes="(max-width: 660px) 100vw, 660px" data-recalc-dims="1"><figcaption>The Agave Virtual Office as of October 2020</figcaption></figure>







<p>To sum it up: I learned a lot in this process and continue to learn more every day. Agave is truly a cross-disciplinary project – it requires more than simply building features to a spec. Blending the engineering of game engines with the art of sprite design (and even interior design!) has been a super cool thing to be a part of. I can’t wait to show it to you.</p>



<p>Like this post? Email dave@agave.com, I’d love to hear from you.</p>
	</div></div>]]>
            </description>
            <link>https://davepaola.com/2020/10/02/what-ive-learned-about-isometric-rendering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663156</guid>
            <pubDate>Fri, 02 Oct 2020 14:47:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BMW fined $18M for providing inaccurate retail sales information to investors]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24663027">thread link</a>) | @zachshefska
<br/>
October 2, 2020 | https://yourautoadvocate.com/guides/bmw-fraud/ | <a href="https://web.archive.org/web/*/https://yourautoadvocate.com/guides/bmw-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><iframe src="https://www.youtube.com/embed/MBe7PNfmvAw" frameborder="0" allowfullscreen=""></iframe></p><p>The Securities and Exchange Commission recently announced $18M in fines that BMW and two of their subsidiaries must pay for having provided misleading and inaccurate retail sales information to their investors.</p><p>The SEC report reads:</p><blockquote><p>According to the SEC’s order, from 2015 to 2019, BMW inflated its reported retail sales in the U.S., which helped BMW close the gap between its actual retail sales volume and internal targets and publicly maintain a leading retail sales position relative to other premium automotive companies. The order finds that BMW of North America LLC (BMW NA) maintained a reserve of unreported retail vehicle sales — referred to internally as the “bank” — that it used to meet internal monthly sales targets without regard to when the underlying sales occurred. The order also finds that BMW NA paid dealers to inaccurately designate vehicles as demonstrators or loaners so that BMW would count them as having been sold to customers when they had not been. Additionally, the order finds that BMW NA improperly adjusted its retail sales reporting calendar in 2015 and 2017 to meet internal sales targets or bank excess retail sales for future use. As a result, according to the order, the information that BMW provided to investors in the bond offerings by BMW’s U.S. financing subsidiary, BMW US Capital LLC, and to credit rating agencies contained material misstatements and omissions regarding BMW’s U.S. retail vehicle sales.</p><cite><a href="https://www.sec.gov/news/press-release/2020-223" target="_blank" rel="noreferrer noopener">https://www.sec.gov/news/press-release/2020-223</a></cite></blockquote><p>After having spent 43 years in the car business (many of which with BMW North America), I can unequivocally say these practices are routine and commonplace within car dealerships. Fraudulent behavior like this is not limited to BMW. Every manufacturer I have ever worked for encourages this.</p><p>When I worked for Penske Automotive Group we were explicitly instructed not to fudge any numbers. If our BMW rep asked us to “pad the numbers” one month, we didn’t. Penske didn’t want to participate in that type of activity. They were the exception to the rule.</p><p>As a dealer you have very little choice but to “play the game.” As I’ve talked about in other videos and guides here on the blog, car dealers don’t make much of anything when they sell vehicles. Instead, <a href="https://yourautoadvocate.com/guides/how-do-car-dealerships-make-money/" target="_blank" rel="noreferrer noopener">they make their money from factory incentives and from selling finance and insurance products</a>.</p><p><iframe src="https://www.youtube.com/embed/RTYnhidJMe8" frameborder="0" allowfullscreen=""></iframe></p><p>With that in mind, it’s clear why dealers “play the game.” If you have a $250,000 incentive that is based on the number of cars you sell in any given month, and the person writing you that check (BMW) is encouraging you to “fake” sales so that you can actually attain the bonus, what would you do? The answer is simple.</p><p>Car manufacturers are happy to pay out giant monthly bonuses to subsidize their dealers, but only if they hit certain sales volume thresholds. This is because manufacturers are then able to report better than expected sales volumes to their investors.</p><p>How many fraudulently reported vehicles are “sold” in any given month? In any given month we would designate 15 Mini Coopers as “sold,” even though they hadn’t been. In that same month we may have actually sold 35 or 40 vehicles. Each month, upwards of 20% of our “sales” were fake.</p><p>It’s surprising to think that BMW was only fined $18M. Considering a nontrivial amount of their sold inventory is not actually sold, you would think the fine should be $180M instead of $18M.</p><p>Fiat Chrysler paid $40M in fines a few years ago for similar practices. Regardless of who it is, it’s clear that the fines aren’t enough to stop the fraudulent behavior.</p>
</div></div></div>]]>
            </description>
            <link>https://yourautoadvocate.com/guides/bmw-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663027</guid>
            <pubDate>Fri, 02 Oct 2020 14:35:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache OpenWhisk is a truly portable Serverless Platform]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662975">thread link</a>) | @kiyanwang
<br/>
October 2, 2020 | https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/ | <a href="https://web.archive.org/web/*/https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apache OpenWhisk is a truly portable and multiplatform Serverless engine and it is available now on all the major clouds from multiple commercial vendors. Here is a Chess Engine running on:</p><ul><li><a href="https://whisk-chess.adobeioruntime.net/api/v1/web/default/chess">Adobe I/O</a></li><li><a href="https://eu-de.functions.appdomain.cloud/api/v1/web/a1d40f6b-e5e3-4f07-8f92-77b525392253/default/chess">IBM Cloud</a></li><li><a href="https://wka9bi13u3.apigw.ntruss.com/chess/chess/ZC2o7bFh0x/http">Naver</a></li><li><a href="https://apigcp.nimbella.io/api/v1/web/msciabar-zc3thebgxgh/default/chess">Nimbella</a></li></ul><p>And see below for instructions how to run it also locally and in any Kubernetes cluster, for example AWS EKS…</p><p><iframe src="https://www.youtube.com/embed/02Xezhf_j4U" allowfullscreen="" title="YouTube Video"></iframe></p><p>Apache OpenWhisk is a Serverless Cloud Platform, developed as an open source project at the Apache Software Foundations. It is similar to Amazon Lambda, Google Functions or Azure Functions. The main difference is that it is an Open Source project, it is offered by multiple commercial vendors, and it has a rich serverless programing model for composing functions into workflows.</p><p>Many vendors today offer cloud functions based on OpenWhisk, and it runs on all the major public clouds. However not all the vendors disclose where they run their services, so I will refer to the vendor and not to the cloud that runs it. It can also be installed on any Kubernetes cluster, so you can install in any cloud, either your private cloud or the public one you prefer.</p><p>In this article I am going to show that OpenWhisk is a truly portable serverless solution, and that you can write a single serverless application and then run it on multiple vendors.</p><p>To prove my point, I wrote an open source serverless application and ran it on all the OpenWhisk vendors I got access to. I also created a custom Kubernetes cluster and installed OpenWhisk on it to run my application.</p><p>The application is a chess engine, written in the Go programming language, and that includes backend and frontend. You can use it to play chess using a web interface, while the opponent is an AI algorithm running as a serverless function in OpenWhisk.</p><p>For testing and development you can use the Standalone OpenWhisk. It is a single node installation that can run in your machine and only requires <a href="https://docker.com/"><code>Docker</code></a> to run. You also need to download the <a href="https://github.com/apache/openwhisk-cli/releases/tag/1.0.0">OpenWhisk CLI tool <code>wsk</code></a> for your operating system in order to interact with OpenWhisk.</p><p>Once prerequisites are satisfied, you can start a local OpenWhisk with the following command:</p><div><pre><code data-lang="fallback">bash &lt;(curl -sL https://s.apache.org/openwhisk.sh)
</code></pre></div><p>The command will download a Docker image for standalone OpenWhisk and it will start it. It will also open the playground, that you can use to create and run a function on the fly from your browser.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/playground-ui.png" alt="Playground"></p><p>Once you have OpenWhisk up and running you can configure the <code>wsk</code> tool to access it. OpenWhisk access is protected by a key that you have to retrieve and use to configure <code>wsk</code>, as follows:</p><div><pre><code data-lang="fallback">AUTH=$(docker exec openwhisk wsk property get --auth | awk '{ print $3}')
wsk property set --auth $AUTH --apihost http://localhost:3233
</code></pre></div><p>Now let’s build our chess engine and use the local OpenWhisk to test it locally. The source code of the chess engine <a href="https://github.com/openwhisk-blog/whisk-chess">is available on GitHub</a>.</p><p>The code is based on a freely available chess engine called <a href="https://github.com/ChizhovVadim/CounterGo/pulls">CounterGo</a>. It is written in Go. I adapted it to run as a stateless serverless action, and I added a frontend in JavaScript, using the libraries <a href="https://chessboardjs.com/">Chessboardjs</a> and <a href="https://github.com/jhlywa/chess.js">chess.js</a>.</p><p>In order to build the action, you need common tools like <code>git</code>, <code>make</code> and <code>docker</code>. Once you have them you can download and build the sources with the commands:</p><div><pre><code data-lang="fallback">git clone https://github.com/openwhisk-blog/whisk-chess
cd whisk-chess
make
</code></pre></div><p>Note that you do not need a Go compiler to build the action, just Docker, as you can compile the action using the OpenWhisk Go runtime itself. The result is the file <code>chess.zip</code> containing a pre-compiled Go action ready to be deployed.</p><p>Once you have the action, you use the following command to deploy it in OpenWhisk:</p><div><pre><code data-lang="fallback">wsk action update chess chess.zip --kind go:1.11 --web true
</code></pre></div><p>Finally you can retrieve the URL of the action with the command:</p><div><pre><code data-lang="fallback">wsk action get chess --url
</code></pre></div><p>If you now type the URL in a browser you will see the user interface of our chess engine, a chessboard, and you can play chess against the computer.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/chess.png" alt="Chess"></p><p>Now let’s start deploying our chess in the services of the various vendors that offer OpenWhisk.</p><p><a href="https://nimbella.com/">Nimbella</a> offers a serverless solution based on OpenWhisk and focused on providing an “awesome developer experience”.</p><p>I think it is appropriate to say that I work for Nimbella, but I am trying to be neutral in this article and offer a fair comparison of all the OpenWhisk vendors I am aware of.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/020.png" alt="Nimbella"></p><p>Nimbella uses its own CLI called <code>nim</code> for deployment. The Nimbella CLI was recently <a href="https://github.com/nimbella/nimbella-cli/">open sourced</a>. You need to sign-up and login to use their service. Once you are logged in, you can deploy our chess action and get an URL for it. The <code>nim login</code> command conveniently permits sign-up.
The CLI is available <a href="https://nimbella.io/downloads/nim/nim.html#install-the-nimbella-command-line-tool-nim">for download</a> for Mac OS, Windows and Linux.</p><div><pre><code data-lang="fallback">nim login
nim action update chess chess.zip --kind go:1.12 --web true
nim action get chess --url
</code></pre></div><p>It is possible to use the <code>wsk</code> CLI with Nimbella if one prefers it. You’ll notice the command is identical here to the one shown earlier but replaced <code>wsk</code> with <code>nim</code>.</p><p><a href="https://apigcp.nimbella.io/api/v1/web/msciabar-zc3thebgxgh/default/chess">Follow this link to play chess on Nimbella</a>.</p><p>The IBM cloud was the original cloud offering OpenWhisk as a service.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/030.png" alt="IBM"></p><p>You need to download and install the <code>ibmcloud</code> CLI in order to deploy actions to IBM. There are also some requirements like downloading a plugin and to target a space; all the steps are explained on their website.</p><p>They offer a generous free tier for running functions. You need to register on their website to use a very large number of function invocations for free.</p><p>Once you downloaded the tool, the commands to deploy the chess engine and get an URL to run the action are:</p><div><pre><code data-lang="fallback">ibmcloud login -u "$IBMUSER" -p "$IBMPASS"
ibmcloud fn action update chess chess.zip --kind go:1.11
ibmcloud fn action get chess --url
</code></pre></div><p><a href="https://eu-de.functions.appdomain.cloud/api/v1/web/a1d40f6b-e5e3-4f07-8f92-77b525392253/default/chess">Follow this link to play Chess on IBM Cloud.</a></p><p>Naver is a Korean company, owner of the main search engine in the Korean language, but also offering cloud services. The Naver Cloud Platform uses OpenWhisk to implement cloud functions.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/040.png" alt="Naver"></p><p>Currently Naver does not offer a CLI to deploy actions, however I was told a CLI is actually under development. For now I deployed the chess action using their web interface.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/041.png" alt="Naver Deploy"></p><p><a href="https://wka9bi13u3.apigw.ntruss.com/chess/chess/ZC2o7bFh0x/http">Follow this link to play Chess on Naver.</a></p><p>Adobe has a serverless offering based on OpenWhisk too. It is called the <a href="https://www.adobe.io/apis/experienceplatform/runtime.html">Adobe I/O Runtime</a>.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/045.png" alt="Adobe I/O"></p><p>Adobe I/O Runtime currently supports only Node.js based runtimes, so if you pick them as your serverless function providers you have to write your serverless functions in JavaScript. However being based on OpenWhisk, it is possible to use other runtimes by request, and so we can also run our chess engine. I thank the team at Adobe for their kind support and help in deploying my action for demonstration purposes.</p><p><a href="https://whisk-chess.adobeioruntime.net/api/v1/web/default/chess">Follow this link to play Chess on Adobe I/O.</a></p><p>Finally, you can run OpenWhisk in any cluster supporting Kubernetes. For this purpose, I created an EKS cluster on AWS and installed OpenWhisk on it, then I deployed my chess application. I will show here how to do that quickly and easily.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/053.png" alt="AWS"></p><p>You will need to create and configure an AWS account. I refer you to AWS documentation for information how to do this.</p><p>Once I created an account, I installed the <a href="https://eksctl.io/"><code>eksctl</code></a> tool that makes easy to create a Kubernetes cluster on AWS.</p><p>Also you need to install the <a href="https://helm.sh/"><code>helm</code></a> deployment tool and use it to actually install OpenWhisk. You can download the helm chart from GitHub and install OpenWhisk as follows:</p><div><pre><code data-lang="fallback">git clone https://github.com/apache/openwhisk-deploy-kube
cd openwhisk-deploy-kube/helm
</code></pre></div><p>Once everything is ready your can create a Kubernetes cluster and install OpenWhisk with just 3 commands:</p><div><pre><code data-lang="fallback">eksctl create cluster --name openwhisk
eksctl create nodegroup --cluster openwhisk --node-labels openwhisk-role=invoker
helm install --set whisk.ingress.type=LoadBalancer openwhisk ./openwhisk
</code></pre></div><p>The cluster creation will take a while. Once it is completed you will get your private OpenWhisk service running in AWS, and you can deploy your chess application to it.</p><p>You can use the <code>wsk</code> or <code>nim</code> CLIs to deploy to OpenWhisk. You have to retrieve the location of the Apache OpenWhisk entry point, and the authorization key and pass them to the CLI tool. The required commands using <code>nim</code> are:</p><div><pre><code data-lang="fallback">cd whisk-chess
APIHOST=$(kubectl  get svc | awk '/openwhisk-nginx/ { print $4}')
AUTH=$(cat openwhisk/values.yaml |  awk '/guest/ { print $2}' | tr -d '"')
nim auth login --apihost http://$APIHOST --auth $AUTH
</code></pre></div><p>It is important to note that we configured an insecure setup because we are accessing OpenWhisk over the unencrypted HTTP protocol.</p><p>In a real world setup you will need additional steps to setup an HTTPS endpoint with a certificate. You will find relevant details in the <a href="https://github.com/apache/openwhisk-deploy-kube">helm chart GitHub repository</a>.</p><p>Once you retrieved the API host and authentication key, you can deploy your chess app, and get the URL.</p><div><pre><code data-lang="fallback">nim action create chess chess.zip --web true --kind go:1.11
nim action get chess --url
</code></pre></div><p>I cannot provide a URL in this case as I a destroyed the cluster after testing, however, you can see the result in the image at the beginning of the paragraph.</p></div></div>]]>
            </description>
            <link>https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662975</guid>
            <pubDate>Fri, 02 Oct 2020 14:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with the NRF52840 in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662934">thread link</a>) | @daschl1
<br/>
October 2, 2020 | https://nitschinger.at/Getting-Started-with-the-nRF52840-in-Rust/ | <a href="https://web.archive.org/web/*/https://nitschinger.at/Getting-Started-with-the-nRF52840-in-Rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>After my <a href="https://nitschinger.at/Rusty-PID-Porting-the-TSic-sensor-from-C-to-Rust">last blog post</a> on the TSIC 306 temperature sensor port to Rust, someone on <a href="https://www.reddit.com/r/rust/comments/j1g4tp/porting_the_tsic_sensor_from_c_to_rust/g720uww/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">Reddit</a> mentioned that it does not provide any guidance on how to get the code samples actually running on the chip.</p>
<p>So this post takes a step back and runs you through the basics of setting up a project, configuring it properly and finally running different examples.</p>
<p>Before we dive in I want to mention that I’m still quite new to the embedded world, so some of the information might not be accurate or misleading. If you run into issues please comment below and I’ll do my best to get them fixed.</p>
<p>Also, I noticed that especially this part of the Rust ecosystem evolves very quickly. So if you read this post some time in 2021 or later, double check the tooling and see if it has been further improved.</p>
<p>The full code can be found in <a href="https://github.com/daschl/nrf52840dk-sample">this repository</a>.</p>

<ul>
<li>Hardware: <a href="https://www.nordicsemi.com/Software-and-Tools/Development-Kits/nRF52840-DK">nRF52840 DK</a></li>
<li>OS: macOS 10.15.6</li>
<li>Rust: 1.46.0 installed through <a href="https://rustup.rs/">rustup</a></li>
</ul>
<p><img src="https://nitschinger.at/img/nrf-without-usb.jpg" alt="nRF Without USB"></p>
<p>For this post I’m using the <a href="https://www.nordicsemi.com/Software-and-Tools/Development-Kits/nRF52840-DK">nRF52840 DK</a> which contains an Arm Cortex-M4 processor with floating point support. The development kit also contains lots of ports and features that you can use to experiment. Check out the <a href="https://www.nordicsemi.com/-/media/Software-and-other-downloads/Product-Briefs/nRF52840-DK-product-brief.pdf">Product Brief</a> for all details.</p>
<p>I first tried to use the <a href="https://en.wikipedia.org/wiki/ESP32">ESP32</a>, but I struggled to get it working properly because you need to use a custom LLVM fork and the tooling isn’t there yet. I picked the nRF52840, because <a href="https://ferrous-systems.com/">ferrous systems</a> were running an embedded workshop using this board and they are so kind as to provide their material <a href="https://embedded-trainings.ferrous-systems.com/">free online</a>. I figured this might be the easiest way to start exploring Rust embedded, and indeed it has been pretty painless.</p>

<p>Since the initial release of the workshop material (which contained lots of custom code to run, log and flash), many of their tools have been extended and found a new home inside the <a href="https://github.com/knurling-rs/">knurling-rs github organization</a>. In particular, we are going to use:</p>
<ul>
<li><a href="https://github.com/knurling-rs/probe-run">probe-run</a>: a custom cargo runner to transparently flash and run our programs.</li>
<li><a href="https://github.com/knurling-rs/defmt">defmt</a>: for easy and efficient logging back to the host.</li>
</ul>
<p>probe-run uses the <a href="https://probe.rs/">probe-rs</a> debugging toolkit underneath which is adding features and support for more targets all the time so you might be able to use a similar process as below for your own board.</p>
<p>The development kit needs to be connected to your computer via USB like shown in the picture below:</p>
<p><img src="https://nitschinger.at/img/nrf-with-usb.jpg" alt="nRF With USB"></p>
<p>It is important to use the USB port on the left and not the one at the bottom, because I think that’s the only port which contains the J-Link debugging probe (which we are going to use to flash and run our code). <a href="https://embedded-trainings.ferrous-systems.com/hardware.html#nrf52840-development-kit-dk">This</a> section in the training material describes it in greater detail.</p>

<p>Note: if you want to cut corners, you can also use the <a href="https://github.com/rust-embedded/cortex-m-quickstart">Cortex-M Template</a>. In this post we’ll start from an empty cargo project and work our way to a flashed device.</p>
<p>Let’s first start with an empty crate:</p>
<pre><code>$ cargo new nrf52840dk-sample --bin
</code></pre><p>Other than just compiling our code fine with <code>rustc</code>, we also need to achieve the following:</p>
<ul>
<li>cross-compile for our embedded target. In our case this is <code>thumbv7em-none-eabihf</code>.</li>
<li>send the compiled code to our target. We’ll use <code>probe-rs</code> for this task through <code>probe-run</code>.</li>
</ul>
<p>To allow us to cross-compile, we need to make sure that <code>rustup</code> has the toolchain needed for our target:</p>
<pre><code>$ rustup target add thumbv7em-none-eabihf
</code></pre><p>Since by default <code>cargo</code> will build for the host platform we are on, we instruct it through a custom <code>.cargo/config.toml</code> that we always want to build for our target platform instead:</p>
<pre><code>[build]
target = "thumbv7em-none-eabihf"
</code></pre><p>Next up, let’s work on our <code>main.rs</code>. Our embedded device does not have a full operating system installed, which means we cannot use the standard library. Also, our entry point into the program is not <code>main</code> because the usual bootstrapping infrastructure is not available.</p>
<p>These two attributes hint it to rust:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="rs"><span>#![no_main]</span>
<span>#![no_std]</span>

<span>fn</span> <span>main</span>() {
    println<span>!</span>(<span>"Hello, world!"</span>);
}
</code></pre></td></tr></tbody></table>
</div>
</div><p>If we try to run this on our host, we’ll see the following:</p>
<pre><code>error: cannot find macro `println` in this scope
 --&gt; src/main.rs:5:5
  |
5 |     println!("Hello, world!");
  |     ^^^^^^^

error: `#[panic_handler]` function required, but not found

error: aborting due to 2 previous errors
error: could not compile `nrf52840dk-sample`.
To learn more, run the command again with --verbose.
</code></pre><p>This tells us two things: first, the <code>println!</code> macro is not available (this is why we are going to use <code>defmt</code> later). Second, we need a panic handler. At this point, things get a bit tricky and we need to bring in our first dependencies (in <code>Cargo.toml</code>):</p>
<pre><code>[dependencies]
cortex-m = "0.6.3"
cortex-m-rt = "0.6.12"
defmt = { git = "https://github.com/knurling-rs/defmt", branch = "main" }
defmt-rtt = { git = "https://github.com/knurling-rs/defmt", branch = "main" }
nrf52840-hal = "0.11.0"
</code></pre><p>The <code>cortex-m</code> and <code>cortex-m-rt</code> crates are our board support crates and provide the hardware abstractions we need in a minute. Since we cannot use println and friends, we include <code>defmt</code> to provide us with a decent logging infrastructure.</p>
<p>Also, to enable <code>defmt</code> logging we need to add these features:</p>
<pre><code>[features]
# set logging levels here
default = [
  "defmt-default",
]

# do NOT modify these features
defmt-default = []
defmt-trace = []
defmt-debug = []
defmt-info = []
defmt-warn = []
defmt-error = []
</code></pre><p>If those are not present, the code will compile but you won’t see log output on the console.</p>
<p>Ok, so now we can rework our <code>main</code> function a little bit:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="rs"><span>#[cortex_m_rt::entry]</span>
<span>fn</span> <span>main</span>() -&gt; <span>!</span> {
    defmt::info<span>!</span>(<span>"Hello, World!"</span>);
    exit();
}
</code></pre></td></tr></tbody></table>
</div>
</div><p>You’ll notice that we switched to <code>defmt</code> for logging, and also use the <code>cortex_m_rt</code> to provide us with an entry function into our program that is compatible with the nRF board.</p>
<p>Finally, we need to set up our panic handler and an <code>exit</code> function. Note that this is a very simplistic version but helps to get us off the ground:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="rs"><span>#[panic_handler]</span>
<span>fn</span> <span>panic</span>(_info: <span>&amp;</span><span>core</span>::panic::PanicInfo) -&gt; <span>!</span> {
    defmt::error<span>!</span>(<span>"panicked"</span>);
    exit()
}

<span>pub</span> <span>fn</span> <span>exit</span>() -&gt; <span>!</span> {
    <span>loop</span> {
        cortex_m::asm::bkpt();
    }
}
</code></pre></td></tr></tbody></table>
</div>
</div><p>A <code>cargo run</code> attempt later, we are much closer:</p>
<pre><code>    Finished dev [unoptimized + debuginfo] target(s) in 0.03s
     Running `target/thumbv7em-none-eabihf/debug/nrf52840dk-sample`
target/thumbv7em-none-eabihf/debug/nrf52840dk-sample: target/thumbv7em-none-eabihf/debug/nrf52840dk-sample: cannot execute binary file
</code></pre><p>We did not get any compile errors, but of course we cannot run an arm executable on our host machine. Time to flash our device!</p>
<p>To do this, we need to install <code>probe-run</code>. For now we need to install it from git because we need the <code>defmt</code> support. At some point in the future I’m sure you can just install it from a stable version:</p>
<pre><code>$ cargo install probe-run --git https://github.com/knurling-rs/probe-run.git --branch main -f --features defmt
</code></pre><p>While this installs, we need to open our <code>.cargo/config.toml</code> file once again and enable the custom cargo runner:</p>
<pre><code>[target.'cfg(all(target_arch = "arm", target_os = "none"))']
runner = "probe-run --chip nRF52840_xxAA  --defmt"
rustflags = [
  "-C", "link-arg=-Tlink.x",
  "-C", "link-arg=-Tdefmt.x",
]

[build]
target = "thumbv7em-none-eabihf"
</code></pre><p>All these properties and flags are from the <code>probe-run</code> docs. If you are using a different chip, I think you can use <code>probe-run --list-chips</code> to find the right one for your device.</p>
<p>At this point we could try to run it, but there are two issues remaining. <code>defmt</code> wouldn’t log anything, and we are lacking our memory layout for the <code>nrf52840</code>.</p>
<p>So, we finally need to add these two lines before our main function:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="rs"><span>use</span> defmt_rtt <span>as</span> _; <span>// global logger
</span><span></span><span>use</span> nrf52840_hal <span>as</span> _; <span>// memory layout
</span></code></pre></td></tr></tbody></table>
</div>
</div><p>Finally, when we now type <code>cargo run</code>, the program gets flashed onto our device successfully:</p>
<pre><code>$ cargo run
   Compiling nrf52840dk-sample v0.1.0 (/Users/daschl/tmp/nrf52840dk-sample)
    Finished dev [unoptimized + debuginfo] target(s) in 0.24s
     Running `probe-run --chip nRF52840_xxAA --defmt target/thumbv7em-none-eabihf/debug/nrf52840dk-sample`
  (HOST) INFO  flashing program
  (HOST) INFO  success!
────────────────────────────────────────────────────────────────────────────────
0.000000 INFO  Hello, World!
└─ nrf52840dk_sample::__cortex_m_rt_main @ src/main.rs:9
stack backtrace:
   0: __bkpt
   1: nrf52840dk_sample::exit
        at src/main.rs:22
   2: nrf52840dk_sample::__cortex_m_rt_main
        at src/main.rs:11
   3: main
        at src/main.rs:7
   4: ResetTrampoline
        at /Users/daschl/.cargo/registry/src/github.com-1ecc6299db9ec823/cortex-m-rt-0.6.13/src/lib.rs:547
   5: Reset
        at /Users/daschl/.cargo/registry/src/github.com-1ecc6299db9ec823/cortex-m-rt-0.6.13/src/lib.rs:550

</code></pre>
<p>With that little victory under our belt, let’s try one more thing: access a peripheral sensor and display its state. In my previous post I used an external sensor, but we can also use a built-in one. The board features a <a href="https://infocenter.nordicsemi.com/index.jsp?topic=%2Fps_nrf52840%2Ftemp.html&amp;cp=3_0_0_5_27">temperature sensor</a> which measures the temperature of the processor.</p>
<p>The first thing we need to add are two more imports for the <code>Peripherals</code> in general and our <code>Temp</code> sensor specifically:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="rs"><span>use</span> nrf52840_hal::pac::Peripherals;
<span>use</span> nrf52840_hal::temp::Temp;
</code></pre></td></tr></tbody></table>
</div>
</div><p>Inside our main function, we first need to take ownership of the <code>Peripherals</code> and then feed the right <code>TEMP</code> peripheral to our struct:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="rs"><span>// Take ownership of the device peripherals
</span><span></span><span>let</span> peripherals <span>=</span> Peripherals::take().unwrap();

<span>// Access to the temp sensor
</span><span></span><span>let</span> <span>mut</span> temp_sensor <span>=</span> Temp::new(peripherals.TEMP);
</code></pre></td></tr></tbody></table>
</div>
</div><p>Now all we need to do is read the temperature from the sensor and convert it to a <code>i32</code> so that <code>defmt</code> can log it for us:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="rs"><span>let</span> die_temp_c: <span>i32</span> <span>=</span> temp_sensor.measure().to_num();
defmt::info<span>!</span>(<span>"processor temp is {:i32}°C"</span>, die_temp_c);
</code></pre></td></tr></tbody></table>
</div>
</div><p>Run your program again and you’ll see something similar to this:</p>
<pre><code>0.000000 INFO  processor temp is 24°C
</code></pre>
<p>We went from an empty repository to a simple program that reads a temperature sensor and prints it onto your host machines terminal. By not using a template we learned to understand the different components that are at play to get us off the ground. Of course, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nitschinger.at/Getting-Started-with-the-nRF52840-in-Rust/">https://nitschinger.at/Getting-Started-with-the-nRF52840-in-Rust/</a></em></p>]]>
            </description>
            <link>https://nitschinger.at/Getting-Started-with-the-nRF52840-in-Rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662934</guid>
            <pubDate>Fri, 02 Oct 2020 14:27:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Probability, Statistics, and Random Processes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662874">thread link</a>) | @b_d98
<br/>
October 2, 2020 | https://www.probabilitycourse.com/preface.php | <a href="https://web.archive.org/web/*/https://www.probabilitycourse.com/preface.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			
			<hr>
						
									
    		
<!-- Section Content -->
<h3>Introduction and Goals</h3>
<p>
For years, I have been joking with my students that I would teach probability with the same level of excitement even if I were woken up in the middle of the night and asked to teach it. Years later, as a new father, I started writing this book when it became clear to me that I would not be sleeping at night for the foreseeable future.
</p>

<p>
This book is intended for undergraduate and first-year graduate-level courses in probability, statistics, and random processes. My goal has been to provide a clear and intuitive approach to these topics while maintaining an acceptable level of mathematical accuracy.
</p>

<p>
I have been teaching two courses on this subject for several years at the University of Massachusetts Amherst. While one of these courses is an undergraduate course taken by juniors, the other is a graduate-level course taken by our first-year Masters and PhD students.
</p>

<p>
My goal throughout this process has been to write a textbook that has the flexibility to be used in <i>both</i> courses while sacrificing neither the quality nor the presentational needs of either course. To achieve such a goal, I have tried to minimize the dependency between different sections of the book. In particular, when a small part from a different section of the book is useful elsewhere within the text, I have repeated said part rather than simply referring to it. My reasoning for doing so is twofold. Firstly, this format should make it easier for students to read the book and, secondly, this format should allow instructors the flexibility to select individual sections from the book more easily.
</p>

<p>
Additionally, I wanted the book to be easy to read and accessible as a self-study reference. It was also imperative that the book be available to anyone in the world, and as such the book in its entirety can be found online at www.probabilitycourse.com.
</p>

<p>
The book contains a large number of solved exercises. In addition to the examples found within the text, there is a set of solved problems at the end of each section. Detailed and step-by-step solutions to these problems are provided to help students learn problem-solving techniques. The solutions to the end-of-chapter problems, however, are available only to instructors.
</p>

<p>
Lastly, throughout the book, some examples of applications$-$such as engineering, finance, everyday life, etc.$-$are provided to aid in motivating the subject. These examples have been worded to be understandable to all students. As such, some technical issues have been left out.
</p>

<h3>Coverage</h3><p>

After a brief review of set theory and other required mathematical concepts, the text covers topics as follows:
</p><ul>
  <li> Chapters 1 and 2: basic concepts such as random experiments, probability axioms, conditional probability, law of total probability, Bayes' rule, and counting methods;</li>
  <li> Chapters 3 through 6: single and multiple random variables (discrete, continuous, and mixed), as well as moment-generating functions, characteristics functions, random vectors, and inequalities;</li>
  <li> Chapter 7: limit theorems and convergence;</li>
  <li> Chapters 8 and 9: Bayesian and classical statistics;</li>
  <li> Chapters 10: Introduction to random processes, processing of random signals;</li>
  <li> Chapter 11: Poisson processes, discrete-time Markov chains, continuous-time Markov chains, and Brownian motion;</li>
  <li> Chapter 12: basic methods of generating random variables and simulating probabilistic systems (using MATLAB);</li>
  <li> Chapter 13: basic methods of generating random variables and simulating probabilistic systems (using R);</li>
  <li> Chapter 14: recursive methods;</li>
</ul>
<p>
All chapters are available at <a href="http://www.probabilitycourse.com/">www.probabilitycourse.com</a>. Chapters 12 through 14 are available as PDFs and are downloadable from the textbook website. Chapters 12 and 13 cover the same material. The difference is that the codes in chapter 12 are provided in MATLAB while the codes in Chapter 13 are provided in R. The reason for this again is to give flexibility to instructors and students to choose whichever they prefer. Nevertheless, students who are unfamiliar with MATLAB and R should still be able to understand the algorithms.
</p>

<h3>Required Background</h3><p>
The majority of the text does not require any previous knowledge apart from a one-semester course in calculus. The exceptions to this statement are as follows:
</p><ul>
  <li> Sections 5.2 (Two Continuous Random Variables) and 6.1 (Methods for More Than Two Random Variables) both require a light introduction to double integrals and partial derivatives;</li>
  <li> Section 6.1.5 (Random Vectors) uses a few concepts from linear algebra;</li>
  <li> Section 10.2 (Processing of Random Signals) requires familiarity with the Fourier transform.</li>
</ul>

<h3>Acknowledgements</h3>
<p>
This project grew out of my educational activities regarding my National Science Foundation CAREER award. I am very thankful to the people in charge of the Open Education Initiative at the University of Massachusetts Amherst. In particular, I am indebted to Charlotte Roh and Marilyn Billings at the UMass Amherst library for all of their help and support.
</p>
<p>
I am grateful to my colleagues Dennis Goeckel and Patrick Kelly, who generously provided their lecture notes to me when I first joined UMass. These notes proved to be very useful in developing my course materials and, eventually, in writing this book. I am also thankful to Mario Parente$-$who used an early version of this book in his course$-$for very useful discussions.
</p>
<p>
Many people provided comments and suggestions. I would like to especially thank Hamid Saeedi for reading the manuscript in its entirety and providing very valuable comments. I am indebted to Evan Ray and Michael Miller for their helpful comments and suggestions, as well as to Eliza Mitchell and Linnea Duley for their detailed review and comments. I am thankful to Alexandra Saracino for her help regarding the figures and illustrations in this book. I would also like to thank Ali Rakhshan, who coauthored the chapter on simulation and who, along with Ali Eslami, helped me with my LaTeX problems. I am grateful to Sofya Vorotnikova, Stephen Donahue, Andrey Smirnov, and Elnaz Jedari Fathi for their help with the website. I am thankful to Atiyeh Sakaei-Far for managing the development of the website and its maintenance. I would also like to thank Elnaz Jedari Fathi for designing the book cover.
</p>
<p>
I am indebted to all of my students in my classes, who not only encouraged me with their positive feedback to continue this project, but who also found many typographical errors in the early versions of this book. I am thankful to all of my teaching assistants who helped in various aspects of both the course and the book.
</p>
<p>
Last$-$but certainly not least$-$I would like to thank my family for their patience and support.
</p>

					
		</div></div>]]>
            </description>
            <link>https://www.probabilitycourse.com/preface.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662874</guid>
            <pubDate>Fri, 02 Oct 2020 14:21:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boa: an experimental Javascript lexer, parser and compiler written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24662756">thread link</a>) | @jayflux
<br/>
October 2, 2020 | https://boa-dev.github.io/2020/10/02/boa-release-10.html | <a href="https://web.archive.org/web/*/https://boa-dev.github.io/2020/10/02/boa-release-10.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Boa is an experimental Javascript lexer, parser and compiler written in Rust. It has support for some of the language, can be embedded in Rust projects fairly easily and also used from the command line.
Boa also exists to serve as a Rust implementation of the EcmaScript specification, there will be areas where we can utilise Rust and its fantastic ecosystem to make a fast, concurrent and safe engine.</p>

<p>We have a long way to go, however v0.10 has been the biggest release to date, with 138 issues closed!</p>

<p>We have some highlights, but if you prefer to read the full changelog, you can do that <a href="https://github.com/boa-dev/boa/blob/master/CHANGELOG.md">here</a></p>

<h2 id="test262">Test262</h2>

<p>One question we’ve been asked for a long time is “how conformant are you to the spec?”. It’s been tough to answer as we’ve been unable to run against the official test suite.</p>

<p>Test262 is the official ECMAScript Test Suite and exists to provide conformance tests for the latest drafts of the Ecma specification. It is used for all engines, you can even run it in your <a href="https://bakkot.github.io/test262-web-runner/">browser</a>.<br>
Thanks to @Razican in v0.10 we now have a test harness that allows us to run it against Boa at any time.</p>

<p>This is a new crate inside the Boa repository that can parse through all of the tests (roughly 40,000 of them) in under 10 minutes and tell us how conformant we are.</p>

<p><img src="https://boa-dev.github.io/images/2020-10-02/test262-screenshot.png" alt="image"></p>

<p>Today Boa has <span>18</span>% conformity to the specification. We’ll be keeping an eye on this number over the releases. We expect to achieve around 30% by 0.11 due to some of the fixes we’re adding which should pass a few thousand tests.</p>

<p>These are run via Github Actions against PRs and for our master branch so that we can keep track of where we are and if there are regressions.</p>

<h2 id="built-ins">Built-ins</h2>

<p>We’ve added support for <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date"><code>Date</code></a>, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map"><code>Map</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol">well-known symbols</a>. Supporting Well-known symbols unblocks a lot of work around adding <code>@@iterators</code> to some of our global objects which is coming up in the next release.<br>
Both <code>Math</code> and <code>Number</code> have had their remaining methods implemented.</p>

<h2 id="lexer">Lexer</h2>

<p>The lexer has been rebuilt from scratch. Just like the old parser it was a single file before looping through and becoming unmaintainable. Today we’ve reorganised it into separate modules which know how to lex certain areas. The new lexer <a href="https://github.com/boa-dev/boa/issues/294">now supports goal symbols</a> and can now tokenize with the correct context at any time.</p>

<h3 id="goal-symbols">Goal Symbols</h3>

<p>Our issue with goal symbols is explained by the V8 team:
<a href="https://v8.dev/blog/understanding-ecmascript-part-3#lexical-grammar">https://v8.dev/blog/understanding-ecmascript-part-3#lexical-grammar</a></p>

<p>Previously we weren’t distinguishing between the contexts where some input elements are permitted and some are not, so lexing <code>/</code> would yeild a <code>division</code> symbols when it should be a <code>RegularExpressionLiteral</code> for example. This change unblocked us being able to run Test262.</p>

<p>Performance wise it is much faster for larger files. The lexer is far more efficient at streaming tokens to the parser than previously so in some scenarios we have big gains.</p>

<p><em>You can see all the benchmarks <a href="https://boa-dev.github.io/boa/dev/bench/">here</a></em></p>

<h2 id="repl-syntax-highlighting">Repl syntax highlighting</h2>

<p>Syntax highlighting was added to the repl this release thanks to @HalidOdat<br>
Our repl is made possible due to the great work of <a href="https://github.com/kkawakam/rustyline">RustyLine</a></p>

<p><img src="https://boa-dev.github.io/images/2020-10-02/syntaxHighlighting.gif" alt="image"></p>

<h2 id="looking-forward">Looking forward</h2>

<p>There are plenty of fixes and performance changes still needed, we also hope to experiment with producing Bytecode from our AST in future. Test262 coverage will almost certainly increase, and we are polishing the public API for easier use when embedding into other Rust projects.</p>

<p>Thanks to all those who contributed to 0.10, you can see the names in the full changelog linked above.</p>

<p>You can checkout Boa via <a href="https://github.com/boa-dev/boa">Github</a> or on <a href="https://crates.io/crates/Boa">crates.io</a></p>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://boa-dev.github.io/2020/10/02/boa-release-10.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662756</guid>
            <pubDate>Fri, 02 Oct 2020 14:09:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You’re not dumb, you’re learning at the wrong level]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662743">thread link</a>) | @windy-topology
<br/>
October 2, 2020 | https://www.lifetechpsych.com/learn-code-efficiently/ | <a href="https://web.archive.org/web/*/https://www.lifetechpsych.com/learn-code-efficiently/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="8"><p>What’s your idea of learning to code? </p>
<p>Whip out your computer, type out a couple of cool commands. And bam - beauty personified. </p>
<p>Sorry, nope.</p>
<p>The process is at least 50% struggling especially at the beginning. </p>
<p>And that’s how it should be. </p>
<p>
  <a href="https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-1a9e3.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Image of loving to learn" title="" src="https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-f8fb9.jpg" srcset="https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-e8976.jpg 148w,
https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-63df2.jpg 295w,
https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-f8fb9.jpg 590w,
https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-85e3d.jpg 885w,
https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-d1924.jpg 1180w,
https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-9452e.jpg 1770w,
https://www.lifetechpsych.com/static/love-to-learn-e894c2f1581e06bed85279bd69683e3b-1a9e3.jpg 9000w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; <em>Photo by <a href="https://unsplash.com/@timmossholder">Tim Mossholder</a> on <a href="https://unsplash.com/">Unsplash</a></em></p>
<p>I’ve seen people quit programming because they don’t want to struggle with bugs. That’s like hating the gym because you don’t want workouts to hurt.</p>
<h2>Learn to see the struggle as the way.</h2>
<p>You don’t run from bugs; you train yourself to find them quicker. </p>
<p><strong>A proficient programmer is an efficient detective of bugs.</strong></p>
<p>If you’re feeling frustrated that things are not smooth, remember that this is how learning actually works. </p>
<p>Neuroscience research confirms that practice doesn’t simply make you perfect; it is deliberate practice to improve in a specific task that makes you better. And deliberate practice involves struggling.</p>
<p>So your mantra should be:</p>
<ul>
<li>You code. </li>
<li>You debug.</li>
<li>You struggle. </li>
<li>You overcome. </li>
<li>And you repeat.</li>
</ul>
<p>If you’ve not struggled at all, you’re simply playing around. </p>
<p>If you struggle all the time, then the next section is for you.</p>
<h2>You’re not dumb, you’re learning at the wrong level.</h2>
<p>Let’s start with a little analogy. </p>
<p>Imagine learning the English language (the language of exceptions).</p>
<p>You start with a tutorial motivating you to learn to spell big words like <em>ELEPHANT</em>.</p>
<p>But it’s not working. After beating yourself for so long you decide to go to a lower tutorial and learn to spell smaller words like <em>ANT</em>.</p>
<p>But you still struggle.</p>
<p>So you conclude that you’re dumb because you lowered your tutorial level and still didn’t grasp anything.</p>
<p>But when a new teacher investigates why you’re struggling, they find out that you’ve been struggling because you actually don’t know the English alphabets.</p>
<p>Let’s bring this home to our coding world.</p>
<p>Some people jump into beginner tutorials to learn frameworks like <em>React (ELEPHANT)</em>. Then realize it makes no sense so they move on to learn <em>JavaScript (ANT)</em>. But that still makes no sense to them, so they quit.</p>
<p>But they’re simply working with something that’s too advanced.</p>
<p>Even introduction courses can be advanced because your thinking is not wired yet to programming in general. </p>
<p>There’s no shame in finding something lower than Intro courses and starting from there to build up to Intro courses. </p>
<p>I don’t see this recommended enough but if you’re struggling with intro courses, you should consider Intro to programming for kids. </p>
<p>Learn with tools like:</p>
<ul>
<li>Alice </li>
<li>Scratch</li>
<li>Codewars.</li>
</ul>
<p>Since you’re older, you’ll go through them faster. But they’ll give you the much needed soft intro that makes sense and builds your appetite.</p>
<p>Again, this has nothing to do with ego. </p>
<p><strong>It’s your learning journey.</strong></p>
<p>If you learn the alphabets first, you’ll gain the confidence needed to start spelling <em>ANT</em>, <em>ELEPHANT</em>, and later constructing long-winded sentences. </p>
<p>It doesn’t matter what discipline or area of coding you jump into, this holds for <em>Intro to Python</em> as much as it holds for <em>Intro to Machine Learning</em>.</p>
<p>You’ll learn more efficiently if you learn at the right level. </p>
<h2>Elevate how you learn with spaced repetition.</h2>
<p>This technique is from research in Neuroscience. And I’ll summarize it short and quick.</p>
<h3>How it works:</h3>
<ul>
<li>You learn.</li>
<li>Recall in 48 hours.</li>
<li>Then review in 72 hours. </li>
</ul>
<h3>Doing this:</h3>
<ul>
<li>You’ll forget less.</li>
<li>Connect new ideas to old; and</li>
<li>Retain more in long term memory.</li>
</ul>
<p>I put 48 and 72 hours but you can expand that timeline to days and weeks. The most important takeaway is not to simply learn once. But to intentionally set aside time for you to come back and review. </p>
<p>The longer the delay between reviews, the more it gets buried in long-term memory.</p>
<ul>
<li>Duolingo uses it.</li>
<li>Quizlet adopted it.</li>
<li>You can also apply it.</li>
</ul>
<h2>1 project &gt; 10 hello worlds</h2>
<p>Don’t get caught up in <code>hello worlds</code> forever.</p>
<p>I understand the thrill of completing simple exercises:</p>
<div>
      <pre><code># OMG - I can print all day
print “I am awesome”.
print “You’re cool”. 
print “Wait, are we cool?” </code></pre>
      </div>
<p>But I have to be honest with you, this won’t cut it.</p>
<p>Going back to our ANT analogy, no matter how many ways you rearrange the words ANT, you’ll never arrive at ELEPHANT. </p>
<p>No matter how many Intro tutorials you learn, you’ll never really get past the basics unless you push yourself beyond that. </p>
<blockquote>
<p>“<em>But I don’t know what projects to start as a beginner.</em>”</p>
</blockquote>
<p>No worries. Here are two examples:</p>
<ul>
<li>
<p>Random Password Generator: Creating a program that intakes some words from the user and then generates a random password using those words. </p>
</li>
<li>
<p>Currency converter: Create a program that converts currencies from one unit to another, for example, converting Indian rupee into dollars, pound to euros, etc.</p>
</li>
<li>
<p>If you find these boring, here are <a href="https://www.upgrad.com/blog/python-projects-ideas-topics-beginners/">40 other ideas to choose from.</a></p>
</li>
<li>
<p>And if all of them seem too difficult, <a href="https://twitter.com/LifeTechPsych">DM me on Twitter</a> and I’ll create something specifically for you to start with. Remember, this is not about ego; it’s about your learning level and growth.</p>
</li>
</ul>
<h2>Motivation is like taking a hot shower.</h2>
<p>Taking a hot shower feels good - you should do it.</p>
<p>But if your hot water is out for 2 weeks, would you not shower?</p>
<p>The question sounds ridiculous but in the same way, you really shouldn’t base your learning on only days when you’re motivated. </p>
<p>There are lots of exciting days in coding; but there will also be dark, unmotivating days. </p>
<p>Honestly, this is not just with coding. It’s with life and embarking on any new adventure. But you have to train yourself to show up not only when you’re feeling hyper inspirational but also on low, boring days.</p>
<p>This doesn’t mean forget motivation.
Far from it - on days when you feel super motivated, use your motivation to quickly commit yourself to something big that will keep you accountable when the motivation goes dry.</p>
<h4>How? Join an accountability movement like:</h4>
<ul>
<li>30daysofcode</li>
<li>100DaysOfCode</li>
<li>30DaysOfCodingChallenge</li>
</ul>
<p>Something. Anything. To keep you accountable on slow days. </p>
<p>In Behavioral Psychology, this is known as pre-commitment. You use moments when you’re optimistic to commit yourself in the future for when you have zero optimism.</p>
<h2>The journey of learning is never-ending.</h2>
<p>No one teaches you how to learn. </p>
<p>But it’s crucial in going far.</p>
<p>You may have started with the idea of simply learning to code or to one day become a developer. But there’s more.</p>
<p>
  <a href="https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-a3afe.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Image saying you came far" title="" src="https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-f8fb9.jpg" srcset="https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-e8976.jpg 148w,
https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-63df2.jpg 295w,
https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-f8fb9.jpg 590w,
https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-85e3d.jpg 885w,
https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-d1924.jpg 1180w,
https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-9452e.jpg 1770w,
https://www.lifetechpsych.com/static/came-this-far-66906f1fa856aa44bd7a26df588b182b-a3afe.jpg 5355w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    
&nbsp; &nbsp; <em>Photo by <a href="https://unsplash.com/@drewbeamer">Drew Beamer</a> on <a href="https://unsplash.com/">Unsplash</a></em></p>
<p>When you come out on the other side, you’ll come out not just a coder.</p>
<p>But as a renewed person because you’ve picked up a new way of learning and approaching things.</p>
<p>Don’t get me wrong. This isn’t easy peasy lemon squeezy – you’ll work like hell. </p>
<p>But in the end, it’ll be worth it not just because of coding but because of the joy of transforming yourself.</p>
<p>Remember, the ball’s always in your court…</p>
<h2>Thanks for reading.</h2>
<p>If you enjoyed this and you’re on Twitter, <a href="https://twitter.com/LifeTechPsych/status/1311338563884257280">like and retweet this</a> to help spread the word. I know it sounds trivial but it actually really helps.</p>
<p>I’m trying out a new initiative to help new coders and junior devs feel less overwhelmed, manage imposter syndrome and learn smarter. </p>
<p>To be honest, I’m not sure what the entire process looks like yet. But I’m going with the flow and putting together resources and write-ups based on what people need the most help with.</p>
<p><strong>If you’re interested, <a href="https://ctt.ac/I1f33">let me know on Twitter</a>. If you prefer sending a direct message, <a href="https://twitter.com/LifeTechPsych">my DM is open.</a></strong></p>
<p><em>Heads Up</em> - I love research so I tend to back my advice and approach with concepts from Behavioral Psychology and Neuroscience.</p></div></div>]]>
            </description>
            <link>https://www.lifetechpsych.com/learn-code-efficiently/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662743</guid>
            <pubDate>Fri, 02 Oct 2020 14:08:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Guide to Japanese "The Mental Model" [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662726">thread link</a>) | @sova
<br/>
October 2, 2020 | https://japanesecomplete.com/guide | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-wrapper">

			<!-- Header -->
				

			<!-- Content -->
				<section id="content">
					<div>
						<div>
							<div>

								<!-- Left Sidebar -->
									<section>
										<header>
											<h2>Japanese Complete presents</h2>
											<h3>Essential Japanese</h3>
											<h4>Provided free of charge to language learners.</h4>
										</header>
										
										<p>English Sentence Structure</p>
										<p>Japanese Sentence Structure</p>
										<ul><li>Topic</li>
											   <li>Subject</li>
											   <li>Direct-Object</li>
											   <li>Verb</li></ul>
										<p>Particles</p>
										<ul><li>Query Particles</li>
											<li>Elaborative Particles</li></ul>
										<p>Bunsetsu Jars</p>
										<p>Nouns and Verbs</p>
										<p>Sentence-Final Fitters</p>
										<p>Addressing People</p>
										<p>Four Types of Kanji</p>
										</section>
							</div>
							<div>

								<!-- Main Content -->
										<section>
											
											<iframe width="500" height="315" src="https://www.youtube.com/embed/8JLasdP65bY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
											<hr>
										<header>
											<a href="https://learnjapanesebest.files.wordpress.com/2020/02/essential_japanese_mental_model_f1r2.pdf">
											<img id="guideimg" src="https://japanesecomplete.com/img/ejc.jpg">	
											<span>[pdf]</span> Essential Japanese: The Mental Model →</a>
											
										</header>
										<p>Essential Japanese: The Mental Model is a guide offered with kindness from Japanese Complete.  Learn the language with the clearest guide available as of 2020. Plus, it's free.</p>
										<p>If you find it useful, share it with a friend. </p><p> It would mean a lot to us if you would tell a friend about Japanese Complete.  We're adding exciting tools and materials with great vigor.</p>

										<p>Learn more about the cutting-edge interactive learning solution, <a href="https://japanesecomplete.com/">Japanese Complete</a></p>
















										</section>



							</div>
							<div>

								<!-- Right Sidebar -->
									<section>
										<header>
											<h2>Master the Elements of Grammar</h2>
										</header>
										<p>Japanese Particles are what make Japanese unique as a language. When we study Japanese (or Korean for that matter) having a solid understanding of how particles are incorporated and used to reflect and express states of the mind is crucial.</p>
										<p>Japanese Complete focuses on a "Particles First" approach that teaches all the grammatical particles first. This unconventional technique actually enables the most accelerated learning in Japanese ever, because by frequency, particles are the most frequent glyphs of the language.</p>
										<ul>
											<li>Master Japanese Swiftly.</li>
											<li>Retain What you Learn.</li>
											<li>Go All The Way.™</li>	
										</ul>
									</section>
									<section>
										<header>
											<h2>Get Access to the Ninja Training Grounds.</h2>
										</header>
										<p>
											What sets Japanese Complete apart is not just exceptional lessons, but the training grounds. Practice what you learned right away and get your accuracy up and beyond with excellent drills designed to jog with you all the way to fluency.
										</p>
									</section>
									<section>
										<header>
											<h2>Translator-Grade Materials</h2>
										</header>
									<p>Crafted by Translators for Translators, Japanese Complete offers insights into language learning that are simply unavailable elsewhere.</p>
								</section>
							</div>
						</div>
					</div>
				</section>

			<!-- Footer -->
				

			<!-- Copyright -->
				<p>
					© Japanese Complete 2020. All rights reserved.
				</p>

		</div></div>]]>
            </description>
            <link>https://japanesecomplete.com/guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662726</guid>
            <pubDate>Fri, 02 Oct 2020 14:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective Ways to Market Yourself as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24662671">thread link</a>) | @codersrank
<br/>
October 2, 2020 | https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/ | <a href="https://web.archive.org/web/*/https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>Knowing Javascript inside and out or all the programming languages in the world won’t be enough to help you land a great job that pays incredibly well or secure those amazing opportunities that are hard to come by.</p>



<p>If you want to truly advance your career and succeed as a developer, you need to market yourself. Sure, coding is your passion and you’d rather bury yourself in it, but how would anyone know that you’re good at what you do or even discover you unless you put yourself out there?</p>



<p>When screening for developer positions, many companies pay attention to candidates who have active <a href="https://blog.codersrank.io/profile-2-0/" target="_blank" rel="noreferrer noopener">programmer profiles</a>—a blog, podcast, open-source contributions, YouTube channel, or a history of speaking at tech events—that speaks to their abilities. They view developers with these achievements and experiences as more likely to be talented because their reputation suggests it.</p>



<p><a href="https://giphy.com/gifs/the-office-michael-scott-5B6PQ4lDOlbB6">via GIPHY</a></p>



<p>A little marketing can help you shine brightly in the eyes of potential employers. The last thing you want is to be just another candidate or resume when applying for a job. You need to find a way to stand out from the other stack of papers so that companies are pushed to invite you for an interview or make you an offer.</p>



<p>With effective marketing, you may not even have to go job hunting, opportunities will come knocking at your door. When you share your goals, skills, experiences, and knowledge about your field publicly, it helps to establish you as an expert. As such, companies will be happy to pay you a premium salary rather than hiring one of your seemingly less qualified counterparts.</p>



<p>Now that you understand how important marketing is and how it can enhance your reputation and turn you into a job magnet, we’re going to walk you through actionable steps you can take to successfully market yourself as a developer, stand out from the competition, get on recruiters’ radars, and bag the job offer of your dreams.</p>



<p>We have ranked these steps according to how useful and important they can be in helping you market yourself and your skills effectively.</p>







<ol><li><a href="#portfolio">Build your portfolio</a></li><li><a href="#brand">Build a personal brand</a></li><li><a href="#codersrank">Register a profile on CodersRank</a></li><li><a href="#network">Network with fellow tech professionals</a></li><li><a href="#linkedin">Tidy up your LinkedIn profile</a></li></ol>



<p>Following these steps will help you enlarge your horizons and place your best foot forward so life-changing opportunities can find you. While other developers are scrambling to submit resumes and nail their technical interviews, you’ll already be far ahead.</p>



<p>Let’s take an in-depth look into each of these steps and how you can use them to enhance your career as a software developer and go from chasing after the prize to becoming the prize.</p>



<h2 id="portfolio" data-amp-original-style="color:#50b0ba"><strong>1. Build your portfolio</strong></h2>



<p>As a developer, you know that you need to keep practicing and refining your skills. What you might not know is that you can use the assignments and projects you do to create a portfolio that showcases your expertise.</p>



<p>If you don’t already have a GitHub profile, start by creating one and start pushing code to it regularly, and make your experiments public. This is non-negotiable. GitHub is your <a href="https://blog.codersrank.io/the-evolution-of-the-most-popular-repositories-since-2012/" target="_blank" rel="noreferrer noopener">code repository</a> and it should be used to display all the code you’ve written, projects you’ve worked on, and other interesting code-related activities you’ve been involved in.</p>



<p>Your GitHub account is basically your developer resume because it serves as proof of how well you can code. It says more about your skills than any CV or interview can. Contribute to as many open source libraries as you can. The more open source contributions you have the greater the value prospective employers will see in hiring you.</p>



<p>If you’d like to make valuable contributions to open source libraries, but you’re not sure how to go about submitting one, finding projects to contribute to, or even what kind of contributions you can make, check out these resources:</p>



<ul><li><a href="https://opensource.guide/how-to-contribute/" target="_blank" rel="noreferrer noopener">How to contribute to open source</a></li><li><a href="https://auth0.com/blog/a-first-timers-guide-to-an-open-source-project/" target="_blank" rel="noreferrer noopener">A first timer’s guide to an open source project</a></li><li><a href="https://rubygarage.org/blog/how-contribute-to-open-source-projects" target="_blank" rel="noreferrer noopener">How to contribute to open source projects</a></li></ul>



<p>It’s also important to have a portfolio website where potential employers can go to learn more about you, the work you’ve done, and how your skills and experience can benefit their organization.</p>



<p>When building your portfolio, here are the things you’ll want to pay attention to:</p>



<h3>Set up a professional site</h3>



<p>It makes sense for your domain to be in your name since this is a personal portfolio and people should be able to find it by simply entering your name into a search engine. Make sure you purchase the domain so that you can have full control over it and be able to migrate to a different web platform.</p>



<p>You cannot expect employers to take you seriously if you proclaim yourself to be a talented developer, but your website looks shabby and amateurish. You want anyone who stumbles on your site to be immediately impressed by the layout and design even before they go through any of your pages.</p>



<figure><amp-img src="https://file.mockplus.com/image/2019/07/75f1f76e-eeb4-4166-8cf1-3500d6256538.png" alt="" object-fit="contain" width="1170" height="400" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://file.mockplus.com/image/2019/07/75f1f76e-eeb4-4166-8cf1-3500d6256538.png" alt="" width="1170" height="400" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQwMCcgd2lkdGg9JzExNzAnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption><a href="https://www.mockplus.com/blog/post/web-developer-portfolio" target="_blank" rel="noreferrer noopener">Source</a></figcaption></figure>



<p>Your site should be easy to navigate and visually pleasing. You can decide to code your website from scratch and display it as one of the projects in your portfolio or create one using your preferred web platform. Whatever you choose, remember to keep it simple.</p>



<p>Include a well-designed logo that communicates your values and serves as an accurate representation of who you are and what you do.</p>



<p>Keep in mind that a <strong>personal website is going to mean different things to a back end developer and a front end developer</strong> since they’re different fields. Whichever faction you belong to, you just need to find an approach to your website design and presentation that best represents who you are and what you do.</p>



<p>If you’re a newbie developer, this <a href="https://mikkegoes.com/portfolio-site-on-wordpress/" target="_blank" rel="noreferrer noopener">detailed step-by-step guide</a> will help you build a great-looking portfolio website from scratch to showcase your skills and value to potential employers and help you get hired faster. It covers everything from registering a domain name to choosing a reliable website, creating eye-catching home and about me pages, building contact forms, and more.</p>



<p>Check out these <a href="https://www.springboard.com/blog/programmer-portfolio/" target="_blank" rel="noreferrer noopener">7 best practices for creating a programming portfolio website</a> that stands out. The article also contains tips on mistakes to avoid when building your website and what recruiters look for in a developer portfolio, as well as stunning website examples that are sure to get your creativity flowing.</p>



<h3>Showcase your work</h3>



<p><a href="https://giphy.com/gifs/kodewithklossy-coding-karlie-kloss-kwk-ZG719ozZxGuThHBckn">via GIPHY</a></p>



<p>The point of having an online portfolio is to highlight the work you’ve done in the past and the accomplishments you’re proud of. If you don’t have any concrete work experience yet, you can start by creating a single web page and adding links to other online profiles you have like your social media and GitHub account.</p>



<p>When you write articles, host webinars, give talks, contribute to open source libraries, create tutorial videos, or work on anything interesting, update your site accordingly. Explain what each project is about, why it’s important, and when it was done.</p>



<p>Don’t just go on and on about the agile methodologies, frameworks, and programming languages that you know. Display that project you built using Javascript, PHP, CSS, or whatever tech stacks you say you’re familiar with. </p>



<p>Let visitors see the skills you possess in action and how you can use these skills to grow their business. This will establish your expertise, credibility, and trustworthiness.</p>



<h3>Share your story</h3>



<p>Don’t be shy about being yourself. Let your personality shine through. Describe yourself as honestly as you can. What is it that makes you special? What struggles, failures, or challenges have you encountered over the course of your career? Employers don’t want to hire mindless code monkeys, but people they can relate to.</p>



<h3>Include your contact details</h3>



<p>Give visitors and potential employers a way to reach you. Add your email address and phone number or create a simple contact form they can fill out. If they have to jump through hoops to find your contact information, you might miss out on many good opportunities.</p>



<h2 id="brand" data-amp-original-style="color:#50b0ba"><strong>2. Build a personal brand</strong></h2>



<p>Personal branding is simply a way of making yourself known for something. As a programmer, you not only want to be competent in your field, you also want people to see you that way. Thanks to the internet, it’s easier than ever to create a brand around yourself.</p>



<p>Ask yourself what you want to be known for? Who are you and what do you want to represent? What is your core message? What do you want people to think of when they see or hear your name? Once you have this figured out, start putting this message out there and making sure it’s reflected in everything you do.</p>



<p>Here are some of the ways you can create a strong personal brand and actively promote yourself:</p>



<h3>Clean up assets related to communication</h3>



<p>Come up with a logo for your brand if you don’t already have one. It should be something simple, eye-catching, and an accurate representation of who you are and what you’re about. Don’t go changing your logo every week or so. Find one that works for you and use it everywhere.</p>



<p>Get professional headshots taken to use as cover images for your online profiles. Go through your social media accounts and public forums and delete any inappropriate messages or comments that don’t align with the image you want to project or reflect badly on you as a person.</p>



<h3>Start a blog</h3>



<p>A blog can be a wonderful way to showcase your skills as a developer, become well-known in your industry, and attract potential clients or employers.</p>



<p>Your blog doesn’t have to have tens of thousands of readers, but you do need to build a decent audience. You can do this by sharing useful information that adds some kind of value to your readers’ lives. Talk about your professional journey, the challenges you’ve faced along the way, and how you overcame them.</p>



<p>Teach people how to solve problems. Show examples of work you’ve done in the past to help junior developers find their way and build themselves up. Think of something you’ve struggled with that you found a solution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/">https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/</a></em></p>]]>
            </description>
            <link>https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662671</guid>
            <pubDate>Fri, 02 Oct 2020 14:00:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust lets us monitor 30k API calls/min]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662530">thread link</a>) | @jerodsanto
<br/>
October 2, 2020 | https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/ | <a href="https://web.archive.org/web/*/https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p>At Bearer, we are a polyglot engineering team. Both in spoken languages and programming languages. Our stack is made up of services written in Node.js, Ruby, Elixir, and a handful of others in addition to all the languages our agent library supports. Like most teams, we balance using the right tool for the job with using the right tool for the time. Recently, we reached a limitation in one of our services that led us to transition that service from Node.js to Rust. This post goes into some of the details that caused the need to change languages, as well as some of the decisions we made along the way.</p><h2 id="a-bit-of-context"><strong>A bit of context</strong></h2><p>We are building a solution to help developers monitor their APIs. Every time a customer’s application calls an API, a log gets sent to us where we monitor and analyze it.</p><p>At the time of the issue, we were processing an average of 30k API calls per minute. That's a lot of API calls made across all our customers. We split the process into two key parts: Log ingestion and log processing.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion-service---node.jpg" alt="Original architecture with Node.js" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion-service---node.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion-service---node.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion-service---node.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion-service---node.jpg 2400w"></figure><p>We originally built the ingestion service in Node.js. It would receive the logs, communicate with an elixir service to check customer access rights, check rate limits using Redis, and then send the log to CloudWatch. There, it would trigger an event to tell our processing worker to take over.</p><p>We capture information about the API call, including the payloads (both the request and response) of every call sent from a user's application. These are currently limited to 1MB, but that is still a large amount of data to process. We send and process everything asynchronously and the goal is to make the information available to the end-user as fast as possible.</p><p>We hosted everything on AWS Fargate, a serverless management solution for Elastic Container Service (ECS), and set it to autoscale after 4000 req/min. Everything was great! Then, the invoice came 😱.</p><p>AWS invoices based on CloudWatch storage. The more you store, the more you pay.</p><p>Fortunately, we had a backup plan.</p><h2 id="kinesis-to-the-rescue"><strong>Kinesis to the rescue?</strong></h2><p>Instead of sending the logs to CloudWatch, we would use<a href="https://aws.amazon.com/kinesis/data-firehose/"> Kinesis Firehose</a>. Kinesis Firehose is basically a Kafka equivalent provided by AWS. It allows us to deliver a data stream in a reliable way to several destinations. With very few updates to our log processing worker, we were able to ingest logs from both CloudWatch and Kinesis Firehose. With this change, daily costs would drop to about 0.6% of what they were before.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---node_kinesis.jpg" alt="Architecture after adding Kenesis" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---node_kinesis.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---node_kinesis.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---node_kinesis.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---node_kinesis.jpg 2400w"></figure><p>The updated service now passed the log data through Kinesis and into s3 which triggers the worker to take over with the processing task. We rolled the change out and everything was back to normal... or we thought. Soon after, we started to notice some anomalies on our monitoring dashboard.</p><p><strong>We were Garbage Collecting</strong>, a lot. Garbage collection (GC) is a way for some languages to automatically free up memory that is no longer in use. When that happens, the program pauses. This is known as a <em>GC pause</em>. The more writes you make to memory, the more garbage collection needs to happen and as a result, the pause time increases. For our service, these pauses were growing high enough that they caused the servers to restart and put stress on the CPU. When this happens, it can look like the server is down—because it temporarily is—and our customers started to see 5xx errors for roughly 6% of the logs our agent was trying to ingest.</p><p>Below we can see the pause time and pause frequency of the garbage collection:</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/gc-pause.jpg" alt="GC pause and frequency charts" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/gc-pause.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/gc-pause.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/gc-pause.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/gc-pause.jpg 2400w"></figure><p>In some instances, the pause time breached <strong>4 seconds</strong> (as shown on the left), with up to <strong>400 pauses per minute</strong> (as shown on the right) across our instances.</p><p>After some more research, we appeared to be another victim of a<a href="https://github.com/aws/aws-sdk-js/issues/329"> memory leak in the AWS Javascript SDK</a>. We tried increasing the resource allocations to extreme amounts, like autoscaling after 1000 req/min, but nothing worked.</p><h2 id="possible-solutions"><strong>Possible solutions</strong></h2><p>With our backup plan no longer an option, we moved on to new solutions. First, we looked at those with the easiest transition path.</p><h3 id="elixir"><strong>Elixir</strong></h3><p>As mentioned earlier, we are checking the customer access rights using an Elixir service. This service is private and only accessible from within our Virtual Private Cloud (VPC). We have never experienced any scalability issues with this service and most of the logic was already there. We could simply send the logs to Kinesis from within this service and skip over the Node.js service layer. We decided it was worth a try.</p><p>We developed the missing parts and tested it. It was better, but still not great. Our benchmarks showed that there were still high levels of Garbage Collecting, and we were still returning 5xx to our users when consuming the logs. At this point, the heavy load triggered a <a href="https://github.com/benoitc/hackney/issues/594">(now resolved) issue</a> with one of our elixir dependencies.</p><h3 id="go"><strong>Go</strong></h3><p>We considered Golang as well. It would have been a good candidate, but in the end, it is another Garbage Collected Language. While likely more efficient than our previous implementation, as we scale there is a high chance we'd run into similar problems. With these limitations in mind, we needed a better option.</p><h2 id="re-architecting-with-rust-at-the-core"><strong>Re-architecting with Rust at the core</strong></h2><p>In both our original implementation and our backup, the core issue remained the same: garbage collection. The solution was to move to a language with better memory management and no garbage collection. Enter Rust.</p><p>Rust isn't a garbage-collected language. Instead, it relies on a concept called <em>ownership</em>.</p><blockquote>Ownership is Rust’s most unique feature, and it enables Rust to make memory safety guarantees without needing a garbage collector. <br>— <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">The Rust Book</a></blockquote><p>Ownership is the concept that often makes Rust difficult to learn and write, but also what makes it so well suited for situations like ours. Each value in Rust has a single owner variable and as a result a single point of allocation in memory. Once that variable goes out of scope the memory is immediately returned.</p><p>Since the code required to ingest the logs is quite small, we decided to give it a try. To test this we addressed the very thing that we had issues with—sending large amounts of data to Kinesis.</p><p>Our first benchmarks proved to be very successful.</p><p>From that point, we were pretty confident that Rust could be the answer and we decided to flesh out the prototype into a production-ready application.</p><p>Over the course of these experiments, rather than directly replacing the original Node.js service with Rust, we restructured much of the architecture surrounding log ingestion. The core of the new service is an <a href="https://www.envoyproxy.io/">Envoy</a> proxy with the Rust application as a sidecar.</p><p>Now, when the Bearer Agent in a user's application sends log data to Bearer, it goes into the Envoy proxy. Envoy looks at the request and communicates with Redis to check things like rate limits, authorization details, and usage quotas. Next, the Rust application running alongside Envoy prepares the log data and passes it through Kinesis into an s3 bucket for storage. S3 then triggers our worker to fetch and process the data so Elastic Search can index it. At this point, our users can access the data in our dashboard.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---rust.jpg" alt="Diagram of new rust service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---rust.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---rust.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---rust.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---rust.jpg 2400w"></figure><p>What we found was that with fewer—and smaller—servers, we are able to process even more data without any of the earlier issues.</p><p>If we look at the latency numbers for the Node.js service, we can see peaks with an average response time nearing 1700ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/before-latency.png" alt="Latency with original Node.js service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/before-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/before-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/before-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/before-latency.png 2400w"></figure><p>With the Rust service implementation, the latency dropped to below 90ms, even at its highest peak, keeping the average response time below 40ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/after-latency.png" alt="Latency after re-architecture" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/after-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/after-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/after-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/after-latency.png 2400w"></figure><p>The original Node.js application used about 1.5GB of memory at any given time, while the CPUs ran at around 150% load. The new Rust service used about 100MB of memory and only 2.5% of CPU load.</p><h2 id="conclusion"><strong>Conclusion</strong></h2><p>As with most startups, we move fast. Sometimes the best solution at the time isn't the best solution forever. This was the case with Node.js. It allowed us to move forward, but as we grew we also outgrew it. As we started to handle more and more requests, we needed to make our infrastructure evolve to address the new requirements. While this process started with a fix that merely replaced Node.js with Rust, it led to a rethinking of our log ingestion service as a whole.</p><p>We still use a variety of languages throughout our stack, including Node.js, but will now consider Rust for new services where it makes sense.<br></p>
	</section></div>]]>
            </description>
            <link>https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662530</guid>
            <pubDate>Fri, 02 Oct 2020 13:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we feel worthless in the age of abundance?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662434">thread link</a>) | @durmonski
<br/>
October 2, 2020 | https://durmonski.com/psychology/feel-worthless-in-the-age-of-abundance/ | <a href="https://web.archive.org/web/*/https://durmonski.com/psychology/feel-worthless-in-the-age-of-abundance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span>Last updated:</span><time datetime="2020-09-28T04:47:48+00:00">28/09/2020</time></p>
<p data-block-type="core"><em>At first, I didn’t know how it happened. How a dorky kid with no fashion sense was able to ditch the ugly sweater and wear a shirt and a tie on major events – sometimes even for breakfast. Was I suddenly obsessed by a fashion spirit or the covers of the modern magazines subconsciously recorded in my memory when I was walking past them on the street? It turns out, it wasn’t any of those things. I simply managed to settle in a glamorous looking crew of folks who shopped for new clothes as often as they checked their Instagram stories. Eventually, their fashion taste and erratic spending habits were quickly adopted by me.</em></p>



<p data-block-type="core">Imagine a blank slate. That’s how the brain of a newborn looks like. Some scientists argue that there are certain traits embedded in our genes influencing our behavior, others claim that such nonsense does not exist.</p>



<p data-block-type="core">What both groups agree with is the following: We’re all heavily influenced by the surrounding people.</p>



<p data-block-type="core">It’s actually our biggest advantage over all other living organisms. Our development is based on imitation. Our ability to observe others, evaluate, and copy their moves is a vital skill that helps us survive and advance.</p>



<p data-block-type="core">Yet, this same copying mechanism is also the reason we’re feeling worthless in the age of abundance. Our tendency to imitate what others are doing – and thinking – is the reason we’re carelessly spending our hard earn cash. Therefore, the more we obey the norms of the social circle we’re in, the more we become incapable of escaping the <a href="https://durmonski.com/well-being/internet-rabbit-holes/" target="_blank" aria-label="never-ending depths (opens in a new tab)" rel="noreferrer noopener">never-ending depths</a> of the online world. A world full of comparison and erratic behavior.</p>



<p data-block-type="core">The mere existence of the Other, as we’ll observe below, is both a blessing and a curse.</p>







<h2 data-block-type="core">Why Other People Are Both Good and Bad For Us?</h2>



<p data-block-type="core">Let’s start with the good things.</p>



<p data-block-type="core">You emerge from your mother’s womb. You cry. You crawl. You get up. You start to run. Eventually, at some point, you start to talk. Respectfully, if you’re born in Germany, you’ll call you dad “vader”. If you’re residing in the US, you’ll call him “father”. If you happen to appear in France, you’ll use the word “père”.</p>



<p data-block-type="core">Same meaning, different words.</p>



<p data-block-type="core">Obviously, you get why we use different words for the word father – because we’re exposed to different languages. If your parents are speaking English, the first language you’ll learn will be, unsurprisingly, English.</p>



<p data-block-type="core">This is simple. We get that.</p>



<p data-block-type="core">But what we often fail to realize is that we also adopt everything else our parents do. Every little act. Every little glimpse of emotion. We accumulate everything the surrounding people do, filter the stuff that are not relevant, and create a set of beliefs for ourselves that we’ll eventually use for (sometimes) the rest of our lives.</p>



<p data-block-type="core">But it’s not only our parents. It’s everyone around us.</p>



<figure data-block-type="core"><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1024x512.jpg" alt="" srcset="https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/09/how-our-beliefs-and-desires-are-influenced-1024x512.jpg"><figcaption>We imitate each other’s desires. That’s why, eventually, we wind up desiring the very same things.</figcaption></figure>







<p data-block-type="core">The horde of people you expose yourself to is calibrating your persona and shaping it based on what you observe.</p>



<p data-block-type="core">The gains here are clear: thanks to our ability to mimic the behavior of others we’re able to learn new skills, tactics, tricks, set of instructions that are essentially helping us live another day.</p>



<p data-block-type="core">What about the downsides?</p>



<p data-block-type="core">There are plenty.</p>



<p data-block-type="core">But before we talk about how corrupting the influence of others is, we first need to explain the mimetic theory.</p>







<h2 data-block-type="core">How The Mimetic Theory is Influencing our Lives?</h2>



<p data-block-type="core">René Girard, a French historian and polymath, is the father of this theory – <a href="https://durmonski.com/book-summaries/rene-girards-mimetic-theory/" target="_blank" aria-label="the mimetic theory (opens in a new tab)" rel="noreferrer noopener">the mimetic theory</a>. The goal of this concept is to explain our human behavior and from where our desires originate.</p>



<p data-block-type="core">According to his views, our desires are a direct consequence of the desires of the surrounding people. Both people who we regularly see, in person, and such we highly admire.</p>



<p data-block-type="core">As we concluded above, our behavior is based on imitation. But we’re not only imitating the moves and the actions of others. We also adopt the motives, the aspirations, the dreams of other people.</p>



<p data-block-type="core">You might think that you want to go on an exotic vacation because you think that you are a free spirit and because you want to take a break from the world. In reality, though, according to the mimetic theory, you’re simply imitating what everyone else is doing. </p>



<p data-block-type="core">Probably a celebrity you follow online is regularly posting pictures of her drinking cocktails on the beach. If that’s so, this behavior transports in your brain and you suddenly want to do the same thing.</p>



<p data-block-type="core">This model of desire takes a triangular shape.</p>



<p data-block-type="core">And it kind of looks like this:</p>



<figure data-block-type="core"><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1024x512.jpg" alt="mimetic-theory-triangle-model-of-desire" srcset="https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/09/mimetic-theory-triangle-model-of-desire-1024x512.jpg"><figcaption>There is always a triangular relationship between the subject, the model, and the object. Through the object, the person feels that he’s getting closer to the model, whom Girard calls the mediator.</figcaption></figure>







<p data-block-type="core">On the top, there is an ideal we strive towards. René Girard calls them mediators. On the right, are our actions, the things we want to obtain, that are always somehow related to this goal – the top. On the left is where we are currently.</p>



<p data-block-type="core">Or to put it differently, our goals, ambitions, and longings are never truly our own. They are a mere reflection of what we see in the world around us and who we want to imitate.</p>



<p data-block-type="core">Actually, if we dig even deeper into the mimetic theory, we can see that we never really know what we actually want. We always adopt the desires of others:</p>



<blockquote data-block-type="core"><p>Human desire is not based on the spontaneity of the subject’s desire, but rather the desires that surround the subject. He argues that humans do not themselves know what to desire; as a result, they imitate the desires of others.” Wolfgang Palaver from <a href="https://durmonski.com/book-summaries/rene-girards-mimetic-theory/" target="_blank" aria-label="René Girard’s Mimetic Theory (opens in a new tab)" rel="noreferrer noopener">René Girard’s Mimetic Theory</a></p></blockquote>



<p data-block-type="core">“This is not so bad,” you say. “What’s wrong with going to a distant island and taking a break? What’s wrong with wanting what others want?”</p>



<p data-block-type="core">Not that traveling 10,000 miles and spending 10,000 USD is necessarily a bad thing to do.</p>



<p data-block-type="core">But the point is different.</p>



<p data-block-type="core">If you don’t take a step back to identify your own desires, the things <em>you </em>want to do, without considering what others want from you, you’ll always feel miserable. You’ll simply respond to what everyone else is doing and never find your genuine, true self – as banal as it might sound.</p>



<p data-block-type="core">A person who is always imitating someone else is unable to trust his own judgment. That’s why, he desires only objects desired by others. And also, he always follows and never leads.</p>







<h2 data-block-type="core">The Bad Influence Of The Other</h2>



<p data-block-type="core">Amongst many, a common “perk” that comes from imitating others is your longing to earn their approval.</p>



<p data-block-type="core">As we observed, we strive to reach an ideal that is shaped by taking into account what everyone around us is wanting. But we don’t do it only because this will move us closer to a potentially god-like existence. We also do it because we want other people to approve of us.</p>



<p data-block-type="core">This tear us from the inside.</p>



<p data-block-type="core">Part of us wants to express our true nature while the other part wants to win the approval of others.</p>



<p data-block-type="core">This forms the following inner conflict:</p>



<p data-block-type="core">“To be myself or to be what others will accept me to be?”</p>



<p data-block-type="core">If you focus on being your genuine, true self, without considering others and caring about their opinion – which is still influenced by other people in your life in some way – you will fail to gain their recognition. After all, your actions will be different from what is “accepted” as right in the group.</p>



<p data-block-type="core">For example, if you’re mostly hanging around people who smoke and visit nightclubs, your reluctance to smoke and say yes to heavy drinking during the night will be badly perceived. After all, since everyone is doing it, and you’re not, you can’t expect their approval of you. Actually, your disobedience will cause them to question their own actions – something nobody wants. “Why don’t you go out with us? What do you think you are, better than us or what?”</p>



<p data-block-type="core">Eventually, you’ll be left out of the group or you won’t enjoy a lot of attention from them.</p>



<p data-block-type="core">The second scenario, if you decide to go along with the group and focus on “being someone who they will adore” – which is kind of sad if you decide to go in that direction – is still not going to be that easy. At least, if you have any will left.</p>



<p data-block-type="core">For example, if you’re a bookworm, an introvert, an anime fanatic, and you start partying only because you want others to approve of you, you’ll be torn between your true self (the person <em>you </em>want to be) and the socially accepted self (the person you strive to become because others will like more).</p>



<p data-block-type="core">Striving towards the socially accepted self, in the book <a aria-label="René Girard’s Mimetic Theory (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/rene-girards-mimetic-theory/" target="_blank">René Girard’s Mimetic Theory</a>, is called “bad faith”.</p>



<p data-block-type="core">Your efforts to appear as this cool kid, which you’re not, at least still not, will put you out of your skin and make you look like an amateur, an imposture at first. When observed under a loop, your actions won’t look natural. After all, you’re pretending to be someone you’re not.<span id="easy-footnote-1-11482"></span><span><a href="#easy-footnote-bottom-1-11482" title="The person who coined the phrase &amp;#8220;bad faith&amp;#8221; is Jean-Paul Sartre. This <a aria-label=&quot;video (opens in a new tab)&quot; rel=&quot;noreferrer noopener nofollow&quot; href=&quot;https://youtu.be/xxrmOHJQRSs&quot; target=&quot;_blank&quot; class=&quot;ek-link&quot;>video</a> describes the concept quite well."><sup>1</sup></a></span></p>



<figure data-block-type="core"><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1024x512.jpg" alt="" srcset="https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/09/bad-faith.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/09/bad-faith-1024x512.jpg"><figcaption>When we assume that we have no other choice than to make others like us, we are living in Bad Faith. It’s an in-between state of existence – you’re neither the person you really are nor the one you want to be.</figcaption></figure>







<p data-block-type="core">You’re simply following a plan, a project, to be this cool kid. Therefore, you’re being someone you’re actually not. If you give yourself enough time, you’ll eventually become good at doing the things everyone else is doing. And eventually, the circles will collide. During the transition period, though, you’ll be a stranger to yourself.</p>







<h2 data-block-type="core">Our Consumption and our Media Habits are Greatly Influencing our Behavior</h2>



<p data-block-type="core">So far, we’ve looked at how others shape our behavior and saw what we do to fit in a group – we’re essentially betraying ourselves.</p>



<p data-block-type="core">But our desires are not formed only by our offline habits.</p>



<p data-block-type="core">The mimetic theory emerged when <a href="https://durmonski.com/life-advice/why-i-quit-social-media/" target="_blank" aria-label="social media (opens in a new tab)" rel="noreferrer noopener">social media</a> and the current modern media outlets were still not that influential. </p>



<p data-block-type="core">Nowadays, what we become is also greatly influenced by what we consume online.</p>

</div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/psychology/feel-worthless-in-the-age-of-abundance/">https://durmonski.com/psychology/feel-worthless-in-the-age-of-abundance/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/psychology/feel-worthless-in-the-age-of-abundance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662434</guid>
            <pubDate>Fri, 02 Oct 2020 13:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Architecture Playbook]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662345">thread link</a>) | @cvs268
<br/>
October 2, 2020 | https://nocomplexity.com/documents/arplaybook/index.html | <a href="https://web.archive.org/web/*/https://nocomplexity.com/documents/arplaybook/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
        
          By Maikel Mardjan<br>
        
            © Copyright 2018,2019, 2020 BM-Support.org. Created by Maikel Mardjan. This work is licensed under the Creative Commons Attribution-ShareAlike 4.0 International License (cc-by-sa).<br>
      </p>
  </div></div>]]>
            </description>
            <link>https://nocomplexity.com/documents/arplaybook/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662345</guid>
            <pubDate>Fri, 02 Oct 2020 13:28:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One function is all you need for ML Experiments]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24662085">thread link</a>) | @LexSiga
<br/>
October 2, 2020 | https://www.logicalclocks.com/blog/hopsworks-ml-experiments | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/hopsworks-ml-experiments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Hopsworks provides support for machine learning (ML) experiments. That is, it can automatically track the artifacts, graphs, performance, logs, metadata, and dependencies of your ML programs.Many of you already know about platforms like <a href="https://mlflow.org/">MLflow</a>, so why should you read about Hopsworks Experiments?&nbsp; Because you do not have to rewrite your TensorFlow/PyTorch/Scikit-learn programs to get <strong>tracking and distributed ML for free</strong>, and TensorBoard comes built-in. We discuss how Hopsworks uniquely supports implicit provenance to transparently create metadata and how it is combined with the oblivious training function to make your training distribution transparent.&nbsp;</p><h2>Hopsworks Introduction</h2><p>Hopsworks is a single platform for both data science and data engineering that is available as both an <a href="http://github.com/logicalclocks/hopsworks">open-source platform</a> and a <a href="http://www.hopsworks.ai/">SaaS platform</a>, including a built-in <a href="https://www.logicalclocks.com/hopsworks-featurestore">feature store</a>. You can train models on GPUs at scale, easily install any Python libraries you want using pip/conda, run Jupyter notebooks as jobs, put those jobs in Airflow pipelines, and even write (Py)Spark or Flink applications that run at scale.&nbsp;</p><p>As a development environment, Hopsworks provides a central, collaborative development environment that enables machine learning teams to easily share results and experiments with teammates or generate reports for project stakeholders. All resources have strong security, data governance, backup and high availability support in Hopsworks, while assets are stored in a single distributed file system (with data stored on S3 in the cloud).<br></p><figure id="w-node-a0d33d55738e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f74366329e691163a9537f8_mT5Xl3PGQNailTwXRoPhMMlEZePoa3PjlnagKaWj7mJxckcqP1SfcSbkOS3P-adIEnIq7kURxZ-TJ4ypWTt7yw94d_vqkB9o2FMTUrosMB8Pnxz0pPYkehYlOoJySGBdjPuDNQ7I.gif" alt=""></p><figcaption>A Hopsworks ML experiment stores information about your ML training run: logs, images, metrics of interest (accuracy, loss), the program used to train the model, its input training data, and the conda dependencies used. Optional outputs are hyperparameters, a TensorBoard, and a Spark history server.</figcaption></figure><figure id="w-node-06188dbd9c79-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743664aeafc406b94b027c_hraL3X_VAEzOtdesnelgqqb4FQcVGC8Q6J0-KQM0UPGGQxgU_TlMb_-LIZuMOszzdZIhxEZogwxlSSfOMdZvcAIgRlLZzoNg2dLmoPUSrNWyK0CABpAglOV9q9SqfogrRxoO6k29.gif" alt=""></p><figcaption>The logs of each hyperparameter trial are retrieved by clicking on its log, and TensorBoard visualizes the different trials results. The TensorBoard HParams plugin is also available to drill down further on the trials.</figcaption></figure><p>When you run a Python or PySpark application on the Hopsworks platform, it can create an<strong> experiment</strong> that includes both the traditional information a program generates (results, logs, errors) as well as ML-specific information to help track, debug, and reproduce your program and its inputs and outputs:</p><ul role="list"><li><strong>hyperparameters</strong>: parameters for training runs that are not updated by the ML programs themselves;&nbsp;</li><li><strong>metrics</strong>: the loss or accuracy of the model(s) trained in this experiment;</li><li><strong>program artifacts</strong>: <em>python/pyspark/airflow</em> <em>programs, </em>and their <em>conda environments</em>;</li><li><strong>model artifacts</strong>: serialized <em>model objects,</em> <em>model schemas</em>, and <em>model checkpoints</em>;</li><li><strong>executions</strong>: information to be able to re-execute the experiment, including parameters, versioned features for input, output files,&nbsp; etc;&nbsp;</li><li><strong>versioned features</strong>: to be able to reproduce an experiment, we need the exact training/test data from the run and how it was created from the feature store;</li><li><strong>visualizations</strong>: images generated during training and score. Also use TensorBoard to visualize training runs - Hopsworks aggregates results from all workers transparently;</li><li><strong>logs (for debugging)</strong>: model weights, gradients, losses, optimizer state;</li><li><strong>custom metadata</strong>: tag experiments and free-text search for them, govern experiments (label as ‘PII’, ‘data-retention-period’, etc), and reproduce training runs.</li></ul><figure id="w-node-55f328a117c2-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f748ce6a667fe73eb582948_Screenshot%202020-09-30%20at%2015.48.58.png" loading="lazy" alt=""></p></figure><h2>Experiment Tracking and Distributed ML in One Library</h2><figure id="w-node-be7859ba57d5-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5ef49c1e473b2c283eb616aa_nXpYXacWzP67N5MmHnhldoZJw6qVoDwpBnTd3JQzx9nFuX9_FVm-fmWztjYeLdun5BI83RGOdD1ibvFFWBHUCvQGtbenUY1f6haaE58VP5aAHHJOSWpf0P8FJkfPuE5JMAfMlcOk.png" alt=""></p></figure><p>
    -- CODE language-bash --
def train(data_path, max_depth, min_child_weight, estimators): 
    X_train, X_test, y_train, y_test = build_data(..)
    ...
    print("hello world") # monkeypatched - prints in notebook
    ...
    model.fit(X_train, y_train) # auto-logging
    ...
    hops.export_model(model, "tensorflow",..,model_name)
    ...
    # create local files ‘logile.txt’, ‘diagram.png’ 
    return {'accuracy': accuracy, 'loss': loss, 'logfile':
       'logfile.txt', 'diagram': 'diagram.png'} # track dict

from maggy import experiment
experiment.lagom(train, name="My Experiment", ...) 

# To launch as a distributed ML HParam Tuning job:
# sp=Searchspace(max_depth=('INTEGER',[2,8]),min_child_weight
# =('INTEGER', [2, 8]), )
# experiment.lagom(train, name=“HP, optimizer='randomsearch',                          
# direction='max', num_trials=15,)
</p><p>Platforms that support experiment tracking require the user to refactor their training code in a function or some explicit scope (such as “with … as xx:” in MLFlow, see Appendix A) to identify when an experiment begins and when an experiment ends. In Hopsworks, we require the developer to write their training code inside a function.&nbsp;</p><p>We call this Python function an <em>oblivious training function</em> because the function is oblivious of whether it is being run on a Python kernel in a Jupyter notebook or on many workers in a cluster, see our <a href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy">blog </a>and <a href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy">Spark/AI summit talk</a> for details. That is, you write your training code once and reuse the same function when training a small model on your laptop or when performing hyperparameter tuning or distributed training on a large cluster of GPUs or CPUs.</p><p>We double down on this “wrapper” Python function by also using it to start/stop experiment tracking. Experiment tracking and distribution transparency in a single function, nice!&nbsp;</p><p>In Hopsworks, the <a href="https://github.com/logicalclocks/maggy">Maggy</a> library runs experiments, see code snippet above. As you can see, the only code changes a user needed compared to a best-practice TensorFlow program are:&nbsp;<br></p><ol role="list"><li>factor the training code in a user-defined function (<strong>def train(..):</strong>);</li><li>return a Python dict containing the results, images, and files that the user wants to be tracked for the experiment and accessible later in the Experiments UI; and</li><li>invoke the training function using the <em>experiment.lagom</em> function.<br></li></ol><p>The hyperparameters can be fixed for a single execution run, or as shown in the last 4 lines of the code snippet, you can execute the <em>train function </em>as a distributed hyperparameter tuning job across many workers in parallel (with GPUs, if needed).&nbsp;</p><p>Hopsworks will automatically:</p><ul role="list"><li>track all parameters of the train function as hyperparameters for this experiment,&nbsp;</li><li>auto-log using Keras callbacks in model.fit;</li><li>create a versioned directory in HopsFS, where a copy of the program, its conda environment, and all logs from all workers are aggregated;</li><li>track all provenance information for this application - input data from HopsFS used in this experiment (train/test datasets from the Feature Store), and all output artifacts (models, model checkpoints, application logs);</li><li>redirect all print statements executed in workers to the Jupyter notebook cell for easier debugging (see GIF below - each print statement is prefixed by the worker ID).<br></li></ul><figure id="w-node-756fb7ca0b23-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f74366291399a79d18af461_4BATblXBajOTlBXREg6utXoqcRgymvySZx03Hh_JeYvjJ7YLGzxYpnUgMwCvHaNxMFgj_XepZ23xJh3QFnfhHsAetRlt24IkRw4BI8R4Wo5gaQLkVuuIRRbE8CK7swOEJaa-Lm-k.gif" alt=""></p><figcaption>In Hopsworks, logs from workers can be printed in your Jupyter notebook during training. Take that Databricks!</figcaption></figure><h2>TensorBoard support</h2><p>
    -- CODE language-bash --
    
    def train():
    from maggy import tensorboard
    ...
    model.fit(.., callbacks=[TensorBoard(log_dir=tensorboard.logdir(),..)], ...)
</p><p>TensorBoard is arguably the most common and powerful tool used to visualize, profile and debug machine learning experiments. Hopsworks Experiments integrates seamlessly with TensorBoard. Inside the training function, the data scientist can simply import the <em>tensorboard</em> python<em> </em>module and get the folder location to write all the TensorBoard files. The content of the folder is then collected from each Executor and placed in the experiment directory in HopsFS. As TensorBoard supports showing multiple experiment runs in the same graph, visualizing and comparing multiple hyperparameter combinations becomes as simple as starting the TensorBoard integrated in the Experiments service. By default, Tensorboard is configured with useful plugins such as HParam, Profiler, and Debugging.&nbsp;</p><h3>Profiling and debugging</h3><p>Hopsworks 1.4.0 comes with TensorFlow 2.3, which includes the TensorFlow profiler. A new long-awaited feature that finally allows users to profile model training to identify bottlenecks in the training process such as slow data loading or poor operation placement in CPU + GPU configurations.&nbsp;</p><p>TensorFlow 2.3 also includes Debugger V2, making it easy to find model issues such as NaN which are non-trivial to find the root cause of in complex models.<br></p><figure id="w-node-821b5c19e74e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743661e73aacd6dc310040_Rywm-fmUfHouqW1zVdYsZ88LvtAYDvCZPpze3hHJeENCBjPVPkkpy_J-2bescj5Z-Xlb7A7DNpmNws1H4lsmUsuOpLROLO_S16jFM_CI-6JdACYY5Rp3Q3yYVMfkecV7aK7ECsf_.png" alt=""></p></figure><figure id="w-node-fc6081bc518f-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743662849afea39f14cb69_S0v-cuc6N5MT4gsC3KUBFa3dQi7ZZBEaF9w684FzTrmXH4FPHkDEFCaMy2ThIpmSHDHSY-vmXCvXyDVrMVS_FYy3vnODkL8uXcHrm4uIlNjhNHHhsxoMghDrFfX_Yn_eVe1eYBbE.png" alt=""></p></figure><h2>Model Registry</h2><figure id="w-node-6cad6e721c68-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743662ec097905b0778b6b_KcTuR12rSnRVQSSDh-eLxqM0ad3eAXSGCkehOJ8ik2BPfnohgCfudLLx7HkUIk3DKfTTxz-DzRwlJ7OAYU0eafq0bwSN2tYy7dt_rnOeth550yYPqa-esKRO6uGREvB1C4iNjk3l.png" alt=""></p></figure><p>In the training code models may be exported and saved to HopsFS. Using the <em>model </em>python module in the <a href="https://hops-py.logicalclocks.com/">hops library</a>, it is easy to version and attach meaningful metadata to models to reflect the performance of a given model version.&nbsp;</p><p>The Hopsworks Model Registry, is a service where all models are listed in addition to useful information such as which user created the model, different versions, time of creation and evaluation metrics such as accuracy.&nbsp;</p><p>The Model Registry provides functionality to filter based on the model name, version number and the user that exported the model. Furthermore the evaluation metrics of model versions can be sorted in the UI to find the best version for a given model.&nbsp;</p><p>In the Model Registry UI, you can also navigate to the experiment used to train the model, and from there to the train/test data used to train the model, and from there to the features in the feature store used to create the train/test data. Thanks, provenance!<br></p><h3>Exporting a model</h3><p>A model can be exported programmatically by using the <em>export</em> function in the <em>model</em> module. Prior to exporting the model, the experiment needs to have written a model to a folder or to a path on HopsFS. Then that path is supplied to the function along with the name of the model and the evaluation metrics that should be attached. The <em>export</em> call will upload the contents of the folder to your Models dataset and it will also appear in the Model Registry with an incrementing version number for each export.</p><p>
    -- CODE language-bash --
    from hops import model

# local path to directory containing model (e.g. .pb or .pk) 
path = os.getcwd() + “/model_dir”

# uploads path to the model repository, metadata is a dict of metrics</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/hopsworks-ml-experiments">https://www.logicalclocks.com/blog/hopsworks-ml-experiments</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/hopsworks-ml-experiments</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662085</guid>
            <pubDate>Fri, 02 Oct 2020 12:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GameDev Notes 1: Taking the Plunge]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661977">thread link</a>) | @cpatuzzo
<br/>
October 2, 2020 | https://tuzz.tech/blog/taking-the-plunge | <a href="https://web.archive.org/web/*/https://tuzz.tech/blog/taking-the-plunge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="root"><div tabindex="-1"><div><div><div tabindex="-1"><div tabindex="-1"><p><time datetime="2020-10-02T12:00Z">Published <!-- -->October 2, 2020<!-- --> by <!-- --> <a href="https://twitter.com/chrispatuzzo" target="_blank">Chris Patuzzo</a><a href="https://tuzz.tech/feed.xml" target="_blank"><svg width="16" height="16" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><circle cx="3.429" cy="20.571" r="3.429"></circle><path d="m11.429 24h4.57c0-8.821-7.178-15.999-15.999-16v4.572c6.302.001 11.429 5.126 11.429 11.428z"></path><path d="m24 24c0-13.234-10.766-24-24-24v4.571c10.714 0 19.43 8.714 19.43 19.429z"></path></svg></a></time></p><p>Follow me on <a href="https://twitter.com/chrispatuzzo" target="_blank">twitter</a> to hear how you can be
a playtester when the time comes.</p><p>For the past few months I’ve been writing my first ever indie game (in Rust).
It’s a 2D <span>puzzle-platformer</span> that I’m super
happy with so far. I think it’s pretty unique and I’m excited to see where it
goes. I’m quite stubborn and like things done a particular way so I’m not using
an off-the-shelf engine like Unity and I’m writing almost everything myself
except for some of the low-level libraries. It’s challenging and fun.</p><p>Anyway, some friends suggested I share what I’ve been doing. Until now, I’ve
been reluctant to because I already have heaps to do but I think it would be a
shame if this knowledge is lost (because I’ll inevitably forget). Therefore,
I’m going to try and write occasional gamedev notes and publish them here. I
don’t guarantee they’ll all make sense without extra context. I’m hoping to
refer back to them later, e.g. if I turn them into YouTube videos or something.</p><p>Most recently (the last few days) I’ve been working on adding water and
swimming to the game. Currently the player character is land-based and I wanted
to expand that out to add variety and a new set of constraints for the player
to grapple with. There are story reasons as well, but I won’t spoil it. Before
diving(!) in, here’s a quick demo of what I made this week:</p><figure><a href="https://tuzz.tech/videos/swimming-high-res.mp4" target="_blank"><video muted="" autoplay="" playsinline="" loop=""><source src="https://tuzz.tech/videos/swimming-low-res.mp4" type="video/mp4"></video></a><figcaption><span>▲</span><span>Demo of swimming in my game (click for a higher resolution)</span></figcaption></figure><p>It probably doesn’t look much compared to AAA games but I added a few niceties
to make it visually interesting and fun to navigate. The first thing I worked
on was a new component called <code><span><span>Liquid</span></span></code> that I can attach to a game entity. I
decided to use the more general term ‘liquid’ rather than ‘water’ because I
already use the term ‘solid’ and it seemed to fit better with the language of
my engine.</p><a href="#liquids"><h2 id="liquids">Liquids</h2></a><p>Here are the properties I can currently set on a liquid:</p><div><pre><code><span><span>Liquid </span><span>{</span><span></span></span><span><span>    direction_of_flow</span><span>:</span><span> Vector2f</span><span>::</span><span>new</span><span>(</span><span>0.2</span><span>,</span><span> </span><span>0</span><span>.</span><span>)</span><span>,</span><span></span></span><span><span>    default_buoyancy</span><span>:</span><span> Buoyancy </span><span>{</span><span></span></span><span><span>      upthrust</span><span>:</span><span> </span><span>1.0</span><span>,</span><span></span></span><span><span>      drag_coefficients</span><span>:</span><span> </span><span>(</span><span>0.15</span><span>,</span><span> </span><span>3</span><span>.</span><span>)</span><span>,</span><span></span></span><span><span>      jump_scale_factor</span><span>:</span><span> </span><span>0.4</span><span>,</span><span></span></span><span><span>      waterline</span><span>:</span><span> </span><span>0.3</span><span>,</span><span></span></span><span><span>      settle_rate</span><span>:</span><span> </span><span>0.01</span><span>,</span><span></span></span><span><span>    </span><span>}</span><span>,</span><span></span></span><span><span></span><span>}</span></span></code></pre></div><p>Before I can do anything interesting with these properties, I first need to
know which entities are ‘submerged’ in the liquid. I created a resource called
<code><span><span>SubmergedEntities</span></span></code> that tracks this and a system that incrementally keeps this
resource up to date based on which entities have moved since the last update. I
consider an entity ‘submerged’ if its bounding box overlaps with the liquid,
even slightly. In other parts of the code I need to distinguish ‘partially’
versus ‘fully’ submerged, but I check this as needed.</p><p>With that out of the way, I wrote a <code><span><span>LiquidPhysics</span></span></code> system that applies these
properties to submerged entities. I made it so this only applies to those that
have a <code><span><span>Mass</span></span></code> component so that static geometry (e.g. the floor) isn’t
affected. I initially tried to make <code><span><span>LiquidPhysics</span></span></code> work in harmony with my
existing <code><span><span>GravityPhysics</span></span></code> system but that turned out to be really fiddly so I
abandoned that. Instead, it’s one or the other: if an entity is submerged,
<code><span><span>LiquidPhysics</span></span></code> handles it. If it is not, <code><span><span>GravityPhysics</span></span></code> does.</p><p>Here’s a quick summary of what each properties does:</p><ul><li><strong>direction_of_flow:</strong> controls the direction/speed entities move in the liquid</li><li><strong>upthrust:</strong> the same as above but only for the y-direction</li><li><strong>drag_coefficients:</strong> controls how rapidly an entity reaches the flow velocity when it’s not moving at that velocity, e.g. if the player jumps into some water, they will initially be travelling much faster than it</li><li><strong>jump_scale_factor:</strong> when an entity is ‘walking underwater’, i.e. it is standing on the ground in liquid, this parameter reduces the velocity applied when it jumps</li><li><strong>waterline:</strong> when an entity is floating at the top of the liquid, this parameter controls how high it naturally sits above the liquid, as a fraction of height</li><li><strong>settle rate:</strong> when an entity isn’t sitting at its waterline, this parameter controls how quickly it converges to it</li></ul><p>There’s quite a lot going on here but <code><span><span>LiquidPhysics</span></span></code> didn’t turn out too
complicated, only 100 lines or so. I did a bunch of reading about <a href="https://en.wikipedia.org/wiki/Terminal_velocity" target="_blank">terminal
velocity</a> and
<a href="https://en.wikipedia.org/wiki/Drag_(physics)" target="_blank">drag</a> before writing it which
helped. The reason most of the properties are nested in a <code><span><span>default_buoyancy</span></span></code>
field is so I can override them on a per-entity basis. For example, I might
want something to float on the surface while everything else sinks or to set a
lower waterline for a pirate ship.</p><a href="#swimming"><h2 id="swimming">Swimming</h2></a><p>I probably spent most of my time working on the swimming controls. I watched a
few videos of how swimming is typically handled in 2D games. In <a href="https://youtu.be/1wR8x5b_ExM?t=298" target="_blank">Super
Mario</a>, the swimming is a bit like jumping.
The player constantly sinks and swims up by jumping. They stay upright at all
times. I eventually got a nostalgia trip watching how swimming works in <a href="https://youtu.be/lSbLrWRLWl4?t=51" target="_blank">Ecco
the Dolphin</a>. I never really understood what
to do in that game but I remember it being fun to play. I like that the
character rotates to face the direction they’re heading. The boost is fun, too.</p><p>Currently, the on-land controls of my game are very responsive - you can
immediately switch directions. I figured it would be a nice change to introduce
some delay in water so you first have to turn to face the direction you want to
go, perhaps bumping into a wall along the way. You effectively always move in
the direction your head is pointing and turn at some arbitrary rate I can
control. Most people are better on land than in water so this fits well with
reality. Another minor reason for choosing this was that my engine works with
arbitrary transforms - it’s richer than a tile-based engine, which many 2D
games are built on, so I figured I may as well make use of this capability. If
I add analogue controller support, I can see it working well with that, too.</p><p>The way this works is by mapping the direction you’re pressing to one of the
eight intercardinal directions. I use the nautical term
‘<a href="https://en.wikipedia.org/wiki/Course_(navigation)" target="_blank">course</a>’ for this. I then
get the angle the player is current facing which I call its
‘<a href="https://en.wikipedia.org/wiki/Heading_(navigation)" target="_blank">heading</a>’ and figure out
which direction to turn to get there soonest. This is a bit fiddly because
angles wrap around and are usually in the range -PI to PI (from the
<a href="https://en.wikipedia.org/wiki/Atan2" target="_blank"><code><span><span>atan2</span></span></code></a> function). Rust has a
<a href="https://doc.rust-lang.org/std/primitive.f32.html#method.rem_euclid" target="_blank"><code><span><span>rem_euclid</span></span></code></a>
function that helps with this. In the case when the player switches to the
opposite direction (e.g. left to right), either direction works. I decided to
arbitrarily* turn counter-clockwise.</p><p>Some things I added later were ‘hold space to boost’ (inspired by Ecco) and
automatic uprighting. If the player is idle, it seemed a bit weird to just
leave them hanging upside down in water so after a couple of seconds, I rotate
them back to their upright position. I quite liked the possibility of using
this for some tricky puzzle later in the game. Maybe there’s a spike-ridden
section that requires very fine turns and requires you to rotate back to your
upright position, rather than holding up and turning in a wider arc. That’s
pretty contrived, though.</p><p>One thing that caused me a headache was what to do at the surface of the water.
What was basically happening was the player was swimming past the waterline and
out of the liquid. They were then falling back down again when <code><span><span>GravityPhysics</span></span></code>
kicked in, flipping between the two. It was very glitchy. My solution to this
was to introduce some logic for
‘<a href="https://ell.stackexchange.com/questions/95478/bobbing-in-the-water" target="_blank">bobbing</a>’
on the water. I tried a few variations but eventually settled on a simple
approach that allowed the player to keep swimming up for a small amount of time
above their waterline but at a greatly reduced speed. After which, they’d drop
down (at the same speed) until below the waterline where they could ‘bob up’
again.</p><p>To control the swim speed and rate they turn in water, I added <code><span><span>swim_speed</span></span></code> and
<code><span><span>turn_rate</span></span></code> to my pre-existing <code><span><span>Agility</span></span></code> component that controls things like
the player’s foot speed and width of their jump arc.</p><a href="#walking-underwater"><h2 id="walking-underwater">Walking underwater</h2></a><p>I decided I wanted the player to be able to walk at the bottom of the liquid.
That’s kind of how it works in reality and it didn’t <em>seem</em> like it would be
hard to add. I basically distinguish between being ‘suspended’ in the liquid
and not (e.g. when walking at the bottom). When you’re not suspended, the
player controls fall through to the already existing walking/jumping controls
but with a few changes, mostly just slowing the player down and reducing their
jump velocity (using the <code><span><span>jump_scale_factor</span></span></code> I mentioned earlier). You also
can’t boost to go faster.</p><p>The slight difficulty here is that normally, gravity is pushing down on you,
which keeps you on the ground. If you swim down to the ground but then stop
pressing down, it doesn’t know you’re still ‘touching’ the ground because
there’s nothing pushing you into it each update (unless the liquid has negative
flow in the y-direction). Maybe this isn’t a problem for better engines than
mine, but my fix was to basically constantly apply a negative velocity of the
player’s swim speed to keep them anchored on the ground after reaching it. I
like this solution because it means if the liquid has a lot of upthrust - more
than the player’s swim speed - they won’t be able to ‘cheat’ and stick to the
ground when they shouldn’t be able to. Similarly, my solution for bobbing on
the water has a similar property. Once you’re pushed under the water, its flow
takes over and out-paces your swim speed.</p><p>A problem I ran into at this point was with accidentally killing the player.
When walking on the ground, i first reset the player’s rotation so they’re
upright, but if they’re too close to the ground (swimming parallel to it), this
can sometimes place the player entity inside the ground. I have some code that
tries to detect if the player has been crushed based on the magnitude of
collision response. This can sometimes trip and kill the player. Not good!</p><p>My solution (read: hack) for this is to give the player a ‘free pass’ from the
grim reaper for a single frame - the exact moment their rotation is reset. I
also re-position the player slightly to reduce the size of this collision and
hopefully prevent any …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tuzz.tech/blog/taking-the-plunge">https://tuzz.tech/blog/taking-the-plunge</a></em></p>]]>
            </description>
            <link>https://tuzz.tech/blog/taking-the-plunge</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661977</guid>
            <pubDate>Fri, 02 Oct 2020 12:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Fistful of States: More State Machine Patterns in Rust]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24661395">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://deislabs.io/posts/a-fistful-of-states/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/a-fistful-of-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Earlier this year, DeisLabs released Krustlet, a project to implement Kubelet
in Rust. <sup id="fnref:Fisher"><a href="#fn:Fisher">1</a></sup> <sup id="fnref:Squillace"><a href="#fn:Squillace">2</a></sup> Kubelet is the component of Kubernetes that
runs on each node which is assigned Pods by the control plane and runs them on
its node. Krustlet defines a flexible API in the <code>kubelet</code> crate, which allows
developers to build Kubelets to run new types of workloads. The project
includes two such examples, which can run Web Assembly workloads on WASI or
waSCC runtimes. <sup id="fnref:wasmtime"><a href="#fn:wasmtime">3</a></sup> <sup id="fnref:waSCC"><a href="#fn:waSCC">4</a></sup> Beyond this, I have been working to
develop a Rust Kubelet for traditional Linux containers using the Container
Runtime Interface (CRI). <sup id="fnref:krustlet-cri"><a href="#fn:krustlet-cri">5</a></sup> <sup id="fnref:CRI"><a href="#fn:CRI">6</a></sup></p>

<p>Over the last few releases, Krustlet has focused on expanding the functionality
of these Web Assembly Kubelets, such as adding support for init containers,
fixing small bugs, and log streaming. This, in turn, has built quite a bit of
interest in alternative workloads and node architectures on Kubernetes, as well
as demonstrated the many strengths of Rust for development of these types of
applications.</p>

<p>For the <code>v0.5.0</code> release, we turned our attention to the internal architecture
of Krustlet, in particular how Pods move through their lifecycle, how
developers write this logic, and how updates to the Kubernetes control plane
are handled. <sup id="fnref:Pod-Lifecycle"><a href="#fn:Pod-Lifecycle">7</a></sup> We settled upon a state machine implementation
which should result in fewer bugs and greater fault tolerance. This refactoring
resulted in substantial changes for consumers of our API; however we believe
this will result in code that is much easier to reason about and maintain. For
an excellent summary of these changes, and description of how you can migrate
code that depends on the <code>kubelet</code> crate, please see Taylor Thomas’ excellent
<a href="https://github.com/deislabs/krustlet/releases/tag/v0.5.0">Release Notes</a>.
In this post I will share a deep dive into our new architecture and the
development journey which led to it.</p>

<h2 id="the-trailhead">The Trailhead</h2>

<p>Before <code>v0.5.0</code>, developers wishing to implement a Kubelet using Krustlet
primarily needed to implement the <code>Provider</code> trait, which allowed them to write
methods for handling events like <code>add</code>, <code>delete</code>, and <code>logs</code> for Pods scheduled
to that node. This offered a lot of flexibility, but was a very low-level API.
We identified a number of issues with this architecture:</p>

<ul>
<li>The entire lifecycle of a Pod was defined in 1 or 2 monolithic methods of the
<code>Provider</code> trait. This resulted in messy code and a very poor understanding
of error handling in the many phases of a Pod’s lifecycle.</li>
<li>Pod and Container status patches to the Kubernetes control plane were
scattered throughout the codebase, both in the <code>kubelet</code> crate and the
<code>Provider</code> implementations. This made it very difficult to reason about what
was actually reported back to the user and when, and involved lot of repeated
code.</li>
<li>Unlike the Go Kubelet, if Krustlet encountered an error it would report the
error back to Kubernetes and then (most of the time) end execution of the
Pod. There was no built-in notion of the reconciliation loop that one expects
from Kubernetes.</li>
<li>We recognized that a lot of these issues were left to each developer to
solve, but were things that any Kubelet would need to handle. We wanted to
move this kind of logic into the <code>kubelet</code> crate, so that each provider did
not have to reinvent things.</li>
</ul>

<h2 id="our-mission">Our Mission</h2>

<p>At its core, Kubernetes relies on declarative (mostly immutable) manifests, and
controllers which run reconciliation loops to drive cluster state to match this
configuration. Kubelet is no exception to this, with its focus being
indivisible units of work, or Pods. Kubelet simply monitors for changes to Pods
that have been assigned to it by <code>kube-scheduler</code>, and runs a loop to attempt
to run this work on its node. In fact, I would describe Kubelet as no different
from any other Kubernetes controller, except that it has the additional
first-class capability for streaming logs and exec sessions. However these
capabilities, as they are implemented in Krustlet, are orthogonal to this
discussion.</p>

<p>Our goal with this rewrite was to ensure that Krustlet would mirror the official
Kubelet’s behavior as closely as possible. We found that many details about
this behavior are undocumented, and spent considerable time running the
application to infer its behavior and inspecting the Go source code. Our
understanding is as follows:</p>

<ul>
<li>The Kubelet watches for Events on Pods that have been scheduled to it by
<code>kube-scheduler</code>.</li>
<li>When a Pod is added, the Kubelet enters a control loop to attempt to run the
Pod which only exits when the Pod is <code>Completed</code> (all containers
exit successfully) or <code>Terminated</code> (Pod is marked for deletion via the
control plane and execution is interrupted).</li>
<li>Within the control loop, there are various steps such as <code>Image Pull</code>,
<code>Starting</code>, etc., as well as back-off steps which wait some time before
retrying the Pod. At each of these steps, the Kubelet updates the control
plane.</li>
</ul>

<p>We recognized this pretty quickly as a finite-state machine design pattern,
which consists of infallible state handlers and valid state transitions. This
allows us to address the issues mentioned above:</p>

<ul>
<li>Break up the <code>Provider</code> trait methods for running the Pod into short,
single-focus state handler methods.</li>
<li>Consolidate status patch code to where a Pod enters a given state.</li>
<li>Include error and back-off states in the state graph, and only stop
attempting to execute a Pod on <code>Terminated</code> or <code>Complete</code>.</li>
<li>Move as much of this logic into <code>kubelet</code> as possible so that providers need
only focus on implementing the state handlers.
<br></li>
</ul>

<p>With this architecture it becomes very easy to understand the behavior of the
application, and strengthens our confidence that the application will not enter
undefined behavior. In addition, we felt that Rust would allow us to achieve
our goals while presenting an elegant API to developers, and with full
compile-time enforcement of our state machine rules.</p>

<h2 id="our-animal-guide">Our Animal Guide</h2>

<p>When first discussing the requirements of our state machine, and the daunting
task of integrating it with the existing Krustlet codebase, we recalled an
excellent blog post,
<a href="https://hoverbear.org/blog/rust-state-machine-pattern/">Pretty State Machine Patterns in Rust</a>,
by Ana Hobden (hoverbear), which I think has inspired a lot of Rust developers.
The post explores patterns in Rust for implementing state machines which
satisfy a number of constraints and leverage Rust’s type system. I encourage
you to read the original post, but for the sake of this discussion I will
paraphrase the final design pattern here:</p>

<pre><code>struct StateMachine&lt;S&gt; {
    state: S,
}

struct StateA;

impl StateMachine&lt;StateA&gt; {
    fn new() -&gt; Self {
        StateMachine {
            state: StateA
        }
    }
}

struct StateB;

impl From&lt;StateMachine&lt;StateA&gt;&gt; for StateMachine&lt;StateB&gt; {
    fn from(val: StateMachine&lt;StateA&gt;) -&gt; StateMachine&lt;StateB&gt; {
        StateMachine {
            state: StateB 
        }
    }
}

struct StateC;

impl From&lt;StateMachine&lt;StateB&gt;&gt; for StateMachine&lt;StateC&gt; {
    fn from(val: StateMachine&lt;StateB&gt;) -&gt; StateMachine&lt;StateC&gt; {
        StateMachine {
            state: StateC 
        }
    }
}

fn main() {
    let in_state_a = StateMachine::new();

    // Does not compile because `StateC` is not `From&lt;StateMachine&lt;StateB&gt;&gt;`.
    // let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_a);

    let in_state_b = StateMachine::&lt;StateB&gt;::from(in_state_a);

    // Does not compile because `in_state_a` was moved in the line above.
    // let in_state_b_again = StateMachine::&lt;StateB&gt;::from(in_state_a);

    let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_b);
}
</code></pre>

<p>Ana introduces a number of requirements for a good state machine
implementation, and achieves them with concise and easily interpretable code.
In particular, these requirements (some based on the definition of a state
machine, and some on ergonomics) were a high priority for us:</p>

<ul>
<li>One state at a time.</li>
<li>Capability for shared state.</li>
<li>Only explicitly defined transitions should be permitted.</li>
<li>Any error messages should be easy to understand.</li>
<li>As many errors as possible should be identified at <strong>compile-time</strong>.</li>
</ul>

<p>In the next section I will discuss some additional requirements that we
introduced and how these impacted the solution. In particular, we relaxed some
of Ana’s goals in exchange for greater flexibility, while satisfying those
listed above.</p>

<h2 id="tribulation">Tribulation</h2>

<p>We were off to a great start, but it was time to consider how we want
downstream developers to interact with our new state machine API. In
particular, while the Kubelets we are familiar with all follow roughly the same
Pod lifecycle, we wanted developers to be able to implement arbitrary state
machines for their Kubelet. For example, some workloads or architectures may
need to have additional provisioning states for infrastructure or data, or
to introduce post-run states for proper garbage collection of resources.
Additionally, it felt like an anti-pattern to have a parent method (<code>main</code> in
the example above) which defines the logic for progressing through the states,
as this felt like having two sources of truth and was not something we could
implement on behalf of our downstream developers for arbitrary state machines.
Ana had discussed how to hold the state machine in a parent structure using an
<code>enum</code>, but it felt clunky to introduce large match statements which could
introduce runtime errors.</p>

<p>We knew that to allow arbitrary state machines we would need a <code>State</code> trait to
mark types as valid states. We felt that it would be possible for this trait to
have a <code>next()</code> method which runs the state and then returns the next <code>State</code>
to transition to, and we wanted our code to be able to simply call <code>next()</code>
repeatedly to drive the machine to completion. This pattern, we soon found,
introduced a number of challenges.</p>

<pre><code>/// Rough pseudocode of our plan.

trait State {
    /// Do work for this state and return next state.
    async fn next(self) -&gt; impl State;
}

fn drive_state_machine(mut state: impl State) {
    loop {
        state = state.next().await;
    }
}
</code></pre>

<h3 id="what-does-next-return">What does <code>next()</code> return?</h3>

<p>Within our loop, we are repeatedly overwriting a local variable with
<em>different</em> types that all implement <code>State</code>. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/a-fistful-of-states/">https://deislabs.io/posts/a-fistful-of-states/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/a-fistful-of-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661395</guid>
            <pubDate>Fri, 02 Oct 2020 11:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Euro [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661368">thread link</a>) | @user1241320
<br/>
October 2, 2020 | https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf | <a href="https://web.archive.org/web/*/https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.ecb.europa.eu/pub/pdf/other/Report_on_a_digital_euro~4d7268b458.en.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661368</guid>
            <pubDate>Fri, 02 Oct 2020 11:13:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privacy is the most important concept of our time]]>
            </title>
            <description>
<![CDATA[
Score 416 | Comments 198 (<a href="https://news.ycombinator.com/item?id=24661271">thread link</a>) | @umilegenio
<br/>
October 2, 2020 | https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/ | <a href="https://web.archive.org/web/*/https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-25770" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p><em>In case you are coming from Hacker News and are confused about some comments, be aware that I updated the essay to deal with some criticism</em>.</p>



<p>The title is not hyperbole. I do think that privacy is the most important concept of our time. Let me tell you why:</p>



<ul><li><strong>internet is not a virtual world anymore</strong>, it is a dimension that permeates our lives; we work, socialize and get informed through the internet</li><li><strong>our society is more diverse</strong>; we have some things in common with our neighbors and some with separate communities</li><li><strong>privacy is integral to separate the</strong> <strong>different parts of our lives</strong>; once the separation could be just physical and accidental (i.e., you live here and work there), now it must be built intentionally because there are no natural barriers in information spreading</li></ul>



<p>In short, since our lives are more complex, both socially and technologically, we need to evolve our understanding of rules and norms, too. </p>



<p>I have always believed in the importance of privacy, but I felt that common definitions (e.g., <em>the right to be left alone</em>) were lacking. In fact, I think that the whole conceptualization of privacy as simply a right of an individual and regarding private information as partial and limiting.</p>



<p>Think about this: the government can send policemen to surveil you and everybody they deem interesting. However, it can do this only for few people. <strong>This limitation is due to physical constraints, not legal ones</strong>. There is a limited number of policemen and you would notice if there was a police car in front of each house of the neighborhood. <strong>This is not true for internet communications: the government can spy everyone at once and you would never notice</strong>. As many whistleblowers have revealed, this is what the NSA has actually done.</p>



<p>So, the changes in reality affect privacy directly but may also affect every single all our rights indirectly. Privacy is the fundamental principle that must respond to these changes.</p>



<p>You might say that then, maybe, I am not really thinking about privacy, but rather something else. That might be true, so let’s not talk about privacy, instead let’s talk about <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco">Ur-Privacy</a>, the principles of any possible concept of privacy. Take this essay as the opinion of a random guy that cares about the issue.</p>



<div><h2>What is Ur-Privacy</h2><p><em>A few principles for privacy</em></p></div>







<p><strong>Privacy is not just something we need to separate our private live from our public live. It is necessary to separate our private live, the communities we belong to and the public sphere from each other.</strong></p>



<p><strong>Privacy is about boundaries.</strong> It is not about hiding something but allowing to create a space with rules decided by its members. I like to compare it to borders. Some people say that borders are a restriction, something that limit freedom of movement and we do not need in the contemporary world. As if they were arbitrary obstacles put there by petty people. It almost makes sense if you do not think about them, after all you are actually stopped at a border.</p>



<p>However, that is not true, that is not why they exist. Borders delimit the area that a certain state control, an area where a specific set of rules and laws applies. There was a time before borders, in fact most of human history did not have clear borders. It was not a time of freedom, but anarchy, where bands of barbarians could roam into your home and pillage everything.</p>



<p>In this context is also important to remember that before the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> modern European states were plagued by continual wars. The short version is that this was due to the combination of two facts:</p>



<ul><li>modernity begets differences, different kings choose different religions<sup><a id="link_1" href="#note_1" data-type="internal" data-id="#note_1">1</a></sup> and separated societies</li><li>however, the legitimacy of kings was still based on shared medieval ideals, like the concept of divine rule</li></ul>



<p>In short, the issue was not that <strong>leaders wanted to make war all the time, they needed to do so</strong> because the legitimacy of their power depended, at least on some level, to what the rest of the European world was doing. If you claim to be a divine king there better be agreement on what the divine is, otherwise a guy that picks a different religion can also pick a different king. And, according to some, he could be a legitimate king. To change the situation this peace treaty established the principle that the internal affairs of a state are the exclusive interest of said state.</p>



<p>The connection with privacy is this: without clear rules on what is private and what is public, nobody knows which stuff belongs to whom. This means chaos and often that all belong to the strongest. Somebody might say that what you do in private, it is not private at all but political. It concerns the society at large. Therefore, it must be regulated according to their rules.</p>



<p><strong>Privacy does not imply hiding the truth.</strong> <strong>Meaning depends on context, therefore everything should be considered within its context.</strong></p>



<p><strong>Privacy is about control</strong>. Without privacy we cannot decide for ourselves how to live our lives. If there is no privacy, all become public. Whoever has more power and an interest can affect your life according to their own rules. Then, I have to care about what other people think, otherwise they will control how I can behave. As before the peace of Westphalia, the issue is not that other people are bad, <em>they have to do it</em>. When everything is subject to public scrutiny, you either control the rules and judge others or you are judged and controlled by others.</p>



<p>Think about this way: we say a lot of things in our private lives that are not meant to be taken literally. In private we say something and then we add: <em>you know what I mean</em>. And that is actually true. We can do that because the people we talk to in private know us; they understand the context in which our words must be understood. And even more importantly: they care about us; they do not want to intentionally misunderstand us.</p>



<p>When I was a child I would sometimes say and think that I wanted to kill my brother. I did not mean it literally and everybody knew it. If I said the same thing now, in public, to somebody that does not know me, the phrase would be different. It would be a threat.</p>



<p>Why is that? They are the exact same words. You know why, of course. I am different and the context is different. The real meaning of something, whether an action or a word, is not absolute, in most cases it is relative. When we speak in public, we share a different context, therefore our words have a different meaning. </p>



<p>So even if I say something as a hyperbole, or something that can be construed as an implicit threat (e.g., <em>they must be stopped at all costs</em>!), they might protest. You might say that they are overreacting, that it was just a joke, but how can they be sure of it? <strong>They do not know me.</strong> It is true that acts of violence are prepared by violent words. Even if you are unsure if something is really violent, you have to take a stand. You have to make clear that any attack against you is not permissible. Otherwise, <a href="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings" data-type="URL" data-id="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings">somebody, maybe a crazy guy, might think that it is permissible and the right course of action</a>. Somebody might feel legitimated to take your land and kingdom.</p>



<p><strong>Privacy is not just needed to protect us from the government or exceptional situations. It is about understanding the rules that applies to every aspect of our life so that they can be fair for everybody.</strong></p>



<p><strong>Privacy is about everyday life</strong>. The issue is not simply that something we say can be considered a threat. When you are communicating with someone you need to be able to understand them. Communication requires a shared understanding at some level.</p>



<p>The easiest example to understand this are work discussions. When we talk with people that work in our field, we can communicate more easily the impact of a choice. This goes beyond the ability to use technical terminology: we know which are the main things to care about. The same discussion with our bosses would be different. Even to make them understand the basic strength and weaknesses would be more challenging.</p>



<p>Now imagine being forced to communicate everything you do in the most general terms to people that do not care about you, because <strong>everybody can see you</strong>. So, they can use any piece of information for their own needs. This could mean a policeman investigating you. It could also mean a company making you pay more for a pair sneakers, because they know you have much disposable income you have and that you really love sneakers.</p>



<p>We need privacy to be aware of what is happening to us. It is too much to demand we know how other people interpret what we say. However, it is not excessive to ask that we can control what is shared about us.</p>



<div><h2>Privacy Affects Everything</h2><p><em>Defending privacy would require all-around changes</em></p></div>







<p><strong>Privacy is the most important concept of our time, because it influences everything else. Without privacy we do not know what rules applies. Our lives will be judged according to the rules of somebody else</strong> <strong>in ways we cannot even imagine.</strong></p>



<p>We cannot discuss all of the possible implications of privacy on other rights, so let’s see the example of <em>freedom of speech</em>. Of course, sometimes you can also be judged for who you are: your religion or lack thereof, political opinion or sexual orientation.</p>



<blockquote><p>Give me six lines written by the most honest man, and there I will find something to hang him.</p><cite>Cardinal Richelieu</cite></blockquote>



<p>People lost jobs and had their lives ruined, because the mob judged something they said in private in a different way from what they expected. And they paid a price. You might say: that was fair. We might judge ourselves by our intentions, but others by their actions, which are real and objective.</p>







<p>I, for once, disagree with XKCD and this view. There are a couple of different issues here:</p>



<ul><li>how we should react to speech we disagree with</li><li>what was meant to be shared among friends was taken out of context and made public</li></ul>



<p>This complicates the whole matter. At a first glance the first …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</a></em></p>]]>
            </description>
            <link>https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661271</guid>
            <pubDate>Fri, 02 Oct 2020 10:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare – two years later]]>
            </title>
            <description>
<![CDATA[
Score 365 | Comments 320 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GNU stow to manage dotfiles]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660912">thread link</a>) | @mathieuh
<br/>
October 2, 2020 | http://mathieuhendey.com/posts/stowing-dotfiles/ | <a href="https://web.archive.org/web/*/http://mathieuhendey.com/posts/stowing-dotfiles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>I recently found about a piece of GNU software called Stow<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p>
<p>It lets you manage your dotfiles in a really simple way, meaning you can put them in git and have them easily transferable between machines.</p>
<p>What it will do is let you move all your dotfiles into a directory, and then symlink them back into your home directory with a simple command.</p>
<p>From the man page<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>:</p>
<blockquote>
<p>Stow is a symlink farm manager which takes distinct sets of software and/or data located in separate
directories on the filesystem, and makes them all appear to be installed in a single directory tree.</p>
</blockquote>
<h2 id="set-up">Set up</h2>
<p>First you’ll need to install <code>Stow</code> using your package manager of choice. I use a Mac so it’s just:</p>
<p>Then you’ll need to create a directory in which to store your dotfiles, and directories within it to keep them separate.</p>
<div><pre><code data-lang="sh">mkdir ~/dotfiles;
mkdir ~/dotfiles/git;
mkdir ~/dotfiles/zsh;
</code></pre></div><p>Move your dotfiles into the relevant directories:</p>
<div><pre><code data-lang="sh">mv ~/.gitconfig ~/dotfiles/git;
mv ~/.zshrc ~/dotfiles/zsh;
mv ~/.zshenv ~/dotfiles/zsh;
</code></pre></div><h2 id="the-magic-part">The magic part</h2>
<p>Now here’s where <code>stow</code> comes in. Stow will, given a source directory and a destination directory, create symlinks in the destination directory to all the files in the source directory.</p>
<p>From within <code>~/dotfiles</code></p>
<p>Here’s an explanation of what that command is doing:</p>
<ol>
<li>
<p><code>-R</code> means “restow”. This will overwrite your symlinks, say if you’ve updated your dotfiles on another machine and want to sync them to your current machine From the manpage:</p>
<blockquote>
<p>Restow packages (first unstow, then stow again). This is useful for pruning obsolete symlinks
from the target tree after updating the software in a package.</p>
</blockquote>
</li>
<li>
<p><code>-t ~</code> is the target directory. This is where the symlinks will be created.</p>
</li>
<li>
<p>The final argument is the directory containing the files to be symlinked to.</p>
</li>
</ol>
<p>Putting it all together, running <code>stow -R -t ~ git</code> will create a symlink in your home directory to <code>~/dotfiles/git/.gitconfig</code>.</p>
<p>And it’s that simple.</p>
<p>Now you can <code>git init</code> inside your <code>~/dotfiles</code> directory, push them up to your remote and have them immediately available on all your machines.</p>
<p>Here’s a simple bit of bash that will stow all the dotfiles in your home directory from your <code>~/dotfiles</code> repo:</p>
<div><pre><code data-lang="sh"><span>for</span> d in */ ; <span>do</span>
    stow -R -t ~ <span>"</span>$d<span>"</span>
<span>done</span>
</code></pre></div><p>For reference, <a href="https://github.com/mathieuhendey/dotfiles">here are my dotfiles on GitHub</a>.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://www.gnu.org/software/stow/">https://www.gnu.org/software/stow/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://linux.die.net/man/8/stow">https://linux.die.net/man/8/stow</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

    </div></div>]]>
            </description>
            <link>http://mathieuhendey.com/posts/stowing-dotfiles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660912</guid>
            <pubDate>Fri, 02 Oct 2020 10:03:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js malware caught posting IPs, username, and device info on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24660810">thread link</a>) | @axsharma
<br/>
October 2, 2020 | https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/ | <a href="https://web.archive.org/web/*/https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="683" src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" alt="red and blue hearts illustration" loading="lazy" srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            




<p>Multiple NodeJS packages laden with malicious code have been spotted on npm registry.</p>



<p>These “typosquatting” packages served no purpose other than collecting data from the user’s device and broadcasting it on public GitHub pages.</p>



<p>The findings were spotted by Sonatype’s <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">automated malware detection systems</a> and further investigated by the company’s Security Research team which includes me. </p>



<p>The packages previously present on the open source npm registry included:</p>



<ol><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/electorn" target="_blank">electorn</a> (intentional misspelling of a legitimate package “electron”)</li><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/loadyaml" target="_blank">loadyaml</a> </li><li>loadyml</li><li>lodashs (intentional misspelling of a legitimate package “lodash”)</li></ol>



<p>All four packages were published by the same user “simplelive12” and have now been removed, with the first two having been taken down by npm as of October 1, 2020. The previous two packages were unpublished by the author themselves.</p>



<p>Once installed, <code>electorn</code> ran a script in the background <strong>every</strong> <strong>hour</strong> which collected the logged-in user’s IP, geolocation data, username, path to home directory, and CPU model information.</p>



<figure><img loading="lazy" width="1024" height="356" src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>The malicious code within <code>electorn</code> and 3 other identical packages which exfiltrated user information</figcaption></figure>



<p>This information, part of which constitutes the device “fingerprint” was uploaded and published on <a rel="noreferrer noopener" href="http://web.archive.org/web/20201001065601/https://github.com/h4ppyl1ve/collect/issues/4" target="_blank">GitHub</a> in real-time.</p>



<p>Some of the information being published is base64-encoded but this can be trivially decoded by anyone who has access to it:</p>



<figure><img loading="lazy" width="1024" height="488" src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Sonatype’s Security Research team has accounted for these malicious packages into their products, and had notified both npm and GitHub teams of the malicious activity stemming from the components. This led to the takedown of these malicious packages. </p>



<p>To this date, all 4 packages have scored a little over <strong>400</strong> total downloads.</p>



<p>It is not exactly clear what was the purpose of collecting this data and why was it being published on the web for the world to see, however, incidents like these highlight the potential of typosquatting attacks on the open-source ecosystem.</p>



<p>We can only imagine what the next possible version of these packages could have been capable of – possibly carrying out even more sinister activities. </p>



<p>By tricking an unsuspecting developer into mistakenly installing a misspelled package, attackers can push their malicious code “downstream” into any other open-source projects that use the misspelled malicious component as a transitive dependency.</p>



<p>Adopting DevSecOps best practices and building security early on into your software development lifecycle can prevent “counterfeit components” such as electorn and loadyaml from entering, and thriving in your software supply chains.</p>



<p>The complete research findings are available on the <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">Sonatype blog</a>.</p>
                <div>
                    <h3>About the author</h3>
                                        
        <div>

                <p><a href="https://securityreport.com/author/ax-sharma/"><img alt="" src="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=150&amp;d=retro&amp;r=pg" srcset="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=300&amp;d=retro&amp;r=pg 2x" height="150" width="150" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
                </p>
                <div>
                    <h4>
                        <a href="https://securityreport.com/author/ax-sharma/">Ax Sharma</a>
                    </h4>

                    
                    
                                            <p>
                        <a href="https://axsharma.com/" target="_blank">https://axsharma.com/</a>
                        </p>
                                        <div>
                        <p>Ax Sharma is a Security Researcher, Engineer, and Tech Columnist. His works and expert analyses have frequently been featured by leading media outlets like Fortune, The Register, TechRepublic, CIO, etc.</p>
<p>Ax’s expertise lies in vulnerability research, reverse engineering, software development, and web app security. He’s an active community member of the OWASP Foundation and the British Association of Journalists (BAJ).</p>
<p>Send any tips via email or Twitter DM.</p>
                    </div>
                    
                                    </div>
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660810</guid>
            <pubDate>Fri, 02 Oct 2020 09:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Looking at the experience of black Britons through an American lens]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 354 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it … I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country—it cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country’s flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country’s does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label “black British.” For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)—about the same number as white students. But black Caribbean students are significantly less likely to do so—while those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label “black British.” But we need to invest it with the nuance consonant with its reality—and to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism—rather than law, medicine or finance—if you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country—or the black community—really benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison’s iconic protagonist, is “invisible because no one wants to see him.”</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people—a narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Test to Figure Out Why You Feel Down Lately]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660666">thread link</a>) | @azarai
<br/>
October 2, 2020 | https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test | <a href="https://web.archive.org/web/*/https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                                                            
                                                                         <p>Feeling down lately?</p>
<p>But you don’t know why?</p>
<p>This quick test helps you to figure it out and gives you tips on getting up again.</p>
<h2>Quick Test</h2>
<blockquote>
<p>Did you sleep 7-8 hours a night for most of the last 7 days?</p>
</blockquote>
<p>Sleep is essential, and we should not skip on that. While we sleep, our brain processes the day and also cleans itself of toxic waste (<a href="https://www.scientificamerican.com/article/deep-sleep-gives-your-brain-a-deep-clean1/#:~:text=Why%20sleep%20has%20restorative%E2%80%94or,is%20hugely%20improved%20during%20sleep.">see</a>)</p>
<blockquote>
<p>Did you drink less than 10 drinks of alcohol in the last 7 days?</p>
</blockquote>
<p>There is nothing to say against a drink or two. But if you take it too far, you start to feel down, groggy and more. Moreover, alcohol can be addictive, and you don’t want to become an alcoholic.</p>
<blockquote>
<p>Did you drink too much caffeine in the last 7 days? (Coffee, black tea, energy drinks, etc.)</p>
</blockquote>
<p>Caffeine is a short energy booster, but it comes with downsides too. It blocks the body’s desire to rest for a short time, but then your body is twice as tired, wanting to rest.</p>
<p>Now, if you drink caffeine again, you start a vicious cycle. You’ll only feel productive when you got your dose of caffeine. Otherwise, you feel tired again.</p>
<p>Over time you need to consume more and more caffeine to even get the effect.</p>
<p>Rest. Your body needs rest, and you should give it.</p>
<blockquote>
<p>Do you think you’re eating healthy in the last 7 days?</p>
</blockquote>
<p>Your body needs proper nutrition to function.</p>
<p>A diet of chips, chocolate bars, ice cream, or fast food is not the right thing to fuel your body the energy it needs.</p>
<p>Once in a while, it is fine but don’t thrive on it.</p>
<blockquote>
<p>Have you gone outside in the last 7 days?</p>
</blockquote>
<p>Pandemic here, pandemic there. But even without it, many of us don’t go outside enough—especially people working from home.</p>
<p>But we need movement and fresh air. So, enjoy a long walk in nature, or a park or forest near you. Or just stroll through your city.</p>
<blockquote>
<p>Have you exercised in the last 7 days?</p>
</blockquote>
<p>Move your ass. Doesn’t matter what kind of exercise you like, do it. Movement is king.</p>
<p>Not only will it lift your mood. It will also help you to think fresh and clear again.</p>
<blockquote>
<p>Have you meditated in the last 7 days? Or journaled, etc.</p>
</blockquote>
<p>Meditation is a great tool to clear your thoughts and calming down. But you don’t need to sit still.</p>
<p>You can do <a href="https://mindfuldevmag.com/issues/issue-3-mindfulness-for-skeptics/walking-meditation">walking meditations</a> or journaling or other kinds of activities that help you to focus and clear your mind.</p>
<blockquote>
<p>Have you done anything to actively relax?</p>
</blockquote>
<p>This can be taking massages, doing yoga, taking a hot bath, sauna, or anything else that helps you relax.</p>
<p>Take your time and do it on purpose.</p>
<p>Btw watching tv might feel like relaxation, but it mostly is not. Our brain’s on alert mode.</p>
<p>Can’t decide on one?</p>
<p>Go for a walk in the next park.</p>
<blockquote>
<p>Have you talked to other people or met with your friends? Preferably IRL</p>
</blockquote>
<p>Even the most introverted of us love to talk to somebody. Sure, I can go without days of talking to somebody except my family. But even that has its limit.</p>
<p>Talk or, better yet, meet your friends, and have a great time. None handy at the moment? Talk to your neighbor, cashiers, or anybody else you can have interactions with.</p>
<blockquote>
<p>If you’re in a relationship, are you with the right person?</p>
</blockquote>
<p>If your relationship sucks, your mood will drop too. But if it is a loveable and stable one, it can lift you up and help through darker times.</p>
<blockquote>
<p>Have you helped someone in the last days with something you’re good at?</p>
</blockquote>
<p>Believe it or not. It’s humans to help others and feel good about it at the same time. It’s totally refreshing and re-energizing.</p>
<blockquote>
<p>Have you made any new experiences in the last month?</p>
</blockquote>
<p>Doing the same old from day to day, week to week, and month to month can drag you down. It feels like a rut. Being stuck.</p>
<p>Energize your life and go for new experiences. Go for a hike, visit a new city, test a new restaurant. Whatever it is, pick something new.</p>
<blockquote>
<p>Are you working on stuff that’s meaningful to you?</p>
</blockquote>
<p>Does your job or the things you work on in your spare time give you enough meaning? Or does it feel like working for the devil?</p>
<p>Does it fulfill you?</p>
<blockquote>
<p>Does your current situation allow you to do what you really want to do in life?</p>
</blockquote>
<p>If not, think about what you could start to change? What are thing top 3 things holding you back?</p>
<p>How could you remove them?</p>
<blockquote>
<p>Did you create anything in the last week?</p>
</blockquote>
<p>Does not matter what it is. Maybe you draw comics or paint art, make music, build websites, or whatever.</p>
<p>Let your creativity go wild, and your mood will go up.</p>
<blockquote>
<p>Are your working on too many things at the same time?</p>
</blockquote>
<p>Pursuing multiple things at the same time makes you feel like nothing moves forward. Often paired with getting frustrated and then feeling down.</p>
<p>Set your focus on one thing for now and work on that. The down feelings will fade.</p>
<blockquote>
<p>Do you have the feeling that you accomplished something?</p>
</blockquote>
<p>Sometimes we hustle and hustle but have the feeling we got nowhere. Just being tired and running towards a burnout.</p>
<p>Think about what small things you could add that make you feel to have accomplished something? Must not be work-related. It could also be private things you pushed for years in front of you.</p>
<h2>All Positive But Still Feeling Down?</h2>
<p>If you answered all questions positively and are still feeling down, it might be time to visit a therapist. There is no shame in that. We all need help sometimes.</p>
<p>Find someone near you or use an online service like <a href="https://www.talkspace.com/">talkspace</a> or more on this <a href="https://www.e-counseling.com/online-therapy/">list of online therapy services</a>.</p>
                                     
                                     <hr>
                                     
                                                                          
                                     
                                       
                                       
                            </div>

                    </div></div>]]>
            </description>
            <link>https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660666</guid>
            <pubDate>Fri, 02 Oct 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a lay-down desk]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660610">thread link</a>) | @polote
<br/>
October 2, 2020 | https://blog.luap.info/i-built-a-lay-down-desk.html | <a href="https://web.archive.org/web/*/https://blog.luap.info/i-built-a-lay-down-desk.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>After spending part of the last 12 months <a href="https://blog.luap.info/travelling-with-24-monitors.html">travelling in Europe</a> I'm now settling down around Paris and I need to adapt my multi-screens setup.</p>
<p>You probably have seen an ads for <a href="https://altwork.com/">the altwork desk</a> <em>a $7000 desk that let you work laying down</em>. Spending a big part of my day in front of a computer I want to have the most comfortable position as possible, but well $7000 + $1000 for the delivery seems so expensive. There is also <a href="http://www.ergoquest.com/">this company</a> but this is still about $4000 all included. Let's be creative and build it myself.</p>
<p>Here is the result</p>
<p><img alt="complete desk" src="https://blog.luap.info/static/desk/complete.jpg"> </p>
<p>The things I have to take into account are:</p>
<ul>
<li>
<p>I have three monitors</p>
</li>
<li>
<p>I have no diy tools</p>
</li>
<li>
<p>I want a laying down position</p>
</li>
<li>
<p>This should be easy to use</p>
</li>
<li>
<p>This should be light and not take too much space</p>
</li>
<li>
<p>I have only a bike to move the parts</p>
</li>
<li>
<p>I haven't found anyone who has done something similar and so don't really have examples</p>
</li>
</ul>
<p>So instead of doing the waterfall way I decided to go the agile way and to not do any plans, I didn't know what to expect, so let's do it step by step and see how it goes</p>
<h2>Take care of the chair</h2>
<p>There are several options:</p>
<ol>
<li>
<p>Built a chair from scratch including the 'mattress' part</p>
</li>
<li>
<p>Use a reclined chair</p>
</li>
<li>
<p>Adapt a chair</p>
</li>
</ol>
<p>The issue with the first option is that I will not be sure of the result, is it going to be comfortable ? How I'm going to wash the seat covers ? I have no idea of the things to take into account for building a comfortable chair.</p>
<p>Reclined chairs are great but they are very heavy (except the garden ones but not very comfortable) and expensive. So again let's be creative, I got inspired by <a href="https://www.ikeahackers.net/2017/04/poang-gravity-recliner.html">this</a> and <a href="https://www.ikeahackers.net/2020/04/remove-poang-arms.html">this</a> ikea hacks which use a IKEA POANG chair and transform it into a reclined chair.</p>
<p>Here is the result :</p>
<p><img alt="ikea poang adaptation" src="https://blog.luap.info/static/desk/chair.jpg"></p>
<p>The chair is 69 euro, I had to buy three cushion to extend it</p>
<p>The most complex part was to do 7km with the chair on a bike. I do not recommend doing the same, particularly because I have done it on a rainy day but well a bit of challenge in my life is always welcome!</p>
<p><img alt="ikea bike" src="https://blog.luap.info/static/desk/ikea_bike.jpg"></p>
<p>Great, the chair is comfortable, let's do something for the desk part.</p>
<h2>What structure for the desk</h2>
<p>The biggest issue you are going to have with the lay down position, is that the desk is going to be on your legs and you cant 'enter' or 'leave' the desk if you can't move the desk. So you need the 'desk' part to be dynamic from the 'chair' part.</p>
<p>I had two ideas for that, either the Altwork way, the structure goes above your head and can incline, or the the base is on the side and the desk can move somewhere (writing that, having the desk in front of me, I wonder if having the base where the foot are is not an even better solution ? Damn, too late). Having the base on the side seems better because it would be smaller and lighter and also you can balance the weight much better. But the structure also needs to be more rigid and I need to find a way to incline the desk, anyway I haven't found a way to do it :(, after a night of thinking I went the altwork way.</p>
<p>There are two parts to design:</p>
<ol>
<li>
<p>The base + the incline system</p>
</li>
<li>
<p>The desk + the screen supports</p>
</li>
</ol>
<h3>1. Base + incline system</h3>
<p>The base is pretty standard, you need something strong enough so that it can suppot the whole thing. At that point I still didn't know the weight of the complete platform so I didn't know how strong it should be. After a few failing choices, I ended up with a main pole of 7cm x 7cm.</p>
<p>Now the complex part, how to design the rotation part ? How heavy is going to be the rest of desk ? How much does the desk need to move so that I can 'enter' the desk ? So many questions I didnt have an answer for.</p>
<p>So let's try something and see how it goes, I bought an <a href="https://www.amazon.fr/gp/product/B00H8SZ87W">gaz actuator on Amazon</a> which can support 70kg with a range of 31cm, it is built for cars and pretty cheap, 19euro. Actually 70kg is a lot. So at least I have a some freedom on the weight of the structure.</p>
<p>I had two issues with the actuator:</p>
<ul>
<li>70kg IS A LOT, it is so much that when I was fixing it on the wood of the base, it was breaking the wood. The best would be to have an iron piece that I can fix to the wood but I didnt have the tools for that so I used stronger woods but this is still fragile. </li>
</ul>
<p><img alt="fixation verrin" src="https://blog.luap.info/static/desk/fixation_verrin.jpg"></p>
<ul>
<li>The desk follows a circular trajectory when you move it up and down. As a result the barycenter of the structure changes depending on the Y position of the 'desk part' and so there is more strength applied on the actuator when it is up than when it is down. So basically the desk will not stay by itself when in the up position.  I need to find a way to get the desk in the up position.</li>
</ul>
<p>I'm not really proud of the way I've done it, but it somewhat works. I've built a piece of wood that inserts itself in the area between the two poles where the actuator is. There is a counterweight which drags the piece into the zone when in up position, and when I want to release it, I just need to pull on the rope. (I think I will replace the actuator with a real electric actuator when the current system breaks so that I can control the movement, it is about 120euro)</p>
<p><img alt="system block" src="https://blog.luap.info/static/desk/blocking_system.jpg"></p>
<h3>2. Desk + screens support</h3>
<p>I bought a chipboard plate of 80cm x 120cm, and cut some space for my body</p>
<p><img alt="plaque bois" src="https://blog.luap.info/static/desk/agglo.jpg"> </p>
<p>This is pretty solid, so I can directly screw this plate to the pole and we have a desk surface</p>
<p><img alt="plaque bureau" src="https://blog.luap.info/static/desk/bureau_with_plaque.jpg"></p>
<p>For holding the monitors I did something pretty basic, I created a box for each screen. Then comes the position of the screen, how to know the position of each screen ? I didnt know how to know it beforehand, so I just created dynamic arms and adjusted them while in front of the screens</p>
<p><img alt="support monitor" src="https://blog.luap.info/static/desk/support_monitor.jpg"></p>
<h2>Next steps</h2>
<p>This is only a few days old so I can't really make a feedback but there are already a few things that I need to fix</p>
<ul>
<li>
<p>I can't use a mouse anymore, as the mouse would fall down, I'm probably going to replace it by a trackball</p>
</li>
<li>
<p>I need to invest in an ergonomic keyboard to get really comfortable, probably going to buy the kenesis advantage 2, but this is expensive !</p>
</li>
</ul>
<p>Here is a video of the complete desk:</p>
<video controls="">
  <source src="https://blog.luap.info/static/desk/video.mp4" type="video/mp4">
</video>

<h2>Conclusion</h2>
<p>When you want to build this kind of structure, I'm not sure you can plan everything beforehand, there are always things that will happen that you didn't expect, like when you code: if you want to modify the actuator when the 60kg setup is mounted how do you do ? (I have done it 6 times) When your base can't support the weight because it lacks one screw and you need to unmount everything what do you do ? ...</p>
<p>I'm really annoyed by the actuator part, I hope I will find something more reliable</p>
<p>Overall it cost me :</p>
<ul>
<li>
<p>45 euro for tools</p>
</li>
<li>
<p>130 euro for wood pieces, screws, joins, ...</p>
</li>
<li>
<p>110 euro for the IKEA chair + cushions</p>
</li>
</ul>
<p>and I spent 26 hours working, excluding the transport and the time shopping for pieces</p>
<p>Don't forget when you do woodworking to clean afterwards  :)</p>
<p><img alt="dirty" src="https://blog.luap.info/static/desk/dirty_floor.jpg"></p>
<p>If you have done something similar and know a few advice, please send me an email</p>
<p>PS: If you wonder whether you can do that or not, everyone can do it, basic woodworking is not complex, you need to know how to cut wood, how to join wood, how to screw and a little bit of imagination, you dont even need a car to transport parts, I transported everything: pole of 2m40, big plate ... on a bike</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/i-built-a-lay-down-desk.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660610</guid>
            <pubDate>Fri, 02 Oct 2020 09:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Flancia there are no walled gardens]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660583">thread link</a>) | @ColinWright
<br/>
October 2, 2020 | https://flancia.org/mine/flanbook/ | <a href="https://web.archive.org/web/*/https://flancia.org/mine/flanbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p>In Flancia the internet is truly open: they managed to get rid of <a href="https://en.wikipedia.org/wiki/Closed_platform">walled gardens</a>. How they did it is an interesting&nbsp;story.</p>
<h2>Status&nbsp;quo</h2>
<p>Let’s take just one example; it should suffice to represent the general approach they took. In Flancia they had a social network — well, they had many of course, same as we do, but one in particular had grown into dominance. People had sort of liked it at some point, then eventually didn’t anymore, but they were stuck with it by then; it had developed at just the right time in internet history, and it had done enough things right in the beginning to take over from contenders and really soar in&nbsp;usage. </p>
<p>As it often was the case in those days, this network was fully controlled by a single corporation, and although at the beginning there were some provisions in place that made it look like a relatively healthy platform eventually the company had chosen to consolidate their dominion; namely close down APIs and turn it into a walled garden. By then network effects had taken over and de facto locked people in, too: the company had gotten users to build up an expansive social graph for them and had succeeding in retaining control over it. They proceeded to use this virtual monopoly on many users’ social capital and attention to make billions selling ads — and gained the ability to significantly steer public opinion in the process, too. Many people recognized problems with this approach, but users at large mostly kept using it. It was that or being locked out of a significant portion of social activity online and&nbsp;offline. </p>
<h2>X marks the&nbsp;spot</h2>
<p>One of the obstacles that Flancians faced when trying to improve on this status quo was that there was no single clearly better platform of choice available; in areas where there were some alternatives there were often too many, so the competitive landscape was fragmented, and that played to the company’s advantage. The company also used their ad-fueled wealth to buy most promising contenders and offer them as relatively empty alternatives to their main network, while effectively gaining access to more social data and expanding their influence. After a while network effects and inertia were so strong that competitors all but stopped trying; social networks are known to be hard to decamp from, as most of their value is in the social graph that users build on them; and the oh-so-valuable graph was kept very deep within the company’s walled&nbsp;garden. </p>
<p>Flancians didn’t have much when facing this dire state of affairs, but they had one thing, and it was an important one: they had <a href="https://flancia.org/agora/">a machine for solving coordination problems</a>. So they used it. First they sketched out a declaration of intents flowing naturally from their publicly espoused&nbsp;values.</p>
<ul>
<li>Useful internet platforms should be&nbsp;open.</li>
<li><span>‘</span>Open’ means that no single monolithic entity can fully control them and that their inner workings are transparent to interested parties and appropriately&nbsp;malleable.</li>
<li><span>‘</span>Open’ is desirable because otherwise monolithic egotistical entities can gain control of the network and extort value out of its users, or mislead&nbsp;them.</li>
</ul>
<p>Then they proceeded to write a plan together. The first version was remarkably simple; a sketch to get the real discussion started. It said essentially as&nbsp;follows:</p>
<ul>
<li>For each useful internet platform X that is not&nbsp;open:</li>
<li>Let X’ be its open&nbsp;replica.</li>
<li>Write down a plan to reimplement its core functionality, F(X’) ≈&nbsp;F(X).</li>
<li>Write down a plan to reproduce its critical data set, D(X’) ≈&nbsp;D(X).</li>
<li>Add X’ to the <a href="https://anagora.org/wiki/Missing_Devices">Catalog of Missing Devices</a> in the Agora. This both marks it as a canonical replica of X and announces it as a priority for&nbsp;Flancians.</li>
</ul>
<p>Once this bootstrap process was complete, the standard Agora algorithms took over; Flancians would best-effort iterate, improving on plans and resource estimates and executing actions as available to them, until failure or&nbsp;convergence.</p>
<p>Social networks were useful internet platforms; the Agora, after all, was in many ways a social network (a focused, goal-oriented one). So Flancians set out to replicate the company’s social network. They named that particular X’ <em>Flanbook</em> — after <a href="https://en.wikipedia.org/wiki/The_Book_of_Sand">The Book of Sand</a>, of course. It was fitting because the task of replicating it seemed at that point in time infinite in&nbsp;scope.</p>
<h2>I(X’)</h2>
<p>Looking around, it turned out that Flancians were relatively lucky. Most of the tools and libraries needed to build an open replica of the social network were available off-the-shelf. From all its algorithms, its ranking algorithms were perhaps the most sophisticated; but Flancians intended to replace those anyways, thinking the community could do better, so that was not an issue. The road to I(X’) was not trivial by any means, but it wasn’t very interesting for the purpose of telling this particular&nbsp;story.</p>
<h2>D(X’)</h2>
<p>In the case of social networks, then, it followed that most of their value was in their data; and, from all their data, none was more valuable than their social graph. Here Flancians had an ideological advantage, albeit perhaps not strictly a legal one to begin with, as they were known to often burst into chant in unison in barely appropriate&nbsp;occasions:</p>
<p><em>This, which is our data,<br>
will always be our data.<br>
A Flancian and their data<br>
shall never come apart.</em><br></p>
<p>This somewhat awkward ritual came handy sometimes, though. Flancians strongly believed that any information they produced and maintained was theirs; they believed this almost as much as they believed in the Agora. To a Flancian, the idea of their part of the social graph (the piece they had contributed a node and edges to) being out of their reach, locked down somewhere deep in a walled garden, just didn’t make sense. They refused to take it. So they just agreed to take their data&nbsp;back.</p>
<p>To perform this kind of task in a scalable way, they built special devices called <em>syphons</em>. The simplest came in the form of browser extensions. Whenever a Flancian used a targeted service X, the syphon redirected relevant data in the background to the replica X’. This allowed building up D(X’) incrementally so it could eventually function as a drop-in replacement. Flancians agreed to use these devices any time they could in platforms being replicated, even when they were not otherwise directly involved in the replication&nbsp;project.</p>
<p>Now, Flancians are an altogether friendly group, and they have the added advantage of knowing how to use an Agora; but they still do sometimes come into disagreements. Here Flancians disagreed with each other in how to define <em>relevant</em> in the above paragraph. Some Flancians, believing closed platforms to be actively dangerous to society, took the position that <em>all</em> data could be considered relevant in the noble pursuit of replicating such platforms, and consequently took a relatively aggressive stance and built and used syphons that actively sought to crawl and extract the largest portion of D(X) possible as fast as possible, regardless of provenance of data. Other Flancians, mostly aligned with the Middle Way, built syphons that only extracted data that they could strongly claim to be <em>theirs</em> to begin with, according to a shared and public&nbsp;definition:</p>
<ul>
<li>If the user of the syphon added the node or edge, it is considered&nbsp;relevant.</li>
<li>If a non-Flancian added the node or edge, and they give explicit consent to extraction, it is&nbsp;relevant.</li>
<li>If a Flancian added the node or edge, it is relevant (Flancians consent by default to the rational constructive actions of other&nbsp;Flancians).</li>
</ul>
<p>The second approach introduced the additional problem of identifying users across platforms and tracking consent. The syphons offered cross-platform validation as a feature; otherwise it could be manually accomplished by cross-posting tokens and declarations of intent publicly in the relevant&nbsp;networks.</p>
<p>Once this system was in place, it would presumably make D(X’) converge into a usable&nbsp;dataset.</p>
<p>The company, of course, put up a battle. They correctly identified X’ as an existential risk, and sought to attack syphons and their users. This started an arms race. Both groups of Flancians were affected differently, with those subscribing to the Middle Way being on more solid legal footing. The fact that Flancians had enough resources and a platform to organize a united resistance (the Agora) helped them tremendously; also helpful was the fact that relatively small but dense parts of D(X’) were sufficient to bootstrap smaller social networks within the&nbsp;network.</p>
<p>It would be perhaps unwise of me to say at this point which group fared better in the end, and precisely when and how the first replication project was brought to effective completion. Suffice it to say that Flanbook was a success, at least for a while, and it remains somewhat popular among the more old school Flancians. I, myself, am more partial to&nbsp;Instaflan.</p>
</div>
    </div></div>]]>
            </description>
            <link>https://flancia.org/mine/flanbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660583</guid>
            <pubDate>Fri, 02 Oct 2020 08:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome85 is stopping to send URL path as HTTP Referer field]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24660580">thread link</a>) | @yoshiokatsuneo
<br/>
October 2, 2020 | https://engineering.paiza.io/entry/referrer_policy | <a href="https://web.archive.org/web/*/https://engineering.paiza.io/entry/referrer_policy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
        <div id="main-inner">
          


          
  
  <!-- google_ad_section_start -->
  <!-- rakuten_ad_target_begin -->
  
  
  

  

  
    
      
        <article id="entry-26006613635480643" data-keyword-campaign="" data-uuid="26006613635480643" data-publication-type="entry">
  <div>
    

    


    <div>
  
    <p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002144505.png" alt="f:id:paiza:20201002144505p:plain" title="f:id:paiza:20201002144505p:plain" itemprop="image"></span></p>

<div>
<p><small>(Japanese article is <a href="https://paiza.hatenablog.com/entry/2020/10/02/referrer_policy">here</a>)</small></p>
</div>


<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20151217/20151217152725.jpg" alt="f:id:paiza:20151217152725j:plain" title="f:id:paiza:20151217152725j:plain" itemprop="image"></span>Hi, I'm Tsuneo([twitter:@yoshiokatsuneo]).</p>

<p>Now, the latest Chrome is stopping to send the URL path as HTTP Referer on cross-domain access.</p>

<p>If you analyze access to your web site, you can not know which article leads the user to your site.</p>

<h2>Beginning</h2>

<p>We have a blog as our own media to lead to our web service.
And, we are monitoring the reference URLs to our web service.</p>

<p>We happen to nice that the more and more reference is from the blog top page, and less and less reference from each article URLs.</p>

<h2>Chrome 85</h2>

<p>From our access logs, it looks like the change happens only on Chrome.</p>

<p>And, we noticed that the default "Referrer Policy" is changed from <strong>no-referrer-when-downgrade</strong> to <strong>strict-origin-when-cross-origin</strong> on Chrome85.</p>

<p>For example, the reference URL "<a href="https://paiza.hatenablog.com/entry/2020/10/01/140612">https://paiza.hatenablog.com/entry/2020/10/01/140612</a>" is stripped to "<a href="https://paiza.hatenablog.com/">https://paiza.hatenablog.com/</a>" .</p>

<p><cite><a href="https://www.chromestatus.com/feature/6251880185331712">www.chromestatus.com</a></cite></p>

<p>But, actually, when I test on Chrome85 my machine, the setting was  "no-referrer-when-downgrade", yet.
It looks that the setting is changing gradually.</p>

<h2>How to see the Referrer Policy</h2>

<p>We can see that what URL is sent as Referer on the cross-domain link.</p>

<p><a href="https://webdbg.com/test/refer/">https://webdbg.com/test/refer/</a></p>

<p>If the first green box has a URL with the path, your Chrome has "no-referrer-when-downgrade" as the Referrer Policy.</p>

<figure title="ãƒ‘ã‚¹å��ã�Œã�‚ã‚‹å&nbsp;´å�ˆ"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143005.png" alt="f:id:paiza:20201002143005p:plain" title="f:id:paiza:20201002143005p:plain" itemprop="image"></span><figcaption>URL with path(no-referrer-when-downgrade)</figcaption></figure>

<p>If the first green box has a URL without the path like below, your Chrome has the new "strict-origin-when-cross-origin" settings like below.</p>

<figure title="ãƒ‘ã‚¹å��ã�Œã�ªã�„å&nbsp;´å�ˆ"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002142849.png" alt="f:id:paiza:20201002142849p:plain" title="f:id:paiza:20201002142849p:plain" itemprop="image"></span><figcaption>URL without path(strict-origin-when-cross-origin)</figcaption></figure>

<p>You can also see the Referrer-Policy on Chrome developer tool, network tab.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143238.png" alt="f:id:paiza:20201002143238p:plain" title="f:id:paiza:20201002143238p:plain" itemprop="image"></span></p>

<h2>Why is the "Referrer Policy" changed ?</h2>

<p>The Referrer Policy is changed because of privacy and security concerns.</p>

<p>The Referer URL may contain search keywords, account ID, e-mail address, or other IDs, and the information may be sent to the linked site as "Referer".</p>

<p><cite><a href="https://web.dev/referrer-best-practices/">web.dev</a></cite></p>

<figure title="(https://web.dev/referrer-best-practices/ ã‚ˆã‚Š)"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143341.png" alt="f:id:paiza:20201002143341p:plain" title="f:id:paiza:20201002143341p:plain" itemprop="image"></span><figcaption>(from <a href="https://web.dev/referrer-best-practices/)">https://web.dev/referrer-best-practices/)</a></figcaption></figure>

<p>Nowadays, security and privacy are getting more critical than before. So, other browsers may change the settings as Chrome does.</p>

<h2>Current Referrer Policy deployment status</h2>

<p>How many Chrome85 have new "strict-origin-when-cross-origin", at now ?</p>

<p>At first, I created a poll at Slack. It looks more than half have the new settings.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002143535.png" alt="f:id:paiza:20201002143535p:plain" title="f:id:paiza:20201002143535p:plain" itemprop="image"></span></p>

<p>Also, from the access logs to our web sites, the percentage of Referer from the top page is growing from less than 10% to around 20% on  8th/Sep, and more than 50% on 29th/Sep or later.</p>

<h2>Solution</h2>

<p>If you can change the HTTP header or the HTML meta tag, you can change the Policy Referrer settings.</p>

<h3>HTTP header(Policy-Referrer) settings</h3>

<p>You can change Policy-Referrer HTTP response header field.
On nginx, you can change the configuration file like below.</p>

<pre data-lang="" data-unlink="">add_header 'Referrer-Policy' 'no-referrer-when-downgrade';</pre>


<h3>meta tag(name=referer) settings</h3>

<p>You can also change using the HTML meta tag like below.</p>

<pre data-lang="html" data-unlink=""><span>&lt;</span><span>meta</span><span> </span><span>name</span><span>=</span><span>"referrer"</span><span> </span><span>content</span><span>=</span><span>"no-referrer-when-downgrade"</span><span>/&gt;</span>
</pre>


<h3>Chrome settings</h3>

<p>You can also change on Chrome settings by putting "chrome://flags/#reduced-referrer-granularity" on the URL bar for testing.
By enabling the settings, Chrome does not send pathname on the URL.
By disabling the settings, Chrome sends pathname on the URL.</p>

<p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20201002/20201002153758.png" alt="f:id:paiza:20201002153758p:plain" title="f:id:paiza:20201002153758p:plain" itemprop="image"></span></p>



<p>On Safari 13 introducing ITP2.3, the access from the domain classified as tracker does not contain the path on Referer.</p>

<p><cite><a href="https://webkit.org/blog/9521/intelligent-tracking-prevention-2-3/">webkit.org</a></cite></p>



<p>The new Chrome85 is gradually stopping to send a URL path on Referer on cross-domain link, and it can cause huge impact on your web marketing.
I recommend checking your settings on web sites, access logs, or analysis tools.</p>

<hr>


<p>Withã€Œ<a href="https://paiza.cloud/">PaizaCloud Cloud IDE</a>ã€�, you can flexibly and easily develop your Web application or server application, and publish it, just in your browser.
<a href="https://paiza.cloud/"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/p/paiza/20171214/20171214153422.png" alt="https://paiza.cloud"></a></p>

<hr>


    

  
</div>

    
  

  </div>
</article>

      
      
    
  

  
  <!-- rakuten_ad_target_end -->
  <!-- google_ad_section_end -->
  
  
  
  


  



        </div>
      </div></div>]]>
            </description>
            <link>https://engineering.paiza.io/entry/referrer_policy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660580</guid>
            <pubDate>Fri, 02 Oct 2020 08:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I can't write a JavaScript for loop, and it does not matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660465">thread link</a>) | @slorber
<br/>
October 2, 2020 | https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj | <a href="https://web.archive.org/web/*/https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I've been using JavaScript daily for 7 years, and I'm not able to remember the syntax of a JavaScript for loop.</p>
<p>Despite this fact, I'm a rather successful freelance developer. Recently I even had the awesome opportunity to work for Facebook, as the <a target="_blank" href="https://github.com/facebook/docusaurus/issues/2336">Docusaurus lead maintainer</a>, writing the code for the framework that powers the documentation sites of Babel, Prettier, Jest, ReactNative...</p>
<p>I'll explain why I'm not able to remember such syntax, and why it does not matter much.</p>
<hr>

<p><strong>TLDR</strong>: I'm a functional programmer</p>
<p>I've really started programming at the beginning of my engineer degree, around 2004 (before that, I was only able to hack some scripts for Counter-Strike console or IRC).</p>
<p>Most of our school teaching was based on Java, but we also saw a bit of C, C++, OCaml. </p>
<p>The first loop syntax I learned probably looked like this one:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (<span>int</span> i = <span>0</span>; i &lt; numbers.length; i++) {
   System.out.println(numbers.get(i));
}
</code></pre>
<p>Before I came out of school, Java 6 brought some new, simpler syntax:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (Integer number : numbers) {
   System.out.println(number);
}
</code></pre>
<p>At my first job, the <a target="_blank" href="https://github.com/google/guava">Google Guava</a> lib brought some new verbose functional syntax to Java, and I was able to do weird things with it 😅.</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

Lists.newArrayList(Collections2.transform(numbers, <span>new</span> Function&lt;Integer,Void&gt;() {
  <span>@Override</span>
  <span><span>public</span> Void <span>apply</span><span>(Integer number)</span> </span>{
    System.out.println(number);
    <span>return</span> <span>null</span>;
  }
}));
</code></pre>
<p>This Guava lib got me intrigued by functional programming, and lead me to become a Scala developer since 2012, and I was finally able to use functional programming concepts (loops, but not only) without the ugly Java/Guava syntax.</p>
<pre><code>val numbers = List(1, 2, 3)
numbers.foreach(println)
</code></pre>
<p>In 2013, <a target="_blank" href="https://reactjs.org/blog/2013/06/05/why-react.html">ReactJS came out</a>, and this totally changed my career path. At this time, I didn't like JavaScript much and was only able to hack some inline JQuery things in server-rendered pages. But as a startup CTO, I saw my team struggle with architecture, BackboneJS and RequireJS, and thought I had to become better at frontend to lead them.</p>
<p>AngularJS looked like the safer choice at this time, but a Scala developer colleague really pushed for React, which looked fancy and risky. All things made sense with the visionary post of David Nolen (<a target="_blank" href="https://swannodette.github.io/2013/12/17/the-future-of-javascript-mvcs/">The Future of JavaScript MVC Frameworks</a>), and we finally adopted React in January 2014, as it seemed we would be able to use our functional programming knowledge to the frontend app as well, and make the UI more predictable.</p>
<p>Fast forward, it wasn't easy to be a React early-adopter for our critical app. All companies were building their own state management solution, trying to figure things out, <a target="_blank" href="https://github.com/stample/atom-react">and so we did</a>, based on the ideas of David Nolen to hold a single immutable state in an atom (I was able to get a <a target="_blank" href="https://www.youtube.com/watch?v=zxN8FYYBcrI">hacky time-travel working</a> before Redux). </p>
<p>Since then both the JavaScript language and the ReactJS ecosystem have progressed a lot, and it's very common to use functional programming principles nowadays.</p>

<p>As a long-time functional programmer, <strong>I simply don't write for loops</strong> very often. </p>
<p>Like anything you don't use regularly, you end up forgetting the syntax.</p>
<p>Today, many of us use ES5+ syntax (or Lodash/Ramda...) and some functional constructs. Using <code>map</code>, <code>forEach</code>, <code>filter</code> are the most illustrated examples in the JS community.</p>
<pre><code><span>const</span> numbers = [<span>1</span>, <span>2</span>, <span>3</span>]
numbers.forEach(<span><span>number</span> =&gt;</span> <span>console</span>.log(number));
</code></pre>
<p>But we can go much further than that once we are more experienced with functional programming, and almost never write any for loops anymore. </p>
<p>Don't get me wrong, it's not necessarily a goal to not write for loops anymore, and I'm not telling you that you should remove all for loops of your production codebase.</p>
<p>Very often there's an alternative syntax possible for your loops that might be more expressive and easier to understand. After a while, you end up seeing a for loop as an implementation detail of a more elegant functional abstraction.</p>
<p>This more expressive syntax is not only for loops, and you can as well see a functional abstraction being an implementation detail of another higher-level abstraction.</p>
<p>Let's consider we want to increment the age of 2 brothers.</p>
<pre><code><span>const</span> brothers = {
  <span>id1</span>: {<span>name</span>: <span>"Sébastien"</span>, <span>age</span>: <span>34</span>},
  <span>id2</span>: {<span>name</span>: <span>"Antoine"</span>, <span>age</span>: <span>23</span>}
};
</code></pre>
<p>I very often see the <code>array.reduce()</code> operator used when a more expressive alternative was possible.</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
    .reduce(<span>(<span>acc,[id,brother]</span>) =&gt;</span> {
      acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
      <span>return</span> acc;  
    },{})
}
</code></pre>
<p>You know what? <strong>I really struggled to write this code</strong>. </p>
<p>My first attempt was not working at all (TypeScript would have helped).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
      
      .reduce(<span>(<span>[id,brother],  acc</span>) =&gt;</span> {
        acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
        
      },{});
}
</code></pre>
<p>Yet, writing this kind of transform is idiomatic for me, using higher-level functional programming abstractions, such as <code>mapValues</code> (included in lodash).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> mapValues(
    brothers, 
    <span><span>brother</span> =&gt;</span> ({...brother, <span>age</span>: brother.age + <span>1</span>})
  );
}
</code></pre>
<p>And I think nobody would argue that this is harder to read and maintain right? If junior developers are not familiar with functional programming, they'll catch up fast and get used to it. This might even be harder to learn <code>reduce</code>.</p>

<p>I don't write for loops (or <code>reduce</code>), but I know the concepts. I know that these loops exist in different syntaxes, that can be useful for different use cases, and how to make a choice with a good tradeoff (performance, readability...).</p>
<p>I'll illustrate this with a concrete example from my daily work that actually led me to write this article.</p>
<p>I had this async function that performs some long task for a given country.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runCountryTask</span>(<span>country</span>) </span>{

  
  <span>const</span> taskDuration = <span>1000</span> + <span>Math</span>.random() * <span>4000</span>;
  <span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, taskDuration));

  <span>console</span>.log(<span>`Task completed for <span>${country}</span>`</span>);
}
</code></pre>
<p>This task had to be run for many countries, but the tasks should be run sequentially, not in parallel.</p>
<p>As I know the concepts, and I knew that the following would not work, as <code>Promise.all</code> would run all tasks in parallel.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> <span>Promise</span>.all(countries.map(runCountryTask))
}
</code></pre>
<p>I also knew that there were multiple possible solutions to solve this problem:</p>
<ul>
<li>use a third-party dependency exposing the higher-level async primitive I need</li>
<li>use <code>Promise.then()</code> recursively</li>
<li>use async/await, using a for loop syntax to iterate over a fixed-size array</li>
</ul>
<p>I didn't want to introduce a new third party dependency just for a tiny utility function. </p>
<p>I also knew that using <code>Promise.then()</code> recursively could be harder to read, write, and maintain. There are many ways to write such a recursion, one of them could be:</p>
<pre><code><span>async</span> <span><span>function</span> <span>forEachAsyncSequential</span>(<span>array, asyncFn</span>) </span>{
  <span>await</span> array.reduce(<span>(<span>acc, item</span>) =&gt;</span> {
    <span>return</span> acc.then(<span>() =&gt;</span> asyncFn(item))
  }, <span>Promise</span>.resolve());
}
</code></pre>
<p>So I opted for a basic for loop, as it seemed the right tradeoff. </p>
<p>As I'm totally unable to remember the syntax (<code>in</code> vs <code>of</code>, can I actually use <code>const</code>?), I had to actually google it, and it didn't take me long to be able to write the TypeScript code that will be shipped in production.</p>
<pre><code><span>export</span> <span>async</span> <span><span>function</span> <span>forEachAsyncSequencial</span>&lt;<span>T</span>&gt;(<span>
  array: T[],
  asyncFn: (t: T) =&gt; <span>Promise</span>&lt;<span>void</span>&gt;,
</span>): <span>Promise</span>&lt;<span>void</span>&gt; </span>{
  <span>for</span> (<span>const</span> item <span>of</span> array) {
    <span>await</span> asyncFn(item);
  }
}
</code></pre>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> forEachAsyncSequencial(countries, runCountryTask);
}
</code></pre>
<p>Believe me or not, but I think It's the only for loop I actually wrote in JavaScript this year. And once it's written, I won't need to write it ever again (at least for this project), as it's now part of my functional programming abstractions, that I can reuse anywhere I need.</p>
<p><a target="_blank" href="https://jsfiddle.net/y17c6et8/1/">JsFiddle playground</a></p>
<hr>

<p>It's not very important to remember every syntax details to be productive in your daily work, particularly when you don't use them often (on purpose), as you prefer to work with more expressive, higher-level abstractions. </p>
<p>I had to google many things to write this article:</p>
<ul>
<li>Syntax for declaring a Java list</li>
<li>Syntax for iterating a Java list</li>
<li>Does <code>System.out.println</code> accept an Integer?</li>
<li>Syntax for Scala string interpolation</li>
<li>Is there a <code>forEach</code> in Guava (actually found <a target="_blank" href="https://stackoverflow.com/questions/38251257/guava-iterators-for-nested-foreach">my own StackOverflow question</a>)</li>
<li>What are the possible syntaxes for iterating over a JavaScript array</li>
<li>Signature of <code>array.reduce()</code></li>
</ul>
<p>Not remembering all this does not matter much, as long as I know what to look for.</p>
<p>In the same way, I don't know much about many other JavaScript things:</p>
<ul>
<li>prototypes: I think I never hard to use them directly in my entire life, and I'm fine</li>
<li>classes: used them temporarily when I really had to in React</li>
<li>JavaScript quirks: I know some of them, but simply avoid the others by using ESLint, <code>===</code>, TypeScript... it's not worth knowing all of them</li>
<li>...</li>
</ul>
<p>The knowledge and concepts you learn are more easily transposable from one language to another. I was able to learn React and contribute to its ecosystem quickly, thanks to my functional programming background. </p>
<p>I would argue that knowing how to do a recursive algorithm is more important than knowing the syntax of a for loop of a particular language. You will likely write many recursive algorithms in your career: the concept of recursion is not going anywhere anytime soon. But it's way more likely that you switch from one language to another from time to time. </p>
<p>Hopefully, writing this post will help me remember the syntax for a while until I forget it again 🤪.</p>
<hr>
<p>🙏 If you like this post, please like it, share it or comment it 🙏: </p>
<ul>
<li><a target="_blank" href="https://twitter.com/sebastienlorber/status/1311948662843551744">Tweet</a></li>
<li><a target="_blank" href="https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">Hashnode</a></li>
<li><a target="_blank" href="https://dev.to/sebastienlorber/i-can-t-write-a-javascript-for-loop-and-it-does-not-matter-11jb">Dev</a></li>
<li><a target="_blank" href="https://www.reddit.com/r/javascript/comments/j3r08h/i_cant_write_a_javascript_for_loop_and_it_does/">Reddit</a></li>
<li><a target="_blank" href="https://news.ycombinator.com/item?id=24660465">HackerNews</a></li>
</ul>
<p>For more content like this, subscribe to <a target="_blank" href="https://mailchi.mp/4ea4df0b54f7/sebastienlorber">my mailing list</a> and follow me on <a target="_blank" href="https://twitter.com/sebastienlorber">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660465</guid>
            <pubDate>Fri, 02 Oct 2020 08:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bead Sort]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24659668">thread link</a>) | @kkaranth
<br/>
October 1, 2020 | https://karthikkaranth.me/blog/bead-sort/ | <a href="https://web.archive.org/web/*/https://karthikkaranth.me/blog/bead-sort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<header id="top">
    <section>
        <a href="https://karthikkaranth.me/">Karthik Karanth</a>
    </section>

    <div>
        <section>
            
                
                

                <a href="https://karthikkaranth.me/blog/">Blog</a>
            
                
                

                <a href="https://karthikkaranth.me/art/">Art</a>
            
                
                

                <a href="https://karthikkaranth.me/projects/">Projects</a>
            
        
        </section>
    </div>
</header>


<header>
  
</header>
<section id="category-pane">
  
  <p>
    <h6>
        PUBLISHED ON OCT 1, 2020 
      
    </h6>
  </p>
  
</section>
<section id="content-pane">
  <div>
    <div>
    <canvas id="bead-sort-canvas">
    </canvas>

    
</div>

<p>Bead sort<sup id="fnref:wiki"><a href="#fn:wiki">1</a></sup> is a sorting algorithm powered by gravity!</p>

<ul>
<li>For each number <code>x</code> in the array we want to sort, we arrange <code>x</code> beads in a row.</li>
<li>Let them all drop.</li>
<li>Count the number of beads in each row from top to bottom, and we have our sorted array!</li>
</ul>



<div>

<hr>

<ol>
<li id="fn:wiki"><a href="https://en.wikipedia.org/wiki/Bead_sort">Bead sort - Wikipedia</a>
 <a href="#fnref:wiki"><sup>[return]</sup></a></li>
</ol>
</div>

  </div>
</section>
<section id="tag-pane">
  
  
  
</section>








<section id="menu-pane">
  
  
  

  
  
  
  
  
  
  
  
  

  
  
  <div><p><span><a href="https://karthikkaranth.me/blog/starting-with-order/">&lt; PREV</a></span><span><a href="https://karthikkaranth.me/blog">BLOG</a></span><span></span></p></div>
  
  <div><p><span><a href="https://karthikkaranth.me/">HOME</a></span></p></div>
</section>





</div></div>]]>
            </description>
            <link>https://karthikkaranth.me/blog/bead-sort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659668</guid>
            <pubDate>Fri, 02 Oct 2020 06:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659489">thread link</a>) | @lukastyrychtr
<br/>
October 1, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust introduces features that do not provide the same memory and
thread safety guarantees. This causes programs or libraries to be
susceptible to memory corruption (CWE-119)[8] and concurrency issues
(CWE-557)[9]. Modern C and C++ compilers provide exploit mitigations to
increase the difficulty to exploit vulnerabilities resulting from these
issues. Therefore, the Rust compiler must also support these exploit
mitigations in order to mitigate vulnerabilities resulting from the use of
Unsafe Rust. This post is going to document these exploit mitigations and
how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to “the Rust compiler” in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Yes (enabled when debug assertions are enabled, and disabled when debug assertions are disabled)
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) (via operating system default or specified allocator)
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">↩</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as “full ASLR”.</p>

<p>The Rust compiler supports position-independent executable, and enables it
by default since version 0.12.0 (2014-10-09)[10]–[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1. Checking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]–[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]–[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2. hello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3. Build and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4. Build and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">↩</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX’s
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as “No Execute (NX) Bit”,
“Execute Disable (XD) Bit”, “Execute Never (XN) Bit”, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]–[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5. Checking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">↩</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region—allowing arbitrary data in both to be overwritten using each
other—by reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as “stack probes” or “stack probing”.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]–[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as “partial RELRO”.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9. Checking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup, so all segments containing relocations can be marked …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659489</guid>
            <pubDate>Fri, 02 Oct 2020 06:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Software Foundation gives developers money for their first GNU contribution]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659354">thread link</a>) | @protontypes
<br/>
October 1, 2020 | https://gnucode.me/make-money-contributing-to-gnu.html | <a href="https://web.archive.org/web/*/https://gnucode.me/make-money-contributing-to-gnu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So, the truth is that I and <a href="https://rednosehacker.com/">Jeremy Korwin</a> hate
having money.  It is really quite annoying.  We have decided to get rid of some
of it, and we hope you will help us.</p><p>If you have been wanting to contribute to a GNU project, but did not know how,
then here is your chance.  I will pay you $1 (and Jeremy will pay 1€) for any
single contribution to any GNU project.  The only requirement, is that it has to
be your first contribution to that project.  Examples include:</p><ul><li>Your first commit to a GNU software project</li><li>Your first commit to a GNU manual</li><li>You contribute artwork that is accepted into a GNU project.</li><li>You commit a new package or update an existing one to a <a href="https://www.gnu.org/distros/free-distros.html">GNU
distro</a>.</li><li>You help translate a GNU package or manual</li><li>Improve h-node.org <a href="https://www.gnu.org/help/help.html#hnode">h-node.org</a></li><li>Improve <a href="https://libreplanet.org/wiki/Main_Page">libreplanet.org</a></li><li>You successfully <a href="https://www.gnu.org/philosophy/selling.html">sell</a> free software for the first time.</li><li>Start a free software blog.  I can <a href="https://gnucode.me/services.html">help with this</a>.</li><li>Write for the free software bulletin. Email <a href="mailto:info@fsf.org">info@fsf.org</a>.</li><li>Post a video on <a href="https://audio-video.gnu.org/">audio-video.gnu.org</a>.  You'll
need to email <a href="https://gnucode.me/campaigns@fsf.org">info@fsf.org</a>.</li><li>Switch to a completely <a href="https://www.gnu.org/distros/free-distros.html">free operating system</a>.</li><li>Add your program as <a href="https://www.gnu.org/help/evaluation.html">a GNU package</a>.</li><li>Write a Firefox extension that will replace the nonfree Javascript code of
some useful web site (when that nonfree code is blocked by LibreJS). Either
pick a site yourself, or ask for suggestions.  I hang out in <code>#guix</code> on irc.</li><li>Convince your University to release <a href="https://www.gnu.org/philosophy/university.html">your program as free
software</a>.</li><li>Join the <a href="http://www.gnu.org/people/webmeisters.html">GNU webmasters team</a>.</li><li>Improve <a href="https://www.gnu.org/server/tasks.html">gnu.org</a>.</li><li>List your company in the <a href="https://www.fsf.org/resources/service">FSF service
directory</a>.</li></ul><p>Please keep in mind, that we will need to be able to verify that this is your
first contribution to a specific GNU project.  Ideally, you will commit some
change to a software project, and we can use <code>git-log</code> to verify this is your
first commit to that project.</p><p>We are setting aside $90 and 90€ for this "Helping GNU" campaign.  First come,
first serve.  Email me at
<a href="mailto:jbranso+helping-gnu@dismail.de">jbranso+helping-gnu@dismail.de</a> when
your submission is done.</p><p>Your email should look something like:</p><pre><code>Hey Joshua and Jeremy!

So I contributed my first change to this GNU &lt;software project&gt;.
As you can see my email address is &lt;your email address&gt;.  You can verify that
this is my first submission to the GNU &lt;software project&gt; via this &lt;method&gt;.
You can pay me via paypal.  My email address is: &lt;email address&gt;.

Thanks,

Live long and prosper,

&lt;Your Name&gt;
I'm a rock star!
</code></pre><p>Live long and prosper.</p><p>P.S.  If you know of a better payment method, please let me know.  Jeremy is in
the E.U., and I am based in the U.S.</p></div></div>]]>
            </description>
            <link>https://gnucode.me/make-money-contributing-to-gnu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659354</guid>
            <pubDate>Fri, 02 Oct 2020 05:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods Programmers Believe About Map Coordinates]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24659039">thread link</a>) | @boyter
<br/>
October 1, 2020 | https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates | <a href="https://web.archive.org/web/*/https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Mercator projection SW" title="Mercator projection SW" src="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg" srcset="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e4a55/Mercator_projection_SW.jpg 256w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/36dd4/Mercator_projection_SW.jpg 512w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg 1024w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/ac99c/Mercator_projection_SW.jpg 1536w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e1596/Mercator_projection_SW.jpg 2048w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/1cd85/Mercator_projection_SW.jpg 2058w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy">
    </span>
(Map image by Daniel R. Strebe, licensed under CC BY-SA 3.0)</p><h2>1. The only projection that is important is Web Mercator</h2><p>While <a href="https://en.wikipedia.org/wiki/Web_Mercator_projection">Web Mercator</a> is
probably the most popular projection that most people will run into, the
<a href="https://en.wikipedia.org/wiki/Albers_projection">Albers</a> and
<a href="https://en.wikipedia.org/wiki/Lambert_cylindrical_equal-area_projection">Lambert</a>
equal-area projections are fairly common for when the projection needs to maintain
the area rather than the navigational direction (which is one of the main features
of the Mercator projection).</p><h2>2. All coordinates are latitude/longitude pairs</h2><p>In addition to latitude/longitude coordinates, <a href="https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">Universal Transverse Mercator (UTM)
coordinates</a>
are also fairly common. UTM splits the Earth into 60 zones, and then
further specifies northings and eastings in metres (as opposed to degrees, minutes and seconds).</p><p>The UTM notably omits the polar areas - which are covered by the <a href="https://en.wikipedia.org/wiki/Universal_polar_stereographic_coordinate_system">Universal Polar Stereographic (UPS)
coordinate system</a>
instead.</p><h2>3. Latitude always comes before longitude in a coordinate pair</h2><p>While it is common to see items in (latitude,longitude) order, some formats
(e.g. <a href="https://en.wikipedia.org/wiki/GeoJSON">GeoJSON</a>) dictate that coordinates
follow (longitude,latitude) order instead. This matches the typical way coordinates
are specified in a Cartesian coordinate system: (x,y).</p><h2>4. A degree of latitude or longitude always represents the same distance</h2><p>In the Mercator projection, the Earth - which, in reality, is an
<a href="https://en.wikipedia.org/wiki/Spheroid#Oblate_spheroids">oblate spheroid</a> -
is projected as a simple cylinder. This means that "parallel" longitude lines
meet at the poles, so the distance between degrees of longitude are much shorter
as they get closer to the poles than they are at the equator (~111 km).</p><p>The variance in latitude is not as large - but it still varies by about 1km going
from the equator to the poles.</p><h2>5. The shortest path between two points is a straight line</h2><p>The Earth isn't flat - as such, although your map may be projected to be flat,
the distance between two points needs to follow the curvature of
the Earth and can usually be approximated by the
<a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine formula</a>.</p><h2>6. Coordinates for a given landmark are always fixed</h2><p><a href="https://en.wikipedia.org/wiki/Continental_drift">Movements of the Earth's tectonic plates</a>
mean that the land masses are moving slowly with the passage of time.
For example, Australia has shifted about 1.8 metres from where it
was in 1994 (about 7 centimetres per year). This also means that <a href="http://www.ga.gov.au/scientific-topics/positioning-navigation/geodesy/datums-projections/gda2020">geocentric
datums</a>
have to be updated to account for these changes every once in a while.</p><h2>7. Given a pair of coordinates, you can plot it on a map</h2><p>In addition to coordinates, we also need to know the datum, which is
the coordinate system and its specific set of reference points on the Earth.
While most coordinates often follow the
<a href="https://en.wikipedia.org/wiki/World_Geodetic_System">WGS84 datum</a>,
care should be taken to ensure that the map and the coordinates plotted
are using the same datum.</p><h2>8. There is one global ellipsoid to base coordinates on</h2><p>Most modern datums are based on the WGS84
<a href="https://en.wikipedia.org/wiki/Ellipsoid">ellipsoid</a>
as the surveys are often completed using GPS as a reference, but notably
Russia and China still base their local datums on different reference ellipsoids.</p><p>As a result, conversions to and from datums based on different
ellipsoids may result in inaccuracies and deviations and may be of concern
if you have to deal with GPS, GLONASS, and BeiDou data at the same time.</p></div></div>]]>
            </description>
            <link>https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659039</guid>
            <pubDate>Fri, 02 Oct 2020 04:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport Tycoon a.k.a. the great optimiser, Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon — who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon — especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here — or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they’ve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We’ll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making — a decade of hard work, toiling in obscurity…or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade — it’s five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since — such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he’d encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he’d become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts — where Chris set off towards the lands where he’d make his name. And I find it fascinating how serendipitous this was — for, you see, Chris’s two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he’d not had access to an assembler for that Lynx computer, so when he’d wanted to move beyond coding in BASIC he’d needed to write his programs byte-by-byte in machine code — the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he’d made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‘k’ rather than a ‘c’) as though that somehow made his unapologetic, blatant clone of another’s work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren’t much concerned. Or at least their games guy Jim Wills wasn’t much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris’s work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers — an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he’d already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he’d shifted over to the Amstrad CPC, which technologically-speaking wasn’t hugely different to the Memotech system he’d been on before — but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can’t be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn’t doing too well at managing the transition. </p><p>So Chris didn’t have a job waiting for him after all, and he’d missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry — he’d made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he’d thought it a “stop-gap” measure, just “a bit of fun” while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who’d had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Jargon File]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24658797">thread link</a>) | @purec
<br/>
October 1, 2020 | http://jargon-file.org/archive/jargon-4.4.7.dos.txt | <a href="https://web.archive.org/web/*/http://jargon-file.org/archive/jargon-4.4.7.dos.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jargon-file.org/archive/jargon-4.4.7.dos.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658797</guid>
            <pubDate>Fri, 02 Oct 2020 04:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to compute a factorial with λ calculus in a post card]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658404">thread link</a>) | @martyalain
<br/>
October 1, 2020 | http://lambdaway.free.fr/lambdawalks/?view=lambdafact | <a href="https://web.archive.org/web/*/http://lambdaway.free.fr/lambdawalks/?view=lambdafact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambdaway.free.fr/lambdawalks/?view=lambdafact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658404</guid>
            <pubDate>Fri, 02 Oct 2020 03:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The (Not Failing) New York Times - How the NYT pivoted into subscription]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658206">thread link</a>) | @ReallyFantastic
<br/>
October 1, 2020 | https://minesafetydisclosures.com/blog/newyorktimes | <a href="https://web.archive.org/web/*/https://minesafetydisclosures.com/blog/newyorktimes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper" role="main">
        <!-- CATEGORY NAV -->
        
      <section id="page">

      <div data-content-field="main-content">
        <article id="article-5f70e3da36b37d25b6fe92ee" data-item-id="5f70e3da36b37d25b6fe92ee">

  <!--SPECIAL CONTENT-->

  

  
  <!--POST HEADER-->
    
  <header>
    
    <div>
      <p><span><a href="https://minesafetydisclosures.com/blog/newyorktimes" title="Permalink"><time datetime="2020-10-01">October 01, 2020</time></a></span>
       in <span><a href="https://minesafetydisclosures.com/blog/category/Companies" rel="tag">Companies</a></span>
    </p></div>
  </header>
  
  
  <!--POST BODY-->

  <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1601234027667" id="item-5f70e3da36b37d25b6fe92ee"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1601572339034_143602"><div><p><strong>CLICK TO EXPAND</strong> (<a href="https://www.dropbox.com/s/qy3nfaxjiplmtcf/The%20%28Not%20Failing%29%20New%20York%20Times.pdf?dl=0">or download the PDF</a>)</p></div></div><div data-block-json="{&quot;transparentBackground&quot;:false,&quot;existingGallery&quot;:null,&quot;hSize&quot;:null,&quot;newWindow&quot;:true,&quot;floatDir&quot;:null,&quot;methodOption&quot;:&quot;transient&quot;,&quot;aspect-ratio&quot;:&quot;four-three&quot;,&quot;aspectRatio&quot;:null,&quot;auto-crop&quot;:false,&quot;autoplay&quot;:false,&quot;blockAnimation&quot;:&quot;none&quot;,&quot;collectionId&quot;:&quot;5f75feeb15e1c70b3500b2af&quot;,&quot;controls&quot;:true,&quot;design&quot;:&quot;grid&quot;,&quot;lightbox&quot;:true,&quot;lightboxTheme&quot;:&quot;dark&quot;,&quot;meta-position&quot;:&quot;bottom&quot;,&quot;padding&quot;:4,&quot;show-meta&quot;:true,&quot;show-meta-basic&quot;:true,&quot;show-meta-only-title&quot;:false,&quot;show-meta-only-description&quot;:false,&quot;show-meta-on-hover&quot;:false,&quot;square-thumbs&quot;:false,&quot;thumbnail-strip-height&quot;:130,&quot;thumbnail-strip-margin&quot;:20,&quot;thumbnails&quot;:true,&quot;thumbnails-per-row&quot;:3,&quot;vSize&quot;:null,&quot;transientGalleryId&quot;:&quot;5f75feeb15e1c70b3500b2af&quot;}" data-block-type="8" id="block-yui_3_17_2_1_1601554581161_153023"><div>




  

  


<div>
  <div>
    
      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.001.jpeg" data-load="false" data-image-id="5f75feebcd2d631e090d8ecf" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491898-QSKD151WV1V66SWF76RX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.001.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.002.jpeg" data-load="false" data-image-id="5f75feeb0df493541c6b0f58" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491687-BUFX9ZE5GUJAGSBOVDB9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.002.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.003.jpeg" data-load="false" data-image-id="5f75feeb753f9f3986c12f5b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568491980-NS9879K140O4DB5H89E9/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.003.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.004.jpeg" data-load="false" data-image-id="5f75feec2b2362390706eb55" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568492756-KSFTPTJFGSP526MW1UKF/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.004.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.005.jpeg" data-load="false" data-image-id="5f75feec753f9f3986c13128" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493267-8B3VVVKJ56OBBNJ2G96W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.005.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.006.jpeg" data-load="false" data-image-id="5f75feed0dd0c87c41a98128" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493207-7YR1TD6N9L1PKMK2N6FQ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.006.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.007.jpeg" data-load="false" data-image-id="5f75feedd134f3794caf0000" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568493555-9EF3RMHI4MF4OTXSGG8W/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.007.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.008.jpeg" data-load="false" data-image-id="5f75feed8036587780b953a7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494053-VPDXKBOQ1BUKTW0ZKQFC/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.008.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.009.jpeg" data-load="false" data-image-id="5f75feee0373414277bdfd7c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568494716-UHDI7FEBGQOVNR8SHMKV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.009.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.010.jpeg" data-load="false" data-image-id="5f75feef7a7dba1ef4d84dcc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568495258-UTWT4HEEUYA5KZKX6IVW/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.010.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.011.jpeg" data-load="false" data-image-id="5f75feef15e1c70b3500b4a9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496734-P4HP47QWQ6IRPH5JT74Q/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.011.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.012.jpeg" data-load="false" data-image-id="5f75feefcd2d631e090d8f05" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568496800-PE3LOP4L3ZSMZYGXOE9X/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.012.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.013.jpeg" data-load="false" data-image-id="5f75fef096d0d45d87873ae4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497147-28FKSZORBFDD17JLLSLJ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.013.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.014.jpeg" data-load="false" data-image-id="5f75fef196d0d45d87873ae5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568497521-EWBNLMCM0ZDZTK3XPZ8E/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.014.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.015.jpeg" data-load="false" data-image-id="5f75fef178c626590ead63bd" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498130-H8QT1RS246K919X5SQRX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.015.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.016.jpeg" data-load="false" data-image-id="5f75fef1cd2d631e090d90d5" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498473-EIHAUFRT6BG08IVZURSV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.016.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.017.jpeg" data-load="false" data-image-id="5f75fef20cb6f82db9374309" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568498729-B330234GGXYLVBDU6130/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.017.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.018.jpeg" data-load="false" data-image-id="5f75fef2fcfe7968a6c406c0" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568499948-VLV4587BFNX0LDWHIW4H/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.018.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.019.jpeg" data-load="false" data-image-id="5f75fef31158a96d1adab031" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500013-N4BX21PST785J6FK8YEK/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.019.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.020.jpeg" data-load="false" data-image-id="5f75fef4a1b4e25ba6ac297c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500821-X2OXQN1L8KR8THJ3QV5N/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.020.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.021.jpeg" data-load="false" data-image-id="5f75fef4a1b4e25ba6ac297f" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568500697-BM3FM16OOZIYBBE9KYYP/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.021.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.022.jpeg" data-load="false" data-image-id="5f75fef5883c6055aa1defb2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501352-S7J64XCV0X2P97ZP2NES/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.022.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.023.jpeg" data-load="false" data-image-id="5f75fef52b2362390706f660" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501618-3E7W4Z1STCOJP5NOISTX/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.023.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.024.jpeg" data-load="false" data-image-id="5f75fef59993bf06c4e0fd0b" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568501743-XFRV55E2U72DOREBV745/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.024.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.025.jpeg" data-load="false" data-image-id="5f75fef50dd0c87c41a983ae" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502651-A0BJQXLUEU8MH8TU1YEU/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.025.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.026.jpeg" data-load="false" data-image-id="5f75fef51158a96d1adab04e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502122-XIO1PMT8VIJMWAT5OZY4/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.026.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.027.jpeg" data-load="false" data-image-id="5f75fef6df48bb24d6e115b8" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568502736-FB2FXT4PKZSTQBBHLCTV/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.027.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.028.jpeg" data-load="false" data-image-id="5f75fef6f5a59735fc9dad85" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504546-6QFZ8QWG6WZXQD37C25Y/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.028.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.029.jpeg" data-load="false" data-image-id="5f75fef705a7793966d1d02c" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568503675-K0JPRBENUV0OIBNRJVNA/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.029.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.030.jpeg" data-load="false" data-image-id="5f75fef70dd0c87c41a983cb" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568504260-2ZJZ0N29T60PUYVO0PD2/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.030.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.031.jpeg" data-load="false" data-image-id="5f75fef878c626590ead67cf" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505505-SXMJKTI3GZ4KPP5T89H0/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.031.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.032.jpeg" data-load="false" data-image-id="5f75fef92fbf5a3363926728" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568505726-IGC0IN2QUPBGN7UG35QZ/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.032.jpeg">
                </a>
                
              </p></div>
            </div>
          

          
        

      

        

        

        
          
            <div data-type="image" data-animation-role="image">
              <div>
                
                <p><a data-title="" data-description="" data-lightbox-theme="dark" href="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" role="button">
                  
                    <span>View fullsize</span>
                  
                  <img data-src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg" data-image-dimensions="1024x768" data-image-focal-point="0.5,0.5" alt="NYT Deck Images.033.jpeg" data-load="false" data-image-id="5f75fef996d0d45d87873f25" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5693d8b50ab377deeede80ac/1601568506018-0D7AQ4VKMJZNXSXBUDRE/ke17ZwdGBToddI8pDm48kL3VKmwKI3leYB51VJjLFB8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcgK5SGg9Ovb1yloBBOHcruw_mYLfAhRzzgArFCB07Dw0L8n4JypuoE5Tg6Wg5Oyvs/NYT+Deck+Images.033.jpeg">
                </a>
                
              </p></div>
            </div></div></div></div></div></div></div></div></div></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://minesafetydisclosures.com/blog/newyorktimes">https://minesafetydisclosures.com/blog/newyorktimes</a></em></p>]]>
            </description>
            <link>https://minesafetydisclosures.com/blog/newyorktimes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658206</guid>
            <pubDate>Fri, 02 Oct 2020 02:34:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[London, Ont. study reveals science behind curling's 2015 'Frankenbroom' ban]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658102">thread link</a>) | @lando2319
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A Western University study suggests the so-called 'Frankenbrooms' that were banned by the World Curling Federation in 2015 can leave scratches in the ice that are up to four times deeper than their legal counterparts.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.2982097.1425923428!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/cur-brier-20150304.jpg"></p></div><figcaption>At least 50 of the world's top curlers signed a joint statement in October of 2015, saying they would not use the controversial brush heads,&nbsp;believing the technology&nbsp;would diminish&nbsp;the integrity of the sport.<!-- --> <!-- -->(Jeff McIntosh/Canadian Press)</figcaption></figure><p><span><p>A Western University study suggests the so-called 'Frankenbrooms' <a href="https://www.cbc.ca/sports/olympics/winter/curling/high-tech-curling-brooms-banned-1.3324802">banned by the World Curling Federation in 2015</a> may leave scratches in the ice that are up to four times deeper than their legal counterparts.&nbsp;</p>  <p>The&nbsp;study results confirm what many believed to be true in the first place, that the high tech "directional fabric" in the broom heads may give sweepers the unprecedented ability to manipulate the rock's trajectory in ways they wouldn't be able to do with a regular broom.&nbsp;</p>  <p>At least <a href="https://www.cbc.ca/news/canada/manitoba/top-curling-teams-say-they-won-t-use-high-tech-brooms-1.3274903">50 of the world's top curlers signed a joint statement in October of 2015</a>, saying they would not use the controversial brush heads,&nbsp;believing the technology&nbsp;would diminish&nbsp;the sport's integrity by lowering the throwing accuracy and athleticism required to play the sport.&nbsp;</p>  <p>Megan Balsdon, a PhD researcher in Western's faculty of engineering and an avid curler since the age of eight, said the results of the&nbsp;study now lend evidence to what many&nbsp;leading voices in the sport&nbsp;suspected all along, that the sandpaper-like effect of the&nbsp;high tech brush against the ice&nbsp;can influence&nbsp;the game.&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.4548815.1519402879!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/curling-team.jpg 300w,https://i.cbc.ca/1.4548815.1519402879!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/curling-team.jpg 460w,https://i.cbc.ca/1.4548815.1519402879!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/curling-team.jpg 620w,https://i.cbc.ca/1.4548815.1519402879!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/curling-team.jpg 780w,https://i.cbc.ca/1.4548815.1519402879!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/curling-team.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4548815.1519402879!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/curling-team.jpg"></p></div><figcaption>A Western University study suggests the so-called 'frankenbrooms' that were banned by the World Curling Federation in 2015 may leave scratches in the ice that are up to four times deeper than their legal counterparts. <!-- --> <!-- -->(Dean Mouhtaropoulos/Getty Images)</figcaption></figure></span></p>  <p>"We found that what most people believed to be true was true. The illegal broom heads were leaving scratches in the ice surface," she said. "Upwards of four times higher than the legal fabric."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5744899.1601489758!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/megan-baldson.jpg 300w,https://i.cbc.ca/1.5744899.1601489758!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/megan-baldson.jpg 460w,https://i.cbc.ca/1.5744899.1601489758!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/megan-baldson.jpg 620w,https://i.cbc.ca/1.5744899.1601489758!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/megan-baldson.jpg 780w,https://i.cbc.ca/1.5744899.1601489758!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/megan-baldson.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5744899.1601489758!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/megan-baldson.jpg"></p></div><figcaption>Aside from studying the sport as part of her PhD thesis, Megan Baldson is avid player and was a coach for the Western University women's curling team from 2014 to 2018.<!-- --> <!-- -->(Megan Baldson/Twitter)</figcaption></figure></span></p>  <p>"The illegal broom heads would, depending on which direction you were sweeping,&nbsp;help steer the rock in that direction."</p>  <p>"It didn't necessarily affect the spin of the rock, but the direction of the rock. We didn't look&nbsp;at exactly the output of the rock itself, just the ice surface, what the fabric was doing to the ice surface."</p>  <p>Balsdon said the way they measured the difference was by using dental impression materials to take an imprint of the ice surface after being scoured by one of the brushes.&nbsp;</p>  <p>"You can't really take a chunk of ice and put it in the microscope. So that's how we did it," she said. "We basically replicated the microscopic element of the ice and then looked at that in the microscope."&nbsp;</p>  <p>The surface was then scanned by a piece of technology called an optical profiler, which was used to scan the depths of the marks left by the brooms.&nbsp;</p>  <p>Balsdon said while the study does confirm the outlawed brooms were leaving deeper scratches in the ice than their traditional counterparts, further research&nbsp;is needed to understand how big of a difference those scratches make in how a team performs on the ice.&nbsp;</p>  <p>"I think this research in conjunction with some future studies on how the actual output of the rock will just give us a little more insight so we can compare the actual scratches to the actual output of the rock."&nbsp;</p></span></p></div><div><h2>About the Author</h2><div><div><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.4216135.1507903562!/fileImage/httpImage/image.jpg_gen/derivatives/square_300/colin-butler.jpg 300w,https://i.cbc.ca/1.4216135.1507903562!/fileImage/httpImage/image.jpg_gen/derivatives/square_460/colin-butler.jpg 460w,https://i.cbc.ca/1.4216135.1507903562!/fileImage/httpImage/image.jpg_gen/derivatives/square_620/colin-butler.jpg 620w" sizes="258px" src="https://i.cbc.ca/1.4216135.1507903562!/fileImage/httpImage/image.jpg_gen/derivatives/square_620/colin-butler.jpg"></p></div></figure></div></div><p>Colin Butler is a veteran CBC reporter who's worked in Moncton, Saint John, Fredericton, Toronto, Kitchener-Waterloo, Hamilton and London, Ont. Email: colin.butler@cbc.ca</p><ul><li><a href="http://www.cbc.ca/1.3677031">More by Colin Butler:</a></li></ul></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/london/curling-frankenbrooms-directional-fabric-1.5744754</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658102</guid>
            <pubDate>Fri, 02 Oct 2020 02:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coping with the TCP Time-Wait State on Busy Linux Servers ⁕ Vincent Bernat]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657821">thread link</a>) | @todsacerdoti
<br/>
October 1, 2020 | https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux | <a href="https://web.archive.org/web/*/https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lf-text">
            <div>
<p>TL;DR</p>
<p>Do not enable <code>net.ipv4.tcp_tw_recycle</code>—it doesn’t even
exist anymore since Linux 4.12. Most of the time, <code>TIME-WAIT</code> sockets
are harmless. Otherwise, jump to <a href="#summary">summary</a> for the
recommended solutions.</p>
</div>
<p>The Linux kernel documentation is not very helpful about what
<code>net.ipv4.tcp_tw_recycle</code> and <code>net.ipv4.tcp_tw_reuse</code> do. This lack of
documentation opens the path to numerous tuning guides advising to set
both these settings to 1 to reduce the number of entries in the
<code>TIME-WAIT</code> state. However, as stated by the <a href="https://manpages.debian.org/buster/manpages/tcp.7.en.html" title="tcp - TCP protocol">tcp(7)</a> manual page,
the <code>net.ipv4.tcp_tw_recycle</code> option is quite problematic for
public-facing servers as it won’t handle connections from two
different computers behind the same <abbr title="Network Address Translation">NAT</abbr> device, which is a problem
hard to detect and waiting to bite you:</p>
<blockquote>
<p>Enable fast recycling of <code>TIME-WAIT</code> sockets.  Enabling this option
is not recommended since this causes problems when working with <abbr title="Network Address Translation">NAT</abbr>
(Network Address Translation).</p>
</blockquote>
<p>I will provide here a more detailed explanation on how to properly
handle the <code>TIME-WAIT</code> state. Also, keep in mind we are looking at the
TCP stack of Linux. This is completely unrelated to <em>Netfilter</em>
connection tracking which may be tweaked in other ways.<sup id="fnref-netfilter"><a href="#fn-netfilter">1</a></sup></p>


<p>Let’s rewind a bit and have a close look at this <code>TIME-WAIT</code> state.
What is it? See the TCP state diagram below:<sup id="fnref-source"><a href="#fn-source">2</a></sup></p>
<figure><p><span><img alt="TCP state diagram" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/tcp/tcp-state-diagram-v2.svg" width="727" height="867" loading="lazy"></span></p><figcaption>TCP state diagram</figcaption></figure>
<p>Only the <strong>end closing the connection first</strong> will reach the
<code>TIME-WAIT</code> state. The other end will follow a path which usually
permits it to quickly get rid of the connection.</p>
<p>You can have a look at the current state of connections with <code>ss
-tan</code>:</p>
<div><pre><span></span><span>$</span> ss -tan <span>|</span> head -5
<span>LISTEN     0  511             *:80              *:*</span>
<span>SYN-RECV   0  0     192.0.2.145:80    203.0.113.5:35449</span>
<span>SYN-RECV   0  0     192.0.2.145:80   203.0.113.27:53599</span>
<span>ESTAB      0  0     192.0.2.145:80   203.0.113.27:33605</span>
<span>TIME-WAIT  0  0     192.0.2.145:80   203.0.113.47:50685</span>
</pre></div>

<h2 id="purpose">Purpose<a href="#purpose" title="Permanent link">#</a></h2>
<p>There are two purposes for the <code>TIME-WAIT</code> state:</p>
<ul>
<li>The most known one is to <strong>prevent delayed segments</strong> from one
    connection being accepted by a later connection relying on the
    same quadruplet (source address, source port, destination address,
    destination port). The sequence number also needs to be in a
    certain range to be accepted. This narrows a bit the problem but
    it still exists, especially on fast connections with large receive
    windows. <a href="https://tools.ietf.org/html/rfc1337" title="RFC 1337: TIME-WAIT Assassination Hazards in TCP">RFC 1337</a> explains in details what happens when the
    <code>TIME-WAIT</code> state is deficient.<sup id="fnref-rfc1337"><a href="#fn-rfc1337">3</a></sup> Here is an example of
    what could be avoided if the <code>TIME-WAIT</code> state wasn’t shortened:</li>
</ul>
<figure><p><span><img alt="Duplicate segments accepted in another connection" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/tcp/duplicate-segment.svg" width="512" height="524" loading="lazy"></span></p><figcaption>Due to a shortened TIME-WAIT state, a delayed TCP segment has been accepted in an unrelated connection.</figcaption></figure>
<ul>
<li>The other purpose is to ensure <strong>the remote end has closed the
    connection</strong>. When the last <em>ACK</em> is lost, the remote end stays in
    the <code>LAST-ACK</code> state.<sup id="fnref-lastack"><a href="#fn-lastack">4</a></sup> Without the <code>TIME-WAIT</code> state, a
    connection could be reopened while the remote end still thinks the
    previous connection is valid. When it receives a <em>SYN</em> segment (and
    the sequence number matches), it will answer with a <em>RST</em> as it is
    not expecting such a segment. The new connection will be aborted
    with an error:</li>
</ul>
<figure><p><span><img alt="Last ACK lost" src="https://d1g3mdmxf8zbo9.cloudfront.net/images/tcp/last-ack.svg" width="500" height="337" loading="lazy"></span></p><figcaption>If the remote end stays in LAST-ACK state because the last ACK was lost, opening a new connection with the same quadruplet will not work.</figcaption></figure>
<p><a href="https://tools.ietf.org/html/rfc793" title="RFC 793: Transmission Control Protocol">RFC 793</a> requires the <code>TIME-WAIT</code> state to last twice the time of the
<abbr title="Maximum Segment Lifetime">MSL</abbr>. On Linux, this duration is <strong>not</strong> tunable and is defined in
<code>include/net/tcp.h</code> as one minute:</p>
<div><pre><span></span><span>#define TCP_TIMEWAIT_LEN (60*HZ) </span><span>/* how long to wait to destroy TIME-WAIT</span>
<span>                                  * state, about 60 seconds     */</span><span></span>
</pre></div>

<p>There have been
<a href="http://web.archive.org/web/2014/http://comments.gmane.org/gmane.linux.network/244411" title="[RFC PATCH net-next] tcp: introduce tcp_tw_interval to specify the time of TIME-WAIT">propositions to turn this into a tunable value</a> but
it has been refused on the ground the <code>TIME-WAIT</code> state is a good
thing.</p>
<h2 id="problems">Problems<a href="#problems" title="Permanent link">#</a></h2>
<p>Now, let’s see why this state can be annoying on a server handling a
lot of connections. There are three aspects of the problem:</p>
<ul>
<li>the slot taken in the connection table preventing <strong>new
   connections</strong> of the same kind,</li>
<li>the <strong>memory</strong> occupied by the socket structure in the kernel, and</li>
<li>the additional <strong>CPU usage</strong>.</li>
</ul>
<p>The result of <code>ss -tan state time-wait | wc -l</code> is not a problem per
se!</p>
<h3 id="connection-table-slot">Connection table slot<a href="#connection-table-slot" title="Permanent link">#</a></h3>
<p>A connection in the <code>TIME-WAIT</code> state is kept for one minute in the
connection table. This means, another connection with the same
<em>quadruplet</em> (source address, source port, destination address,
destination port) cannot exist.</p>
<p>For a web server, the destination address and the destination port are
likely to be constant. If your web server is behind an L7
load-balancer, the source address will also be constant. On Linux, the
client port is by default allocated in a port range of about 30,000
ports (this can be changed by tuning
<code>net.ipv4.ip_local_port_range</code>). This means that only 30,000
connections can be established between the web server and the
load-balancer every minute, so about <strong>500 connections per second</strong>.</p>
<p>If the <code>TIME-WAIT</code> sockets are on the client side, such a situation is
easy to detect. The call to <code>connect()</code> will return <code>EADDRNOTAVAIL</code>
and the application will log some error message about that. On the
server side, this is more complex as there is no log and no counter to
rely on. In doubt, you should just try to come with something sensible
to list the number of used quadruplets:</p>
<div><pre><span></span><span>$</span> ss -tan <span>'sport = :80'</span> <span>|</span> awk <span>'{print $(NF)" "$(NF-1)}'</span> <span>|</span> <span>\</span>
      sed <span>'s/:[^ ]*//g'</span> <span>|</span> sort <span>|</span> uniq -c
<span>    696 10.24.2.30 10.33.1.64</span>
<span>   1881 10.24.2.30 10.33.1.65</span>
<span>   5314 10.24.2.30 10.33.1.66</span>
<span>   5293 10.24.2.30 10.33.1.67</span>
<span>   3387 10.24.2.30 10.33.1.68</span>
<span>   2663 10.24.2.30 10.33.1.69</span>
<span>   1129 10.24.2.30 10.33.1.70</span>
<span>  10536 10.24.2.30 10.33.1.73</span>
</pre></div>

<p>The solution is <strong>more quadruplets</strong>.<sup id="fnref-outgoing"><a href="#fn-outgoing">5</a></sup> This can be done in
several ways (in the order of difficulty to setup):</p>
<ul>
<li>use <strong>more client ports</strong> by setting <code>net.ipv4.ip_local_port_range</code> to
   a wider range,</li>
<li>use <strong>more server ports</strong> by asking the web server to listen to several
   additional ports (81, 82, 83, …),</li>
<li>use <strong>more client IP</strong> by configuring additional IP on the load
   balancer and use them in a round-robin fashion,<sup id="fnref-bind"><a href="#fn-bind">6</a></sup></li>
<li>use <strong>more server IP</strong> by configuring additional IP on the web
   server.<sup id="fnref-others"><a href="#fn-others">7</a></sup></li>
</ul>
<p>A last solution is to tweak <code>net.ipv4.tcp_tw_reuse</code> and
<code>net.ipv4.tcp_tw_recycle</code>. Don’t do that yet, we will cover these
settings later.</p>
<h3 id="memory">Memory<a href="#memory" title="Permanent link">#</a></h3>
<p>With many connections to handle, leaving a socket open for one
additional minute may cost your server some memory. For example, if
you want to handle about 10,000 new connections per second, you will
have about 600,000 sockets in the <code>TIME-WAIT</code> state. How much memory
does it represent? Not that much!</p>
<p>First, from the application point of view, a <code>TIME-WAIT</code> socket does
not consume any memory: the socket has been closed. In the kernel, a
<code>TIME-WAIT</code> socket is present in three structures (for three different
purposes):</p>
<ol>
<li>
<p>A <strong>hash table of connections</strong>, named the “TCP established hash
    table” (despite containing connections in other states) is used to
    locate an existing connection, for example when receiving a new
    segment.</p>
<p>Each bucket of this hash table contains both a list of connections
in the <code>TIME-WAIT</code> state and a list of regular active
connections. The size of the hash table depends on the system
memory and is printed at boot:</p>
<div><pre><span></span><span>$</span> dmesg <span>|</span> grep <span>"TCP established hash table"</span>
<span>[    0.169348] TCP established hash table entries: 65536 (order: 8, 1048576 bytes)</span>
</pre></div>

<p>It is possible to override it by specifying the number of entries
on the kernel command line with the <code>thash_entries</code> parameter.</p>
<p>Each element of the list of connections in the <code>TIME-WAIT</code> state
is a <code>struct tcp_timewait_sock</code>, while the type for other
states is <code>struct tcp_sock</code>:<sup id="fnref-tcptimewaitsock"><a href="#fn-tcptimewaitsock">8</a></sup></p>
<div><pre><span></span><span>struct</span> <span>tcp_timewait_sock</span> <span>{</span>
    <span>struct</span> <span>inet_timewait_sock</span> <span>tw_sk</span><span>;</span>
    <span>u32</span>    <span>tw_rcv_nxt</span><span>;</span>
    <span>u32</span>    <span>tw_snd_nxt</span><span>;</span>
    <span>u32</span>    <span>tw_rcv_wnd</span><span>;</span>
    <span>u32</span>    <span>tw_ts_offset</span><span>;</span>
    <span>u32</span>    <span>tw_ts_recent</span><span>;</span>
    <span>long</span>   <span>tw_ts_recent_stamp</span><span>;</span>
<span>};</span>

<span>struct</span> <span>inet_timewait_sock</span> <span>{</span>
    <span>struct</span> <span>sock_common</span>  <span>__tw_common</span><span>;</span>

    <span>int</span>                     <span>tw_timeout</span><span>;</span>
    <span>volatile</span> <span>unsigned</span> <span>char</span>  <span>tw_substate</span><span>;</span>
    <span>unsigned</span> <span>char</span>           <span>tw_rcv_wscale</span><span>;</span>
    <span>__be16</span> <span>tw_sport</span><span>;</span>
    <span>unsigned</span> <span>int</span> <span>tw_ipv6only</span>     <span>:</span> <span>1</span><span>,</span>
                 <span>tw_transparent</span>  <span>:</span> <span>1</span><span>,</span>
                 <span>tw_pad</span>          <span>:</span> <span>6</span><span>,</span>
                 <span>tw_tos</span>          <span>:</span> <span>8</span><span>,</span>
                 <span>tw_ipv6_offset</span>  <span>:</span> <span>16</span><span>;</span>
    <span>unsigned</span> <span>long</span>            <span>tw_ttd</span><span>;</span>
    <span>struct</span> <span>inet_bind_bucket</span> <span>*</span><span>tw_tb</span><span>;</span>
    <span>struct</span> <span>hlist_node</span>        <span>tw_death_node</span><span>;</span>
<span>};</span>
</pre></div>

</li>
<li>
<p>A <strong>set of lists of connections</strong>, called the “death row”, is used
    to expire the connections in the <code>TIME-WAIT</code> state. They are
    ordered by how much time left before expiration.</p>
<p>It uses the same memory space as for the entries in the hash table
of connections. This is the <code>struct hlist_node tw_death_node</code>
member of <code>struct inet_timewait_sock</code>.<sup id="fnref-deathrow"><a href="#fn-deathrow">9</a></sup></p>
</li>
<li>
<p>A <strong>hash table of bound ports</strong>, holding the locally bound ports
    and the associated parameters, is used to determine if it is safe
    to listen to a given port or to find a free port in the case of
    dynamic bind. The size of this hash table is the same as the size
    of the hash table of connections:</p>
<div><pre><span></span><span>$</span> dmesg <span>|</span> grep <span>"TCP bind hash table"</span>
<span>[    0.169962] TCP bind hash table entries: 65536 (order: 8, 1048576 bytes)</span>
</pre></div>

<p>Each element is a <code>struct inet_bind_socket</code>. There is
one element for each locally bound port. A <code>TIME-WAIT</code> connection
to a web server is locally bound to the port 80 and shares the
same entry as its sibling <code>TIME-WAIT</code> connections. On the other
hand, a connection to a remote service is locally bound to some
random port and does not share its entry.</p>
</li>
</ol>
<p>We are only concerned by the space occupied by <code>struct
tcp_timewait_sock</code> and <code>struct inet_bind_socket</code>. There is one <code>struct
tcp_timewait_sock</code> for each connection in the <code>TIME-WAIT</code> state,
inbound or outbound. There is one dedicated <code>struct inet_bind_socket</code>
for each outbound connection and none for an inbound connection.</p>
<p>A <code>struct tcp_timewait_sock</code> is only 168 bytes while a <code>struct
inet_bind_socket</code> is 48 bytes:</p>
<div><pre><span></span><span>$</span> sudo apt-get install linux-image-<span>$(</span>uname -r<span>)</span>-dbg
<span>[...]</span>
<span>$</span> gdb /usr/lib/debug/boot/vmlinux-<span>$(</span>uname -r<span>)</span>
<span>(gdb)</span> <span>print sizeof(struct tcp_timewait_sock)</span>
<span> $</span><span>1</span> <span>=</span> <span>168</span>
<span>(gdb)</span> <span>print sizeof(struct tcp_sock)</span>
<span> $</span><span>2</span> <span>=</span> <span>1776</span>
<span>(gdb)</span> <span>print sizeof(struct …</span></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux">https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux</a></em></p>]]>
            </description>
            <link>https://vincent.bernat.ch/en/blog/2014-tcp-time-wait-state-linux</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657821</guid>
            <pubDate>Fri, 02 Oct 2020 01:17:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O, Little N]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24657747">thread link</a>) | @adamzerner
<br/>
October 1, 2020 | https://adamzerner.bearblog.dev/big-o-little-n/ | <a href="https://web.archive.org/web/*/https://adamzerner.bearblog.dev/big-o-little-n/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>I remember when I was first learning about hash tables. I thought I stumbled across an ingenious optimization for dealing with hash collisions. Before explaining my optimization, let me first briefly explain how hash tables work and what hash collisions are. I also made a video if you're interested.</p>
<p><a href="http://www.youtube.com/watch?v=pM9zhZB2KkM" title="Hash Tables"><img alt="" src="http://img.youtube.com/vi/pM9zhZB2KkM/0.jpg"></a></p>
<p>Say that we have a hash that maps someone's name to their age. <code>"adam"</code> is <code>27</code>, so we want to enter that into our hash.</p>
<p><img alt="" src="https://i.ibb.co/qWdjbhM/Slice.png"></p>
<p>Here's what happens:</p>
<ul>
<li><code>"adam"</code> gets put through a hash function.</li>
<li>The hash function spits out <code>7</code>.</li>
<li><code>7</code> is the index of the array where we are going to store <code>"adam"</code>'s value.</li>
<li>So we store <code>27</code> into <code>array[7]</code>.</li>
</ul>
<p>If we run <code>hash.get("adam")</code> in the future and need to look up the value for <code>"adam"</code>, we:</p>
<ul>
<li>Run <code>"adam"</code> through the hash function.</li>
<li>Get <code>7</code> as the output.</li>
<li>This means we have to look at <code>array[7]</code> to get the value.</li>
<li>So we look at <code>array[7]</code> to get our value.</li>
</ul>
<p>Hopefully if we have a key of <code>"alice"</code> or <code>"bob"</code> it'll hash to a different index. But... what happens if it hashes to the same index? That's called a hash collision.</p>
<p><img alt="" src="https://i.ibb.co/sJbJKnD/Slice.png"></p>
<p>A common approach is that if there's a collision, you store the values in a linked list.</p>
<p><img alt="" src="https://i.ibb.co/VJsSW3T/Slice.png"></p>
<p>Fair enough. That makes sense.</p>
<p>But wait!!! It takes <code>O(n)</code> time to look up a value in a linked list. Can't we use a binary search tree to speed that up to <code>O(log n)</code>???</p>
<p><img alt="" src="https://i.ibb.co/R3Vrc10/Slice.png"></p>
<p>Or... can't we take it a step further and use a <em>hash inside of a hash</em> to get the lookup time all the way down to <code>O(1)</code>?!</p>
<p><img alt="" src="https://i.ibb.co/7CyYNWY/Slice.png"></p>
<p>I hate to say it, but however many years ago when I had these thoughts, there were a few moments where I thought I was a genius. Now when I look back at that former self, I facepalm.</p>
<p>It is true that going from a linked list to a BST to a hash takes you from <code>O(n)</code> to <code>O(logn)</code> to <code>O(1)</code> lookup time. However, since collisions are rare, <code>n</code> is going to be small. And when <code>n</code> is small, <code>O(n)</code> might be faster than <code>O(1)</code>.</p>
<p>To understand why that is, think back to what Big-O really means. I think it helps to think about it as a "math thing" instead of a "programming thing". Consider two functions:</p>
<pre><code>f(n) = 4n + 1000
g(n) = 2n^2 + 5
</code></pre>
<p>Big-O of <code>f</code> is <code>O(n)</code> and Big-O of <code>g</code> is <code>O(n^2)</code>. We just focus on the part that "really matters". When <code>n</code> gets really big, the fact that it's <code>4n</code> doesn't really matter. Nor does the <code>+ 1000</code>.</p>
<p>But what about when <code>n</code> is small? Well, let's look at happens when <code>n</code> is <code>5</code>:</p>
<pre><code>f(5) = 4(5) + 1000 = 20 + 1000 = 1020
g(5) = 2(5^2) + 5 = 2(25) + 5 = 50 + 5 = 55
</code></pre>
<p>Look at that! The <code>O(n^2)</code> function is almost 20 times faster than the <code>O(n)</code> function!</p>
<p>And <em>that</em> is basically why they use a linked list instead of a BST or hash to handle collisions. Since <code>n</code> is small, Big-O isn't the right question to ask.</p>
<hr>
<p>Here's another example. I just wrote the following code while prepping for an interview:</p>
<pre><code>const isVowel = (char) =&gt; ["a", "e", "i", "o", "u"].includes(char);
</code></pre>
<p>Normally I wouldn't think twice about it, but since interviewers care so much about time complexity, I stopped to think about whether it could be improved.</p>
<p>And it hit me that it's actually <code>O(n)</code>(<a href="https://news.ycombinator.com/item?id=24660824">caveat</a>), because we've got an array and have to iterate over every element to see if the element matches <code>char</code>. It's easy to overlook this because we're using <code>includes</code> and not writing the code ourselves.</p>
<p>So then I thought that maybe we could use a hash instead to get <code>O(1)</code> lookup. Something like this:</p>
<pre><code>const isVowel = (char) =&gt; {
  const vowels = {
    a: true,
    e: true,
    i: true,
    o: true,
    u: true,
  };

  return !!vowels[char];
};
</code></pre>
<p>But then I realized that this is the same mistake I made with the hash collision stuff however many years ago. <em><code>n</code> is small, so Big-O isn't the question we should be asking</em>. Here <code>n</code> is <code>5</code>.</p>
<p>I think that the array approach would actually be faster than the hash approach, even though it's <code>O(n)</code> instead of <code>O(1)</code>. The reason for this is called locality.</p>
<p>If you dive deep under the hood, when you look up an element in an array, the CPU actually grabs a bunch of adjacent elements as well as the one you wanted, and it stores the adjacent elements in a cache. So here when we look up <code>"a"</code> in the array, it'll probably grab <code>"a"</code>, <code>"e"</code>, <code>"i"</code>, <code>"o"</code>, and <code>"u"</code>. And so next time when we want to grab <code>"e"</code>, it can take it from the cache, which is a lot faster. This works because the elements in the array are close to each other in the physical memory. But with a hash, my understanding is that they wouldn't be so close, and thus we wouldn't benefit from this spatial locality effect.</p>
<p>I'm no low-level programming wiz so I'm not sure about any of this. That's ok, I think it's beside the point of this post. The real point of this post is that when you have a little <code>n</code>, Big-O doesn't matter.</p>
</div>
</div></div>]]>
            </description>
            <link>https://adamzerner.bearblog.dev/big-o-little-n/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657747</guid>
            <pubDate>Fri, 02 Oct 2020 00:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Designer's Guide to JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657624">thread link</a>) | @philipcdavis
<br/>
October 1, 2020 | https://react.design/javascript | <a href="https://web.archive.org/web/*/https://react.design/javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You can learn the basics of JavaScript quickly. You don't need a engineering degree, or a front end bootcamp.</p><p>Learning the basics of JavaScript is enough to get started with modern frameworks like React.js. Once you know the basics, you can do some truly amazing things.</p><p>You can quickly spin up interactive prototypes.<br>You can use live data sets.<br>You can create web, mobile, and desktop apps.<br>You can define interfaces in high fidelity.<br>You can write scripts to automate daily tasks.<br>You can make plugins for design tools like Sketch and Figma.<br>You can build with modern frameworks like React.js.</p><p>You can't learn JavaScript in a day, but you can learn it quickly. The best way to learn is to build. This guide is meant to give you enough information to start building. </p><h2>Editor</h2><p><img src="https://react.design/assets/javascript/theme.png">
</p><p>Before we write any code, it's a good idea to get comfortable with your text editor. I'd recommend using a text editor like <a href="https://code.visualstudio.com/">VSCode</a>, or <a href="https://atom.io/">Atom</a> as you write JavaScript. They're both free and support lots of plugins to make things easier. You can also find lots of nice themes. Here's a <a href="https://marketplace.visualstudio.com/items?itemName=Framer.framer-syntax">theme</a> for VSCode that I like.</p><p>Learning keyboard shortcuts, and customizing the look of your editor will make for a much more enjoyable coding experience.</p><h2>Setup</h2><p>JavaScript is a scripting language that for our intents and purposes, will be executed by the browser.</p><p>There are multiple ways to include javascript inside your webpage. The way we will use javascript will be by including <code>&lt;script&gt;</code> tags right before the closing <code>&lt;/body&gt;</code> tag. </p><pre><code><span>&lt;!</span><span>DOCTYPE</span><span> </span><span>html</span><span>&gt;</span><span>
</span><span></span><span>&lt;</span><span>html</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>head</span><span>&gt;</span><span>&lt;/</span><span>head</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>body</span><span>&gt;</span><span>
</span>    
<span>    </span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span>        </span><span>// Javascript will go here</span><span>
</span><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"Hello friend!"</span><span>)</span><span>
</span><span>    </span><span>&lt;/</span><span>script</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;/</span><span>body</span><span>&gt;</span><span>
</span><span></span><span>&lt;/</span><span>html</span><span>&gt;</span></code></pre><p>Weâ€™ll put our javascript inside here, but we could also reference an external file.
<code>console.log()</code> is a helpful tool for debugging. Here I'm writing "Hello Friend!" To the console. You an access the console in Chrome using the <code>CMD+Option+J</code> shortcut.</p><p><img src="https://react.design/assets/javascript/console.png">
</p><p>There are 5 core concepts in JavaScript that are important to understand.</p><p><strong>1. Variables</strong><br><strong>2. Data Structures</strong><br><strong>3. Loops</strong><br><strong>4. Conditionals</strong><br><strong>5. Functions</strong></p><h2>Variables</h2><p>Variables are containers that hold values. These values can take lots of different forms. If you wanted a variable to hold a number you could write it as <code>var num = 20;</code>. If I use <code>console.log(num)</code> it should show me the number twenty.</p><p>Variables can be referenced later. <code>var double = num * 2; // 40</code></p><p>Variables can hold lots of different data types. I want to discuss a few different common ways to hold data. There are primitive data types like numbers, which we used earlier, There are strings, which are just a way to store text, and booleans which are values that are either true or false.</p><pre><code><span>var</span><span> days </span><span>=</span><span> </span><span>40</span><span>;</span><span> </span><span>// Number</span><span>
</span><span></span><span>var</span><span> label </span><span>=</span><span> </span><span>"Hello"</span><span>;</span><span> </span><span>// String</span><span>
</span><span></span><span>var</span><span> hidden </span><span>=</span><span> </span><span>true</span><span>;</span><span> </span><span>// Boolean</span></code></pre><h2>Data Structures</h2><p>In addition to primitive data types there are others that have more complex structures. Two of these important types are objects (sometimes called object literals) and arrays. </p><p>Objects can be defined using curly braces. 
<code>var obj = {}</code></p><p>What goes inside the curly braces are a collection of key value pairs. The key goes first, followed by a colon, and then the value. </p><pre><code><span>var</span><span> obj </span><span>=</span><span> </span><span>{</span><span>
</span><span>  key</span><span>:</span><span> value
</span><span></span><span>}</span></code></pre><p>Keys are labels that help you find the data you want to store. Keys in a single object must be unique. Values can be any data type. Numbers, strings, arrays, and even other objects. 
Here's an example Object with multiple key value pairs in action:</p><pre><code><span>var</span><span> profile </span><span>=</span><span> </span><span>{</span><span>
</span><span>	name</span><span>:</span><span> </span><span>'Philip'</span><span>,</span><span> 
</span><span>	age</span><span>:</span><span> </span><span>25</span><span>,</span><span> 
</span><span>	contact</span><span>:</span><span> </span><span>{</span><span>
</span><span>		twitter</span><span>:</span><span> </span><span>'philipcdavis'</span><span>,</span><span> 
</span><span>		email</span><span>:</span><span> </span><span>'reactfordesigners@gmail.com'</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Name, age, contact, twitter, and email are all different keys in this object. The values are all different and many have different value types. Some are strings, some are numbers, and some are other objects.</p><p>This nested structure is common and you will see it a lot when working with data sets.</p><p>There are two ways to access a value inside an object. The first way is sometimes called dot notation: <code>profile.name</code>. The second way is by using brackets <code>profile['name']</code>. Bracket notion is useful when your key name is dynamic.</p><p>The other data type thatâ€™s important to know about is the Array. You define an array with square brackets. </p><p><code>var myArr = [];</code></p><p>You can store any type of data inside these arrays and they don't need to all be the same type (though they usually are). An example array might look like this: </p><pre><code><span>var</span><span> teams </span><span>=</span><span> </span><span>[</span><span>'lakers'</span><span>,</span><span> </span><span>'nuggets'</span><span>,</span><span> </span><span>'rockets'</span><span>]</span><span>;</span></code></pre><p>Instead of using keys, arrays use a built in index to keep track of location. The index of arrays starts at 0. If we wanted to access the second value of this array (nuggets) we could do so by typing <code>teams[1];</code></p><p>If your data was as simple as this, using objects and arrays might seem unnecessary. They start to shine when you have data sets that are larger. To work with more data, we'll probably want to use a loop</p><h2>Loops</h2><p>Loops enable you to run a block of code multiple times. You can use a loop with objects and arrays to execute a block of code on each item in the structure. </p><p>To loop through each value in an array you can use a for loop that executes a block. </p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Block to be executed</span><span>
</span><span></span><span>}</span></code></pre><p>What goes into the parenthesis determines how many times the block of code is executed. The first value is a counter variable. <code>i</code> is often used to refer to the fact that it's used as the index value of the array. We will start the counter at 0. </p><p>The next value is called the conditional. Once the conditional is false, the loop will end. We can set the value to be <code>i &lt; teams.length</code>. The <code>.length</code> is a helper value built into every array that will tell you how many items are in the array. Once the value of the counter is as great as the length of the array, we can stop looping. The last value <code>i++</code> is what we want to happen after our loop runs. We want our counter to increase in value by one every time the loop runs.</p><p>If we log a string, you can see that it will print out 4 times.
If we log the value i, you can see that it increments up. If you combine this incremented value i with our array, you can see how we can access each value in our array.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span>i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span><span> 
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>
</span><span></span><span>}</span><span>;</span></code></pre><p>There are other types of loops but they all are doing something pretty similar, running a block of code multiple times. Thatâ€™s the essential work of a loop.</p><h2>Conditionals</h2><p>Next up on our list is conditionals. The most common type of conditional is the if/else statement. </p><pre><code><span>if</span><span> </span><span>(</span><span>conditional</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to true'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to false'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>If the <code>conditional</code> value in the parenthesis evaluates to true, the block inside the first set of curly brackets is run, otherwise the else block is run.</p><p>Letâ€™s use it in combination with our loop to log only the first two items in our array. Because we donâ€™t need the else here, we can remove it, and weâ€™ll get the same result.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>if</span><span> </span><span>(</span><span>i </span><span>&lt;</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>	  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Youâ€™ll use these conditionals to to control what gets executed when.</p><h2>Functions</h2><p>Functions allow you to create reusable and modular code.</p><p>Another way to say it is that they are blocks of code than can be executed whenever they are needed. </p><p>Here's what one looks like</p><pre><code><span>function</span><span> </span><span>add</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>var</span><span> total </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>	</span><span>return</span><span> total</span><span>;</span><span>
</span><span></span><span>}</span><span> </span></code></pre><p>Here we have a simple function that takes two input values, adds them together, and then returns the total. Weâ€™ll use generic names for our input arguments. You can name these pretty much whatever you want, but they will be used within our block so if your function is complex, itâ€™s good to have descriptive names. Because this is a pretty simple function we're using <code>a</code> and <code>b</code>. </p><p>What we've created is a function declaration. In order to execute, or invoke our function we can call <code>add(2,50)</code>.
<code>console.log(add(2,50)) // 52</code></p><p><code>console.log</code> is itself a function. Functions can be stored in variables, objects, arrays, or even passed into other functions.</p><p>One other important thing to note about functions is how they affect variables inside them. If you define a variable within a function, the variable cannot be used outside the function. That's because javascript has a function based scope.</p><hr><p>Javascript is a really fun language to learn. If you feel comfortable with the material above you can do a lot! Most of JavaScript is just building on to these core concepts.</p><h2>Modern JavaScript</h2><p>In 2015 a set of new syntax and features were introduced that made writing JavaScript easier. Many of the following updates are meant to help you write code faster and cleaner. If you're using modern frameworks like React you'll often see them in examples.</p><h3>Const / Let</h3><p>This is just a new way to write variables. </p><pre><code><span>const</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span><span>
</span><span></span><span>let</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span></code></pre><p><code>const</code> values cannot be reassigned after the initial assignment. This is usually the default way of creating variables. </p><p><code>let</code> values can be reassigned but are scoped to conditionals, the same way all variables are scoped to functions. If you declare one inside an if/else statement it won't be available outside the statement.</p><h3>Arrow Functions</h3><p>This a shorthand for writing functions.
Instead of writing:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>function</span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span>{</span><span> </span><span>return</span><span> a </span><span>+</span><span> b </span><span>}</span></code></pre><p>You can use an arrow function which looks like this:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span> </span><span>=&gt;</span><span> a </span><span>+</span><span> b</span></code></pre><p>If your function takes a single parameter you can omit the parenthesis.</p><pre><code><span>const</span><span> </span><span>getStyle</span><span> </span><span>=</span><span> </span><span>a</span><span> </span><span>=&gt;</span><span> a</span><span>.</span><span>style</span></code></pre><h3>Template Literals</h3><p>Previously is you wanted dynamic strings, you would insert values using the following syntax.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>"Hello my name is"</span><span> </span><span>+</span><span> firstName </span><span>+</span><span> </span><span>". Welcome!"</span></code></pre><p>Using template literals, you can use the backtick for strings, and <code>${}</code> to insert variables.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>`</span><span>Hello my name is </span><span>${</span><span>firstName</span><span>}</span><span>. Welcome!</span><span>`</span></code></pre><h3>Imports and Exports</h3><p>Instead of using large javascript files, you'll often want to break your code into smaller modules and export anything that other modules need to access.</p><pre><code><span>// Colors.js</span><span>
</span><span></span><span>export</span><span> </span><span>const</span><span> colors </span><span>=</span><span> </span><span>{</span><span>
</span><span>	blue</span><span>:</span><span> </span><span>"#EA3232"</span><span>,</span><span>
</span><span>	red</span><span>:</span><span> </span><span>"#4062F3"</span><span>,</span><span>
</span><span>	yellow</span><span>:</span><span> </span><span>"#FFAD05"</span><span>,</span><span>
</span><span></span><span>}</span></code></pre><p>In a different file you can import these colors using the following syntax.</p><pre><code><span>import</span><span> </span><span>{</span><span>colors</span><span>}</span><span> </span><span>from</span><span> </span><span>'./Color'</span></code></pre><p>You can also define default exports …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://react.design/javascript">https://react.design/javascript</a></em></p>]]>
            </description>
            <link>https://react.design/javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657624</guid>
            <pubDate>Fri, 02 Oct 2020 00:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic-Differentiation-Worked-Examples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657571">thread link</a>) | @formalsystem
<br/>
October 1, 2020 | http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/ | <a href="https://web.archive.org/web/*/http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h3>automatic-differentiation-worked-examples</h3>
  
<p>– forwards and reverse</p>
<h2 id="introduction">Introduction</h2>
<p>This article demonstrates how to perform source transformations on a program to generate forward mode and reverse mode derivative programs (automatic differentiation, or “AD”). My aim is to write the shortest possible article that communicates all the essential features of a source-to-source AD system with a particular focus on making the reverse mode transformation clear.</p>
<p>The goal of brevity means that a lot of possible commentary has been omitted. If you find this makes some part of the article hard to understand then please <a href="http://web.jaguarpaw.co.uk/~tom/contact">contact me</a> and I’ll do my best to clarify. In particular this article contains hardly any mathematical content at all. I hope that the reader who is familiar with multivariate calculus will be able to obtain an intuitive understanding of how AD relates to mathematical techniques he or she is already familiar with. A more in-depth description of the relationship will have to wait for another article.</p>
<h2 id="the-program">The program</h2>
<p>Let’s consider the following pseudocode program that performs some elementary arithmetic through a sequence of assignment statements.</p>
<pre><code>p = 7 * x
r = 1 / y
q = p * x * 5
v = 2 * p * q + 3 * r</code></pre>
<p><code>x</code> and <code>y</code> are not defined in the program so I’m going to informally consider them to be “inputs”; <code>v</code> is not used anywhere so I’m going to consider it to be the “output”. (I won’t burden the article by formalising these notions here.)</p>
<h2 id="preparation">Preparation</h2>
<p>We’ll do a small amount of preparation to our original program which will preserve its behaviour and get it into a form in which it is straightforward to apply the automatic differentiation (AD) algorithms. It is possible to apply AD algorithms without doing these transformations first but then the AD algorithms would have to do equivalent operations implicitly. Doing these transformations first is a kind of <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns</a>.</p>
<h3 id="use-prefix-functions-with-exactly-one-argument">Use prefix functions with exactly one argument</h3>
<p>Let’s use prefix functions instead of <a href="https://en.wikipedia.org/wiki/Infix_notation">infix operators</a>. Infix operators are more familiar for arithmetic but the AD algorithms will be clearer to present if we use prefix functions. Additionally I want every function to have exactly one argument (although that argument may be a tuple). Single-argument style will make the reverse mode transformation much clearer (although it does not make any difference for forward mode). For example, <code>x1 + x2</code> would become <code>add (x1, x2)</code>. Our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
q = mul (mul (p, x), 5)
v = add (mul (mul (2, p), q), mul (3, r))</code></pre>
<h3 id="no-nested-subexpressions">No nested subexpressions</h3>
<p>Next let’s convert to a form where every function is applied to (tuples of) variables and constants only, i.e.&nbsp;where there are no nested sub-expressions (besides potentially nested tuples). We assign each nested sub-expression to an intermediate variable. For example</p>
<pre><code>a = add (add (b, c), d)</code></pre>
<p>would become</p>
<pre><code>i = add (b, c)
a = add (i, d)</code></pre>
<p>The choice of <code>i</code> is arbitrary; it just has to be a variable that’s not used elsewhere in our program. This form without nested subexpressions is a lot like <a href="https://en.wikipedia.org/wiki/A-normal_form">ANF</a> from the field of functional compiler construction. It’s also a lot like the <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">SSA form</a> of assembly language. After removing nested subexpressions, our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<h2 id="differentiation-line-by-line">Differentiation line-by-line</h2>
<p>We have performed all the transformations needed to prepare our program and we are ready to proceed to differentiation. We will differentiate the program line-by-line, that is, both the forward mode and reverse mode differentiation algorithms will generate one line of derivative code for each line of input code. But what <em>is</em> the derivative of an assignment statement? For forward mode, the derivatives correspond quite closely to what you might be familiar with from a first multivariate calculus course..</p>
<h3 id="examples">Examples</h3>
<h4 id="addition">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (dx1, dx2)</code></pre>
<h4 id="multiplication">Multiplication</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (mul (x2, dx1), mul (x1, dx2))</code></pre>
<h4 id="division">Division</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = div (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (div (dx1, x2), negate (mul (div (x1, mul (x2, x2)), dx2)))</code></pre>
<h2 id="forward-mode">Forward mode</h2>
<p>The forward mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a derivative line (listed on the right). To each line we apply exactly one rule and the form of the rule does not depend on any of the other lines.</p>
<pre><code>p = mul (7, x)   | dp = mul (7, dx)
r = div (1, y)   | dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)  | di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)  | dq = mul (di1, 5)
i2 = mul (2, p)  | di2 = mul (2, dp)
i3 = mul (i2, q) | di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)  | di4 = mul (3, dr)
v = add (i3, i4) | dv = add (di3, di4)</code></pre>
<p>If we form a new program consisting of the sequence of assignments on the left followed by the sequence of assignments on the right then we have a program that calculates the forward derivative! The “inputs” of this program are <code>x</code>, <code>y</code>, <code>dx</code> and <code>dy</code>. The “outputs” are <code>v</code> and <code>dv</code>.</p>
<p>(The derivatives of constants are zero and I’ve left terms that are zero out for simplicity.)</p>
<p>In fact we can be a little more clever. We can interleave the assignments, so an assignment from the left is immediately followed by its corresponding assignment from the right, that is</p>
<pre><code>p = mul (7, x)
dp = mul (7, dx)
r = div (1, y)
dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)
di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)
dq = mul (di1, 5)
i2 = mul (2, p)
di2 = mul (2, dp)
i3 = mul (i2, q)
di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)
di4 = mul (3, dr)
v = add (i3, i4)
dv = add (di3, di4)</code></pre>
<p>This interleaving demonstrates an important property of the automatic derivative: that it uses space proportional to the space usage of the original program. Specifically, as soon as we no longer need a variable that was assigned in the original program we no longer need the corresponding <code>d</code> version either.</p>
<p>We can also see another important property of the forward derivative: it runs in time proportional to the run time of the original program (assuming that the derivative of every primitive runs in time proportional to the run time of the primitive itself).</p>
<h2 id="reverse-mode-requires-two-additional-ideas">Reverse mode requires two additional ideas</h2>
<p>Now that we’ve shown how to generate the forward mode derivative we can move on to the reverse mode derivative. Reverse mode requires two additional ideas:</p>
<ol type="1">
<li><p>We need to convert our original program to “explicit duplication” form: if a variable is used more than once then we make that explicit in the structure of the program. This is unusual but straightforward.</p></li>
<li><p>We need to use a form of the derivative that will be unfamiliar to most readers. It will appear quite bizarre when seeing it for the first time but it is crucial to implementing the reverse mode derivative.</p></li>
</ol>
<h2 id="explicit-duplication-form">Explicit duplication form</h2>
<p>Before applying the reverse mode AD transformation we will convert to “explicit duplication” form. Again, the transformation is not strictly required but if we omit it then the differentiation pass will have to do it implicitly. We take the ANF form of the program and insert explicit duplications (<code>dup</code>) for any variable that is used more that once. Recall that after removing nested subexpressions our program was</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>We can see that <code>x</code> and <code>p</code> appear on the right hand side (i.e.&nbsp;are consumed) twice each. Therefore, they will need explicit duplication, so that each variable in the resulting program is used only once. With explicit duplication the program looks like</p>
<pre><code>(x1, x2) = dup x
p = mul (7, x1)
(p1, p2) = dup p
r = div (1, y)
i1 = mul (p1, x2)
q = mul (i1, 5)
i2 = mul (2, p2)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>(If a variable were used <span><em>n</em></span> times then we would have to insert <span><em>n</em> − 1</span> <code>dup</code>s for it. In our example no variable is used more than twice.)</p>
<p>Notice that now not only is every variable defined exactly once, but every variable is also <em>used</em> exactly once (except the inputs and outputs, <code>x</code>, <code>y</code> and <code>v</code> – I won’t say more here about how exactly these seemingly special cases fit into the story). This property is important for a reason which will be explained when we come to generate the reverse mode program.</p>
<h2 id="differentiation-line-by-line-1">Differentiation line-by-line</h2>
<p>The line-by-line differentiation rules for generating the reverse mode need another article to explain thoroughly, but in this article I will hope to provide some basic intuition via examples and the informal notion that the reverse mode program calculates how sensitive the output is to different variables. For example, if the variable <code>y</code> appears in the original program then the variable <code>d_dy</code> will appear in the reverse mode program and measures “how sensitive the output is to small changes in <code>y</code>”. (I’ll abbreviate this to “<code>d_dy</code> is the sensitivity to <code>y</code>”.)</p>
<h3 id="examples-1">Examples</h3>
<h4 id="addition-1">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivatives are</p>
<pre><code>d_dx1 = d_dy
d_dx2 = d_dy</code></pre>
<p>because the sensitivity to <code>x1</code> is the same as the sensitivity to <code>y</code> (and likewise for <code>x2</code>). This is written on a single line as</p>
<pre><code>(d_dx1, d_dx2) = dup (d_dy)</code></pre>
<h4 id="multiplication-1">Multiplication</h4>
<p>If a line of our program was</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>(d_dx1, d_dx2) = (mul (x2, d_dy), mul (x1, d_dy))</code></pre>
<p>because the sensitivity to <code>x1</code> is <code>x2</code> times the sensitivity to <code>y</code> (and similarly for <code>x2</code>).</p>
<h4 id="duplication">Duplication</h4>
<p>If a line of our program was</p>
<pre><code>(x1, x2) = dup (x)</code></pre>
<p>then the derivative line is</p>
<pre><code>d_dx = add (d_dx1, d_dx2)</code></pre>
<p>because the sensitivity to <code>x</code> is the sensitivity to <code>x1</code> plus the sensitivity to <code>x2</code>.</p>
<h2 id="generating-reverse-mode-code">Generating reverse mode code</h2>
<p>Like forward mode before it, the reverse mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</a></em></p>]]>
            </description>
            <link>http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657571</guid>
            <pubDate>Fri, 02 Oct 2020 00:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Community Moderation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657148">thread link</a>) | @minimaxir
<br/>
October 1, 2020 | https://www.joinclubhouse.com/on-community-moderation | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/on-community-moderation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Oct 1, 2020</p>
      <p>Since <a href="https://www.joinclubhouse.com/check-1-2-3">our last blog post</a>, Clubhouse has gone from a small community of beta testers to a growing network of communities, made up of people with vastly different opinions, experiences, worldviews and perspectives. This past week, people on Clubhouse have hosted several intense conversations on topics of identity, ethnicity, gender, racism, and religion. These conversations led to a number of serious incident reports, and we received questions and concerns from our community about how we plan to scale safety and moderation on Clubhouse. In the wake of this, we wanted to share some thoughts regarding what we stand for as a company, what we will and will not tolerate, what we are doing to prevent abuse, and how we plan to empower conversation hosts with better moderation tools as we grow.</p>
      <p>First, we unequivocally condemn Anti-Blackness, Anti-Semitism, and all other forms of racism, hate speech and abuse on Clubhouse. Our <a href="http://community.joinclubhouse.com/">Community Guidelines</a> and <a href="http://tos.joinclubhouse.com/">Terms of Service</a> make this clear, and we have trust and safety procedures in place to address any violation of these rules. People who violate them are warned, suspended, or removed completely from the platform, depending on the severity of the offense. This is a critical area of investment for us as a company and we are working hard to continue building tools and policies that are robust and that account for the unique dynamics of real-time voice conversations and group discussions.</p>
      <p>Second, we celebrate the fact that Clubhouse is not one single community, but a network of interconnected and diverse communities. As these communities grow, we need to provide moderators and club leaders with better tools and infrastructure to bring people together. Our goal is to empower them to host important, and even difficult, conversations—because some of the most powerful moments on Clubhouse happen when you find yourself speaking with a room full of people whose backgrounds and experiences are completely different from your own. These conversations often go on for hours, spilling out into breakout rooms full of people connecting, debating, evolving their worldviews and recognizing their blindspots. Our hope for Clubhouse is that it can be a new type of network based on empathy, discussion and sensemaking, rather than polarization. We think social media needs more of this.</p>
      <p>PREVENTING ABUSE</p>
      <p>Our Terms of Service and Community Guidelines define what type of behavior is allowed on Clubhouse and we are committed to addressing behavior that violates these rules. Here is what we’re doing to help with that:</p>
      <ul>
          <li><u>We’re taking action on all incident reports.</u> Any time someone reports a violation of our Terms of Service or Community Guidelines, we immediately investigate it. We don’t discuss these investigations publicly for user privacy reasons, but they are happening, and when rules are violated, corrective action is taken. This week, we’re also shipping real-time systems to investigate incidents more quickly and empower moderators to restrict and end rooms.</li>
          <li><u>We’re continuing to scale our trust and safety operations</u>. This is an ongoing effort for us that spans people, policy and product. On the people side, we’re focused on:</li>
          <ul>
              <li><u>Adding advisors.</u> We are building a team of advisors with deep expertise in trust, safety, diversity and inclusion to provide ongoing advice and input.</li>
              <li><u>Engaging directly with the community.</u> Since the earliest days of Clubhouse we’ve been engaging deeply with a diverse cross-section of our community to understand their needs—through weekly Town Halls, New User Orientation sessions and deeper discussions, both on Clubhouse and off. We plan to continue the dialogue and see how these formats can be improved. We also use these discussions to continuously evolve our Terms of Service, Privacy Policy and Community Guidelines. These will be living documents.</li>
              <li><u>Growing our team.</u> Our trust and safety efforts are staffed to respond swiftly to incident reports, and we plan to proactively scale this operation as we grow. </li>
            </ul>
          
          <li><u>We’re shipping a wave of new safety features</u>. Over the past couple months we introduced blocking, muting, in-room reporting, and the ability for moderators to end a room. This week we are shipping a wave of new enhancements to make in-room reporting more real-time, specific and robust. We are also making the Community Guidelines accessible from every room and shipping new features to empower Clubhouse moderators.</li>
        </ul>
      
      <p>EMPOWERING MODERATORS AND CLUB LEADERS</p>
      <p>As we take these steps, we want to avoid conflating abuse with other things that can feel uncomfortable—like differences in opinion or conversational style. Abuse, racism, religious intolerance, sexism and hate speech are never okay. Targeted and coordinated harassment is never okay. But what about general rudeness? Or holding opposing political viewpoints? While these things might seem jarring, we don’t believe they should be banned. We want to make sure that when you use Clubhouse, you get to choose your communities, your rooms, and your style of conversation. Here’s what we’re working on to enable this:</p>
      <ul>
          <li><u>Allowing clubs to set their own norms.</u> With our next release, club founders will be able to write rules that are specific to their clubs—to share their community values, communicate their norms, and define the dos and don'ts for speaking. When people join the club they'll be asked to agree to the rules. And when the club hosts a public conversation, non-members will be asked to agree to the rules before speaking. We think this will help people create intentional gathering spaces that cater to many interests and styles. These rules will supplement the Community Guidelines, which still apply to everyone.</li>
          <li><u>Hosting formal moderator training sessions.</u> There is no single way to moderate, and each room can have its own style. To help with this, we’re going to start offering regular moderator training sessions on the app, to ensure that people who wish to host discussions are equipped with the tools and knowledge they need.</li>
          <li><u>Improving moderator tooling.</u> Great moderators create great conversations, and we need to empower them with the right tools. This week we are building infrastructure that will allow us to notify moderators when there is a safety concern related to their room. Moderators can also tap the “End Room” button anytime if they feel the conversation is getting out of hand.</li>
          <li><u>Adding moderator badges.</u> This is a small thing, but it’s easier to provide a speaker with feedback when you know who’s in charge of the room. These will be live in the next release.</li>
        </ul>
      
      <p>The world is not a monoculture, and we want Clubhouse to reflect that. Ideally the experience is more like a town square, where people with different backgrounds, religions, political affiliations, sexual orientations, genders, ethnicities, and ideas about the world come together to share their views, be heard and learn. Some of these communities come together to debate. Some come to relax and joke around. Others hold listening parties and fireside chats. We think many styles should be supported, and we’re working on tools to help everyone create their own space, deepen friendships, meet new people and have meaningful discussions—in the way that suits them best.</p>
      <p>Clubhouse is nothing without the community, and we are immensely grateful for all of your ideas, emails, tweets, support and critiques. We’ll continue working around the clock on all of this as we open it up to more of the world. Thank you! 🙏🏽</p>

    </div></div>]]>
            </description>
            <link>https://www.joinclubhouse.com/on-community-moderation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657148</guid>
            <pubDate>Thu, 01 Oct 2020 23:11:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VMware Fusion 12 Metal Support]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656836">thread link</a>) | @wila
<br/>
October 1, 2020 | https://www.vimalin.com/blog/fusion-12-0-metal-support/ | <a href="https://web.archive.org/web/*/https://www.vimalin.com/blog/fusion-12-0-metal-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			<div>
				
				<article id="post-1344">	
			<figure>
		<img width="1136" height="918" src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" alt="VMware Fusion 12 Metal Support" loading="lazy" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w" data-lazy-sizes="(max-width: 1136px) 100vw, 1136px" data-lazy-src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</figure>
			<div>
					
				
									<div>
				
<p>Ok.. I’m so ecstatic.. a quick blog post must be written…</p>



<p>The Product manager of VMware Fusion, Michael Roy, had a classic “One More Thing” item in his VMworld presentation. The presentation was “What’s New with VMware Workstation and VMware Fusion”.</p>



<p>While running a Big Sur macOS guest, he showed “Metal Support” working without a hitch… Now we have been told for years that we cannot get 3D Acceleration in a macOS guest. Seeing this on the list of “things to come” was already pretty great. Something to look forward to.<br>During that same presentation he also showed the .vmx settings in order to get that working. Once the feature lands… </p>



<h3>Who wants to wait?</h3>



<div><p>So of course, immediately after the presentation I <em>had</em> to try. No matter that it is only supposed to be working in a future version of VMware Fusion 12.0.<br>After adding the .vmx settings from the presentation I got a “Invalid configuration” error (or something along those lines).<br>OK, sad panda.</p><p>But … silly me did not look at the vmware.log file. Today I was poking Michael a bit on twitter and asking about how well Metal works on Big Sur beta 9 and that it is “so hard to wait” and he tells me “but you can try it yourself already”… 😮</p></div>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>You can totally use it today actually, but AutoFit doesn't work (needs new tools that haven't shipped yet… future versions won't require Tools at all)</p><p>svga.present="FALSE"<br>appleGPU0.present="TRUE"</p><p>appleGPU0.screenWidth=1680 appleGPU0.screenHeight=1050</p></div>— Michael Roy (@mikeroySoft) <a href="https://twitter.com/mikeroySoft/status/1311754703055675392?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>OMG.. that’s when I realized that I had missed a detail..</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Ohh… I had not put the svga.present="FALSE" line and now I see what other precondition I missed (silly me)…</p><p>vmx| I005: AppleGPU: Apple GPU support is not available: requires macOS 11.</p><p>Looks like I will update that box to macOS 11 right now.</p></div>— Wil van Antwerpen (@wilva) <a href="https://twitter.com/wilva/status/1311759349572870144?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<h3>It’s all in the details</h3>



<p>Also my host wasn’t running Big Sur yet (I had only run it in a VM)<br>… so… next hour or so I was frantically busy installing Big Sur Beta 9 on my 2014 Mac Mini and YES… IT DOES WORK and it is SOOOO SMOOTH</p>



<figure><img loading="lazy" width="1024" height="827" src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" data-lazy-src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This is the best thing since sliced bread.</p>



<p><br>THANK YOU VMware Fusion team!</p>



<h3>In summary</h3>



<div><p>This is not an officially released feature, treat it what it is: Experimental</p><p>Required: minimum of macOS Big Sur as host OS<br>Required: minimum VMware Fusion 12.0<br>Guest OS support: So far I have only gotten this to work with a macOS Big Sur guest (but I haven’t tried others beyond macOS Mojave)</p><p>You have to add the following lines to the .vmx file of your VM in order to test this:<br><code>svga.present="FALSE"<br>appleGPU0.present="TRUE"<br>appleGPU0.screen0.width = "1680"<br>appleGPU0.screen0.height = "1050"</code></p></div>



<p>To be honest I don’t even have the lines with width and height, but that’s how you can define that for now.<br>It will only get better from here on once it is officially supported.</p>



<hr>



<p>Now that you are here. Please check out our product “<a href="https://www.vimalin.com/">Vimalin</a>“. It has been designed for making your life easier to get good backups of your VMs. We support VM’s running in VMware Fusion, VMware Workstation and VMware Player. </p>



<p>More info at our <a href="https://www.vimalin.com/">main page</a></p>
			</div>
					
			<hr>
			
					</div>
</article>						</div>	
			
		<!--/Blog Content-->
		         				</div></div>]]>
            </description>
            <link>https://www.vimalin.com/blog/fusion-12-0-metal-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656836</guid>
            <pubDate>Thu, 01 Oct 2020 22:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using artificial intelligence to make publishing profitable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24656437">thread link</a>) | @Sanksshep
<br/>
October 1, 2020 | https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-1fd98981423ebe5f9a2e"><p><h2>Artificial Intelligence has significant implications in making publishing profitable – from automation to improvements in advertising. Let’s dive into what AI is, as well as the potential applications within the publishing industry to make it profitable.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601450467819_4883"><div><h3><strong>What is AI?</strong></h3><p>Artificial intelligence, or AI, refers to the ability of tools or technology to perform tasks that would normally require human intelligence to complete.&nbsp;</p><p>Machine learning is a subset of AI in the computer science space – where the platform or model learns from an existing data set so that it can understand the underlying trends and patterns. This knowledge is then used by the machine learning models to make predictions or determine outcomes from the new data it encounters.</p><p>In other words, the computer model uses statistical techniques to learn how to get better at a task, whether that be categorizing data or predicting if a client is a good fit for a certain product. For the model to learn to do this without specific programming, it must analyze existing data that is already pre-labeled.</p><p>Deep learning is another subset of artificial intelligence that involves the creation of a neural network, which has layers and layers of data processing. This type of AI can make deep connections and gain valuable insights from a dataset since it processes information almost like the human brain does.</p><h3><strong>Goals of Artificial Intelligence in Publishing</strong></h3><p>The goals of artificial intelligence in publishing include automating story production and evaluating content automatically.&nbsp;</p><p>The Associated Press started using AI back in 2015 for story automation. They understood that machine learning could create content such as public company earnings report recaps since they need details and accuracy but do not require much creativity.&nbsp;</p><p>They took this further in 2016 when they developed an AI platform that could report on Minor League Baseball games – the machine learning model could incorporate statistics and highlights that, again, are strictly fact-based.&nbsp;</p><p>This is just the beginning for automatic story production, and as artificial intelligence platforms become more accessible there will be more publishers utilize it to create automated content.</p><p>Another goal of artificial intelligence in publishing is evaluating content. A machine learning model can help an editor when making decisions regarding moderation and editing.&nbsp;</p><p>AI can be used to automate complex tasks, such as comparing the characteristics of a manuscript to those of a bestseller to see where improvements can be made. This can help editors focus on the most marketable content and save time and effort narrowing them down.&nbsp;</p><p>Automated text analysis can optimize plagiarism detection as well as copyright enforcement! Artificial intelligence can eliminate some of the tedious work involved with researching copyrights and ensuring that the content being published is 100% authentic.&nbsp;</p><p>Comment moderation can be significantly improved as a result of artificial intelligence. Machine learning models can save publishers valuable time and resources by automatically detective inappropriate or abusive labels and comments – and removing them.&nbsp;</p><p>Reducing the workload of human moderators can allow publishers to open more content for commenting and facilitate a wider scope of articles. The New York Times has already implemented automation within the moderation space, and this has allowed them to open up more content for commenting – where previously they capped it at 10% of their articles.&nbsp;</p><h3><strong>Artificial Intelligence and Advertising</strong></h3><p>Artificial intelligence can also help publishing firms when it comes to advertising. It can improve everything from engagement to the structuring and design of content.&nbsp;</p><p>AI platforms allow publishers to personalize content for marketing campaigns since statistics have shown that personal advertisements have a higher level of engagement – and therefore, a better return on investment.</p><p>Machine learning models will analyze content and engagement to curate newsletters and articles that fit right in with your audience segment. Research performed by McKinsey found that this level of personalization is essential and can increase the efficiency of marketing budgets by up to 30%!</p><p>This type of personalization can also be used for the automation of recommendations. You can gain insights into what your readers like based on their browsing history, and then the machine learning model can identify trends and patterns.&nbsp;</p><p>With this information, you can give your readers personalized recommendations on other content they may enjoy. This will help your firm boost engagement as well as make your advertisements much more personalized.&nbsp;</p><h3><strong>Conclusion</strong></h3><p>These are just a few aspects in which artificial intelligence can impact publishing by reorganizing the workforce towards better things with the help of automation and improve revenue by personalizing content and experiences for a diverse set of users. Publishing companies can benefit a lot by using artificial intelligence in tough economic climates and weather the storm and keep the lights on. </p></div></div></div>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656437</guid>
            <pubDate>Thu, 01 Oct 2020 21:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous Development for Hybrid Remote Dev Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656046">thread link</a>) | @davetwichell
<br/>
October 1, 2020 | https://linearb.io/blog/asynchronous-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/asynchronous-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Hope and optimism are default settings for my LinearB co-founder, Ori Keren. For Ori, one silver lining in this tumultuous year is that 2020 ushered in the age of the hybrid remote work model. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png.webp 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Asynch-2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>“Hybrid remote is how software development teams were always meant to work. It just took 20 years and a global pandemic for us to figure that out.” </p>



<p>Ori believes that, to be highly successful, developers need uninterrupted time to get into a deep state of focus on their task at hand. Getting in “the zone” is hard and when you get interrupted you can’t easily get your deep focus back. </p>



<p>Remote work has eliminated most dev interruptions, right? Not so fast. </p>



<p>Company culture is a powerful force. Like gravity, we don’t see or or think about most days but it effects everything we do. </p>



<div><p>According to Ori, culture is even more powerful than a global pandemic or a new trend like hybrid remote. </p><p>“Working remote was great for our dev team at first. Once we got over the initial disruption of getting equipment and finding a quiet place to work at home, team productivity soared. But then we started noticing our efficiency going down.” </p></div>



<div><p>What happened? Our in-the-office culture grabbed hold and brought us right back to where we were in March. </p><p>“All of the interruptions crept back in… scheduled meetings, impromptu Zoom status meetings…” </p><p>In other words, we were a hybrid remote company with an in-the-office mindset and process. </p><p>You can see the effects here in our Cycle Time trend chart. </p></div>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<div><p>“Being a remote employee used to be a semi-unique experience that came with a certain level of trust, preparation and experience. Then the entire global dev community went remote at the same time, without preparation or understanding of what needs to change.”</p><p>Hybrid remote can be a business advantage for companies embracing it. But only if we adapt our culture and process to make it work. </p></div>



<p>This is how Asynchronous Development was born. </p>







<h2>What is Asynchronous Development?</h2>



<p>Async Dev is an approach to development grounded in asynchronous communication. It works for hybrid remote, full remote and any dev teams that wants to unlock the full creative power of their developers. </p>







<iframe width="560" height="465" src="https://www.youtube.com/embed/w0pw0dcFZ-w?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>







<p>Async Dev builds on the foundation Agile put in place. Since the Agile Manifesto was published 20 years ago, software development has gone through some drastic changes. Many of those changes like asynchronous communication tools (e.g. Slack &amp; Teams) becoming the default form of communication and hiring remote developers were forced into the spotlight in 2020. </p>



<p>Ori  started wrote the Async Dev manifesto to help engineering and product leaders see how they can change the way they work to turn this new situation into an opportunity. </p>



<p><strong><em>Below Ori explains how Async Dev builds on the Agile and DevOps movements and talk through each of the five core tenets of Async Dev. Listen to the accompanying 60~ second audio clip from Ori in each section or just read the blog</em></strong>. </p>







<h2>The Async Dev Movement</h2>



<p>Hybrid remote development is not new, but 2020 accelerated the adoption of many of the practices already in place. As these hybrid remote methods are normalized globally, we also have to accept the way we work, the processes, and the ceremonies have changed as well. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/history-1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Asynchronous Development acknowledges the importance of movements like Agile and DevOps and offers a new way of looking at development that is a better fit for 2020.&nbsp;</p>











<h2>The 5 Tenets of Asynchronous Development</h2>



<p>There are 5 core tenets of Async Dev that we have adopted to transform the hybrid remote reality into an opportunity to strengthen the alignment between development and the business.</p>







<div><div>
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>
</div></div>







<ol><li>Asynchronous is the default form of communication</li><li>Git is the central element of your development process</li><li>Project Management tools are for planning, not status updates</li><li>Continuous improvement is a daily practice</li><li>Dev teams are the core of the business</li></ol>











<figure><blockquote><p>LinearB built a new kind of project board exclusively for hybrid remote dev teams.</p><p><span><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get our Devboard free</a></span></p></blockquote></figure>







<h2>Tenet 1 – Asynchronous is the default form of communication</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png.webp 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-1.mp3"></audio><figcaption>Click here to listen to Ori</figcaption></figure>







<p>Asynchronous communication means using collaboration tools and mentions by default. It helps reduce context switching, avoid unnecessary interruptions, and increases productivity. </p>



<p>After LinearB went full remote back in April of 2020, we analyzed our development team’s metrics to understand exactly how this change effected the productivity and efficiency of the team. </p>



<p>In true Asynchronous fashion, 92% of developers at LinearB were writing more code, while PR sizes and Cycle Times increased. This clearly tells us that fewer interruptions means greater individual productivity. It also clearly shows what we needed to adapt the way worked to the new circumstances if we were going to continue delivering at the same level as pre-wfh. </p>



<p>At LinearB we have started taking a closer look at the function of the daily stand-up and how to use that time to best suit our team. Now that we are a hybrid remote development team with up to the minute updates on issue statuses using LinearB, we use our stand-up time to connect on a personal level, and then just talk about blockers. It’s not perfect, but it’s been a nice adaptation to our new reality.</p>







<h2>Tenet 2 – Git is the central element of your development process</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png.webp 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-2_2-1.mp3"></audio><figcaption>Click here to hear Ori</figcaption></figure>







<p>Whether you use GitHub, GitLab, Bitbucket, Azure DevOps or other git flavor, most of the stages of the development cycle either start or involve your git system. How you choose to configure, deploy and utilize it has a great impact on your dev process. </p>



<p>In addition the most up to date status of work progress resides in the git system. Fortunately git was built with open source in mind so most of the phases (coding, review, merge) do not require mandatory synchronous communication and can be executed in different places and different times.</p>











<h2>Tenet 3 – Project Management tools are for planning, not status updates</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png.webp 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet3_2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Whether your team uses Jira, Trello or something else, project management tools are great for planning an iteration or the next week, but trying to use them to enrich dozens of micro decisions that dev teams are taking every day will slow down productivity. </p>



<p>Every update to the work status while in ‘building mode’ should be with dev first in mind, meaning it should automatically reflect the status based on actual git activity and it should mainly serve the people that build and ship the software.</p>







<figure><blockquote><p>Does your current project board</p><p>give you more questions than answers?</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Try the LinearB Devboard free</a></p></blockquote></figure>







<h2>Tenet 4 – Continuous improvement is a daily practice</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png.webp 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/tenet4new.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Data should always be accessible to everyone – no gate keepers, not just data engineers, and not just reviewed in meetings by management.</p>



<p>Your KPIs and how you decide to utilized them will define your culture. </p>



<p>Key Principles for Data Usage: </p>



<ul><li>Team-based data over developer stack ranking</li><li>Measure process over output</li><li>Measure empiric over subjective</li><li>Focus on leading indicators vs. lagging indicators</li><li>Establish baseline data points and trends</li><li>Make sure it’s actionable</li></ul>







<p>Data should be used in an ethical way and cannot replace good managers with good soft skills and human interaction.</p>







<figure><blockquote><p>High-risk code &amp; stuck PR Slack Alerts are pretty amazing.</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get them Free with LinearB</a></p></blockquote></figure>







<h2>Tenet 5 – Dev teams are the core of the business</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png.webp 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-5_1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>The best companies in the world evolved from developers that were highly aligned with business and market needs. Dev-led companies empower developers to make decisions on behalf of customers and the business by giving them context instead of instructions.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>We believe that ‘developers’ and ‘business’ are not disjoint sets and sometimes the most important business decisions are hiding in code lines. That is why the best businesses should focus on pushing context to dev teams, and dev teams should provide transparency into their decision making so both can enjoy a refinement cycle.</p>



<p>This is probably the hardest part of making Async Dev a reality because, as dev leaders, it is the element we have least control over. We need buy-in from throughout the business. </p>







<h3><strong>Here are 5 practical steps you can take today to start practicing Async Dev:</strong></h3>







<h4>1) Cut status updates from your daily stand-up</h4>



<p>Instead focus on what matters – who needs help and whether you’re going to ship on time. Async Dev means never spending valuable meeting time on status updates when everyone could take 5 minutes on their own before the meeting to see what happened yesterday and what’s happening today. <a href="https://linearb.io/blog/make-daily-better/" target="_blank" rel="noreferrer noopener">Click here to get 16 tips</a> for how to run a better daily stand-up. </p>







<h4>2) Decouple learning and improvement from your retro. </h4>



<p>We’re not saying to cancel your retro. Getting together every few weeks to discuss learnings is great. But if you un-gate your team metrics so everyone can see bottlenecks and suggestions for how to improve each day, then improvement can be led everyone on your team (not just managers) and become part of the fabric of your team culture. <a href="https://linearb.io/blog/data-driven-dev-team/" target="_blank" rel="noreferrer noopener">Click here to see how to use data in your day-to-day</a> practices without damaging culture. </p>







<h4>3) Combine quantitative signals &amp; qualitative assessments for team health</h4>



<p>Use multiple data points to identify signs of overload and burnout. Face to face conversation is not the only way to see if a teammate is struggling. Looking at your WIP balance across the team and consecutive days worked, in combination with 1:1 conversation, can tell you a lot about a person’s work health. <a href="https://linearb.io/blog/dev-team-health/" target="_blank" rel="noreferrer noopener">Click here to see which data points can help you …</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/asynchronous-development/">https://linearb.io/blog/asynchronous-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/asynchronous-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656046</guid>
            <pubDate>Thu, 01 Oct 2020 20:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interviewing During Covid – Google/Apple/ByteDance/Databricks/Citadel/HRT/JS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24655799">thread link</a>) | @oneraynyday
<br/>
October 1, 2020 | https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/ | <a href="https://web.archive.org/web/*/https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>I interviewed for Googleâ€™s Tensorflow, Appleâ€™s MLPT (Machine Learning Platform &amp; Technology), Bytedanceâ€™s ad infrastructure, Databrickâ€™s ML team, Citadel Securities as a quantitative research analyst, Hudson River Trading(HRT) as an algorithm engineer, and Jane Streetâ€™s research desk as SWE. I received offers from all of the companies except for Jane Street. Hereâ€™s my experience interviewing during COVID.</strong></p>

<p><em>Disclaimer: I wonâ€™t be walking on the edge of leaking confidential information like an idiot(yes, I signed an NDA for all of these companies). Donâ€™t expect to get any hints for your interviews.</em></p>

<p>The structure of this blog is inspired by my friend <a href="https://medium.com/@XiaohanZeng/i-interviewed-at-five-top-companies-in-silicon-valley-in-five-days-and-luckily-got-five-job-offers-25178cf74e0f">Hanâ€™s medium blogpost.</a></p>

<p><img src="http://oneraynyday.github.io/assets/interviews.png" alt="interviews"></p>



<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of Contents</a></li>
  <li><a href="#preparation" id="markdown-toc-preparation">Preparation</a>    <ul>
      <li><a href="#algorithms" id="markdown-toc-algorithms">Algorithms</a></li>
      <li><a href="#systems-design" id="markdown-toc-systems-design">Systems Design</a></li>
      <li><a href="#math-questions" id="markdown-toc-math-questions">Math Questions</a></li>
    </ul>
  </li>
  <li><a href="#the-interview-process" id="markdown-toc-the-interview-process">The interview process</a>    <ul>
      <li><a href="#more-interview-rounds-during-covid" id="markdown-toc-more-interview-rounds-during-covid">More interview rounds during COVID</a></li>
      <li><a href="#dealing-with-time-zones" id="markdown-toc-dealing-with-time-zones">Dealing with time zones</a></li>
      <li><a href="#which-ones-were-the-hardest" id="markdown-toc-which-ones-were-the-hardest">Which ones were the hardest?</a></li>
    </ul>
  </li>
  <li><a href="#making-a-decision" id="markdown-toc-making-a-decision">Making a decision</a>    <ul>
      <li><a href="#the-culture-and-the-small-things-count" id="markdown-toc-the-culture-and-the-small-things-count">The culture and the â€œsmallâ€� things count</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>



<p><strong>Working on machine learning infrastructure is 99% systems engineering and 1% machine learning.</strong> My experience on machine learning infrastructure teams has taught me this, and preparing for systems engineering topics was the right way to go. I did the following to prepare:</p>

<h2 id="algorithms">Algorithms</h2>

<p><strong>~50 leetcode hard questions</strong>. Some of them are DP, some are graph based, some of them are just NP-hard problems that are a pain to code(which is the point), and some include devising some clever data structure that supports a very specific access pattern. I gave myself roughly 40 minutes to solve these problems. ~15%(7 questions) of the time I couldnâ€™t figure out the correct solution because time limit exceeded, memory limit exceeded, or I was just flat out wrong. I directly read the solutions and learned the tricks necessary to solve the type of problems moving forward. Donâ€™t bother with medium or easy questions since hard questions often contain medium/easy tasks as subroutines, and these companies probably wouldnâ€™t ask you easy leetcode questions anyways.</p>

<p>I wrote the solutions in either python and C++(sometimes both) and went back to polish my code for minor optimizations or readability improvements. For C++, I made sure I wasnâ€™t using raw pointers unless appropriate and I was using C++17 (<code>constexpr</code> functions, <code>std::array</code> instead of raw arrays, smart pointers, template type deduction with lambdas, etc) features. The reason I wasnâ€™t using C++20 was because the online coding platforms(like coderpad) likely use stable distributions of GCC and clang, which means some of the new features are in their experimental phase. <strong>I didnâ€™t want to encounter a bug with concepts or <code>std::ranges</code>  in the middle of the interview.</strong> (In fact, I found a <a href="https://stackoverflow.com/questions/62398252/why-likely-attribute-in-c20-raises-a-warning-here">bug with attributes</a> recently in a new version of gcc)</p>

<p>I also spent a few days on problems elsewhere:</p>

<ul>
  <li><a href="https://codingcompetitions.withgoogle.com/codejam/archive">Codejam problems</a>. Round 1 and 2 are feasible, but round 3 was very difficult. Iâ€™d suggest studying round 1â€™s if you only care about interviews.</li>
  <li><a href="https://codeforces.com/">Codeforce contests</a>. There are 3 tiers(or Divs, as they call it), and for interviews I suggest Div 3 and Div 2. Donâ€™t bother with the D+ questions in Div 2, and definitely donâ€™t bother with Div 1.</li>
</ul>

<h2 id="systems-design">Systems Design</h2>

<p>Working at Airbnb has made me pretty familiar with high level distributed systems design, but of course I worked only with a subset of them. I think Martin Kleppmanâ€™s book <a href="https://www.google.com/books/edition/Designing_Data_Intensive_Applications/p1heDgAAQBAJ?hl=en">Designing Data Intensive Applications</a> is a great read, but youâ€™ll have to pick and choose which sections you want to go over as itâ€™s a pretty dense book. If you donâ€™t have time, maybe just try understanding how Kubernetes works with Marko Luksaâ€™s <a href="https://www.manning.com/books/kubernetes-in-action">Kubernetes in Action</a>, which is a much easier read. You can then draw parallels with the distributed design for K8s against whatever systems design question the interviewer has for you.</p>

<p>Make sure you know some fundamental ideas about distributed systems like the <strong>map reduce paradigm</strong>, <strong>sharding</strong>, <strong>asynchronous and synchronous follower replicas</strong>, <strong>CAP theorem</strong>, etc. <em>What you donâ€™t want to do is read 3 sentences about each of the terms above and regurgitate it in your interviews. Interviewers have been doing this for a while, they know you donâ€™t actually understand the concepts.</em> Donâ€™t be that guy.</p>

<h2 id="math-questions">Math Questions</h2>

<p><strong>These are only asked in finance firms.</strong> Honestly, these are just all over the place. I read this green book called <a href="http://quantfinanceinterviews.com/">A Practical Guide to Quantitative Finance Interviews</a> by Xinfeng Zhou, but only doing a single problem in each section by myself. Hedge funds will quiz you on discrete math to probability theory to geometry to information theory to literally anything. My advice is if youâ€™re a software engineer interviewing for a hybrid of finance and tech places, timebox yourself in this category.</p>

<hr>

<p>I have not seen an interview question this cycle that was an exact question Iâ€™ve seen online or in books. Your mileage may vary.</p>



<p>Interviewing and talking with all of these companies was a great experience, even with COVID in place. Obviously, as shelter-in-place continues, these companies are conducting virtual on-site interviews and trying to make this process as smooth as possible. Without getting into the specifics, Iâ€™ll outline some common things Iâ€™ve noticed during the process in the COVID era.</p>

<ul>
  <li>Many companies use Zoom or Google Hangouts for their on-sites.</li>
  <li>They give you ~15 minute breaks in between interviews for water breaks.</li>
  <li>Some companies give you a longer lunch break (45 mins to an hour).</li>
  <li>If youâ€™re interviewing for a company in another time zone, prepare to wake up in the early AMâ€™s or interview in the late afternoon (sometimes after dinner).</li>
  <li>Conveying an idea takes slightly longer because youâ€™re not drawing on a whiteboard. Some companies have virtual whiteboard apps and others allow the use of Zoom whiteboards.</li>
  <li><strong>Some companies added more interview rounds for virtual on-sites.</strong> Apparently more people are getting into companies with subpar technical skills during COVID and theyâ€™re making the process more selective. I think this can also be due to the increase in competition due to unemployment rates increasing.</li>
  <li>Feedback and communications with recruiters is generally faster.</li>
</ul>

<h2 id="more-interview-rounds-during-covid">More interview rounds during COVID</h2>

<p>The bolded text might scare you as a potential candidate, but donâ€™t worry too much. The added questions arenâ€™t testing you if you know how to implement a bloom filter or a fibonacci heap or something niche. They usually test on the <em>coding abilities of the person and how well theyâ€™d actually ramp up in a novel, collaborative environment</em>. This can manifest itself in multiple ways - live debugging session with a new codebase, reading documentation to work with new technology, or a collaborative brainstorming sesion for a hard(er) problem. If youâ€™re a decent software engineer you shouldnâ€™t worry about these as much.</p>

<h2 id="dealing-with-time-zones">Dealing with time zones</h2>

<p><em>One of the biggest struggles I had during the interview process was adjusting my sleep schedule to wake up at 5-6AM to make sure Iâ€™m awake and on time for the interviews in New York/Chicago (Iâ€™m in California so this was a 3 hour gap)</em>. Usually, companies would fly you out the day-of or the day before the on-site. Iâ€™ve always felt tired after a plane flight and was able to get a good nightâ€™s rest before the interviews in the past. With COVID, everything is virtual and the companies expect you to interview at their hours.</p>

<p>Even with slowly adjusting my sleep schedule over a week or two I still had trouble with sleep. Personally, I get pretty nervous before an on-site and Iâ€™d need to feel adequately tired to get a good nightâ€™s rest instead of tossing and turning in bed. With the clock turned 3 hours back, I suddenly found myself not tired enough to sleep on time the night before the interview(even with a whole week of adjusting). This led to me consistently getting 6-7 hours of sleep instead of the 9 hours of sleep I usually get on game day, which really sucked.</p>

<p>Ultimately, I have no idea how much the sleep problem really affected my performance, but it was enough to shake my confidence going in.</p>

<p><em>NOTE: +1 to Citadel for proactively breaking my on-site over multiple days so I can have a sane sleep schedule for their interviews. This might depend on the specific team youâ€™re interviewing with.</em></p>

<h2 id="which-ones-were-the-hardest">Which ones were the hardest?</h2>

<p>This is subjective, and the question can be broken up into multiple components:</p>

<ul>
  <li><strong>Time pressure - Jane Street</strong>. This is probably why I failed their interviews, which were a bit longer than usual. I tend to explain my approach before coding anything to get a confirmation on the interviewerâ€™s side that Iâ€™m on the right track. I probably spent too much time explaining and didnâ€™t have enough time to finish the code for some interviews.</li>
  <li><strong>Math questions - Citadel</strong>. They asked me some <em>really</em> interesting math problems that arenâ€™t related to finance at all. I donâ€™t think they expect the interviewer to get 100% of the questions since whenever I solved one the interviewer was ready with another. HRT also asked some.</li>
  <li><strong>Systems design - HRT</strong>.</li>
  <li><strong>Outside-the-box problems - Databricks</strong>. They conduct one of the most unique interviews Iâ€™ve ever had.</li>
  <li><strong>Language specific questions - Citadel/HRT</strong>. Grilled me a lot on low level C++ stuff.</li>
  <li><strong>Length of interview - HRT</strong>. I started at 8AM PST (I requested to move it to 8AM from 7AM) and finished at ~2:30PM. <strong>That is a whopping 6 hours and 30 minutes.</strong> I also did a coding challenge and 2 phone screens before I moved to on-site, totalling almost 10 hours for interviews.</li>
  <li><strong>General algorithm questions - Jane Street/HRT</strong>. I think Jane Street was a bit harder given the time pressure. The flavor of algorithm questions are also different between these firms.</li>
</ul>

<p>Once again, this breakdown is <strong>subjective</strong>. I obviously have a lot of experience interviewing with Silicon Valley companies so the novelty of questions from the finance companies added to the difficulty.</p>



<p>This was the hardest part for me. I spent two weeks suffering from analysis paralysis. I would …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</a></em></p>]]>
            </description>
            <link>https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655799</guid>
            <pubDate>Thu, 01 Oct 2020 20:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24655752">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655752</guid>
            <pubDate>Thu, 01 Oct 2020 20:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use the internet, not just companies (2018)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24655745">thread link</a>) | @downshun
<br/>
October 1, 2020 | https://sive.rs/netskill | <a href="https://web.archive.org/web/*/https://sive.rs/netskill">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2018-02-12</small>
</header>

<p>
	I’ve been online since 1994, and seen so many companies come and go.
</p><p>
	In the year 2000, the place to be was mp3.com.
	Every musician would keep all of their music and fans there.
	A few years later, it was gone — shut down — all music and fan lists deleted.
</p><p>
	In 2005, it was MySpace.
	Again, musicians kept all of their music, photos, and fans there.
	A few years later, it was gone.
	Not shut down, but basically moot.
	There was no way to communicate with all of those people, because you didn’t have their direct contact info — you only had their MySpace inbox, which nobody checked anymore.
</p><p>
	As I’m writing this now in 2018, it’s Facebook, YouTube, and Spotify.
	Just like with mp3.com and MySpace, people act like these websites are everything, and keep all of their music, photos, and fans there.
	By the time you read this, they might be gone.
</p><p>
<strong>
	Don’t depend on a company.
	They come and go.
</strong>
	Think long-term.
	You’re going to be creating stuff, making fans, and building relationships for the rest of your life — much longer than these companies will last.
</p><p>
<strong>
	So have your own website.
</strong>
	Instead of sending your fans to some company’s site, send them to yours.
	Get everyone’s direct contact information so you don’t have to go through a company to reach them.
</p><p>
<strong>
	Your website should be the definitive place to get everything you create.
</strong>
	If you put your stuff on some company’s site, have it be secondary — a copy of the stuff that’s already on your site.
	That way you can use the popular networks without depending on them.
</p><p>
	Only rely on open standards that aren’t owned by any company — like email and the web.
</p>
<h3>
	Email skills:
</h3>
<p>
	Go into your email settings, and make sure you <strong>have a signature</strong>.
	You need this because you’re going to be emailing people who have no idea who or where you are!
	Give them some context.
	Your signature should say who, what, and where, with a URL or two.
	For example:
</p>
<pre>--
Maya Danubé, fragrant jazz bass clarinet, New York City
http://mayadanube.com  <a href="https://sive.rs/cdn-cgi/l/email-protection" data-cfemail="3a575f7a575b435b5e5b544f585f14595557">[email&nbsp;protected]</a>  (917)611-5310
Watch &amp; listen: https://www.youtube.com/user/mayadanube
Friend me, baby: https://www.facebook.com/mayadanube
</pre>
<p>
	When you email people, write a <strong>descriptive subject</strong>.
	Never “hey” or “booking”.
	Try “Available June 6 for showcase?” or “introduction to photographer”.
	This is considerate.
	Now when your email is one of hundreds in an inbox, it will say exactly what is contained inside.
</p><p>
	Make it <strong>as short as possible</strong>.
	The shorter your email, the more likely it will get a response.
	Be direct.
	Five sentences is ideal.
	If your email is too long, they are likely to procrastinate, and never get back to it.
</p><p>
	Use short paragraphs.
	Leave plenty of space.
	Reading a screen is different from reading a book.
</p>
<h3>
	Web skills:
</h3>
<p>
<strong>
	Know how to update your website.
</strong>
	Don’t depend on someone else to do this for you.
	Know how to add new songs or videos, and how to make any changes.
</p><p>
<strong>
	Know your URLs.
</strong>
	Telling someone to go search for you is like telling them to look up your phone number.
	Instead, know your exact URLs (yoursite.com, twitter.com/something, facebook.com/whatever) so you can give it to people directly.
	If you don’t, they’ll probably never bother to go search for you.
</p><p>
<strong>
	Know how to make an MP3.
</strong>
	Give it a good filename like YOUR_NAME-Song_Title.mp3 (not mix7.mp3)
	Don’t use spaces in the filename.
	Edit the ID3 tags to put your full name and URL in the info, so whoever has this MP3 knows who it is and how to find you.
</p><p>
	Sorry if these sound too basic to you.
	But you’d be surprised by how many people don’t know these skills, and so are silently handicapped when interacting with the world.
</p>
<img alt="" src="https://sive.rs/images/internet-skills.gif">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/netskill</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655745</guid>
            <pubDate>Thu, 01 Oct 2020 20:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why plain text emails perform better than HTML designed ones]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655493">thread link</a>) | @pau_alcala
<br/>
October 1, 2020 | https://blog.palabra.io/plain-text-engagement | <a href="https://web.archive.org/web/*/https://blog.palabra.io/plain-text-engagement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a></em></p><p>Plain text sounds boring? Well, let me tell you that plain text is more important than you can imagine. At <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a> we love plain text to send every email, specially our onboarding sequences. And in this article we’ll share why we think you should start using it too.</p><h2>Isn’t plain text for grannies?👵🏼</h2><p>Plain text has been around since the beginnings of the Internet. So it is understandable that some people think it is obsolete. Maybe there was a time where HTML emails were on a boom, but plain text today is more functional than ever.</p><p>Before we continue we’d like all of us to be in the same page about what plain text is:</p><p>The term Plain text, when we talk about an email, refers to the composition that consists of the copy within the style. Which means that it does not include complex formatting or styled fonts. Although it can have images and links.</p><p>Even if plain text could sound boring at first compared with HTML emails, you will discover that their use can bring many benefits in general, and especially for onboarding sequences.</p><h2>Use plain text for onboarding sequences 🏆</h2><p>When you have a service or a product that depends, on a large portion, of having a constant flow of users, you might want to apply an onboarding sequence in order to avoid the churn rate and to connect with your community.</p><p>If you’re still in the early stage of your strategy, we recommend to read our article about <strong><a href="https://blog.palabra.io/questions-onboarding">5 questions to ask yourself before creating an onboarding email sequence</a></strong>, it will guide you in the process.</p><p>Over the years, new technologies have risen in the field of user experience. We now have many tools to call the attention of customers. This means people are getting a bunch of emails that now look like ads delivered right to your inbox.</p><p>Onboarding should look nothing like ads. That's when you start a close relationship with early users, you educate them about how to use your product better, and open communication channels.</p><h2>5 reasons why plain text is always a good idea</h2><h3>📩 It ensures deliverability</h3><p>The number one thing that you need to do to engage with someone is to get their attention. And for that, you need to get them to open your emails.</p><p>As we said before, HTML emails have images, links, GIFs, all sorts of things that attract the attention of email filters. So they’re more susceptible to being redirected to the spam folder if they have broken links or suspicious behaviours.</p><p>Since plain text emails don’t contain much more information than text, it’s much more likely that they will not alert spam filters.</p><p>Also, plain text emails seem more “real” to your email filters. And that's also handy for your readers!</p><h3>📜 It feels more personal</h3><p>Once your customers open your emails, you don’t want them to say “ugh, another stupid corporative email. DELETE”. That’s probably the worst case scenario.</p><p>Plain text has been proved to have higher click-through rates. Not just because they can pass spam filters, but also because they feel more personal. They look like something a real person sends, to offer information instead of driving sales.</p><p>Then, when you receive a plain text email, it is more associated with a regular person, someone who just wants to talk and know about you as an individual (and not as a target). Your users can perceive you more relatable, human and trust-worthy ✨.</p><h3>🗣️ Starts 1-1 conversations</h3><p>As you can see, there’s a progression. And with plain text you help your emails to be delivered and opened. Do you know what is even better? If your users answer the email!</p><p>We like plain text precisely because of this. Through this kind of emails, we’ve received feedback from our users that was very valuable for us to grow as a company and as a team. They respond because there's a real email address from a real person to answer to.</p><p>We send onboarding emails that appeal to conversation. Having a dialog is the fuel to power the relationship with the users. We try to build a space where the user can feel part of the process and can say something to improve the use of a tool that is so necessary in his life.</p><h3>👩🏼‍🦽 Is more accessible</h3><p>Now we want to highlight something that usually goes unnoticed. Plain text is readable for accessibility systems. This kind of emails has an ethical benefit, because they’re reachable for people with different needs.</p><p>When you send an HTML email, you’re making it more difficult for a blind person, for example, to understand your message.</p><p>At this point, it is good to ask ourselves if our emails can be accessed by a blind person using a screen reader.</p><h3>🔮 Adapts to new technology</h3><p>From the previous point it follows the fact that plain text is more readable. I personally was surprised to discover that you can read your emails in smartwatches and smart assisters,or that you can obtain a more comprehensible preview of the content.</p><p>I know, it is super obvious when you think about it. But we do not always have in mind that there are other kinds of displays where people read their emails or notifications. And that we have to be ahead of the new possibilities, because we don’t know what type of devices will be developed in the future.</p><p>In this case, keeping it simple will ensure you that people can read your messages.</p><p>So, now you know, don’t be shy and start sending those emails and talking to your users. You may be pleasantly surprised with what you discover.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/plain-text-engagement</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655493</guid>
            <pubDate>Thu, 01 Oct 2020 19:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next-Gen Rust Web Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654891">thread link</a>) | @yannikyeo
<br/>
October 1, 2020 | https://blog.shortepic.com/blog/first/ | <a href="https://web.archive.org/web/*/https://blog.shortepic.com/blog/first/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>This is an homage to this absolute <a href="http://www.sheshbabu.com/posts/rust-wasm-yew-single-page-application/">work of art</a> by Shesh Babu.</p>

<p>Rust's strong typing and fearless concurrency means we can skip virtual DOM differencing. </p>
<p>In the JavaScript world, avoiding the vDOM is the bread and butter of <a href="https://svelte.dev/">Svelte</a> 
started by Rich Harris, which uses compile-time code generation to assist.</p>
<p>When I can't have static typing I love Clojure, and have spent some time reviewing and 
playing with the stupendous full-stack Clojure SPA framework <a href="http://book.fulcrologic.com/">Fulcro</a> 
by Tony Kay (and associated back-end enabler <a href="https://blog.wsscode.com/pathom/">Pathom</a> 
by Wilker Lucio). It does use vDOM, leveraging Clojure immutable/concurrent data structures 
for time travel superpowers.</p>
<p>For me, the major innovation (among many) in Fulcro is the use of a browser-side normalised database 
which is queried to populate properties for components. This means that updating (<em>mutating</em>) 
a uniquely-keyed item results in the update trivially propagating to any and all components 
referencing the data through that identifier. In Shesh Babu's language: all state is App state.</p>
<p>This article, or series of articles, is going to share my findings and thinking on the 
state of the nation in Rust front-end frameworks which are avoiding the vDOM strategy.</p>
<p>There are actually two Rust front-end frameworks with significant progress already, and they are 
awesome:</p>
<ul>
<li><a href="https://crates.io/crates/mogwai">mogwai</a> by Schell Scivally</li>
<li><a href="https://crates.io/crates/valerie">valerie</a> by Emmanuel Antony</li>
</ul>

<p>The official React site offers a <a href="https://reactjs.org/tutorial/tutorial.html">guided introduction</a> 
by progressively implementing a client-side tic-tac-toe game (also known as <em>noughts and crosses</em>). 
They don't explore a back-end, routing or forms, or many of the other SPA complexities. </p>
<p>For us, it is just enough to highlight the potential of the two Rust frameworks above and paint 
a picture of how those advanced extensions can be easily incorporated, and gives us a solid 
reference point from the old world.</p>

<p>This is the first in a series of articles showing how the two frameworks might attack the example 
application, and then show some code which extends the frameworks to incorporate Fulcro-like app 
state.</p>
<p>My code will concentrate on the ergonomics of the frameworks from the perspective of the SPA-writer.</p>
<p>Next up, I'll show an implementation of the game in Valerie.</p>
<p><a href="https://blog.shortepic.com/blog/second/">On to the first code sample</a>.</p>

  </article></div>]]>
            </description>
            <link>https://blog.shortepic.com/blog/first/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654891</guid>
            <pubDate>Thu, 01 Oct 2020 19:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incarceration in Real Numbers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654820">thread link</a>) | @tmsh
<br/>
October 1, 2020 | https://mkorostoff.github.io/incarceration-in-real-numbers/ | <a href="https://web.archive.org/web/*/https://mkorostoff.github.io/incarceration-in-real-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="prisoners">
    
    
    
    

    <div>
      <p>The United States holds more people in jails and prisons than any other country by far, both in absolute numbers and as a percentage of population.</p>
    </div>

    <div id="per-one-hundred">
      <div id="per-one-hundred-inner">
        <h2>Incarcerated per 100,000 residents <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p><span>USA (698)</span></p>
        <p><span>El Salvador (590)</span></p>
        <p><span>Turkmenistan (552)</span></p>
        <p><span>Thailand (531)</span></p>
        <p><span>Rwanda (511)</span></p>
        <p><span>Cuba (510)</span></p>
        <p><span>Panama (401)</span></p>
        <p><span>Costa Rica (374)</span></p>
        <p><span>Cayman Islands (365)</span></p>
        <p><span>Russia (363)</span></p>
        <p><span>Belize (356)</span></p>
        <p><span>Brazil (348)</span></p>
        <p><span>Belarus (343)</span></p>
        <p><span>Nicaragua (332)</span></p>
        <p><span>Turkey (324)</span></p>
        <p><span>Puerto Rico (313)</span></p>
        <p><span>Brunei Darussalam (307)</span></p>
        <p><span>Cape Verde (296)</span></p>
        <p><span>Uruguay (295)</span></p>
        <p><span>Namibia (295)</span></p>
        <p><span>Iran (294)</span></p>
        <p><span>Trinidad and Tobago (292)</span></p>
        <p><span>Guyana (284)</span></p>
        <p><span>Peru (278)</span></p>
        <p><span>South Africa (275)</span></p>
        <p><span>Georgia (262)</span></p>
        <p><span>Taiwan (258)</span></p>
        <p><span>Swaziland (258)</span></p>
        <p><span>Greenland (249)</span></p>
        <p><span>Colombia (246)</span></p>
        <p><span>French Guiana (243)</span></p>
        <p><span>Gabon (241)</span></p>
        <p><span>Morocco (237)</span></p>
        <p><span>Dominican Republic (237)</span></p>
        <p><span>CuraÃ§ao (236)</span></p>
        <p><span>Azerbaijan (235)</span></p>
        <p><span>Israel (234)</span></p>
        <p><span>Bahrain (234)</span></p>
        <p><span>Ecuador (233)</span></p>
        <p><span>Macau (233)</span></p>
        <p><span>Chile (232)</span></p>
        <p><span>Argentina (230)</span></p>
        <p><span>Malaysia (230)</span></p>
        <p><span>Honduras (229)</span></p>
        <p><span>Lithuania (221)</span></p>
        <p><span>Cambodia (220)</span></p>
        <p><span>Martinique (215)</span></p>
        <p><span>Fiji (210)</span></p>
        <p><span>Botswana (208)</span></p>
        <p><span>Mauritius (203)</span></p>
        <p><span>New Zealand (201)</span></p>
        <p><span>Paraguay (199)</span></p>
        <p><span>Singapore (199)</span></p>
        <p><span>Jordan (198)</span></p>
        <p><span>Saudi Arabia (197)</span></p>
        <p><span>Czech Republic (197)</span></p>
        <p><span>Poland (195)</span></p>
        <p><span>Tunisia (195)</span></p>
        <p><span>Slovakia (195)</span></p>
        <p><span>Moldova (194)</span></p>
        <p><span>New Caledonia (189)</span></p>
        <p><span>Estonia (187)</span></p>
        <p><span>Latvia (183)</span></p>
        <p><span>Montenegro (183)</span></p>
        <p><span>Suriname (183)</span></p>
        <p><span>Philippines (179)</span></p>
        <p><span>Venezuela (178)</span></p>
        <p><span>Albania (177)</span></p>
        <p><span>Hungary (173)</span></p>
        <p><span>Myanmar (171)</span></p>
        <p><span>Australia (170)</span></p>
        <p><span>Mexico (163)</span></p>
        <p><span>Kyrgyzstan (161)</span></p>
        <p><span>Bolivia (158)</span></p>
        <p><span>Kazakhstan (156)</span></p>
        <p><span>Serbia (156)</span></p>
        <p><span>Algeria (151)</span></p>
        <p><span>Uzbekistan (150)</span></p>
        <p><span>Scotland (149)</span></p>
        <p><span>Ukraine (148)</span></p>
        <p><span>Bhutan (145)</span></p>
        <p><span>Lebanon (144)</span></p>
        <p><span>Guatemala (143)</span></p>
        <p><span>England &amp; Wales (140)</span></p>
        <p><span>Nauru (140)</span></p>
        <p><span>Libya (139)</span></p>
        <p><span>Jamaica (138)</span></p>
        <p><span>Malta (131)</span></p>
        <p><span>Laos (130)</span></p>
        <p><span>Vietnam (128)</span></p>
        <p><span>Ethiopia (127)</span></p>
        <p><span>Micronesia (127)</span></p>
        <p><span>Guernsey (127)</span></p>
        <p><span>Iraq (126)</span></p>
        <p><span>Portugal (125)</span></p>
        <p><span>Bulgaria (125)</span></p>
        <p><span>Isle of Man (125)</span></p>
        <p><span>Spain (124)</span></p>
        <p><span>Uganda (124)</span></p>
        <p><span>Cameroon (124)</span></p>
        <p><span>Zambia (123)</span></p>
        <p><span>Tajikistan (121)</span></p>
        <p><span>China (120)</span></p>
        <p><span>Kuwait (117)</span></p>
        <p><span>Egypt (116)</span></p>
        <p><span>Zimbabwe (114)</span></p>
        <p><span>North Macedonia (112)</span></p>
        <p><span>Mongolia (110)</span></p>
        <p><span>Canada (107)</span></p>
        <p><span>Romania (107)</span></p>
        <p><span>Hong Kong (106)</span></p>
        <p><span>France (105)</span></p>
        <p><span>Sri Lanka (105)</span></p>
        <p><span>Luxembourg (105)</span></p>
        <p><span>UAE (104)</span></p>
        <p><span>Kenya (102)</span></p>
        <p><span>Italy (101)</span></p>
        <p><span>Indonesia (99)</span></p>
        <p><span>Austria (98)</span></p>
        <p><span>Belgium (95)</span></p>
        <p><span>Greece (95)</span></p>
        <p><span>Kosovo (95)</span></p>
        <p><span>Madagascar (93)</span></p>
        <p><span>Angola (93)</span></p>
        <p><span>Lesotho (92)</span></p>
        <p><span>Afghanistan (87)</span></p>
        <p><span>Cyprus (86)</span></p>
        <p><span>Burundi  (85)</span></p>
        <p><span>Monaco (83)</span></p>
        <p><span>Cote d'Ivoire  (82)</span></p>
        <p><span>Switzerland  (81)</span></p>
        <p><span>Haiti  (80)</span></p>
        <p><span>Croatia  (79)</span></p>
        <p><span>Ireland (79)</span></p>
        <p><span>Nepal  (79)</span></p>
        <p><span>Northern Ireland (78)</span></p>
        <p><span>Germany  (77)</span></p>
        <p><span>Armenia  (76)</span></p>
        <p><span>Malawi (76)</span></p>
        <p><span>Slovenia (69)</span></p>
        <p><span>Benin  (68)</span></p>
        <p><span>Senegal  (68)</span></p>
        <p><span>Djibouti (66)</span></p>
        <p><span>Togo (66)</span></p>
        <p><span>Andorra  (64)</span></p>
        <p><span>Denmark  (63)</span></p>
        <p><span>Equatorial Guinea  (63)</span></p>
        <p><span>Mozambique (63)</span></p>
        <p><span>Papua New Guinea (62)</span></p>
        <p><span>Sweden (61)</span></p>
        <p><span>Netherlands  (61)</span></p>
        <p><span>Norway (60)</span></p>
        <p><span>Sierra Leone (60)</span></p>
        <p><span>Syria  (60)</span></p>
        <p><span>Chad (59)</span></p>
        <p><span>Tanzania (59)</span></p>
        <p><span>Finland  (53)</span></p>
        <p><span>Mauritania (53)</span></p>
        <p><span>Qatar  (53)</span></p>
        <p><span>Yemen  (53)</span></p>
        <p><span>Bangladesh (52)</span></p>
        <p><span>Ghana  (52)</span></p>
        <p><span>Sudan  (52)</span></p>
        <p><span>Timor-Leste (52)</span></p>
        <p><span>Liberia  (50)</span></p>
        <p><span>South Sudan  (50)</span></p>
        <p><span>Niger  (44)</span></p>
        <p><span>Burkina Faso (39)</span></p>
        <p><span>Japan  (39)</span></p>
        <p><span>Pakistan (38)</span></p>
        <p><span>Iceland  (37)</span></p>
        <p><span>Nigeria  (36)</span></p>
        <p><span>Oman (36)</span></p>
        <p><span>India  (34)</span></p>
        <p><span>Mali (33)</span></p>
        <p><span>Gambia (31)</span></p>
        <p><span>Liechtenstein  (31)</span></p>
        <p><span>Democratic Republic of Congo (29)</span></p>
        <p><span>Guinea (28)</span></p>
        <p><span>Congo (27)</span></p>
        <p><span>Central African Republic (16)</span></p>
        <p><span>Guinea Bissau  (10)</span></p>
        <p><span>San Marino (6)</span></p>
      <p><a onclick="toggleExpand('per-one-hundred', 'per-one-hundred-inner')">Expand ▼</a>
      </p></div>
    </div>

    <div id="country-rank">
      <div id="country-rank-inner">
        <h2>Number of people incarcerated <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p>USA (2.3M)</p>
        <p><span>China (1.7M)</span></p>
        <p><span>Brazil (747K)</span></p>
        <p><span>Russian Federation (524K)</span></p>
        <p><span>India (466K)</span></p>
        <p><span>Thailand (368K)</span></p>
        <p><span>Indonesia (267K)</span></p>
        <p><span>Turkey (265K)</span></p>
        <p><span>Iran (240K)</span></p>
        <p><span>Philippines (215K)</span></p>
        <p><span>Mexico (203K)</span></p>
        <p><span>South Africa (163K)</span></p>
        <p><span>Vietnam (124K)</span></p>
        <p><span>Colombia (123K)</span></p>
        <p><span>Ethiopia (114K)</span></p>
        <p><span>Egypt (106K)</span></p>
        <p><span>Argentina (103K)</span></p>
        <p><span>Myanmar  (92K)</span></p>
        <p><span>Peru (91K)</span></p>
        <p><span>Bangladesh (88K)</span></p>
        <p><span>Morocco (86K)</span></p>
        <p><span>United Kingdom: England &amp; Wales (83K)</span></p>
        <p><span>Pakistan (77K)</span></p>
        <p><span>Poland (74K)</span></p>
        <p><span>Malaysia (74K)</span></p>
        <p><span>Nigeria (73K)</span></p>
        <p><span>France (71K)</span></p>
        <p><span>Rwanda (65K)</span></p>
        <p><span>Germany (64K)</span></p>
        <p><span>Algeria (63K)</span></p>
        <p><span>Saudi Arabia (61K)</span></p>
        <p><span>Taiwan (61K)</span></p>
        <p><span>Italy (61K)</span></p>
        <p><span>Spain (58K)</span></p>
        <p><span>Cuba (57K)</span></p>
        <p><span>Venezuela (57K)</span></p>
        <p><span>Uganda (55K)</span></p>
        <p><span>Republic of  (55K)</span></p>
        <p><span>Ukraine (53K)</span></p>
        <p><span>Kenya (51K)</span></p>
        <p><span>Japan (49K)</span></p>
        <p><span>Iraq (45K)</span></p>
        <p><span>Uzbekistan (44K)</span></p>
        <p><span>Australia (43K)</span></p>
        <p><span>Chile (43K)</span></p>
        <p><span>Ecuador (40K)</span></p>
        <p><span>Canada (40K)</span></p>
        <p><span>El Salvador (38K)</span></p>
        <p><span>Cambodia (37K)</span></p>
        <p><span>Tanzania (36K)</span></p>
        <p><span>Belarus (33K)</span></p>
        <p><span>Afghanistan (31K)</span></p>
        <p><span>Cameroon (31K)</span></p>
        <p><span>Turkmenistan (30K)</span></p>
        <p><span>Kazakhstan (29K)</span></p>
        <p><span>Dominican Republic (26K)</span></p>
        <p><span>Guatemala (25K)</span></p>
        <p><span>Madagascar (25K)</span></p>
        <p><span>Angola (24K)</span></p>
        <p><span>Nepal (24K)</span></p>
        <p><span>Sri Lanka (23K)</span></p>
        <p><span>Azerbaijan (23K)</span></p>
        <p><span>Zambia (23K)</span></p>
        <p><span>Tunisia (23K)</span></p>
        <p><span>Cote d'Ivoire (21K)</span></p>
        <p><span>Czech Republic (21K)</span></p>
        <p><span>Sudan (21K)</span></p>
        <p><span>Nicaragua (21K)</span></p>
        <p><span>Romania (21K)</span></p>
        <p><span>Democratic Republic of Congo (21K)</span></p>
        <p><span>Honduras (21K)</span></p>
        <p><span>Jordan (20K)</span></p>
        <p><span>Mozambique (20K)</span></p>
        <p><span>Zimbabwe (19K)</span></p>
        <p><span>Israel (19K)</span></p>
        <p><span>Costa Rica (19K)</span></p>
        <p><span>Bolivia (18K)</span></p>
        <p><span>Panama (17K)</span></p>
        <p><span>Hungary (17K)</span></p>
        <p><span>Ghana (15K)</span></p>
        <p><span>Malawi (15K)</span></p>
        <p><span>Yemen (14K)</span></p>
        <p><span>Paraguay (14K)</span></p>
        <p><span>Portugal (13K)</span></p>
        <p><span>Singapore (12K)</span></p>
        <p><span>Senegal (12K)</span></p>
        <p><span>Belgium (11K)</span></p>
        <p><span>Serbia (11K)</span></p>
        <p><span>Burundi (11K)</span></p>
        <p><span>Slovakia (11K)</span></p>
        <p><span>Syria (11K)</span></p>
        <p><span>Puerto Rico  (10K)</span></p>
        <p><span>Netherlands (10K)</span></p>
        <p><span>Uruguay (10K)</span></p>
        <p><span>Greece (10K)</span></p>
        <p><span>Kyrgyzstan (10K)</span></p>
        <p><span>New Zealand (10K)</span></p>
        <p><span>United Arab Emirates (10K)</span></p>
        <p><span>Georgia (10K)</span></p>
        <p><span>Niger (10K)</span></p>
        <p><span>Tajikistan (9K)</span></p>
        <p><span>Libya (9K)</span></p>
        <p><span>Bulgaria (9K)</span></p>
        <p><span>Laos (9K)</span></p>
        <p><span>Haiti (9K)</span></p>
        <p><span>Chad (9K)</span></p>
        <p><span>Austria (9K)</span></p>
        <p><span>United Kingdom: Scotland (8K)</span></p>
        <p><span>Hong Kong  (8K)</span></p>
        <p><span>Benin (8K)</span></p>
        <p><span>Burkina Faso (8K)</span></p>
        <p><span>Namibia (7K)</span></p>
        <p><span>South Sudan (7K)</span></p>
        <p><span>Lebanon (7K)</span></p>
        <p><span>Switzerland (7K)</span></p>
        <p><span>Moldova  (7K)</span></p>
        <p><span>Sweden (6K)</span></p>
        <p><span>Lithuania (6K)</span></p>
        <p><span>Mali (5K)</span></p>
        <p><span>Togo (5K)</span></p>
        <p><span>Papua New Guinea (5K)</span></p>
        <p><span>Albania (5K)</span></p>
        <p><span>Sierra Leone (5K)</span></p>
        <p><span>Kuwait (5K)</span></p>
        <p><span>Gabon (4K)</span></p>
        <p><span>Botswana (4K)</span></p>
        <p><span>Trinidad and Tobago (4K)</span></p>
        <p><span>Ireland, Republic of (4K)</span></p>
        <p><span>Jamaica (4K)</span></p>
        <p><span>Guinea  (4K)</span></p>
        <p><span>Denmark (4K)</span></p>
        <p><span>Latvia (4K)</span></p>
        <p><span>Bahrain (3K)</span></p>
        <p><span>Swaziland/eSwatini (3K)</span></p>
        <p><span>Mongolia (3K)</span></p>
        <p><span>Croatia (3K)</span></p>
        <p><span>Norway (3K)</span></p>
        <p><span>Finland (3K)</span></p>
        <p><span>Mauritius (3K)</span></p>
        <p><span>Estonia (2K)</span></p>
        <p><span>Liberia (2K)</span></p>
        <p><span>North Macedonia (2K)</span></p>
        <p><span>Mauritania (2K)</span></p>
        <p><span>Armenia (2K)</span></p>
        <p><span>Guyana (2K)</span></p>
        <p><span>Lesotho (2K)</span></p>
        <p><span>Fiji (2K)</span></p>
        <p><span>Maldives (2K)</span></p>
        <p><span>Bahamas (2K)</span></p>
        <p><span>Bosnia and Herzegovina: Federation (2K)</span></p>
        <p><span>Kosovo/Kosova (2K)</span></p>
        <p><span>Macau  (2K)</span></p>
        <p><span>Cape Verde  (2K)</span></p>
        <p><span>United Kingdom: Northern Ireland (1K)</span></p>
        <p><span>Slovenia (1K)</span></p>
        <p><span>Brunei Darussalam (1K)</span></p>
        <p><span>Oman (1K)</span></p>
        <p><span>Belize (1K)</span></p>
        <p><span>Congo  (1K)</span></p>
      <p><a onclick="toggleExpand('country-rank', 'country-rank-inner')">Expand ▼</a>
      </p></div>
    </div>

    <div>
      <p>There are more incarcerated people than members of almost any profession. There are more incarcerated people than military personnel. There are more incarcerated people than bus drivers, bar tenders, and hair dressers combined. [<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-compared-to-professions"></a>]</p>
    </div>

    <div>
      <p>
        More Americans are incarcerated today than there have been Americans killed in all of the wars in all of history combined.
      </p>
    </div>

    <div id="casualties">
      <div>
        <h2>Incarceration compared to casualties of war <sup>[<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#american-war-dead"></a>]</sup></h2>
        <p>Americans currently incarcerated (2.3M)</p>
        <p>American war dead, all of history combined (1.3M)</p>
        <p>American war wounded, all of history combined (1.5M)</p>
      </div>
    </div>

    <div>
      <p>While the incarcerated population is unfathomably large, it is just the tip of the iceberg.</p>
    </div>

    <div id="correctional-population">
      <div>
        <h2>The total correctional population <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#total-correctional-population" target="_blank"></a>]</sup></h2>
        <div>

          <div>
            <p>Currently incarcerated (2.3M)</p>
          </div>

          <div>
            <p>Will be incarcerated this year (4.9M)</p>
          </div>

          <div>
            <p>Alive currently, will go to prison ever (10.9M)</p>
          </div>

          <div>
            <p>Has a criminal record (77M)</p>
          </div>

          <div>
            <p>Ever had an immediate family member incarcerated (113M)</p>
          </div>

        </div>
      </div>
    </div>

    <div>
      <p>Almost no one gets a trial.</p>
    </div>

    <div>
      <p><img src="https://mkorostoff.github.io/incarceration-in-real-numbers/img/person/blue.svg">Notice that the background icons have changed. The blue icons are the portion of incarcerated people who got trials, around 2%.</p>
    </div>

    <div>
      <p>Almost all accused people are extorted into taking plea bargains under the threat of a longer sentence, the ruinous cost of mounting a defense, and the wildly under-resourced public defender system. [<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#plea-bargains" target="_blank"></a>]</p>
    </div>

    <div>
      <p>No other country on earth incarcerates so many people without trial. …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mkorostoff.github.io/incarceration-in-real-numbers/">https://mkorostoff.github.io/incarceration-in-real-numbers/</a></em></p>]]>
            </description>
            <link>https://mkorostoff.github.io/incarceration-in-real-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654820</guid>
            <pubDate>Thu, 01 Oct 2020 18:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting a blog on Azure for $2.5 per month]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654536">thread link</a>) | @fleide
<br/>
October 1, 2020 | https://www.eiden.ca/azure-static-blog/ | <a href="https://web.archive.org/web/*/https://www.eiden.ca/azure-static-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>High level picture of hosting a static site (blog) on Azure with details on how to wire a custom domain (root and www) with HTTPS support. It’s actually easier that it sounds.</p>

<!--more-->

<p>Let’s start by noting that $2 out of the $2.5 mentioned in the title are for the custom domain name and associated SSL certificate (for HTTPS). Static content hosting, CDN (<a href="https://en.wikipedia.org/wiki/Content_delivery_network">content delivery network</a>) and networking in Azure cost less than 50 cents per month for this application. To be fair, this is not the most read blog of the Internet.</p>

<p>Also I’m using <a href="https://jekyllrb.com/">Jekyll</a> for this blog, and it’s been good to me so far.</p>

<h2 id="summary">Summary</h2>

<p>The main components used are:</p>

<ul>
  <li>From non-Microsoft providers
    <ul>
      <li>a <strong>custom domain name</strong> from a registrar of our choosing (I’m using <a href="https://www.gandi.net/en-CA">Gandi</a>) - here <code>eiden.ca</code></li>
      <li>a <strong>SSL certificate</strong> to enable HTTPS, I recommend Namecheap (<a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">PositiveSSL</a>) to procure one. This certificate will need to be generated for the custom domain name we created above (we’ll see how). <strong>THIS IS IF</strong> you want HTTPS for the <strong>root</strong> of the custom domain (<a href="https://eiden.ca/">https://eiden.ca</a>), even if you just want it to redirect to <strong>www</strong>. This was a must have for me, and the reason for the existence of this very article. If you don’t care about the root, you can use the <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-custom-ssl?tabs=option-1-default-enable-https-with-a-cdn-managed-certificate">managed certificate included</a> in Azure CDN (which at the time of writing doesn’t support root).</li>
    </ul>
  </li>
  <li>In Azure
    <ul>
      <li>a <strong>Storage Account</strong> with <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website">static web hosting</a> enabled. That feature allows to serve static content (html, css, javascript, images) directly from a container</li>
      <li>a <strong>Key Vault</strong> to help generate the certificate and store it once issued by the provider</li>
      <li>a <strong>CDN Profile</strong>, to cache the content and optimize performance and cost. The CDN profile loads our content from the storage account, distributes in its worldwide network, and serves to visitors in a scalable fashion automatically</li>
      <li>a <strong>DNS Zone</strong>, to manage the name resolution of our custom domain and point the traffic towards the CDN profile</li>
    </ul>
  </li>
</ul>

<p>On a picture:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, all details will be explained below in this post"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 1 : Schema of the solution</a></em></p>

<p>Let’s jump into it.</p>

<h2 id="step-1-and-2--starting-with-the-static-website-and-the-cdn-profile">Step 1 and 2 : Starting with the Static Website and the CDN Profile</h2>

<p>First we will follow the <strong>parts 1 and 2</strong> from this <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">awesome tutorial</a> from John M. Wright to get the storage account and CDN profile set up. <strong>Let’s not go further than part 2</strong>, we’ll switch to another guide for the following step.</p>

<p>In part 2, I’ve personally used the <code>Azure CDN from Microsoft</code> and it went great.</p>

<p>At this point, what we should have is this:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png" alt="Step 1 : a storage account with static hosting and a CDN endpoint"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png">figure 2 : a storage account with static hosting and a CDN endpoint</a></em></p>

<p>We can already see our content online at the following URLs:</p>

<ul>
  <li><code>https://&lt;sa&gt;.web.core.windows.net</code>, directly from the storage account</li>
  <li><code>https://&lt;cdn&gt;.azureedge.net</code>, from the CDN endpoint</li>
</ul>

<p>To be noted that to upload our content to the <code>$web</code> container of the storage account, the best option is to use the <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> or <a href="https://azure.microsoft.com/en-us/features/storage-explorer/">Azure Storage Explorer</a>. I tend to default on PowerShell but here <code>Set-AzStorageBlobContent</code> doesn’t manage the content-types of the files it uploads.</p>

<p>The syntax in the CLI is straightforward (in a PowerShell host, cmd or bash terminal) :</p>

<pre><code># Here the parameter syntax is PowerShell and I'm already logged in the CLI via az login
$contentLocalPath = "C:\..."
$storageAccountName = "mystorageaccount"
az storage blob upload-batch -s $contentLocalPath -d '$web' --account-name $storageAccountName
</code></pre>

<h2 id="step-3--adding-a-dns-zone">Step 3 : Adding a DNS Zone</h2>

<p>To add the DNS Zone, let’s switch to the <strong>part 3</strong> of this <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-3-set-up-dns-configuration">exhaustive guide</a> from Rune Aamodt.</p>

<p>Here we will <strong>not only</strong> create a record for the <strong>www subdomain</strong> (type <code>CNAME</code>, alias record set to the CDN endpoint) like in the guide, but also for the <strong>root (apex) domain</strong> (type <code>A</code>, alias record set to the same CDN endpoint).</p>

<p>This is how it should look now (<strong>bold</strong> being the ones we created above):</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>TTL</th>
      <th>Value</th>
      <th>Alias resource type</th>
      <th>Alias target</th>
      <th>Comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>@</strong></td>
      <td><strong>A</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>Root/apex domain record</strong></td>
    </tr>
    <tr>
      <td>@</td>
      <td>NS</td>
      <td>172800</td>
      <td>ns1-07.azure-dns.com…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>SOA</td>
      <td>3600</td>
      <td>Email:… Host: ns1-07.azure-dns.com…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>MX</td>
      <td>3600</td>
      <td>10 spool.mail.gandi.net.,50 fb.mail.gandi.net.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>@</td>
      <td>TXT</td>
      <td>3600</td>
      <td>“v=spf1 include:_mailcust.gandi…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>cdnverify</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
    <tr>
      <td>sa</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>external.simpleanalytics.com.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Record required by the analytics provider I use here</td>
    </tr>
    <tr>
      <td><strong>www</strong></td>
      <td><strong>CNAME</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>www subdomain record</strong></td>
    </tr>
    <tr>
      <td>cdnverify.www</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure…</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
  </tbody>
</table>

<p>This is where we will have to log in to the admin portal of our Domain Registrar (Gandi for me) to switch our custom domain to use <strong>external nameservers</strong>. We will provide the 4 Azure ones listed in our DNS zone.</p>

<p>This can be a frustrating step since making changes to DNS records can take hours to take effect. Let’s try and be patient…</p>

<p>On <strong>Gandi</strong> it looks like this:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg" alt="Step 3 : Screenshot of the admin portal in Gandi"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg">figure 3 : updating nameservers in Gandi</a></em></p>

<p>Now that we have the DNS Zone setup, the situation looks like that:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png" alt="Step 3 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png">figure 4 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated</a></em></p>

<p>Now let’s head back to the CDN endpoint to add the custom domains we just created here.</p>

<h2 id="step-4--enabling-https-for-the-cdn-endpoint-custom-domains">Step 4 : Enabling HTTPS for the CDN Endpoint Custom Domains</h2>

<p>We will head back to the first tutorial, but <strong>before let’s quickly sum up the situation</strong>. As I mentioned in the summary, Azure CDN offers managed certificate for HTTPS, but at the time of writing they are not available for the root / apex domain.</p>

<p>This is why we need to bring our own certificate.</p>

<p>Before heading back into the tutorial, let’s review the 3 high level steps of that process:</p>

<ol>
  <li>In an Azure Key Vault, we will create a new certificate that will be issued by a <strong>non-integrated</strong> CA (Namecheap). <strong>Contrary</strong> to what’s in the guide, use <strong>PKCS#12</strong> (even if we don’t understand the details, it’s just easier)</li>
  <li>We will then download the CSR (<code>Certificate Signing Request</code>) from Azure Key Vault, upload it to our SSL certificate provider to get processed, get the PKCS#12 file generated there back into Azure Key Vault (<code>merge signed request</code>)</li>
  <li>Back in the CDN Endpoint, we will create the custom domains (root and www), with HTTPS, using our own certificate hosted in Key Vault</li>
</ol>

<p>So let’s head back to <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">the tutorial</a> from John for <strong>part 4 and 5</strong> (sorry there’s no direct links) that explains everything in details.</p>

<h2 id="step-5--adding-cdn-rules">Step 5 : Adding CDN rules</h2>

<p>Finally, we need to add some rules in the CDN Rules engine to sort traffic coming from the root and subdomain on both HTTP and HTTPS. I wanted everything to end on <code>https://www.eiden.ca</code>, but you can adapt the rules below for a different result:</p>

<ul>
  <li>Rule 1 : <code>http://</code> requests need to be redirect to <code>https://www...</code></li>
  <li>Rule 2 : root requests need to be redirected to <code>https://www...</code></li>
</ul>

<p>For that we can get inspiration from the <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-5-enforce-https">step 5</a> of the second guide to get something looking like that:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg" alt="Step 5 : Screenshot of the CDN endpoint rules engine configuration, details below"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg">figure 5 : Rules to manage traffic across domains and protocols</a></em></p>

<p>The details of these rules:</p>

<ul>
  <li>Rule 1
    <ul>
      <li>Name : <strong>http2https</strong></li>
      <li>If Request <strong>protocol</strong>
        <ul>
          <li>Operator : <code>Equals</code></li>
          <li>Request URL : <code>HTTP</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Rule 2
    <ul>
      <li>Name : <strong>root2www</strong></li>
      <li>If Request <strong>URL</strong>
        <ul>
          <li>Operator : <code>Begins with</code></li>
          <li>Request URL : <code>https://eiden.ca</code></li>
          <li>Case transform : <code>To lowercase</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>The picture is now complete:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, everything has been explained above"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 6 : The whole thing wired up together</a></em></p>

<h2 id="step-6--flushing-the-cdn-profile">Step 6 : Flushing the CDN profile</h2>

<p>As discussed earlier, the CDN caches our files to serve them in an optimal fashion. Like any cache, it will need to be expired and reloaded when new content is uploaded to the storage account. This is not done automatically.</p>

<p>In the Azure CDN world, this operation is called a <strong>purge</strong>. It can be done in <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-purge-endpoint">the Azure portal</a> or via script.</p>

<p>In my case I’m using the <a href="https://docs.microsoft.com/en-us/powershell/azure/new-azureps-module-az?view=azps-4.7.0">PowerShell Az module</a> (not to be mistaken with the AzureRM module) to do that every time I publish a new article:</p>

<pre><code># Already logged via Connect-AzAccount

$cdnProfileName = "eiden-ca"

Get-AzCdnProfile `
  | Where-Object {$_.Name -eq $cdnProfileName} `
  | Get-AzCdnEndpoint `
  | Unpublish-AzCdnEndpointContent -PurgeContent "/*"

</code></pre>

<h2 id="closing">Closing</h2>

<p>So really, $2.5 per month?</p>

<ul>
  <li><a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">Namecheap</a> SSL Certificate : $9 per year</li>
  <li><a href="https://www.gandi.net/en-CA">Gandi</a> custom domain (<code>.ca</code>) : $15 per year</li>
  <li>Everything <a href="https://azure.microsoft.com/en-us/free/">Azure</a> : $.5 per month</li>
</ul>

<p><strong>Total : $2.5 per month!</strong></p>

      </article></div>]]>
            </description>
            <link>https://www.eiden.ca/azure-static-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654536</guid>
            <pubDate>Thu, 01 Oct 2020 18:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build an open source business]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24654427">thread link</a>) | @mattgreg
<br/>
October 1, 2020 | https://www.ockam.io/learn/blog/zero_ipo/ | <a href="https://web.archive.org/web/*/https://www.ockam.io/learn/blog/zero_ipo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s Zero-to-IPO map is a key strategy input to our tactical short, medium and long-term business planning. It focuses on the one-thing that <em>really</em> matters, at specific points in time. We live our values at Ockam, and as an open source company, we want to share our roadmap.</p><p font-family="body" font-weight="body" font-size="body" color="text">As outlined in the progression below, we’ve plotted a course from stoking awareness to operating an enterprise sales machine.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" alt="Zero to IPO map" title="Zero to IPO map" srcset="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a2ead/map.png 259w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/6b9fd/map.png 518w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png 1035w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/44d59/map.png 1553w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a6d66/map.png 2070w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png 3652w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The time scale for our route to IPO is, as you’d expect, years long. Given that startups plan around funding cycles, let’s plot funding cycles as waypoints on our course. It can generally be assumed that there is 18-24 months between these waypoints.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" alt="Funding time scale" title="Funding time scale" srcset="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a2ead/funding.png 259w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/6b9fd/funding.png 518w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png 1035w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/44d59/funding.png 1553w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a6d66/funding.png 2070w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png 3660w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The cloud, edge, and open source landscape continues to evolve - which means that we need to chart our own course into the future. However, Ockam’s route to IPO also considers the various ways that other companies have run the gauntlet from Zero-to-IPO. I’ve been fortunate to have been ‘in the rooms where it happened’. Over the past 10 years I’ve directly worked with well over 100 companies that were underpinned by open source software projects. I’ve seen spectacular successes, breathtaking failures, modest acquisitions, and some companies that simply fade into the darkness. I'll save those stories for another time, maybe over a beer.</p><p font-family="body" font-weight="body" font-size="body" color="text">In the image below are experiences that I’ve drawn from the previous decade in the open source, cloud, and developer tool space.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" alt="Rooms where it happened" title="Rooms where it happened" srcset="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a2ead/rooms.png 259w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/6b9fd/rooms.png 518w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png 1035w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/44d59/rooms.png 1553w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a6d66/rooms.png 2070w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png 3724w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">Let’s dive into each stage, in turn, to unpack what we are doing, when we are doing it, and how we are going to measure it.</p><h2 id="motion" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">In order to recruit our team, or for a developer to consider using Ockam, first they have to know we exist. We create and distribute a tremendous amount of content at Ockam with one goal - driving developer awareness.</p><p font-family="body" font-weight="body" font-size="body" color="text">For example, The first product Ockam shipped was <a href="https://www.ockam.io/learn/guides/team/values_and_virtues_on_the_Ockam_Team/">a blog on our Values</a>. The second was a white paper that shared our vision. Even this post is an example!  We have a learning library that outlines our thesis on the open source ecosystem, teaches computer science fundamentals, gives insights into our team culture, and demonstrates our technology. We’ve sat down for dozens of podcasts and interviews over the past two years. Ockam’s content is based around teaching. Being an effective listener and a great teacher are core underpinnings when building an open source community.</p><h2 id="metrics" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">To gauge awareness we track activity including page views on ockam.io, 'contact us' webform inquiries, GitHub stars, social media mentions, followers and, most importantly, applications to join our team.</p><h2 id="motion-1" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a critically important step in our progression to IPO. Building Ockam's community is a never-ending endeavor. It takes years of focus and unrelenting attention to get this step right. For example, Kafka spent it's first 5 years in this phase as an Apache project before Confluent was started.</p><p font-family="body" font-weight="body" font-size="body" color="text">We have three code interfaces to Ockam, which means that there are three different personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Application layer developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s users build systems and applications with our simple APIs, OckamD binary downloads, and hosted cloud services.</p><p font-family="body" font-weight="body" font-size="body" color="text">To simplify what’s going on at this stage, we create packages that any developer can grab in the middle of the night, on the other side of the world, and get a quick win for their demo day at work. You’ve got a job to be done, and we’ve got a simple solution for you. You can get it right now and we will measure your time to a technical-win in the scale of minutes.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Partners</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Community partners build add-ons, connectors, and plug-ins to connect Ockam to other codebases, cloud services and hardware components. Examples include InfluxData, Confluent - Kafka, Microchip, NXP, MacOS, and Microsoft Azure.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Open source developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s open source builders are engaged in development of Ockam's core codebase. They attend our monthly community meetings, and are hands-on with our OSS codebase on GitHub. Their participation ranges from updating a typo in documentation, to building complex features.</p><h2 id="metrics-1" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">We track Monthly Active Users across all three personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text">Binary downloads, account signups, or SaaS service IOPS are all indicators of usage. As hinted above, time to ‘technical win’, for an individual developer is also paramount. We’ve defined time to ‘technical win’ as the time it takes to go from an individual developer’s initial discovery to a working prototype that includes Ockam features.</p><p font-family="body" font-weight="body" font-size="body" color="text">The easiest user growth to track is the number of partner integrations. Since partners engage with us 1:1 on an integration, we are highly selective and deliberate about the partnerships that we support. Eventually the development of our technical partnerships will become programmatic. Programmatic examples from my past include the partner program for Heroku Add-ons and the Azure Marketplace partner portal.</p><p font-family="body" font-weight="body" font-size="body" color="text">We also track the intersection of partnerships and usage. For example, the number of Ockam Daemons that run alongside Influx Telegraf, or the number of IOPS in Ockam Routers that securely move packets to a Kafka Connector.</p><p font-family="body" font-weight="body" font-size="body" color="text">Finally open source activity and engagement is transparent through the tools in GitHub. Check out <a href="https://github.com/ockam-network">how we are doing</a> with stars, forks and commits.</p><h2 id="motion-2" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a really fun stage for a product-and-pricing-nut like me. By this point in our journey we have users, but not customers. To satisfy investor expectations and to further fund product development, we start to feed our product development machine with revenue.</p><p font-family="body" font-weight="body" font-size="body" color="text">This stage is far simpler than it’s often made out to be. Here’s my basic formula;</p><ul><li>If you are an individual developer, then Ockam is free.</li><li>If you are a commercial enterprise, but have not yet had a ‘technical win’ with Ockam, then Ockam is free.</li><li>If you are a commercial enterprise, and have had a ‘technical win’ with Ockam, then you pay.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">From here things get a bit more complicated. Services need to be packaged and priced. This, in my opinion, is the most challenging, but also the most fun part of product development. The classic product marketing mix (aka the 4P’s) framework is durable and applies for Ockam’s planned product offerings. In this phase we are packaging <strong>P</strong>roducts (say S, M, L sizes), establishing a <strong>P</strong>rice for each product, <strong>P</strong>romoting the product through rigorous segmentation and targeting, and <strong>P</strong>lacing it into various channels and partner marketplaces for distribution.</p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam’s SaaS products will have a freemium pricing and packaging structure. It’s worth calling out that freemium is not a pricing strategy. It’s a customer acquisition tactic that aligns with the formula above.</p><h2 id="metrics-2" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Monthly Recurring Revenue (MRR) is the top line / key metric during this phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">The free-to-paid funnel is another key metric since it is a leading indicator and helps to forecast MRR. We will track both conversion and velocity of our freemium SaaS users.</p><p font-family="body" font-weight="body" font-size="body" color="text">The metrics we track in the Self-Serve SaaS phase allow us to A/B test in our demand generation funnel. A/B testing allows us to optimize month-over-month revenue growth.  The target is 10-15% MoM growth.</p><h2 id="motion-3" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Inside Sales is a channel strategy for specific types of large customers we already have. This is mainly a cultivate-and-grow tactic. Our bottoms-up, Self Serve SaaS product model feeds leads to our Inside Sales Team. This team is technical, includes sales engineers and provides world-class support.</p><p font-family="body" font-weight="body" font-size="body" color="text">There are two separate objectives during this phase.</p><ul><li>Increase MRR through an increase in our customer base, and in the average ticket size.</li><li>Learn about Customer Acquisition Costs (CAC) for specific segments, prior to launching the Enterprise Sales phase.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">Monthly recurring revenue is still our top priority during the Inside Sales phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">What’s less obvious is the second objective. Understanding CAC prepares us for an all-in Enterprise Sales motion. Moving from here onto the Enterprise Sales waypoint is probably the most challenging. It’s fraught with peril. Many, many smart companies, with great products, and ‘developer love’ die right here.</p><p font-family="body" font-weight="body" font-size="body" color="text">How can that be? It’s because Inside Sales is bottoms-up and Enterprise Sales is tops-down. This means entirely new buyers, new product-marketing mix, and new internal talent. We must hold onto our developer roots, while we also learn to sell to the suits. While we are executing on Inside Sales we are doing the primary research that will help spawn a new company from our company.</p><p font-family="body" font-weight="body" font-size="body" color="text">This is fantastically difficult - mostly from a cultural standpoint. Fortunately there are a lot of people with a lot of scar tissue from the past 10 years - including myself - and we will push through. The key is patience. We need to use our inside sales motion to find specific beachheads to land our Enterprise Sales motion.</p><h2 id="metrics-3" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">MRR carries over as our key metric from the Self Serve SaaS phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">CAC analysis for multiple customer segments.</p><h2 id="anti-metrics" color="heading" font-family="heading" font-weight="heading">Anti-Metrics<a href="#anti-metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">There will be noise in our Inside Sales data!</p><p font-family="body" font-weight="body" font-size="body" color="text">The noise is any sale that looks like it could be Enterprise Sales. Up to this point, non-recurring engineering (NRE) and enterprise-like sales don’t count as Enterprise Sales, as we define the term in the next section. Typically they are one-off deals because the motion to win these deals isn’t scalable. We will do large custom deals to gain access to smart teams that deploy interesting technology. I prefer to categorize this class of revenue as ‘business development’ or even R&amp;D.</p><p font-family="body" font-weight="body" font-size="body" color="text">Why is this an anti-metric? Because other Open Source startups typically stand up a couple one-off enterprises like sales as a way to puff themselves up and to convince themselves that they are ready to move to the next phase. I strongly caution my future self to parse the noise from the signal prior to launching Enterprise Sales.</p><p font-family="body" font-weight="body" font-size="body" color="text">Furthermore, there are other Open Source companies that entirely bypass the Self Serve SaaS phase in favor of the chunky revenue that comes with Enterprise Sales. Those companies tend not to be product companies. They become …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ockam.io/learn/blog/zero_ipo/">https://www.ockam.io/learn/blog/zero_ipo/</a></em></p>]]>
            </description>
            <link>https://www.ockam.io/learn/blog/zero_ipo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654427</guid>
            <pubDate>Thu, 01 Oct 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the difference between Docker and a Virtual Machine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654229">thread link</a>) | @championshuttle
<br/>
October 1, 2020 | https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>While in principle they are very similar, it might be more common to know about Virtual Machines than Docker Containers. Virtual Machines are like Inception, but with computers; you’re running another computer inside your computer. A usual use-case for this setup that’s applicable even to people not working in tech, is for example, you have a Windows machine (your Host OS) and you want to somehow have Ubuntu (your Guest OS) just to test a software that only runs on Linux machines. You just want to quickly try it out, so you don’t want to go through the process of installing another OS in your system (dual booting).</p>
<p><span>
      <a href="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Running an Ubuntu session using VirtualBox" title="Running an Ubuntu session using VirtualBox" src="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg" srcset="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/7237a/ubuntu-vm.jpg 148w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/0cfdf/ubuntu-vm.jpg 295w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg 590w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Now let’s discuss the underlying technology a bit. A virtual machine is a system which emulates a computer system. It has its own CPU, memory, hard disk, network and other hardware resources which are managed by a ‘virtualization layer’. This layer then translates these requests to the physical hardware (host computer).</p>
<p>If you have tried running a VM in your machine, you know how your machine started heating up. This whole process is resource-intensive, because hey, you’re practically running a full version of another machine! That’s definitely something you won’t do when you want to solve a bigger use-case that requires this setup.</p>
<p><span>
      <a href="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Virtual Machine Simple Architecture" title="Virtual Machine Simple Architecture" src="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" srcset="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/00d96/vm-architecture.png 148w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/0b23c/vm-architecture.png 295w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>What if my colleagues also want to try that software? Do they also have to install the same heavy thing on their system? What if their hardware can’t handle it?</p>
<p>That’s where Docker comes in. It’s like milk, but the leanest version with the least amount of fat that you can find (sort of).</p>
<p>With Docker, you can run applications on your host operating system (e.g. Windows), in what is called a Container. A container is almost similar to an operating system minus the graphical user interface (the stuff you can click). It technically functions just like running a session on a VM, but here’s the magic: unlike in a VM where you have to run a session of an entire OS to use an application, with Docker, you are able to run the application in light-weight containers AND control it from the host OS. The part where you see another OS running? The part where you turn on Ubuntu on your VM Manager that you installed on your Windows machine? That part has been scrapped, making the whole setup way lighter. Instead, you just write some commands on the command line and you go directly into running your application.</p>
<p><em>Whuuuut?</em></p>
<p>Let’s try to visualize that with this image, compared to our previous one.</p>
<p><span>
      <a href="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker vs VM Visualized" title="Docker vs VM Visualized" src="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png" srcset="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/00d96/docker-vm.png 148w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/0b23c/docker-vm.png 295w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png 590w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The game-changing advantage of Docker is that it allows you to package any software with all of its dependencies into a single standardized unit called image.</p>
<p>Virtual machines run on a host OS and make guest OS available inside each VM, each OS needs to be booted individually. On the other hand, Docker containers are hosted on a single docker engine on a host OS. All the containers share the docker instance. Sharing the engine between containers makes them light and decreases the boot time. While Docker Containers boot in a few seconds, VMs take a few minutes to boot. </p>
<p><span>
      <a href="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker Architecture" title="Docker Architecture" src="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" srcset="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/00d96/docker-architecture.png 148w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/0b23c/docker-architecture.png 295w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<p>Now that we have that background, let’s take a look at some real examples of how these can be applied:</p>
<p><strong>Virtual machine</strong></p>
<p>You have a Windows machine and want to try out GIMP on Ubuntu. Here’s how the process will look like:</p>
<ol>
<li>Install an Ubuntu VM on a Windows machine</li>
<li>Go inside the VM window and operate Ubuntu</li>
<li>Install GIMP there and use it.</li>
</ol>
<p>The host OS (Windows) is totally unaware of what is being done inside VM (Ubuntu).</p>
<p><strong>Docker</strong></p>
<p>You use Wordpress.com and discovered that there is an open source version of it that you can run yourself, so you want to test it out on your own computer first. Now, setting up a Wordpress site has dependencies, that is, your system needs to have Apache, MySQL database and PHP installed.</p>
<p>Using Docker, here’s how the process will look like.</p>
<ol>
<li>Create a container using a <a href="https://hub.docker.com/_/wordpress">Wordpress image</a>. We’re able to jump directly to this step because the Wordpress image has already been packaged by the Docker community. It contains all the dependencies needed to run Wordpress.</li>
<li>Run Wordpress on your browser!</li>
</ol>
<p>In a nutshell, Docker containers support OS virtualization, and VM supports hardware virtualization.</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654229</guid>
            <pubDate>Thu, 01 Oct 2020 18:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Lessons I Needed to Learn First Hand (But Maybe You Don’t)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654192">thread link</a>) | @jlrubin
<br/>
October 1, 2020 | http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/ | <a href="https://web.archive.org/web/*/http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1586">
		<!-- .entry-header -->

	
	<div>
		
<p>When I stepped down as CEO in 2018, I wrote a post mortem and shared it privately with founder friends who directly asked <a rel="noreferrer noopener" href="http://www.nancyhua.com/2020/01/06/2019-2020-post-pre-mortems/" target="_blank">when I blogged here</a>. The company got acquired in 2019 and now I’m sharing the post mortem publicly because readers told me they saw novel concepts in my document they hadn’t heard elsewhere (as I write this I wonder if it’s because I was wrong. LMK!). </p>



<p>I used to abhor failure, but publicly releasing this post mortem no longer holds charge for me. Through Apptimize, I’ve learned and changed such that my subsequent companies will be very different. One of my biggest learnings is that I’d played a finite game and missed <a rel="noreferrer noopener" href="https://youtu.be/3QyurhNwk14?t=56" target="_blank">the infinite game</a>. I didn’t know those concepts at the time and saw “product innovation” as a separate category of work. After shifting my reference frame, I now know innovation as a sign of infinite game behavior. Anyway, I hope the below is useful to founders whose sales motions aren’t getting easier years into their venture backed company and want to consider frameworks for evaluating their position.&nbsp;</p>



<p>=================</p>



<p><strong>Startup Post Mortem, </strong>written Q3 2018</p>



<p>At times, the company we founded in 2013 seemed to be doing well by various objective metrics— we had a prestigious customers list ranging from CNN to Comcast, we raised 3 funding rounds summing to over $20MM in venture capital investment, and our revenue grew exponentially for the first few years (obviously easier to 3x when x is small). As the cofounder and CEO, I always bet on our ability to figure it out and be a financial success. I put in the first $50K and bought our domain for an additional $10K, which isn’t much money in the scheme of startup funding, but this was before we had users, before we’d gotten into Y Combinator, before it was anyone other than me and my cofounder. I used to be a trader, so I wasn’t goofing around— I fully expected to eventually make tons of money off our startup. I wrote a draft S-1 for how we would IPO, I didn’t pay myself for the first year, I was the lowest paid person in the company for years, and I guarded our equity like it was the blood of my children. I always wanted more equity because I valued it so highly. When founder friends told me to pay myself more, I asked for more equity instead. When we raised an oversubscribed Series B, founder friends told me to ask if I could sell some of my shares or take money off the table, but again I asked for more equity instead. Suggestions to get cash seemed ridiculous to me because I didn’t think I deserved cash yet; we weren’t a success and I, more than anyone, knew all our warts. When we were getting acquired, founder friends suggested I block the acquisition unless I made money off it, but that also sounded ridiculous to me because I felt I deserved money least of all. I’m sure my VC’s would’ve agreed.</p>



<p>Our company didn’t exit at anywhere near as well as I’d pitched, and I felt sad to fail after so many years of everyone working so hard. For years, we worked weekends and holidays, regularly in the office till 10pm. My VP of marketing was back at work weeks after birthing each of her babies, working through her pregnancies, and we forced anyone who entered my house or office to do user tests. Had it all been a waste? Should we have spent that time partying instead? Being successful is important to me and I felt ashamed my company wasn’t a financial success despite how hard everyone worked on it and how much money we raised. Sure, I could twist the story to make it sound like a success in terms of learning and building, and we made a product people used, and we got acquired, but the fact is that the company didn’t make money the way I’d imagined and pitched. I felt scared my investors would view me as a failure and dislike me or view me as incompetent. We should’ve done better— we had some of the smartest people you’d ever meet working on this problem that I convinced them was important enough to warrant their time and resources. How had I been so wrong about the financial outcome?&nbsp;</p>



<p><strong>Two Key Qualifying Questions:</strong></p>



<p>One of my investors put it well: everyone in a company is either a) making the product or b) selling the product. I learned there were 2 key questions that separated successful vs unsuccessful hires in our company:</p>



<ol><li>How hard is it to make this product?</li><li>How hard is it to sell this product?</li></ol>



<p>Our product was both hard to make and hard to sell. What do I mean by this and how does this impact the hiring profile?</p>



<p><strong>Product vs Sales Driven Company:</strong></p>



<p>On the spectrum of how hard it is to build a product, web forms are on the easier side. Easy products are anything that a person could do with a series of google docs and sheets, anything that you’re 100% sure is possible to make. On the harder side, there are products like a rocket or a flying car, where it’s &lt;100% guaranteed the engineering will get there in the time required. If the product is easy to build, then engineering is easier and it’s more on the sales and marketing teams to drive the company forward and show why your company is better even though others can make this commoditizable product (through network effect/ better land grab execution, brand/ trust, integrations/ partnerships, “thought leadership,” customer service/ support, etc).&nbsp;</p>



<p>In contrast, the harder a product is to build, the better engineers you need and the more everything depends on the product team shipping something 10x better.&nbsp;</p>



<p>Our product was nowhere as hard to build as a rocket, but it was harder than a webapp, and we made design choices that increased the difficulty of building and maintaining our product in exchange for gaining competitive advantage, which was high at one point but eroded. This means our company had to be product driven. But after the first few years, we failed to be product driven because 1) I struggled to hire product leadership that was technical enough and 2) I was short term focused on revenue goals. Single-threaded on sales, I didn’t focus on the product roadmap because all I cared about were short term goals to lead us to the next funding round because I was mainly driven by my fear of the startup failing versus any love for shipping a better product.&nbsp;</p>



<p><strong>Transactional vs. Consultative Sales:</strong></p>



<p>Everyone in B2B SaaS knows from SaaStr etc you’re supposed to distinguish between sales people who sold to technical vs non-technical teams, and differentiate sales candidates based on the price point they were comfortable selling at, but I learned an additional point of differentiation: how consultative must the sale be? On the spectrum of how hard it is to sell a product, widgets like video conferencing software are on the easier end, easy to explain and demo. On the harder end, there’s consulting services to suggest TBD process improvements. Even harder is stuff that’s a new category where you have to educate the buyer on the need. The hardest sales require founders to drive sales; the salesperson needs to be at least as smart as the buyer so they can credibly educate the buyer on how the product will urgently impact their revenue. Buyers of video conferencing software don’t expect to get promoted because they chose Zoom over Webex or talk about the impact of their choice at a conference, but buyers of analytics software do want to hear how they’re going to become Chief Product Officer vs VP, that they’re going to show their CEO a powerpoint with graphs clearly illustrating the revenue their analytics choices have created for their team, and how they’re going to speak at the conference on their data driven decision making processes.</p>



<p>If the product fulfills a clear, established need, you can hire a wider variety of salespeople. But when the product’s harder to sell, you need a “consultative” salesperson, a specific profile correlated but distinct from price point. When the product differences/ usage/ impact are hard to explain, or there’s no category yet, or it’s not a drastic, budgeted need, you need sales people who are like consultants, subject matter experts who are smarter than the buyers.&nbsp;</p>



<p>If the sales person is interested in presenting a custom, strategic overview of how our product impacts the buyer’s product strategy, they eventually want to become customer success managers. Other than our first business hire, who was more like a cofounder to me and eventually founded his own company, I couldn’t get anyone to do both sales and customer success at the same time. I think our deals weren’t big enough and our customer success process was in the awkward gap between easy and hard— not hard enough to warrant consulting services, but not easy enough to remain a yearly check-in to upgrade the account.&nbsp;</p>



<figure><img loading="lazy" width="1024" height="856" src="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png" alt="" srcset="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png 1024w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--400x334.png 400w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--768x642.png 768w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups-.png 1404w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption><em>Pros and cons of product vs. sales driven startups</em></figcaption></figure>



<p><strong>Fear/ Ego:</strong></p>



<p>Shifting gears from the tactical company building stuff to the touchy feely, the following section is philosophical.</p>



<p>It had started out really fun. In the 2nd year of the company, one executive told me that she got all her social fulfillment from our work. We were always together, working from my house on weekends, engineers sleeping over when they got tired, cooking together, talking about each other’s love languages, a group of friends going on an adventure together.&nbsp;</p>



<p>But now I see that I didn’t start the company with a pure heart. I started the company because I thought it’d be successful and I wanted to prove I could contribute something to the world, not because I specifically cared about our product or market, which I learned matters for me as time passes.&nbsp;</p>



<p>I thought I could get passionate about anything, and that was true at first, but it drained me to force myself to be an expert on our product for years because it wasn’t something I would’ve done if it weren’t for the company, the team, and my ego. For years, I always knew the most about our market and would send links to the rest of the team for news that had come out, anything they …</p></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</a></em></p>]]>
            </description>
            <link>http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654192</guid>
            <pubDate>Thu, 01 Oct 2020 18:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmers need to think like hackers]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24654136">thread link</a>) | @gexos
<br/>
October 1, 2020 | https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/ | <a href="https://web.archive.org/web/*/https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654136</guid>
            <pubDate>Thu, 01 Oct 2020 18:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Is Not Your Ideal]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24653013">thread link</a>) | @amortize
<br/>
October 1, 2020 | https://sujithjay.com/not-aws | <a href="https://web.archive.org/web/*/https://sujithjay.com/not-aws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span> 01 Oct 2020  • <span>
  
    
    
    <a href="https://sujithjay.com/tag/product"><code><nobr>PRODUCT</nobr></code>&nbsp;</a>
  
    
    
    <a href="https://sujithjay.com/tag/management"><code><nobr>MANAGEMENT</nobr></code>&nbsp;</a>
  
</span></span></p><p>Let me start with an assertion. Every platform engineering team <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> in every organisation aspires to be like AWS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>Every platform team wants to be like AWS, because like AWS, they provide infrastructure abstractions to users. AWS provides infrastructure via the abstractions of VMs and disks and write-capacity-units, while platform teams provide infrastructure using higher abstractions which solve service definitions, database or message queue provisioning, and service right-sizing <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This similarity prompts leaders of platform engineering teams to model their teams as agnostic providers of universal, non-leaky (within SLO bounds), self-served abstractions for their engineering organisation. Platform teams structured as such detached units struggle to define cohesive roadmaps which provide increasing value to business. But how does your platform differ from AWS?</p>

<h2 id="your-platform-vs-the-platform">Your Platform vs. The Platform</h2>

<h3 id="1-the-middle-ground">1. The Middle Ground</h3>
<p>As an agnostic service provider, AWS can afford to cater to median use-cases. The reason platform engineering teams exist is to bridge the gap between PaaS abstractions which work for the median use-case to your business’ specific use-cases. AWS can afford to target the median (economy of scale etc.), but you cannot.</p>

<p><img src="https://sujithjay.com/public/notaws/Median.jpeg" alt="AWS can afford to stay within a single σ. You cannot."></p>
<p><span> AWS can afford to stay within a single σ. You cannot.</span>
</p>

<p>Agnostic platform engineering teams which emulate AWS try to get away from this responsibility by proposing abstractions which target the median use-case. A tell-tale sign of this is when the lack in wide usability of internal abstractions is compensated for by extensive onboarding &amp; repeated training. This is also a side-effect of the relative valuation of engineering time vs. the time of another function <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<h3 id="2-follow-the-money">2. Follow the Money</h3>
<p>The dictum ‘follow the money’ works beautifully for customer-front products. When faced with a choice between two competing features to prioritise, a common tactical play is to make something which leads to more (immediate &amp; long-term) revenue. The proxy for increased revenue could be increased acquisition conversion, better retention or improved user experience – metrics which ensure increased revenue for the company over time. In short, revenue growth is the north star <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>Not so much in platform engineering. There is no revenue since your customers are internal, captive ones. Captive audiences are forced to use a solution by the force of dictum and lack of choice. The metrics used in platform products are proxies for usability and user satisfaction – but there are no foolproof ways to measure it for captive audiences. For captive audiences, solutions can not compete and better solutions cannot win. Like a command economy, platform products are designed rather than evolved. Design takes priority over market economy. So why is design bad?</p>

<h2 id="bad-design">Bad Design</h2>
<p>For design to work, there has to be an objective function against which we can design. A specification is an objective function against which engineering teams design a solution. Since we do not have reliable metrics <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> to rely on for platform engineering, how do we come up with specifications? And without rigorous specifications, new features created by the platform run a high risk of not solving worthwhile problems for the users.The current accepted methodology among platform engineering leaders to solve this paucity of specifications is to rely on user-interviews. This is, as mentioned before, an unreliable source since captive users do not have the best view of the ideal state of tooling and abstractions that could be available to them.</p>

<p>The only way to flip this situation is to let go of command-economy-style designed abstractions, and to let your platform self-organise along the principle of markets. How does that look in practice?</p>

<h3 id="1-market-ftw">1. Market, FTW</h3>
<p>Camille Fournier mentions in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> how her team partners with customer teams to develop prototypes for specific problems. These specific solutions are later honed and iterated on to become general solutions provided by your team. I would go a step further on this route, where possible. Partner to prototype with multiple teams facing related problems to develop multiple specific solutions. These specific solutions can be seen as competing candidates to solve a general problem. Bring in user-interviews at this point to gauge pain-points, and iterate individually on these specific solutions. This switches the economy of your team to a self-organised market. Once considerable thought and iteration has gone into each solution, it is time to assimilate. Assimilate the best solution(s) while migrating the rest to the chosen solution. As emphasised in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a>, an early investment of time into migration strategies is essential for such a scheme to sustain.</p>

<p>In platforms designed with experimentation, you will find that innovation continues to thrive at the edges of the platform’s domain while the stable core of the platform is subject to periodic rework or maintenance. The use-cases a platform supports grows in a controlled manner to address an ever-growing percent of the consumers, and does not stagnate after addressing just the median users.</p>

<h3 id="2-overloaded-use-cases">2. Overloaded Use-cases</h3>
<p>Although agnostic platform engineering teams might only be catering to very specific median use-cases, the customer teams with specific needs cannot afford to be blocked and they cannot stop delivering their deliverables. These teams sometimes create their own solutions, and in such cases the above strategy of assimilation works wonders. You get a prototype for free on which the team can iterate on. However, this scenario is rarer in cases where it requires specific skills to build such solutions, such as in data platforms. One common pattern in such knowledge-constricted situations is that users find ways to overload the existing solutions with minor tweaks to fit their use-case. Look out for such overloaded use-cases within your platform, for they are excellent guides to unmet needs of the users. You can leverage them to advocate for newer features to explicitly support those use-cases.</p>

<h3 id="3-listen-to-them-only-at-the-start">3. Listen To Them (Only At The Start!)</h3>
<p>As a parting note, I will take a jab at user-interviews again. The above tactics work when you are trying to scale your platform from 1 to N. When taking a platform from 0 to 1, the only solution to creating specifications is to listen to the users. Give them exactly what they want. Listen to their exact demands. A propensity of platform product managers is to rely on this excessively at a much later stage in the product’s lifecycle. User-interviews have their place in evolving products, but the over-reliance on the methodology is a bane to platform product management.</p>

<p><strong>P.S.</strong> As I read back the above essay, the heavy influence of <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> is clear. I would like to say that was the intention: to reassert the ideas in it which resounded with me, while stating a few of my own.</p>

<h3 id="footnotes">Footnotes</h3>


  </div>









      </div></div>]]>
            </description>
            <link>https://sujithjay.com/not-aws</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653013</guid>
            <pubDate>Thu, 01 Oct 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Let expressions]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24652842">thread link</a>) | @todsacerdoti
<br/>
October 1, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-7/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">previous</a></em></p>

<p>Welcome back to the “Compiling a Lisp” series. Last time we added a reader
(also known as a parser) to our compiler. This time we’re going to compile a
new form: <em>let</em> expressions.</p>

<p>Let expressions are a way to bind variables to values in a particular scope.
For example:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>)</span> <span>(</span><span>b</span> <span>2</span><span>))</span>
  <span>(</span><span>+</span> <span>a</span> <span>b</span><span>))</span>
</code></pre></div></div>

<p>Binds <code>a</code> to <code>1</code> and <code>b</code> to <code>2</code>, but only for the body of the <code>let</code> — the
rest of the S-expression — and then executes the body.</p>

<p>This is similar in C to opening a new block:</p>

<div><div><pre><code><span>int</span> <span>result</span><span>;</span>
<span>{</span>
  <span>int</span> <span>a</span> <span>=</span> <span>1</span><span>;</span>
  <span>int</span> <span>b</span> <span>=</span> <span>2</span><span>;</span>
  <span>result</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>but it’s a little different because C has a divide between <em>statements</em> and
<em>expressions</em>, whereas Lisp does not.</p>

<p>It’s <em>also</em> different because let-expressions do not make previous binding
names available to expressions being bound. For example, the following program
should fail because it cannot find the name <code>a</code>:</p>



<p>There is a form that makes bindings available serially, but that is called
<code>let*</code> and we are not implementing that today.</p>

<p>For completeness’ sake, there is also <code>let rec</code>, which makes names available
serially and also within the same binding. This is useful for binding recursive
or mutually recursive functions. Again, we are not implementing that today.</p>

<h3 id="name-binding-implementation-strategy">Name binding implementation strategy</h3>

<p>You’ll notice two new things about let expressions:</p>

<ol>
  <li>They introduce ways to bind names to values, something we have to figure out
how to keep track of</li>
  <li>In order to use those names we have to figure out how to look up what the
name means</li>
</ol>

<p>In more technical terms, we have to add <em>environments</em> to our compiler. We can
then use those environments to map <em>names</em> to <em>stack locations</em>.</p>

<p>“Environment” is just a fancy word for “look-up table”. In order to implement
this table, we’re going to make an <em>association list</em>.</p>

<p>An <em>association list</em> is a list of <code>(key value)</code> pairs. Adding a pair means
tacking it on at the end (or beginning) of the list. Searching through the
table involves a linear scan, checking if keys match.</p>

<blockquote>
  <p>You may be wondering why we’re using this data structure to implement
environments. Didn’t I even take a data structures course in college?
Shouldn’t I know that <em>linear</em> equals <em>slow</em> and that I should <em>obviously</em>
use a hash table?</p>

  <p>Well, hash tables have costs too. They are hard to implement right; they have
high overhead despite being technically constant time; they incur higher
space cost per entry.</p>

  <p>For a compiler as small as this, a tuned hash table could easily be as long
as the rest of the compiler. Since we’re also compiling small <em>programs</em>,
we’ll worry about time complexity later. It is only an implementation detail.</p>
</blockquote>

<p>In order to do this, we’ll first draw up an association list. We’ll use a
linked list, just like cons cells:</p>

<div><div><pre><code><span>// Env</span>

<span>typedef</span> <span>struct</span> <span>Env</span> <span>{</span>
  <span>const</span> <span>char</span> <span>*</span><span>name</span><span>;</span>
  <span>word</span> <span>value</span><span>;</span>
  <span>struct</span> <span>Env</span> <span>*</span><span>prev</span><span>;</span>
<span>}</span> <span>Env</span><span>;</span>
</code></pre></div></div>

<p>I’ve done the usual thing and overloaded <code>Env</code> to mean both “a node in the
environment” and “a whole environment”. While one little <code>Env</code> struct only
holds a one name and one value, it also points to the rest of them, eventually
ending with <code>NULL</code>.</p>

<p>This <code>Env</code> will map names (symbols) to <em>stack offsets</em>. This is because we’re
going to continue our strategy of <em>not doing register allocation</em>.</p>

<p>To manipulate this data structure, we will also have two functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>);</span>
<span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>);</span>
</code></pre></div></div>

<p><code>Env_bind</code> creates a new node from the given name and value, borrowing a
reference to the name, and prepends it to <code>prev</code>. Instead of returning an
<code>Env*</code>, it returns a whole struct. We’ll learn more about why later, but the
“TL;DR” is that I think it requires less manual cleanup.</p>

<p><code>Env_find</code> takes an <code>Env*</code> and searches through the linked list for a <code>name</code>
matching the given <code>key</code>. If it finds a match, it returns <code>true</code> and stores the
<code>value</code> in <code>*result</code>. Otherwise, it returns <code>false</code>.</p>

<p>We can stop at the first match because Lisp allows name <em>shadowing</em>. Shadowing
occurs when a binding at a inner scope has the same name as a binding at an
outer scope. The inner binding takes precedence:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>))</span>
  <span>(</span><span>let</span> <span>((</span><span>a</span> <span>2</span><span>))</span>
    <span>a</span><span>))</span>
<span>; =&gt; 2</span>
</code></pre></div></div>

<p>Let’s learn about how these functions are implemented.</p>

<h3 id="name-binding-implementation">Name binding implementation</h3>

<p><code>Env_bind</code> is a little silly looking, but it’s equivalent to prepending a
node onto a chain of linked-list nodes. It returns a struct <code>Env</code> containing
the parameters passed to the function. I opted <em>not</em> to return a heap pointer
(allocated with <code>malloc</code>, etc) so that this can be easily stored in a
stack-allocated variable.</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span><span>Env</span><span>){.</span><span>name</span> <span>=</span> <span>name</span><span>,</span> <span>.</span><span>value</span> <span>=</span> <span>value</span><span>,</span> <span>.</span><span>prev</span> <span>=</span> <span>prev</span><span>};</span>
<span>}</span>
</code></pre></div></div>

<p><em>Note</em> that we’re <strong>pre</strong>pending, not <strong>ap</strong>pending, so that names we add deeper
in a let chain shadow names from outside.</p>

<p><code>Env_find</code> does a recursive linear search through the linked list nodes. It may
look familiar to you if you’ve already written such a function in your life.</p>

<div><div><pre><code><span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>env</span> <span>==</span> <span>NULL</span><span>)</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>env</span><span>-&gt;</span><span>name</span><span>,</span> <span>key</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
    <span>*</span><span>result</span> <span>=</span> <span>env</span><span>-&gt;</span><span>value</span><span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>Env_find</span><span>(</span><span>env</span><span>-&gt;</span><span>prev</span><span>,</span> <span>key</span><span>,</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We search for the node with the string <code>key</code> and return the stack offset associated
with it.</p>

<p>Alright, now we’ve got names and data structures. Let’s implement some name
resolution and name binding.</p>

<h3 id="compiling-name-resolution">Compiling name resolution</h3>

<p>Up until now, <code>Compile_expr</code> could only compile integers, characters, booleans,
<code>nil</code>, and some primitive call expressions (via <code>Compile_call</code>). Now we’re
going to add a new case: symbols.</p>

<p>When a symbol is compiled, the compiler will look up its stack offset in the
current environment and emit a load. This opcode, <code>Emit_load_reg_indirect</code>, is
very similar to <code>Emit_add_reg_indirect</code> that we implemented for primitive
binary functions.</p>

<div><div><pre><code><span>int</span> <span>Compile_expr</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>,</span> <span>word</span> <span>stack_index</span><span>,</span>
                 <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>node</span><span>))</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>symbol</span> <span>=</span> <span>AST_symbol_cstr</span><span>(</span><span>node</span><span>);</span>
    <span>word</span> <span>value</span><span>;</span>
    <span>if</span> <span>(</span><span>Env_find</span><span>(</span><span>varenv</span><span>,</span> <span>symbol</span><span>,</span> <span>&amp;</span><span>value</span><span>))</span> <span>{</span>
      <span>Emit_load_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>kRax</span><span>,</span> <span>/*src=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>value</span><span>));</span>
      <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>-</span><span>1</span><span>;</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected node type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If the variable is not in the environment, this is a compiler error and we
return <code>-1</code> to signal that. This is not a tremendously helpful signal. Maybe
soon we will add more helpful error messages.</p>

<p>Ah, yes, <code>varenv</code>. You will, like I had to, go and add an <code>Env*</code> parameter to
all relevant <code>Compile_XYZ</code> functions and then plumb it through the recursive
calls. Have fun!</p>

<h3 id="compiling-let-finally">Compiling let, finally</h3>

<p>Now that we can resolve the names, let’s go ahead and compile the expressions
that bind them.</p>

<p>We’ll have to add a case in <code>Compile_expr</code>. We could add it in the body of
<code>Compile_expr</code> itself, but there is some helpful setup in <code>Compile_call</code>
already. It’s a bit of a misnomer, since it’s not a call, but oh well.</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>,</span>
                 <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"let"</span><span>))</span> <span>{</span>
      <span>return</span> <span>Compile_let</span><span>(</span><span>buf</span><span>,</span> <span>/*bindings=*/</span><span>operand1</span><span>(</span><span>args</span><span>),</span>
                         <span>/*body=*/</span><span>operand2</span><span>(</span><span>args</span><span>),</span> <span>stack_index</span><span>,</span>
                         <span>/*binding_env=*/</span><span>varenv</span><span>,</span>
                         <span>/*body_env=*/</span><span>varenv</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected call type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We have two cases to handle: no bindings and some bindings. We’ll tackle these
recursively, with no bindings being the base case. For that reason, I added a
helper function <code>Compile_let</code>.</p>

<p>As with all of the other compiler functions, we pass it an machine code buffer,
a stack index, and an environment. Unlike other functions, we passed it two
expressions and two environments.</p>

<p>I split up the bindings and the body so we can more easily recurse on the
bindings as we go through them. When we get to the end (the base case), the
bindings will be <code>nil</code> and we can just compile the <code>body</code>.</p>

<p>We have two environments for the reason I mentioned above: when we’re
evaluating the expressions that we’re binding the names to, we can’t add
bindings iteratively. We have to evaluate them in the parent environment. It’ll
be come clearer in a moment how that works.</p>

<p>We’ll tackle the simple case first — no bindings:</p>

<div><div><pre><code><span>int</span> <span>Compile_let</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>binding_env</span><span>,</span> <span>Env</span> <span>*</span><span>body_env</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>));</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>In that case, we compile the body using the <code>body_env</code> as the environment. This
is the environment that we will have added all of the bindings to.</p>

<p>In the case where we <em>do</em> have bindings, we can take the first one off and pull
it apart:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_expr</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Once we have the <code>binding_expr</code>, we should compile it. The result will end up
in <code>rax</code>, per our internal compiler convention. We’ll then store it in the next
available stack location:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Compile the binding expression</span>
  <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>binding_expr</span><span>,</span> <span>stack_index</span><span>,</span> <span>binding_env</span><span>));</span>
  <span>Emit_store_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>stack_index</span><span>),</span>
                          <span>/*src=*/</span><span>kRax</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>We’re compiling this binding expression in <code>binding_env</code>, the parent
environment, because we don’t want the previous bindings to be visible.</p>

<p>Once we’ve generated code to store it on the stack, we should register that
stack location with the binding name in the environment:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Bind the name</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Note that we’re binding it in the <code>body_env</code> because we want this to be
available to the body, but not the other bindings.</p>

<p>At this point we’ve done all the work required for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-7/">https://bernsteinbear.com/blog/compiling-a-lisp-7/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652842</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Data Science Pull Requests– Review and merge code, data and experiments]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24652832">thread link</a>) | @Dean-DAGsHub
<br/>
October 1, 2020 | https://dagshub.com/blog/data-science-pull-requests/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/data-science-pull-requests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <h3 id="a-step-forward-for-mlops-and-unlocking-open-source-data-science">A step forward for MLOps and unlocking Open Source Data Science</h3><p>Today, we're releasing Data Science Pull Requests (DS PRs), which are Pull Requests (PRs), re-imagined for the data science (DS) workflow. This new capability unlocks a standard review process for data science teams, enabling them to merge data across different branches and accept data contributions across forks. This provides a better collaborative experience for teams in data science organizations and enables truly Open Source Data Science (OSDS) projects. </p><p>For more details, read on...</p><h2 id="introduction">Introduction</h2><p>When we started DAGsHub, we were focused on making data science collaboration possible. Specifically, we deeply <em>care</em> and <em>rely on</em> Open Source Software (OSS), and we set out on a mission to make OSDS as accessible and prevalent as OSS is today.</p><p>This meant that we were concerned about <strong><em>discoverability </em></strong>of data science projects and experiments to work on, <strong><em>understandability</em></strong> of the context of an experiment, <strong><em>reproducibility</em> of </strong>its results, and finally, <strong><em>contributability</em></strong> of code-, data- and models- changed back to the original project.</p><p>When reviewing these processes and the existing solutions some things become clear:</p><ul><li><em><strong>Discoverability </strong></em>means being able to answer the question "<em>What should I do next?</em>" – finding a project to work on, and within that project finding what experiments might be interesting or important. <br>It is solved mainly by <strong>experiment tracking</strong> systems, many of them using proprietary or black box formats that are hard to understand and migrate to/from.<p>DAGsHub goes beyond this by creating an experiment tracking system that relies on simple open formats (<code>YAML</code> and <code>CSV</code>). This means you don't need to add obscure lines of code – everything works by automatically scanning and analyzing the git commits pushed into the platform.</p></li><li><em><strong>Understandability</strong></em> means being able to answer the question "<em>How should I do what I want to do?</em>" – this usually consists of reviewing why, how, and what was already done in a project or experiment. The solution for this step is mostly manual and relies on self-documenting one's work and discussions with collaborators.<p>DAGsHub improves on this by providing a convenient interface into projects' code, data, models, and pipelines which give users a window into their projects' components, and how they interact with each other.</p></li><li><em><strong>Reproducibility</strong></em> means setting up an exact copy of the experiment you want to work on. Many times this process is reduced to a Git commit and the experiment parameters (logged in the experiment tracking system). However, the true standard for reproducibility involves <em><strong>easily </strong></em>retrieving the same version of data, models, and other artifacts. It is best solved by using Git with some dedicated data versioning solution.<p>DAGsHub solves this by relying on open source tools such as Git and DVC to provide the standard discussed above – a complete copy of your project (code, data, models, parameters, and other artifacts) with one (or two) commands.</p></li><li><em><strong>Contributability</strong></em> means that you can take a new experiment or result, and incorporate them back into the project you started from so that you don't need to maintain your result separately. Today, this is entirely manual, full of friction, and fundamentally <strong>non-existent</strong>.</li></ul><p>We have many more things to build, but it was clear that one aspect needed to be covered first – a <strong><em>CONTRIBUTION </em></strong>mechanism.</p><h2 id="contributing-data-science-pull-requests">Contributing – Data Science Pull Requests</h2><p>The final step of the collaborative process is arguably the most important one. Without it, the workflow is one-sided, a monologue, which means collaboration isn't happening. Practically, <strong><em>Contributing</em></strong> can be broken down into two tasks - <strong>reviewing</strong> and <strong>merging </strong>contributions.</p><p>In software, both reviewing and merging are a part of the <strong>pull request</strong> process, but their focus was solely on code. </p><blockquote>Data Science Pull Requests let you <strong>review experiments<u>,</u></strong> <strong>code, data, models, </strong>and your<strong> pipelines</strong>, and <strong><u>merge changes to all of them automatically.</u></strong> </blockquote><h3 id="data-science-review">Data Science Review</h3><p>If you've ever worked on a data science project with other people or tried reviewing someone else's data science work, you know how hard it is to get the information you need to understand someone else's work, or explain your own, so that the review process is meaningful. The process is slow and manual because systems are not built for review.</p><p>An automatic review process means changes and updates can be discussed and integrated faster into your project.<strong> You need to quickly see what has changed, discuss it, in context, and decide how to move forward.</strong></p><p>What this means in practice:</p><ul><li>Commenting on experiments, in context – you can look at the new experiments that are being contributed as part of the DS PR, and compare them to the base experiment in the original project. See all the visualization and information, and add comments on these within the PR discussion with links to the relevant comparison/visualization.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/exp-comment-long-hq.gif" alt="Commenting on experiments"><figcaption>Commenting on experiments in DS PRs</figcaption></figure><ul><li>See what data and models have changed (not just code) – view what data, model, and artifact files were added, removed, or modified. This means you can easily pinpoint changes and focus the discussion on what's important.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png" alt="Viewing data changes in a DAGsHub project" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1189w" sizes="(min-width: 720px) 720px"><figcaption>Data Comparison Example</figcaption></figure><ul><li>Compare and diff notebooks side-by-side – notebooks are an important part of many data science projects. However, for a very long time, they haven't received adequate treatment in the review process, relying on diffs to the raw <code>JSON</code> file, which were mostly unreadable. You can now review the changes in an intuitive UI as part of the DS PR. Another benefit of this is that if you require a special visualization, you can commit a notebook with that visualization, and view the changes conveniently.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png" alt="Notebook comparison" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 2298w" sizes="(min-width: 720px) 720px"><figcaption>Notebook Diffing Example</figcaption></figure><p>After reviewing a collaborator's work, we need a way to incorporate those changes, automatically. That's why we built data science merging.</p><h3 id="data-science-merging">Data Science Merging</h3><p>Merging code is possible with Git, but as we already discussed, that is not the full picture for data science projects. With DS PRs, you can merge your data and other artifacts as well. </p><h4 id="data-merging">Data Merging</h4><p>Everyone knows about bugs in code, but you might also have data bugs that you're not aware of. Examples include data that is not up to date, biased, or mislabeled. Assuming you found out about such a bug and you wanted to fix it – that would usually mean you need to agree on and perform some manual operation to update or add new data. With data merging, once you accept a DS PR, the new data would automatically be copied into your project in an entirely automatic process.</p><h4 id="artifact-merging">Artifact Merging</h4><p>This doesn't end with just the <em>raw data – </em>data merging lets you merge models and any other artifact of your data pipeline (e.g. preprocessed data or 3d models). Take a case where one of the steps in a pipeline takes 2 weeks to run and results in some trained model or a processed dataset. If only raw data was merged, you'd have to run that excruciating 2-week process again. Artifact merging means that after a DS PR is merged, the resulting project is as reproducible as the original contribution.</p><p>After accepting a DS PR you are in the same state of your DS project, as you would after accepting a PR in a software project.</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png" alt="Data Merging on DAGsHub" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1846w" sizes="(min-width: 720px) 720px"><figcaption>Data Science Merging – Note that 171 MB of data will be copied on accepting this DS PR</figcaption></figure><p>Data merging means you can accept data and models from contributors with ease, without giving each one full access to your data storage. This can reduce friction and speed up team efforts.</p><p>This last capability is especially useful for OSDS.</p><h2 id="what-does-this-mean-for-osds">What does this mean for OSDS?</h2><p><a href="https://dagshub.com/blog/a-case-for-open-source-data-science/">Open Source Data Science (OSDS) has the potential to have a similar effect on the world</a>, as Open Source Software (OSS) had. It is DAGsHub's stated goal to promote OSDS and build the technology to make it as easy as possible. OSDS must come first, and industry workflows will mirror those in OSDS projects, as they have for OSS. </p><p>But let's face it – OSDS doesn't <em>really</em> exist yet. If you maintain some OSDS project and you want to accept contributions from people (like you would for OSS) – you have to do it entirely manually or <strong>resort to accepting only code changes</strong> (no way to accept data bug fixes – and we all know there are plenty).</p><p>From the individual contributor side, if you want to improve your ML portfolio by contributing to some OSDS project, you're also stuck. You have to either fork the project and not contribute your changes (which means their quality is never reviewed – you don't learn as much) or go through a painstaking manual effort<sup>[1]</sup>.</p><blockquote>DS PRs make OSDS possible by providing a standard interface and workflow to review and accept contributions from anyone, anywhere, and for any type of data science component.</blockquote><p><strong>We'd love to support open source data science projects that want to accept data science contributions from the community. Please reach out to us at <a href="mailto:osds@dagshub.com">osds@dagshub.com</a> if this is relevant for you.</strong></p><h2 id="thank-you-">Thank You!</h2><p>Thank you to all the people that gave us feedback before and while we were building DS PRs. We'd love to get your feedback as well on how DS PRs could be improved for the community – the best way to do this is to join our <a href="https://discord.com/invite/9gU36Y6">Discord channel</a>. Looking forward to hearing your thoughts and seeing what people build with open source data science.</p><hr><!--kg-card-begin: markdown--><p>
[1] Kaggle is worth a mention here – It is a common way to show some of your DS chops. However, it's competitive (as opposed to collaborative). Furthermore, data science projects in the wild rarely have one all-encompassing metric to optimize at the expense of everything else - 80% of the work is just gathering data and deciding what is even worth optimizing! 
Our goal with DAGsHub is to enable a collaborative way to showcase your capabilities while encouraging interoperability – i.e. working together rather than everyone doing their own thing and ending up with a ton of fragmentation.
</p><!--kg-card-end: markdown-->
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science/" title="Data Science">Data Science</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science-workflow/" title="Data Science Workflow">Data Science Workflow</a>
                      </li>
                      <li>
               …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/data-science-pull-requests/">https://dagshub.com/blog/data-science-pull-requests/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/data-science-pull-requests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652832</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at PostGIS vs. Geocoder in Rails]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652608">thread link</a>) | @leighhalliday
<br/>
October 1, 2020 | https://pganalyze.com/blog/postgis-rails-geocoder | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgis-rails-geocoder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
This article sets out to compare PostGIS in Rails with Geocoder and to highlight a couple of the areas where you'll want to (or need to) reach for one over the other. I will also present some of the terminology and libraries that I found along the way of working on this project and article as I set out to understand PostGIS better and how it is integrated with Rails.</p>

<p><span>
      <span></span>
  <img alt="PostGIS vs. Geocoder in Rails" title="PostGIS vs. Geocoder in Rails" src="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg" srcset="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e52aa/postgis_rails_geocoder_pganalyze.jpg 175w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/70ebb/postgis_rails_geocoder_pganalyze.jpg 350w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg 700w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/9ecec/postgis_rails_geocoder_pganalyze.jpg 1050w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e5166/postgis_rails_geocoder_pganalyze.jpg 1200w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span>
Picture via <a href="https://unsplash.com/@anniespratt">Annie Spratt</a> on Unsplash</p>
<p>I have built a number of Rails applications over the years that show locations on a map, have nearby search functionality, and I had never used <a href="https://postgis.net/">PostGIS</a> before! How was this possible? The reason is that there is a Ruby gem named <a href="https://github.com/alexreisner/geocoder">Geocoder</a> which enables you to do these sorts of queries, and it's quite efficient! That said, there is a reason that PostGIS exists. For more complex geo queries I’d recommend reaching beyond Geocoder to PostGIS.</p>
<p>As an example, if you wanted to find homes which have a school within 1km of them, or if you wanted to draw an oddly shaped polygon on a map and search within it, this is the world where PostGIS shines and makes these complex geo queries possible.</p>
<p>In this article we will be covering:</p>
<ul>
<li>PostGIS in Rails setup</li>
<li>Finding nearby records (Geocoder + PostGIS)</li>
<li>Finding records within a bounding box (Geocoder + PostGIS)</li>
<li>Finding records within a polygon (PostGIS)</li>
<li>Finding nearby related records (PostGIS)</li>
</ul>
<p>The source code referenced in this article can be <a href="https://github.com/pganalyze-resources/rails-postgis-demo">found here</a>.</p>
<h2 id="installing-postgis"><a href="#installing-postgis" aria-label="installing postgis permalink"></a>Installing PostGIS</h2>
<p>Postgres comes with a number of built-in extensions that you can enable, but unfortunately PostGIS (Spatial and Geographic objects for Postgres) isn't one of them. In order to enable this extension, you will have to use a Postgres install with PostGIS support. I recommend using the <a href="https://registry.hub.docker.com/r/postgis/postgis">official postgis docker image</a>, but luckily many hosted Postgres solutions come with PostGIS already available. If you are not sure, you can query the available extensions with the following query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span>
<span>from</span> pg_available_extensions
<span>where</span> name <span>like</span> <span>'%postgis%'</span></code></pre></div>
<p>If you'd like to see if the extension is <em>already</em> enabled, you can run this query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> pg_extension</code></pre></div>
<p>And finally, to enable this extension, you can use the command <code>create extension postgis</code>, but since we're working within Rails, there is a Gem that will take care of this step for us as we'll see below.</p>
<h2 id="activerecord-postgis-adapter"><a href="#activerecord-postgis-adapter" aria-label="activerecord postgis adapter permalink"></a>ActiveRecord PostGIS Adapter</h2>
<p>If you have confirmed that your version of Postgres supports the <code>postgis</code> extension, you're ready to integrate it with your Rails application. This can be done by using the <a href="https://github.com/rgeo/activerecord-postgis-adapter">activerecord-postgis-adapter</a> gem. Two things need to be done to get up and running. The first is to update the <code>adapter</code> within <code>config/database.yml</code> to be set to <code>postgis</code>. Next, if this is a new application, you can run <code>rails db:create</code> as normal, but if it is an existing one, you'll have to run the command <code>rake db:gis:setup</code>. This command is enabling the postgis extension in your database.</p>
<h2 id="our-example-data"><a href="#our-example-data" aria-label="our example data permalink"></a>Our Example Data</h2>
<p>We'll be working with sample data for a realtor website that allows us to find homes in a variety of ways, including homes that are nearby a local school. There are two models: <code>homes</code> and <code>schools</code>. The Rails migration to create these tables is below:</p>
<div data-language="ruby"><pre><code><span>class</span> <span>CreateHomes</span> <span>&lt;</span> <span>ActiveRecord</span><span>:</span><span>:</span><span>Migration</span><span>[</span><span>6.0</span><span>]</span>
  <span>def</span> <span><span>change</span></span>
    create_table <span>:homes</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>string <span>:name</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>string <span>:status</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>bigint <span>:price</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>integer <span>:beds</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>integer <span>:baths</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>
      t<span>.</span>float <span>:longitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>float <span>:latitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>timestamps

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>index <span>%i[latitude longitude]</span>
      t<span>.</span>index <span>:status</span>
      t<span>.</span>index <span>:price</span>
    <span>end</span>

    create_table <span>:schools</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>timestamps
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>By using <code>activerecord-postgis-adapter</code> we are able to define PostGIS columns within our migration file. When working with PostGIS you can store a point (latitude + longitude) as a single column of type <code>ts_point</code>, whereas when working with <a href="https://github.com/alexreisner/geocoder">Geocoder</a> the latitude and longitude are stored as floats in separate columns. Because we are comparing the two approaches, we will store the data both ways, but typically you would choose one approach or the other.</p>
<p>PostGIS <strong>geographic</strong> columns can be indexed using <a href="https://www.postgresql.org/docs/current/gist-intro.html">GiST</a> style indexes. GiST indexes are required over B-Tree indexes when working with geographic data because coordinates cannot be easily sorted along a single axis (such as numbers, letters, dates, etc...) in a way that would allow the database to speed up common geographic operations.</p>
<p>The example project for this article contains a seeds file (run with <code>rake db:seed</code>) which will generate 100k homes and 100 schools in and around the Atlanta, Georgia area.</p>
<h2 id="building-a-geo-helper-class-with-postgis"><a href="#building-a-geo-helper-class-with-postgis" aria-label="building a geo helper class with postgis permalink"></a>Building a Geo Helper Class with PostGIS</h2>
<p>The Rails PostGIS adapter is based on a library named <a href="https://github.com/rgeo/rgeo">RGeo</a>, which while incredibly powerful, I found a little bit confusing due to a lack of documentation. I ended up building a small helper class to generate different geo objects for me. The first thing to point out is what <a href="https://en.wikipedia.org/wiki/Spatial_reference_system">SRID</a> is. Just like the imperial and metric systems are used to measure and weigh amounts using an agreed upon reference point, coordinates also need a coordinate reference system to ensure that the latitude and longitude that one uses means the same thing to different people when referring to a single place on earth. <a href="https://spatialreference.org/ref/epsg/wgs-84/">4326</a> is the spatial system used for GPS satellite navigation systems and the one we will be using within this article.</p>
<p>One last thing to define is what <a href="https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry">WKT</a> is. Well-known Text representation of geometry is a string representation of a point, line string, and polygon (among other things) that we will be using in our examples in this article. This is the format Postgres (PostGIS) receives and displays geographic data types in.</p>
<div data-language="ruby"><pre><code><span>class</span> <span>Geo</span>
  <span>SRID</span> <span>=</span> <span>4326</span>

  <span>def</span> <span><span>self</span><span>.</span><span>factory</span></span>
    <span>@@factory</span> <span>||</span><span>=</span> <span>RGeo</span><span>:</span><span>:</span><span>Geographic</span><span>.</span>spherical_factory<span>(</span>srid<span>:</span> <span>SRID</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>pairs_to_points</span></span><span>(</span>pairs<span>)</span>
    pairs<span>.</span>map <span>{</span> <span>|</span>pair<span>|</span> point<span>(</span>pair<span>[</span><span>0</span><span>]</span><span>,</span> pair<span>[</span><span>1</span><span>]</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>point</span></span><span>(</span>longitude<span>,</span> latitude<span>)</span>
    factory<span>.</span>point<span>(</span>longitude<span>,</span> latitude<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>line_string</span></span><span>(</span>points<span>)</span>
    factory<span>.</span>line_string<span>(</span>points<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>polygon</span></span><span>(</span>points<span>)</span>
    line <span>=</span> line_string<span>(</span>points<span>)</span>
    factory<span>.</span>polygon<span>(</span>line<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>to_wkt</span></span><span>(</span>feature<span>)</span>
    <span>"srid=<span><span>#{</span><span>SRID</span><span>}</span></span>;<span><span>#{</span>feature<span>}</span></span>"</span>
  <span>end</span>
<span>end</span></code></pre></div>
<h2 id="finding-nearby-records-with-postgis-and-geocoder"><a href="#finding-nearby-records-with-postgis-and-geocoder" aria-label="finding nearby records with postgis and geocoder permalink"></a>Finding Nearby Records with PostGIS and Geocoder</h2>
<p>One of the most common geo queries used in applications is to find all records within X distance from a known point (the user's location, an event, a search, etc...). Because we installed <code>Geocoder</code> and added <code>reverse_geocoded_by :latitude, :longitude</code> to our <code>Home</code> class, we can use the <code>nearby</code> method to find all homes within 5km of this latitude and longitude (which happens to be Atlanta, Georgia). Geocoder likes to have arrays with latitude and then longitude, as opposed to PostGIS which <strong>prefers the exact opposite</strong> order!</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>near<span>(</span><span>[</span><span>33.753746</span><span>,</span> <span>-</span><span>84.386330</span><span>]</span><span>,</span> <span>5</span><span>)</span><span>.</span>count<span>(</span><span>:all</span><span>)</span> </code></pre></div>
<p>This query ran in about 5ms on my computer (searching through 100k records)... pretty fast! The reason it is fast is because we added an index on the latitude and longitude fields, but also because Geocoder applies a bounding box filter which utilises the index. Remember the Spatial Reference System (SRID) that we mentioned above? Because our coordinates do not take place on a <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian plane</a>, we can’t use a standard distance formula to calculate the <a href="https://www.mathsisfun.com/algebra/distance-2-points.html">distance between two points</a>. Although we won’t venture further into the math of this query below, it takes into consideration the Earth’s spherical nature when calculating the distance between two coordinates as specified by latitude and longitude. <a href="https://www.movable-type.co.uk/scripts/latlong.html">This article</a> dives into more detail on these calculations if you are interested.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.708779919704064</span> <span>AND</span> <span>33.798712080295935</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.44041260768655</span> <span>AND</span> <span>-</span><span>84.33224739231345</span> <span>AND</span> <span>(</span><span>6371.0</span> <span>*</span> <span>2</span> <span>*</span> ASIN<span>(</span>SQRT<span>(</span>POWER<span>(</span>SIN<span>(</span><span>(</span><span>33.753746</span> <span>-</span> homes<span>.</span>latitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span> <span>+</span> COS<span>(</span><span>33.753746</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> COS<span>(</span>homes<span>.</span>latitude <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> POWER<span>(</span>SIN<span>(</span><span>(</span><span>-</span><span>84.38633</span> <span>-</span> homes<span>.</span>longitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>)</span><span>)</span> <span>BETWEEN</span> <span>0.0</span> <span>AND</span> <span>5</span><span>)</span></code></pre></div>
<p>We'll have to build our own <code>near</code> query when working with PostGIS, but don't worry, it's pretty straight forward! The <code>g_near</code> method lives within the <code>Home</code> model, and takes advantage of the <a href="https://postgis.net/docs/ST_DWithin.html">ST_DWithin</a> function provided by PostGIS. Remember that we have to convert our point into the correct WKT format so that PostGIS understands the data we are passing it.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_near</span></span><span>(</span>point<span>,</span> distance<span>)</span>
  where<span>(</span>
    <span>'ST_DWithin(coords, :point, :distance)'</span><span>,</span>
    <span>{</span> point<span>:</span> <span>Geo</span><span>.</span>to_wkt<span>(</span>point<span>)</span><span>,</span> distance<span>:</span> distance <span>*</span> <span>1000</span> <span>}</span> 
  <span>)</span>
<span>end</span>

<span>Home</span><span>.</span>g_near<span>(</span><span>Geo</span><span>.</span>point<span>(</span><span>-</span><span>84.386330</span><span>,</span> <span>33.753746</span><span>)</span><span>,</span> <span>5</span><span>)</span><span>.</span>count </code></pre></div>
<p>This query performs just about as fast as the Geocoder version (because of our GiST index on the <code>coords</code> column), but is definitely a little easier on the eyes to read.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>ST_DWithin<span>(</span>coords<span>,</span> <span>'srid=4326;POINT (-84.38633 33.753746)'</span><span>,</span> <span>5000</span><span>)</span><span>)</span></code></pre></div>
<h2 id="finding-records-within-a-bounding-box-with-postgis-and-geocoder"><a href="#finding-records-within-a-bounding-box-with-postgis-and-geocoder" aria-label="finding records within a bounding box with postgis and geocoder permalink"></a>Finding Records Within a Bounding Box with PostGIS and Geocoder</h2>
<p>Geocoder provides us a way to find all records within a bounding box (roughly a rectangle, ignoring projection onto a sphere), and we just have to pass it the bottom left (south west) and top right (north east) coordinates.</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>within_bounding_box<span>(</span>
  <span>[</span><span>33.7250057553</span><span>,</span> <span>-</span><span>84.4224209302</span><span>]</span><span>,</span>
  <span>[</span><span>33.774350796</span><span>,</span> <span>-</span><span>84.3570139222</span><span>]</span>
<span>)</span><span>.</span>count </code></pre></div>
<p>Because it can use the index on latitude and longitude, it is quite efficient.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.7250057553</span> <span>AND</span> <span>33.774350796</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.4224209302</span> <span>AND</span> <span>-</span><span>84.3570139222</span><span>)</span></code></pre></div>
<p>To perform a bounding box query using PostGis, we'll create a method named <code>g_within_box</code> inside of the <code>Home</code> model, and utilize a PostGIS function named <a href="https://postgis.net/docs/ST_MakeEnvelope.html">ST_MakeEnvelope</a> along with the <code>&amp;&amp;</code> operator.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_within_box</span></span><span>(</span>sw_point<span>,</span> ne_point<span>)</span>
  where<span>(</span>
    <span>"coords &amp;&amp; ST_MakeEnvelope(:sw_lon, …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgis-rails-geocoder">https://pganalyze.com/blog/postgis-rails-geocoder</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgis-rails-geocoder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652608</guid>
            <pubDate>Thu, 01 Oct 2020 16:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building your own air pollution monitor with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24652488">thread link</a>) | @stevenhubertron
<br/>
October 1, 2020 | https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>With all the wildfires happening around the US this summer (2020) I finally got motivated enough to put together an air quality monitor home base station to see air quality in person, on the web and on my phone. &nbsp;If you has a Raspberry Pi plus a few other items you can set this up in an afternoon. I have it tuned to measure PM1.0, PM2.5, PM10, and Carbon Monoxide inside my house. </p><p>As an example, here is what I see in my Adafruit Dashboard</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1000w, https://www.drkpxl.com/content/images/size/w1600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1600w, https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 2024w" sizes="(min-width: 720px) 720px"><figcaption>My Adafruit dashboard.&nbsp;</figcaption></figure><p>I already had most of the the supplies but here is a list of what you will need:</p><ul><li><a href="https://shop.pimoroni.com/products/raspberry-pi-zero-wh-with-pre-soldered-header">Raspberry Pi Zero WH</a></li><li><a href="https://shop.pimoroni.com/products/enviro?variant=31155658489939">Enviro+</a></li><li><a href="https://shop.pimoroni.com/products/pms5003-particulate-matter-sensor-with-cable">PMS50003</a> Particulate Matter Sensor with cable</li><li>A free <a href="https://io.adafruit.com/">Adafruit IO</a> account</li></ul><p>Once you get it all plugged into, the Enviro+ into the Pi, and the PMS5003 into the Enviropi you can get the OS setup with a standard install.</p><p>I'll assume you know how to get Raspberry setup on your PI as well as SSH into it. If not there are a great number of <a href="https://desertbot.io/blog/headless-raspberry-pi-4-ssh-wifi-setup">tutorials</a> <a href="https://www.tomshardware.com/reviews/raspberry-pi-headless-setup-how-to,6028.html">out</a> <a href="https://medium.com/@jay_proulx/headless-raspberry-pi-zero-w-setup-with-ssh-and-wi-fi-8ddd8c4d2742">there</a>.</p><p>Once you are SSHed in, you can follow along with the instructions on the Pimoroni site or just run this script after an <code>apt upgrade</code> and <code>apt update</code></p><pre><code>git clone https://github.com/pimoroni/enviroplus-python
cd enviroplus-python
sudo ./install.sh</code></pre><p>This will install all the various code and samples to get playing with the sensors. The Enviro+ has a bunch of different sensors and LCDs in one making it extremely easy.</p><p>My goals for the setup are:</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5163-1.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5163-1.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg 1500w" sizes="(min-width: 720px) 720px"></figure><h3 id="lcd">LCD</h3><p>The LCD displays PM10, PM2.5 and PM1, temp, and noise level on the screen by default. If the pollution spikes, or the gas spikes the LCD will turn red and display a warning.</p><h3 id="adafruit-io">Adafruit IO</h3><p>All the LCD data <strong>plus</strong> Carbon Monoxide, CPU Temp, and CPU load so that I just have a view that everything is healthy on the Pi.</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5168.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5168.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg 1123w" sizes="(min-width: 720px) 720px"></figure><h3 id="ifttt">IFTTT</h3><p>Push alerts to high pollution or gas to my phone so I can be notified immediately if something is at issue.</p><h2 id="key-code-snippets">Key Code Snippets</h2><h3 id="get-the-cpu-temp">Get the CPU Temp</h3><figure><pre><code>def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())</code></pre><figcaption>Get CPU temp, convert to F and send both temp and usage to Adafruit</figcaption></figure><h3 id="get-noise">Get Noise</h3><figure><pre><code>def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))</code></pre><figcaption>Get noise within a wide range, round it and send off to display and Adafruit</figcaption></figure><h3 id="get-ambient-temps-w-corrections">Get Ambient Temps w/ Corrections</h3><pre><code>def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array so it doesn't overflow memory
    if (len(cpu_temps) &gt; 10):
        cpu_temps.pop(0)
        aio.send('temp', tempf)</code></pre><p>The thing you would think would be the easiest is actually the hardest due mainly to the fact the themometer is so close to the CPU that it's picking up ambient heat from it. What this does (and is heavily cribbed from the Pimoroni example) is use the CPU temp as a baseline measure that fills up an array, correct for it and convert it to F. Since this "app" is basically one big loop I want to clear the array out after 10 readings or 10 minutes. That should give me enough history to get a good average and the temps I see pass the gut check. </p><p>The <code>factor</code> float may need to be adjusted for your specfic needs. For example if you don't have the Pi in a Lego case, or have different airflow the factor you need to adjust it to may need to be different. </p><h3 id="get-gas-specfically-reducing-aka-carbon-monoxide">Get Gas, specfically Reducing AKA Carbon Monoxide </h3><figure><pre><code>def gas_func():
    global gas_reading, gas_average, gas_warning_amount
    # Get Gas
    gas_reading = gas.read_all()
    gas_array.append(gas_reading.reducing)
    # If the array is larger than 8 items dump the first one
    if (len(gas_array) &gt; 8):
        gas_array.pop(0)
        #print("Popped!")
        aio.send('gas', round(gas_reading.reducing))
    gas_average = (sum(gas_array) / len(gas_array))
    gas_warning_amount = str(round(gas_reading.reducing))
</code></pre><figcaption>Get an average gas reading, current reading and send to Adafruit</figcaption></figure><h3 id="get-air-pollution">Get Air Pollution</h3><figure><pre><code>def pollution_func():
    global pm25, pm10_display, pm25_display, pm1_display
    # Read Particulate Matter
    readings = pms5003.read()
    pm25 = readings.pm_ug_per_m3(2.5)
    pm10 = readings.pm_ug_per_m3(10)
    pm1 = readings.pm_ug_per_m3(1)
    # Send to Adafruit
    aio.send('pollution.pm25', pm25)
    aio.send('pollution.pm1', pm1)
    aio.send('pollution.pm10', pm10)
    # Draw on Screen
    pm10_display = "PM10: " + str(pm10) + " ug/m3"
    pm25_display = "PM25: " + str(pm25) + " ug/m3"
    pm1_display = "PM10: " + str(pm1) + " ug/m3"</code></pre><figcaption>Get the standard ug/m3 readings, send to Adafruit and display</figcaption></figure><h3 id="display-logic">Display Logic</h3><pre><code># Display output of sensors on display
        disp.set_backlight(1)
        if (gas_reading.reducing &gt; (gas_average * 1.05) and len(gas_array) == 8):
            print("High Pollution Warning")
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), gas_warning_amount, font=font, fill=text_colour)
        elif (pm25 &gt; 50):
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), pm25_display, font=font, fill=text_colour)
        else:
            draw.rectangle((0, 0, 160, 80), back_colour)
            draw.text((0, 0), pm10_display, font=font, fill=text_colour)
            draw.text((0, 20), pm25_display, font=font, fill=text_colour)
            draw.text((0, 40), pm1_display, font=font, fill=text_colour)
            draw.text((0, 60), tempf_display, font=font, fill=text_colour)
            draw.text((80, 60), noise_display, font=font, fill=text_colour)
        disp.display(img)
        time.sleep(60)</code></pre><p>This is a basic if else statement that has the following rules:</p><ul><li>If gas is higher than the average + 5% (indicating a spike) push an alarm to the Pi's display</li><li>If gas is ok, but PM2.5 pikes over 50 push an alarm to the Pi's display</li><li>Otherwise just show the PM numbers, Temp and Noise</li></ul><p>As you can see it's all pretty straightforward code in one big loop. If you just copy and paste the code following, add your Adafruit key, and do some additional setup in Adafruit IO you can have this up and running very quickly.</p><h2 id="the-complete-code">The Complete Code</h2><pre><code>import psutil
from gpiozero import CPUTemperature
import time
import datetime
from Adafruit_IO import Client
from bme280 import BME280
from enviroplus.noise import Noise
import colorsys
import sys
import ST7735
try:
    # Transitional fix for breaking change in LTR559
    from ltr559 import LTR559
    ltr559 = LTR559()
except ImportError:
    import ltr559

try:
    from smbus2 import SMBus
except ImportError:
    from smbus import SMBus


from pms5003 import PMS5003, ReadTimeoutError as pmsReadTimeoutError, SerialTimeoutError
from enviroplus import gas
from subprocess import PIPE, Popen
from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont
from fonts.ttf import RobotoMedium as UserFont
from datetime import timedelta



# Initial Setup of sensors / API
bus = SMBus(1)
bme280 = BME280(i2c_dev=bus)
aio = Client('XXX', 'aio_XXX')
pms5003 = PMS5003()
noise = Noise()

# Create LCD class instance.
disp = ST7735.ST7735(
    port=0,
    cs=1,
    dc=9,
    backlight=12,
    rotation=270,
    spi_speed_hz=10000000
)

# Create array for averages
gas_array = []
cpu_temps = []

# Initialize display.
disp.begin()

# Width and height to calculate text position.
WIDTH = disp.width
HEIGHT = disp.height

# New canvas to draw on.
img = Image.new('RGB', (WIDTH, HEIGHT), color=(0, 0, 0))
draw = ImageDraw.Draw(img)

# Text settings.
font_size = 20
small_font_size = 12
font = ImageFont.truetype(UserFont, font_size)
small_font = ImageFont.truetype(UserFont, small_font_size)
text_colour = (255, 255, 255)
back_colour = (0, 0, 0)
#size_x, size_y = draw.textsize(message, font)
warning = "Warning!"

# Calculate text position
#x = (WIDTH - size_x) / 2
#y = (HEIGHT / 2) - (size_y / 2)
x = 0
y = 0


def warm_func():
    currentTime = datetime.datetime.now()
    draw.rectangle((0, 0, 160, 80), (30, 160, 30))
    draw.text((10, 20), "Warming Up", font=font, fill=text_colour)
    draw.text((0, 66), currentTime.strftime("%a, %b %d %I:%M:%S %p"), font=small_font, fill=text_colour)
    disp.display(img)
    print("Warming Up at " + currentTime.strftime("%a, %b %d %I:%M:%S %p"))

def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())

def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))

def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    #print("CPU Temp: " + str(cpu_temp))
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array …</code></pre></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652488</guid>
            <pubDate>Thu, 01 Oct 2020 16:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing TikTok’s multi-billion dollar algorithm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651822">thread link</a>) | @ailon
<br/>
October 1, 2020 | https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573 | <a href="https://web.archive.org/web/*/https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="aae4">Almost a month ago my wife wanted to register on TikTok and was experiencing some odd difficulties. As our family’s tech-support person I ended up registering myself in the process of helping her. After posting a random TikTok (again, to help with some issues) I realized that it’s a good opportunity to put TikTok’s mighty algorithm to the test.</p><p id="8ee7">Since I went deep(ish) into my music making hobby this year, I decided to make <a href="https://www.tiktok.com/@ailonid" rel="noopener">my TikTok</a> focused on that. Both as a content consumer and creator. To try to preserve the “purity” of the experiment I decided not to tell anyone about my TikTok for the duration of this experiment. Well, my wife knew, obviously, and “contaminated” the results a bit. But I don’t think that was a major factor. So, here’s what I find out…</p><h2 id="168f">TikTok’s Algorithm for Consumers</h2><p id="571d">In the onboarding process you get asked very little. You pick some very wide-ranging themes of interest like entertainment, sports, music, etc. And that’s about it. Not surprisingly the initial experience is quite random — you get a bunch of half-naked beautiful people, kitty-puppy videos, poor dad joke reenactments and alike.</p><p id="c9fc">I tried not to “like” any of the above and not to follow any celebrities. I went into search and tried to look up people posting TikToks about music production, music theory, audio engineering, music business and similar. After I followed a bunch of those not much changed in the first couple of days. But then my “For You” feed (TikTok’s algorithmic feed) improved dramatically and became quite on-point.</p><p id="8d99">Interestingly, I was traveling for a couple of days (yes, this still happens once in a while in our neck of the woods) and didn’t use TikTok for a day or two. When I launched it after the break I got quite an increase in “funny” videos again. I guess this is AI’s idea of how to best “reactivate” churning users. But after a day or two it got back to my regular programming.</p><p id="a2bb">So, from the consumer’s side the algorithm works quite well. On the other hand, so does the algorithm on YouTube or Instagram. As <a href="https://twitter.com/mattcutts" rel="noopener">Matt Cutts</a> (one of the early Googlers) <a href="https://youtu.be/kpmbptHDVJg?t=1335" rel="noopener">said on TWiT</a>:</p><blockquote><p id="8242">You can probably do a pretty good approximation [of TikTok’s algorithm] in like a thousand lines of code. You are looking for engagement, you are looking for growth, you are looking at the first derivative… it’s gonna be pretty simple…</p></blockquote><p id="4112">In any case, it does work fine but this wasn’t the most interesting part to me. I’d be more surprised if it didn’t work well for consumers.</p><p id="cde4">What I was more interested in is the constant stream of raving comments on how well it works for creators — “nobodies” can reach millions with a good video, they said. Let’s see how that works…</p><h2 id="3e43">TikTok’s Algorithm for Creators</h2><p id="1833">I tried to post TikToks regularly. Not exactly every day but so far I posted 17 videos in about 4 weeks.</p><p id="8bc1">Quite obviously TikTok’s “hook” is that they over-expose TikToks from newbies and make you feel really good in your first few days. (How do they deal with bots and trolls trying to abuse this is an interesting question but beside the point here.) My first 5 TikToks (the first one was just a random test) got between 500 and 700 views. Not bad for someone with 1 follower. But then the views started to go down.</p><p id="2433">Obviously, I didn’t produce any stunning content and I don’t think I deserve more views from the algorithm pushing me. But I’ve noticed something peculiar…</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2070/1*TlzZOu5ZTizu7xsCT9oaNQ.png" width="1035" height="483" srcset="https://miro.medium.com/max/552/1*TlzZOu5ZTizu7xsCT9oaNQ.png 276w, https://miro.medium.com/max/1104/1*TlzZOu5ZTizu7xsCT9oaNQ.png 552w, https://miro.medium.com/max/1280/1*TlzZOu5ZTizu7xsCT9oaNQ.png 640w, https://miro.medium.com/max/1400/1*TlzZOu5ZTizu7xsCT9oaNQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TlzZOu5ZTizu7xsCT9oaNQ.png?q=20"></p></div></div></div><figcaption>Typical stats for most of my recent TikToks</figcaption></figure><p id="2de3">While all of my TikToks (except one) are in [mostly broken] English, and I added relevant hashtags and descriptions in English, they were primarily shown in my home country of Lithuania. That’s a very small niche. Add that TikToks were for a niche subject of “music-making” and you get close to zero of overlap.</p><p id="2d64">Interestingly, I got similar results on a couple of videos that I posted from Poland and Germany.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png" width="506" height="368" srcset="https://miro.medium.com/max/552/1*A0bxyk6k9iMsg6XC5xs4kg.png 276w, https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png 506w" sizes="506px" data-old-src="https://miro.medium.com/max/60/1*A0bxyk6k9iMsg6XC5xs4kg.png?q=20"></p></div></div><figcaption>Stats for TikTok posted from Germany</figcaption></figure><p id="d459">As you can see there’s Germany present here but the majority is still from Lithuania. The one from Poland had more Polish viewers but still fewer than Lithuanians. (FYI, the population of Poland is about 14x of Lithuania)</p><p id="569a">So the “almighty algorithm” somehow prioritizes your profile’s country over everything else. Not very smart, if you ask me. You may not notice this if you live in the US or some other big country, or if you create content for your local market. But, anecdotally, it feels like TikTok’s algorithm is quite discriminatory towards people from small countries trying to create global content.</p><p id="9aa2">To add insult to injury, I’m pretty sure TikTok never asked me for my country (I registered with email address, not phone or other account), and it doesn’t require location permissions (kudos for that). So basically they took my IP address at the time of registration and hard-coded my profile’s country to what they got from the IP lookup. Good thing I didn’t register at the office as many services think we are in Norway based on that IP. Or maybe that’s a bad thing given my goals.</p><blockquote><p id="e552"><strong>Untested pro-tip</strong>: create your account over VPN to US (or whatever location you care about) for better distribution.</p></blockquote><p id="5b0f">The bottom line is that TikTok’s algorithm still gave me more exposure than probably any other service would, considering I didn’t do anything to assist it (I didn’t tell anyone about my TikTok, remember?). Having said that, it handicapped me for no apparent reason purely based on my home country.</p><p id="2686">And that’s the main problem with all the algorithmic social media — you are at the mercy of a bunch of “if-then” statements with their bugs, quirks, and oddities.</p><p id="cef8">Now that you know <a href="https://www.tiktok.com/@ailonid" rel="noopener">I have TikTok</a>, we can proceed to the phase 2 of the experiment. If you are even remotely interested in music production and don’t live in Lithuania, please <a href="https://www.tiktok.com/@ailonid" rel="noopener">follow me on TikTok @ailonid</a> and in another month I will report if having followers outside of Lithuania had any impact on the algorithm.</p></div></div></div>]]>
            </description>
            <link>https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&amp;sk=a736bbdd904768fa4d7bcfb536615573</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651822</guid>
            <pubDate>Thu, 01 Oct 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julian Assange Acted Responsibly]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651796">thread link</a>) | @DiogenesKynikos
<br/>
October 1, 2020 | https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen | <a href="https://web.archive.org/web/*/https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-css-88vvl0=""><p data-pos="0-0" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Bieler Professor Christian Grothoff hat keine Ahnung, wer M.Â&nbsp;I.Â&nbsp;A. ist. Schade eigentlich. Schon allein wegen ihres spektakulÃ¤ren, verstÃ¶renden und kontrovers diskutierten Ausblicks auf das Trump-Zeitalter aus dem Jahr 2010, des zehnÂ­minÃ¼tigen Videos zu ihrer Single Â«Born FreeÂ». Darin werden in einer alternativen RealitÃ¤t Rothaarige als verfolgte ethnische Minderheit von paraÂ­militÃ¤rischen US-Truppen zu Tode gejagt.</p><figure data-pos="0-1" data-css-1esus25=""><a data-css-11au926=""><span data-css-mcluq8=""><svg width="26" height="36.01" viewBox="0 0 26 36"><path d="M25.956 18.188L.894 35.718V.66" fill="#fff"></path></svg></span><span data-css-fijd0m="">Dies ist ein Vimeo-Video. Wenn Sie das Video abspielen, kann Vimeo Sie tracken.</span><span data-css-1bqahl="" role="img" aria-label=""></span></a><figcaption data-css-s9b1dj="" data-css-qc9yqx="">M.I.A, Born Free</figcaption></figure><p data-pos="0-2" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">DafÃ¼r weiss M.Â&nbsp;I.Â&nbsp;A. aber, wer Christian Grothoff ist.</p><p data-pos="0-3" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A.Â&nbsp;â€“ jene englische Rapperin, die 2012 von der NFL auf eine Million Dollar SchadenÂ­ersatz verklagt worden war, weil sie wÃ¤hrend ihres Super-Bowl-PausenÂ­auftritts mit Nicki Minaj und Madonna den MittelÂ­finger <a href="https://www.youtube.com/watch?v=qlEUz1IlN70&amp;ab_channel=ATownHR23" data-css-9r2oe9="" data-css-1exity3="">in die Kameras gehalten hatte</a>. Oder 2016: Verklagt vom FussballÂ­club Paris Saint-Germain, weil sie im Video zu ihrem Song Â«BordersÂ» ein T-Shirt des franzÃ¶sischen Vereins trug und dabei den SchriftÂ­zug des Sponsors Â«Fly EmiratesÂ» <a href="https://www.youtube.com/watch?v=r-Nw7HbaeWY&amp;ab_channel=MIAVEVO" data-css-9r2oe9="" data-css-1exity3="">in Â«Fly PiratesÂ» abgeÃ¤ndert hatte</a>. </p><p data-pos="0-4" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die 45-jÃ¤hrige Musikerin und politische Aktivistin setzt sich derzeit mit zahlÂ­reichen KÃ¼nstlerinnen, darunter <a href="https://www.washingtonpost.com/entertainment/dissident-ai-weiwei-protests-possible-extradition-of-assange/2020/09/28/89e17c56-0183-11eb-b92e-029676f9ebec_story.html" data-css-9r2oe9="" data-css-1exity3="">Ai Weiwei oder Designerin Vivienne Westwood</a>, dafÃ¼r ein, dass Wikileaks-GrÃ¼nder Julian Assange nicht an die USA ausgeliefert wird. Seit dem 7.Â&nbsp;September lÃ¤uft an einem Londoner Gericht die zweite Runde des AuslieferungsÂ­verfahrens, das wegen Covid-19 im April unterbrochen worden war. Die USA beschuldigen Assange, mit der VerÃ¶ffentlichung von 250â€™000Â&nbsp;Depeschen aus US-Botschaften das Leben von Diplomaten und amerikanischen Helfern weltweit gefÃ¤hrdet zu haben.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="der-zeuge-aus-der-schweiz"></a>Der Zeuge aus der Schweiz</h2><p data-pos="0-6" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A. war es mÃ¶glich, das Verfahren per VideoÂ­stream live zu verfolgenÂ&nbsp;â€“ was alles andere als selbstÂ­verstÃ¤ndlich ist: Im Gericht waren fÃ¼r die neue AnhÃ¶rungsÂ­runde nur noch fÃ¼nf Journalistinnen und ein paar wenige GÃ¤ste zugelassen, diversen ProzessÂ­beobachtern wie Amnesty International wurde am ersten AnhÃ¶rungsÂ­tag kurzfristig der Zugang verweigert, zugesagte BeobachterÂ­plÃ¤tze wurden gestrichen, ihnen wurde zusammen mit vierzig anderen Organisationen oder akkreditierten Medien die MÃ¶glichkeit entzogen, <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">das Verfahren wenigstens per Stream verfolgen zu kÃ¶nnen</a>.</p><p data-pos="0-7" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Dieser Vorgang wurde laut Amnesty International <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">nicht weiter begrÃ¼ndet</a> und sei Â«sehr beunruhigendÂ». Â«Mit diesem Schritt missachtet das Gericht das GrundÂ­prinzip der Ã–ffentlichkeitÂ», schrieb die MenschenrechtsÂ­organisation: Â«Konkret, dass internationale ProzessÂ­beobachterinnen nachvollziehen kÃ¶nnen, ob nationales und internationales Recht eingehalten wird.Â» Und dies in einem Verfahren, in dem die RechtÂ­sprechung sowieso ziemlich eigenwillig interpretiert wird. Assange, dem der Zugang zu seinen eigenen AnwÃ¤lten in den letzten sechs Monaten verweigert worden war, sitzt mittlerweile seit 16Â&nbsp;Monaten ohne juristische Grundlage in IsolationsÂ­haft, wasÂ&nbsp;â€“ Grundlage hin oder herÂ&nbsp;â€“ als Folter gesehen werden muss. (Sein Vergehen, <a href="https://www.forbes.com/sites/thomasbrewster/2019/05/01/assange-given-50-weeks-in-prison-for-breaking-bail/#2af1cd5fa1d8" data-css-9r2oe9="" data-css-1exity3="">der Verstoss gegen Kautionsauflagen</a>, wird in Grossbritannien normalerÂ­weise nicht einmal mit einer kurzen GefÃ¤ngnisÂ­strafe geahndet.)</p><p data-pos="0-8" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.Â&nbsp;I.Â&nbsp;A. also war es mÃ¶glich, den Prozess live zu verfolgen.</p><p data-pos="0-9" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und am Morgen des 21.Â&nbsp;September twitterte die Rapperin:</p><div data-css-wnj6iv="" data-pos="0-10"><p data-css-87w1y="" data-css-5rrfwp="">Â«Ich beobachtete diesen Zeugen. Ziemlich intensive Befragung, sogar die Richterin wurde wÃ¼tend wegen des schonungsÂ­losen KreuzÂ­verhÃ¶rs, das er zu erdulden hatte. Ich empfehle es allen: Studiert bei Professor Dr.Â&nbsp;Christian Grothoff. Grothoff ist Professor der Informatik in der Schweiz. Er war brillant.Â»</p><figcaption data-css-s9b1dj="" data-css-qc9yqx=""><a href="https://twitter.com/MIAuniverse/status/1308129185240580096" data-css-9r2oe9="" data-css-1exity3="">Tweet von @MIAuniverse</a></figcaption></div><p data-pos="0-11" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Am Tag darauf rief ich den InformatikÂ­professor an. </p><figure data-pos="0-12" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Â«Mit dem nÃ¶tigen FachÂ­wissen lÃ¤sst sich alles Schritt fÃ¼r Schritt nachvollziehenÂ»: Christian Grothoff. <span data-css-puup3u="">Martin Gross/youtube/gnunet</span></figcaption></figure><p data-pos="0-13" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«KÃ¶nnen Sie mir sagen, was da los war?Â», fragte ich.</p><p data-pos="0-14" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Ja, natÃ¼rlichÂ», sagt er. Â«Nach meinem Auftritt vor Gericht ist es mir jetzt erlaubt, meine Erkenntnisse mit der Presse zu teilen.Â»</p><p data-pos="0-15" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Sie waren Zeuge im Assange-Prozess?Â»</p><p data-pos="0-16" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«JaÂ», sagte Professor Grothoff. Â«Ich habe meine Expertise dem Gericht zur VerfÃ¼gung gestellt, einen dicken Stapel Unterlagen.Â»</p><p data-pos="0-17" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Was fÃ¼r eine Expertise?Â»</p><p data-pos="0-18" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Ich sollte im Auftrag der Verteidigung nach bestem Wissen und Gewissen analysieren, wie es dazu kam, dass die DiplomatenÂ­depeschen, die Chelsea Manning Wikileaks Ã¼bergeben hatte, spÃ¤ter komplett ungeschwÃ¤rzt im Internet kursierten. Das ist ja eigentlich einer der zentralen AnklageÂ­punkte: Diese Publikation der gesamten Depeschen. Wer hat sie zuerst ins Netz gestellt? Wikileaks, wie es die USA behaupten?Â»</p><p data-pos="0-19" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Haben Sie eine Antwort gefunden?Â»</p><p data-pos="0-20" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Mit dem nÃ¶tigen FachÂ­wissen lÃ¤sst sich alles Schritt fÃ¼r Schritt nachvollziehen.Â»</p><p data-pos="0-21" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Wir trafen uns einen Tag spÃ¤ter zum AbendÂ­essen in einem chinesischen Imbiss in der Berner Altstadt.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="die-hauptschuld-liegt-beim-guardian"></a>Â«Die Hauptschuld liegt beim â€¹Guardianâ€ºÂ»</h2><p data-pos="0-23" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und die Geschichte, die der Bieler Professor Christian Grothoff an jenem Abend im September zu erzÃ¤hlen hat, ist hÃ¶chst erstaunlich.</p><figure data-pos="0-24" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Assange-UnterstÃ¼tzerinnen: Chelsea Manning (Mitte) und Dame Vivienne Westwood, hier mit ihrem Mann Andreas Kronthaler. <span data-css-puup3u="">David M. Benett/Getty Images</span></figcaption></figure><p data-pos="0-25" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Zehn Jahre lang <a href="https://www.bbc.com/news/technology-37165230" data-css-9r2oe9="" data-css-1exity3="">behaupteten die US-BehÃ¶rden (ohne jemals einen einzigen Beweis dafÃ¼r zu erbringen</a>), dass Julian Assange MenschenÂ­leben gefÃ¤hrdet habe, weil er die ihm von Chelsea Manning anvertrauten diplomatischen Depeschen der US-Regierung komplett und einfach so ins Netz gestellt habe, und deswegen sei Assange kein Journalist.</p><p data-pos="0-26" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die ErzÃ¤hlung von der GefÃ¤hrdung hat sich bis heute gehalten, obwohl Mitarbeitende des State Department bereits Ende 2010 gegenÃ¼ber dem US-Kongress hatten durchsickern lassen (wÃ¤hrend die Obama-Administration Ã¶ffentlich das Gegenteil behauptete), <a href="https://www.reuters.com/article/us-wikileaks-damage-idUSTRE70H6TO20110118" data-css-9r2oe9="" data-css-1exity3="">dass Wikileaks die USA zwar blossgestellt habe, dabei aber niemand zu Schaden gekommen sei</a>.</p><p data-pos="0-27" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Bei seiner Analyse fand Grothoff zudem heraus: Die BehauptungÂ&nbsp;â€“ ein zentraler AnklageÂ­punkt der US-JustizÂ&nbsp;â€“, Wikileaks habe als erste Quelle die Depeschen komplett und unbearbeitet ins Netz gestellt und sei deshalb unter dem Â«Espionage ActÂ» zu verfolgen, ist nachweislich falsch. Mit dem nÃ¶tigen FachÂ­wissen sei im Netz nachvollziehbar und unzweifelhaft belegbar, so Grothoff in seiner Expertise, dass Wikileaks erst im Nachgang die gesamten Depeschen publiziert habeÂ&nbsp;â€“ nachdem diese von anderen Quellen bereits online gestellt worden waren.</p><p data-pos="0-28" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Informatiker Christian Grothoff mit akademischen und beruflichen Stationen in Los Angeles, Denver, MÃ¼nchen und Rennes ist ein international angesehener Fachmann unter anderem fÃ¼r VerschlÃ¼sselungsÂ­techniken, aber auch in der Analyse von Peer-to-Peer-Netzwerken und der Ãœberlastung von Servern zum Beispiel durch sogenannte DDOS-Angriffe.</p><p data-pos="0-29" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Kurz: Grothoff vereint so ziemlich das ganze FachÂ­wissen, das in dieser Angelegenheit gefragt ist.</p><p data-pos="0-30" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Es ist im Ãœbrigen so, dass Assange die diplomatischen Depeschen derart gut geschÃ¼tzt hatÂ», sagte Grothoff im GesprÃ¤ch mit der Republik und auch vor Gericht, Â«dass sie auch von der NSA nicht hÃ¤tten geknackt werden kÃ¶nnen.Â»</p><p data-pos="0-31" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Bild, das Grothoff stattdessen zeichnet, ist ein ArmutsÂ­zeugnis fÃ¼r den Journalismus: Die Journalisten des Â«GuardianÂ», mit denen sich Assange bald Ã¼berwarf, hefteten sich wie BlutÂ­sauger an den Wikileaks-GrÃ¼nder, um mit seiner Hilfe die grossen Geschichten fahren zu kÃ¶nnen. Der Â«GuardianÂ»-Journalist David Leigh Ã¼bte dabei massiven Druck auf Assange aus: Er solle ihm das Passwort fÃ¼r die verschlÃ¼sselten Depeschen nennen, fÃ¼r den Fall, dass Assange verhaftet werde und dann keine weiteren Geschichten mehr publiziert werden kÃ¶nnten.</p><p data-pos="0-32" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die Quelle dafÃ¼r: das Buch Â«Wikileaks: Inside Julian Assangeâ€™s War on SecrecyÂ», das David Leigh im Februar 2011 selbst publiziert hatte. Dort steht auch, Assange habe schliesslich eingewilligt, Leigh das Passwort auszuhÃ¤ndigenÂ&nbsp;â€“ mit der eindringlichen Bitte, es niemals irgendwo als Ganzes aufzuschreiben.</p><p data-pos="0-33" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Assange, das steht in meiner Expertise fÃ¼r das Gericht, ist verantwortungsÂ­voll mit den Daten umgegangenÂ», sagt Grothoff. Â«Das lÃ¤sst sich alles nachvollziehen und belegen.Â» Doch was nach der PasswortÂ­Ã¼bergabe passiert sei, kÃ¶nne er als Fachmann nur als Â«grob fahrlÃ¤ssigÂ» bezeichnen, und zwar nicht von Wikileaks, sondern vom Â«GuardianÂ»: Â«Der Journalist David Leigh schwatzt Julian Assange das Passwort abÂ&nbsp;â€“ und dann publiziert er es ein paar Monate spÃ¤ter als KapitelÂ­titel in seinem Buch â€¹Inside Wikileaksâ€º.Â»</p><p data-pos="0-34" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Ja, Sie haben richtig gelesen.</p><p data-pos="0-35" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Passwort, 58Â&nbsp;Buchstaben, Ziffern und SonderÂ­zeichen, als Ãœberschrift in einem Buch. Der Â«GuardianÂ»-Journalist habe spÃ¤ter behauptet, er sei davon ausgegangen, das Passwort sei veraltet gewesen. Als VerschlÃ¼sselungsÂ­experte, sagte Grothoff, mÃ¼sse er entgegnen, dass man in der Pflicht sei, sich zu informieren, mit welcher Technik man es zu tun habe, wenn man mit derartig sensiblen Daten operiere. </p><p data-pos="0-36" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es dauerte nicht lange, da wurde in den Medien (namentlich im Â«FreitagÂ» und im Â«SpiegelÂ») ein ZusammenÂ­hang zwischen dem Passwort aus dem Buch des Â«GuardianÂ»-Journalisten und der Depeschen-Datei hergestellt, die nach massiven sogenannten DDOS-Angriffen auf den Wikileaks-Server (Angriffe, um den Server lahmzulegen) und Spiegelungen ebenjenes Servers durch Dritte irgendwo unkontrolliert als Kopie in den Weiten des Netzes umherschwirrte. Am 1.Â&nbsp;September 2011 sei diese dann unverschlÃ¼sselt auf einer Plattform namens Â«CryptomeÂ» aufgetaucht. </p><p data-pos="0-37" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">TatsÃ¤chlich sagte der Betreiber von Â«CryptomeÂ» nun vor dem Londoner Gericht aus, er habe als Erster die Depeschen vollumfÃ¤nglich, ungeschwÃ¤rzt und unverschlÃ¼sselt hochgeladenÂ&nbsp;â€“ <a href="https://www.fr24news.com/a/2020/09/us-never-asked-wikileaks-rival-to-remove-leaking-cables-court-says-julian-assange.html" data-css-9r2oe9="" data-css-1exity3="">und bis heute habe die US-Regierung bei ihm nichts von sich hÃ¶ren lassen</a>.</p><p data-pos="0-38" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Â«Die Depeschen finden sich immer noch dortÂ», sagt Grothoff. </p><p data-pos="0-39" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es sei problemlos chronologisch aufzuzeigen, sagte InformatikÂ­professor Grothoff im Berner Imbiss, dass die HauptÂ­schuld fÃ¼r die Publikation der gesamten Depeschen beim Â«GuardianÂ» liege. Â«WÃ¤re man …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</a></em></p>]]>
            </description>
            <link>https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651796</guid>
            <pubDate>Thu, 01 Oct 2020 15:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on QA]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24651571">thread link</a>) | @tigranhakobian
<br/>
October 1, 2020 | https://blog.superannotate.com/how-to-detect-mislabeled-annotations | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/how-to-detect-mislabeled-annotations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>Manual QA is a significant part of the annotation pipeline. Annotation companies report that 40 percent of the annotation time can be spent on manual QA. As a result, finding ways to reduce QA testing time can have a significant impact on annotation costs.&nbsp;</em></p>
<!--more--><p><em>At SuperAnnotate, we’ve developed a tool to accelerate the QA process. This article discusses SuperAnnotate’s features that speed up the quality assurance process substantially. It presents several automation tools within the platform listing specific use cases in which a major acceleration of the QA process can be obtained. We also explored various ML algorithms that can detect over 90 percent of mislabeled instances in data while accelerating the QA process up to 4 times.&nbsp;</em></p>
<h3><strong><span>Outline</span></strong></h3>
<ul>
<li><em>Problem with noisy annotation in data&nbsp;</em></li>
<li><em>Manual QA acceleration</em></li>
<li><em>QA automation</em></li>
<li><em>Conclusion</em></li>
</ul>
<h2><span>Problem with annotation noise in data</span></h2>
<p><strong><span>1.1. The importance of model accuracy and the impact of annotation noise&nbsp;&nbsp;</span></strong></p>
<p>In real-world applications, the performance of machine learning (ML) systems is of crucial importance. ML models heavily rely on the quality of annotated data, but obtaining high-quality annotations is costly and requires extensive manual labor.&nbsp;</p>
<p><span>In any annotation pipeline, regardless of the data collection method, i.e., human or machine, several factors inject annotation noise in data. As a result, even the most celebrated datasets contain mislabeled annotations.</span></p>

<p><img src="https://lh3.googleusercontent.com/mL1r0JU9VM5-WflEsLU04zQ7vhYhl8cKRux8LvOnUTYEKZvnIUD9Gv8HmkVTqPfgoDtEkb_5ApX3SjgJjdTAHNfG6I-5Q7_fag_cra8IhXTWp-uVdrvQCf7kzoqt03BwtgKlTb4i" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"><em>Figure: Ambiguous or Mislabeled annotations from ImageNet. Source (</em><a href="https://arxiv.org/abs/2001.10528"><em><span>Pleiss et al</span></em></a><em>.)</em></p>

<p><span>Recent studies show that both natural and malicious corruptions of annotations tend to radically degrade the performance of machine learning systems. Deep Neural Networks (DNNs) tend to memorize noisy labels in data, resulting in less generalizable features and poor model performance (<a href="https://arxiv.org/abs/1611.03530">Zhang et al.</a>)</span></p>
<p><span>Therefore, extensive quality control of annotated data is required to clean annotation noise and improve model performance.</span><em><br></em></p>

<p><img src="https://lh4.googleusercontent.com/7BKHH4Am8Z_PZebzMe7mkbGCA6J_UyNRZE-ClAMwP5qVo52ZEuybUx81EOWYSdKrz2Mz7P4zf2cHuoz9nlyl4Alg-D16cD58mSCLf1CAOUwwDEp2MUkIsaTi37D6y9aliNShqdUz" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Accuracy drop in multiple datasets when injecting label noise. Source (</em><a href="https://arxiv.org/abs/1611.03530"><em><span>Rolnick et al.</span></em></a><em>)</em></p>

<h2>Manual QA Acceleration</h2>
<p><strong><span>2.1 SuperAnnotate’s QA pipeline&nbsp;</span></strong></p>
<p><span>Quality Assurance of annotated data is time-consuming and requires particular attention. Annotation tools need to provide reliable and scalable QA pipelines to accelerate the QA process. <a href="https://annotate.online/login">SuperAnnotate</a> provides interlinked annotation and QA processes within the same platform. As a result, QA systems do not require additional management.</span></p>
<p><span>The design of SuperAnnotate’s QA system guarantees an efficient process and ensures a minimal probability of error.&nbsp;</span></p>
<p><strong><span>2.2 Pinning images to reduce common errors&nbsp;</span></strong></p>
<p><span>Sharing repetitive labeling mistakes across the annotation team is essential to reduce systematic errors throughout single or multiple annotation projects. </span>SuperAnnotate’s pin functionality is designed specifically for this cause.&nbsp;</p>
<p>Once the reviewer notices a recurring error, they can share this information through pinned annotations instead of extensive project instructions. Pinned annotations will appear first in the annotation editor to immediately grab the annotation team’s attention.&nbsp;</p>
<p>This functionality is highly efficient since it allows the project coordinator to instantly share common instructions, eliminating the spread of systematic errors.&nbsp;</p>

<p><img src="https://lh6.googleusercontent.com/g1sh6D7Xy1hLYBMczMWfFGdO1_1gktJn7dNF1Spx3lwUxeZd8isGaMHgYLB1GoT0lY8jJKTemdqvtExgPJIocgjNEFuzYGjbPQYeRo31873mdN3U4U10DMjW7DZOnr1eAh5_o-bc" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Pin functionality</em></p>

<p><strong><span>2.3 Approve/Disapprove functionality</span></strong></p>
<p>Apart from various image-level QA tools, SuperAnnotate also provides instance-level QA functionalities. The latter is designed to help the QA focus on a specific instance area. As a result, no error is overlooked, at the time a meticulous QA is time-efficient.</p>
<p>Additionally, the Approve/Disapprove functionality works on the level of individual instances<span>.</span> If a QA specialist disapproves of an annotation, they can send it back to the Annotator for correction. The QA specialist can send the annotation back to the Annotator as many times as needed until the annotation is corrected. Once approved, the annotations can be exported from the platform.</p>

<p><img src="https://lh4.googleusercontent.com/BpQPXRUuTMRYUP-YGJTSRJwFUtdLr6wsB5LVwn66wK6TqFJCTRW5LLwhTp4sRttqgzQaCngKzm7Z6ONZBpPhwzxifj1KlBRs5_FOl_Nk0cFpaC_jn7-l9CMn1WJX2FENx9f9NI24" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p>Figure: Approve/Disapprove functionality</p>

<p><span>The QA mode is another useful tool for manual instance inspection. When enabled, the annotations are visually isolated from the background. This allows the user to distinguish between instances and the underlying objects, making the instance inspection easier.</span></p>
<p><span>All listed features extensively accelerate the manual QA process. However, machine learning techniques that automatically detect annotation noise can provide an additional level of automation.</span></p>

<h2><span>QA Automation</span></h2>
<p><strong><span>3.1 ML for QA Automation</span></strong></p>
<p><span>QA of annotated data takes around 40 percent of the annotation time.</span></p>
<p><span>On average, only a small fraction of annotated data contains noise. Still, QA is applied to the entire dataset, and monitoring clean data costs the annotators extra time and resources. An automation method could substantially cut down the QA process of clean data by isolating a set of risky annotations. So, our goal is to determine ML techniques that identify noisy annotations in data with high precision and recall.</span></p>
<p><strong><span>3.2 Current research</span></strong></p>
<p><span>Learning on datasets that contain annotation noise has been an active research area in ML. Several methods use predictions from DNNs to detect label noise and modify training loss (Reed et al., 2015; Tanaka et al., 2018). These methods do not perform well under high noise ratio as the domination of noisy annotations in data causes overfitting of DNNs. Another approach is to treat small loss samples as clean annotations and allow only clean samples to contribute to the training loss (Jiang et al., 2017). Ultimately, this research area’s core challenge is to design a reliable criterion capable of identifying the annotation noise.</span></p>
<p><span>A significant amount of research in this area is focused on classification with noisy labels. The proposed methods range from detecting and correcting noisy samples to using noise-robust loss functions. Unsupervised and semi-supervised learning techniques are also relevant to this task since those require few or no labels. Mislabeled samples that are detected without label correction can be used as unlabeled data in a semi-supervised setting (Li et al. 2020).&nbsp;</span></p>
<p><span>Going beyond classification makes things far more challenging. In classification, the existence of an object per image is guaranteed. So, the noisiness criterion can be defined between predicted and annotated image labels. However, in more complex tasks such as object detection, the correspondence between predicted and annotated instances is less trivial. Even though research in this area is in its initial state, several methods suggest valid measures to indicate both localization and label noise in object detection (Pleiss et al 2020, Chadwick et al. 2019).</span></p>
<p><strong><span>3.3&nbsp; Proposed method</span></strong></p>
<p>Consider the task of object detection on a dataset that contains mislabeled annotations. Several techniques use DNN predictions to identify label noise in data. Based on this concept, we propose the following algorithm.</p>
<ul>
<li>For each bounding box annotation, we obtain the matching prediction that has the maximum IOU.&nbsp;</li>
<li><span>Compute <strong>L2 distance</strong> between one hot vector of an annotated class and Fast RCNN softmax logits of the matched prediction. </span>This distance serves as a mislabel metric for annotations. We treat this number as the probability of annotation being mislabeled. As we aim to achieve maximal recall and precision in mislabel detection, we select an optimal threshold to attain the desired objective. This defines the split of data between clean and mislabeled annotations by the given criterion.</li>
</ul>

<p><img src="https://lh6.googleusercontent.com/JJtyM51584r8uJCIbHuW0UKhdgxQIIMm4G23vuD8lxnn5yrYHONPRytIxl-9QjFodM51zy7d8pvswhiMYokXY8XOz-DxqTd4ua-_DHGemiuXULNKqCbq_ePQfzulkbsrNu_jyX0D" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: L2 distance on gt one hot and prediction logits</em></p>

<p>Along with mislabeled detections, we also suggest considering the most confident predictions as missing annotations.&nbsp;</p>
<p><strong><span>3.4 Experiments and results</span></strong></p>
<p>To evaluate the performance of our method, we used PASCAL VOC as a toy dataset. When we manually injected asymmetric label noise in 20 percent of bbox annotations, the described mislabel criterion resulted in the precision-recall curve shown below.</p>
<p><img src="https://lh5.googleusercontent.com/OhgoPNrwmPWqR21Y1jnMY-1rbgKV8cxdFd8F0lZsVCZTcrN9C77EBX-0yqvZfVbYOVAFH_pxHNh88T7r26Gbp6hxWWdF5XqyLkN8SS5G46q512ZOHILlP1wmeR20aCo2QDWsOMms" width="400" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: PR curve with optimal mismatch threshold selected</em></p>

<p>Here, recall determines the portion of annotation noise captured, and precision identifies the fraction of data validated as clean.</p>
<p><span>Based on the PR curve above, using optimal mislabel threshold results in over 93 percent recall. This proves the reliability of our method, as we capture the dominant fraction of annotation noise. Along with high recall, we obtained over 75 percent precision, which attributes to validating ¾ of annotations as clean. This cuts manual inspection time over the whole dataset by a margin of 4, resulting in extensive automation for the manual QA.&nbsp;</span></p>
<p>Note that detected risky annotations contain clean samples apart from correctly detected mislabeled instances. Those are the images that were hard to capture by the detection model and thus are misclassified as risky. Distinguishing between these two categories is a challenging problem for further research.&nbsp;</p>
<p>You can find the source code for the discussed experiments at our <a href="https://github.com/superannotateai/qa-automation"><span>GitHub repository</span></a>.</p>
<p>Also, consider our <a href="https://colab.research.google.com/drive/1Xbt3dxkmX4ozQhdY_vnHXAH67OUeg0Nj#scrollTo=7unkuuiqLdqd&amp;uniqifier=2"><span>Colab tutorial</span></a> as a step-by-step guide to reproduce the given results.&nbsp;</p>
<p><strong><span>3.5 Automate Approve/Disapprove functionality&nbsp;</span></strong></p>
<p>Once mislabeled annotations are captured by ML techniques, SuperAnnotate allows users to import the detected information to the platform through the <strong>error </strong>key of SA formatted annotations. Just set the <strong>error</strong> key in mislabeled annotations and import SA formatted JSONs to SuperAnnotate via Python SDK.&nbsp;</p>

<p><img src="https://lh3.googleusercontent.com/to5CwRUFKERkSeyPgA1Nzl84I0ijhR8bQCpsUHhIxi_zhsm7FnNGOxSJ-i0V8HXnJSzN4VOxDnVgj_JWo2QCwQF6ECSjO4CrLShBB9V3YPHp8SWxO9D2CEwC6UbfqClElWgxIOf3" width="654" height="183" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: JSON Code Block</em></p>

<p><img src="https://lh3.googleusercontent.com/0SJ8E5OnOSxB50Fh_4d4_qjJNT0lygY1yHzFGuFlZ9fMDjIGyUGQDqxGsDDG9j2dMcfmf6PLOHvj3JRJ4F3UtaQup-muynR2TFd18W6vbjI1ANF8Ll99dK_b8v1GIzkBUbpwVaPn" width="654" height="121" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: SDK Code Block</em></p>

<p><span>Discussed pipeline provides complete automation of Approve/Disapprove functional.</span></p>

<p><img src="https://lh5.googleusercontent.com/w9VXvs6INaP4WaEADW2pW6fEVj6s8sj5FZd44gN-10LcKplspRX3N7tt-aRuV1BUmNFzANwQTjKgq9rt-EbND0_SpY2z5Ikcpc3xo6wZHQMm2-TB3iY6ao5LboT86FK8qaw8ZwPu" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Before v.s After autoqa in SA platform&nbsp;</em></p>

<h3><span>Conclusion</span></h3>
<p><span>QA automation is of crucial importance as it constitutes a significant portion of annotation time. This article shows that using proper algorithms and associated tools can help us detect mislabeled annotations with high precision while spending 4x less time on QA.</span></p></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/how-to-detect-mislabeled-annotations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651571</guid>
            <pubDate>Thu, 01 Oct 2020 14:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CodeShip Status – Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651240">thread link</a>) | @jwilk
<br/>
October 1, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users’ pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I’d like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651240</guid>
            <pubDate>Thu, 01 Oct 2020 14:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memgraph DB 1.1]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24651091">thread link</a>) | @karimtr
<br/>
October 1, 2020 | https://memgraph.com/blog/memgraph-1-1-benchmarks | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-1-benchmarks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p>At Memgraph, we put great effort into delivering a high-performance in-memory graph storage and analytics engine. We do this by investing a lot of time optimizing and continuously improving various aspects of the Memgraph core engine. In this blog post, we will explore some of the improvements we have made on the storage layer and their impact on performance and memory usage.</p>
<p>The two most significant improvements we introduced in recent years are a new storage engine and a new way of storing properties on both nodes and edges.  Prior to version v0.50.0 Memgraph had an <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC</a> storage where copies of nodes and edges were used to version the data. <strong>Memgraph v0.50.0</strong> introduced a new way of managing graph data where each node or edge consists of the latest version of data, and associated changes of data required to reconstruct previous versions.</p>
<p><img src="https://i.imgur.com/bQbvvp6.png" alt=""></p>
<p><strong>Memgraph v1.1.0</strong> introduced a new way of storing properties. Each node or edge has a property store that takes at least 16B of memory. Memgraph tries to hold properties data in 16B on the stack, if possible. If the properties data exceeds 16B, the first 8B of the stack buffer indicates the total number of bytes required for the storage of properties, and the second 8B a pointer to the array on the heap that stores properties. This technique is called small buffer optimization.</p>
<p><img src="https://i.imgur.com/LWP2te8.png" alt=""></p>
<p>Additionally, there were various other smaller improvements of existing internal data structures, most notably the <a href="https://en.wikipedia.org/wiki/Skip_list">skip list</a> which is used as an indexing data structure. The combined result was a massive improvement in memory usage with a substantial reduction in memory fragmentation while ensuring equivalent or better performance. Before jumping into the analysis and explanations, let’s have a look at the benchmark setup.</p>
<h2>Setup</h2>
<h3>Target Systems</h3>
<p>The benchmark tests different Memgraph versions. The release dates and details of each version are the following:</p>
<ul>
<li><strong>v0.15.2</strong>, October 23, 2019, the last version of Memgraph that used an in-memory storage engine based on copies of nodes/edges.</li>
<li><strong>v0.50.0</strong>, December 11, 2019, introduced the new in-memory storage engine based on data changes and a C-based storage API.</li>
<li><strong>v1.0.0</strong>, April 6, 2020, introduced a Python-based storage API.</li>
<li><strong>v1.1.0</strong>, July 1, 2020, added encoding and compression to node and edge properties.</li>
</ul>
<p>The <a href="https://docs.memgraph.com/memgraph/changelog">Memgraph Changelog Docs</a> page contains more details about changes in each version.</p>
<h3>Hardware</h3>
<ul>
<li>Server: HP DL360 G6</li>
<li>CPU: 2x Intel Xeon X5650 6C12T @ 2.67GHz</li>
<li>RAM: 144GB</li>
<li>Disk: 120GB SSD</li>
<li>OS: Debian 9 Stretch</li>
</ul>
<h3>Workload</h3>
<p>The benchmark consists of several different queries that test the performance of the graph database. Typical graph database workloads consist of READ, CREATE, and ANALYZE queries.</p>
<p>Memgraph is particularly well suited for hybrid transactional-analytical workloads where it’s crucial to ingest data as fast as possible and simultaneously deliver analytics as quickly as possible. For this reason, we are mostly interested in traversal queries (1-Hop, 2-Hop, etc.) which represent the majority of analytical queries.</p>
<p>In the following table, you can find the exact queries we have used for benchmarking.</p>
<pre><code>|            Query Name             |                                                Query                                                        |  Query Type |
| --------------------------------- | ----------------------------------------------------------------------------------------------------------- | ----------- |
| Aggregation                       | `MATCH (n:User) RETURN n.age, COUNT(*);`                                                                    | ANALYZE     |
| 1-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;(n:User) RETURN n.id;`                                                          | ANALYZE     |
| 2-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                            | ANALYZE     |
| 3-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                       | ANALYZE     |
| 4-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                  | ANALYZE     |
| 2-Hop Variable Expand             | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id;`                                          | ANALYZE     |
| 2-Hop Variable Expand with Result | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id, n;`                                       | ANALYZE     |
| Shortest Path                     | `MATCH p=(n:User {id: $from})-[*bfs..15]-&gt;(m:User {id: $to}) RETURN extract(n in nodes(p) | n.id) AS path;` | ANALYZE     |
| Insert New Relationship           | `MATCH (n:User {id: $from}), (m:User {id: $to}) WITH n, m CREATE (n)-[e:Temp]-&gt;(m) RETURN e;`               | CREATE      |
| Find Node                         | `MATCH (n:User {id : $id}) RETURN n;`                                                                       | READ        |
| Insert a New Node                 | `CREATE (n:UserTemp {id : $id}) RETURN n;`                                                                  | CREATE      |
</code></pre>
<p>The benchmarking harness executed all queries against the <a href="https://snap.stanford.edu/data/soc-Pokec.html">Pokec dataset</a> which contains 1.6M nodes and 30.6M edges. Given that the goal of each benchmark is to saturate the target system to extract its peak characteristics, we took great care in carefully designing and polishing our setup. Some of the essential elements of the harness are:</p>
<ul>
<li>optimized C/C++ client to minimize client overhead.</li>
<li>fresh dataset load before each execution.</li>
<li>concurrent execution (up to 12 cores) to push Memgraph to its limits.</li>
</ul>
<h2>Data Import Analysis</h2>
<p>Before delving deep into the workload queries execution analysis, a couple of notes about the data import.</p>
<p>The harness imported data in a real-time manner, equivalent to normal query execution by running queries. The data was imported using 8 concurrent clients.  Throughput and peak memory usage were measured during the data import. A couple of interesting insights emerged. On the memory usage side, there is already a massive difference between Memgraph versions. <strong>Before v0.50.0</strong>, Memgraph stored all data modifications as whole copies of the modified objects. By removing the need to make whole copies of database objects, versions <strong>after v0.50.0</strong> provide a significantly less memory usage. The same benefits apply to the runtime environment since the import uses regular queries.</p>
<p><img src="https://i.imgur.com/VfDzuCw.png" alt=""></p>
<p>At this point, you might be wondering about the import speed. As the chart below shows, throughput on basic CREATE queries also improved. Since data copying is generally a fast operation, throughput improvement is not huge but is still significant. One important thing to notice is the difference between v1.0.0 and v1.1.0. <strong>v1.1.0</strong> has almost the same throughput as versions before even though more work is involved in property compression.</p>
<p><img src="https://i.imgur.com/hsh6uDj.png" alt=""></p>
<h2>Query Execution Analysis</h2>
<p>Let’s start analyzing the <strong>workload queries</strong>. The following radar chart shows peak memory usage during query execution across different Memgraph versions. Keep in mind that less is better.</p>
<p>As you can see, <strong>v1.1.0 uses ~50%</strong> less memory compared to v0.15.2. v0.50.0 and v1.0.0 fall in-between with almost no difference because not much from the storage perspective changed between these two versions. The most significant difference is between v0.15.2 and v0.50.0 (introduction of the new storage engine), and v1.0.0 and v1.1.0 (introduction of encoded and compressed properties).</p>
<p><img src="https://i.imgur.com/4ETpDXT.png" alt=""></p>
<p>On the other hand, while looking at memory, it’s also critical to observe what is happening with the throughput. Generally, there is a well-known trade-off between space and time. But, as you can see in the following chart, v1.1.0 has the best performance. Please note that in this case, more is better.</p>
<p><img src="https://i.imgur.com/c0nBqJS.png" alt=""></p>
<p>Of course, not all queries yield significant throughput improvements. E.g., the <code>Insert New Node</code> query performance stayed similar across different Memgraph versions. Nonetheless, the following chart illustrates well how Memgraph scales with the number of concurrent requests.</p>
<p><img src="https://i.imgur.com/vIy7rTM.png" alt=""></p>
<p>The new storage engine also introduced a feature where it is possible to disable storing properties on edges. Sometimes graph datasets don’t have any data attached to edges. Memgraph offers a configuration option to remove all associated data structures required to store data on edges. As you can see in the following chart, by not having properties on edges, memory usage goes down by almost 50% (in addition to the reductions mentioned above). v0.15.2 can’t disable the property storage on edges, so the chart shows nothing there. Using all the improvements in new versions of Memgraph you can store the same dataset in 3.36x less memory (comparing v0.15.2 with properties enabled and v1.1.0 with properties disabled).</p>
<p><img src="https://i.imgur.com/PtQviBf.png" alt=""></p>
<p>The rest of the charts show performance for each query with regards to linear scalability. Linear scalability is the ability of a system to handle more work by adding more resources linearly. E.g., by doubling the number of cores, the system is capable of executing twice as many queries. In practice, it’s impossible to reach perfect linear scalability due to various overheads.  The real question is how far Memgraph is from linear scalability? As you can see below, not by a lot.</p>
<p>The following chart shows throughput data for the simple read query (Find Node). The node lookup inside Memgraph has an O(logN) complexity.</p>
<p><img src="https://i.imgur.com/0z46Rg5.png" alt=""></p>
<p>In the next case, instead of reading, Memgraph creates an edge. The operation contains two node lookups and one edge write. Which means it’s very similar to the Find Node query. Instead of one lookup, the action has two lookups and one write. The chart looks very similar to the Find Node chart.</p>
<p><img src="https://i.imgur.com/ZWzeFc6.png" alt=""></p>
<p>By moving towards more complex queries, there is a more significant scalability difference between previous versions of Memgraph and the latest ones. v0.15.2 is far behind the latest versions.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memgraph.com/blog/memgraph-1-1-benchmarks">https://memgraph.com/blog/memgraph-1-1-benchmarks</a></em></p>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-1-benchmarks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651091</guid>
            <pubDate>Thu, 01 Oct 2020 14:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ElasticSearch Query Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650651">thread link</a>) | @piranha
<br/>
October 1, 2020 | https://solovyov.net/blog/2020/elasticsearch-query-builder/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/elasticsearch-query-builder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>This post strives to be useful to anyone who uses ElasticSearch, but all examples are going to be in Clojure since it’s what we use.</p>
<p>ElasticSearch is a wildly useful database (if I may say so), but at times it feels like its query language evolved rather than was planned. This manifests in it being rather ad-hoc and non-orthogonal. Plus using JSON with its low expressiveness adds quite a bit of verbosity. All of this leads to code which builds ES queries being messy and unpleasant to use.</p>
<h2 id="jump-in">Jump in</h2>
<p>Certainly, this was our case a few years ago. Our code was a bunch of functions calling one another, which sounds like functional programming and should be fine, right? Well, as always, the devil is in the detail, and:</p>
<ul>
<li><code>if</code>/<code>case</code>/<code>cond</code> everywhere, various cases were piling on top of each other</li>
<li><a href="https://solovyov.net/blog/2020/higher-order-functions/">functions parametrized with functions</a> — it’s a good tool if you make some higher-order well-documented/understood function, but your business logic should be free of this stuff in general; makes logic hard to be understood</li>
<li>code factorization was quite a bit off: function boundaries felt a bit random</li>
<li>it was written at the start of the current codebase, grew with it and just happened, was never planned</li>
</ul>
<p>Our use case, by the way, is a product filtering API (facets and all that stuff) for an ecommerce site, <a href="https://kasta.ua/">Kasta</a>. Apply some filters and retrieve some aggregations, which is enough of a problem to need a proper solution.</p>
<h2 id="what-is-out-there">What is out there</h2>
<p>So where to go? I looked around and saw stuff like <a href="https://elasticsearch-dsl.readthedocs.io/en/latest/">elasticsearch-dsl</a>, which was just like ES data structures, but methods on mutable objects. Ugh. Also, <a href="https://elastic-builder.js.org/docs/">ElasticBuilder</a>, which is similar, but with different names, so you have to remember two layers of abstraction. Thanks, but no.</p>
<p>And there are a lot of articles on how to make a query to get what you need from ES, but nobody wrote an article on how to make an ES query builder! Well, except for me. :-)</p>
<h2 id="solution">Solution</h2>
<p>What I like in terms of API is <a href="https://github.com/seancorfield/honeysql">HoneySQL</a>, which is a compiler from maps/vectors to SQL queries. This got me thinking and it turns out that a good question is half of the answer.</p>
<p>What we need is a compiler from our API interface — GET request query string — to an ES query.</p>
<p>Rephrased like this it makes the task almost a walk in the park. A long-long walk, but much less “here be dragons” if-peppered abomination of the past. And the design cornerstones are:</p>
<ul>
<li>branchless pipeline</li>
<li><a href="https://clojuredocs.org/clojure.core/defmulti">multimethods</a></li>
<li>small dictionary of verbs on top of ES incantations</li>
</ul>
<h3 id="data-format">Data format</h3>
<p>Some time ago I stumbled upon a great article about working with ES, and one of its parts <a href="https://project-a.github.io/on-site-search-design-patterns-for-e-commerce/#generic-faceted-search">describes a data model</a> they have used. It proposes that instead of a map like <code>{:brand "wow" :color "red"}</code> you use a following structure:</p>
<pre><code>{:facets [{:name "brand"
           :value "wow"}
          {:name "color"
           :value "red"}]}
</code></pre>
<p>This allows you to query all those facets with a single definition, rather than sending a separate aggregation for every field. More than that, you don’t need to know which facets are available for filtering upfront, since you’ll receive all of them from ES.</p>
<p>In practice, two lists of facets are needed - regular ones and ranged facets. Regular facets are aggregated by <code>terms</code> aggregation, and ranged are aggregated by a combo of <code>ranges</code> and <code>percentiles</code>.</p>
<h3 id="verbs">Verbs</h3>
<p>So we have several functions like <code>not</code>, <code>and</code>, <code>or</code>, <code>term=</code>. They signal intent rather than what ES is doing inside and make reading aggregations and filters much easier. Or should I say <code>should</code> easier? Or <code>must</code> easier? :-) You can understand what’s it doing without opening ES docs. Some examples:</p>
<pre><code>(defn or* [&amp; clauses]
  (let [clauses (filterv identity clauses)]
    (cond
      (empty? clauses)
      {:bool {}}

      (= 1 (count clauses))
      (first clauses)

      :else
      {:bool {:should               clauses
              :minimum_should_match 1}})))


(defn facet= [k v]
  {:nested {:path  "facets"
            :query (and* (term= "facets.id" k)
                         (term= "facets.value" v))}})
</code></pre>
<p>What they accomplish is that most of our lower-level use cases are covered with “loaded” terminology rather than “neutral” (and often cryptic) ES maps.</p>
<h3 id="pipeline">Pipeline</h3>
<p>The pipeline is 4 steps:</p>
<ul>
<li><code>qs-&gt;query</code> parses query string, cookies, headers into a basic query data structure</li>
<li><code>make-aggs-q</code> loops through supplied filters and known aggregations, and builds an ES query</li>
<li>then a query is executed</li>
<li><code>aggs-&gt;response</code> converts ES response to what our API returns</li>
</ul>
<p>We represent a user query internally with a map like that:</p>
<pre><code>{:base    {"menu" "pants"}
 :filters {"1" #{"123" "456"}}
 :sort    :default
 :cursor  "ZXCVB"
 :limit   100}
</code></pre>
<p>This is easier to interact with than with just a raw query string.</p>
<h3 id="make-aggs-q">make-aggs-q</h3>
<p>This part is the most convoluted one. It builds the essence of an ES query for aggregations, and consists of:</p>
<ul>
<li>loop over known non-facet aggregations</li>
<li>loop over every facet which was used as a filter in a query</li>
<li>query for regular facets</li>
<li>query for ranged facets</li>
</ul>
<p>What is a facet aggregation is described in <a href="#data-format">data format</a> section. All other aggregations are non-facet and should be explicitly mentioned. Those are filters such as price, depot (whenever they are on stock in our warehouse rather than supplier’s one), supplier, etc. When I look there it feels like most of them need to be in facets. Historical reasons. :)</p>
<p>Every loop then delegates to <code>make-agg</code> multimethod, which builds its piece of the query. Here is an example of a filter for colors - it’s one of the simplest aggregations, just generates a list of colors available for selected products.</p>
<pre><code>(def NESTED-AGG :_nest)

(defn agg-filter [agg filter-data]
  {:filter filter-data
   :aggs   {NESTED-AGG agg}})

(defmethod make-agg :color [filter-name _ filters options]
  [filter-name
   (-&gt; {:terms {:field "color_group"
                :size  (:max-buckets options)}}
       (agg-filter (filters/make filters)))])

</code></pre>
<p><code>filters</code> are filters for the given query except for the one for the given aggregation, so that you’ll receive all possible values for the current aggregation in a given context. So we apply them with an <code>agg-filter</code> function.</p>
<p><code>-&gt;</code> could be confusing, but look at it as a pipeline operator: every function you give it is executed in order.</p>
<p>ElasticSearch aggregation rules are nested, read on to discover why we need <code>NESTED-AGG</code>.</p>
<h3 id="aggs-response">aggs-&gt;response</h3>
<p>This stage loops over response and converts data from ES into API response format. Fortunately most parts of the response are independent, so it’s pretty clean and simple: it’s a loop, which calls <code>extract-agg</code> on every aggregation:</p>
<pre><code>(defn agg-recur [{:keys [doc_count] :as agg}]
  (loop [agg agg]
    (if-let [nested (get agg NESTED-AGG)]
      (recur nested)
      (if-not (:doc_count agg)
        (assoc agg :doc_count doc_count)
        agg))))

(defn aggs-&gt;response [query es-response]
  (for [[k agg] (:aggregations es-response)
     (extract-agg k (agg-recur agg) query))
</code></pre>
<p><code>agg-recur</code> is a way to get to the real data: ES aggregations are very nested. To get through we use key <code>:_nest</code> (value of <code>NESTED-AGG</code>), and then use this <code>agg-recur</code> function.</p>
<p>Unfortunately, there is no good way to pass additional information from <code>make-agg</code> to <code>extract-agg</code>, so it’s stringly-typed, as is <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.x/returning-aggregation-type.html">recommended by ES</a>. Look at our <code>extract-agg</code> multimethod (<code>defmulti</code> defines dispatcher, this is a function which determines which method to call):</p>
<pre><code>(defmulti extract-agg
  (fn [filter-name data query]
    (condp #(str/starts-with? %2 %1) filter-name
      "facet_"      :facet
      "percentile_" :percentile
      "range_"      :range
      :else         filter-name)))
</code></pre>
<p><code>extract-agg</code> methods extract data, sort if necessary (so brands are alphabet-sorted rather than count of matches-sorted), fix up document count (in case of nested aggregations). Here’s an example processing <code>:depot</code>:</p>
<pre><code>(defmethod extract-agg :depot [filter-name agg query]
  (let [cnt (-&gt; agg :real_count :doc_count)]
    [{:id        filter-name
      :widget    :toggle
      :values    [{:key       "true"
                   :doc_count cnt}]
      :doc_count cnt}]))
</code></pre>
<p>That part is pretty simple since you just have to massage data into whatever you need for the API. :)</p>
<h2 id="divide-and-conquer">Divide and conquer</h2>
<p>There is nothing new under the sun. If only the right idea would appear right at the start. :-) Just factor your functions correctly and you’re golden.</p>
<p>In the end what we’ve got is a straightforward pipeline, no parametrization with functions, every chunk of a query is as simple as it gets, and extensibility is just great! It’s been in production for 1.5 years now with no significant changes to the logic, received some new features, and doesn’t feel like it was holding us back.</p>
<p>I hope this post can serve as an inspiration for your code. If you feel confused or have questions, please contact me by email — I would love to make this post more approachable.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/elasticsearch-query-builder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650651</guid>
            <pubDate>Thu, 01 Oct 2020 13:38:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario police used Covid-19 database illegally, civil rights groups find]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 73 (<a href="https://news.ycombinator.com/item?id=24650515">thread link</a>) | @seigando
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5704129.1598642644!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-medium-file-typing-on-laptop.jpg"></p></div><figcaption>The Canadian Civil Liberties Association and the Canadian&nbsp;Constitution Foundation say in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.<!-- --> <!-- -->(maradon 333 / Shutterstock)</figcaption></figure><p><span><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p>  <p>The Canadian Civil Liberties Association (CCLA) and the Canadian&nbsp;Constitution Foundation (CCF) said in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.</p>  <p>"People weren't told that when they went for COVID tests that&nbsp;this information was being shared with police and they certainly weren't asked for their consent," said Abby Deshman, the criminal&nbsp;justice program director for the CCLA.&nbsp;</p>  <p>"That should be a decision every person makes about what they&nbsp;want to do with their own personal medical information."</p>  <p>In early April, the&nbsp;Ontario&nbsp;government passed an emergency order&nbsp;that allowed police to obtain the names, addresses and dates of birth of Ontarians who had tested positive for COVID-19. The portal was aimed at helping to protect first responders.</p>  <p>Police access to that database ended on Aug. 17, after a legal&nbsp;challenge was filed by a group of human rights&nbsp; organizations.</p>  <p>The group, which included the CCLA, argued that allowing police&nbsp;to access personal health records violated individuals'<br> constitutional rights to privacy and equality.</p>  <h2>Police conducted 95,000 searches of database</h2>  <p>Data released in the context of the legal action showed that&nbsp; Ontario&nbsp;police services conducted over 95,000 searches of the&nbsp;database while it was active.</p>  <p>The CCF filed a freedom of information act request to the&nbsp;province related to police use of the database.&nbsp;</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Christine Van Geyn, Canadian Constitution Foundation</cite></span></blockquote>    <p>On Wednesday, the CCF made public a June memo from the Solicitor&nbsp;General's office to chiefs of police that warned against using the&nbsp;database beyond the "express purpose" of the emergency order.</p>  <p>The CCF said the memo revealed a "shocking misuse" of personal&nbsp;health information by police.</p>  <p>"Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities," said CCF litigation director, Christine Van&nbsp;Geyn.&nbsp;<span><ul><li><a href="https://www.cbc.ca/news/canada/toronto/covid-ont-police-database-1.5690220" data-contentid="" flag="" text="Ontario ends police access to COVID-19 database after legal challenge"><span>Ontario ends police access to COVID-19 database after legal challenge</span></a></li></ul></span></p>  <p>The CCF said it has filed a complaint with&nbsp;Ontario's privacy&nbsp;commissioner over violations of the Personal Health Information Protection Act, and with the&nbsp;Ontario&nbsp;Independent Police Review Director for officer misconduct.</p>  <p>Meanwhile, the CCLA sent letters to 37 police forces, asking them&nbsp;for details of how the database was used and if any information was retained from it.</p>  <p>Twenty-three responded and Deshman said she expects more to do&nbsp;so.</p>  <h2>Thunder Bay, Durham police conducted more than 40% of searches</h2>  <p>Many forces found the database difficult to use and resorted to&nbsp;problematic broad searches in an attempt to find workarounds, the CCLA said.</p>  <p>The association notes that more than 40 per cent of the 95,000&nbsp;searches of the database were conducted by either the Thunder Bay police or Durham Region police.&nbsp;</p>    <p>In Durham Region, police continued to run unauthorized searches&nbsp;even after provincial audits called attention to the inappropriate&nbsp;searches taking place, the CCLA said. The force's access to the portal was cut off by the province as a result, the CCLA said.</p>  <p>"Durham is a particularly concerning example," said Deshman.&nbsp;"In those cases there needs to be disclosure (to citizens whose information was accessed) and accountability by following up with the individuals in the police service that looked up information inappropriately."</p>  <h2>Anyone concerned can contact police, privacy commissioner&nbsp;</h2>  <p>Holly Walbourne, the legal counsel for Thunder Bay police, said&nbsp;in a letter sent to the groups that filed the legal challenge that&nbsp;the force understood their concerns but that police had "lawful authority" to use the database to protect first responders.</p>    <p>Durham police Supt. Peter Cousins wrote a report to the force's&nbsp;police services board on the issue on Sept. 1 saying&nbsp; access to theportal and its information was treated "seriously and with due care."&nbsp;</p>  <p>Toronto police never used the database because of "issues with&nbsp;the accuracy and reliability of the information," the CCLA reported. York Region police said they asked the province to revoke access to the database after an internal review found the risks associated with accessing personal health information outweighed any benefits.</p>  <p>Deshman said anyone concerned about police access to the province's COVID-19 database should contact their local police force&nbsp;and the&nbsp;Ontario&nbsp;Privacy Commissioner.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650515</guid>
            <pubDate>Thu, 01 Oct 2020 13:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not PHP?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650385">thread link</a>) | @muglug
<br/>
October 1, 2020 | https://mattbrown.dev/articles/why-not-php | <a href="https://web.archive.org/web/*/https://mattbrown.dev/articles/why-not-php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
                                
                <p>
                    October 1, 2020 - 
                                            4&nbsp;minute&nbsp;read
                                    </p>
                                <!--
	title: Why not PHP?
	date: 2020-10-01
    author: Matt Brown
    author_link: https://twitter.com/mattbrowndev
-->
<p>I was intrigued by <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">Why Not Rust</a>, a list of compelling disadvantages written by someone who uses Rust a lot, and the author of <a href="https://github.com/rust-analyzer/rust-analyzer">a popular Rust static analysis tool</a>. I have a similar relationship to PHP – I use it every day (at <a href="https://vimeo.com/">Vimeo</a>), and I’m the author of <a href="https://psalm.dev/">a popular PHP static analysis tool</a>.</p>
<p>The similarities end there, though – Rust and PHP are very different languages, with very different reputations in the wider programming community. Rust has been getting a lot of hype in the last few years, while PHP has been getting the opposite. Indeed, a lot has been written about PHP from a place of contempt. Here’s my attempt to argue against PHP, but from a place of admiration:</p>
<h2 id="its-mainly-for-serving-simple-http-requests">It’s mainly for serving simple HTTP&nbsp;requests</h2>
<p>PHP was originally designed for the then-nascent world wide web, and its popularity has risen (and, lately, fallen) with the popularity of server-rendered HTML.</p>
<p>Its process model (no shared memory between requests) makes it ideal for serving HTML on a case-by-case basis. If that’s what you’re after, it’s incredibly easy to get started.</p>
<p>On the one hand that means the average PHP programmer never has to worry about memory-related race conditions within a single request, because they simply can’t happen.</p>
<p>But all of PHP’s optimisations for serving individual HTML requests will get in the way if you do, in fact, want to run your own service with shared memory between requests, or any other long-running process. While PHP <em>can</em> do that, its implementation won’t be half as pretty as it would be in a language like Go.</p>
<h2 id="its-relatively-old">It’s (relatively)&nbsp;old</h2>
<p>New programming languages are often a thoughtful combination of languages that came before them. Writing code in a recently-written language can expose you to new idioms, and helps you see the world of programming through a different lens.</p>
<p>PHP is not a new language – it’s 26 years old, and pretty thoroughly-cooked at this point.</p>
<h2 id="no-large-corporate-backers">No large corporate&nbsp;backers</h2>
<p>Some languages come directly from large profitable companies that devote considerable resources to their development (e.g. Go, TypeScript, C#, Swift, Java, Kotlin) while others are sort of adopted by companies (Python at Dropbox, OCaml at Jane St, JS interpreters at Google &amp; Mozilla).</p>
<p>PHP hasn’t had a large corporate backer for a while. As far as I know, only one PHP core engineer is <a href="https://blog.jetbrains.com/phpstorm/2019/01/nikita-popov-joins-phpstorm-team/">paid to work on the language full-time</a>.</p>
<p>Large corporate sponsors can be great for a language. Sponsorship sends a message to other companies that “we trust X to help run our billion-dollar business” and also “if you use X you’ll benefit from the work we’re putting into it”.</p>
<p>PHP’s community is pretty strong, though, and has produced some <a href="https://getcomposer.org/">great</a> <a href="https://phpunit.de/">pieces</a> of <a href="https://symfony.com/">software</a> that have moved the entire ecosystem forward.</p>
<h2 id="many-beginners-few-experts">Many beginners, few&nbsp;experts</h2>
<p>PHP is very easy to get into, and it’s easy to make things in PHP that other people find useful.</p>
<p>PHP’s community is also sort of like a high school, where other language communities (e.g. Rust) are like universities: the teachers in a high school can make you a productive member of society, but if you’re looking to surround yourself with professors who are specialists in things you find interesting, universities are a better bet.</p>
<p>This reputation problem isn’t unique to PHP – other popular interpreted languages like Ruby have it too – but it can deter people who want to feel smart when writing code.</p>
<p>JavaScript had this problem for years, but in the last decade several big internet companies have thrown tons of money at its language ecosystem, and JavaScript experts are now plentiful.</p>
<h2 id="it-has-many-minor-potholes">It has many minor&nbsp;potholes</h2>
<p>API inconsistency comes up repeatedly in peoples’ criticism of PHP. While it’s something the vast majority of PHP developers get used to quickly, there’s no getting around the clunkiness of some core library functions: <code>strpos($haystack, $needle)</code> vs <code>in_array($needle, $haystack)</code> and <code>array_map($callback, $array)</code> vs <code>array_filter($array, $callback)</code>.</p>
<hr>
<h2 id="where-do-we-go-from-here">Where do we go from&nbsp;here?</h2>
<p>People have been predicting its demise for a couple of decades, but PHP’s still a pretty popular option. Why? Despite everything written above, there’s never been a better time to start a new PHP project.</p>
<p>PHP now has a huge ecosystem of open-source packages, and its main download hub has been accessed <a href="https://packagist.org/statistics">over a billion times last month</a> by developers around the world. That’s up roughly 50% from the year before, and doubly impressive once you factor in all the things PHP can do natively.</p>
<p>There’s also good reason to be optimistic about PHP’s future. Ten years ago, things were looking much more dire, but the community has invested a lot of time and effort into improving things:</p>
<ul>
<li>
<strong>Package management</strong><br>
<a href="https://getcomposer.org/">Composer</a>, introduced in 2012, has made setting up a new project a breeze</li>
<li>
<strong>Static analysis</strong><br>
A bunch of great competing static analysis tools (including my own, <a href="https://psalm.dev/">Psalm</a>) have been released in the last five years</li>
<li>
<strong>Raw performance</strong><br>
At Vimeo time spent in PHP itself has roughly halved since we upgraded from PHP 5 to PHP 7. Each new version squeezes out a little more speed, and PHP handily outperforms similar interpreted languages like Ruby, Python and Node</li>
<li>
<strong>Standard ways to write modern PHP</strong><br>
<a href="https://www.php-fig.org/psr/">PSR</a> emerged from a primordial soup of spaghetti code, and now pretty much all modern PHP looks very similar</li>
</ul>
<hr>
<p><a href="https://www.reddit.com/r/PHP/comments/j37zih/why_not_php/">Discuss on /r/php</a></p>
            </article>
        </div></div>]]>
            </description>
            <link>https://mattbrown.dev/articles/why-not-php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650385</guid>
            <pubDate>Thu, 01 Oct 2020 13:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Opposition Leader Navalny on His Poisoning: “Putin Was Behind the Crime”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650372">thread link</a>) | @rerx
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;54d78056-207d-4c6f-b894-b46c2774c039&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;a7cc09e8-f0e0-4cf9-897b-b6411766665d&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg" srcset="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w520_r1.77_fpx58_fpy45.jpg 520w, https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto: <p>Peter Rigaud / DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p>It's six o'clock in the morning on Wednesday when Alexei Navalny shows up at the Berlin editorial office of DER SPIEGEL for an interview. The office is located a few hundred meters from Charité University Hospital, where Navalny spent a month receiving treatment, hovering between life and death.</p>


<div>
<p>Navalny, who was poisoned with the nerve agent Novichok, was only released from the hospital last week.</p><p>Four agents from the State Office of Criminal Investigation (LKA) accompanied him during his visit. Navalny, who wasn't able to walk not long ago, took the stairs to the office rather than the elevator.</p><p>Alexei Navalny, 44, is Russia's most prominent opposition politician. Following the attempt on his life on August 20 in the Siberian city of Tomsk, however, he is now squarely in the international spotlight. German Chancellor Angela Merkel intervened for him to be allowed to leave Russia for treatment in Germany. Because he was poisoned with a substance that can essentially only come from state-run laboratories in Russia, the question of Russian President Vladimir Putin's personal responsibility is one that many around the world are asking. It's not the first time that a Russian opposition politician was to be killed, but it is the first time that the circumstances seem to so clearly point at the Kremlin.</p>
</div>

<div>
<p>The interview with DER SPIEGEL is the first that Navalny has given since the attack. He is alert at the meeting and he remembers many things - and yet the impact of the poisoning is still clear. Scars on his neck show where he was hooked up to a ventilator. When he pours water from the bottle into his glass, it is obvious that it requires effort and he has to use both hands. But he refuses assistance. "My physical therapist says I should try to do everything myself," he says</p><p>Navalny&nbsp;seems more nervous than he did at previous meetings. His face is gaunter and his figure more angular after losing 12 kilos. But his voice is the same as it has always been, as is his humor, his irony. Sitting next to him is his spokeswoman, Kira Yarmysh, who was with him on the plane on August 20 when he first began showing signs of having been poisoned.</p>
</div>

<p>Before the interview begins, he has something he wants to say.</p>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;02a833ee-fba3-4850-98b7-7c4ed3654454&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;49fab9cd-427d-45c0-b178-218dab36c25a&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," width="683" height="498" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," title="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison." alt="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.">
</span>
</span>
</span>
</p><figcaption>
<p>This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.</p>
<span>
Foto: AFP
</span>
</figcaption>
</div>
</div>
</div>
</figure><p><strong>Navalny:</strong> It is important to me that this interview appears in the German press. I have never been closely associated with Germany. I don't know anyone here. I didn't know a single politician. And yet it turned out - you see, my voice is trembling, I have become so emotional - that German politicians and Angela Merkel have taken an interest in my fate and saved my life. The doctors at Charité saved my life a second time and, more importantly, they gave me back my personality. So, the first thing I want to say is: I feel a tremendous gratitude to all Germans. I know it sounds a bit overblown, but Germany has become a special country for me. I had few connections here before and only visited Berlin for the first time three years ago! And then so much human compassion from so many people.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Our readers will be happy to hear that. How are you doing Mr. Navalny?</p><p><strong>Navalny:</strong> Much better than three weeks ago, and it is getting better each day. Not long ago, I could only climb 10 steps, but now I can make it up to the 5th floor. The most important thing for me is that my mental abilities have returned. Well, maybe we will find the opposite to be true during this interview (<em>laughs</em>).</p><p><strong>DER SPIEGEL:</strong> You wrote on Instagram that you are no longer able to stand on one foot.</p><p><strong>Navalny:</strong> Now I can again. My next challenge is to stand on one leg and stretch the other leg forward, which I practice every day. These are actually exercises that ninety-year-olds do in the park.</p><p><strong>DER SPIEGEL:</strong> Are you able to sleep well?</p><p><strong>Navalny:</strong> That's my biggest problem. I used to laugh about people with sleep problems because I never had them myself. But then came the coma, the anesthesia, the weaning off of the sedatives, that long hovering state when I was neither asleep nor awake. I haven't been able to sleep without sleeping pills since.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;ae3d6308-8e23-4f16-b6a0-25e3b742c41c&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;3676fb52-9179-49a0-90c7-57bf91901521&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg" srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," width="683" height="497" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," title="Navalny was flown from Omsk to Berlin on this chartered plane." alt="Navalny was flown from Omsk to Berlin on this chartered plane.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny was flown from Omsk to Berlin on this chartered plane.</p>
<span>
Foto: Kira Yarmysh / dpa
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> When you lost consciousness, you were a figure in Russian politics. When you woke from the coma, you were a global political figure. Chancellor Merkel even visited you at your bedside. What did you talk about?</p><p><strong>Navalny:</strong> That was last week. It was totally unexpected. The door opened, my doctor came in - and Merkel. It was a private meeting with my family - my wife Julia and my son Zahar were there. I can't tell you the details, but we didn't discuss anything secret or sensational. The visit was a gesture. I was impressed by how precisely she knows Russia and my case. She knows some of the details better than I do. She really has a deep understanding of what is going on in Russia. And when you talk to her, you understand why she has been at the top in Germany for so long. I thanked her for her efforts and she said: "I only did my duty."</p><p><strong>DER SPIEGEL:</strong> What has daily life been like for you since you left the hospital? Where are you living?</p><p><strong>Navalny:</strong> I live with my wife and my son here. My daughter has returned to Stanford University. We've rented an apartment. My everyday life is monotonous. I exercise daily - that's all I do. In the morning, I take a walk in the park - that's my job. Then I do the exercises with the doctor. In the evening, I go for another walk. During the day, I try to work on the computer. The doctors say I can be restored to 90 percent of my former self, maybe even 100 percent, but nobody really knows for sure. Basically, I'm a bit of a guinea pig. After all, there aren't many people you can observe who are still alive after being poisoned with a nerve agent. At some point, I will probably be written about in medical journals. And I am happy to share my experiences. Seriously: The Russian leadership has developed such a penchant for poisoning that it is not going to stop doing so anytime soon. My medical history will be instructive.</p><p><strong>DER SPIEGEL:</strong> Going by your posts on social media, it appears that you left your bed in the hospital often.</p><p><strong>Navalny:</strong> The doctors and nurses at Charité are the most tolerant people in the world. I was a difficult patient. I would get up at night in the intensive care unit, and one time I tore all the tubes out of my body and started bleeding. Later, when I was already conscious and could recognize and talk to the people around me, I had hysterical fits. I said I was healthy and wanted to go to a hotel. Weeks later, I understood that this strange behavior was a consequence of the poisoning.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;39d3599b-4262-4232-b6f7-b6016c2162e6&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;98e31d54-2c7e-4689-96a0-cb788f7044e5&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" width="718" height="508" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" title="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital" alt="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital">
</span>
</span>
</span>
</p><figcaption>
<p>A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charité University Hospital</p>
<span>
Foto: Alexei Navalny / ddp media
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> Let's go over what happened to you, and we'll start with your last memory before you lost consciousness. It's August 20, at eight o'clock in the morning. You're sitting in a plane from Tomsk to Moscow. You had spent a few days in Siberia. What was going through your head?</p><p><strong>Navalny:</strong> It was a wonderful day. I'm on my way home, with a strenuous and successful business trip behind me. We shot videos for the regional election campaign, and everything had gone according to plan. I'm sitting comfortably in my seat and I'm looking forward to a quiet flight during which I can watch a series. Once I get back to Moscow, I am looking forward to recording my weekly YouTube show and then spending the weekend with my family. I feel good, as I did at the airport. And then… it's hard to describe because there is nothing to compare it with. Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you. You can no longer concentrate. I can feel that something is&nbsp;wrong. I break out in a cold sweat. I ask Kira beside me for a tissue. Then I say to her: Speak to me. I need to hear a voice - something's wrong with me. She looks at me like I'm crazy and starts talking.</p><p><strong>DER SPIEGEL:</strong> What happened then?</p><p><strong>Navalny:</strong> I don't understand what is happening to me. The stewards come by with the trolley. I first want to ask them for water, but I then say: No, let me by, I'm going to the bathroom. I wash myself with cold water, sit down and wait and then wash myself again. And then I think: If I don't get out now, I'll never get out. The most important feeling was: You are feeling no pain, but you know you're dying. And I mean, right now, yet nothing hurts. I leave the toilet, turn to the steward - and instead of asking for help, I say, to my own surprise: "I've been poisoned. I'm dying." And then I lay down on the ground in front of him to die. He’s the last thing I see - a face that looks at me with slight astonishment and a light smile. He says: "Poisoned?" and by that he probably means I was served bad chicken.</p><p>And the last thing I hear, already on the floor is: Do you have heart problems? But my heart doesn't hurt. Nothing hurts. All I know is that I am dying. Then I hear voices growing ever quieter, and a woman calling: "Don't leave us! Don't leave us!" Then it's over. I know I'm dead. Only later would it turn out that I was wrong.</p><p><strong>DER SPIEGEL:</strong> There's a video shot by a passenger in which your screams can be heard on the plane. It sounds horrible, almost like the cries of an animal.</p><p><strong>Navalny:</strong> I've watched it - it's circulating on the internet under the title: "Navalny screaming in pain." But it wasn't pain. It was something else, worse. Pain makes you feel like you're alive. But in this case, you sense: This is the end.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;fe4efb86-8391-4038-9e36-19f7e61bb096&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;05a17892-8960-486b-a336-d5ca15581d1f&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg" srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," width="655" height="757" sizes="655px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," title="Navalny posted photos of himself on Instagram showing him on the balcony of his room." alt="Navalny posted photos of himself on Instagram showing him on the balcony of his room.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny posted photos of himself on Instagram showing him on the …</p></figcaption></div></div></div></figure></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650372</guid>
            <pubDate>Thu, 01 Oct 2020 13:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China forces international birding organization to eject Taiwan, gags employees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650128">thread link</a>) | @ilamont
<br/>
October 1, 2020 | https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/ | <a href="https://web.archive.org/web/*/https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<hr>



<p><strong>The&nbsp;</strong><a href="https://www.theguardian.com/world/2020/sep/25/hawk-or-dove-birdwatching-worlds-feathers-ruffled-over-taiwan-independence"><strong>ejection</strong></a><strong>&nbsp;of Taiwan’s Chinese Wild Bird Federation (CWBF) from BirdLife International and the subsequent&nbsp;</strong><a href="https://www.reuters.com/article/us-taiwan-environment-politics/british-bird-group-issues-gag-order-over-taiwan-china-issue-idUSKBN2690BX"><strong>gag order</strong></a><strong>&nbsp;asking BirdLife employees to refrain from speaking to the press may appear at first glance to be the smallest of China’s many micro-aggressions, but is indicative of a serious security threat.&nbsp;</strong></p>



<hr>



<p>BirdLife notified the CWBF on September 7 that their 24-year-old partnership had ended. The reason? BirdLife asked the Taiwanese partner to change their official Chinese name and to sign a document promising to neither promote the independence of Taiwan from China nor to advocate the legitimacy of the Republic of China (Taiwan’s official name). It didn’t matter that the Federation had never taken a political stance on Taiwan’s status. It didn’t matter that they had already changed their English name three times at the behest of BirdLife, even twisting facts to alter the name from “Wild Bird Federation Taiwan” to “Chinese Wild Bird Federation” in 2007. BirdLife wouldn’t even give them time, as a democratically run NGO, to debate this at the Annual General Meeting. They simply kicked them out of the nest.&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/29/mbss-admits-full-responsibility-for-the-khashoggi-murder-what-this-means-for-the-kingdoms-allies/"><strong>🏅2020 CIPS Blog Award Winner! MBS admits “full responsibility” for the Khashoggi murder: What this means for the Kingdom’s allies</strong></a></p>



<hr>



<p>Taiwan protested. The&nbsp;<a href="https://focustaiwan.tw/politics/202009150029">Ministry of Foreign Affairs</a>&nbsp;condemned China for interfering in international conservation NGOs and BirdLife for cooperating with China to coerce the CWBF into taking a political stance.&nbsp;On September 19, the General Assembly of the CWBF decided to finally revert to the more accurate name in English as the&nbsp;<a href="https://www.bird.org.tw/news/602?fbclid=IwAR1RgQoW9nXgZCHRBxlGgr7qamTs_nRhbUyffndt5WEbziqkX92HmKTIdDA">Taiwan Wild Bird Federation</a>.&nbsp;</p>



<p><strong>What is BirdLife?</strong></p>



<p>BirdLife, a global coalition of scientific and conservation NGOs, is active in Canada through Nature Canada and Birds Canada. It coordinates the IBA (Important Bird and Biodiversity Areas) program that identifies and manages important bird habitat sites. Because birds do not respect borders, collaboration between countries is central to BirdLife’s mandate. Since 2000, Taiwan’s Forestry Bureau has contributed to BirdLife conservation projects in Madagascar, Cambodia, and Sao Tome.&nbsp;</p>



<p>Taiwan is second only to Japan in Asia for bird conservation and scientific research. Taiwan hosts 682 bird species, 29 endemic species, and 43 endangered species. Taiwanese birders are active contributors to eBird, the world’s most comprehensive citizen science project in ornithology. The CWBF does important work to protect the Chinese Crested Tern and Black-faced Spoonbill. In 2020, the 4,864 Black-faced Spoonbills that wintered in Taiwan accounted for 57.3% of the population of that endangered species. Migratory birds along the East Asian-Australasian Flyway depend on Taiwan because of its strategic location on their pathways that stretch from Siberia to Australia. Taiwan’s expulsion from BirdLife will hinder cross-border cooperation on conservation, just because China prioritizes its political goals over even pragmatic scientific cooperation. China makes everything into a zero-sum game.&nbsp;</p>



<figure><p>
https://twitter.com/TaiwanBirding/status/1309409778393776128?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1309409778393776128%7Ctwgr%5Eshare_3&amp;ref_url=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2FTaiwanBirding2Fstatus2F1309409778393776128widget%3DTweet
</p></figure>



<p><strong>China Curtails Freedom of International Civil Society</strong></p>



<p>BirdLife is a dangerous precedent for other NGOs. Because China can pressure one leading NGO into cutting out Taiwan, they will feel emboldened to go after other NGOs – including in Canada. NGOs hoping to expand into China will hesitate to build partnerships with Taiwan. This is a shame because Taiwanese NGOs have strong expertise as well as the financial means to get things done. It is even more unfortunate because democratic Taiwan, like Canada, actually has real social movements run by civilians without government interference. China, on the other hand, strictly limits the freedoms of Chinese NGOs. Since 2017, when China changed its NGO regulations in line with broader security-related legislation, international NGOs have been required to register with the Ministry of Public Security and must have an approved local partner. This means the Chinese Communist Party can use NGOs to export their standards to the world.&nbsp;</p>



<p>Until now, China has not permitted BirdLife to enter China, which means the closest they get is collaboration with the Hong Kong Birdwatching Society. Maybe that is the point. Quite possibly, BirdLife is negotiating with China and took action against Taiwan as a precondition for collaboration. The cost is high. It means letting China dictate the norms of how international NGOs operate. BirdLife even imported Chinese norms on media freedom by issuing a gag order to their employees. And this is in Great Britain, which takes pride in the Magna Charta as one of the founding documents of democracy.&nbsp;</p>



<p>Because of China’s sheer size and long coastlines used by migratory birds, BirdLife is badly needed in China. International bird conservation would improve if China were to open up its own borders to free, unfettered cooperation between Chinese and international NGOs. Bird habitats along migration routes would be best protected if China were to set aside politics and collaborate with Taiwanese ornithologists and conservation scientists&nbsp;&nbsp;like Japan and Russia do in spite of long-standing territorial disputes that straddle bird habitats.&nbsp;&nbsp;</p>



<p><strong>The Bigger Picture</strong></p>



<p>China’s pressure on BirdLife is part of a new strategy. For decades, BirdLife’s Taiwanese partner could simply accept a compromise name of “Chinese Wild Bird Federation” internationally; and “Republic of China Wild Bird Federation” at home. BirdLife and the CWBF could collaborate as long as they remained silent about China-Taiwan relations. The most troubling sign is not the requested name change, but the fact that the CWBF was asked to commit themselves to a political stance. China is trying to shape a world in which even silence is not an option. China’s goal is to get the entire world to parrot its claims that Taiwan is part of the People’s Republic of China. This must be seen as part of a larger strategy in which the Chinese military during a global pandemic feels emboldened to practice invasion of Taiwan and to regularly send jets into Taiwanese airspace.&nbsp;</p>



<p>BirdLife should be reminding the world that coastal birds inhabiting wetlands along the Taiwan Straits would be the first victims if China were to ever invade Taiwan. Instead, their abandonment of the Taiwan Wild Bird Federation gives Beijing one more sign that the world does not oppose their strategy to annex Taiwan. Acquiescing to Chinese micro-management of international NGOs is not good for the birds and, in the long run, it is dangerous for the security of the entire region.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/27/twitter-conference-understanding-the-five-eyes/"><strong>Twitter Conference: Understanding the Five Eyes</strong></a></p>




</div></div></div>]]>
            </description>
            <link>https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650128</guid>
            <pubDate>Thu, 01 Oct 2020 12:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segment Tree]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24650084">thread link</a>) | @pmoriarty
<br/>
October 1, 2020 | https://cp-algorithms.com/data_structures/segment_tree.html | <a href="https://web.archive.org/web/*/https://cp-algorithms.com/data_structures/segment_tree.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    


<p>A Segment Tree is a data structure that allows answering range queries over an array effectively, while still being flexible enough to allow modifying the array. 
This includes finding the sum of consecutive array elements $a[l \dots r]$, or finding the minimum element in a such a range in $O(\log n)$ time. 
Between answering such queries the Segment Tree allows modifying the array by replacing one element, or even change the elements of a whole subsegment (e.g. assigning all elements $a[l \dots r]$ to any value, or adding a value to all element in the subsegment).</p>

<p>In general a Segment Tree is a very flexible data structure, and a huge number of problems can be solved with it. 
Additionally it is also possible to apply more complex operations and answer more complex queries (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#advanced-versions-of-segment-trees">Advanced versions of Segment Trees</a>).
In particular the Segment Tree can be easily generalized to larger dimensions. 
For instance with a two-dimensional Segment Tree you can answer sum or minimum queries over some subrectangle of a given matrix.
However only in $O(\log^2 n)$ time.</p>

<p>One important property of Segment Trees is, that they require only a linear amount of memory.
The standard Segment Tree requires $4n$ vertices for working on an array of size $n$.</p>

<h2>Simplest form of a Segment Tree</h2>

<p>To start easy, we consider the simplest form of a Segment Tree. 
We want to answer sum queries efficiently. 
The formal definition of our task is:
We have an array $a[0 \dots n-1]$, and the Segment Tree must be able to find the sum of elements between the indices $l$ and $r$ (i.e. computing the sum $\sum_{i=l}^r a[i]$), and also handle changing values of the elements in the array (i.e. perform assignments of the form $a[i] = x$). 
The Segment Tree should be able to process both queries in $O(\log n)$ time.</p>

<h3>Structure of the Segment Tree</h3>

<p>So, what is a Segment Tree?</p>

<p>We compute and store the sum of the elements of the whole array, i.e. the sum of the segment $a[0 \dots n-1]$. 
We then split the array into two halves $a[0 \dots n/2]$ and $a[n/2+1 \dots n-1]$ and compute the sum of each halve and store them. 
Each of these two halves in turn also split in half, their sums are computed and stored. 
And this process repeats until all segments reach size $1$. 
In other words we start with the segment $a[0 \dots n-1]$, split the current segment in half (if it has not yet become a segment containing a single element), and then calling the same procedure for both halves. 
For each such segment we store the sum of the numbers on it.</p>

<p>We can say, that these segments form a binary tree: 
the root of this tree is the segment $a[0 \dots n-1]$, and each vertex (except leaf vertices) has exactly two child vertices. 
This is why the data structure is called "Segment Tree", even though in most implementations the tree is not constructed explicitly (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#implementation">Implementation</a>).</p>

<p>Here is a visual representation of such a Segment Tree over the array $a = [1, 3, -2, 8, -7]$:</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree.png" alt="&quot;Sum Segment Tree&quot;"></p>

<p>From this short description of the data structure, we can already conclude that a Segment Tree only requires a linear number of vertices. 
The first level of the tree contains a single node (the root), the second level will contain two vertices, in the third it will contain four vertices, until the number of vertices reaches $n$. 
Thus the number of vertices in the worst case can be estimated by the sum $1 + 2 + 4 + \dots + 2^{\lceil\log_2 n\rceil} = 2^{\lceil\log_2 n\rceil + 1} \lt 4n$.</p>

<p>It is worth noting that whenever $n$ is not a power of two, not all levels of the Segment Tree will be completely filled. 
We can see that behavior in the image.
For now we can forget about this fact, but it will become important later during the implementation.</p>

<p>The height of the Segment Tree is $O(\log n)$, because when going down from the root to the leaves the size of the segments decreases approximately by half.</p>

<h3>Construction</h3>

<p>Before constructing the segment tree, we need to decide:</p>

<ol>
<li>the <em>value</em> that gets stored at each node of the segment tree.
For example, in a sum segment tree, a node would store the sum of the elements in its range $[l, r]$.</li>
<li>the <em>merge</em> operation that merges two siblings in a segment tree.
For example, in a sum segment tree, the two nodes corresponding to the ranges $a[l_1 \dots r_1]$ and $a[l_2 \dots r_2]$ would be merged into a node corresponding to the range $a[l_1 \dots r_2]$ by adding the values of the two nodes.</li>
</ol>

<p>Note that a vertex is a "leaf vertex", if its corresponding segment covers only one value in the original array. It is present at the lowermost level of a segment tree. Its value would be equal to the (corresponding) element $a[i]$.</p>

<p>Now, for construction of the segment tree, we start at the bottom level (the leaf vertices) and assign them their respective values. On the basis of these values, we can compute the values of the previous level, using the <code>merge</code> function.
And on the basis of those, we can compute the values of the previous, and repeat the procedure until we reach the root vertex.</p>

<p>It is convenient to describe this operation recursively in the other direction, i.e., from the root vertex to the leaf vertices. The construction procedure, if called on a non-leaf vertex, does the following:</p>

<ol>
<li>recursively construct the values of the two child vertices</li>
<li>merge the computed values of these children.</li>
</ol>

<p>We start the construction at the root vertex, and hence, we are able to compute the entire segment tree.</p>

<p>The time complexity of this construction is $O(n)$, assuming that the merge operation is constant time (the merge operation gets called $n$ times, which is equal to the number of internal nodes in the segment tree).</p>

<h3>Sum queries</h3>

<p>For now we are going to answer sum queries. As an input we receive two integers $l$ and $r$, and we have to compute the sum of the segment $a[l \dots r]$ in $O(\log n)$ time.</p>

<p>To do this, we will traverse the Segment Tree and use the precomputed sums of the segments.
Let's assume that we are currently at the vertex that covers the segment $a[tl \dots tr]$.
There are three possible cases.</p>

<p>The easiest case is when the segment $a[l \dots r]$ is equal to the corresponding segment of the current vertex (i.e. $a[l \dots r] = a[tl \dots tr]$), then we are finished and can return the precomputed sum that is stored in the vertex.</p>

<p>Alternatively the segment of the query can fall completely into the domain of either the left or the right child.
Recall that the left child covers the segment $a[tl \dots tm]$ and the right vertex covers the segment $a[tm + 1 \dots tr]$ with $tm = (tl + tr) / 2$. 
In this case we can simply go to the child vertex, which corresponding segment covers the query segment, and execute the algorithm described here with that vertex.</p>

<p>And then there is the last case, the query segment intersects with both children. 
In this case we have no other option as to make two recursive calls, one for each child.
First we go to the left child, compute a partial answer for this vertex (i.e. the sum of values of the intersection between the segment of the query and the segment of the left child), then go to the right child, compute the partial answer using that vertex, and then combine the answers by adding them. 
In other words, since the left child represents the segment $a[tl \dots tm]$ and the right child the segment $a[tm+1 \dots tr]$, we compute the sum query $a[l \dots tm]$ using the left child, and the sum query $a[tm+1 \dots r]$ using the right child.</p>

<p>So processing a sum query is a function that recursively calls itself once with either the left or the right child (without changing the query boundaries), or twice, once for the left and once for the right child (by splitting the query into two subqueries). 
And the recursion ends, whenever the boundaries of the current query segment coincides with the boundaries of the segment of the current vertex. 
In that case the answer will be the precomputed value of the sum of this segment, which is stored in the tree.</p>

<p>In other words, the calculation of the query is a traversal of the tree, which spreads through all necessary branches of the tree, and uses the precomputed sum values of the segments in the tree.</p>

<p>Obviously we will start the traversal from the root vertex of the Segment Tree.</p>

<p>The procedure is illustrated in the following image.
Again the array $a = [1, 3, -2, 8, -7]$ is used, and here we want to compute the sum $\sum_{i=2}^4 a[i]$.
The colored vertices will be visited, and we will use the precomputed values of the green vertices.
This gives us the result $-2 + 1 = -1$.</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree-query.png" alt="&quot;Sum Segment Tree Query&quot;"></p>

<p>Why is the complexity of this algorithm $O(\log n)$?
To show this complexity we look at each level of the tree. 
It turns out, that for each level we only visit not more than four vertices. 
And since the height of the tree is $O(\log n)$, we receive the desired running time.</p>

<p>We can show that this proposition (at most four vertices each level) is true by induction.
At the first level, we only visit one vertex, the root vertex, so here we visit less than four vertices. 
Now let's look at an arbitrary level.
By induction hypothesis, we visit at most four vertices. 
If we only visit at most two vertices, the next level has at most four vertices. That trivial, because each vertex can only cause at most two recursive calls. 
So let's assume that we visit three or four vertices in the current level. 
From those vertices, we will analyze the vertices in the middle more carefully. 
Since the sum query asks for the sum of a continuous subarray, we know that segments corresponding to the visited vertices in the middle will be completely covered by the segment of the sum query. 
Therefore these vertices will not make any recursive calls. 
So only the most left, and the most right vertex will have the potential to make recursive calls. 
And those will only create at most four recursive calls, so also the next level will satisfy the assertion.
We can say that one branch approaches the left boundary of the query, and the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cp-algorithms.com/data_structures/segment_tree.html">https://cp-algorithms.com/data_structures/segment_tree.html</a></em></p>]]>
            </description>
            <link>https://cp-algorithms.com/data_structures/segment_tree.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650084</guid>
            <pubDate>Thu, 01 Oct 2020 12:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIT new large tokamak to be the first in history to do self-sustaining reaction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650030">thread link</a>) | @vermontdevil
<br/>
October 1, 2020 | https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/ | <a href="https://web.archive.org/web/*/https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Scientists at the Massachusetts Institute of Technology <a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?smtyp=cur&amp;smid=tw-nytimes&amp;utm_source=Default+audience&amp;utm_campaign=88af7df3e9-EMAIL_CAMPAIGN_2020_09_29_06_13&amp;utm_medium=email&amp;utm_term=0_3cb9478f4c-88af7df3e9-193252502" target="_blank">are developing</a> a type of reactor, called a tokamak, which if it works as intended will generate conditions of sufficient intensity to fuse hydrogen isotopes and harness all the incredible energy released in the process. Their goal is super ambitious: There are other tokamaks, but the MIT scientists expect their large tokamak to be the first in history that is capable of a self-sustaining reaction, and the first that generates more energy than it uses. And they expect to pivot immediately from this historic engineering feat to commercial energy production, and to do all of this on a relatively modest budget, and on a timeline of just three to four years. They expect, in other words, to build the world’s first fully operational thermonuclear fusion reactor, pumping out infinitely sustainable energy right here in the U.S. of A.</p>



<p>I expect to walk up to this tokamak, engage the help of several brawny nuclear engineers, and to be hurled bodily into the inconceivable heat and indescribable beauty of the radiant plasma cloud magnetically suspended in its core, so that I am instantaneously vaporized and eradicated altogether from this plane of existence. The sooner the better.</p>



<p>Initially it seemed that the best choice for this job would be the International Thermonuclear Experimental Reactor, or ITER, in Provence, France. Whereas the <a href="https://www.psfc.mit.edu/sparc" target="_blank">SPARC tokamak</a> being developed by MIT will be the size of a tennis court, <a href="https://www.iter.org/mach" target="_blank">the ITER</a>, which has been in various phases of development and construction for something like 13 years, will eventually be the size of a soccer field. The specs on this thing <a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">are mind-boggling</a>:</p>



<blockquote><p>At its core, densely packed high-precision equipment will encase a cavernous vacuum chamber, in which a super-hot cloud of heavy hydrogen will rotate faster than the speed of sound, twisting like a strand of DNA as it circulates. The cloud will be scorched by electric current (a surge so forceful that it will make lightning seem like a tiny arc of static electricity), and bombarded by concentrated waves of radiation. Beams of uncharged particles—the energy in them so great it could vaporize a car in seconds—will pour into the chamber, adding tremendous heat. In this way, the circulating hydrogen will become ionized, and achieve temperatures exceeding two hundred million degrees Celsius—more than ten times as hot as the sun at its blazing core.</p><cite>&nbsp;Raffi Khatchadourian, <em><a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">The New Yorker</a></em></cite></blockquote>



<p>“Tremendous heat” is an understatement of brain-scrambling, laugh-out-loud proportions. This cloud of plasma will be so hot that no physical substance on Earth or known to humankind could contain it for even a fraction of a second: “Metals, plastics, ceramics, concrete, even pure diamond—all would be obliterated on contact.” The only way to keep the plasma cloud in place, and thus concentrated enough to trigger nuclear fusion, is to squeeze it into a pocket of space using the “titanic forces” of “the largest system of superconducting magnets in the world,” actively cooled to deep-space temperatures in order to survive the heat of an actual star.</p>



<p>So in an ultra-secure chamber in a pit in the countryside of Provence, a blob of the hottest substance in our entire solar system will hang in the air, consuming hydrogen isotopes and generating enough energy to turn diamonds into vapor on contact. There are those who would point out that it is probably a bad idea to let humanity just have the Sun, that inevitably some technician is going to want to pull a viral YouTube prank by aiming a beam of the God Cloud at his buddy’s balls and wind up boring a hole through the planet itself. Or that a janitor will absentmindedly unplug the supercooling systems that allow the mega-magnets to contain the reaction and accidentally atomize the Western Hemisphere. Those people are probably right. Humanity can’t be counted upon to safely handle livestock—putting it in charge of a star seems like something that should not be allowed, by the universe.</p>



<p>But since we are building these things anyway, all I ask is that I be lifted by the scruff of my shirt and the seat of my pants by two strong nuclear technicians and, on the count of three, heaved face-first into whichever of the two God Clouds is completed first. It’s nice to think of all my atoms instantly dispersing into the fabric of the universe, but mostly it will be extremely bitchin’ to be devoured by a star. If this cannot be arranged for whatever reason, I will accept having a beam of the star juice fired into my chest, so that I may utter “fuck yeah” before it is over.</p>
</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650030</guid>
            <pubDate>Thu, 01 Oct 2020 12:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Neural Network API]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24649616">thread link</a>) | @rajveermalviya
<br/>
October 1, 2020 | https://webmachinelearning.github.io/webnn/ | <a href="https://web.archive.org/web/*/https://webmachinelearning.github.io/webnn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>We’re working on this section. Meanwhile, please take a look at the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.</p>
   <h2 data-level="2" id="usecases"><span>2. </span><span>Use cases</span><a href="#usecases"></a></h2>
   <h3 data-level="2.1" id="usecases-application"><span>2.1. </span><span>Application Use Cases</span><a href="#usecases-application"></a></h3>
   <p>This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) models.</p>
   <h4 data-level="2.1.1" id="usecase-person-detection"><span>2.1.1. </span><span>Person Detection</span><a href="#usecase-person-detection"></a></h4>
   <p>A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a> or <a data-link-type="biblio" href="#biblio-yolo">[YOLO]</a> that use a single DNN) to detect regions in a camera
input frame that include persons.</p>
   <p>When she comes back, the application automatically detects her and notifies
other online users that she is active now.</p>
   <h4 data-level="2.1.2" id="usecase-segmentation"><span>2.1.2. </span><span>Semantic Segmentation</span><a href="#usecase-segmentation"></a></h4>
   <p>A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as <a data-link-type="biblio" href="#biblio-deeplabv3">[DeepLabv3+]</a> or <a data-link-type="biblio" href="#biblio-maskr-cnn">[MaskR-CNN]</a> to semantically split an image into segments and replaces
segments that represent other people and background with another picture.</p>
   <h4 data-level="2.1.3" id="usecase-skeleton-detection"><span>2.1.3. </span><span>Skeleton Detection</span><a href="#usecase-skeleton-detection"></a></h4>
   <p>A web-based video conferencing application tracks a pose of user’s skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as <a data-link-type="biblio" href="#biblio-posenet">[PoseNet]</a> to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.</p>
   <h4 data-level="2.1.4" id="usecase-face-recognition"><span>2.1.4. </span><span>Face Recognition</span><a href="#usecase-face-recognition"></a></h4>
   <p>There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a>) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as <a data-link-type="biblio" href="#biblio-facenet">[FaceNet]</a>,
which verifies whether two faces would be identical or not.</p>
   <h4 data-level="2.1.5" id="usecase-facial-landmarks"><span>2.1.5. </span><span>Facial Landmark Detection</span><a href="#usecase-facial-landmarks"></a></h4>
   <p>A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network <a data-link-type="biblio" href="#biblio-fan">[FAN]</a> to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly render the selected glasses on the detected position of eyes on her
facial image.</p>
   <h4 data-level="2.1.6" id="usecase-style-transfer"><span>2.1.6. </span><span>Style Transfer</span><a href="#usecase-style-transfer"></a></h4>
   <p>A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like <a data-link-type="biblio" href="#biblio-contextualloss">[ContextualLoss]</a> or <a data-link-type="biblio" href="#biblio-pairedcyclegan">[PairedCycleGAN]</a> to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.</p>
   <h4 data-level="2.1.7" id="usecase-super-resolution"><span>2.1.7. </span><span>Super Resolution</span><a href="#usecase-super-resolution"></a></h4>
   <p>A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as <a data-link-type="biblio" href="#biblio-srgan">[SRGAN]</a> to generate
higher-resolution video frames.</p>
   <h4 data-level="2.1.8" id="usecase-image-captioning"><span>2.1.8. </span><span>Image Captioning</span><a href="#usecase-image-captioning"></a></h4>
   <p>For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as <a data-link-type="biblio" href="#biblio-im2txt">[im2txt]</a> which predicts explanatory words of the presentation slides.</p>
   <h4 data-level="2.1.9" id="usecase-translation"><span>2.1.9. </span><span>Machine Translation</span><a href="#usecase-translation"></a></h4>
   <p>Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as <a data-link-type="biblio" href="#biblio-gnmt">[GNMT]</a> or <a data-link-type="biblio" href="#biblio-opennmt">[OpenNMT]</a>, which translates every
text into different language.</p>
   <h4 data-level="2.1.10" id="usecase-emotion-analysis"><span>2.1.10. </span><span>Emotion Analysis</span><a href="#usecase-emotion-analysis"></a></h4>
   <p>A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend’s
face. The application analyses the friend’s emotion by using a machine learning
model such as <a data-link-type="biblio" href="#biblio-deepmoji">[DeepMoji]</a>, which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.</p>
   <h4 data-level="2.1.11" id="usecase-video-summalization"><span>2.1.11. </span><span>Video Summarization</span><a href="#usecase-video-summalization"></a></h4>
   <p>A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as <a data-link-type="biblio" href="#biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]</a>.</p>
   <h4 data-level="2.1.12" id="usecase-noise-suppression"><span>2.1.12. </span><span>Noise Suppression</span><a href="#usecase-noise-suppression"></a></h4>
   <p>A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time 
noise suppression using Recurrent Neural Network such as <a data-link-type="biblio" href="#biblio-rnnoise">[RNNoise]</a> for 
suppressing background dynamic noise like baby cry or dog barking to improve 
audio experiences in video conferences.</p>
   <h3 data-level="2.2" id="usecases-framework"><span>2.2. </span><span>Framework Use Cases</span><a href="#usecases-framework"></a></h3>
   <p>This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.</p>
   <h4 data-level="2.2.1" id="usecase-custom-layer"><span>2.2.1. </span><span>Custom Layer</span><a href="#usecase-custom-layer"></a></h4>
   <p>A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like <a data-link-type="biblio" href="#biblio-leakyrelu">[LeakyReLU]</a>, <a data-link-type="biblio" href="#biblio-elu">[ELU]</a>,
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.</p>
   <h4 data-level="2.2.2" id="usecase-network-concat"><span>2.2.2. </span><span>Network Concatenation</span><a href="#usecase-network-concat"></a></h4>
   <p>A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.</p>
   <p>Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.</p>
   <h4 data-level="2.2.3" id="usecase-perf-adapt"><span>2.2.3. </span><span>Performance Adaptation</span><a href="#usecase-perf-adapt"></a></h4>
   <p>A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.</p>
   <p>After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.</p>
   <h2 data-level="3" id="api"><span>3. </span><span>API</span><a href="#api"></a></h2>
   <h3 data-level="3.1" id="api-navigator"><span>3.1. </span><span>Navigator</span><a href="#api-navigator"></a></h3>
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator" id="ref-for-navigator"><c- g="">Navigator</c-></a> {
  <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="idl-name" href="#ml" id="ref-for-ml"><c- n="">ML</c-></a> <dfn data-dfn-for="Navigator" data-dfn-type="attribute" data-export="" data-readonly="" data-type="ML" id="dom-navigator-ml"><code><c- g="">ml</c-></code><a href="#dom-navigator-ml"></a></dfn>;
};
</pre>
   <h3 data-level="3.2" id="api-ml"><span>3.2. </span><span>ML</span><a href="#api-ml"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="ml"><code><c- g="">ML</c-></code></dfn> {
  <a data-link-type="idl-name" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext"><c- n="">NeuralNetworkContext</c-></a> <dfn data-dfn-for="ML" data-dfn-type="method" data-export="" data-lt="getNeuralNetworkContext()" id="dom-ml-getneuralnetworkcontext"><code><c- g="">getNeuralNetworkContext</c-></code><a href="#dom-ml-getneuralnetworkcontext"></a></dfn>();
};
</pre>
   <h3 data-level="3.3" id="api-operanddescriptor"><span>3.3. </span><span>OperandDescriptor</span><a href="#api-operanddescriptor"></a></h3>
<pre><c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandlayout"><code><c- g="">OperandLayout</c-></code></dfn> {
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nchw"><code><c- s="">"nchw"</c-></code><a href="#dom-operandlayout-nchw"></a></dfn>,
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nhwc"><code><c- s="">"nhwc"</c-></code><a href="#dom-operandlayout-nhwc"></a></dfn>
};

<c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandtype"><code><c- g="">OperandType</c-></code></dfn> {
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float32"><code><c- s="">"float32"</c-></code><a href="#dom-operandtype-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float16"><code><c- s="">"float16"</c-></code><a href="#dom-operandtype-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-int32"><code><c- s="">"int32"</c-></code><a href="#dom-operandtype-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-uint32"><code><c- s="">"uint32"</c-></code><a href="#dom-operandtype-uint32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float32"><code><c- s="">"tensor-float32"</c-></code><a href="#dom-operandtype-tensor-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float16"><code><c- s="">"tensor-float16"</c-></code><a href="#dom-operandtype-tensor-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-int32"><code><c- s="">"tensor-int32"</c-></code><a href="#dom-operandtype-tensor-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-quant8-asymm"><code><c- s="">"tensor-quant8-asymm"</c-></code><a href="#dom-operandtype-tensor-quant8-asymm"></a></dfn>
};

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-operanddescriptor"><code><c- g="">OperandDescriptor</c-></code></dfn> {
  // The operand type.
  <c- b="">required</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype"><c- n="">OperandType</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="OperandType " id="dom-operanddescriptor-type"><code><c- g="">type</c-></code><a href="#dom-operanddescriptor-type"></a></dfn>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b="">sequence</c->&lt;<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long"><c- b="">long</c-></a>&gt; <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="sequence<long> " id="dom-operanddescriptor-dimensions"><code><c- g="">dimensions</c-></code><a href="#dom-operanddescriptor-dimensions"></a></dfn>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float"><c- b="">float</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="float " id="dom-operanddescriptor-scale"><code><c- g="">scale</c-></code><a href="#dom-operanddescriptor-scale"></a></dfn>;
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①"><c- b="">long</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="long " id="dom-operanddescriptor-zeropoint"><code><c- g="">zeroPoint</c-></code><a href="#dom-operanddescriptor-zeropoint"></a></dfn>;
};
</pre>
   <h3 data-level="3.4" id="api-operand"><span>3.4. </span><span>Operand</span><a href="#api-operand"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="operand"><code><c- g="">Operand</c-></code></dfn> {};
</pre>
   <h3 data-level="3.5" id="api-neuralnetworkcontext"><span>3.5. </span><span>NeuralNetworkContext</span><a href="#api-neuralnetworkcontext"></a></h3>
   <p>The <code><a data-link-type="idl" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①">NeuralNetworkContext</a></code> defines a set of operations derived from the first-wave models <a data-link-type="biblio" href="#biblio-models">[Models]</a> that address identified <a href="#usecases">§ 2 Use cases</a>.</p>
<pre><c- b="">typedef</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double" id="ref-for-idl-double"><c- b="">double</c-></a> <dfn data-dfn-type="typedef" data-export="" id="typedefdef-number"><code><c- g="">number</c-></code></dfn>;

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-namedoperand"><code><c- g="">NamedOperand</c-></code></dfn> {
  <c- b="">required</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="DOMString " id="dom-namedoperand-name"><code><c- g="">name</c-></code><a href="#dom-namedoperand-name"></a></dfn>;
  <c- b="">required</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand"><c- n="">Operand</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="Operand " id="dom-namedoperand-operand"><code><c- g="">operand</c-></code><a href="#dom-namedoperand-operand"></a></dfn>;
};

<c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="neuralnetworkcontext"><code><c- g="">NeuralNetworkContext</c-></code></dfn> {
  // Create an Operand object that represents a model input.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand①"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="input(name, desc)" id="dom-neuralnetworkcontext-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-input"></a></dfn>(<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString①"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-name"><code><c- g="">name</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-name"></a></dfn>, <a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-desc"></a></dfn>);

  // Create an Operand object that represents a model constant.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand②"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(desc, value)" id="dom-neuralnetworkcontext-constant"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant"></a></dfn>(<a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor①"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-desc"></a></dfn>, <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView"><c- n="">ArrayBufferView</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-value"></a></dfn>);

  // Create a single-value tensor from the specified number of the specified type.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand③"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(value, type)|constant(value)" id="dom-neuralnetworkcontext-constant-value-type"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type"></a></dfn>(<a data-link-type="idl-name" href="#typedefdef-number" id="ref-for-typedefdef-number"><c- n="">number</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-value"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype①"><c- n="">OperandType</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-type"><code><c- g="">type</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-type"></a></dfn> = "float32");

  // Create a Model object by identifying output operands.
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#model" id="ref-for-model"><c- n="">Model</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="createModel(outputs)" id="dom-neuralnetworkcontext-createmodel"><code><c- g="">createModel</c-></code><a href="#dom-neuralnetworkcontext-createmodel"></a></dfn>(<c- b="">sequence</c->&lt;<a data-link-type="idl-name" href="#dictdef-namedoperand" id="ref-for-dictdef-namedoperand"><c- n="">NamedOperand</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext/createModel(outputs)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g="">outputs</c-></code><a href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"></a></dfn>);
};
</pre>
   <h4 data-level="3.5.1" id="api-neuralnetworkcontext-batchnorm"><span>3.5.1. </span><span>batchNormalization</span><a href="#api-neuralnetworkcontext-batchnorm"></a></h4>
    Normalize the tensor values across dimensions in a batch through a specialized <a data-link-type="biblio" href="#biblio-batchnorm">[BatchNorm]</a> <a href="https://en.wikipedia.org/wiki/Batch_normalization#Batch_Normalizing_Transform">transform</a>. The <em>mean</em> and <em>variance</em> tensors are previously calculated during model training pass. 
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext②"><c- g="">NeuralNetworkContext</c-></a> {
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand④"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="batchNormalization(input, mean, variance, scale, bias, axis, epsilon)|batchNormalization(input, mean, variance, scale, bias, axis)|batchNormalization(input, mean, variance, scale, bias)|batchNormalization(input, mean, variance, scale)|batchNormalization(input, mean, variance)" id="dom-neuralnetworkcontext-batchnormalization"><code><c- g="">batchNormalization</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization"></a></dfn>(<a data-link-type="idl-name" href="#operand" id="ref-for-operand⑤"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑥"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g="">mean</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑦"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g="">variance</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑧"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g="">scale</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑨"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g="">bias</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②"><c- b="">long</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g="">axis</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"></a></dfn> = 1, <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float①"><c- b="">float</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g="">epsilon</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"></a></dfn> = 1e-5);
};
</pre>
   <div data-algorithm="batchnorm">
     <p><strong>Arguments:</strong></p><ul>
     <li data-md="">
      <p><em>input</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪">Operand</a></code>. The input N-D tensor.</p>
     </li><li data-md="">
      <p><em>mean</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①①">Operand</a></code>. The 1-D tensor of the batch mean values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     </li><li data-md="">
      <p><em>variance</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①②">Operand</a></code>. The 1-D tensor of the batch variance values
whose length is equal to the size of the input …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://webmachinelearning.github.io/webnn/">https://webmachinelearning.github.io/webnn/</a></em></p>]]>
            </description>
            <link>https://webmachinelearning.github.io/webnn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649616</guid>
            <pubDate>Thu, 01 Oct 2020 11:18:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supporting a misbehaving NAND ECC engine in the Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649565">thread link</a>) | @pabs3
<br/>
October 1, 2020 | https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/ | <a href="https://web.archive.org/web/*/https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13845">
	<!-- .entry-header -->

	
	
	<div>
		<p>Over the years, Bootlin has grown a significant expertise in U-Boot and Linux support for flash memory devices. Thanks to this expertise, we have recently been in charge of rewriting and upstreaming a driver for the <a href="https://www.arasan.com/products/nand-flash/">Arasan NAND controller</a>, which is used in a number of <a href="https://www.xilinx.com/products/silicon-devices/soc.html">Xilinx Zynq SoCs</a>. It turned out that supporting this NAND controller had some interesting challenges to handle its ECC engine peculiarities. In this blog post, we would like to give some background about ECC issues with NAND flash devices, and then dive into the specific issues that we encountered with the Arasan NAND controller, and how we solved them.</p>

<p>NAND flash memories are known to be intrinsically rather unstable: over time, external conditions or repetitive access to a NAND device may result in the data being corrupted. This is particularly true with newer chips, where the number of corruptions usually increases with density, requiring even stronger corrections. To mitigate this, Error Correcting Codes are typically used to detect and correct such corruptions, and since the calculations related to ECC detection and correction are quite intensive, NAND controllers often embed a dedicated engine, the ECC engine, to offload those operations from the CPU.</p>
<p>An ECC engine typically acts as a DMA master, moving, correcting data and calculating syndromes on the fly between the controller FIFO’s and the user buffer. The engine correction is characterized by two inputs: the size of the data chunks on which the correction applies and the strength of the correction. Old SLC (Single Level Cell) NAND chips typically require a strength of 1 symbol over 4096 (1 bit/512 bytes) while new ones may require much more: 8, 16 or even 24 symbols.</p>
<p>In the write path, the ECC engine reads a user buffer and computes a code for each chunk of data. NAND pages being longer than officially advertised, there is a persistent Out-Of-Band (OOB) area which may be used to store these codes. When reading data, the ECC engine gets fed by the data coming from the NAND bus, including the OOB area. Chunk by chunk, the engine will do some math and correct the data if needed, and then report the number of corrected symbols. If the number of error is higher than the chosen strength, the engine is not capable of any correction and returns an error.</p>

<p>As explained in our introduction, as part of our work on upstreaming the Arasan NAND controller driver, we discovered that this NAND controller IP has a specific behavior in terms of how it reports ECC results: the hardware ECC engine never reports errors. It means the data may be corrected or uncorrectable: the engine behaves the same. From a software point of view, this is a critical flaw and fully relying on such hardware was not an option.</p>
<p>To overcome this limitation, we investigated different solutions, which we detail in the sections below.</p>
<h2>Suppose there will never be any uncorrectable error</h2>
<p>Let’s be honest, this hypothesis is highly unreliable. Besides that anyway, it would imply that we do not differentiate between written/erased pages and users would receive unclean buffers (with bitflips), which would not work with upper layers such as UBI/UBIFS which expect clean data.</p>
<h2>Keep an history of bitflips of every page</h2>
<p>This way, during a read, it would be possible to compare the evolution of the number of bitflips. If it suddenly drops significantly, the engine is lying and we are facing an error. Unfortunately it is not a reliable solution either because we should either trigger a write operation every time a read happens (slowing down a lot the I/Os and wearing out very quickly the storage device) or loose the tracking after every power cycle which would make this solution very fragile.</p>
<h2>Add a CRC16</h2>
<p>This CRC16 could lay in the OOB area and help to manually verify the data integrity after the engine’s correction by checking it against the checksum. This could be acceptable, even if not perfect in term of collisions. However, it would not work with existing data while there are many downstreams users of the vendor driver already.</p>
<h2>Use a bitwise XOR between raw and corrected data</h2>
<p>By doing a bitwise XOR between raw and corrected datra, and compare with the number of bitflips reported by the engine, we could detect if the engine is lying on the number of corrected bitflips. This solution has actually been implemented and tested. It involves extra I/Os as the page must be read twice: first with correction and then again without correction. Hence, the NAND bus throughput becomes a limiting factor. In addition, when there are too many bitflips, the engine still tries to correct data and creates bitflips by itself. The result is that, with just a XOR, we cannot discriminate a working correction from a failure. The following figure shows the issue.</p>
<p><a href="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png"><img loading="lazy" src="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png" alt="Show the engine issue when it creates bitflips when trying to correct uncorrectable data" width="840" height="377" srcset="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png 1024w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-300x135.png 300w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-768x345.png 768w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1200x539.png 1200w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png 1458w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a></p>
<h2>Rely on the hardware only in the write path</h2>
<p>Using the hardware engine in the write path is fine (and possibly the quickest solution). Instead of trying to workaround the flaws of the read path, we can do the math by software to derive the syndrome in the read path and compare it with the one in the OOB section. If it does not match, it means we are facing an uncorrectable error. This is finally the solution that we have chosen. Of course, if we want to compare software and hardware calculated ECC bytes, we must find a way to reproduce the hardware calculations, and this is what we are going to explore in the next sections.</p>

<p>There is already a BCH library in the Linux kernel on which we could rely on to compute BCH codes. What needed to be identified though, were the BCH initial parameters. In particular:</p>
<ul>
<li>The BCH primary polynomial, from which is derived the generator polynomial. The latter is then used for the computation of BCH codes.</li>
<li>The range of data on which the derivation would apply.</li>
</ul>
<p>There are several thousands possible primary polynomials with a form like <code>x^3 + x^2 + 1</code>. In order to represent these polynomials more easily by software, we use integers or binary arrays. In both cases, each bit represents the coefficient for the order of magnitude corresponding to its position. The above example could be represented by <code>b1101</code> or <code>0xD</code>.</p>
<p>For a given desired BCH code (ie. the ECC chunk size and hence its corresponding Gallois Field order), there is a limited range of possible primary polynomials which can be used. Given <code>eccsize</code> being the amount of data to protect, the Gallois Field order is the smallest integer <code>m</code> so that: <code>2^m &gt; eccsize</code>. Knowing <code>m</code>, one can check <a href="https://www.partow.net/programming/polynomials/index.html">these tables</a> to see examples of polynomials which could match (non exhaustive). The Arasan ECC engine supporting two possible ECC chunk sizes of 512 and 1024 bytes, we had to look at the tables for <code>m = 13</code> and <code>m = 14</code>.</p>
<p>Given the required strength <code>t</code>, the number of needed parity bits <code>p</code> is: <code>p = t x m</code>.</p>
<p>The total amount of manipulated data (ECC chunk, parity bits, eventual padding) <code>n</code>, also called BCH codeword in papers, is: <code>n = 2^m - 1</code>.</p>
<p>Given the size of the codeword <code>n</code> and the number of parity bits <code>p</code>, it is then possible to derive the maximum message length <code>k</code> with: <code>k = n - p</code>.</p>
<p>The theory of BCH also shows that if <code>(n, k)</code> is a valid BCH code, then <code>(n - x, k - x)</code> will also be valid. In our situation this is very interesting. Indeed, we want to protect <code>eccsize</code> number of symbols, but we currently cover <code>k</code> within <code>n</code>. In other words we could use the translation factor <code>x</code> being: <code>x = k - eccsize</code>. If the ECC engine was also protecting some part of the OOB area, <code>x</code> should have been extended a little bit to match the extra range.</p>
<p>With all this theory in mind, we used GNU Octave to <a href="https://github.com/miquelraynal/find-bch-prim-poly/blob/master/find_bch_polynomial.m">brute force the BCH polynomials</a> used by the Arasan ECC engine with the following logic:</p>
<ul>
<li>Write a NAND page with a <code>eccsize</code>-long ECC step full of zeros, and another one full of ones: this is our known set of inputs.</li>
<li>Extract each BCH code of <code>p</code> bits produced by the hardware: this is our known set of outputs.</li>
</ul>
<p>For each possible primary polynomial with the Gallois Field order <code>m</code>, we derive a generator polynomial, use it to encode both input buffers thanks to a regular BCH derivation, and compare the output syndromes with the expected output buffers.</p>
<p>Because the GNU Octave program was not tricky to write, we first tried to match with the output of Linux software BCH engine. Linux using by default the primary polynomial which is the first in GNU Octave’s list for the desired field order, it was quite easy to verify the algorithm worked.</p>
<p>As unfortunate as it sounds, running this test with the hardware data did not gave any match. Looking more in depth, we realized that visually, there was something like a matching pattern between the output of the Arasan engine and the output of Linux software BCH engine. In fact, both syndromes where identical, the bits being swapped at byte level by the hardware. This observation was made possible because the input buffers have the same values no matter the bit ordering. By extension, we also figured that swapping the bits in the input buffer was also necessary.</p>
<p>The primary polynomial for an <code>eccsize</code> of 512 bytes being already found, we ran again the program with <code>eccsize</code> being 1024 bytes:</p>
<p><code>     eccsize =  1024<br>
     eccstrength =  24<br>
     m =  14<br>
     n =  16383<br>
     p =  336<br>
     k =  16047<br>
     x =  7855<br>
     Trying primary polynomial #1: 0x402b<br>
     Trying primary polynomial #2: 0x4039<br>
     Trying primary polynomial #3: 0x4053<br>
     Trying primary polynomial #4: 0x405f<br>
     Trying primary polynomial #5: 0x407b<br>
     [...]<br>
     Trying primary polynomial #44: 0x43c9<br>
     Trying primary polynomial #45: 0x43eb<br>
     Trying primary polynomial #46: 0x43ed<br>
     Trying primary polynomial #47: 0x440b<br>
     Trying primary polynomial #48: 0x4443<br>
     Primary polynomial found! 0x4443</code></p>

<p>With the two possible primary polynomials in hand, we could finish the support for this ECC engine.</p>
<p>At first, we tried a “mixed-mode” solution: read and correct the data with the hardware engine and then re-read the data in raw mode. Calculate the syndrome over the raw data, derive the number …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</a></em></p>]]>
            </description>
            <link>https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649565</guid>
            <pubDate>Thu, 01 Oct 2020 11:08:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Deep Learning Toolchain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649488">thread link</a>) | @rosshemsley
<br/>
October 1, 2020 | https://rosshemsley.co.uk/posts/deep_learning_toolchain/ | <a href="https://web.archive.org/web/*/https://rosshemsley.co.uk/posts/deep_learning_toolchain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Successful model development can be surprisingly dependent on good engineering practices. Despite this, many model implementations scattered about Github are difficult to follow and hard to recreate locally.
</p>

<p>
But what should a <em>good model</em> look like? I would propose that the gold standard for a model implemented on Github could be:
</p>
<ol>
<li> The dependencies may be installed automatically, using a single command.</li>
<li> I can build the model in a sandbox without polluting with my dev. environment.</li>
<li> I can easily retrain (and retune!) the model the model exactly as the author did during their development.</li>
<li> I can easily test the inference pass.</li>
<li> I can easily import the model into my own workflow and use it as part of my own code.</li>
</ol>
<p>
It may be that I've never come across a model that met this standard in practical day-to-day development...! But I claim that achieving these things is surprisingly easy given the modern tools available to us.
</p>
<p>
Furthermore, many may simply respond "just ship everything in a Docker container". My response to this is that Docker is a great tool for
<em>deploying</em> a stable, reproducible environment, but Docker images provide a poor basis for sharing code and enabling collaboration.
In this post, we'll focus on designing models that can be <em>installed and imported with a single command, without Docker, on any OS, on any platform,
using the vanilla tools our language provides</em>.
</p>
<p>
So, let's dive in and look at the tools that I use to train models, and how they can be used to meet the gold standard I gave above.
</p>

<h2>Python 3 for model development</h2>
<p><img src="https://rosshemsley.co.uk/posts/deep_learning_toolchain_images/python_logo.png"></p><p>
It may not be controversial these days, but it's worth highlighting that Python 3 is an excellent choice for prototyping and releasing deep learning models. The key feature here is the library support, which is unmatched by other languages.
I tend to target <strong>Python 3.7.5</strong> or later, because I make heavy use of <em><a href="https://docs.python.org/3/library/dataclasses.html">dataclass</a></em>, and it's recent enough to support type annotations. Ubuntu Focal now includes Python 3.8 by default,
so many users will start being able to support this out of the box.
</p>
<h3>Bonus pionts: type annotations</h3>
<p>
If you use type annotations (correctly) in your model, you will get serious points from me.
It's very common that models use native lists, tensors, and numpy arrays almost interchangeably as function
arguments, and so using type hints can make the data flow in your model easier to follow and debug.
</p>
<div><pre><code data-lang="python"><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> typing <span>import</span> List, Optional

<span>import</span> numpy <span>as</span> np
<span>from</span> PIL <span>import</span> Image

<span>@dataclass</span>
<span>class</span> <span>DataSample</span>:
    img: Image
    bboxes: List[np<span>.</span>ndarray]
    scores: Optional[List[float]]

<span>...</span>

sample <span>=</span> DataSample(Image(), [np<span>.</span>array([<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>])], scores<span>=</span>None)</code></pre></div>
<p><em><strong>Above:</strong> an example of using modern Python features to write a clear and simple data container
for a training sample in a model. The dataclass decorator adds all of the utility functions we may want (including
a pretty string reprsentation so we can print the object), and the type annotations make it clear what the user 
should expect the fields to contain.</em></p><h2> Use <em>pyenv</em> to manage Python versions</h2>
<p>
For better or worse, many incompatible versions of Python now exist, and it's easy to get
in a tangle with different Python installs, especially when making system-wide changes.
</p>
<p>
My advice here is to do it properly, and do it once: learn to use <em>pyenv</em> to manage all of your Python
installs.
</p>
<p>
Pyenv is a tool that provides a shim around the <em>python</em> command which redirects it to the correct version 
of Python for the current context. For a given project, you can use <em>pyenv local 3.7.5</em> in a directory
to tell pyenv to use Python 3.7.5 from now on when calling Python in that directory.
</p>
<p>
If you don't have the version of Python installed that you need, you can use pyenv to install it.
If the universe is feeling good to you today, <em>pyenv install 3.7.5</em> should be sufficient to fetch and install Python 3.7.5
for you automatically on any platform.
</p>
<p>
<strong>In practice</strong>, things don't always go so smoothly with pyenv, however I really believe
it's really worth the hassle of spending the time and getting it working - most issues you might enouncter are well understood, and documented on stackoverflow.
</p>
<h3>A few common tips for common pyenv issues</h3>
<ul>
<li><strong>It's not working!</strong> - make sure you have activated it (google "pyenv activate"). Typically you need to add this to e.g. your .bashrc</li>
<li><strong><em>pyenv install</em> failed!</strong> - you may be missing system dependencies. Be patient, and trawl stackoverflow. It can be made to work!</li>
</ul>


<h2>Use <em>poetry</em> to manage your project and dependencies</h2> 
<p>
Keeping your Python project sandboxed is crucial aspect of remaining sane when using Python.
We typically use <em>virtualenvs</em>, or virtual environments, to achieve this. These are are essentially directories containing their own
Python install, and a local copy of all the packages your project needs. 
</p>
<p>
A separate but related problem is ensuring you actually <em>have</em> the dependencies your project needs
installed into that virtualenv. 
</p>
<p>
Once upon a time, you may have used `virtualenv` and `requirements.txt` or `anaconda` or `pipenv` to do these things.
</p>
<p>
Well, my advice is <strong>steer clear from all of them</strong> and move straight to <a href="https://python-poetry.org/">poetry</a>.
It's very much the new kid on the block, but from my perspective it's already miles ahead of the competition.
I have managed to deploy a number of complex Python applications in a professional capacity using
poetry, and I have found it both plays very well with other tools and is generally well designed.
</p>
<p>
Poetry uses the modern <a href="https://snarky.ca/what-the-heck-is-pyproject-toml/">pyproject.toml</a> way of defining a package, and this essentially replaces the old setup.py and friends.
It would be out of scope to explain why pyproject.toml is important and worth learning about, so I recommend some googling here!
</p>
<p>
Ok, so let's create a new project! ... don't forget to `pyenv local 3.7.5` first, to ensure you are using the correct version of Python (if you forgot, you can run it later, and then go
back and edit pyproject.toml to make sure it's set correctly.)
</p>

<p>
Yes, it's as easy as that. Go ahead and move in the directory poetry created for you, and you can now
</p>
<p>
and poetry will automatically create a managed virtualenv for you. Let's now install some of the tools of our trade,
</p><div><pre><code data-lang="bash">$ poetry add torch
$ poetry add numpy</code></pre></div>
<p>
Poetry will install them to the virtualenv and add them to the pyproject.toml. It will 
also <strong>pin</strong> the exact versions of the dependencies into a lock file so that <strong>other users installing your package
can reproduce precisely the same environment as you</strong>. This is perhaps the most important step here, and is worth underscoring:
this is how we are able to achieve <em>reproducibility</em>. 
</p>
<h3>The Best Bit About Poetry</h3>
<p>
Poetry was designed to be good at both developing packages and <em>building/sharing/publishing</em> them.
These latter features are sorely missing from other tools (such as pyenv), and they are really the killer
feature of poetry.
</p>
<p>
Let's suppose you pushed your <em>fancynet</em> package to github (don't forget to check in the lock file!).
Now, <strong>anyone using a recent version of pip can install your package with a single command</strong>,
</p><div><pre><code data-lang="bash">$ pip install git+https://github.com/myusername/fancynet</code></pre></div>
<p>
Pip will fetch the code from github, look into the pyproject.toml, see it uses poetry, and then just do
everything for you, including installing poetry, and fetching the correct versions of the pinned dependencies!
<strong>
This is totally magic and not enough people know this trick.</strong> Go forth and spread this knowledge!
</p>
<p>
If your package reaches a level of maturity where you'd like to publish it to a public package repository (e.g. pypi),
you can use poetry to manage this. To bump the version (you can also bump the minor and major versions this way), use
</p><p>
Then to build and publish to pypi, use
</p><div><pre><code data-lang="bash">$ poetry build
$ poetry publish</code></pre></div><p>
The defaults used by poetry are spookily well designed, and I have never had any problems publishing packages in this way.
</p>

<h2>Use <em>click</em> to manage your entrypoint</h2> 
<p>
An oft-overlooked step in building a good python package is organising the files and "entrypoints" (or "executables"). 
I believe it's worth imagining that someone else is going to use your code at somepoint, and so I try to create nicely named
subdirectories for each part of my model: "datasets", "models", "inference", but also <strong>"cli"</strong>.
In this "cli" directory, I usually have several subdirectories "train", "tune", "test". Each of these contains a single
"__main__.py", which contains the (small!) shim code needed to perform those actions.
</p>
<p>
Inside "__main__.py" I then use <a href="https://click.palletsprojects.com/en/7.x/">click</a> to manage arguments and the entrypoint.
I have found it much easier to use than argparse, and I do think it's worth the effort!
</p>
<div><pre><code data-lang="python"><span>import</span> click
<span>from</span> omegaconf <span>import</span> OmegaConf
<span>from</span> pytorch_lightning <span>import</span> Trainer

<span>from</span> mynet.models <span>import</span> MyNet

<span>@click.command</span>()
<span>@click.option</span>(<span>'--dataset-root-dir'</span>, help<span>=</span><span>'directory containing the dataset'</span>)
<span>@click.option</span>(<span>'--config-path'</span>, default<span>=</span><span>"config.yaml"</span>, help<span>=</span><span>'The config file to use.'</span>)
<span>def</span> <span>train</span>(dataset_root_dir: str, config_path: str):
    cfg <span>=</span> OmegaConf<span>.</span>load(config_path)

    model <span>=</span> MyNet(cfg)
    trainer <span>=</span> Trainer(gpus<span>=</span><span>1</span>, profiler<span>=</span>True)
    trainer<span>.</span>fit(model)

<span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
    train()</code></pre></div>
<p>
Now, if we are developing locally, we can run this using
</p><div><pre><code data-lang="bash">$ poetry run python -m mynet.cli.train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
Which is fine and good, but if we want to go 10X, we can also use a neat future of project.toml and add an entrypoint
</p><div><pre><code data-lang="toml">[<span>tool</span>.<span>poetry</span>.<span>scripts</span>]
<span>train</span> = <span>"mynet.cli.train.__main__:train"</span></code></pre></div><p>
Once we do this, users can run training using
</p><div><pre><code data-lang="bash">$ poetry run train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
or if you "activate" the environment, simply
</p><div><pre><code data-lang="bash">$ train --dataset-root-dir /foo/bar/baz</code></pre></div>

<p>
It's possible to add multiple entrypoints to the pyproject.toml, so you can easily create one for training, tuning, testing.
This is helpful for users trying to discover how to train or evaluate your model from scratch!
</p>
<p>
Do note that if a user installs your package into a shared virtualenv, you may wish to choose a more meaningful name than train!
</p>

<h2>Use <em>pytorch</em> to develop your net</h2>
<p></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rosshemsley.co.uk/posts/deep_learning_toolchain/">https://rosshemsley.co.uk/posts/deep_learning_toolchain/</a></em></p>]]>
            </description>
            <link>https://rosshemsley.co.uk/posts/deep_learning_toolchain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649488</guid>
            <pubDate>Thu, 01 Oct 2020 10:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PowerShell Universal v1.4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649270">thread link</a>) | @l33t_d0nut
<br/>
October 1, 2020 | https://blog.ironmansoftware.com/powershell-universal-1-4/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/powershell-universal-1-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>PowerShell Universal v1.4</h2><h4>September 30, 2020</h4><p>I’m pleased to announce another feature-packed <a href="https://ironmansoftware.com/powershell-universal">PowerShell Universal</a> release! Today, we’re releasing version 1.4 of the ultimate platform for building web-based IT tools. This release contains an extensive list of features as well as bug fixes. This blog post will go over them but I encourage you to <a href="https://ironmansoftware.com/downloads">download or upgrade</a> to take full advantage of everything that has been added.</p><h2 id="release-notes">Release Notes</h2><p>Full release notes can be found <a href="https://docs.ironmansoftware.com/changelog">here</a>.</p><h2 id="downloads">Downloads</h2><ul><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/PowerShellUniversal.1.4.0.msi">Windows MSI</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.win-x64.1.4.0.zip">Windows ZIP</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.linux-x64.1.4.0.zip">Linux ZIP</a></li><li><a href="https://hub.docker.com/r/ironmansoftware/universal">Docker</a></li></ul><h2 id="platform">Platform</h2><h3 id="environments">Environments</h3><p>We’ve extended the concept of PowerShell Versions and replaced it with Environments. Environments allow you to specify the executable, arguments, modules and variables that are defined whenever you execute an API request, run a job or host a dashboard. The execution environment will automatically create a runspace pool with the assets you define so there is no need to import them every time.</p><p>We’ve standardized environments across all features and now you can select which environment is used in each place.</p><p><a href="https://docs.ironmansoftware.com/config/environments">Learn more about Environments</a></p><p><img src="https://blog.ironmansoftware.com/images/environments.png" alt=""></p><h3 id="windows-authentication-with-iis">Windows Authentication with IIS</h3><p>You can now configure Windows Authentication without IIS. IIS can complicate deployments and if it’s not something you need, you can now avoid it by simply installing Universal as a service and configuring Windows authentication.</p><p><a href="https://docs.ironmansoftware.com/config/security#windows-authentication-outside-of-iis">Learn more about Windows Authentication without IIS</a></p><h2 id="apis">APIs</h2><h3 id="rate-limiting">Rate Limiting</h3><p>We’ve added the ability to configure rate limiting for APIs. This is an important feature for anyone that may be exposing their API publicly or may call a sensitive resource that you do not want to overload. You can configure rate limits based on HTTP method, endpoint (or pattern), and the number of requests over a period of time.</p><p><a href="https://docs.ironmansoftware.com/api/rate-limiting">Learn more about Rate Limiting</a></p><p><img src="https://blog.ironmansoftware.com/images/ratelimit.png" alt=""></p><h3 id="connection-information">Connection Information</h3><p>You’ll have access to more connection information in your endpoints. Variables are now defined for Local IP Address, Remote IP Address, Local Port and Remote Port.</p><h3 id="updated-endpoint-page">Updated Endpoint Page</h3><p>We’ve enhanced the API page to provide a neat in-browser experience for developing your API. This includes the ability to test your APIs directly in the browser.</p><p><img src="https://blog.ironmansoftware.com/images/apis.png" alt=""></p><h2 id="automation">Automation</h2><h3 id="continuous-schedules">Continuous Schedules</h3><p>You can now define continuous schedules that will run a job over and over again with a configurable delay. It won’t start another job until the previous one has finished.</p><p><a href="https://docs.ironmansoftware.com/automation/schedules#continuous">Learn more about Scheduling</a></p><p><img src="https://blog.ironmansoftware.com/images/continuous-schedule.png" alt=""></p><h3 id="variables">Variables</h3><p>Variables are now global for the entire Universal platform. By default, your existing Environments will import all variables but you can define specific variables or patterns to use in an environment. This change shouldn’t affect your jobs but be aware that variables are no longer present only present in jobs but present in any one of the features using an Environment.</p><p><a href="https://docs.ironmansoftware.com/automation/variables">Learn more about Variables</a></p><h2 id="dashboard">Dashboard</h2><h3 id="role-based-access">Role-based Access</h3><p>We’ve added the ability to assign roles to dashboards and pages in the v3 framework. If you assign a role to a dashboard, only users of that role will have access to the entire dashboard. When you assign roles to a page in a dashboard, any authenticated user will be able to access the dashboard but only users in the specified role will have access to the pages.</p><p><a href="https://docs.ironmansoftware.com/dashboard/role-based-access">Learn more about Role-Based Access in Dashboards</a></p><h3 id="chartjs">ChartJS</h3><p>We’ve brought back ChartJS support. This was the primary chart library in UDv2. Many users preferred this library over our Nivo charts integration so we have decided to include it. We’ve also simplified the API to make it even easier to build charts.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/data-visualization/charts#chartjs">Learn more about ChartJS integration</a></p><p><img src="https://blog.ironmansoftware.com/images/chartjs.png" alt=""></p><h3 id="improved-navigation">Improved Navigation</h3><p>We’ve simplified and extended the built in navigation. You can now more easily define your navigation items for a page. We also support a persistent layout that does not require a click of a hamburger menu to open the navigation.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/pages#navigation">Learn more about Navigation</a></p><p><img src="https://blog.ironmansoftware.com/images/permanent-drawer.png" alt=""></p><h3 id="redesigned-dashboard-page">Redesigned Dashboard Page</h3><p>The dashboard page has been redesigned to make it easier to see an overview of the dashboards running in your environment.</p><p><img src="https://blog.ironmansoftware.com/images/new-dashboards.png" alt=""></p><h2 id="get-started-now">Get Started Now</h2><p>PowerShell Universal is free to try. <a href="https://ironmansoftware.com/downloads">Download now</a> and start building tools with your existing PowerShell scripts. Please feel free to join our <a href="https://forums.universaldashboard.io/">growing community</a>.</p></div></div></div>]]>
            </description>
            <link>https://blog.ironmansoftware.com/powershell-universal-1-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649270</guid>
            <pubDate>Thu, 01 Oct 2020 10:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can drive more traffic and engagement with content amplification]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649266">thread link</a>) | @JamesConverge
<br/>
October 1, 2020 | https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification | <a href="https://web.archive.org/web/*/https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><strong>Content amplification is one of the most underused&nbsp;pieces of the&nbsp;content marketing puzzle.</strong></p>
<p><strong>Hands down.</strong></p>
<p><span>So many businesses create great content, but then they only publish that content on their own website, and maybe share it once or twice on social media.</span></p>
<p><span>Sorry to break it to you, but with millions of other businesses doing the same thing, that isn't going to help you cut through the noise.&nbsp;</span></p>
<p><span>At all.&nbsp;</span></p>
<p><span>And hoping that someone will just stumble across your content isn’t a good strategy, either.&nbsp;</span></p>
<p><span>In reality, you need to <strong>AMPLIFY YOUR CONTENT</strong></span><span>.</span></p>
<p><span>Without content amplification, your hard work and effort will remain essentially “on the shelf collecting dust".</span></p>
<p><span>Creating content is less than half the battle. If you don't have a distribution, or amplification strategy for your content, then you're missing out on more traffic, more awareness, more backlinks, better SEO and a more engaged audience.</span></p>
<p><span>And, of course, all of the above <em>usually</em> lead to additional commercial benefits such as more customers and more sales.</span></p>
<p><span>In this article, we’re going to break down content amplification, tell you what it is, how it works, and how you can get the most out of it so your content can start to work harder and more effectively for you.&nbsp;</span></p>
<p><span>We’re going to answer the most common questions we get that relate to content amplification, such as:</span></p>
<ul>
<li><span>What is content amplification?</span></li>
<li><span>Why is content amplification so important?</span></li>
<li><span>How can I build a content amplification strategy?</span></li>
</ul>
<p><span>But enough with the preamble. Let’s jump in and get right into the good stuff.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Mark%20Masters.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"The reason we shy away from content distribution or amplification is that it feels far better to be creative and produce, than it is to encourage people to watch/listen/read, as this side takes far more effort. Then again, the reason we are creating is to motivate people and get them to subscribe, enquire, interact and buy.</em></p>
<p><em>What is really important is to have something to say that can be amplified. Distribution channels work really well, once you have something to distribute. So, make sure that your message links to your values and that can strike a chord with others. This is how you find your allies, make sure your work is seen and people want to feel a part of it and prepared to stand with you."&nbsp;</em></p>
<p><strong><em>Mark Masters - <a href="https://www.wearethemedia.co.uk/">We Are The Media</a></em></strong></p>
<p>What is content amplification, and why is it so important?</p>
<p><span>Content amplification is the act of promoting and distributing your content across multiple channels (paid, owned and earned) so you can increase the reach and impact of both your content and your brand.</span></p>
<p><span>However, amplifying your content does more than simply provide your brand with additional exposure. It also allows you to position yourself as a thought leader, and build valuable backlinks, as well as build relationships, and increase both engagement and conversion rates with your target audience.&nbsp;</span></p>
<p><span>There are many different ways to amplify content. Paying to promote your content on Facebook or Twitter, leveraging influencers to promote your content, publishing your content on </span><a href="https://promos.converge.today/join-converge"><span>other platforms with an already captivated audience</span></a><span> - they’re all different ways to amplify your content, and we’ll get into them in a bit more detail later on.</span></p>
<p><span>Without amplification, it’ll be much more difficult for you to get the results you want from your content.&nbsp;</span></p>
<p><span>Every single day, there are</span><a href="https://www.worldometers.info/blogs/"><span> millions of new blogs published</span></a><span>. Yes, not all of them will be competing with what you’ve created, but that’s a lot of potential noise getting in the way of your message. And organic reach is getting lower and lower all the time.</span></p>
<p><span>Because organic reach across the board is down, way down, when it comes to creating content - and you may be producing the best stuff out there - the likelihood is that without amplifying your content, it’s not going to perform well.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Cathy%20McPhillips.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“You’ve written an amazing article – and now what? You can’t expect the results to happen without some distribution work on your end. This includes content amplification – a multi-channel approach to increase your brand’s reach. It’s taking your owned media, and combining it with paid and earned media. It’s really knowing the right places – and people – to help amplify your message to your audience.</em></p>
<p><em>Through content amplification, you’re able to extend your reach into new areas you couldn’t achieve on your own through organic methods. It’s getting out of your echo chamber of your current customers and brand loyalists and finding new and relevant customers who wouldn’t have necessarily heard of you otherwise. Amplification done right brings customers to you who didn’t yet know how much they needed you.</em></p>
<p><strong><em>Cathy McPhillips - <a href="http://contentmarketinginstitute.com/">Content Marketing Institute</a></em></strong></p>
<p>The problem with organic traffic</p>
<p><span>OK, that’s a little misleading. There is no problem with organic traffic.</span></p>
<p><span>The problem lies with the expectations people have when it comes to organic traffic. And, frankly, the delusion that generating it is both a) easily achievable and, b) that it is the only traffic source worth aiming for.&nbsp;</span></p>
<p><span>Nope.</span></p>
<p><span>Listen, organic traffic is great. It’s wonderful. If you’re getting huge organic traffic and your website and blogs are appearing right at the top of search results for your most relevant and valuable keywords and phrases, then brilliant! You’ve smashed it already.&nbsp;</span></p>
<p><span>Chances are, though, that’s not the case. Because, 1) only a handful of businesses across the entire planet can claim to have achieved the above. And it’s a constant battle for them to remain at the top. And, 2) organic reach is in decline </span><a href="https://blog.hootsuite.com/organic-reach-declining/"><span>across the board</span></a><span>.</span></p>
<p><span>We’re not saying achieving a first page ranking on Google for your content is impossible, but it may take both time and resources that you currently don’t have to get there. So, before you become a high-ranking Google superstar, you must find another way to get eyeballs on your content.</span></p>
<p><span>You need to amplify content so you can generate the consistent traffic and backlinks you need to get it the awareness and engagement it deserves, and to get it started on the long, arduous climb towards the first page of search results.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Abby%20Sorensen.jpg" alt="" width="1600" height="150"></span></p>
<p><em>“Imagine this scenario at the most important trade show in your industry - Your sales team picks up their badges and heads for the show floor, eager to make connections and meet potential buyers. Your product/service is the exact right fit for these prospects, and your message has been carefully crafted to resonate with them. But your booth is set up at the empty convention center across town. Maybe you were trying to stretch your budget. Or maybe you thought your product/service was so exciting that buyers would go out of their way to find you. Your sales team heads back to the office empty-handed, a complete waste of time and energy spent setting up your booth where your buyers were not.</em></p>
<p><em>This is exactly what happens when you create content with no plan to distribute it.<strong> Only a select few companies can afford to buy their way to the top of Google’s search rankings.</strong> The only way to get the most out of your content is to distribute it where your buyers are likely to be. And while your website might be the most strategized, optimized, digitized, mobilized website in your market, your buyers simply are not likely to spend a great deal of time there (especially if you hit them with gates and form-fills).”</em></p>
<p><strong><em>Abby Sorensen - <a href="https://www.followyourbuyer.com/">Follow Your Buyer</a></em></strong></p>
<p>Creating content is less than half the battle</p>
<p><span>That’s right. All that time you spent researching, planning, creating and publishing content is less than half of what’s required to give your content the best chance of generating the return on investment you want from it.&nbsp;</span></p>
<p><span>Depending on who you talk to and the articles you read, you may have heard people saying content creation is anywhere from 20-40% of the job.</span></p>
<p><span>The rest of it? You guessed it; amplification/distribution/promotion - whatever you call it. Whatever it takes to get your content in front of everyone you want to read it.</span></p>
<p><span>But let’s not get bogged down in specific percentages. The only thing you need to know is that you need to spend more time promoting your hard work than you do creating it. Because the competition for attention is fierce, and you need to cut through the noise and make sure people are actually engaging with your content. Otherwise why spend the time creating it in the first place?&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Alexandra%20Cote.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"Beyond simply creating a really good post, you'll also need really great content amplification methods in place. In fact, everything that happens AFTER you publish a piece of content is much more important than the post itself. This is because sharing content across appropriate channels and talking about your findings and products gets your brand in front of more people.</em></p>
<p><em>This being said, content amplification is the core driver behind reaching your business goals and hitting your KPIs. Whether you want to improve your brand awareness, get more qualified leads, gain new partnerships, or just position yourself as a thought leader in the industry, content amplification can help you hit those targets. Do remember to stay away from vanity metrics though. Just because a lot of people like a post of yours on LinkedIn doesn't mean they read your article and it's a far cry from them actually making a purchase.</em></p>
<p><em>The best advice I have to ensure you're seeing real results from your content amplification techniques is to choose the right networks and websites to promote your content. You'll first need a clear image of your buyer persona. By analyzing potential customers and their behavior, you'll see where they spend most of their time and, above all, what determines them to make a purchase decision. Then, all you have to do is craft the right messaging revolving around the benefits they're looking to get and stay consistent on a couple of networks of choice. Feel free to include the same terms and pain points they use and remember to be responsive so the conversation is bidirectional."</em></p>
<p><strong><em><a href="https://mktodyssey.wordpress.com/">Alexandra Cote</a>, B2B and SaaS Content Writer and SEO Strategist</em></strong></p>
<p>Building a content amplification strategy</p>
<p><span>Of course, it’s easy …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</a></em></p>]]>
            </description>
            <link>https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649266</guid>
            <pubDate>Thu, 01 Oct 2020 10:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are secrets in Git such a threat?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649034">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secret-sprawl | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secret-sprawl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What are secrets in the software development world?</p><div><p>In the common language, a secret can be any sensitive data that we want to keep private. When discussing secrets in the context of software development, secrets generally refer to digital authentication credentials that grant access to systems or data. These are most commonly API keys, usernames and passwords, or security certificates.</p><p>Secrets exist in the context of applications that are no longer standalone monoliths. Applications nowadays rely on thousands of independent building blocks: cloud infrastructure, databases, SaaS components such as Stripe, Slack, HubSpot…&nbsp;</p><p>Secrets are what tie together these different building blocks of a single application by creating a secure connection between each component.</p></div><p>What is secret sprawl?</p><div><p>Secret sprawl is the unwanted distribution of secrets like API keys and credentials through multiple systems.&nbsp;</p><p>In modern software development, secrets are regularly used by developers and applications. As a result they often get shared through different services like Slack or email and can be stored in multiple locations including different machines, git repositories or inside company wikis. This is a phenomenon we call secret sprawl.</p></div><p>What are some of the best practices to securely manage secrets like API keys?</p><div><p>Storing and managing secrets like API keys and other credentials can be challenging. Even the most careful policies can sometimes be circumvented in exchange for convenience. We have put together a helpful <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">cheat sheet</a> and article explaining the <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">best practices for managing secrets</a>.</p><p>As a minimum here are some points you should consider:</p></div><div><p>Never store unencrypted secrets in git repositories</p></div><div><p>Avoid git add * commands on git</p></div><div><p>Add sensitive files in .gitignore</p></div><div><p>Don’t rely on code reviews to discover secrets</p></div><div><p>Use automated secrets scanning on repositories</p></div><div><p>Don’t share your secrets unencrypted in messaging systems like Slack</p></div><div><p>Store secrets safely (method to be used depends on every use case)</p></div><div><p>Default to minimal permission scope for APIs</p></div><div><p>Whitelist IP addresses where appropriate</p></div><p>What are the threats associated with secret sprawl?</p><div><p>When secrets are sprawled through multiple systems it increases what is referred to as the ‘attack surface’. This is the amount of points where an unauthorized user could gain access to your systems or data. In the case of secret sprawl, each time a secret enters another system it is another point where an attacker could gain access to your secrets.</p><p>Most internal systems are not an appropriate place to store sensitive information, even if those systems are private. No company wants credit card numbers in plaintext in databases, PII in application logs, bank account credentials in a Google Doc. Secrets benefit from the same kind of protective measures.</p><p>As a general security principle, where feasible, data should remain safe even if it leaves the devices, systems, infrastructure or networks that are under organizations’ control, or if they are compromised. This helps prevent credential stealing, which is a well-known adversary technique described in the MITRE ATT&amp;CK framework:</p></div><p>“ Adversaries may search local file systems and remote file shares for files containing passwords. These can be files created by users to store their own credentials, shared credential stores for a group of individuals, configuration files containing passwords for a system or service, or source code/ binary files containing embedded passwords. ”<br></p><p>Secrets accessed by malicious threat actors can lead to information leakage and allow lateral movement or privilege escalation, as secrets very often lead to other secrets. Furthermore, once an attacker has the credentials to operate like a valid user, it is extremely difficult to detect the abuse and the threat can become persistent.<br></p><p>What are some of the biggest challenges associated with secret sprawl?</p><div><p>Because secrets tie together each component of an application, developers and ops need access to these secrets to build, connect, test and deploy applications. The result is that secrets need to be both tightly wrapped and also widely distributed. </p><p>Enforcing good security practices at the organization level is hard. Developers today can have large turnovers inside companies, be spread through many different teams and geographies. They have a growing number of technologies they must master and are under hard pressure due to shortened release cycles. This makes secret management very complicated and an ever changing challenge. </p><p>This is further complicated when VCS like git are introduced because secrets can be buried deep inside the history. The actual version of source code might look clean, while the history might present credentials that were added than later removed. Any secret reaching the Version Control System must be considered compromised and the presence of valid secrets in the git history presents a threat!</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secret-sprawl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649034</guid>
            <pubDate>Thu, 01 Oct 2020 09:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is it hard to detect API keys in source code?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24649026">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Why is it hard to detect secrets like API keys and other credentials?</p><div><p>Secrets detection is probabilistic—that is to say that it is not always possible to determine what is a true secret (or true positive). Because secrets share very few common, distinctive factors, decisions must be taken by aggregating weak signals to make strong predictions. </p><p>One of the most common factors is that almost all secrets are strings that look random. We call these strings high entropy strings. The issue is that this common factor is not very distinctive: 99% of strings that look random in source code aren’t secrets. They are for example database IDs or other types of false positives. </p><p>Of course, some secrets have fixed patterns: AWS keys often start with AKIA for example. But most secrets do not. The portions of code surrounding them are also very different, depending on what the secrets are used for and how they are used by the developers in the context of specific applications. Usernames and passwords can be used to authenticate in many different ways, and it is really hard to distinguish between real and fake credentials used as placeholders for example. </p><p>All this makes it extremely challenging to accurately capture all true secrets without also capturing false positives. At some point, a line in the sand needs to be drawn that considers the cost of a secret going undetected (a false negative) and compares it to the outcome that too many false positives would create. Different organizations with different people, cultures and workflows will draw different lines!</p></div><p>Why do code reviews fail at finding secrets in source code?</p><p>Code reviews are great overall for detecting logic flaws or maintaining certain good coding practices. But they are not adequate protection for detecting secrets, mostly for two reasons:<br></p><div><p>Reviews generally only consider the net difference between the current and proposed states. Not the entire history of changes. If a commit adds a secret and another one later deletes it, this has a zero net effect that is not of any interest to reviewers. But the vulnerability is there.</p></div><div><p>Reviewers prefer to focus on errors that cannot be automatically detected, like design flaws. As a general principle, security automation should be implemented wherever it can be, so that humans focus on where they bring the most value.</p></div><p>What is a "good" secrets detection algorithm?</p><div><p>Detecting secrets in source code is like finding needles in a haystack: there are a lot more sticks than there are needles, and you don’t know how many needles might be in the haystack. In the case of secrets detection, you don’t even know what all the needles look like!</p><p>Ideally, you want your detection system to achieve at the same time:</p></div><div><p>A low number of false alerts raised. We call this high precision. Precision answers the question: «What is the percentage of the secrets that you detect that are actual secrets?». This question is perfectly legitimate, especially in the context of security teams being overwhelmed with too many alerts.</p></div><div><p>A low number of secrets missed. This is what we call high recall. Considering that a single undetected credential can have a big impact for an organization, some organizations prefer to triage more false alerts but make sure they don’t miss a secret.</p></div><p>Balancing the equation to ensure that the algorithm captures as many secrets as possible without flagging too many false results is an intricate and extremely difficult challenge. Read more on evaluating <a href="https://blog.gitguardian.com/secrets-detection-accuracy-precision-recall-explained/" target="_blank">secrets detection algorithms</a>.<br></p><p>What is a false positive in secrets detection?</p><div><p>A false positive in secrets detection refers to when a secret candidate is wrongly marked as a true secret when it is in fact a non-sensitive string. </p><p>Typical examples of strings that can be mistaken for true secrets are:</p></div><div><p>UUIDs (Universally Unique Identifiers) that are used for example by databases as unique keys.</p></div><div><p>High entropy URLs or file paths. They often contain random strings that look like keys.</p></div><p>Examples of server-side hooks:<br></p><div><p>Test keys. Service Providers sometimes provide developers with a set of test credentials with a very restricted scope so developers can exercise parts of the API without charging their account</p></div><div><p>Public keys. As surprising as it is, a very small number of keys are really meant to be public (like Firebase keys, see this Stack Overflow <a href="https://stackoverflow.com/questions/37482366/is-it-safe-to-expose-firebase-apikey-to-the-public" target="_blank">conversation</a>).</p></div><p>Are secrets detection algorithms language-dependent?</p><p>Secrets detection is, for the most part, not language specific. Of course, there are some subtleties to take into account, like the way variables are assigned in any programming language. But there is no need to support all the different syntaxes in their greatest details. This means that the same algorithms can be applied to any project, in any programming language, without using things like Abstract Syntax Trees.<br></p></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649026</guid>
            <pubDate>Thu, 01 Oct 2020 09:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why automate secrets scanning throughout your SDLC?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649022">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secrets-detection-application-security | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secrets-detection-application-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My source code is private, so why is hardcoding credentials in git considered a bad practice?</p><div><p>While private repositories offer some level of protection for your code they still do not have adequate protection to store information as sensitive as secrets. </p><p>Imagine if there was a plain text file with all your credit card numbers within it, you hopefully wouldn’t put this into the companies git repository. Secrets are just as sensitive.</p><p>A few things to consider when storing secrets in private repositories:</p></div><div><p>Source code is made to be duplicated and distributed, therefore lives in multiple places. Source code is a leaky asset and you never know where it is going to end up. It can be cloned to a compromised workstation or server, intentionally or accidentally published in whole or in part, uploaded to your website, released to a customer, pasted in Slack, or end up in your package manager or mobile application...</p></div><div><p>It would just take one compromised developer account to compromise all the secrets they have access to.</p></div><div><p>Hardcoded credentials make it impossible to know what secrets a developer accessed, and very difficult to rotate keys.</p></div><p>Why automate secrets scanning throughout the Software Development Life Cycle (SLDC)?</p><p>While DevOps, Continuous Integration and Continuous Delivery speed up software development, they can also significantly increase security risks.<br></p><p>“DevOps is rapid and requires lots of small, iterative changes. But this increases complexity and opens up a new set of security problems. With DevOps, existing security vulnerabilities can be magnified and manifest themselves in new ways. The speed of software creation can mean new vulnerabilities are created unseen by developers. The solution is to build security monitoring into the DevOps process from the start.”<br></p><p>Greg Day, RSA Conference Organizer (<a href="https://www.securityroundtable.org/the-biggest-cybersecurity-risks-in-2020/" target="_blank">source</a>)<br></p><p>Security now needs to be part of the SDLC from the start, and part of every incremental change. This concept is called Shifting Left, a development principle which states that security should move from the right (or end) of the SDLC to the left (the beginning). A great deal of automation is needed in order to be able to cope with running security checks at each incremental change. &nbsp;Automation helps streamline the detection, alerting and remediation processes and workflows.<br></p><p>How does secrets detection compare with Static Application Security Testing (SAST)?</p><div><p>Secrets detection is often confused with SAST because both scan through static source code. </p><p>SAST is mostly testing control structure, input validation, error handling, etc. Such vulnerabilities like SQL injection vulnerabilities only express themselves the moment the code is deployed. Exposed secrets are unlike these vulnerabilities, because any secret reaching version control system must be considered compromised and requires immediate attention. This is true even if the code is never deployed. </p><p>Implementing secrets detection is not only about scanning the most actual version of your master branch before deployment. It is also about scanning through every single commit of your git history, covering every branch, even development or test ones.</p><p>To conclude, SAST is concerned only with the current version of a project, the version that is going to be deployed, whereas secrets detection is concerned with the entire history of the project.</p></div><p>What are git hooks?</p><div><p>Git hooks are scripts that are triggered by certain actions in the software development process, like committing or pushing. By automatically pointing out issues in code, they allow reviewers not to waste time on mistakes that can be easily diagnosed by a machine. </p><p>There are client-side hooks, that execute locally on the developers’ workstation, and server-side hooks, that execute on the centralized version control system.</p><p>Examples of client-side hooks:</p></div><p>Examples of server-side hooks:<br></p><p>What is a pre-commit hook?</p><div><p>"The pre-commit hook is run first when committing, before you even type in a commit message. It’s used to inspect the snapshot that’s about to be committed, to see if you’ve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. </p><p>Exiting non-zero from this hook aborts the commit, although you can bypass it with <span>git commit --no-verify</span>. You can do things like check for code style (run lint or something equivalent), check for trailing whitespace, or check for appropriate documentation on new methods."</p></div><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>What is a pre-receive hook?</p><div><p>A pre-receive hook is a script that runs on the server. It performs checks on the content of the push; if it exits non-zero, the push is rejected. You can use this hook to do things like prevent a PR author from merging their own changes, or require commit messages to follow some specific guidelines. </p><p>Be careful when using pre-receive hooks as they are blocking: if the checks don’t pass, the server is not updated.</p></div><p>What is a post-receive hook?</p><p>"The post-receive hook runs after the entire process of pushing code to the server is completed and can be used to update other services or notify users. Examples include emailing a list, notifying a continuous integration server, or updating a ticket-tracking system – you can even parse the commit messages to see if any tickets need to be opened, modified, or closed. This script can’t stop the push process, but the client doesn’t disconnect until it has completed, so be careful if you try to do anything that may take a long time."<br></p><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>Unlike the pre-receive hook, post-receive is non-blocking.<br></p><p>Where in the DevOps pipeline to implement automated secrets scanning? Client-side or server-side?</p><div><p>The earlier a security vulnerability is uncovered, the less costly it is to correct. Hardcoded secrets are no exceptions. If the secret is uncovered after the secret reaches centralized version control server-side, it must be considered compromised, which requires rotating (revoking and redistributing) the exposed credential. This operation can be complex and typically involves multiple stakeholders.</p><p>Client-side secrets detection early in the software development process is a nice-to-have as it will prevent secrets entering the VCS earlier. </p><p>Server-side secrets detection is a must have:</p></div><div><p>&nbsp;Server-side is where the ultimate threat lies. From the server, the code can uncontrollably spread in a lot of different places, with the hardcoded secrets in it.</p></div><div><p>Implementing client-side hooks on an organization level is hard. This is something we have heard many application security professionals claim they are not confident to do, due to the difficulty to deploy and update this on every developer’s workstation.</p></div><div><p>Client-side hooks can and must be easy to bypass (remember secret detection is probabilistic). Usage of client side hooks largely comes down to the individual developers’ responsibility. Hence the need to have visibility over the later stages.</p></div><p>Should secrets detection be blocking or non-blocking in the SDLC?</p><div><p>From our experience, when trying to impose rules that are too constraining, people will bend them, often in an effort to collaborate better and do their job. Security must not be a blocker. It should allow flexibility and enable information to flow, yet enable visibility and control. </p><p>On one hand, security measures will be bypassed, sometimes for the worst. But on the other hand, it is also good sometimes that the developer can take the responsibility to bypass them. </p><p>Because even the best algorithms can fail and need human judgement. Secrets detection is probabilistic: algorithms achieve a tradeoff between not raising false alerts and not missing keys.</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secrets-detection-application-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649022</guid>
            <pubDate>Thu, 01 Oct 2020 09:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paralyzed Dutch man can temporarily move and talk again thanks to sleeping pill]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24648831">thread link</a>) | @jacquesm
<br/>
October 1, 2020 | https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/ | <a href="https://web.archive.org/web/*/https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A Dutch man who has been unable to move and speak for eight years due to brain damage, can temporarily do so after taking the sleeping drug Zolpidem.  Brain scans show that the sleeping pill removes an obstacle to these actions, scientists from Radboudumc and Amsterdam UMC report Thursday.</p>
<p>In men, the brain activity for moving and talking is drowned out by the brain activity for the transfer of information.</p>
<p>“You could compare the brain, as it were, to a large string orchestra”, explains fellow researcher Hisse Arnts.  “With Richard (the man, ed.) The first violins play so loud that they drown out the other members of the string orchestra and people can no longer hear each other. Zolpidem ensures that these first violins play more ‘pianissimo’, so that everyone back within time. “</p>
<p>The fact that the man does not go to sleep because of Zolpidem is probably due to the way his brain has become confused, Arnts thinks.  The problem, however, is that the man gets used to the sleeping aid, so that the effect becomes shorter and shorter.  Yet he still receives it regularly and the discovery is a promising starting point for further research.</p>
<p>The man is not the first to return to a normal situation briefly with such a means;  there are similar reports from Italy and South Africa.  But how that is possible has now been determined for the first time on the basis of scans, according to the medical centers.</p>

<p>The man, in his late twenties at the time, suffered a severe lack of oxygen eight years ago due to choking.  He ended up in a nursing home with the very rare diagnosis of akinetic mutism.  Because Richard’s situation seemed hopeless, it was decided to give him the remedy.</p>

</div><p>    .</p></div>]]>
            </description>
            <link>https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648831</guid>
            <pubDate>Thu, 01 Oct 2020 08:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers (2019)]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24648639">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648639</guid>
            <pubDate>Thu, 01 Oct 2020 08:15:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian opposition leader Alexei Navalny describes his poisoning with Novichok]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24648502">thread link</a>) | @FrojoS
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;83eb2320-0da2-4c9c-971a-560530cea088&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;90b9f427-fb52-48a9-b441-009431a3d1a6&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg" srcset="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w520_r1.77_fpx28.11_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg 948w" width="948" height="536" sizes="948px" title="Alexei Nawalny" alt="Alexei Nawalny">
</span>
</span>
</span>

</p>
<figcaption>
<p>Alexei Nawalny</p>
<span>
Foto: Peter Rigaud&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p>In his first media interview following his poisoning, Russian opposition leader Alexei Navalny expresses his "tremendous gratitude to all Germans" in an interview with the newsmagazine DER SPIEGEL. In the interview, he says that although he never had close ties to Germany, it was German politicians and Chancellor Angela Merkel who saved his life. He says the doctors at Berlin's Charité University Hospital saved his life for a second time and nursed him back to health. "I know it sounds a bit over the top, but Germany has become a special country for me," Navalny says. Describing the personal visit paid to him by Merkel last week, he says: "I was impressed by the detail she knows about <a href="https://www.spiegel.de/thema/russia_en/" data-link-flag="english">Russia</a> and my case."</p>



<section data-area="contentbox">

</section>
<p>Navalny says he is doing "much better than three weeks ago, and things are getting better each day." The doctors say he could get back to 90 percent of his former self, perhaps even 100 percent, although no one knows for sure. "Basically, I’m a bit of a guinea pig," he says. "There aren’t many people you can observe who are still alive after being poisoned with a nerve agent." Describing the moment in the airplane when the poison started to take effect, Navalny says: "You feel no pain, but you know you’re dying. And I mean, right now. Even though nothing hurts you." You just think: This is the end. "Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you," he told DER SPIEGEL.</p>

<div>
<p>"I assert that <a href="https://www.spiegel.de/thema/vladimir_putin_en/" data-link-flag="english">Putin</a> was behind the crime, and I have no other explanation for what happened." Despite the attempt on his life, he says he wants to return to Russia. "And my job now is to remain the guy who isn’t afraid. And I’m not afraid! When my hands shake, it’s not from fear – it’s from this stuff. I would not give Putin the gift of not returning to Russia."</p><p>When asked whether he thinks Germany should stop the completion of the Nord Stream 2 Russian gas pipeline project, Navalny didn’t want to answer. "That’s Germany’s business. Decide for yourself!" Any strategy toward Russia must "take into account the level of insanity that Putin has reached."</p>
</div>

<div>
<p><em>The full interview with Navalny will be posted in English later today.</em></p>
<p><span><svg aria-labelledby="title-f2f6c24e-2448-4a58-81af-d99a30576d47" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-f2f6c24e-2448-4a58-81af-d99a30576d47">Icon: Der Spiegel</title><g id="l-s-flag-f2f6c24e-2448-4a58-81af-d99a30576d47"><path id="vector-f2f6c24e-2448-4a58-81af-d99a30576d47" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648502</guid>
            <pubDate>Thu, 01 Oct 2020 07:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baremetal programming on the tinyAVR 0 micro-controllers]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 95 (<a href="https://news.ycombinator.com/item?id=24648397">thread link</a>) | @unwind
<br/>
October 1, 2020 | https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers | <a href="https://web.archive.org/web/*/https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><h4>All you need is a text editor, a makefile and a USB-serial cable.</h4></div></section><section><div><p><img src="https://www.omzlo.com/uploads/std_attiny-406-macro.jpg" alt=""></p>

<h2 id="introduction">Introduction</h2>

<p>Are you an 8-bit or a 32-bit programmer? </p>

<p>At OMZLO, we have been mainly focussing our development efforts on newer 32-bit Arm-Cortex chips (STM32 and SAMD), which typically offer more RAM, more speed, more peripherals, at a similar or lower price-point than older 8-bit MCUs. But 8-bit MCUs are far from dead. Microchip has notably released a new series of chips, collectively branded as the "tinyAVR 0-series", which offer more modern peripherals than the older AVR chips at a very competitive price point. They seem like the perfect candidate for simple products that don't need all the features and fine-tuning capabilities of the newer 32-bit MCUs. 8-bit MCUs are also substantially simpler to program, which translates into faster development time. </p>

<p>Thanks to the success of the Arduino UNO, there are tons of tutorials online that explain how to program 8-bit Atmega328 microcontrollers and their cousins like the Attiny85 using direct register access, without the Arduino language or any vendor IDE such as Atmel Studio. Just google "atmega328 blinky". All you need is an AVR C-compiler, a text editor, <a href="https://www.nongnu.org/avrdude/">avrdude</a>, and an AVR programmer. Some <a href="https://www.instructables.com/id/Getting-Started-With-the-ATMega328P/">resources</a> even show how to also build the electronics needed to get a basic atmega328 running on a breadboard. However, it's hard to find the same information for these newer "tinyAVR 0" chips.</p>

<p>Of course, Microchip offers all the tools necessary to program these newer "TinyAVR" MCUs with their windows-only IDE. There are also "Arduino cores" for some of these newer "TinyAVR" MCUs that let you program them with the Arduino IDE. But again, if you like to write code for MCUs in "baremetal" style, with your favorite text editor, a makefile, and a c-compiler, there are few resources available online. </p>

<p>In this blog post, we will describe how to program a <a href="https://www.ladyada.net/learn/proj1/blinky.html">blinky</a> firmware on an <strong>Attiny406</strong>, from the ground up, using the simplest tools. Most of the things described here can be easily transposed to other TinyAVR MCUs. Our approach is generally guided toward macOS or Linux users, but should also be applicable in an MS-Windows environment with a few minor changes.</p>

<h2 id="hardware">Hardware</h2>

<p>We decided to play with the <a href="https://www.microchip.com/wwwproducts/en/ATTINY406">Attiny406</a>, with a view of using it in the future to replace the Attiny45 we currently use on the <a href="https://www.omzlo.com/articles/the-piwatcher">PiWatcher</a>, our Raspberry-Pi watchdog. The Attiny406 has 4K of flash space, 256 bytes of RAM, and can run at 20Mhz without an external clock source.</p>

<p>One of the most important differences between the new TinyAVR MCUs and the older classic AVR MCU like the Attiny85 is that the newer chips use a different programming protocol called UPDI, which requires only 3 pins, as opposed to the 6-pin ISP on the classic AVRs.</p>

<p>A little research shows that programming TinyAVRs with UPDI can be achieved with a simple USB-to-serial cable and a resistor, thanks to a python tool called <a href="https://github.com/mraardvark/pyupdi">pyupdi</a>, which suggests the following connection diagram for firmware upload:</p>
<pre>                        Vcc                     Vcc
                        +-+                     +-+
                         |                       |
 +---------------------+ |                       | +--------------------+
 | Serial port         +-+                       +-+  AVR device        |
 |                     |      +----------+         |                    |
 |                  TX +------+   4k7    +---------+ UPDI               |
 |                     |      +----------+    |    |                    |
 |                     |                      |    |                    |
 |                  RX +----------------------+    |                    |
 |                     |                           |                    |
 |                     +--+                     +--+                    |
 +---------------------+  |                     |  +--------------------+
                         +-+                   +-+
                         GND                   GND
</pre>
<h3 id="shematic">shematic</h3>

<p>We created a minimalistic breakout board for the Attiny406. The board can be powered by 5V through USB or a lower 3.3V through dedicated VCC/GND pins. An LED and a button were also fitted on the board. For testing purposes, we decided to embed the 4.7K resistor needed for the UPDI programming directly in the hardware (i.e. resistor <em>R2</em>). 
This gives us the following schematic:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-schematic.png" alt="schematic"></p>

<h3 id="board">Board</h3>

<p>The resulting breakout board is tiny and fits conveniently on a small breadboard. The design files are <a href="https://aisler.net/p/SIEGFIYL">shared on aisler.net</a>.</p>

<p><img src="https://www.omzlo.com/uploads/std_attiny-406-breadboard.jpg" alt=""></p>

<p>Programming the Attiny406 on the board with a USB-serial cable is done by connecting the headers on the board edge:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-prog.png" alt=""></p>

<h2 id="software">Software</h2>

<h3 id="pyudpi">pyudpi</h3>

<p>We installed <strong>pyupdi</strong> following the instructions provided on <a href="https://github.com/mraardvark/pyupdi">their webpage</a>. </p>

<p>We connected our USB-Serial cable to the board with the 4 dedicated UPDI pins available on the board. Our USB-Serial converter shows up as the file <code>/dev/tty.usbserial-FTF5HUAV</code> on a MacOS system.</p>

<p>To test that the programmer recognizes the Attiny406, you can issue a command similar to the following, adapting the path for the USB-serial converter to your setup:</p>
<pre>pyupdi -d tiny406 -c /dev/tty.usbserial-FTF5HUAV -i
</pre>
<p>This should result in the following output if all goes well:</p>
<pre>Device info: {'family': 'tinyAVR', 'nvm': 'P:0', 'ocd': 'D:0', 'osc': '3', 'device_id': '1E9225', 'device_rev': '0.1'}
</pre>
<h3 id="the-c-compiler">The C compiler</h3>

<p>The typical <strong>avr-gcc</strong> available on macOS with <a href="https://brew.sh/">homebrew</a> did not seem to recognize the Attiny406 as a compiler target, so we went off to install the avr-gcc compiler provided by Microchip, which is available <a href="https://www.microchip.com/mplab/avr-support/avr-and-arm-toolchains-c-compilers">here</a>. Downloading the compiler requires you to create an account on the Microchip website, which is a bit annoying. </p>

<p><img src="https://www.omzlo.com/uploads/avr-toolchain.png" alt="AVR toolchain link"></p>

<p>Once downloaded, we extracted the provided archive in a dedicated directory. The <code>bin</code> directory in the archive should be added to the <code>PATH</code> variable to make your life easier. Assuming the downloaded compiler is stored in the directory <code>$HOME/Src/avr8-gnu-toolchain-darwin_x86_64</code>, the PATH can be altered by adding the following line to your <code>.bash_profile</code> file:</p>
<pre>export PATH=$PATH:$HOME/Src/avr8-gnu-toolchain-darwin_x86_64/bin/
</pre>
<p>Newer Attiny MCUs are not supported out of the box by the Microchip <strong>avc-gcc</strong> compiler. You need to download a dedicated <em>Attiny Device Pack</em> from <a href="http://packs.download.atmel.com/">their website</a>, as shown below:</p>

<p><img src="https://www.omzlo.com/uploads/microchip-pack-repository.png" alt="AVR toolchain link"></p>

<p>The resulting downloaded <em>Device Pack</em> is named <code>Atmel.ATtiny_DFP.1.6.326.atpack</code> (or similar depending on versioning). Though the extension is <code>.atpack</code>, the file is actually a zip archive. We changed the extension to <code>.zip</code> and extracted the package in the directory <code>$HOME/Src/Atmel.ATtiny_DFP.1.6.326</code> next to the compiler files. </p>

<h3 id="c-program">C program</h3>

<p>We created the following program that blinks the LED on pin PB5 of our Attiny board at a frequency of 1Hz.</p>
<pre><span>#include &lt;avr/io.h&gt;
#include &lt;util/delay.h&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>_PROTECTED_WRITE</span><span>(</span><span>CLKCTRL</span><span>.</span><span>MCLKCTRLB</span><span>,</span> <span>0</span><span>);</span> <span>// set to 20Mhz (assuming fuse 0x02 is set to 2)</span>

    <span>PORTB</span><span>.</span><span>DIRSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>PORTB</span><span>.</span><span>OUTSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
        <span>PORTB</span><span>.</span><span>OUTCLR</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre>
<p>The code looks very similar to what you would see on a classic AVR "blinky" program. One visible change is the use of structures to access various registers of the MCU: e.g instead of setting bits in <code>PORTB</code>, you access <code>PORTB.DIRSET</code>.</p>

<p>The other visible change is the clock setup code <code>_PROTECTED_WRITE(CLKCTRL.MCLKCTRLB, 0)</code>. Out of the box, at reset, the Attiny406 runs at 3.33Mhz, which corresponds to a base frequency of 20Mhz with a 6x clock divider applied. To enable the full 20Mhz speed, the register <code>CLKCTRL.MCLKCTRLB</code> is cleared. Because this register needs to be protected against accidental changes, the Attiny406 requires a specific programming sequence to modify it. Fortunately, this is natively offered by the macro <code>_PROTECTED_WRITE</code>. More details are available in the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/ATtiny406-DataSheet-DS40001976B.pdf">Attiny406 datasheet</a>.</p>

<p>In comparison with an STM32 or a SAMD21, the code is blissfully simple. </p>

<h3 id="makefile">Makefile</h3>

<p>We assume the following directory structure where:</p>

<ul>
<li><code>Src/Atmel.ATtiny_DFP.1.6.326/</code> is the location of the Microchip <em>Device Pack</em></li>
<li><code>Src/attiny406-test/</code> is the directory where the code above is stored in a file called <code>main.c</code></li>
</ul>

<p>Compiling the code can be done by issuing the following command within <code>attiny406-test/</code> directory,:</p>
<pre>avr-gcc -mmcu=attiny406 -B ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ -O3 -I ../Atmel.ATtiny_DFP.1.6.326/include/ -DF_CPU=20000000L -o attiny406-test.elf main.c
</pre>
<p>An <code>-O</code> optimization flag is required to make the <code>_delay_ms()</code> function calls work successfully, as well as defining the variable F_CPU to reflect the expected chip clock speed. The rest of the parameters provide the location of the Attiny406 device-specific files we previously extracted from the <em>Device Pack</em>.</p>

<p>Uploading the firmware to the MCU requires a conversion to the intel HEX format and a call to the <strong>pyupdi</strong> tool. To address all these steps, we created a simple Makefile.</p>
<pre><span>OBJS</span><span>=</span>main.o
<span>ELF</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.elf  
<span>HEX</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.hex
<span>F_CPU</span><span>=</span>20000000L


<span>CFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ <span>-O3</span>
CFLAGS+<span>=</span><span>-I</span> ../Atmel.ATtiny_DFP.1.6.326/include/ <span>-DF_CPU</span><span>=</span><span>$(</span>F_CPU<span>)</span>
<span>LDFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/
<span>CC</span><span>=</span>avr-gcc
<span>LD</span><span>=</span>avr-gcc

all:    <span>$(</span>HEX<span>)</span>  

<span>$(</span>ELF<span>)</span>: <span>$(</span>OBJS<span>)</span>
                <span>$(</span>LD<span>)</span> <span>$(</span>LDFLAGS<span>)</span> <span>-o</span> <span>$@</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>LDLIBS<span>)</span>

<span>$(</span>HEX<span>)</span>: <span>$(</span>ELF<span>)</span>
                avr-objcopy <span>-O</span> ihex <span>-R</span> .eeprom <span>$&lt;</span> <span>$@</span>

flash:  <span>$(</span>HEX<span>)</span>
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-f</span> attiny406-test.hex

read-fuses:
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-fr</span>

clean:
                <span>rm</span> <span>-rf</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>ELF<span>)</span> <span>$(</span>HEX<span>)</span>
</pre>
<p>To compile the code, we simply type <code>make</code>. Uploading is done with <code>make flash</code>. This Makefile can be further enhanced as needed.</p>

<h2 id="conclusion">Conclusion</h2>

<p>With the right tools, baremetal programming on the new TinyAVR MCUs is as simple as on its older AVR cousins. </p>

<p>If you have programming tips for the AVRTiny, please share them with us on <a href="https://twitter.com/OmzloElec">on Twitter</a> or in the comments below.</p>
</div></section><section><div><h4>Comments</h4><div><div><p>Hi, </p>

<p>It's great that …</p></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</a></em></p>]]>
            </description>
            <link>https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648397</guid>
            <pubDate>Thu, 01 Oct 2020 07:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start your open-source venture with AsyncAPI at Hacktoberfest]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648373">thread link</a>) | @derberg
<br/>
October 1, 2020 | https://www.asyncapi.com/blog/hacktoberfest-2020 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/hacktoberfest-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/hacktoberfest.webp" alt="Post cover image"><h2 id="what-is-asyncapi">What is AsyncAPI</h2><p>AsyncAPI is a specification for describing your <a href="https://www.asyncapi.com/docs/getting-started/event-driven-architectures/">event-driven architecture</a>. You are probably using already <a href="https://www.asyncapi.com/docs/getting-started/coming-from-openapi/">OpenAPI/Swagger specification</a> for describing your synchronous RESTful APIs. AsyncAPI is something that supplements OpenAPI. As an example, you should use AsyncAPI when your services do not talk to each other directly but through a message broker.</p><p>In contrast to the OpenAPI Initiative, AsyncAPI Initiative is focused not only on creating and evolving the AsyncAPI specification but also on its tooling. It is a vendor-neutral space for the community to work together on the spec and its tools. We work on tools like specification parsers or docs and code generators.</p><p><iframe src="https://www.youtube.com/embed/pU71J-F7pfI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="what-is-hacktoberfest-and-why-asyncapi-initiative-joins-it">What Is Hacktoberfest And Why AsyncAPI Initiative Joins It</h2><p><a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> is a well-known event that promotes open source contributions. In short, you have the entire October to submit four pull requests to any project you want, and in exchange, you get a super cool t-shirt. Is that it? Is it just for a t-shirt? Nah, the t-shirt is nice but what you also get is easy access to open source world. Maintainers of many projects open up for contributions, and it is a great chance to make your first step to joining this fantastic world.</p><p>AsyncAPI Initiative joins the Hacktoberfest for two main reasons:</p><ul><li>Promote AsyncAPI Initiative as a place where we don't work on the specification only but also build a lot of great tools</li><li>Make it much easier for the community to make the first contribution to one of the AsyncAPI repositories</li></ul><p>In the past, we were also there where you are now, shy and uncertain if we can impact open source community. We want to give you an easy path to take the first baby steps in the world of open source in a welcoming and friendly environment.</p><blockquote><p>Don't forget to <a href="https://hacktoberfest.digitalocean.com/login">sign up</a> to the Hacktoberfest</p></blockquote><p><iframe src="https://www.youtube.com/embed/_1WRr3Ml9t4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="how-can-you-help">How Can You Help</h2><p>There is always a lot of work waiting out there. For the sake of this special event, we prepared around 75 GitHub issues that you can pick up. They represent different areas (for example, JavaScript or HTML), different difficulty (for example, 50 issues are easy), and different repositories. No matter if they are trivial or demanding, all of them are important for us. Even with trivial ones where you, for example, need to remove a semicolon, we will still be super happy because this will improve the quality of the project (SonarCloud reports). In other words, every single issue from <a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">this</a> list is important.</p><h3 id="1-pick-the-right-issue">1. Pick The Right Issue</h3><p><a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">Here</a> you can find a list of all the issues that you can work on. Most of the issues are about code contribution, but not all of them. There are also issues about documentation or CI/CD configuration (we use GitHub Actions). Just pick the issues you want to work on, one at a time, and let us know in the comments section that you want to work on it.</p><p><iframe src="https://www.youtube.com/embed/Iqs_2BiNEEo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h3 id="2-setup-your-environment-and-create-a-first-pull-request">2. Setup Your Environment And Create A First Pull Request</h3><p>Once you <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">install Git</a> on your machine and get a <a href="https://github.com/join">GitHub account</a>, you need first to decide if you are here just for Hacktoberfest or longer, and make sure if your issue is easy and maybe you can complete it in the GitHub UI. </p><p>In case you are here just for the Hacktoberfest, and you picked easy issues that involve changes only to a single file, there is no need to install Git and complicate your life. GitHub UI enables you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-files-in-a-repository/editing-files-in-your-repository">make changes to a single file online</a>.</p><p>In case you:</p><ul><li>want to stay with us longer,</li><li>you picked up an issue where you need to make changes to more than just one file,</li><li>you also need to run the project locally to check if it works</li></ul><p>Then follow <a href="https://github.com/asyncapi/.github/blob/master/git-workflow.md">this</a> short instruction on how to fork the repository and set it up locally.</p><p>Once you are ready with your changes, submit a pull request. Be nice and follow our <a href="https://github.com/asyncapi/.github/blob/master/CODE_OF_CONDUCT.md">code of conduct</a> and make sure your pull request is <a href="https://github.com/asyncapi/.github/blob/master/CONTRIBUTING.md#conventional-commits">described properly</a>.</p><p><iframe src="https://www.youtube.com/embed/BsC5tu4M1rw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="office-hours">Office Hours</h2><p>Do you feel overwhelmed? No need. You can do it. Just take this blog post seriously. </p><p>Trust me when I write that every pull request is crucial for us.
Trust me when I write that we are a welcoming community.
Don't be afraid that you will waste our time. If we would think about it this way, we would not even join the Hacktoberfest.</p><p>Still not sure if you can make it? Don't worry. We want to host office hours throughout the event, 2x a week, 1h long, and different time zones. You can join whenever you want and ask us anything, or do pair programming with us. We start with the first meeting on <a href="https://calendar.google.com/calendar/u/0?cid=dGJyYmZxNGRlNWJjbmd0OG9rdmV2NGxzdGtAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">Tuesday 6th, 8AM UTC</a> and then on the following days:</p><ul><li>Tuesday 6th, 8AM UTC</li><li>Thursday 8th, 4PM UTC</li><li>Tuesday 13th, 8AM UTC</li><li>Thursday 15th, 4PM UTC</li><li>Tuesday 20th, 8AM UTC</li><li>Thursday 22nd, 4PM UTC</li><li>Tuesday 27th, 8AM UTC</li><li>Thursday 29th, 4PM UTC</li></ul><p>You can also join us in a more asynchronous discussion on <a href="https://www.asyncapi.com/slack-invite/">Slack</a>. For updates and latest news, the best is to follow our <a href="https://twitter.com/AsyncAPISpec">Twitter account</a>. </p><h2 id="blooper-reel">Blooper Reel</h2><p>Before you jump to your first contribution, have a look at the making of the videos. It was quite fun.</p><p><iframe src="https://www.youtube.com/embed/anjcF2l0lGs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><p>Enjoy the Hacktoberfest!</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/hacktoberfest-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648373</guid>
            <pubDate>Thu, 01 Oct 2020 07:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MobX 6]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24648363">thread link</a>) | @nikivi
<br/>
October 1, 2020 | https://michel.codes/blogs/mobx6 | <a href="https://web.archive.org/web/*/https://michel.codes/blogs/mobx6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><section><center><br><small>September 24, 2020</small></center><div><h2>Five years of MobX</h2>
<p>Time flies, and it has been 5.5 years since the first commit to MobX was made to build <a href="https://www.mendix.com/">Mendix Studio</a>.
In those years MobX has been adopted by well-known Software companies like Microsoft (Outlook), Netflix, Amazon and, my personal favorite, it runs in the Battlefield games by EA.
<a href="https://www.amazon.co.uk/MobX-Quick-Start-Guide-Supercharge/dp/1789344832/ref=sr_1_1?crid=BRUIHPUQL64D&amp;dchild=1&amp;keywords=mobx&amp;qid=1600809874&amp;s=books&amp;sprefix=mobx%2Caps%2C138&amp;sr=1-1">Books</a> and video courses have been written, and so have implementations in other languages.</p>
<p><span>
    <span></span>
    <img alt="Battlefield &amp; MobX" title="" src="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg" srcset="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/08cbc/dice.jpg 160w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/37ac5/dice.jpg 320w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg 640w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/52793/dice.jpg 800w" sizes="(max-width: 640px) 100vw, 640px">
  </span></p>
<p>Yet, since that first commit the philosophy of the MobX hasn't changed: <em>Anything that can be derived from the application state, should be derived. Automatically.</em>.
The API hasn't changed too much since those days either,
and you will find the original <a href="https://www.mendix.com/blog/making-react-reactive-pursuit-high-performing-easily-maintainable-react-apps/">introduction of MobX</a> still pretty recognizable.
If <code>React.createClass</code> still rings a bell that is.</p>
<p>In contrast, the JavaScript eco-system has changed significantly over the years.
TypeScript and Babel have become the de-facto standards.
React went from <code>createClass</code> to classes to hook-based function components.
Yet, relevant JavaScript proposals for observables, Object.observe and decorators have never materialized.</p>
<p>MobX 6 is a new major version that doesn't bring many new features, but is rather a consolidation of MobX on the current state of affairs in JavaScript.
That doesn't come without a few plot twists, so if you are an existing MobX user, please read till the end!</p>
<h2>Bye bye decorators</h2>
<p>Let's start with the bad news: Using decorators is no longer the norm in MobX.
This is good news to some of you, but others will hate it.
Rightfully so, because I concur that the declarative syntax of decorators is still the best that can be offered.
When MobX started, it was a TypeScript only project, so decorators were available.
Still experimental, but obviously they were going to be standardized soon.
That was my expectation at least (I did mostly Java and C# before).
However, that moment still hasn't come yet, and two decorators proposals have been cancelled in the mean time.
Although they still can be transpiled.</p>
<p>So why did we stop using decorators by default?</p>
<p>First of all, the current experimental decorator implementations are incompatible with the soon-to-be-standardized class-fields proposal.
The legacy (Babel) and experimental (TypeScript) decorator implementations will no longer be able to <a href="https://github.com/tc39/proposal-class-fields/issues/151">trap class fields initializations</a>.</p>
<p>Secondly, using decorators has always been a serious hurdle in adopting and advocating MobX.
In Babel, it is quite fragile to set up.
<code>create-react-app</code> doesn't support it out of the box, and many developers rightfully don't like to use non-standard features.
Even though decorators have always been optional in MobX, the fact that they were prominent in the docs left many confused.
Or as one MobX fan <a href="https://github.com/mobxjs/mobx/issues/2325#issuecomment-693130586">puts it</a>:</p>
<p><em>I am guessing this choice [to drop decorators] was probably a good call. Maybe now without decorators I am hopeful I will be able to convey to people how amazing Mobx is and at least I won't hear the decorators excuse anymore. I have never seen an "@" sign scare so many people.</em></p>
<p>So, what does MobX after decorators look like?
Simply put, instead of decorating class members during the class definition, instance members need to be annotated in the constructor instead, using the new <code>makeObservable</code> utility:</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span>observable<span>,</span> computed<span>,</span> action<span>,</span> makeObservable<span>}</span> <span>from</span> <span>"mobx"</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>,</span> <span>{</span>
            todos<span>:</span> observable<span>,</span>
            unfinishedTodoCount<span>:</span> computed<span>,</span>
            addTodo<span>:</span> action
        <span>}</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Admittedly, this is a slightly worse DX than before, since member and annotation are no longer co-located.
But the good news is that using <code>makeObservable</code> doesn't require any fancy build setup.
It should work everywhere out of the box.</p>
<p>Migrating an entire code-base from decorators to <code>makeObservable</code> might be challenging, so that is why we released a <a href="https://www.npmjs.com/package/mobx-undecorate">code-mod</a> together with MobX 6 to do that automatically!
Just run the command <code>npx mobx-undecorate</code> inside the folder where your source files live, and after that all decorators should have been magically rewritten!
After that, make sure to <a href="https://mobx.js.org/migrating-from-4-or-5.html#getting-started">update your TypeScript / babel config</a>, and you should be good to go!</p>
<h2>Introducing <code>makeAutoObservable</code></h2>
<p>We realize it is easier to make mistakes now that the annotations are no longer adjacent to the fields they are decorating.
Hence a convenience utility has been introduced that automates the annotation process by picking sane defaults: <code>makeAutoObservable</code>.
It will automatically pick the best annotation for every member of a class, thereby simplifying the above listing to:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeAutoObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that it is possible to pass a map of <em>overrides</em> as second argument, in case you want to use a modifier.
For example: <code>makeAutoObservable(this, { todos: observable.shallow })</code>.
Pass <code>member: false</code> to have MobX ignore that member entirely.
(Technical fineprint: class methods will not be decorated with <code>action</code>, but with the new <code>autoAction</code>, this annotation will make methods suitable to be used both as a state updating action, or as function that derives information from state).</p>
<p>What I personally like about <code>makeAutoObservable</code> is that it plays really nice with factory functions.
Which is great if you prefer to not use classes (factory functions make it is easy to hide members and prevent issues with <code>this</code> and <code>new</code>. And they compose more easily).
The same store expressed as factory function will look as follows. Pick the style that suits you:</p>
<div data-language="typescript"><pre><code><span>function</span> <span>createTodoStore</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>makeAutoObservable</span><span>(</span><span>{</span>
        todos<span>:</span> <span>[</span><span>]</span> <span>as</span> Todo<span>[</span><span>]</span><span>,</span>
        <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
            <span>return</span> store<span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
        <span>}</span><span>,</span>
        <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
            store<span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
        <span>}</span>
    <span>}</span><span>)</span>
    <span>return</span> store
<span>}</span></code></pre></div>
<h2>Fresh docs!</h2>
<p>Since decorators are no longer the norm, <a href="https://twitter.com/faassen">Martijn Faassen</a>, <a href="https://twitter.com/zangornjak">Žan Gornjak</a> and yours truly went over all the documentation.
We updated all examples and significantly restructured the docs that have grown quite organically over the years.
We feel the current docs are shorter, have less repetition, and better discuss common scenarios.
Also, we marked all non-essential knowledge in the docs with a {🚀} rocket emoji, to make it clear which knowledge is optional.
Hopefully it is much quicker now to find your way around in MobX!</p>
<p>On a similar note, we've updated all <a href="https://mobx.js.org/react-integration.html">React related documentation</a> to use function components instead of class components. And added documentation on how to use MobX with hooks, context and effects.
This knowledge existed before (little has changed technically), but was scattered all over the place.
As a result, we now recommend <code>mobx-react-lite</code> over <code>mobx-react</code> for (greenfield) projects that don't use class components.
As a result the separate mobx-react.js.org/ website has been deprecated.
All credits go to <a href="https://twitter.com/danielk_cz">Daniel K</a> for maintaining those two projects!</p>
<p>And finally, there is now a <a href="https://gum.co/fSocU">one pager MobX 6 cheat sheet 👨‍🎓</a> covering all the import mobx / mobx-react(-lite) API's.
(It is a great way to one-time sponser the project in an invoicable way).</p>
<h2>Improved browser support</h2>
<p>A probably little surprising improvement in MobX 6 is that it supports <em>more</em> JavaScript engines than MobX 5.
MobX 5 required proxy support, making MobX unsuitable for Internet Explorer or React Native (depending on the engine).
For this reason MobX 4 was still actively maintained.
However, MobX 6 replaces both at once.</p>
<p>By default MobX 6 will still require Proxies, but it is possible to opt-out from Proxy usage in case you need to support older engines.
And, as a result, it is now possible for MobX 6 to warn in development mode when features that would require proxies are used.
See the documentation for more <a href="https://mobx.js.org/configuration.html#proxy-support">details</a>.</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span> configure <span>}</span> <span>from</span> <span>"mobx"</span>

<span>configure</span><span>(</span><span>{</span>
    
    
    
    useProxies<span>:</span> <span>"never"</span>
<span>}</span><span>)</span></code></pre></div>
<h2>Decorators are back!</h2>
<p>Ok, time for the plot twist. MobX 6 stills supports decorators!
The decorator implementation in MobX 6 is entirely different from the one in earlier versions, but does work with the current implementations in TypeScript and Babel.
It basically provides an alternative way to construct the annotations map for <code>makeObservable</code>, and allows us to rewrite the first example as:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that we still need to add a constructor to the class, but this time we omit the second argument to <code>makeObservable</code>, so that it will rely on the decorators instead.
We don't recommend this set up for greenfield projects, after all decorators are still experimental, but this is a great compromise for
existing code bases.
Generating constructors without removing decorators is supported by <code>mobx-undecorate</code> as well, and can be achieved by running <code>npx mobx-undecorate --keepDecorators</code>.</p>
<p>And here is even more good news: There is a fresh <a href="https://github.com/tc39/proposal-decorators">decorators proposal</a> being championed by the tireless hero <a href="https://twitter.com/littledan">Daniel Ehrenberg</a>.
I've been a bit involved in it, and the MobX use case has inspired the proposal.
So the benefits of the fresh decorator implementation are that it a) solves the compatibility issue with the class fields spec discussed above, and
b) it also paves the way …</p></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michel.codes/blogs/mobx6">https://michel.codes/blogs/mobx6</a></em></p>]]>
            </description>
            <link>https://michel.codes/blogs/mobx6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648363</guid>
            <pubDate>Thu, 01 Oct 2020 07:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Decision of My Career]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24648256">thread link</a>) | @fribmendes
<br/>
October 1, 2020 | https://subvisual.com/blog/posts/the-worst-decision-of-my-career/ | <a href="https://web.archive.org/web/*/https://subvisual.com/blog/posts/the-worst-decision-of-my-career/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><section><div><div><div><div><div><div>
<p>This is a reflection on software development and complexity. Let's start with
some quotes to make me look smart:</p>
<blockquote>
<p>A complex system that works is invariably found to have evolved from a simple
system that worked. A complex system designed from scratch never works and
cannot be patched up to make it work. You have to start over with a working
simple system -- <em>Gall's law</em></p>
</blockquote>
<p>I only came across this quote recently, but I think that it summarizes what
I've learned these past seven years. Another idea that I've found in a few books
is that programming in isolation is problem-solving, but software engineering
is all about managing complexity. This distinction between programming and
software engineering makes sense to me, probably because of my mental models.
I'm sure we can all disagree on this, but that's not the topic of today.
Complexity is.</p>
<h2>Complexity</h2>
<p>Almost everyone I know in the software industry wants to build products that
solve real and challenging problems. Change the world! The last thing you want
is to build another CRUD application. They are fine, but it gets boring after
a while.</p>
<p>Most of us will get bored without novelty. That's why the software industry has
a recycling mechanism to keep things fresh and interesting for us: every once
in a while a new, or different, language/framework will rise and light the path
for a brighter future, overthrowing the existing standard, demanding that we
learn it to be on top of the game.</p>
<p>We change our tools, but we keep building the same things over and over. I've
been doing this long enough to see that we are just going in circles. Let's be
honest, most of us aren't building life-changing products that wouldn't have
been possible ten years ago, so let's not jump straight into another shiny
technology that just came out and is going to solve all of our problems.</p>
<h2>Solutions, solutions, solutions</h2>
<blockquote>
<p>For a while, the solution to every problem I encountered was a Rails app. --
<em>this one is mine</em></p>
</blockquote>
<p>Over the years, I've seen companies rewrite their products to change languages,
frameworks, or architectures because they were told that the change would make
their product better, run faster, and scale. By the way, you're only a true
Ruby developer after you've heard the question "but does it scale?" at least
one hundred times (kidding, but it'll happen).</p>
<p>Think about it, how many times were you sold a new programming language,
technology, or a concept like microservices, serverless, event sourcing, clean
architecture, micro frontends. There are many preachers in the software world.</p>
<p>At Subvisual, we started using Elixir a lot these past years, so I've learned
a bit about the history of Erlang. If you don't know, Erlang uses the Actor
Model, and the interesting part is that the designers of Erlang only learned
about the Actor Model after having designed Erlang. This is important because
the designers of Erlang didn't start with the intent of applying the Actor
Model; it came as a solution to fault-tolerant distributed programming.</p>
<blockquote>
<p>If all you have is a hammer, everything looks like a nail <em>Abraham Maslow</em></p>
</blockquote>
<p>The designers of Erlang picked the right tool for the job and most of us want
to do the same. Unfortunately, there's usually more than one "tool" that would
be "right," but to know which ones, you need to know what "job" you're solving.
All of us <strong>should</strong> know this, but I keep learning about teams that fail to do
it. There are so many companies, with a handful of experienced developers, that
don't know what they are building, don't have a clear business yet, but their
product is already built on complex architectures and technologies such as
microservices, Kubernetes or event-sourcing.</p>
<h2>Improving</h2>
<p>Every project we start from scratch is an opportunity to do it right. We'll
think to ourselves: <em>This time I won't fall into the same traps! I have learned
my lessons, I've studied the books, and I even met some of my gurus that wrote
them! This time I'll follow "industry standards"!</em></p>
<p><em>I am the "architect"; I will design the perfect system! Without me, none of
this will be possible. Those mindless programmers have no idea what they are
doing. I, and only I, am the true heir of Martin Fowler!</em></p>
<p>This was a bit dramatic, but I needed a break from all of that whining. I know
it's easy to fall into these traps. It's even easier when your company raised
money, and everyone is expecting you to deliver the absolute best product ever
because they are paying you for it! This is why your starting team is so
important; they have to withstand the pressure. They must know that to build
the grand vision, they have to go one step at a time.</p>
<h2>The decision</h2>
<p>I've made many bad decisions, and I've been fortunate enough to suffer the
consequences of those decisions. A lot of developers don't get to experience
consequences, so they never learn.</p>
<p>So what was the worst decision of my career? I don't know. But the title of
this blog post is inspired by something an old colleague said. At the time, we
were working for a product company that reached for event-driven architecture
and event-sourcing too soon. They knew little about their market, and the
choices the software team made were crippling their ability to change. Business
rules were almost set in stone. Migrating data was a pain and the source of
many bugs. And unfortunately, because the team didn't have experience with
event-sourcing, the event store, which kept the state of all services, was also
being used as an event-bus to communicate between services. Because of that, it
was possible to couple one service to the internal state of another, which
happened a lot. This almost invisible coupling made everything worse.</p>
<p>What did we do against such an unpredictable system? We took it apart: merging
services that were too coupled; defining clear boundaries between services;
moving some services away from the event-store into a traditional database;
making some communication channels synchronous; writing integration and
end-to-end tests.</p>
<p>When we were finished it was still an unnecessarily complex system, but it was
one that we could change with some confidence. After that, we defined
a long-term plan for the product's architecture and technology, but we didn't
implement it. We waited for the right moment when something was starting to
slow us down to make a small step in that direction. When the business goals
changed, we changed our long-term plan, and once again made small steps in that
direction when we felt the need for it.</p>
<p>Eventually, complexity found its way again into the codebase, but it was fine
because the codebase was evolving slowing, adding and removing complexity when
necessary.</p>
<h2>Making the right call</h2>
<p>Was that the worst decision of his career? I don't think so. The issue with him
going for event-sourcing and event-driven architecture was that it wasn't the
right moment, but my colleague didn't know that. He thought the goals for the
next years were well defined, but unfortunately, they never are.</p>
<p>Should you use microservices or event-sourcing? Maybe, it depends on the
context and the client. The decisions I make are the best that I can with the
information that I have. For instance, when I'm part of the team that's
starting a product, the technology we pick will depend on how we'll hire: if
you want to build an office in Portugal, we have to make sure we have
developers for that technology available. We have to think things through, and
some things you only learn from experience. This applies to the systems we
design as well. I've seen enough people design around what they believe the
product will become in two years to know that those designs always fail to
accommodate the changes that will come. So we design systems for small,
incremental changes. Do the smallest thing that will get us started and
doesn't compromise our ability to change once we know what the business needs.</p></div></div></div></div></div></div></section></article></div></div></div>]]>
            </description>
            <link>https://subvisual.com/blog/posts/the-worst-decision-of-my-career/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648256</guid>
            <pubDate>Thu, 01 Oct 2020 07:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before You Start Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647918">thread link</a>) | @dinomad
<br/>
September 30, 2020 | https://scorpil.com/post/before-you-start-coding/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/before-you-start-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>Full disclosure: things discussed in this post are, to be frank, quite obvious. My intent is not so much to teach a reader something new, as to remind him what might have been forgotten. After all, anyone who does a single kind of work daily for years inevitably develops habits and mental-shortcuts that are <em>usually</em> useful but can misfire from time to time. After all, software development is too complex and too technical to be guided by subconscious intuition.</p><p>Pilots use pre-flight checks to combat this kind of problem, so why not developers? Here’s a check-list of things I find important to consider <strong>before</strong> writing the first line of code.</p><h3 id="set-your-target-straight">Set your target straight</h3><p>Imagine yourself solving these tasks:</p><ul><li>generating a single-use report for an established company</li><li>writing a feature in proof-of-concept MVP for a startup</li><li>extending at enterprise product that has 20 years of codebase support guarantee in its SLAs</li></ul><p>Clearly, it wouldn’t be smart to blindly apply the same set of software development best-practices for all three cases. You probably don’t need a perfectly polished code for a single-use report. A startup that operates in the “rush to market before we run out of money" mode is much more worried about the feature working than about its performance. Long-support code needs to be first and foremost maintainable. Also, if you’re working on a pet-project for fun, you might gasp skip writing tests (unless you enjoy writing tests, in which case I envy you a little bit). Some developers take so much pride in their craft that they lose sight of the forest behind the trees. Following all best practices and writing state-of-the-art code <em>feels</em> right, but logically it’s not the only option. Sometimes you should consciously generate technical debt. Reality constraints are not something that can be ignored.</p><p>As self-evident as this advice is, we’ve all heard stories where things went wrong because of misaligned goals. “Premature optimization” is a common special case. Refactoring an old codebase that rarely changes, just so it’s pretty, is another one. And to not leave you with the thought that goal misalignment is always linked to perfectionism: writing an unsupportable code to meet a <em>fictional</em> deadline, either self-imposed or forced on to developers by impatient management, is the same kind of error.</p><p>You need to know where to go before you can start thinking about how to get there. Think of the most important criteria your solution needs to fulfill and align your decision-making with those.</p><h3 id="consider-alternatives">Consider alternatives</h3><p>You’ve got the task in front of you, requirements are pretty clear, and you vaguely remember how you did something similar a few years before. Or maybe you don’t know how to solve it at first, but after some googling, you get a general idea. Start coding?</p><p>There are always multiple ways to solve a problem. The first viable solution is unlikely to be an optimal one. By focusing on the first approach discovered you rob yourself of choice. Do a thorough research first, and after you have options in front of you, carefully consider the pros and cons of each. There is no magical number of solutions you need. I often set the minimum bound to three for myself.</p><p>Selecting the right tool for a job is an obvious example of a decision that benefits from upfront research, and even then, in a real-world scenario, a tool that’s familiar often gets selected over the tool that fits. Don’t think this advice only applies to „macro“ decisions, it can be applied just as well for your everyday code design choices.</p><h3 id="consult-the-docs-yes-upfront">Consult the docs. Yes, upfront</h3><p>It’s impossible to keep up with the pace modern tech is moving. Doesn’t matter how many years of experience you have under your belt, when you pick up the project on a modern stack there will be tools and libraries, released recently, that have slipped under your radar. So most developers are in a constant in-flight-learning mode: picking up knowledge as they search answers on immediate questions. It’s an efficient way to learn, but it creates a risk of missing an easy solution because of the inability to form the right question.</p><p>Skimming the docs upfront, without digging deep into any particular topic, doesn’t take much time, but it helps create mental anchors, which your brain will fetch when you encounter the problem. You will have a better starting point for finding the right answer quickly.</p><h3 id="design-your-apis">Design your APIs</h3><p>The hardest part of writing code is to imagine in the minutest details how to handle each workflow, each exceptional situation, and each edge case. Many developers first solve a problem, then write a „wrapper“ to expose their work to the outside world through some kind of API (i don’t mean just REST API, function signatures and interfaces are APIs as well). Often this bottom-up design leads to an API that’s too „technical“, i.e. leaking it’s abstractions to the consumer. It’s hard to make your brain switch from one level of abstraction to another.</p><p>Before starting the work on implementation, put yourself in the shoes of the API user first (even if that user is you). What would be the user’s most common usage pattern? What’s the absolute minimal required set of parameters the API needs to have? Which terminology makes sense for the user? What input format would be most convenient? What defaults to set? It’s up to you how thorough you want this process to be.</p><h3 id="split-up-the-work">Split up the work</h3><p>Each entity in a system exponentially increases the number of possible interactions. Code that’s easy to reason about forms a pyramid of abstraction layers, each one hiding its inner workings from the layer above. Each layer can be reasoned about independently, limiting the amount of „moving parts“ you need to keep track of in your brain. If you succeed in splitting the task into multiple loosely coupled entities upfront, you will simplify your code and work process.</p><p>If the task at hand is large enough, it might make sense to form a tree-like task structure, starting from the highest level of abstraction and moving down the layers until the tasks are small enough. The „small enough“ parameter depends on your particular codebase, mindset, and type of work you do, but after a bit of practice, you’ll find what granularity suits you the best.</p><p>Each task should be fairly self-sufficient and ideally shouldn’t stay in “kinda-finished” state for long (“finished but not deployed”, “finished but not reviewed”, “finished but not tested” or “finished but waiting for authorization from XYZ department”). Finished is when you don’t think about it anymore and it doesn’t drain your mental resources.</p><p><img src="https://scorpil.com/img/tree.png" alt="Example of a task tree"></p><p>Do you have your own tips and tricks for organizing developer’s work? Please share!</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/before-you-start-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647918</guid>
            <pubDate>Thu, 01 Oct 2020 06:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Write Slow Rust Code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24647910">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/ | <a href="https://web.archive.org/web/*/https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post">
    
    
    <article>
        <p>There's a thing that comes up from time to time in the Rust community: people wanting to optimize their code. Make the code run faster. Make it allocate less memory. These are worthy goals, but maybe not necessary for all projects. Just because your program is written in Rust, it doesn't have to be optimized to the moon and back to do it's job. In a lot of cases, you'll be fine using <code>.clone()</code>.</p>
<p>There's a fantastic quote from a discussion on the <a href="https://users.rust-lang.org/">Rust user forums</a> which I always think of when these discussions emerge:</p>
<blockquote>
<p>Just because Rust allows you to write super cool non-allocating zero-copy algorithms safely, doesn't mean every algorithm you write should be super cool, zero-copy and non-allocating.<br>
-- <a href="https://users.rust-lang.org/t/feeling-rust-is-so-difficult/29962/15">trentj on The Rust Programming Language Forum</a></p>
</blockquote>
<p>Of course there's a time and place for <em>super cool no-allocating zero-copy algorithms</em>, but very often it's not the time, nor the place. You can write fantastically effective code with Rust, but <strong>you don't have to</strong>! A lot of the time it's entirely fine to just write code that works with minimal effort. You don't have to spend 4 days trying to figure out how lifetimes work just to avoid calling <code>.clone()</code> a few times.</p>
<p>Don't spend time trying to make micro optimizations now. Take the easy route. You'll probably come back to that piece of code in a few months time, smile, and change that <code>.clone()</code> to something more efficient.</p>
<p>Happy coding!</p>
<p><small>NB: Watch this <a href="https://youtu.be/rAl-9HwD858">video by Jon Gjengset</a> if you want a good, pragmatic walk through of lifetimes in Rust.</small></p>

    </article>
</div></div>]]>
            </description>
            <link>https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647910</guid>
            <pubDate>Thu, 01 Oct 2020 06:19:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed IOS14 Icons to to fight the screen time, clutter and visual fatigue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24647737">thread link</a>) | @hren
<br/>
September 30, 2020 | https://hren.io/products/iso14-home-screen-icons-set/ | <a href="https://web.archive.org/web/*/https://hren.io/products/iso14-home-screen-icons-set/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As IOS14 allows the customization of the home screen with the Shortcuts app, this icon set tries to fight the screen time, clutter and fatigue by minimizing visuals.</p><p>The goal is to also lover the Screen Time by only limited to one screen.</p><p>More icons will be added. For icon requests DM on<!-- --> <a href="https://twitter.com/@darjanhren" target="_blank">Twitter</a>.</p><p><a href="https://gum.co/wIROw" target="_blank">Get Calm Icon Set</a></p></div></div></div>]]>
            </description>
            <link>https://hren.io/products/iso14-home-screen-icons-set/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647737</guid>
            <pubDate>Thu, 01 Oct 2020 05:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running GitHub Actions for Certain Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24647722">thread link</a>) | @kiyanwang
<br/>
September 30, 2020 | https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages | <a href="https://web.archive.org/web/*/https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
                <section>
        
        <p>A quick look at how you can configure your GitHub Actions workflows to only run when a certain phrase is present in the commit message.</p>
                    <small>Published 5 days ago</small>
                            <span>|</span>
                <small>Updated 5 days ago</small>
                                                <p><span>
    Tooling
</span>
 
                                     <span>
    GitHub Actions
</span>
 
                            </p>
                        <article>
            <p>I'm going to be honest with you all for a second. I write a lot of <code>wip</code> commits. These commits are normally small changes that I want to push up to GitHub so that:</p>
<ol>
<li>I don't lose things if anything goes wrong and my backup hasn't picked it up.</li>
<li>If I can't describe the change I have just made.</li>
<li>If I'm demonstrating something to somebody on a pull-request.</li>
</ol>
<p>The problem is, my actions are setup to run on <code>push</code>, so every single <code>wip</code> commit gets run through the CI process, whether it be running tests, linting or formatting.</p>
<p>After doing some research, I found a way of preventing these from running on every single commit.</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"! contains(github.event.head_commit.message, 'wip')"</span>
</code></pre>
<p>Now, whenever I push a <code>wip</code> commit or any commit that contains the word <code>wip</code>, it will be marked as skipped inside of GitHub actions.</p>
<p>You could also flip the logic and perhaps do something like:</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"contains(github.event.head_commit.message, '[build]')"</span>
</code></pre>
<p>Any commit that contains <code>[build]</code> will now trigger these jobs, everything else will be skipped.</p>
<p>You can thank me later! 😉</p>

        </article>
    </section>
        </div>
    </div></div>]]>
            </description>
            <link>https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647722</guid>
            <pubDate>Thu, 01 Oct 2020 05:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prime and battery usage on Linux laptops: sometimes it's not what it seems to be]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646504">thread link</a>) | @todsacerdoti
<br/>
September 30, 2020 | https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://wiki.archlinux.org/index.php/PRIME">PRIME</a> is a technology used to manage hybrid graphics. It was meant to be a resource saver since you can configure it to use only the Integrated GPU, and render offload to the dedicated GPU whenever is needed. But that is not what happened in my real life situation.</p>

<p>I was not happy with the fact that my laptop was draining a lot of battery. Not only while using render offload by running software with <code>prime-run</code> and delegating gpu stuff to my dGPU(Nvidia MX150), but using the iGPU(i915 Intel) to daily stuff(terminal, browser) was also draining a lot of battery. Overheating was also a problem and then, i started to investigate.</p>
<p>Using <code>powertop -t 3</code> shown that Firefox was draining as much as <code>800 mW</code> per process(tab) on the <code>Power Est.</code> column. Meanwhile, <code>i915</code> module was using about <code>150 mW</code> alone. That got me thinking if, using the dedicated GPU to render stuff would get it better, but it didn’t. Launching Firefox with <code>prime-run</code> reduced a little the power usage per tab (opening the same websites), but the Intel module was still draining almost the same amount of power(<code>145 mW</code>) while the <code>nvidia</code> module was using <code>35mW</code>.</p>
<p>Other thing that bugged me was that my system always started with a lot of RAM already compromissed(<code>900MB</code>) on a simple <code>i3</code> setup. Could be the case where my iGPU was already allocating a lot of that resource to itself?</p>
<p>After that, i’ve decided to try some 3D, and <a href="https://veloren.net/">Veloren</a> was the game i’ve chosen. Those were the metrics captured with my status bar and <code>powertop</code>:</p>
<ul>
<li>
<p>Using <code>i915</code> driver:</p>
<ul>
<li>Driver drain reached <code>400mW</code>.</li>
<li><code>1,9 GB</code> Ram used</li>
<li>Battery expected duration after full charge was <code>1:28</code>.</li>
</ul>
</li>
<li>
<p>Using <code>nvidia</code> driver with <code>prime-run</code>.</p>
<ul>
<li><code>i915</code> driver was still draining <code>200 mW</code> approximately, spiking to <code>400</code> sometimes.</li>
<li><code>nvidia</code> driver was using about <code>50mW</code>, spiking to <code>80</code> once in a while.</li>
<li><code>1,7 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>Battery expected duration after full charge was <code>1:12</code>.</li>
<li>nvidia temperature reached <code>73ºC</code>.</li>
</ul>
</li>
</ul>
<p>I know that this doesn’t seems to be a fair test, comparing a dGPU with an iGPU while executing a game. The point I was trying to prove was: Using the render offload didn’t really help on reducing resource consumption at all. On the oposite, it seems that it somehow helped me to have resources wasted by doubling energy consumption due to this binding created between modules with the <a href="https://wiki.archlinux.org/index.php/PRIME#PRIME_render_offload">render offload</a> feature.</p>

<p>I was decided to try a new approach and use <a href="https://wiki.archlinux.org/index.php/NVIDIA_Optimus#Use_NVIDIA_graphics_only">Nvidia graphics only</a>. Setup was pretty straightforward and after rebooting, I’ve launched Firefox with the same sites and <code>Power Est.</code> was about <code>570mW</code> per process. Good news, lets try Veloren again:</p>
<ul>
<li>Using <code>nvidia</code> driver only
<ul>
<li><code>nvidia</code> driver was using about <code>120mW</code>.</li>
<li>Battery expected duration after full charge was <code>1:47</code>.</li>
<li><code>1,3 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>nvidia temperature reached <code>67ºC</code>.</li>
</ul>
</li>
</ul>
<p>That’s a lot better. I also noticed that my system was using only <code>500MB</code> RAM after a fresh start(a <code>400MB</code> difference).</p>
<p><strong>Lesson learned.</strong> Try things by yourself when it comes to power management.</p>

<p>Other things changed on my system after spending the weekend optimizing energy stuff:</p>
<ul>
<li>Not using <a href="https://github.com/tobi-wan-kenobi/bumblebee-status"><code>bumblebee-status</code></a> anymore. It’s a great bar, full of useful modules, but it was creating some weird spikes on power usage. Migrated to <a href="https://github.com/greshake/i3status-rust/"><code>i3status-rust</code></a> and now my bar isn’t even listed on the top 20 power usage agressors.
<ul>
<li>All previous tests were done using the same bar.</li>
</ul>
</li>
<li><code>telegram-desktop</code> is a mess on power and cpu usage and i’m seriously thinking on ditching this software and using it’s web version only. Firefox is a software I already use so, there’s nothing to lose.</li>
<li>Try to get used with some lightweight browser like <a href="https://qutebrowser.org/">qutebrowser</a> while on battery, and stop using my bookmark sync of choice. Have to test since not having video acceleration could be a caveat.</li>
<li>Find out why while using specific softwares <code>pulseaudio</code> gets crazy and it spikes with <code>4W</code> of Power Estimated usage.</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646504</guid>
            <pubDate>Thu, 01 Oct 2020 02:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Voice Assistant Spoke to Google Duplex. Here’s What Happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646421">thread link</a>) | @xingyzt
<br/>
September 30, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrkšić</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here’s a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">﻿</span></iframe></p>
<p>As far as we’re aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I’m incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we’d say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller’s request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant — Siri or Alexa, for example — to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel’s individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‘AI system for accomplishing real-world tasks over the phone’. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I’ll be the first to point out how incredible Google’s TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human – it does mention that it’s an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you’ll hear our voice assistant ask the caller when they’d like to come in, and Duplex speaks over it. In reality, these are machines – no-one’s getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it’s practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley – but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we’ll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary “Dr Livingstone, I presume” moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned – and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646421</guid>
            <pubDate>Thu, 01 Oct 2020 01:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Grand Design (2010)]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24646120">thread link</a>) | @got-any-grapes
<br/>
September 30, 2020 | https://blas.com/the-grand-design/ | <a href="https://web.archive.org/web/*/https://blas.com/the-grand-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">

			
				
	<article id="post-5144">
				<!-- .entry-header -->

				<div>
			
<p>Summary</p>



<ol><li>Traditionally these are questions for philosophy, but philosophy is dead. Philosophy has not kept up with modern developments in science, particularly physics. Scientists have become the bearers of the torch of discovery in our quest for knowledge. The purpose of this book is to give the answers that are suggested by recent discoveries and theoretical advances. They lead us to a new picture of the universe and our place in it that is very different from the traditional one, and different even from the picture we might have painted just a decade or two ago.</li></ol>



<p>Key Takeaways</p>



<ol><li>According to the traditional conception of the universe, objects move on well-defined paths and have definite histories. We can specify their precise position at each moment in time. Although that account is successful enough for everyday purposes, it was found in the 1920s that this “classical” picture could not account for the seemingly bizarre behavior observed on the atomic and subatomic scales of existence. Instead it was necessary to adopt a different framework, called quantum physics. Quantum theories have turned out to be remarkably accurate at predicting events on those scales, while also reproducing the predictions of the old classical theories when applied to the macroscopic world of daily life. But quantum and classical physics are based on very different conceptions of physical reality.</li><li><strong>We will explain Feynman’s approach in detail, and employ it to explore the idea that the universe itself has no single history, nor even an independent existence. That seems like a radical idea, even to many physicists. Indeed, like many notions in today’s science, it appears to violate common sense. But common sense is based upon everyday experience, not upon the universe as it is revealed through the marvels of technologies such as those that allow us to gaze deep into the atom or back to the early universe.</strong></li><li><strong>To deal with such paradoxes we shall adopt an approach that we call model-dependent realism. It is based on the idea that our brains interpret the input from our sensory organs by making a model of the world. When such a model is successful at explaining events, we tend to attribute to it, and to the elements and concepts that constitute it, the quality of reality or absolute truth. But there may be different ways in which one could model the same physical situation, with each employing different fundamental elements and concepts. If two such physical theories or models accurately predict the same events, one cannot be said to be more real than the other; rather, we are free to use whichever model is most convenient.</strong><ol><li><em>Model-dependent realism, mental models</em></li></ol></li><li><strong>M-theory is not a theory in the usual sense. It is a whole family of different theories, each of which is a good description of observations only in some range of physical situations. It is a bit like a map. As is well known, one cannot show the whole of the earth’s surface on a single map. The usual Mercator projection used for maps of the world makes areas appear larger and larger in the far north and south and doesn’t cover the North and South Poles. To faithfully map the entire earth, one has to use a collection of maps, each of which covers a limited region. The maps overlap each other, and where they do, they show the same landscape. M-theory is similar. The different theories in the M-theory family may look very different, but they can all be regarded as aspects of the same underlying theory. They are versions of the theory that are applicable only in limited ranges—for example, when certain quantities such as energy are small. Like the overlapping maps in a Mercator projection, where the ranges of different versions overlap, they predict the same phenomena. But just as there is no flat map that is a good representation of the earth’s entire surface, there is no single theory that is a good representation of observations in all situations.</strong><ol><li><em>The Mp is Not the Terrain</em></li></ol></li><li>Today most scientists would say a law of nature is a rule that is based upon an observed regularity and provides predictions that go beyond the immediate situations upon which it is based.<ol><li><em>General and broadly applicable</em></li></ol></li><li>Because it is so impractical to use the underlying physical laws to predict human behavior, we adopt what is called an effective theory. In physics, an effective theory is a framework created to model certain observed phenomena without describing in detail all of the underlying processes.</li><li>There is no picture- or theory-independent concept of reality. Instead we will adopt a view that we will call model-dependent realism: the idea that a physical theory or world picture is a model (generally of a mathematical nature) and a set of rules that connect the elements of the model to observations. This provides a framework with which to interpret modern science.</li><li><strong>We make models in science, but we also make them in everyday life. Model-dependent realism applies not only to scientific models but also to the conscious and subconscious mental models we all create in order to interpret and understand the everyday world. There is no way to remove the observer—us—from our perception of the world, which is created through our sensory processing and through the way we think and reason. Our perception—and hence the observations upon which our theories are based—is not direct, but rather is shaped by a kind of lens, the interpretive structure of our human brains.</strong><ol><li><em>Mental Models, Galilean Relativity</em></li></ol></li><li><strong>A model is a good model if it: Is elegant, Contains few arbitrary or adjustable elements, Agrees with and explains all existing observations, Makes detailed predictions about future observations that can disprove or falsify the model if they are not borne out.</strong></li><li>Another of the main tenets of quantum physics is the uncertainty principle, formulated by Werner Heisenberg in 1926. The uncertainty principle tells us that there are limits to our ability to simultaneously measure certain data, such as the position and velocity of a particle. According to the uncertainty principle, for example, if you multiply the uncertainty in the position of a particle by the uncertainty in its momentum (its mass times its velocity) the result can never be smaller than a certain fixed quantity, called Planck’s constant. That’s a tongue-twister, but its gist can be stated simply: The more precisely you measure speed, the less precisely you can measure position, and vice versa.</li><li><strong>In other words, nature does not dictate the outcome of any process or experiment, even in the simplest of situations. Rather, it allows a number of different eventualities, each with a certain likelihood of being realized.</strong></li><li>Given the state of a system at some time, the laws of nature determine the probabilities of various futures and pasts rather than determining the future and past with certainty.</li><li><strong>Quantum physics tells us that no matter how thorough our observation of the present, the (unobserved) past, like the future, is indefinite and exists only as a spectrum of possibilities. The universe, according to quantum physics, has no single past, or history. The fact that the past takes no definite form means that observations you make on a system in the present affect its past.</strong></li><li>Electric and magnetic forces are far stronger than gravity, but we don’t usually notice them in everyday life because a macroscopic body contains almost equal numbers of positive and negative electrical charges. This means that the electric and magnetic forces between two macroscopic bodies nearly cancel each other out, unlike the gravitational forces, which all add up.</li><li>Maxwell’s equations dictate that electromagnetic waves travel at a speed of about 300,000 kilometers a second, or about 670 million miles per hour. But to quote a speed means nothing unless you specify a frame of reference relative to which the speed is measured. That’s not something you usually need to think about in everyday life. When a speed limit sign reads 60 miles per hour, it is understood that your speed is measured relative to the road and not the black hole at the center of the Milky Way. But even in everyday life there are occasions in which you have to take into account reference frames. For example, if you carry a cup of tea up the aisle of a jet plane in flight, you might say your speed is 2 miles per hour. Someone on the ground, however, might say you were moving at 572 miles per hour. Lest you think that one or the other of those observers has a better claim to the truth, keep in mind that because the earth orbits the sun, someone watching you from the surface of that heavenly body would disagree with both and say you are moving at about 18 miles per second, not to mention envying your air-conditioning.<ol><li><em>Galilean Relativity</em></li></ol></li><li>Electromagnetic forces are responsible for all of chemistry and biology.</li><li>The histories that contribute to the Feynman sum don’t have an independent existence, but depend on what is being measured. We create history by our observation, rather than history creating us. The idea that the universe does not have a unique observer-independent history might seem to conflict with certain facts we know. There might be one history in which the moon is made of Roquefort cheese. But we have observed that the moon is not made of cheese, which is bad news for mice. Hence histories in which the moon is made of cheese do not contribute to the present state of our universe, though they might contribute to others. That might sound like science fiction, but it isn’t.</li><li>What makes this universe interesting is that although the fundamental “physics” of this universe is simple, the “chemistry” can be complicated. That is, composite objects exist on different scales. At the smallest scale, the fundamental physics tells us that there are just live and dead squares. On a larger scale, there are gliders, blinkers, and still-life blocks. At a still larger scale there are even more complex objects, such as …</li></ol></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blas.com/the-grand-design/">https://blas.com/the-grand-design/</a></em></p>]]>
            </description>
            <link>https://blas.com/the-grand-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646120</guid>
            <pubDate>Thu, 01 Oct 2020 01:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Computer Dungeon Slash Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24646063">thread link</a>) | @panic
<br/>
September 30, 2020 | https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem | <a href="https://web.archive.org/web/*/https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-article_id="496">


    

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image2.png"></p>


        

    


<p>I consider <a href="https://museumofzzt.com/file/c/CDZ20MOZ.ZIP" target="_blank"><i>Computer Dungeon Slash: ZZT 2.0</i></a> my personal best for ZZT games. I've now released two versions, one in September of 2019 and then another with some updates and optimizations in May of 2020. Aside from a couple of smaller errors and special-thanks additions, there's not much more to fix, so this will probably be the final version with any major changes.</p>

<p>Like some of my previous ZZT games, it relies heavily on procedural generation, with apparently such complexity that Dr. Dos called it "basically sorcery" during their <a href="https://museumofzzt.com/article/479/livestream-computer-dungeon-slash-zzt-20">playthrough on Twitch</a>, which I took as a great compliment. He also mentioned that this game, its generators in particular, could use a write-up. So I wrote one!</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image24.png"></p>

<p>In case you're reading this and unfamiliar with this game, it concerns a player finding themselves in the town of Habeas Corpus, where almost everyone and everything has been swallowed by the dungeon.</p>

<p>The player's task is to brave the randomly-generated dungeon, rescuing the town and townspeople from its clutches.</p>

<p>There's not much more plot or lore than the above, since I focused mainly on characterization in my worldbuilding and most of the actual plot isn't revealed until the end.</p>

<p>So what about the workings of this game?</p>

<p>I'll start with "sorcery"--there's something to that, for sure. When I work with procedural generation it feels a bit like alchemy. Scientific, but also a little bit mysterious and magical. I hope this article helps you better understand the scientific side of that coin.</p>

<p>For readers not intimately familiar with ZZT, one reason a veteran ZZTer would call my level generation "sorcery"  is its limitations. ZZT is a 1991 DOS game-creation-system, after all, simple enough for 8-year-old me to use. So if you don't know anything about ZZT coming in, I hope this write-up helps you better understand the absurdity and appeal of working in it and pushing its limits.</p>

<p>Further, if you came into this wanting to know how this stuff works so that you can experiment with it or even improve on it, I want you to be empowered to do so.</p>

<h2>Goals</h2>

<p>With <i>Computer Dungeon Slash: ZZT</i> (called <i>CDZ</i> here for short) I had three goals for generation. I wanted levels to be interesting to look at, fun to play, and fair. What does fair mean?</p>

<p>Most previous ZZT releases with procedural generation would probably not soft-lock players (block them off from finishing the game). In the early 2000s when this fad hit, most ZZTers involved were in high school and "probably not" was enough. But that small chance of soft-locking players with my generators annoyed me even then.</p>

<p>With <i>CDZ</i>, I wanted some certainty that my algorithms absolutely would not soft-lock players.</p>

<p>With these goals in mind, let's look at the tools I had to accomplish them.</p>

<h2>Building Blocks for Procedural Level Generation in ZZT</h2>

<p>ZZT is tile-based, so making it create its own levels is kind of like generating dungeons for classic ASCII roguelikes, except with much more restrictive tools and limits than, for example, C++ or Python. There's no way to easily store level layout data outside of "in the level", and ZZT boasts precious few variables and only ten true-or-false flags. In addition, the entire game is made up of "boards" of only 60x25 tiles! Despite being such a limited system, ZZT lets us do a fair amount.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image4.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image7.gif"></p>

<p>Almost any element (terrain or other object) that takes up a space on a board is helpful, but a few basic ones are laid out in a reference image on the left. Fake walls prove pretty invaluable because they don't block objects but help the engine easily keep track of where another terrain type <i>will</i> later appear.</p>

<p>While <i>CDZ</i> uses sliders and boulders to some extent, the classic examples of ZZT level generators using sliders and boulders are probably WiL's <i>Run-On</i> and Benco's <i>Lost</i>.</p>

<p>And of course, one of the elements of play is actually <i>called</i> an object, and can run little scripts in ZZT-OOP, the engine's default "language." ZZT-OOP has a number of helpful commands for procedural generation.</p>

<p>The <code>#change</code> command can change almost any ZZT gameplay element into almost any other, which is invaluable both for structuring and theming levels. <code>#put THING DIRECTION</code> and <code>#become THING</code> allow for level builder objects to modify environments directly, and they have a more complex use we'll go into later.</p>

<p>Procedural level generation in <i>CDZ</i> is random. Appropriately, ZZT-OOP's random directions proved immensely useful in making it happen. A number of situations call for a "four-sided" dice-roll, and ZZT does have an <i>rnd</i> direction (randomly north, south, east, or west), but as the reader may know, <i>rnd</i> is twice as likely to give an east-west result as a north-south. So what to do?</p>

<p>Well, there are also <i>rndne</i> (north or east) and <i>rndp DIRECTION</i> (one of two directions perpendicular to <i>DIRECTION</i>). Because <i>rndne</i> is a valid direction in itself, you can use <i>rndp rndne</i> to get a random cardinal direction with equal probability of each. (I'm ashamed that I didn't realize that one until reading Anna Anthropy's <i>ZZT</i> a few years back.)</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image14.gif"></p>

<p>In ZZT, <code>#if blocked DIRECTION</code> tells an object whether it is blocked in a given direction. And <code>#send OBJECTNAME:LABEL</code> tells another object, <i>OBJECTNAME</i>, to immediately begin executing code starting with <i>:LABEL</i>.</p>

<p>Slime enemies move erratically and leave breakable walls behind, so you can change their color frequently to fill empty spaces with different colors of breakable walls.</p>

<p>One last limitation and one last "coding" trick deserves mention. ZZT has a limit of about 20 kilobytes per board (including code) before the board misbehaves or gets corrupted at runtime. Objects can use the command <code>#bind OBJECTNAME</code> to work from the same exact instance of the same code as the other object <i>OBJECTNAME</i>, saving valuable code space.</p>

<p>Nowadays, one can "pre-bind" objects with external editors, causing them to share identical labels and behaviors but eliminating the need for the 5+ bytes of space that a <code>#bind</code> command needs.</p>

<h2>Two Big Insights</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image18.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image20.png"></p>

<p>In addition to the more concrete "tools" above, two big conceptual insights greatly impacted this project. The first is about level connectedness, and it hit me after reading Rabbitboots's musings on house generation in <a href="https://museumofzzt.com/file/d/dood2018.zip" target="_blank"><i>Doodads 2018</i></a>.</p>

<p>Say I have a house with four rooms, and I block off only one doorway in the house, as on the left. Any room in the house can still visit any other.</p>

<p>Rabbitboots goes on to note that if we make a larger house out of smaller ones, the large house remains fully connected.</p>

<p>If House A connects to House B and B connects to House C, then A connects to C.</p>

<p>This was huge for me. It gave me hope that I could avoid soft-locks while also making more interesting, varied levels.</p>

<p>Shortly after the 2019 release, while looking at TriphEd's maze generation in <a href="https://museumofzzt.com/file/b/BACKTRAX.zip" target="_blank"><i>Backtrax</i></a>, I had another "Aha!" moment.</p>


<p>The algorithm is best explained step-by-step, and you can follow along with the following roughly equivalent method if you have a pencil and paper.</p>

<p>(1) Start with a grid of dots. Any size 3 x 3 or up will do.</p>

<p>(2) Connect all the outer dots along the edge so that they make a rectangle.</p>

<p>(3) For each "middle dot" within the square, draw <i>exactly one line</i> from that dot to any dot directly above, below, left, or right of it. Edge dots can receive lines.</p>

<p>If you used a 3 x 3 grid of dots, the end result will resemble the 2 x 2 house above.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/backtrax-levels.gif"></p>

<p>Any edge tile can access any other edge tile in this algorithm. It can leave some squares inaccessible from the edges, but this is acceptable if nothing essential to player progress is placed in those tiles.</p>

<p>In ZZT, you can accomplish this by having objects use <code>#put rndp rndne ELEMENT</code> on a grid, and that's exactly what <i>Backtrax</i> is doing.</p>

<p>A <i>very</i> small set of soft-lock possibilities does exist in <i>Backtrax</i>. Because there's a blocking linewall diagonally southeast of the lower-right-hand wall generator object, the wrong combinations of walls <i>could</i> block the player, but it is <i>incredibly</i> unlikely and easily remedied.</p>

<p>This is the most elegant level generator in ZZT to date--and also, in case it wasn't already elegant enough, it weighs in at only 10.9 kilobytes and re-uses its "grid" after you reach the exit, using a separate trick (that I won't discuss in detail here) to teleport the player back to the start for a new level.</p>

<p>Recognize TriphEd's genius.</p>

<p>After the initial <i>CDZ</i> release, I experimented a lot with this algorithm. Several generators in version 2.0 benefited from its use. We can now move slowly but surely into the actual inner workings of this game.</p>

<h2>Primary Generators</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image6.png"></p>

<p><i>Computer Dungeon Slash</i> level generators have a "primary generator" object that handles a lot of needed dice-rolls and uses <code>#send</code> to communicate its randomization to different groups of objects. It's usually set up as on the left, or similar.</p>

<p>This particular setup involves fake walls placed north, south, east, and west of the primary generator and water (a blocking terrain) in the four corners. To make a four-direction roll, it uses <code>#put rndp rndne gem</code> and then iterates over some variation of:</p>

<code>#if blocked n #send object:option1
#if blocked e #send object:option2
#if blocked s #send object:option3
#if blocked w #send object:option4</code>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image16.png"></p>

<p>The objects referred to in the <code>#send object:option</code> commands  are pre-bound objects with exactly the same code, and positioned so that only one of them will place a wall, generate an important key, etc. at the time they're called. In this example, the pre-bound group of objects has this code:</p><p>

<code>@object
#cycle 1
#end
:option1
#if blocked n become solid
#die
:option2
#if blocked e become solid
#die
:option3
#if blocked s become solid
#die
:option4
#if blocked w become solid
#die</code></p><p>There is a fake wall in the middle of the house, so that only one object becomes a wall, and the rest die. Then the primary generator turns the fake into a solid wall.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image23.gif"></p>

<p>This method also extends to larger houses similar to those in the <i>Doodads 2018</i> example, and can …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</a></em></p>]]>
            </description>
            <link>https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646063</guid>
            <pubDate>Thu, 01 Oct 2020 00:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 175 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> – the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown—similar to what was in place in the spring—would not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau—a signatory of the letter—pointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases […] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are “now facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.”</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday—the day 700 new cases were recorded—up from 65 a week before; however, on April 24—when 640 new cases were recorded—government data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ≥60 year olds, now in Sept only 14% of cases are in ≥60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children’s rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government’s response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It’s time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
    </channel>
</rss>
